{"153890":{"abstract":"Many digital images are not acquired for documentary evidence or for archival use, but instead are intermediate pieces of information to be ultimately used by a human to assess a situation, make a decision, or reach a conclusion. Often, the image need not provide \"picture-perfect quality\" in order for a human to successfully perform a task - consider security screening of carry-on baggage, for example. Many tasks can be easily performed with images that would be considered to be severely degraded in a purely aesthetic sense. To date, however, image assessment algorithms have been primarily focused on evaluating aesthetic quality. These algorithms are typically designed for relatively high-quality images, and they do not perform well on highly degraded images which exhibit low aesthetic quality but remain useful for human-performed tasks.<br\/><br\/>This research characterizes the suitability of an image for recognition and the perceived utility in terms of conveying information about content. The characterization is performed in terms of properties of the image, rather than in terms of the response of higher-level vision to the image, and is based upon extensive subjective experiments quantifing the perceived utility of highly degraded images and identifing recognition thresholds for images - maximally degraded images that still allow recognition. A utility measure is developed which takes as input the original image and the distorted image and outputs a distance quantifying the amount of degradation in the image relative to both the recognition threshold (at the low end) and to the original or a visually lossless representation of the original (at the high end). Use of this measure is demonstrated by integration this measure into imaging applications including compression and enhancement.","title":"CIF:Small:Visual Information Measures for Task-Based Imaging Applications","awardID":"0916471","effectiveDate":"2009-08-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":["530523"],"PO":["564898"]},"151052":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). The goal of this project is to develop computational models of the nonverbal behavior and interactive strategies observed during face-to-face teaching. These computational models will serve as a foundation for a new generation of embodied teaching agents that approximate the benefits of face-to-face human tutoring. The project will help advance the science of learning and teaching by improving our understanding of the dynamics of nonverbal behavior in teaching at a computational level, across multiple time scales: From low-level micro-expressions in the timescale of tens of milliseconds, to cognitive and affective processes with time scales of seconds, to higher level strategic behaviors operating at longer time scales.<br\/><br\/>In addition to its scientific and technological value, this project has a significant outreach component. The project would help grow links between a research oriented campus (UCSD) an undergraduate teaching university (SDSU). The robotics aspects of the project will be developed in collaboration with the Preuss School Robotics Club. The Preuss School is a charter school for low-income students in grades 6-12 and is currently ranked as one of the top high schools in the nation.","title":"HCC: Medium: Collaborative Research: Computational Analysis of Nonverbal Behavior in Adaptive Tutoring","awardID":"0905622","effectiveDate":"2009-08-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["523911","463668"],"PO":["565227"]},"165363":{"abstract":"","title":"CAREER: Error-Correcting Codes --- List Decoding and Related Algorithmic Challenges","awardID":"1002437","effectiveDate":"2009-08-20","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["485293"],"PO":["550329"]},"154121":{"abstract":"This project develops compile time techniques and a software tool (called the Reduction Simplification Engine, RSE) for optimization of equational programs with reductions (associative, and usually commutative, operations applied to collections of data). By using these techniques and tools it is possible to generate programs with lower asymptotic complexity than the original specification. Such complexity reduction is an ambitious, almost unheard of, goal in compilation: most compilers seek constant factor gains, usually a few percentage points. The techniques developed in this project build on more than twenty years of research by the PI on a formalism called the \"polyhedral model.\" The main novelty of the current effort is that in addition to polyhedral techniques, algebraic properties such as idempotency and distributivity are also used to augment the analyses performed.","title":"SHF: Small: Simplifying Reductions","awardID":"0917319","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["528018"],"PO":["565272"]},"154011":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 <br\/>(Public Law 111-5). <br\/>The research funded by this award targets the difficult problem of how to debug programs running on large parallel systems. The state <br\/>of hundreds to hundreds of thousands of parallel tasks that form a single <br\/>computation are too complicated for a programmer to usefully analyze. <br\/>This project will develop tools to find similarities between the state of <br\/>different processes, simplifying the task of the programmer. The challenge <br\/>in finding these similar tasks is to do it efficiently, without imposing an<br\/>overhead so hight that the tool is useless. A naive implementation would <br\/>compare the state of all processors against one another, and would introduce <br\/>overheads increasing as the square of the number of processors. Our approach <br\/>will successively refine sets of similar processes, will use key attributes <br\/>of program behavior (e.g. communication patterns) to perform this grouping. <br\/>We will also investigate the use these groups of similar processes to allow <br\/>invariance and statistically based techniques developed for sequential <br\/>programs (such as value and PC invariance) to be effectively adapted to <br\/>parallel programs. Because these techniques look for rarely occurring program<br\/>activities, applying them to disparate processes together will introduce<br\/>noise into the analysis, severely diminishing their accuracy. The use of <br\/>our grouping strategy will allow effective parallelization of the <br\/>techniques, allowing them to be applied with significantly less overhead <br\/>than when used with sequential applications.","title":"SHF: SMALL: Ant: Automatic and Manual Debugging Support for Massively Parallel Programs","awardID":"0916901","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}}],"PIcoPI":["550994","550995"],"PO":["565272"]},"148940":{"abstract":"Advanced wireless technologies allow users to communicate anytime and anywhere and wireless communities are becoming ubiquitous with the proliferation of various handheld mobile devices. These communities are very different from traditional Internet-based online communities in which people are connected with one another but neither know each other in person nor necessarily care where they are at any specific moment. In contrast, in wireless communities, people are much more closely bound to each other through a sense of sharing a common physical and\/or social context. This planning grant explores small 'nomadic' and 'settled'- like wireless communities in educational environments and the social trust aspects when using educational services within these mobile learning communities (MLC). The PIs develop a limited mobile wireless testbed, with hybrid wireless peer-to-peer, and infrastructure-based connectivity, and a small set of trust-ensuring educational services, made available in the form of a MLC-toolkit to students in a selected class. The PIs validate the MLC- toolkit in a small MLC group and explore the social trust depending on the type of class \/ users activity, active participation of students, and mobility of students (nomadic versus settled). The PIs also explore, where the assurance of social trust comes from, e.g., from friends and their various types of ties (strong versus weak ties), and\/or from the underlying software and hardware infrastructure. The impact is in developing, and deploying the MLC-toolkit, and understanding social trust metrics and their relations to users and underlying infrastructures.","title":"II-NEW: Exploration of Social Trust in Mobile Educational Environments","awardID":"0855129","effectiveDate":"2009-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["451105","563534","561784","561785","457205"],"PO":["497499"]},"154022":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Traditionally collisions of transmitted packets in wireless networks have been treated as a hindrance. If however the information contained in the packets is recovered even after the packets collide, significantly higher transmission rates can be attained in wireless systems. The project is developing a novel network-friendly approach for resolving collisions.<br\/><br\/>The relevant information is being extracted from collided packets through sophisticated signal processing and higher layer resource allocation schemes that function in conjunction with the physical layer techniques. The signal processing techniques recover the relevant information by exploiting source of diversity that are present in a collision, such as small user delays and carrier frequency offsets. The higher layer resource allocation techniques maximize the throughput and minimize the delay in end-to-end delivery of information through the exploitation of collision resolution capabilities at the physical layer.<br\/><br\/>This research will lead to a quantum leap in performance of wireless systems which will in turn facilitate a plethora of advanced applications such as high quality multimedia transmission over wireless networks, rescue and recovery operations, etc. Results will be disseminated through (i) publications of scholarly papers in premier journals and conferences and available through the world-wide-web, and (ii) direct interactions with wireless industry and non-profit organizations which will facilitate the design of wireless systems that can be effectively used in daily lives.","title":"CNS:NeTS: SMALL: Collaborative research: Collision: Friend or Foe","awardID":"0916947","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["526916","503250"],"PO":["565303"]},"148962":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>The objective of this project is to inspire students at Tuskegee University and Auburn University in mathematics, aerospace science engineering, and networking by inviting them to contribute to a grand project: fly safely and efficiently, in a limited space, a fleet of autonomous UAVs on a cooperative mission with terrestrial vehicles. <br\/><br\/>The team of Dr. Sriram Vishwanath at the University of Texas (UT) Austin will deliver six Proteus modules (terrestrial vehicles) and will assist the team at Tuskegee University (TU) and Auburn University (AU) to build for this project six other Proteus modules adapted to the ultimate objective of this project. Dr. Biaz and his students will develop and implement at Auburn University the networking protocols that will allow all terrestrial and aerial vehicles to communicate with each other. The implementation will be made through series of laboratory exercises and research projects collaboratively conducted at Tuskegee University and Auburn University. <br\/><br\/>Intellectual Merit: This project will set up a research infrastructure that enables laboratory exercises in mathematics, aerospace and computer networking. For each discipline, students will contribute to the solution of challenging problems. To this day, most research on mobile ad hoc networks is conducted through simulation. This research infrastructure will allow students to test and evaluate the most promising networking protocols with hardware-in-the-loop. In mathematics, students will realize for example that solving a system of equations not only can obviously determine the position of a vehicle but also can be directly used to enable networking coding and improve communications efficiency. <br\/><br\/>Broader Impacts: <br\/>Tuskegee University is the only HBCU with an ABET-accredited Aerospace Engineering program and graduates the largest number of African-American aerospace engineers in the US. This research infrastructure will contribute to attract and retain students in STEM fields at Auburn University and Tuskegee University in general and under-represented minorities in particular. The multidisciplinary collaboration between Tuskegee University, UT Austin and Auburn University will benefit students from these institutions to work in a multi-disciplinary environment and will expose them to state of the art education and research. The results of the collaborative effort will be disseminated through presentations at engineering education and other professional conferences.","title":"Collaborative Research: CRI-RUI: II-NEW: ATTRACT: Aerial and Terrestrial Testbed for Research in Aerospace, Computing, and maThematics","awardID":"0855182","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[397025,"505916"],"PO":["565090"]},"154055":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>This project develops novel methods for integrating image and non-image geospatial data to (1) advance the state-of-the-art of automated remote sensed image analysis and, in turn, (2) improve the coverage and fidelity of the non-image repositories.<br\/><br\/>A characteristic of remote sensed imagery which has not been sufficiently exploited by the analysis community is that the images can be georeferenced to extensive repositories of non-image geospatial data such as maps and geographic dictionaries termed gazetteers. In particular, these associations represent a rich source of labeled data needed to train the analysis algorithms.<br\/><br\/>The first part of this project develops a framework for learning appearance models for a large set of geospatial objects indexed by an extensive gazetteer in an unsupervised fashion. Besides the standard challenges such as choice of features and form of the model, this problem is made interesting by the fact that current gazetteers only specify the spatial footprint of indexed objects using a single point location. Methods are explored for simultaneously estimating the model parameters and the spatial extents of the known objects.<br\/><br\/>The second part investigates using the learned models to update the gazetteer from imagery. This includes estimating the spatial extents of known object instances as well as detecting unknown or novel instances.<br\/><br\/>The project has research and educational synergies with a Spatial Analysis Research Center that the PI is establishing at the new University of California at Merced. The PI plans to open imagery so that evaluation datasets can be made publicly available through the project website (http:\/\/vision.ucmerced.edu\/projects\/integrating\/).","title":"III:Small:RUI:Integrating Image and Non-Image Geospatial Data","awardID":"0917069","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["502374"],"PO":["563751"]},"154066":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Communication protocols on the Internet are typically designed first to work, then to interoperate and evolve, and eventually to be resilient to misbehavior and selfishness. Unfortunately, these extensions to protocols often sacrifice backward compatibility, because otherwise a misbehaving user can claim to be legacy. At the other extreme, the ``incentive compatible'' protocols are often designed assuming selfish users are also myopic, focusing narrowly on the short term and unwilling to donate resources for no immediate gain. This project investigates the iOwe, a new primitive for exchanging value in competitive protocols, and applies it to two new overlay network protocols, PeerWise and HoodNets. The iOwe is a verifiable promise of future service that can be exchanged by nodes that trust the issuer. PeerWise and HoodNets are protocols by which users can achieve better network performance, either in terms of latency (PeerWise) or wireless bandwidth (HoodNets). Both rely on a non-simultaneous exchange of service: PeerWise because simultaneous use is unlikely, HoodNets because channel bonding achieves better apparent bandwidth only when both links aren't already saturated. The project results are expected to provide new facilities to help build protocols in which repeated interactions permit users to operate at a short term loss for long term gain. Similarly, the protocols being prototyped can aid in the robustness and performance of network service.","title":"NeTS: Small: Greed-Resistant Protocols","awardID":"0917098","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["438680","548322"],"PO":["564993"]},"148995":{"abstract":"The FrameNet project has been building a lexical database containing<br\/>highly detailed information about the syntax and semantics of the<br\/>different senses of English words, with applications such as question<br\/>answering and information extraction. The database is based on<br\/>Charles Fillmore's theory of Frame Semantics, relating word meanings<br\/>to conceptualizations of situations and their participants, ranging<br\/>from simple actions like Placing to complex events such as a Criminal<br\/>process, with subevents like Arraignment and Trial. The<br\/>generalizations are derived from annotated example sentences from<br\/>large text corpora.<br\/><br\/>In this planning grant, input will be gathered from researchers in the<br\/>NLP field regarding how the FrameNet data is currently being used, how<br\/>it can be made more useful to a wider range of users, and how it can<br\/>be enhanced so as to enable new directions of research. As part of<br\/>this, a series of conferences will be held, both face-to-face and by<br\/>videoconference, to plan future FrameNet development and cooperation<br\/>and alignment of data with other lexical resources and annotation<br\/>projects, such as WordNet, PropBank, OntoNotes, etc., with the<br\/>ultimate goal of improving results in sense disambiguation, semantic<br\/>role recognition, and natural language understanding in general.","title":"CI-ADDO-EN: FrameNet 3: Upgrading FrameNet for the NLP Community","awardID":"0855271","effectiveDate":"2009-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["561714"],"PO":["565215"]},"146575":{"abstract":"Most words have more than one meaning. The standard computational model for word meaning is through lists of dictionary senses. However, choosing the right dictionary sense is a highly difficult task for humans as well as machines. This CAREER project follows the hypothesis, based on current models of human concept representation, that word meaning is better described through a graded notion of similarity than through dictionary senses. The hypothesis is tested through a novel meaning annotation framework and computationally through a vector space model of word meaning. The model uses vector characterizations of typical arguments to compute the meaning of an individual occurrence compositionally from the words in its syntactic context. For evaluation, the project focuses on the ability to draw appropriate inferences, in both shallow and deep frameworks, from similarity-based meaning representations. The research effort goes together with educational work that focuses on supporting undergraduate research, stressing hands-on data exploration and interdisciplinary work.<br\/><br\/>The characterization of word meaning is a central issue in lexical semantics and in computational linguistics as a whole. This CAREER project will yield a broadly applicable paradigm that describes word meaning without recourse to dictionary senses. It aims both to provide a more cognitively adequate model and to benefit language technology applications, in particular information retrieval, which already relies heavily on vector space models.","title":"CAREER: Word Meaning: Beyond Dictionary Senses","awardID":"0845925","effectiveDate":"2009-08-15","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"1311","name":"LINGUISTICS"}}],"PIcoPI":[390771],"PO":["565215"]},"154077":{"abstract":"The research will develop the foundations for a framework for reasoning about the formal properties of programming languages, compilers, software specifications, concurrent systems and other related computational systems. The framework will be based on two separate but interacting logics. One logic will be geared towards specifying and prototyping varied software systems. The second logic, referred to as the meta-logic, will provide flexible and powerful mechanisms for reasoning about specifications written in the first logic. The objects to be specified and reasoned about typically have complex syntactic structures, often involving some form of binding. Use will be made of a higher-order approach to representing syntactic structure in both logics to facilitate a natural treatment of such objects. Useful new logical capabilities will be exposed and embedded in actual computer systems that can be used in prototyping and reasoning tasks in the intended domains. The insights and the tools produced will be used pedagogically to expose high-school students and beginning undergraduates to important ideas in logic and computation. A close collaboration with a group of French researchers will provide an international dimension to the research, co-funded in part by the NSF Office of International Science and Engineering. In the long run, mechanized formal specification of (and reasoning about) programming languages has clear application to the improvement of software infrastructure in the real world: its correctness, reliability, maintainability, and security.","title":"SHF:Small:Reasoning about Specifications of Computations","awardID":"0917140","effectiveDate":"2009-08-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["499410"],"PO":["564388"]},"146586":{"abstract":"Proposal ID: 0845983 <br\/>Title: CAREER: Wireless Network-on-Chip: A New Communication Paradigm for Heterogeneous Gigascale MPSoCs<br\/>PI name: Zhao, Danella <br\/>Institution: University of Louisiana at Lafayette <br\/><br\/>ABSTRACT<br\/>Many-core System-on-Chip (MCSoC) designs are rapidly emerging, where hundreds or even thousands of IP cores are integrated on a single die. Such MCSoC devices allow superior performance gains while side-stepping the power and heat dissipation limitations of clock frequency scaling. Consequently, the on-chip communication fabric becomes the performance determinant. This project aims at developing a new on-chip communication system, dubbed Wireless Network-on-Chip (WNoC) to sustain the exponential growth of computing performance in the next generation gigascale heterogeneous MCSoCs. The PI lays out the research directions of WNoC from various crucial aspects. The UWB physical layer will be explored to accomplish high data-rate, high bandwidth and low-power wireless on-chip communication. The system architecture will be designed in a way that decouples communication from computation, and a reconfigurable RF infrastructure will be developed to address the heterogeneity of MCSoC. The layered protocol will be specially designed to tackle distinct features of WNoC from conventional wireless networks and to simplify the hardware implementation. Highly compact and configurable RF nodes will be designed to support heterogeneous architecture and customization for specific application mapping. A suite of development and prototyping activities will be carried out to demonstrate the applicability and feasibility of WNoC. Some breakthroughs could be forthcoming in the area of intra-chip RF\/wireless interconnect network for high performance computing in the upcoming nanoscale MCSoC paradigm. <br\/><br\/><br\/>Boarder Impact: This project will have a very broad impact on the on-going and future research in Nanodevices for high performance computation. Innovative pedagogical methods for classroom instruction will be explored. Research opportunities will be offered for minority and female students. It will foster the partnerships with industry and government laboratories.","title":"CAREER: Wireless Network-on-Chip: A New Communication Paradigm for Heterogeneous Gigascale MPSoCs","awardID":"0845983","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[390797],"PO":["562984"]},"158576":{"abstract":"The Twenty-Second ACM Symposium on Operating Systems Principles will be held in Big Sky, Montana on October 11-14, 2009. For over 30 years SOSP has been the leading forum for innovative research in operating systems. Like its predecessors, SOSP 2009 will bring together researchers from around the world to present and discuss the latest results. In addition to such traditional topics as the performance, functionality, and security of kernels, file systems, and networks, this year's conference will place increasing attention on such emerging topics as ubiquitous and mobile computing, sensor networks, overlay and peer-to-peer communications, and power management. Particularly noteworthy papers will be forwarded to ACM Transactions on Computer Systems for possible journal publication. There will also be poster and work-in-progress sessions for the presentation of promising preliminary work.<br\/>This proposal requests funding to support the attendance of 20 US-based graduate students. Participation in leading conferences is an extremely important part of the graduate school experience, providing the opportunity to interact with more senior researchers and to be exposed to leading edge work. The support requested in this proposal will make possible the participation of students who would otherwise be unable to attend. Particular attention will be paid to directing support towards underrepresented minorities including women, African-Americans, and Native Americans.","title":"Travel Support for the 22nd ACM Symposium on Operating Systems Principles (SOSP 2009)","awardID":"0936184","effectiveDate":"2009-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["463055"],"PO":["493916"]},"148687":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Accurate modeling of power, leakage, and timing while accounting for process variations, is crucial for the manufacturable design of nanoscale CMOS integrated circuits. Thus, there is a pressing need for statistical models that allow design engineers to make fast architectural or system level design space exploration without resorting to a complete design iteration, from system to physical level. The thrust of the project's methodology is the progression of data transfer from lowest (transistor) to highest (system) level while utilizing minimal data from actual silicon. This allows for fast concurrent design for manufacturing of new systems with a clear delineation of the needed data at every level.<br\/><br\/>To conduct research on nanoscale CMOS modeling that can be used for realization of robust circuits, and to make the deliverables available to the VLSI and educational communities, the project utilizes the following infrastructure: <br\/>(1) Specialized equipment: mixed-signal analyzer, probing station and arbitrary waveform generator for sample data collection, probing and analysis for model validation.<br\/>(2) Computing resources: a high-end, 4 processor server with 16-GB local memory and 4-TB RAID5 storage to be used by two faculty members and 10 students for nanoscale data acquisition, control, analysis, and storage.<br\/>(3) Research and development personnel to develop the models and libraries, to validate the methodology, and to maintain the infrastructure.<br\/>The educational impact of the project is 3-fold: impact on curricula at UNT, impact on curricula of other researchers who will use this infrastructure, and impact on the community colleges around the Dallas-Fort Worth metroplex.","title":"II-EN: Infrastructure Acquisition for Statistical Power, Leakage, and Timing Modeling Towards Realization of Robust Complex Nanoelectronic Circuits","awardID":"0854182","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["529751","470229"],"PO":["564778"]},"149325":{"abstract":"By allowing us to understand one concept in terms of another, metaphors enrich our mental imagery and imbue concepts with meaningful attributes. The cognitive juxtaposition provided by metaphors stimulates creativity by allowing us to see a concept from a new point of view, highlighting previously hidden aspects. This project develops meta4acle, a Creative IT software tool to help build creativity, inspiration and communication in design teams through the generation and application of metaphors. <br\/><br\/>The project develops algorithms for assisted metaphor generation to tap into a pool of knowledge significantly larger than that of a single design team to find appropriate metaphors for better framing a design problem and expanding the space of concepts. In this project, variations in the creative benefit of meta4acle will be observed in different user demographics and at different stages of the design process. <br\/><br\/>The project includes the development of curricular modules on the creative use of metaphors for use in design classes at both the undergraduate and graduate levels at the University of California at Berkeley. Given the social imperative and need for creative solutions for sustainable products, services and building designs, sustainability and biomimicry will be a focus for expanding the metaphor database and will provide the major test bed and case study for implementation and evaluation. The meta4acle tool will be tested with top design firms in the San Francisco Bay Area in order to explore its potential use and impact in the commercial sector.","title":"Pilot: Meta4acle - A Software Tool for Generating Metaphors, Stimulating Creativity and Framing Solutions","awardID":"0856098","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":["555580"],"PO":["562669"]},"152560":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Moore?s law promises consistent increasing transistor densities for the foreseeable future. However, device scaling no longer delivers the energy gains that drove the semiconductor growth of the past several decades. This has created a design paradox: more gates can now fit on a die, but cannot actually be used due to strict power limits. In this project, we will address this energy crisis through the universal application of ?near-threshold computing? (NTC), where devices operate at or near their threshold voltage to obtain 10X or higher energy efficiency improvements. To accomplish this we focus on three key challenges that to date have kept low voltage operation from widespread use: 1) 10X loss in performance, 2) 5X increase in performance variation, and 3) 5 orders of magnitude increase in functional failure. We present a synergistic approach combining methods from algorithm and architecture levels to the circuit and technology levels. We will demonstrate NTC for applications that range from sensor-based platforms which critically depend on ultra-low power (\u00a1\u00dcmW) and reduced form factor (mm3) to unlock new applications, to high-performance platforms in large data-centers, which dissipate so much power that they require co-location near dedicated cooling facilities. Our end goal is to reduce national energy consumption and environmental impact by providing dramatic gains in energy efficiency while also opening up new application areas in health care by providing for in situ monitoring of biological functions with minimum intervention.","title":"CSR:Large:Collaborative Research:Reclaiming Moore's Law through Ultra Energy Efficient Computing","awardID":"0910699","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["518174"],"PO":["565255"]},"153660":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\"<br\/><br\/>The proliferation of multiple cores on the same die has given rise to communication-centric systems, wherein the design of the interconnection network has become extremely important. To address the growing wire delay problems and improve performance in CMP architectures, a growing number of multi-core designs have adopted a more flexible, scalable, packet-switched architecture called Network-on-Chip (NoC). Of the several challenges facing current NoC designs, the three prominent ones are power dissipation, die area, and overall performance. In this research, we propose to develop energy-efficient, area-efficient, high-performance, and fault-tolerant NoCs by exploiting innovative technological (circuit) optimizations and architectural design space. On the technology side, we will develop and design novel circuit techniques that will achieve significant power savings, fault-tolerance and considerable reduction in area requirements. On the architectural side, we will develop novel NoC designs that incorporate the proposed circuit design techniques and further improve network performance. This research is an organized effort that will combine circuit analysis, architecture study, performance evaluation and design synthesis. We will develop a comprehensive NoC design platform which will analyze the trade-offs among various parameters of interest ? power, area and performance. <br\/><br\/>The success of this research is likely to have a significant impact on the design of NoC architectures for CMPs. The proposed research will tackle some of the major limitations of NoC design, namely power consumption and reliability, and will make significant advances in understanding the interplay between performance, energy, and reliability for NoC architectures. Realistic solutions to these problems will provide the ability to continue the improvements in computational performance that the information technology sector of our economy depends on. This multi-disciplinary research will also play a major role in education by integrating discovery with teaching and training.","title":"SHF: Small: Collaborative Research: Design of Power and Area Efficient, Fault-tolerant Network-on-Chip Circuits and Architectures","awardID":"0915537","effectiveDate":"2009-08-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["289167","559883","417677","559859"],"PO":["366560"]},"153671":{"abstract":"The primary objective of this research is to develop new cognitively informed plan-based models of narrative action and to demonstrate that these models can be used both to control a virtual environment and to make effective predictions about the results of users' mental models of the stories that they characterize. Motivated by psychological models of plans and plan reasoning, this research builds on prior work in plan generation and plan-related communication to develop an architecture for creating understandable interaction in narrative-oriented virtual environments. The specific research program can be divided into two high-level thrusts: 1) Developing new generative knowledge representation schemes for the control of narrative action, focusing on the structures of conflict and goal dynamics. 2) Formally validating the results from the items via large-scale empirical evaluations. <br\/><br\/>This work will develop computational models of narrative, focusing on elements of creativity in narrative (as defined roughly by coherence and expectation violation). The project will explore the hypothesis that creativity in the design of many artifacts (and in the design of narrative in particular) is not only a property of the algorithms used to create the artifacts but also a property of how the artifacts are experienced or understood by human users.<br\/><br\/>This work will have a significant impact on the theory and understanding of the relationships between computation and cognition, particularly in the context of narrative. Because of the multidisciplinary nature of the research objectives, the project will produce significant advances in both computer science and cognitive science. It is anticipated that the resulting model will serve as a foundation for a new generation of tools that support mixed-initiative virtual world design, particularly focusing on the generation of narrative systems. In addition, the research will explore the use of the models to create customized, context-sensitive storylines for computer game-based learning environments. <br\/><br\/>The project will contribute to the infrastructure of science and education by training new researchers (graduate research assistants) in an area that is broadly multidisciplinary (computer science, cognitive science and narrative theory). These new researchers will gain from the project a unique integrated view of the contributing disciplines. The project will train undergraduates through involvement in formal and informal research exposure efforts supported in part by REU supplements.","title":"HCC: Small: Plan-Based Models of Narrative Structure for Virtual Environments","awardID":"0915598","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["550629"],"PO":["564456"]},"152593":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>The burgeoning revolution in high-end computer architecture has far reaching implications for the software infrastructure of tools for performance measurement, modeling, and optimization, which has been indispensable to improved productivity in computational science over the past decade. The heart of the problem is that new multicore processors are the foundation of next generation systems, ranging from workgroup clusters to petascale supercomputers. The main motivation by chip manufacturers for the movement to multicore processors is better performance per watt than the traditional single core processor. Hence, multicore processors are not equivalent to multiple CPUs that traditional tools addressed. While significant work is underway on understanding performance tradeoffs with multicores, much of this work is ad hoc and needs a unifying framework to which the community can contribute in a systematic manner. Furthermore, little work has been done on understanding performance-power tradeoffs in supercomputer systems for large-scale applications. It is important to understand performance and performance-power tradeoffs in the context of the significant resource sharing that occurs in multicore systems. <br\/><br\/>This proposal is focused on developing the Multicore Application Modeling Infrastructure (MAMI) that will facilitate systematic measurement, modeling, and prediction of performance, power consumption and performance-power tradeoffs in multicore systems. In addition to developing MAMI, the proposed work will use MAMI to model, analyze and optimize performance and power consumption of key benchmarks and applications on multicore systems.","title":"CSR: Large: Collaborative Research: Multi-core Applications Modeling Infrastructure (MAMI)","awardID":"0910784","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["563791"],"PO":["564778"]},"175033":{"abstract":"The research objective of this CAREER proposal is to develop computer hardware architectures that would accelerate cognitive applications based on hierarchical neocortex models. These new class of cognitive models have shown significant promise in describing the functioning of the neocortex. Cognitive applications include perception, natural language comprehension, and cognitive reflection and are important in a large variety of domains such as national security, medicine, transportation, industry, and science. Large scale implementations will also enable neurobiologists to evaluate new models of the neocortex. In this work, biologically inspired architectures will be developed for large scale FPGA systems and embedded processing applications. Once these are developed, a model to predict the performance of the cognitive models on other architectures will be investigated. The research work will enable real-time implementations of cognitive applications at the large scale through FPGA clusters and at the embedded scale through a specialized architecture.<br\/><br\/>The educational objectives of this proposal are aimed at benefiting students from the K-12 to the university level. At the university level, an architecture visualization tool to enhance learning of architecture concepts will be developed. In addition, the research ideas developed form this work will be introduced into the curriculum through classroom projects. At the K-12 level, a set of lesson plans and learning tools about computer technology will be developed for elementary school students. Elementary school teachers will be trained in the use of the tools and lesson plans through a series of workshops. This work will be implemented in collaboration with the \"Call Me Mister\" program at Clemson University (this program is aimed at increasing the number of minority school teachers in South Carolina).","title":"CAREER: Scalable Computer Architectures of Hierarchical Noeoctex Models and K-12 Education Enhancement","awardID":"1053149","effectiveDate":"2009-08-15","expirationDate":"2015-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["545710"],"PO":["366560"]},"154133":{"abstract":"Modern processors are designed to perform more tasks simultaneously, rather than to perform single tasks more quickly. These new multicore processors are powerful, but using that power is challenging; interesting problems often divide irregularly, requiring difficult and error-prone coordination among subtasks. Consequently, parallel programming is considered hard to learn and harder to do. Observationally Cooperative Multithreading (OCM) is a new approach. In programs written for cooperative multithreading (CM), subtasks take turns and execute one at a time. The CM model is well-known to rule out conflicts and to simplify programming. OCM takes these same programs but runs them on modern multicore machines, executing subtasks simultaneously when there are no conflicts. The result can be a speed and resource-utilization benefit with no extra complexity for programmers. Potentially, OCM could make concurrency more accessible to a broad audience, including introductory students. The research will develop OCM implementations using techniques such as Transactional Memory and Lock Inference, with the aim of fostering adoption of OCM by a large user community. Realistic benchmarks will be constructed to analyze the speed and scalability of OCM implementations, and to verify ease of programming in the OCM model.","title":"SHF: Small: RUI: Observationally Cooperative Multithreading","awardID":"0917345","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":["518669","533642"],"PO":["564588"]},"148952":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The objective of this project is to inspire students at Tuskegee University and Auburn University in mathematics, aerospace science engineering, and networking by inviting them to contribute to a grand project: fly safely and efficiently, in a limited space, a fleet of autonomous UAVs on a cooperative mission with terrestrial vehicles. <br\/><br\/>The team of Dr. Sriram Vishwanath at the University of Texas (UT) Austin will deliver six Proteus modules (terrestrial vehicles) and will assist the team at Tuskegee University (TU) and Auburn University (AU) to build for this project six other Proteus modules adapted to the ultimate objective of this project. Dr. Biaz and his students will develop and implement at Auburn University the networking protocols that will allow all terrestrial and aerial vehicles to communicate with each other. The implementation will be made through series of laboratory exercises and research projects collaboratively conducted at Tuskegee University and Auburn University. <br\/><br\/>Intellectual Merit: This project will set up a research infrastructure that enables laboratory exercises in mathematics, aerospace and computer networking. For each discipline, students will contribute to the solution of challenging problems. To this day, most research on mobile ad hoc networks is conducted through simulation. This research infrastructure will allow students to test and evaluate the most promising networking protocols with hardware-in-the-loop. In mathematics, students will realize for example that solving a system of equations not only can obviously determine the position of a vehicle but also can be directly used to enable networking coding and improve communications efficiency. <br\/><br\/>Broader Impacts:<br\/>Tuskegee University is the only HBCU with an ABET-accredited Aerospace Engineering program and graduates the largest number of African-American aerospace engineers in the US. This research infrastructure will contribute to attract and retain students in STEM fields at Auburn University and Tuskegee University in general and under-represented minorities in particular. The multidisciplinary collaboration between Tuskegee University, UT Austin and Auburn University will benefit students from these institutions to work in a multi-disciplinary environment and will expose them to state of the art education and research. The results of the collaborative effort will be disseminated through presentations at engineering education and other professional conferences.","title":"Collaborative Research: CRI - RUI: II - NEW: ATTRACT: Aerial and Terrestrial Testbed for Research in Aerospace, Computing, and maThematics","awardID":"0855155","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["526658","560478"],"PO":["565090"]},"148985":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>With the growth in the size of scientific applications the level of parallelism provided by existing techniques leads to suboptimal performance and, therefore, an integrated approach to parallelism is necessary. This research involves the acquisition of a cluster for high performance computing. Using this infrastructure the investigators will improve parallelism at many levels ranging from compiler to I\/O, in order to increase the execution performance of scientific applications. The infrastructure offers a valuable tool to validate the results on a state-of-the-art system using large scale scientific applications.<br\/><br\/>This research aims to elevate the productivity and efficiency of high-performance scientific computing through innovative language, compiler, empirical tuning, parallel I\/O, and power management technologies. The investigators develop new methods for flow-sensitive static and dynamic program analysis to enhance loop parallelization. The investigators implement new speculative parallelization techniques to expose higher levels of thread parallelism for chip-multiprocessors (CMPs). Furthermore, the investigators plan to build an integrated framework for parallel I\/O by studing various aspects of declustering, including novel declustering schemes, replicated declustering, heterogeneous declustering, adaptive declustering and declustering using multiple databases. Finally, the investigators plan to develop efficient energy management schemes for parallel high-performance clusters, study various fault tolerance approaches by exploring the inherent space redundancy in CMPs, and address the potential negative effects of energy management on system reliability. The computing platform enables the investigators to validate the impact of their research on application performance and scalability on a large scale parallel system.","title":"II-NEW: Enhanced Parallelization for High Performance Computing","awardID":"0855247","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["525789",397106,"451043","451043","538267","538267"],"PO":["565272"]},"146565":{"abstract":"Protein identification is a major research perspective in proteomics holding the promise of signaling and treating diseases. Several techniques have been developed for protein identification. Among which, tandem mass spectrometry (MS\/MS) is currently the most popular technique used to identify proteins. The process of identifying proteins by tandem mass spectrometry is analogous to identifying a person using his\/her fingerprints. Since a MS\/MS spectrum usually is incomplete and contains noise peaks due to contaminants, poor peptide segmentation, and other technical or biological reasons, it is a challenging problem to protein identification. The problem becomes more difficult when the spectrum contains post-translational modifications (PTMs). The presence of PTMs significantly increases the difficulty of both de novo sequencing and database search.<br\/><br\/>This research addresses this challenging problem of protein identification with theoretical studies and computational approaches. This work builds a complete system focusing on identifying proteins by determining the amino acid sequences of the proteins from their MS\/MS spectra. In particular, for a given experimental tandem mass spectrum, the system identifies its amino acid sequence and PTMs through a series of activities: (a) separating different ion types and noises, (b) generating sequence tags, c) identifying candidate peptide sequences, and (d) verifying the candidate peptide sequences and identifying PTMs.","title":"CAREER: A Complete System for Protein Identification with Computational Approaches","awardID":"0845888","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7946","name":"BIO COMPUTING"}}],"PIcoPI":["497974"],"PO":["565223"]},"149216":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\"<br\/><br\/>Music-making is universal and has been a conduit for human creativity for at least tens of thousands of years, and music plays an essential role in human social bonding, emotional communication, and entertainment. Because information technology and entertainment constitute an increasing share of the total economic output in developed countries, creativity lies at the heart of the modern economy. Yet the creativity that underlies musical domains is poorly understood. In this project the PI and his team will seek to understand, model, and support improvisation, or real-time collaborative creativity, in the context of music. Most musical traditions in the world use improvisation as a method of creativity, so analysis and modeling of improvisation in highly evolved musical systems should provide essential insights into creative activity. This study will consider a representative subset of musical traditions, in order to keep the results as broadly applicable as possible: jazz, Indian classical music, and avant-garde art music. The research will employ an interdisciplinary approach involving ethnography, music theory, statistical modeling, machine learning, signal processing and instrument design, and cognitive studies. The objectives are to develop computational models of improvisation and to use them to develop new technologies that support creativity in music and education. To these ends, the PI and his team will investigate machine modeling of musical improvisation as a means to understand real-time creativity. They will perform analysis of improvisational traditions from many cultures and attempt to unify them using a common probabilistic framework. They will also conduct systematic evaluation of formal models in realistic performance contexts, and use brain imaging of improvising musicians to gain insight into highly creative mental activity. Ethnography will be applied to characterize the diversity of improvisational traditions, while music theory will help define basic concepts and provide working hypotheses and frameworks for formal models. Relationships between musical concepts will be represented using a probabilistic, generative model that seeks to represent the complex conditional dependencies among musical parameters as well as among performers; this abstraction will help unify different surface traditions within a common framework, revealing essential patterns in systems for real-time creativity. Through modeling, the study will explore how improvising musicians learn these systems and reference them in performance. Cognitive studies will elucidate whether a distinct set of cognitive processes are employed during improvisation; understanding what neural networks are active may be a first step in engineering systems that foster creativity in other contexts. Taken together, these studies will improve our understanding of creative processes.<br\/><br\/>Broader Impacts: Studying the arts, where creativity has been developed, refined, and systematized, will offer insight into developing systems that foster creativity in other areas such as engineering and information technology. Improvisation systems built from this research will be used to create ensembles through which programming, computational modeling, and creative problem solving may be taught. The development of technology to support improvisation will also help teach creativity alongside rote performance skills, and encourage new programming paradigms. For artists, project outcomes will enable new improvisation systems to be built using reconfigurable building blocks, thereby catalyzing research in improvisation and the development of sophisticated systems. Planned collaborations with world-renowned musicians will expose a broad public to this research, and will help recruit new students to engineering, turn public attention to the study of creativity, and hopefully also create satisfying works of art.","title":"MAJOR: Modeling Musical Improvisation to Support Creativity in Education and Performance","awardID":"0855758","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7788","name":"CreativeIT"}}],"PIcoPI":["554219","470115","496811","496811","471954"],"PO":["565227"]},"153980":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Graphics Processing Units (GPUs) have emerged as a promising alternative in<br\/>the transition of the computing industry to mainstream parallel computing.<br\/>Enabling applications to benefit from their potential requires that GPU programming be made accessible to the average programmer. This research focuses on the challenges making GPU programming easier through new high-level programming models, and enabling efficient GPU execution through compilation frameworks for these models.<br\/>Two complementary GPU programming models are proposed --- OpenMP, which is widely used for shared-memory parallel programming, and Parallel Operator Data-Flow Graphs (PO-DFGs), which naturally represent algorithms in a wide range of current and emerging application domains. Various optimization techniques are developed for programs written to these models, including partitioning the program between the host CPU and GPUs, stream optimizations that render the program's memory access characteristics to be more amenable to the GPU's memory system, minimizing data transfer between the host and GPU memory, and GPU architecture-specific optimizations. The research contributes to the evolution of GPGPU programming from manual ports of applications using low-level APIs, to the use of high-level parallel programming models.","title":"SHF: Small: High-level Programming Models and Frameworks for GPGPU-based Computing","awardID":"0916817","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}}],"PIcoPI":["551013","558595"],"PO":["565272"]},"153881":{"abstract":"This research aims to turn existing wireless mesh networks (WMNs) into productive and reliable computing platforms, made possible innovatively by reliability enhancement via adaptive checkpointing (REACT) to yield wireless Grids (WiGs). WiGs can expand immensely the wired Grid in support of rapidly growing cloud applications, besides serving as their original role of ubiquitous communications. It is extremely challenging and yet interesting to realize effective checkpointing in WiGs, due to their unique characteristics. This REACT project deals with three technical challenges, which together constitute the basis of our Checkpoint Manager, able to render WMNs into productive WiGs for enhancing and complementing wired Grids.<br\/><br\/>The project holds great promise to advance technical understanding and scientific frontiers of effective checkpointing in WiGs. It will also improve the research and educational activities on Grid computing and wireless systems strongly in the University of Louisiana, with the testbed established under this project deemed a valuable asset. New research findings and technologies for effective checkpointing and wireless communication performance enhancement will be incorporated into relevant courses, helping to integrate research and education for enriched teaching, training, and learning experience and to educate quality future scientists critical to the NSF mission. Underrepresented students will be recruited aggressively to participate in this project, taking advantage of the established REACT testbed and working collaboratively with funded graduate research assistants to stimulate their research interest.","title":"SHF: Small: Reliability Enhancement via Adaptive Checkpoingint in Wireless Grids","awardID":"0916451","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":[409472],"PO":["366560"]},"153452":{"abstract":"This project will explore a novel direction to address the privacy\/ utility tradeoff of trace sharing: secure queries on original traces under their owner?s control. The data owner publishes a query language and an online portal, allowing researchers to submit sets of queries to be run on data. Only certain operations are allowed on certain data &#64257;elds, and in speci&#64257;c contexts. This policy is speci&#64257;ed by the provider and enforced by the language interpreter. The interpreter analyzes the queries, runs those that are permitted and returns the results to the researcher. The results consist of aggregate information such as counts, histograms, distributions and not of individual packets.<br\/><br\/>Secure queries address privacy\/utility tradeoff much better than sanitization. Privacy is protected by &#64257;ner-grain control given to data owner, which permits detection of many passive attacks and minimization of information leakage from active attacks. Future attack vectors can be handled by adding new constraints on the query language. Secure queries also show a potential to reveal more data to researchers than it was possible with sanitization. Fine-grain control via query language enables processing of many &#64257;elds in the application header, and even in sensitive application content, while satisfying the owner?s privacy concerns. This is likely to increase utility of public traces for application and security research.<br\/><br\/>The work will investigate research utility of network trace data, and the relationship of known and novel attacks to combinations of packet &#64257;elds, operations on those &#64257;elds, and contexts that pose privacy risk. Based on these &#64257;ndings, the team will develop a secure query language Trol, and an interpreter for this language Patrol. Trol will support common operations on traces, needed for networking research, and Patrol will prohibit queries and contexts that pose a privacy risk as speci&#64257;ed by the provider ?s privacy policy. Both the language and policies will be extensible by data owners to accommodate future discoveries. Trol and Patrol will be deployed at USC\/ISI and will run on publicly available, sanitized trace archives and on synthetically generated, full packet traces. This deployment will help to test expressiveness and privacy protection of Trol operations. The work will also publicize the work among data owners, to motivate the shift from sanitization to protection of traces via secure queries.","title":"TC: Small: Privacy-safe sharing of network data via secure queries (PSEQ)","awardID":"0914780","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550312"],"PO":["565136"]},"152495":{"abstract":"Despite heroic efforts in testing, static analysis, specification, and verification, all real-world software -- desktop applications, servers, and transportation systems---deploys with defects and missing functionality, costing the US economy billions and threatening our well-being. This project proposes a transformative paradigm shift to \"perpetually available software systems\" (PASS) that will make software more available and robust by directly addressing errors in deployed software. PASS innovations will (1) improve user experience by keeping real-world software running longer; (2) ensure good performance; (3) assist developers in fixing errors while allowing patches to be safely deployed on running software, to avoid downtime. The project will mine error reports in open source software repositories to derive error classes and test suites. It will evaluate system effectiveness by comparing with bug reports and patches in repositories. Innovations will include (1) detection and remediation elements that target common errors, (2) semantic foundations for remediation and on-line updating, and (3) integration of elements to exploit synergy among the components. The project will explore and analyze novel safe, probabilistically-safe, and extended-semantics remediations\/updates. The project will develop both C\/C++ and Java runtimes, because they are the most widely used languages and pose unique challenges. Methods will include combining dynamic, static, and remediation\/update analysis and results. The project will train graduate, undergraduate, and post doctoral students, and participate in outreach to under-represented groups. The tools will be made publicly available, adding to the national research infrastructure.","title":"SHF: Large: Collaborative Research: PASS: Perpetually Available Software Systems","awardID":"0910530","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["550282"],"PO":["564388"]},"153474":{"abstract":"IIS - 0916129 <br\/>HCC: Small: Collaborative Research: Asynchrony and Persistence for Complex Contact Simulations<br\/>Grinspun, Eitan <br\/>Columbia University<br\/><br\/>Collaborative Proposals<br\/>IIS - 0914833 <br\/>Guibas, Leonidas J <br\/>Stanford University<br\/><br\/>ABSTRACT<br\/>This proposal addresses the challenge of complex contact simulations by working entirely in an asynchronous setting. The project operates along three lines, combining tools from Asynchronous Variational Integrators (AVIs) and Kinetic Data Structures (KDSs) with a novel effort to perform and exploit qualitative analysis of contact simulation data. The first investigation will show that AVIs, meant to handle the continuous aspects of the physics, can be ntegrated well with KDSs, meant to handle discrete geometric events. The second research component addresses the fundamental problem of event scheduling when future trajectories are uncertain. Methods will be explored that improve event detection times, reduce the number of auxiliary events that have to be processed, and allow events to be processed in parallel. The third research task will be to initiate a study of the qualitative behavior of contact simulation by building a hierarchy of coarser models which can then be used for better resource allocation, for the validation of various approximations, and in improved simulation design to attain desired effects.","title":"HCC: Small: Collaborative Research: Asynchrony and Persistence for Complex Contact Stimulations","awardID":"0914833","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["521232"],"PO":["565227"]},"153364":{"abstract":"For many applications of computer graphics, it is important that viewers perceive an accurate sense of the scale and spatial layout depicted in the displayed imagery. Medical and scientific visualizations need to accurately convey information about the size, shape, and location of entities of potential interest. Architectural and educational systems should give the user an overall sense of the scale of a real or hypothesized environment, along with the arrangement of objects in that space. Simulation and training systems need to allow users to perform tasks with the same or similar facility as in the real world. Despite the importance of achieving a high level of perceptual fidelity in computer graphics, there are as yet no established methodologies for evaluating how well computer graphics imagery conveys spatial information to a viewer. The lack of such methodologies is a significant impediment to creating more effective computer graphics systems, particularly for non-entertainment applications. In this multidisciplinary project involving genuine collaboration between computer scientists and cognitive psychologists, the PI and his team will develop a method for quantifying perceptual fidelity that is both generalizable and task-relevant. This work will be the first systematic use of the concept of perceived affordances, defined as the perception of one's own action capabilities, for characterizing the accuracy of space perception in computer graphics. The methodology involves a verbal indication that a particular action can or cannot be performed in a viewed environment. By varying the spatial structure of the environment, these affordance judgments can be used to probe how accurately viewers are able to perceive action-relevant spatial information. The result is a measure relevant to action, less subject to bias than verbal reports of more primitive properties such as size or distance, and applicable to non-virtual-environment display systems in which the actual action cannot be performed. <br\/><br\/>Broader Impacts: This research will lead to a methodology that significantly impacts displays and rendering methods not yet developed, and will result in qualitative improvements in domain-specific systems that go beyond current practice. Project outcomes will be applicable across a broad range of display technologies and rendering techniques, and will reduce the confounds associated with training and prior experience found in more specialized task performance measures. The nature of this collaboration will lead to an exceptional educational environment, from which students will come away with a depth and breadth of experience which makes them especially well qualified to tackle demanding problems in science and engineering. The investigators have a well established record of involving undergraduates and women in research, and will continue that tradition with this work.","title":"HCC:Small: A New Method for Evaluating Perceptual Fidelity in Computer Graphics","awardID":"0914488","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["560997","553308","553309"],"PO":["565227"]},"148942":{"abstract":"This project at the University of Toledo focuses on the acquisition of new high-performance scalable computing (HPSC) and storage infrastructure to further<br\/>collaborative multi-disciplinary research, education, and outreach activities. The instrumentation integrates easily expandable energy-efficient high-performance rackmounted servers with an enterprise storage system. The main objective of this project is to dramatically expand research and educational opportunities for faculty and students in the College of Engineering (COE) and the College of Arts and Sciences (CAS). The proposed infrastructure opens the door for collaborative basic as well as applied multidisciplinary research in semiconductor technologies, wireless electronics, sensors and networks, fluid dynamics, new materials and geospatial technologies. Cutting-edge research enabled by the HPSC infrastructure will enhance the content and quality of curriculum at undergraduate and graduate levels in participating departments and colleges.<br\/>This project facilitates recruitment, retention, and training of world-class engineers and scientists in strategic science and technology frontiers.","title":"II-NEW: High-Performance Scalable Computing Infrastructure","awardID":"0855134","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["524754","459723","396970",396970,396971,"545691"],"PO":["565272"]},"146401":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Developer testing has been widely recognized as an important and valuable means of improving software reliability, partly due to its capabilities of exposing faults early in the software development life cycle. However, manual developer testing is often tedious and insufficient. Testing tools can be used to enable economical use of resources by reducing manual effort. To maximize the value of developer testing, effective and efficient support for cooperation between developers and tools is greatly needed and yet lacking in state-of-the-art research and practice. <br\/><br\/>This research aims to create a systematic framework for cooperative developer testing that provides practical techniques and tools, with an integrated research and education plan. In particular, the research addresses fundamental research questions around specification of test intentions by developers to communicate their testing goals or guidance to tools, satisfaction of test intentions by tools, and explanation of intention satisfaction by tools. Test-intention satisfaction and its explanation assist developers in accomplishing not only their testing tasks but also debugging tasks. The framework also helps infer likely test intentions to reduce manual effort in specification of test intentions. Among the broader impacts of the project includes improvement of software reliability and collaboration with industry to transfer technology.","title":"CAREER: Cooperative Developer Testing with Test Intentions","awardID":"0845272","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8010","name":"Computing in the Cloud"}}],"PIcoPI":["562727"],"PO":["564388"]},"148953":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The work constitutes a significant update of WordNet, a large electronic lexical database of English that is a cornerstone of research and applications in computational linguistics, Natural Language Processing, Knowledge Representation, Semantic Web applications and that serves as the basis for numerous computational linguistics tools. <br\/>WordNet?s database is redesigned and converted from a text-based to a relational (SQL) format to allow flexible and domain-specific extensions. Specific tasks include the definition of an SQL schema, the development of an ASCII-to-WordNetSQL table translation program, a searching interface and additional format conversion utilities. Syntactic limitations on WordNet?s lexicographer files and compiler are eliminated so as to allow long, variable-length word strings and special characters found technical terminology. The table-based SQL format is designed to allow a virtually unlimited number of relations per word form or synonym set, both user-created and ?original? to the Princeton WordNet. User extensions and modifications to WordNetSQL are distinguished from those made ?domestically,? ensuring that development of the core WordNet database remains independent of external updates, and that WordNet?s large user community continues to have available a common, consistent database against which automatic systems can be evaluated. We develp conversion tools for WordNetSQL and other popular WordNet representations (RDF\/OWL, Prolog, XML). Maintenance of the Princeton WordNet lexicon and user support continue. <br\/>The major impact of the freely and publicly available WordNetSQL is to enable flexible extensions by a broad and diverse user group to specific and technical domains including biology and medicine.","title":"CI-ADDO-EN: A Second-Generation Architecture for WordNet","awardID":"0855157","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["511536"],"PO":["565215"]},"158886":{"abstract":"The increasing performance and decreasing cost of processors has enabled increased system intelligence at peripherals such as disk drives. This computational capability at the disk has led to the development of object-based storage whereby some of the file system functionality is moved to the disk. The computation capability can also enable computation at the storage node in what has been called active disks or active storage. This active storage computation serves as a mechanism to enable parallel computation using distributed storage nodes.<br\/>This research focuses on the use of these active disks for parallel file system and storage management. A functional active storage system architecture built on the standardized object-storage device specification is being developed. The architecture supports a variety of execution engines allowing multiple programming languages and models. Using this active object storage architecture, mechanisms to improve overall scalability and large-scale system reliability are being investigated. In addition, active and object storage are used to enable customizable and extensible file systems including autonomic (self-configuring and self-managing) storage as well as application aware storage such that the storage can be optimized for application and user needs.","title":"Active Object Storage to Enable Scalable and Reliable Parallel File Systems","awardID":"0937879","effectiveDate":"2009-08-15","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"I159","name":"Defense Advanced Research Proj"}}],"PIcoPI":["550180"],"PO":["565272"]},"148975":{"abstract":"City University of New York (CUNY) researchers use high performance computing (HPC) to study air pollution in urban environments, develop techniques for visualization of scientific data, develop Monte Carlo-based algorithms for modeling of complex physical and transportation systems, and, with collaborators at the New York State Institute for Basic Research in Behavioral Disabilities (IBR), develop computational methods for autism studies. The investigators use a unique100-teraflops parallel heterogeneous HPC system, funded by NSF, which consists of 96 Intel 5570 quad-core processors connected to 96 NVidia Tesla graphics processing units. The Heterogeneous High Performance Computing System (H-HPCS), is tailor made for computations that are numerically intensive, vectorizable and highly parallel. <br\/><br\/>CUNY scientists use H-HPCS to process atmospheric data obtained from satellites, lidar, and ground weather stations to assess pollution concentration and dispersion. Energy production and vehicular traffic within the City of New York generate large amounts of chemical and fine particulate pollution, which can induce or have adverse affects on residents, particularly those with cardio-respiratory illnesses. The H-HPCS techniques are developed to predict the dispersion of fixed point and mobile releases of chemicals and biological agents. IBR researchers conduct studies on the detection of autism related behavioral disorders using H-HPCS analysis of genomic data and video data obtained from motion capture systems. IBR and CUNY researchers collaborate on the development of these analysis techniques, which also have corollary applicability in the creative arts. The highly parallel nature of CUNY researcher?s models enable the use of the H-HPCS to study physical systems including mixing and transport of biological and physical properties by oceanographic flows, supersolids, atomic optical lattices, quantum phase transitions, and urban transportation systems.","title":"II-EN: City University of New York - Computing Research Infrastructure","awardID":"0855217","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[397066,"539710","490437","425200","482155"],"PO":["565272"]},"154068":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>This project provides challenging test data and benchmarks designed to advance stereo vision methods to a level of practical relevance. It aims to bridge the gap between the sophisticated but brittle methods that perform best on current benchmarks and the robust but simple methods employed in real-world applications.<br\/><br\/>The project provides new high-resolution datasets with accurate ground truth, taken with different cameras under different lighting conditions, and depicting complex indoor and outdoor scenes with non-Lambertian surfaces and outliers such as moving people, reflections, and shadows. The project explores novel algorithmic approaches for dealing with such challenges, including ways to leverage resolution, deriving color and noise models on the fly, and designing local region-growing techniques that allow deferring global optimization from the pixel level to the region level. Undergraduate students are actively involved in all components of this research.<br\/><br\/>The project has strong potential impact along several fronts. The datasets and benchmarks resulting from this work serve as catalyst for new research and enable machine learning approaches. The algorithmic contributions allow harnessing the explosion of images available online. Robust matching techniques that can handle the variety of images available on the Internet enable a host of new applications with broad impacts on the population at large, including visual localization and navigation, as well as automatic 3D reconstruction and visualization of whole cities. Finally, the project exposes undergraduates at a liberal-arts college in rural Vermont to the world of research, experimentation, and discovery.","title":"RI:Small:RUI: Towards the Next Generation of Stereo Algorithms","awardID":"0917109","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["550972"],"PO":["564316"]},"159414":{"abstract":"This grant provides support for travel, conference registration fees, and accommodation costs for students selected to attend the Doctoral Symposium being held at the 2009 International Conference on Requirements Engineering (RE?09) in Atlanta, USA, 31 August ? 4 September 2009. The International Requirements Engineering Conference is sponsored by the IEEE and is the premier academic and industrial event in the field of Requirements Engineering. The Doctoral Symposium at RE?09 provides a venue for young researchers to access worldwide expertise in software engineering. The Symposium is a one-day closed RE?09 event that provides a forum for Ph.D. students to publicly discuss their research goals, methods, and results at an early stage in their research. The Symposium aims to provide useful guidance to the students from a panel of experts, for completion of the dissertation research and initiation of a research career.","title":"Student Travel Support for the Requirements Engineering 2009 Doctoral Symposium","awardID":"0941058","effectiveDate":"2009-08-15","expirationDate":"2010-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["549985"],"PO":["564388"]},"153750":{"abstract":"The broad goal of this line of research is to give a principled answer to the question, \"What sort of data is efficiently learnable, and by what algorithms?\" The current state-of-the-art in machine learning is that there is an overwhelming number of possible algorithms that can be tried on a new machine learning problem, with no clear understanding of which techniques can be expected to work on which problems. <br\/><br\/>Further, it is often the case that machine learning algorithms that work well \"in theory\" do not perform as well \"in practice,\" and vice versa. The PIs have outlined a plan for resolving these difficulties, finding a unification of disparate methods via the Polynomial Method, and investigating how efficient this method can be. On a more immediate level the PIs will aim for broad impact through advising and guiding graduate students and widely disseminating research results.<br\/><br\/>Specifically, the PIs will investigate the effectiveness of the \"Polynomial Method\" in machine learning theory. The PIs observe that nearly all learning algorithms, in theory and in practice, can be viewed as fitting a low-degree polynomial to data. The PIs plan to systematically develop this Polynomial Method of learning by working on the following three strands of research:<br\/><br\/>1. Understand the extent to which low-degree polynomials can fit different natural types of target functions, under various data distributions and noise rates. This research involves novel methods from approximation theory and analysis.<br\/><br\/>2. Develop new algorithmic methods for finding well-fitting polynomials when they exist. Here the PIs will work to adapt results in geometry and probability for the purposes of identifying and eliminating irrelevant data.<br\/><br\/>3. Delimit the effectiveness of the Polynomial Method. The PIs will show new results on the computational intractability of learning intersections of linear separators, and on learning linear separators with noise.","title":"AF: Small: Collaborative Research: The Polynomial Method for Learning","awardID":"0915929","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}}],"PIcoPI":["550576"],"PO":["565157"]},"153871":{"abstract":"This award is funded under the American Recovery and Reinvestment <br\/>Act of 2009 (Public Law 111-5).<br\/><br\/>The Internet has traditionally combined many orthogonal functions into transport protocols, creating significant technical and administrative hurdles to transport service evolution. New or specialized transport protocols are now nearly undeployable because they cannot traverse middleboxes such as NATs, firewalls, performance enhancing proxies, which have mushroomed in the past two decades; new congestion control schemes are restricted by the requirement to compete ?fairly? against traditional TCP flows; and deploying new features such as multi-homing is difficult because applications must be adapted to new naming and communication models.<br\/><br\/>Tng (\"Transport next generation\") is a new but incrementally deployable transport architecture that breaks the above evolutionary impasse by modularizing the transport layer. Tng breaks transports into four explicit layers - Endpoint Naming, Flow Regulation, Identity\/Security, and Semantics - plus a cross-layer Negotiation service. By separating the network-oriented functions of endpoint naming and flow regulation from application-oriented transport semantics, Tng enables middleboxes in the network to enforce network policies and optimize flow performance cleanly across diverse network technologies and administrative domains, without interfering with end-to-end semantics. Tng's identity\/security layer in turn enforces this separation<br\/>between network- and appliation-oriented functions, avoiding past conflicts between middleboxes and IPsec.<br\/><br\/>By developing a working prototype and analyzing its performance and adaptability across a variety of real and simulated network environments, we expect that Tng will prove an important step towards breaking long-standing deadlocks between operators, new network technologies, and end-users.","title":"NeTS: Small: Collaborative Research: Tng, a Next Generation Transport Services Architecture","awardID":"0916413","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["502304"],"PO":["564993"]},"153530":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Significant increases in application complexity demand processing requirements that exceed the performance achievable by current processors using software only implementations. For example, recent multimedia standards, such as JPEG2000, have significantly increased computational demands compared to previous standards. In an effort to alleviate the cost of developing software and\/or hardware solutions capable of fully supporting such standards, many define several profiles ? specific settings for various configurable parameters ? that reduce the level of complexity needed to implement a specific profile. However, the number and variability of profiles even within a single domain still precludes traditional hardware implementations as a viable option for most applications.<br\/><br\/>The Data-Adaptable Reconfigurable Embedded Systems (DARES) project focuses on developing hardware\/software codesign and reconfigurable computing methodologies driven by data-adaptability. This data-adaptable approach allows designers to directly model data configurability of an application, thereby enabling a solution that can be dynamically reconfigured at runtime based on the profile of incoming data. The DARES project combines modeling techniques for capturing the data configuration space with new hardware\/software codesign techniques to synthesize reconfigurable circuits and communication resources directly from the data\/application model. The resulting hardware\/software implementation provides the flexibility of software with the performance of hardware.<br\/><br\/>The results of the DARES project will provide a new design approach for dealing with the trend towards applications with increasing flexibility and configurability and will provide new methodologies for exploiting the reconfigurability of FPGAs beyond current approaches.","title":"CSR: Small: Data-Adaptable Reconfigurable Embedded Systems (DARES)","awardID":"0915010","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["561903",408606,408607,"565273"],"PO":["565255"]},"153420":{"abstract":"Only 35% of seniors (over 65 years of age) in the U.S. use the Internet, reflecting an age-based digital divide when compared with the fact that 90% adults in the ages of 19-29 use the Internet. This project will address this divide through a novel approach that employs conversational agent technology to reduce the critical cognitive and social-psychological barriers hindering older users in web-based consumer environments. The goal of this project is to broaden the engagement of the growing yet underrepresented senior population in Internet technology, a medium that can dramatically improve their quality of life. This goal closely aligns with the human-centered computing objective of transforming the human-computer interaction experience through the development of systems that are aware of the abilities and special needs of people that use them. Research on animated pedagogical agents has revealed promising results on the effectiveness of agents in learning and motivation. However, no previous research program has investigated how agent technology can be designed to promote autonomy and empowerment in the older population, particularly in web-based consumer environments, involving multi-dimensional information processing and complex decision-making. To address this critical gap in the research, this project will systematically investigate, three aspects of agent interactions with older users: 1) locus of control (agent vs. user), 2) interactional style (functional vs. relational), and 3) modality of exchange (unimodal-voice vs. unimodal-text vs. dualmodal-voice + text). This research program will apply a multi-phase, mixed-methods approach involving qualitative studies in the first phase, and a series of controlled experiments with over 400 older users in subsequent phases. The purpose is to examine the effectiveness of the three aspects of agent-user interaction in: 1) reducing cognitive barriers (reducing information load, increasing navigation convenience, enhancing information search and retrieval ease), 2) reducing social-psychological barriers (enhancing control and efficacy, increasing trust, enhancing perception of social support), and 3) increasing Internet technology use intent. The experimental studies will further determine whether users' gender, visual or hearing impairments, and prior Internet competency interact with the three aspects of agent-user interaction to affect the desired outcomes. The findings from this project will generate new knowledge on how multimodal systems employing conversational agents can be designed for the abilities and special needs of older users leading to a potentially transformative and empowering experience for this underrepresented population in information technology.<br\/><br\/>Seniors are increasingly finding the necessity to engage in web-based consumer environments (e.g., online banking, shopping, trading, travel reservations). While the functionality of agents in these domains merits examination, the broader significance of this project lies in its ability to inform the development of agent-mediated interfaces for other applications such as websites that provide important health and medical information to seniors. Anecdotal evidence gathered by the project team from a prototype system has revealed the transformative potential of this technology for older users. This pilot research funded by the Office of Outreach at Auburn University, has extended the impact of this project to constituents in the state of Alabama. In addition to research, outreach will also serve as an important mission in the dissemination of future findings from this project to stakeholders at local and national levels. With the goal of enhancing diversity in research and education, this project will also involve a greater representation of African-American (AA) study participants from surrounding counties in Alabama, and actively engage AA graduate students, who are already part of the PI's lab in the educational goal of this project. This project will further enhance the infrastructure for research and education across two disciplines through an interdisciplinary seminar course will be offered to graduate students in computer science and consumer affairs to enhance the understanding of the future researchers on how humans perceive and use computing artifacts such as conversational agents.","title":"HCC: Small: Conversational Agents in Web-Based Consumer Environments Designed for Older Users","awardID":"0914666","effectiveDate":"2009-08-01","expirationDate":"2009-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[408333,408334,"542299"],"PO":["565227"]},"153662":{"abstract":"Over the last decade, wireless networks of various kinds, including cellular networks, wireless LANs, sensor networks, community networks, etc. have become ubiquitous. This award focuses on algorithmic problems motivated by the design of protocols and applications for some of these networks. One feature of these networks, that the proposal attempts to take advantage of, is that network nodes typically reside in the plane or in 3-dimensional space and furthermore communication and sensing ranges of these nodes may also be modeled geometrically (for example, as disks or spheres in Euclidean space). As a result the award focuses on optimization problems in the geometric context and the goal is to design algorithms for these problems that can eventually be implemented efficiently on the network nodes. One class of problems considered are geometric embedding problems in which network nodes seek to discover their locations based only on information about which other nodes are within communication range. Solutions to these problems have the potential to improve routing protocols on these networks. Another class of problems PIs consider are geometric coverage problems whose aim is to optimally place sensor nodes with given sensing abilities so as to cover certain target regions. Such coverage problems arise in a variety of sensor network applications such as monitoring bridges, vineyards, and factory floors.","title":"AF:Small:Geometric Embedding and Covering: Sequential and Distributed Approximation Algorithms","awardID":"0915543","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7929","name":"COMPUTATIONAL GEOMETRY"}}],"PIcoPI":["549755","550204"],"PO":["565157"]},"153453":{"abstract":"Influencing and Improving Networks Formed by Strategic Agents<br\/><br\/>An increasing number of networks on the forefront of scientific research, and of great importance to our world, are developed, built, and maintained by a large number of independent agents, all of whom act in their own interests. Such networks with strategic agents include the Internet, peer-to-peer file sharing schemes, business contracts between companies, and social networks representing relationships between groups of people. While these networks cannot be fully controlled, they can often be influenced in a limited way, sometimes resulting in dramatic improvement of the global network behavior. For example, this influence can include giving a few agents incentives to behave differently, altering a small part of the network, or even providing some extra information that makes a huge difference. This project will develop methods and algorithms with provable guarantees for influencing networks of strategic agents in order to improve the overall network behavior.<br\/><br\/>This project will study the formation of various networks by strategic agents, and will especially focus on the system of customer-provider and peering contracts between Autonomous Systems (AS's) in the Internet. In the process of this research, new approximation algorithm concepts will be introduced, and will yield techniques for improving the global qualities of a network, and for preventing undesirable entities from gaining undue influence over it. While interactions of self-interested agents have been studied in numerous fields, a systematic study of how to influence such agents with only a limited amount of power has never been done. Besides contributing to algorithmic game theory and the study of networks, this research will open up new research directions in economics, AI, and the social sciences.","title":"AF: Small: Influencing and Improving Networks Formed by Strategic Agents","awardID":"0914782","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7932","name":"COMPUT GAME THEORY & ECON"}}],"PIcoPI":["518263"],"PO":["565251"]},"153574":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5)<br\/><br\/>This proposal develops a technique for allowing the multiple on-chip caches available in multicore processors to be utilized more effectively by systems software. CoreTime is a framework to help data-intensive software obtain good performance on multicore processors. Data-intensive software, such as operating systems and web servers, may not be able to obtain full benefit from the increasing processing power of multicore processors, instead being bottlenecked by access to off-chip Dynamic random access memory (DRAM). One example of an idea the CoreTime project is investigating is a global replacement policy among the per-core caches of a multicore chip. Such a policy has the potential to significantly increase caching effectiveness, for example by preventing waste of cache space on redundant per-core copies of popular data. A key principle in CoreTime's design is that software should control the policy for how cached data is spread over a multicore processor's on-chip caches.<br\/><br\/>The long-term importance of CoreTime is that it will increase the scalability of memory-intensive software on future multicore processors by mitigating the DRAM botteneck. CoreTime software will be distributed as open source. The ideas and software will be used in MIT's undergraduate operating systems course, to give students experience with multicore processors and concurrency. Both undergraduates and graduate students will perform the research. <br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).","title":"CSR: Small: CoreTime: Dynamic Computation Migration for Multicore System Software","awardID":"0915164","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["541752","562011"],"PO":["551712"]},"153695":{"abstract":"The Internet is now the world's dominant information infrastructure. Numerous requests from Internet users and their applications compete for shared resources in multiple ways. It is therefore critical to efficiently allocate limited network resources in order to provide high quality services. Improving the performance of the Internet in this manner has the potential to have extremely broad impact.<br\/><br\/>Resource management becomes even more challenging when mobile devices connecting to the Internet are considered. Designing efficient algorithms is difficult mainly due to the following factors: (1) diverse and unpredictable resource requests; (2) physical limitations on Internet links, on buffer space in network switches, on capacity of wireless channels, and on battery power in mobile devices.<br\/><br\/>This project aims to provide solutions for several fundamental algorithmic problems in networked systems and applications. Robust and insightful online algorithms will be developed for network switches forwarding prioritized packets and energy management in mobile devices. The objective is to understand the mathematical structure of these problems, to design elegant and easy-to implement online algorithms, to provide rigorous analysis on their performance bounds, and to integrate these algorithms into the real systems to achieve better performance.","title":"AF: Small: Collaborative Research: Online Scheduling Algorithms for Networked Systems and Applications","awardID":"0915681","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":["485283"],"PO":["565251"]},"151033":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Traditional database systems are designed to provide the user with a<br\/>clear picture of past states of the world as is represented in the<br\/>database. Recently, stream processing systems are introduced to<br\/>produce near real-time answers for those applications applications<br\/>that require up-to-date information. Thus, we see a trend toward<br\/>shrinking the ?reality gap? to zero. But for some applications, even<br\/>real-time is not good enough. There is often a desire to get out in<br\/>front of the present by delivering predictions of future events to<br\/>take advantage of opportunities or to avert calamity. Security<br\/>applications are a good example since they are typically interested in<br\/>preventing a breach rather than simply reporting that one has<br\/>happened. There is currently no database system that can effectively<br\/>serve as a generic platform to support such predictive applications.<br\/><br\/>This project aims to fill this gap by designing and building a<br\/>prototype database system called \"Longview\" to enable data-centric<br\/>predictive analytics. Longview facilitates the use of statistical<br\/>models to analyze historical and current data and make predictions<br\/>about future data values and events. Users can plug new predictive<br\/>models into the system along with a modest amount of meta-data, and<br\/>the system uses those models to efficiently evaluate predictive<br\/>queries.<br\/><br\/>Longview treats predictive models as first-class citizens by<br\/>intelligently managing them in the process of data management and<br\/>query optimization. This involves automatically building models and<br\/>determining when and which model(s) to apply to answer predictive<br\/>queries. This also involves creating and using the proper physical<br\/>data structures to facilitate efficient model building, selection, and<br\/>execution. Longview handles both streaming and historical queries. In<br\/>fact, many streaming queries need efficient access to an archive of<br\/>past values, making it necessary to seamlessly combine both stream and<br\/>historical processing. Finally, Longview investigates \"white-box\"<br\/>model support, in which the database leverages the operational<br\/>semantics and representation of models to improve performance.<br\/><br\/>Longview's goal is to make it much easier to build predictive<br\/>analytics applications in data intensive situations. Seamlessly<br\/>combining data and model management is key to make the process of<br\/>computing with predictions far easier to express and more efficient<br\/>than the current ad-hoc application-level approaches. The resulting<br\/>technology also allows for a better understanding and support for<br\/>user-defined functions in database systems.<br\/><br\/>Longview is initially used for a real-world sensor-based tracking<br\/>application and a predictive web portal for easy experimentation with<br\/>different models and data sets. Further information on the project can<br\/>be found on the project web page: <br\/>http:\/\/database.cs.brown.edu\/projects\/longview\/","title":"III: Medium: Longview: Querying the Future Now","awardID":"0905553","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["531608","483626","483625"],"PO":["563727"]},"151066":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). The goal of this project is to develop computational models of the nonverbal behavior and interactive strategies observed during face-to-face teaching. These computational models will serve as a foundation for a new generation of embodied teaching agents that approximate the benefits of face-to-face human tutoring. The project will help advance the science of learning and teaching by improving our understanding of the dynamics of nonverbal behavior in teaching at a computational level, across multiple time scales: From low-level micro-expressions in the timescale of tens of milliseconds, to cognitive and affective processes with time scales of seconds, to higher level strategic behaviors operating at longer time scales. <br\/><br\/>In addition to its scientific and technological value, this project has a significant outreach component. The project would help grow links between a research oriented campus (UCSD) an undergraduate teaching university (SDSU). The robotics aspects of the project will be developed in collaboration with the Preuss School Robotics Club. The Preuss School is a charter school for low-income students in grades 6-12 and is currently ranked as one of the top high schools in the nation.","title":"HCC: Medium: Collaborative Research: Computational Analysis of Nonverbal Behavior in Adaptive Tutoring","awardID":"0905661","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[402724],"PO":["565227"]},"158612":{"abstract":"CCF - 0936391 <br\/>Title: SRC\/NSF Forum on 2020 Semiconductor Memory Strategies: Processes, Devices, and Architectures<br\/>PI name: Victor Zhirnov <br\/>Inst: Semiconductor Research Corporation <br\/><br\/>ABSTRACT<br\/>This workshop proposal has been initiated by the Semiconductor Research Corporation (SRC) and is part of an ongoing attempt to periodically examine and evaluate the needs of the NSF\/SRC research community to identify the future directions of the field of microelectronic design automation. This particular proposal is for supporting a workshop on the topic of novel memory technologies. In particular, recent discovery of a new memory device called the ?Memristors? inspired this workshop, but a broader set of issues having to do with design technologies pertaining to advances in memory technology and their continuous scaling behaviors will also be discussed.<br\/><br\/>The Semiconductor Research Corporation (SRC) is a nonprofit consortium of design automation industries. In recent years, it has taken a major role in chalking out the future technology paths and the requirements of industry by publishing the so called ITRS roadmap. While the ITRS roadmap has been a guiding principle for industry, a similar agenda for university researchers seem to be absent at the present time. The workshop is supposed to fill this void for university researchers, by identifying an agenda for longer term research in the domain of memory technologies.","title":"WORKSHOP: SRC\/NSF Forum on 2020 Semiconductor Memory Strategies: Processes, Devices, and Architectures, September, 2009.","awardID":"0936391","effectiveDate":"2009-08-01","expirationDate":"2011-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["525950"],"PO":["562984"]},"154135":{"abstract":"CSR: Small: Collaborative Research: Adaptive Applications and Architectures for Variation-Tolerant Systems<br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The scaling of integrated circuits (ICs) into the nanometer regime has thrown up new challenges for designers, foremost among which are variations in the characteristics of IC components. Variations threaten to diminish the fundamental benefits of technology scaling, such as improvements in cost-per-transistor, performance and power consumption. Variation-aware design techniques that have been proposed thus far are being stretched to their limits, and cannot contain the incessant increase in variations. Therefore, it is important to develop new design approaches for systems that are inherently resilient to variations in the underlying components. <br\/><br\/>This project develops a framework based on adaptive applications and architectures for the design of variation-tolerant application-specific systems. It advances the state-of-the-art by (i) adopting a cross-layer approach at the system architecture and application layers, (ii) leveraging the inherent ?elasticity? of a wide class of applications to adapt to variations in the underlying hardware while still producing acceptable performance and maintaining end-user experience, and (iii) exploring a hybrid (design-time and post-fabrication) design methodology, enabling more accurate and effective system adaptation in response to variations. The developed technologies will significantly extend our ability to avail of the benefits of technology scaling in the face of increasing variations.<br\/><br\/>The efforts towards broader impact include working with the semiconductor industry to validate and transfer the developed technologies, new educational material incorporated in courses on SoC design and embedded systems, and undergraduate design projects.","title":"CSR: Small: Collaborative Research: Adaptive Applications and Architectures for Variation-Tolerant Systems","awardID":"0917354","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["507608"],"PO":["565255"]},"167687":{"abstract":"This research investigates techniques for efficient simulation of large scale agent-based models (ABMs). ABMs are increasingly being used to understand complex multi-scale behaviors in many natural, built and social systems. Although ABMs have the necessary structure to capture complex model characteristics in these systems, this very structure makes them computationally challenging. Current techniques for desktop computing and extensions to traditional high performance computing are incapable of efficiently handling this computational complexity. This has severely limited the applicability of ABMs. This research investigates novel techniques designed to leverage the massive computing power available on commodity graphics processing units (GPUs). It greatly expands the availability and applicability of agent-based modeling by effectively democratizing super computing for ABM simulation. Furthermore, it enables virtual testing of \"what-if\" scenarios in public policy, contingency planning for disaster relief, drug therapy design etc., on inexpensive desktop computers at realistic levels of detail. <br\/><br\/>The main challenge in this research is the re-formulation of ABM computation tofit the data-parallel model of GPUs. Specific research topics include representation of agent data, functions for agent motion, replication, decimation, communication, representation and manipulation of non-spatial agent networks, adaptive behaviors, run-time user interaction, fast visualization, hardware and model-aware automatic code optimization, and multi-level parallelism for multi-GPU platforms. The techniques developed are being applied to two specific problems in medicine: simulation of tuberculosis and systemic inflammatory response syndrome. These models enable efficient simulation of disease pathology and in-silico testing of novel therapeutic drug protocols. Educational topics include development of courses, outreach to K-12 students through development of ABM themed video games, undergraduate involvement in research, and the development of a comprehensive dissemination web page.","title":"CAREER: Towards Interactive Simulation of Giga-Scale Agent-Based Models on Graphics Processing Units","awardID":"1013278","effectiveDate":"2009-08-16","expirationDate":"2015-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7934","name":"PARAL\/DISTRIBUTED ALGORITHMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}}],"PIcoPI":["484022"],"PO":["565272"]},"148965":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\"<br\/><br\/>The objective of this project is to build a state-of-the-art Human Motion Acquisition Facility capable of capturing human motion data using an array of synchronized multiple sensors. It includes hardware and software necessary to capture simultaneously multi-modal aspects of human performance including human movement, ground reaction forces, video data, muscle activation patterns, heart rate, temperature, eye movement, etc. Importantly, all the data is synchronized with each other.<br\/><br\/>The facility enables researchers to explore new frontiers in human motion synthesis. In particular, the captured data is used to study novel compact representations of human motions and to develop new algorithms to efficiently synthesize detailed realistic motions of a single character and crowds. The data is also used to build, animate and populate virtual worlds. The facility also greatly benefits existing computer graphics degree programs at UPenn (Ph.D, Masters, Undergraduate, and summer high school students). The use of the facility is an integral part of the curriculum in these programs.<br\/><br\/>Currently, there are no extensive, publicly available, high quality databases of human motion data synchronized with data from other sensors. All the data we obtain in this project will be made publicly available. The facility will therefore enable new research ranging from human motion synthesis in computer animation to medical studies of people with disabilities to researching novel simulators. As a result, it will foster inter-disciplinary research. The facility will also make computer graphics programs at UPenn even more exciting and will help in attracting more women to computer science.","title":"II-EN: Synchronous Multi-Sensor Human Motion Acquisition Facility","awardID":"0855192","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[397034,"451767"],"PO":["543539"]},"148976":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\"<br\/><br\/>Computer vision research and related technology are on the cusp to be taken out of the lab to meet real-world challenges: understanding, reasoning, and navigation in large-scale, dynamic, and complex environments. <br\/><br\/>This project will acquire a state-of-the-art, custom sensor suite, the 3D Content Digitization Suite (3DCDS), to support research and performance evaluation of computer vision and robotics algorithms in challenging real-world, outdoors, dynamic scenes: 2D-3D fusion for real-time geometry processing; and large-scale scene understanding and hierarchical semantic context inference. <br\/><br\/>3DCDS includes high-end panoramic laser range sensors, panoramic cameras, navigation equipment, and off-the-shelf cameras arranged on a custom made reconfigurable platform which is mounted on a vehicle. 3DCDS enables testing scene understanding and awareness algorithms under various conditions and it facilitates the collection of ground truth data. Trade-offs across different sensing platforms will be evaluated and the extensive dataset will serve as benchmark for a broad range of algorithms. <br\/><br\/>All data and benchmarks will be made publically available. Stevens will host a web portal for researchers to submit the results of their algorithms on the benchmarks.<br\/><br\/>Research agendas that can be supported by this infrastructure and the collected data span multiple domains and include: fusion of range and image data for inferring accurate, high-resolution, hierarchical scene segmentation; object recognition and scene understanding using invariant features combining geometry and appearance; real-time, dynamic scene awareness; comprehensive evaluation of sensors and methods on ground truth data captured in uncontrolled environments.","title":"II NEW: Flexible mobile platforms for continuous range and imagery collection","awardID":"0855218","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["409575","409574",397074,397075,"551285"],"PO":["543539"]},"154058":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Various studies over the past decade have shown that network availability on the Internet is about 99%, which pales in comparison to other utility services such as power grids and telephone networks. The primary cause of network unavailability today is due to problems related to interdomain routing that are unlikely to go away with technology trends or further growth as they are due to systemic limitations of the protocol architecture. This project is developing techniques towards the design of an interdomain routing architecture that provides high availability under flexible routing policies, link and node failures, and router misconfiguration. <br\/><br\/>The project has the following thrusts. First, it develops a quantitative foundation for interdomain \"X-ities\", a term used to describe metrics desired in an interdomain routing protocol such as availability, stability, policy flexibility, accountability, predictability, deployability etc. Second, it develops routing protocols based on insights from the theory of distributed systems, namely, using redundancy to mask failures, and treating consistency as a safety property. Specifically, the project builds upon \"multiprocess routing\", an approach that runs multiple parallel routing processes that select primary or backup routes to deliver packets with high probability under multiple link and node failures; and \"consensus routing\", a consistency-first approach to ensure high availability under flexible policies. The project adapts these approaches to tolerate failures as well as to limit the impact of misconfiguration. These new proposals will be compared with existing research proposals for interdomain routing based on the X-ities axes. The protocol designs will be made available to researchers and practitioners through open-source implementations.","title":"NeTs: Small: Interdomain X-ities: Toward Five Nines Availability in Internet Routing","awardID":"0917078","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["564706","497218"],"PO":["564993"]},"148998":{"abstract":"Energy consumption for data centers (a.k.a. hosting centers, server farms, clusters etc.) is rapidly increasing and is fast becoming a significant portion of the nation?s annual energy budget. Surprisingly, many of the contemporary data centers are designed and managed very inefficiently, mainly due to reliance on folklore techniques rather than those grounded in hard scientific evidence. In addition, contemporary research and experimentation in greening data centers is severely hindered by the unavailability of an experimentation test-bed, the cost of performing live tests of alternative configurations and the excessive long duration for performing simulations based on high-complexity offline models based on computational fluid dynamics.<br\/>The BlueTool project aims to resolve these issues by: 1) increasing awareness of the latest scientific and engineering research on managing data centers, and 2) providing a research and evaluation infrastructure to test and develop new methodologies to address the inefficiencies of data centers. BlueTool will promote the use of holistic cyber-physical concepts to foster the development of energy-efficient and sustainable data centers. It will leverage recent research advances in cooling technologies and cyber-physical management for data centers at Arizona State University (ASU) and provide synergy for advancing the ongoing research in this field at ASU and elsewhere. BlueTool will consist of: (a) an online tool that can simulate various configurations of data centers, in terms of physical layout, hardware and software configuration; (b) a research hub and portal, maintained by the IMPACT Lab at ASU (http:\/\/impact.asu.edu), that offers data services on various updatable archives including power and thermal profiles, multi-scale low-complexity thermal and power models, and data center management methods and software. Researchers from both academia and industry will be able to use BlueTool's online consulting services to improve the computing performance and energy consumption of conventional or existing configurations with newly developed techniques.","title":"II-EN: BlueTool: Infrastructure for Innovative Cyberphysical Data Center Management Research","awardID":"0855277","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["356233","535238","559502"],"PO":["564778"]},"146457":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>This project investigates unstructured dynamic overlay networks (unstructured networks): a type of computer network formed from interactions among constantly changing strategic (i.e., self- interested but rational) users. These users rely on each other for transferring and finding data, and they form unstructured networks based on their own cost-benefit tradeoffs by dynamically introducing\/removing network communications links and performing distributed resource allocations on top of the Internet. Unstructured networks carry the majority of Internet traffic due to the prevalence of the applications they support. Such applications include file sharing (e.g., BitTorrent), user-assisted media streaming, video-on-demand, and voice-over-IP (e.g., Skype). These networks also include selfish data-routing overlays (where users choose routes independently), and multiple self-organized data-routing overlays. The fundamental interactions\/conflicts between users within each unstructured network and among networks, and their interactions with the Internet, can result in drastically unstable states, inefficient resource usage, low performance of the applications they support, and adverse impact on Internet Service Providers. To address these problems, the project is developing effective mechanisms to ensure the stability and efficiency of unstructured networks, and providing seamless interoperation with the Internet architecture and service providers. Relying on a combination of optimization and game theory, stochastic modeling, and distributed algorithm\/mechanism design, this research develops theoretical foundations\/methodologies for quantifying the interaction dynamics within\/among unstructured networks, and between unstructured networks and the Internet. Additionally, the project provides design principles\/algorithms for application\/network designers and service providers for meeting increasingly rich user requirements and will provide guidance for the design of future Internet architecture.","title":"CAREER: Unstructured Dynamic Overlay Networks and Strategic Users","awardID":"0845500","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[390528,390529],"PO":["564993"]},"159118":{"abstract":"This project provides an automated, formal-methods-based methodology and tool<br\/>that analyzes and validates, in advance of its execution,<br\/>PHP, Perl, or Javascript programs that dynamically generate<br\/>HMTL, XML, and SQL documents.<br\/>Such document-generator programs are common to the World Wide Web and are<br\/>notorious for generating ill-structured, faulty, and dangerous<br\/>documents that cause subsequent server errors or security breaches.<br\/><br\/>The methodology integrates techniques from<br\/>LR(k)-parsing, data-flow analysis, and program security<br\/>to synthesize the program-analysis.<br\/>Given the program (e.g., a PHP script) that generates documents and given the<br\/>context-free reference grammar for the document language<br\/>(e.g., a grammar for HTML),<br\/>the analysis tool generates an LR(k) parser for the reference grammar<br\/>and applies a data-flow analysis to analyze the program and<br\/>predict the context-free grammatical structure of the<br\/>documents to be generated by the program.<br\/>The tool computes abstract parse stacks, a novel and innovative structure<br\/>that encodes a generated document's context-free structure.<br\/>Next, the tool applies formal semantics techniques to compute from<br\/>an abstract parse stack its context-sensitive semantics, that is, the<br\/>meaning of the dynamically generated document.<br\/><br\/>Dynamically generated documents are often assembled<br\/>with user-supplied input, which can be erroneous or malicious.<br\/>The analysis annotates the abstract parse stacks to identity<br\/>where user input might appear,<br\/>and the semantic analysis tracks the influence<br\/>of the user input upon the document's meaning.","title":"Abstract Parsing: Static analysis of dynamically generated string output","awardID":"0939431","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["533701"],"PO":["565264"]},"159008":{"abstract":"Challenges inherent in non-visual Web interaction prevent more than 2 million blind Americans from participating effectively in routine Web-based activities. The existing literature does not provide an understanding of cognition and subjective perception by visually-impaired people in these situations. Without this understanding, any effort to overcome the challenges of non-visual Web interaction will not be adequately informed. This project examines cognitive strategies employed by blind Web users that are distinct from typical sighted users. The research design used a problem solving framework to compare how blind participants and sighted participants \"think aloud\" while performing a series of web-based tasks. Activities where blind participants have difficulties, evidenced from their verbalizations, will be explored further in order to determine their cognitive strategies and how they differ from the strategies used by sighted persons. <br\/><br\/>Web interaction is important to many day to day activities, including education, work, information seeking, shopping and socializing. More than 2 million visually-impaired Americans cannot participate effectively in these activities. Findings of this project may form the basis for interventions that allow enable blind people to overcome the challenges and participate effectively in all aspects of life that require Web interaction. In addition, it introduces visually impaired high-school students to research through participation. <br\/><br\/>This work is funded by BCS, CISE, OCI, and EHR.","title":"EAGER: The Mind of the Blind on the Web","awardID":"0938539","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7642","name":"VIRTUAL ORGANIZATIONS"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"7252","name":"PERCEPTION, ACTION & COGNITION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7625","name":"REESE"}}],"PIcoPI":["548759"],"PO":["563458"]},"153970":{"abstract":"This project studies the performance of complex large-scale spatial networks that use distributed communication algorithms by applying different random network models. While much of the previous work on random spatial networks has focused on topological aspects and on centralized algorithm design, the emphasis of this project is on developing distributed algorithms and on characterizing desired invariant network properties that such networks must satisfy to allow for the efficient implementation of distributed algorithms. Expected results from the project include (1) decentralized algorithms for ef&#64257;cient path navigation, (2) decentralized algorithms for information &#64258;ow in random networks, (3) decentralized algorithms for information dissemination, (4) distributed energy management in random networks, and (5) distributed topology control for maintaining percolation-based connectivity. This project will (1) increase the understanding of complex information systems upon which society increasingly depends, (2) lead to design guidelines for practical network architectures and protocols, (3) disseminate the scientific and technological findings through publications, (4) further the development of related disciplines such as mathematics (probability) and statistical physics, (5) impact undergraduate and graduate education through a planned joint course on random networks, and a summer lecture series, (6) enhance research experiences for undergraduates through summer research projects, and (7) encourage the participation of women and minorities in networking research.","title":"NeTS: Small: Collaborative Research: Large Scale Networks and Information Flow: From Emergent Behavior to Algorithm Design","awardID":"0916778","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[409707],"PO":["564993"]},"150340":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\"<br\/><br\/>Mainstream computing - on the desktop, in the datacenter, and in embedded devices - is undergoing an unprecedented shift toward parallelism as manufacturers adopt multi-core architectures. Conventional multi-core processors have very inefficient communication, synchronization, and locality-management mechanisms causing them to scale poorly on hard problems and to be difficult to program. The research proposes to develop a set of efficient mechanisms - hardware APIs and supporting microarchitecture - for communication, synchronization, and locality management. Specifically, the project proposes to develop an agile memory hierarchy, register-based communication and synchronization, and fast active messages. By reducing communication and synchronization overhead by orders of magnitude, it is possible to substantially improve the efficiency, programmability, and scalability of multi-core processors. Overall, the mechanisms will free programmers from the incidental constraints imposed by conventional multi-core architectures - allowing them to concentrate instead on the fundamental issues of parallelism, locality, and load balance.<br\/><br\/>The proposed work is expected to have an immense impact on future architecture and programming systems for multi-core processors. By reducing communication and synchronization overheads, the mechanisms will enable many applications that are not embarrassingly parallel to benefit from multi-core architectures. The work is likely to enable a new generation of multi-core programming systems. The educational plan includes to integrate the results of this research into graduate and undergraduate courses at Stanford University.","title":"MCDA: Efficient Mechanisms for Multicore Processors","awardID":"0903109","effectiveDate":"2009-08-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7786","name":"MCDA"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":[400637],"PO":["366560"]},"153982":{"abstract":"Proposal ID: 0916828 <br\/>PI name: Blanton Shawn <br\/>Institution: Carnegie-Mellon University <br\/>Title: Achieving IC Quality through On-Going Diagnosis and Customized Test<br\/><br\/>ABSTRACT<br\/>The main objective of computer chip testing has and continues to be the separation of good chips from bad ones (i.e., ones that do not meet the desired operational characteristics). Test is now however being expanded as a value-added endeavor. In this project, we are data-mining test data in order to continuously monitor chip quality. We propose to use diagnosis-extracted models of chip failures along with a new technique for estimating chip quality. Both are incorporated in an on-line, quality-monitoring methodology that ensures a desired level of quality by changing the actual tests applied to a computer chip to better match the characteristics of currently-failing chips.<br\/><br\/>This approach to quality is dynamic in nature and is a radical change from the typical approach. Without exception, each chip manufacturer (Intel, IBM, etc.) assumes that any type of defect can occur anywhere within their chip which means that each manufactured instance has to be thoroughly tested at considerable expense. This is akin to prescribing drugs for all possible diseases\/ailments for every patient without performing one diagnostic examination. Opposed to the traditional approach, this proposed work instead diagnoses chips that have failed in the past to determine what ?diseases? (i.e., defects) actually are occurring within the fabricated ICs. The ?prescriptions? (i.e., the tests applied to the chips) can therefore be changed and\/or minimized to match the diseases found instead of over-testing as is done now, leading to improved chip quality at minimal cost.","title":"SHF: Small: Achieving IC Quality through On-Going Diagnosis and Customized Test","awardID":"0916828","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["548338"],"PO":["562984"]},"161000":{"abstract":"NeTS-NR: Efficient and Localized Broadcasting in Ad Hoc Wireless Networks<br\/><br\/>Jie Wu, Florida Atlantic University<br\/><br\/>Award 0434533<br\/><br\/>Abstract<br\/><br\/>Collective communication represents a set of important communication functions that involve multiple senders and receivers. Broadcasting is one of the fundamental operations and has extensive applications, including the route discovery process in reactive routing protocols, naming and addressing, and dense mode multicasting. Due to the broadcast nature of wireless communication, blind flooding of the broadcast message may cause serious contention and collision, resulting in the broadcast storm problem. This project studies the challenge of efficient and localized broadcasting in ad hoc wireless networks by offering a generic framework that can capture many existing localized broadcast algorithms and, in addition, some efficient solutions can be derived from this framework. This research has six thrusts: (1) Provide a more generic framework for deterministic and localized broadcasting in ad hoc networks, including constructing consistent views. (2) Derive cost-effective broadcast schemes from the framework. (3) Reduce excessive broadcast redundancy through energy-efficient design,. (4) Explore the use of broadcasting as a basic building block to support other types of collective communication. (5) Ensure broadcast coverage with controlled redundant transmission without solely relying on ACK\/NACK. (6) Integrate different components and fine tune the system through an empirical study based on a set of well-defined quantitative performance metrics. The new framework can easily integrate other objectives such as energy-efficiency and reliability. The results of this research will provide guidelines for efficient and localized algorithms for a wide range of applications. This research will also exploit and contribute to theoretical studies in graph theory and distributed algorithms.","title":"NeTS: Efficient and Localized Broadcasting in Ad Hoc Wireless Networks","awardID":"0949078","effectiveDate":"2009-08-08","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["7594"],"PO":["557315"]},"153630":{"abstract":"Abstract<br\/>0915376 - Novel Techniques for Lossless Data Compression and Efficient Decompression in Heterogeneous Embedded Systems<br\/>PI: Prabhat Mishra<br\/><br\/>Demands for heterogeneous and complex embedded applications have soared drastically in recent years. Memory is one of the key driving factors in designing such systems since a larger memory indicates an increased chip area, more power dissipation, and higher cost. Compression techniques are promising to reduce memory requirements by reducing the program and data size. The existing approaches either perform efficient compression using complex and variable-length encodings at the cost of slow decompression, or fast decompression using simple and fixed-length encodings at the cost of compression efficiency. This research will develop novel tools and techniques to achieve both efficient compression and fast decompression for a wide variety of application domains and system architectures. This project will make three fundamental contributions: novel decode-aware compression, optimal bitstream placement for parallel decompression, and synergistic integration of compression and encryption. A successful implementation of the proposed research will result in significant improvement in system performance and security, and drastic reduction in overall area, cost and energy requirements. Synergistic integration of compression and encryption will lead to efficient and secure embedded systems. The outcome of this research has a direct impact on everyday life. Improved compression\/decompression techniques will have double impact ? low-cost and low-power everyday appliances for the public and improved performance and security for safety-critical systems. This project will have broad educational impact by developing compression related projects in both graduate and undergraduate courses, and by involving undergraduates as well as minority students through UF Honors, University Minority Mentoring and SEAGEP programs.","title":"CSR:Small: Novel Techniques for Lossless Data Compression and Efficient Decompression in Heterogeneous Embedded Systems","awardID":"0915376","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["518389"],"PO":["561889"]},"153751":{"abstract":"The amount of medical imaging data has been growing at an unprecedented rate in recent years due to the rapid advancement in medical imaging devices and technologies. In many medical application areas, assessment of similarity and disparity from multimodality, multi-dimensional data across subjects plays a central role. Current software in exploration and visualization of a collection of multimodality, multidimensional cross-subject data impedes the effective utilization and better understanding of acquired, large-scale data. <br\/><br\/>The overall objective of this research is to design and develop a unique coordinated visualization framework, based on advanced geometric computing as well as data and visual abstraction, for integrating, interpreting and comparative analysis of cross-subject, multidimensional, multi-measure brain imaging data. This developed visualization framework extends the state-of-the-art in both information visualization and medical visualization. It employs novel geometric feature analysis for better supporting surface matching and shape comparison, and generalizes data warehousing technology to spatially varying information deep inside multi-dimensional medical images. The research outcomes are disseminated through traditional publications as well as the Internet.<br\/><br\/>This research project provides a useful multimodality imaging analytics framework which contributes to diverse application domains, such as clinical diagnosis of neurological disorders, drug efficacy analysis through quantitative image analysis, and basic neuroscience. In addition, the sharing of data and software tools has both clinical and educational values for students, physicians, researchers, and the general public. The integration of the research and education components promotes further interactions between computer science and neuroscience.","title":"III: Small: Collaborative Research: Coordinated Visualization for Comparative Analysis of Cross-Subject, Multi-measure, Multi-dimensional Brain Imaging Data","awardID":"0915933","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["424417"],"PO":["564316"]},"152662":{"abstract":"The project creates robust, widely-deployable and cost-effective technologies for supporting cross-lingual spoken interaction between people who do not share a common language. The target application supports communication between healthcare personnel who speak English only and patients with limited-English proficiency. The state-of-the-art technologies that enable such cross-lingual interactions are characterized by a pipelined architecture of speech recognition, machine translation and speech synthesis, that largely ignore the rich information present in spoken language beyond those conveyed by words. They also do not take advantage of the humans in the loop for collaboratively managing the interaction. Overcoming these limitations requires improving robust intelligence at all levels ? signal, system, and human ? and set the research goals for this project. <br\/><br\/>The project?s intellectual merit comes from the unique combination of theoretical, computational model-ing and empirical elements: The theoretical framework is centered on notions of social co-presence to de-velop new models for translation-mediated communication. The computational modeling focuses on capturing prosody, dialog and user state from spoken language for enriching the technology components. The empirical work relies on a participatory approach to iterative design and evaluation of the system, working directly with the stakeholders.<br\/><br\/>The broader impact can be seen in the potential for facilitating multilingual efforts ranging from disaster relief and global business operations to servicing diverse immigrant populations notably in health care. The effort brings together engineers, linguists, human communication experts, and medical professionals to tackle a broad range of problems, and offers integrated interdisciplinary research training and mentor-ing.","title":"RI: Large: An Integrated Approach to Creating Context Enriched Speech Translation Systems","awardID":"0911009","effectiveDate":"2009-08-15","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["515830",406740,"471988"],"PO":["565215"]},"153520":{"abstract":"With each advance in computing technology, researchers develop innovative user interfaces so users can leverage the technology to enhance productivity. 3D immersive virtual environments have long been considered a new frontier in computing; however, lack of effective user interfaces within these virtual worlds has prevented them from being widely used in industry. The PI's prior work has focused on a user interface framework for immersive virtual environments that facilitates context-driven interaction techniques, which have been proven to enhance productivity. One aspect of \"context\" is the use's workspace: the area and position in the virtual world that the user is most interested in. In this project the PI will build on his previously developed framework to create methods for automatically inferring workspace size and location, and for enabling applications to select the most appropriate navigation technique. The underlying hypotheses are that contextual information can be automatically inferred by observing the user's actions, and that automatically activating specialized interaction techniques suited for the current context will enhance productivity. The hybrid navigation aid to be developed will be based on the well-known WIM and Orbital Viewing approaches. Finding ways to effectively transition between navigation aids based on a changing workspace is a principle objective of this research, which will represent a significant contribution toward making navigation within a virtual world less cumbersome and more efficient.<br\/><br\/>Broader Impacts: This work will lead to more effective user interfaces for immersive virtual environments, which will help unlock their true potential for applications such as architectural design, scientific exploration, and collaborative training applications. The implicit recognition of workspace coupled with the activation and transitioning between navigation techniques will be a valuable addition to the current body of knowledge in 3D user interface design. Although the current project focuses on a single particular area of 3D user interface design, the PI's context-driven framework outlines dozens of instances benefit from this technique. Each of these additional highly focused projects can be undertaken with the equipment funded through this award; together, they constitute excellent opportunities for undergraduate research, which will continue long after the current effort is completed. Virtual environment development inherently requires input from a wide range of specialties (e.g., domain experts to help develop simulation applications and graphics artists to help create content); the PI will take full advantage of his institution's liberal arts focus to bring together students and faculty from a variety of disciplines when carrying out this research.","title":"HCC: SMALL: Modeling and Exploiting Interaction Context in 3D User Interfaces","awardID":"0914976","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[408583],"PO":["565227"]},"153883":{"abstract":"This project will focus on the problem of allocating a limited number of shared resources among competing agents, which is a fundamental problem in operations research and economics. Such problems arise in many settings: scheduling in computer and communication networks, deciding where to locate public facilities, matching colleges to prospective students, assigning housing to graduate students, allocating organs to patients on a waiting-list, dividing an estate between siblings, sharing the cost of a public good, etc. The central aim of this project is to design effective resource allocation mechanisms that (i) have a strong theoretical justification; (ii) are easy to compute; and (iii) are simple to implement in practice. The project can be broadly classified in two parts: the first part deals with a notion of equilibrium based on minimizing maximum regret, and will explore its implications for mechanism design. Initial results of this approach to bargaining problems with incomplete information appear promising. The second part of the project deals with matching and allocation problems. Here, nonstandard criteria such as fairness and incentives are incorporated into some well-studied optimization models. The project will seek to characterize conditions under which it is possible to design mechanisms that are both fair and incentive-compatible for a number of natural models. One of the aims will be to promote a greater interaction between economists and optimization researchers by illustrating how the research questions, ideas, and tools in one discipline can inform and enrich the other. If successful, the results of the project will lead to a better understanding of important phenomena such as collusion and coalition formation in matching and allocation problems.<br\/><br\/>The methods developed in this project, and the algorithms derived from them have the potential to improve the performance of several real-life systems. For example, the work on matching and allocation problems is inspired by applications to \"school choice\" problems. The results of this research will provide insight into how resource allocation decisions interact with the (often conflicting) goals of incentive-compatibility and fairness. The educational goals of the proposed project include the introduction of the exciting recent developments in the area of mechanism design in the undergraduate and graduate curriculum. These courses will serve to expose the undergraduate and graduate students to the large variety of public-decision making problems for which optimization methods and tools are applicable.","title":"AF: Small: Effective Resource Allocation Mechanisms: Fairness and Incentives","awardID":"0916453","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7932","name":"COMPUT GAME THEORY & ECON"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"5514","name":"OPERATIONS RESEARCH"}}],"PIcoPI":["508938"],"PO":["565139"]},"153410":{"abstract":"The amount of medical imaging data has been growing at an unprecedented rate in recent years due to the rapid advancement in medical imaging devices and technologies. In many medical application areas, assessment of similarity and disparity from multimodality, multi-dimensional data across subjects plays a central role. Current software in exploration and visualization of a collection of multimodality, multidimensional cross-subject data impedes the effective utilization and better understanding of acquired, large-scale data. <br\/><br\/>The overall objective of this research is to design and develop a unique coordinated visualization framework, based on advanced geometric computing as well as data and visual abstraction, for integrating, interpreting and comparative analysis of cross-subject, multidimensional, multi-measure brain imaging data. This developed visualization framework extends the state-of-the-art in both information visualization and medical visualization. It employs novel geometric feature analysis for better supporting surface matching and shape comparison, and generalizes data warehousing technology to spatially varying information deep inside multi-dimensional medical images. The research outcomes are disseminated through traditional publications as well as the Internet.<br\/><br\/>This research project provides a useful multimodality imaging analytics framework which contributes to diverse application domains, such as clinical diagnosis of neurological disorders, drug efficacy analysis through quantitative image analysis, and basic neuroscience. In addition, the sharing of data and software tools has both clinical and educational values for students, physicians, researchers, and the general public. The integration of the research and education components promotes further interactions between computer science and neuroscience.","title":"III: Small:Collaborative Research: Coordinated Visualization for Comparative Analysis of Cross-Subject, Multi-Measure, Multi-Dimensional Brain Imaging Data","awardID":"0914631","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[408307],"PO":["564316"]},"153652":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Two of the most important abstractions in Computer Science are graphs and point clouds. A graph abstracts relations between things: two vertices in a graph are connected by an edge if the objects associated with the vertices are related. Directed edges indicate a connection from one vertex to another. Both social networks and the web are modeled as graphs: vertices could represent people with edges between friends, or they may represent web pages with directed edges representing links. Point clouds are sets of vectors, each vector providing a list of numerical attributes. In many computer science applications, one associates a vector with each object being examined. For example, one may rate on a numerical scale different properties of a chemical, or how much a person likes movies from certain genres.<br\/><br\/>This project will unify these two abstractions by translating point clouds into graphs. Each vector becomes a vertex in a graph, with the strength of the edge connecting two vertices indicating the degree of similarity of the corresponding vectors. This translation will enable the application of numerous techniques that have been developed in graph theory to the study of point clouds.<br\/><br\/>Technical objectives of the project include the determination of the best graph to associate with a point cloud, the development of efficient algorithms for the construction of such a graph, and the development of new approaches to the analysis of graphs. In particular, a spectral analysis of directed graphs will be developed.<br\/><br\/>Both graduate students and undergraduates will be trained in research while working on this project. Educational materials developed during the course of the project will be disseminated through the internet as well as incorporated into a book under development.","title":"AF: Small: Spectral Graph Theory, Point Clouds, and Linear Equation Solvers","awardID":"0915487","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":["483530"],"PO":["565251"]},"164542":{"abstract":"Given their ever increasing complexity, modern software systems are plagued with software defects, commonly known as bugs. It usually takes significant amount of efforts for software developers to locate the defects after a program failure is observed. Due to the limited on-chip resource at the time, traditional architectural support for debugging was limited to a basic set of primitive functions like breakpoints and watchpoints. With the advances in semiconductor technology, the resource constraint is less of a concern and much more powerful architectural support becomes possible to be implemented to ease software debugging. In this research, novel software-hardware integrated approaches are developed to automatically pinpoint software defects and the aim is to develop a computer that can automatically pinpoint the faulty code in either sequential or parallel programs and potentially generate a fix to the defect.<br\/><br\/>Previous work on architectural support for debugging mainly focused on one aspect of debugging activities including faithfully reproducing program failures or detecting potential bugs. In comparison, this research introduces novel architectural support for: bug detection to report potential bugs, bug isolation to find the relevant bugs based on cause-effect relationship between the potential bugs and the program failure, and bug validation to generate quick fixes to the isolated bugs, thereby forming a complete process of automated debugging. Bugs in both sequential and parallel programs are the target in this research. For parallel programs, the research investigates thread interaction under the transactional memory programming model and develops novel automated debugging schemes for concurrency bugs. The research also includes the prototype of the novel architectural supports to evaluate their effectiveness with real-world applications.","title":"CAREER: Architectural Support for Automated Software Debugging","awardID":"0968667","effectiveDate":"2009-08-17","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["517241"],"PO":["565272"]},"150264":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009(Public Law 111-5).\"<br\/><br\/><br\/>Lead Proposal#: 0902885<br\/>Title: Parameterized Architecture-Level Thermal Modeling and Characterization for Multi-Core Microprocessor Design<br\/>PI: Sheldon X.-D. Tan, Dept of Electrical Engineering, UC Riverside<br\/>co-PI: Yingbo Hua, Dept of Electrical Engineering, UC Riverside <br\/><br\/>Inst: Department of Electrical Engineering<br\/>CoPI Inst:University of California at Riverside<br\/><br\/><br\/>ABSTRACT<br\/>Multicore (also known as so-called chip-multiprocessors (CMP)) architectures are the trend for current and future microprocessor designs. They provide better performance via thread-level parallelism, better power\/thermal scaling, and easy design by design reuse. However, power\/thermal considerations are still the first-class constraints for multicore microprocessor designs. Thermal-aware design space explorations at core and architecture level for multicore microprocessors become critical design issues. <br\/><br\/>This research seeks to explore new techniques of building compact parameterized, transient thermal models for efficient thermal-aware design space explorations in multicore microprocessor designs. <br\/>The project consists of three thrusts: (1) Architecture-level behavioral transient thermal modeling and characterization; (2) Parameterized thermal modeling considering variable design parameters; (3) Thermal model optimization and reduction. The proposed method is a top-down, black-box approach, meaning that it does not require any knowledge of the internal structures of the systems; This approach makes the proposed method very general and flexible, which contrasts the existing approaches. The accuracy of the models is ensured by the measured or precisely computed thermal-power information from hardware. The parameterized models can accommodate different design variable parameters for efficient design space explorations.<br\/><br\/>The outcome of this research will add significantly to the core knowledge of thermal modeling multicore design. It will provide a new alternative way to complement existing architecture-level thermal models for the architecture community. Since the PIs will work closely with SRC, the proposed project will have immediate impacts on thermal-aware multicore microprocessor design in industry. This grant will enable the PI to hire more women and underrepresented minority students to contribute to the greater diversity in America's science and technology workforce.","title":"Parameterized Architecture-Level Thermal Modeling and Characterization for Multi-Core Microprocessor Design","awardID":"0902885","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7786","name":"MCDA"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":[400450,"535204"],"PO":["562984"]},"150396":{"abstract":"High-end embedded systems such as smart phones, game consoles, GPS-enabled automotive systems, home entertainment centers, and other ?ambient intelligence? systems are becoming increasingly important in everyday life. Making such systems energy-efficient presents new challenges with broad implications for the economy and the environment. Such high-end embedded systems are multicore architectures, which require management of resources such as memory connectivity and scheduling. This proposal investigates the energy implications of system-level concurrency issues in high-end embedded systems that are not limited by real-time constraints. In particular, it aims to develop energy-efficient techniques of synchronizing memory accesses, and tries to understand the optimal division of tasks between hardware and software. <br\/><br\/>Embedded systems are an integral component of modern life, and is a continually growing market. As the computational needs of the products in this market becomes more sophisticated, there will be more challenges in meeting the tight constraints imposed by these systems. Improvements in the performance and in particular the energy efficiency of such devices would have a substantial impact in terms of improved functionality, device longevity, and resource conservation. This proposal involves collaboration between two disciplines, computer engineering and computer science, and two institutions. Broader impacts of the proposal include development of workshops focused on multicore and parallel computing with special emphasis on encouraging women and under-represented minorities to participate. In addition, the findings of this project will be integrated into existing courses, specifically aiming to introduce cross-cutting issues between the computer science and engineering courses.","title":"Collaborative Research: Energy-Aware Memory Synchronization for Embedded Multicore Systems","awardID":"0903295","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7786","name":"MCDA"}}],"PIcoPI":["550431"],"PO":["366560"]},"153443":{"abstract":"NSF proposal: 0914739<br\/>PI: Newberg, Lee A.<br\/><br\/>Computationally efficient estimation of the error rates of hidden Markov model results<br\/><br\/>Hidden Markov models are employed in a wide variety of fields, including speech recognition, econometrics, computer vision, signal processing, cryptanalysis, and computational biology. In speech recognition, hidden Markov models can be used to distinguish one word from another based upon the time series of certain qualities of a sound. In finance, the models can be used to simulate the unknown transitions between low, medium, and high debt default regimes in time. In computer vision they can be used to decode American Sign Language (ASL). Hidden Markov models are used in computational biology to find similarity between sequences of nucleotides (DNA or RNA) or polypeptides (proteins) and to predict protein structure.<br\/><br\/>Hidden Markov models are employed because they permit the facile description and implementation of powerful statistical models and algorithms that are used to score a match possibility in sequence data. Perhaps the most common use of hidden Markov models is for the purpose of hypothesis testing or classification. For instance, a speech-recognition model may be used to quantify the belief that a recorded message contains the word ?elephant.? However, once a score for a belief has been computed, the question is how to interpret that value.<br\/>1. Is the score strong enough to indicate a signal, or is it reasonably probable that noise will yield a score this strong?<br\/>2. Is the score weak enough to indicate noise, or is it reasonably probable that a signal will yield a score this weak?<br\/>The false positive rate (closely related to the type I error or p-value) for a score threshold is the probability that noise data will yield a score at least as strong as the threshold. The false negative rate for a score threshold is the probability that signal data will fail to score at least as strong as the threshold.<br\/><br\/>In 2008, Newberg designed a method for estimating error rates that is more efficient than other approaches that are applicable to general hidden Markov models. However the approach is still too slow for computationally intensive applications such as repeated searches of large DNA databases. This proposed research aims to speed the estimation primarily via two approaches: (1) the creative re-use of simulations, and (2) statistically robust elimination of outlier simulation results.<br\/><br\/>The proposed research is significant because the facile availability of error rates permits researchers in a wide variety of scientific fields to evaluate the statistical significance of their conclusions and the power of their hypothesis tests. Once the technique and software are available, researchers in speech recognition or ASL recognition will be able to use rigorously derived statistical significance values to set their hypothesis test thresholds for word recognition. Financial modelers will have a rigorous standard by which to evaluate their market timing models. Computational biologists will have rigorous statistical significance values for their sequence alignments and for their pattern scans of large sequence databases. More generally, the availability of error rates for hidden Markov model results will significantly enhance the attractiveness of hidden Markov models for use in fields where hidden Markov models are not currently employed.","title":"Computationally efficient estimation of the error rates of hidden Markov model results","awardID":"0914739","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7931","name":"COMPUTATIONAL BIOLOGY"}}],"PIcoPI":["429617",408405,"429617"],"PO":["565223"]},"155786":{"abstract":"Proposal #: CNS 09-23238<br\/>PI(s): Sheng, Weihua; Cheng, Qi; Li, Xiaolin; Rahnavard, Nazanin<br\/>Institution: Oklahoma State University <br\/> Stillwater, OK 74078-1011<br\/>Title: MRI\/Acq.: Acq.of an Optical Motion Capture System for Human-Centered Computing Research<br\/>Project Proposed:<br\/>This project, acquiring an optical motion capture system, supports research for infrastructure-free human context awareness and context-based human intention recognition. The system relies on wearable sensing and computing devices to achieve human context awareness. The research aims to answer central questions in understanding the interplay between human and computing, mainly <br\/>- Understanding human context (e.g., behavior, location) through embedded computing, and<br\/>- Exploring the knowledge of human context to improve embedded computing applications.<br\/>The first research project investigates the development of infrastructure ?free human context awareness in GPS-restricted environments. The second studies the use of the knowledge of human context to better understand human intentions and addresses the study in a human-robot interaction (HRI) setup. Both projects require a motion capture system that can provide location ground truth, allow performance comparison, and facilitate system calibration. The work aims to <br\/>- Develop a theoretical framework to achieve a stand-alone human context awareness that requires zero infrastructure setup. (Some activities, such as 'virtual landmarks' are expected to contribute in indoor human localization.)<br\/>- Develop explicit human intention recognition based in the context of both location and activity that pushes forward research in human-robot interaction <br\/>- Lead to a better understanding of interactive, coupled relationship between human and computing.<br\/><br\/>Broader Impacts: The work impacts wearable computing, human-computer interaction (HCI), and ubiquitous computing research. Modifications of the developed hardware and software might serve to track the locations and monitor the status (activity and health) of first responders, improving the efficiency of personnel safety in their operations. The system improves the research capabilities in Oklahoma, an EPSCoR state. Planned education and training activities contribute in preparing students in embedded computing, wireless communication, signal processing, and human behaviors. Outreach activities stimulate prospective students. Efforts will be made to involve Native American and female students.","title":"MRI: Acquisition of an Optical Motion Capture System for Human-Centered Computing Research","awardID":"0923238","effectiveDate":"2009-08-01","expirationDate":"2012-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["486088","523489","530695","518429","565204"],"PO":["557609"]},"153487":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 <br\/>(Public Law 111-5).<br\/><br\/>Software bugs cost the U.S. economy over $60 billion each year. Promising bug-detection technology depends on high-performance logic solvers for Satisfiability Modulo Theories (SMT), which employ sophisticated algorithms to check large formulas efficiently. Sophistication has a price: the solvers themselves exhibit bugs, and are not trustworthy enough for safety-critical applications. To increase confidence, some SMT solvers can emit formal proofs for valid formulas. Checking these proofs with a simple proof checker confirms the solver's results. SMT's rich logic poses challenges for standardizing a single proof format for all SMT solvers. Furthermore, proofs produced by SMT solvers can be gigabytes long, requiring an optimized proof checker. <br\/><br\/>This collaborative project is developing a verified proof checker supporting a flexible format called the Edinburgh Logical Framework with Side Conditions (LFSC). LFSC is a meta-language for describing different proof systems, thus providing flexibility. Verification techniques are being applied to the proof checker itself to verify its optimizations, by writing it in a verified programming language called Guru. Support is also being added for LFSC proofs to the CVC3 solver. This research will greatly increase confidence in solver results through proofs, thus increasing the power of bug detection.","title":"SHF: Small: Collaborative Research: Flexible, Efficient, and Trustworthy Proof Checking for Satisfiability Modulo Theories","awardID":"0914877","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["532995","521573"],"PO":["565264"]},"154114":{"abstract":"New Theoretical Foundations of Tensor Applications: Clustering, Error Analysis, Global Convergence, and Robust Formulations<br\/><br\/>Tensor decompositions become increasingly important in analyzing high-dimensional multi-index data. However, applications of tensor decompositions are so far restricted: (1) they are mainly used for data compression ? critically important tasks such as data clustering have not been addressed. (2) No bounds on reconstruction error exist ? the compression parameters are determined on a trial-and-error basis. (3) As solutions to non-convex optimizations, tensor decompositions are not unique. This could severely affect the reliability of tensor analysis. (4) Tensor decompositions are obtained via minimizing the sum of squared errors, thus are prone to noise or outliers in the data. A robust formulation of decomposition is highly desirable for applications with large noises. In this proposal, we investigate these new fundamental aspects of tensor applications: <br\/>(1) Investigate the clustering capabilities of tensor decompositions, in addition to the established theoretical results on clustering; <br\/>(2) Provide comprehensive error analysis of tensor decompositions and derive lower and upper error bounds; <br\/>(3) Investigate conditions for global convergence for tensor decompositions and investigate good initializations for the cases where global convergence fails. <br\/>(4) Develop robust formulations for tensor decompositions.<br\/>In addition, we will develop user-friendly software toolbox that contains the resulting algorithms and make it available to the public. We will also educate graduate and undergraduate students with fundamentals in matrix and tensor computations. We will present tutorials and organize workshops on this new direction.","title":"New Theoretical Foundations of Tensor Applications: Clustering, Error Analysis, Global Convergence, and Robust Formulations","awardID":"0917274","effectiveDate":"2009-08-15","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7933","name":"NUM, SYMBOL, & ALGEBRA COMPUT"}}],"PIcoPI":["560636","425256"],"PO":["565251"]},"154059":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The growing popularity of wireless networks at the periphery of the Internet, combined with the need for ubiquitous access to video on demand (VoD) applications, calls for a new generation of video streaming technology. This research is investigating techniques to enable efficient VoD service over wireless mesh networks (WMN). Four methods are studied: wPatching is a multicast technique designed to leverage the broadcast nature of WMN to support VoD applications; Dynamic Stream Merging utilizes smart mesh nodes to merge video streams in order to conserve wireless resources; a hybrid environment uses mobile nodes as relay nodes to extend the service range of the WMN; and Constrained Multicast provides efficient and seamless handoffs for mobile users in the WMN by eliminating Internet router (layer-3) handoff delay. Along with extensive simulation studies, a prototype is developed to experiment with the Dynamic Stream Merging and Constrained Multicast techniques. These new streaming methods provide an enabling technology to extend VoD applications beyond the traditional wired environment to reach mobile users on wireless networks at the edges. The result is a new paradigm for efficient management of VoD traffic over a WMN. Applications such as digital libraries, distance learning, public information systems, electronic commerce, and video entertainment will benefit from this innovative streaming technology. The software and protocols developed for this project will be made available to other researchers to facilitate and encourage future research and application experimentation.","title":"NeTS: Small: Scalable Wireless Mesh Network Technology at the Edge for Efficient Mobile Video Data Access on Demand","awardID":"0917082","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[409925],"PO":["557315"]},"148988":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of<br\/>2009 (Public Law 111-5).<br\/><br\/>Buggy software costs the U.S. up to $60 billion annually, so preventing<br\/>bugs is important to society. It is possible to prevent certain bugs by<br\/>running a type-checker that analyzes a program to find all errors of a<br\/>given type. Current type-checkers for mainstream programming languages are<br\/>limited: there are too many bugs they cannot express and prevent.<br\/><br\/>This project enables a programmer to extend and customize a type-checker.<br\/>As a result, the type-checker can detect and prevent more errors, and in<br\/>particular the errors that the programmer considers most important. The<br\/>outcomes include design of new type systems for solving real-world<br\/>programming problems; a framework for building custom type-checkers, in the<br\/>context of an industrial language (Java); and significant experience with<br\/>real codebases to evaluate the ideas and to generate new research<br\/>questions. The framework will enable a community of researchers to more<br\/>quickly and realistically evaluate their theories. This may encourage more<br\/>relevant research and lead to more impact on practice.","title":"II-NEW: Practical Pluggable Type Systems","awardID":"0855252","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["501796"],"PO":["564388"]},"160670":{"abstract":"Abstract<br\/>The objective of this proposal is to hold a grantees meeting on July 8-9, 2009 focused on the potential of cyber-physical systems and their impact on our lives. The event, ?Cyber-Physical Systems ? Leading the Way to a Smarter, Safer Future for Anyone, Anywhere, Anytime?, This is a two-day event: the first day will take place at the National Science Foundation and will be dedicated to a dry-run session; the second day of the CPS event will take place at Capitol Hill and will include a luncheon with the members of the Senate followed by demonstrations and poster presentations of research work related to CPS. The invited audience includes 25 members of the Senate Commerce Committee and their staffs. <br\/>Intellectual merit: The demonstration and posters will showcase state-of-the-art and innovative research projects describing the potential benefits of CPS to the society, while highlighting the research challenges that need to be address in order to realize the CPS vision. <br\/>Broader Impact: The Grantees meeting will provide an opportunity to showcase the current accomplishments in the CPS to some of the senior senators, members of the Senate Commerce Committee and their staffs and to the NSF staff. The workshop will have participation from 12 institutions and their post Docs, graduate students and undergraduate students. It also includes participation and demonstration by the High school students. This will be a great opportunity for them to interact with other participants and learn about many exciting opportunities in the CPS area.","title":"CPS Grantees Workshop","awardID":"0947792","effectiveDate":"2009-08-01","expirationDate":"2012-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["542301"],"PO":["561889"]},"181152":{"abstract":"Vast quantities of electronic information provide a unique opportunity for scientists identify candidate solutions for grand challenges as scientists, policy makers, and students have never had access to more electronic information than they do today. The goal in this research is to develop new text mining methods that are consistent with the manual processes that experts currently used to resolve contradictory and redundant evidence. Both discovery and synthesis are difficult activities even for people, so the team plans a socio-technical strategy to achieve this goal. This study includes a longitudinal study of manual discovery and synthesis behaviors of a diverse network of faculty, policy makers, and students from UNC and the Research Triangle Park. The majority of effort will be to advance natural language processing methods that automatically identify concepts and relationships, detect entailment and paraphrasing, and generate multi-document summaries. Lastly, a series of qualitative and quantitative studies that accurately reflect the degree to which text mining methods assist in discovery and synthesis activities will be conducted. This project will advance language processing methods that detect concepts and relationships, recognize paraphrases and entailment, and generate multiple documents summaries; provide the natural language community with a collection of gold standards that reflect diverse and realistic information needs; train the next generation of scientists to explore complex research that span disciplines; promote the ?human side of discovery? via a sponsored workshop. The socio-technical solution to text mining proposed in this project will ensure broad impact of the subsequent text mining theory and tools. This project will accelerate scientific discovery by enabling experts to follow connections between disciplines; and accelerate policy development by reducing the time required to resolve seemingly redundant and contradictory evidence within a discipline. Involving policy champions from the Environmental Protection Agency and the Cecil G. Sheps Center for Health Services will ensure that the theory and technology produced from this research are consistent with the complex environment in which discovery and synthesis takes place. Claim Jumper will accelerate their existing policy efforts, but more importantly, tools from this project will enable studies that are not feasible with manual methods.","title":"Towards Evidence-Based Discovery","awardID":"1115774","effectiveDate":"2009-08-31","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[485435],"PO":["565136"]},"150440":{"abstract":"The objective of the proposed research is to design innovative algorithms and tools for energy-aware scheduling and mapping of tasks onto homogeneous and heterogeneous multi-core processor (HeMP) architectures. The research proposes to develop a new theoretical and experimental framework, called multi-element and multi-objective (MEMO) optimization, that will simultaneously and flexibly optimize the goals of energy minimization and performance maximization while taking into account constraints due to multiple architectural elements such as cores and caches of current and emerging multi-core processors. The project will develop CorePac, a toolkit that will provide a flexible and friendly environment to schedule task-parallel applications on HeMPs under various performance\/energy trade-offs and demonstrate the usefulness of the algorithms and CorePac. Benchmarking of the algorithms will be conducted using a diverse suite of scientific, multimedia, and bioinformatics applications.<br\/><br\/>Through its production of new algorithms and software toolkit, this work will have a direct and immediate impact on a number of communities. At the collaborating institutions, this project will have an educational impact by involving undergraduate and graduate students. This situation also presents excellent opportunities for interaction with postdoctoral researchers as well as with colleagues in academic, government and industry research labs. The CorePac software toolkit will be the basis for subsequent development of production quality software for energy-performance tradeoffs. Developing means to manage energy consumption in computers is imperative from both environmental and economical perspectives.","title":"MCDA: Collaborative Research: A Multi-Element and Multi-Objective Optimization Approach for Allocating tasks to Multi-Core Processors","awardID":"0903456","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7786","name":"MCDA"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":["559680"],"PO":["559883"]},"150462":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The objective of this research is to develop a measurement-driven real-time wear-out model for the time-cumulative effects of electrothermal stress on the remaining life of multi-core systems. The approach is to develop highly efficient built-in sensors for accurate temperature, thermal gradient and current measurements and to use real-time measured data to build time-dependent conditional probability density models for electrothermal stress induced circuit failures and time-history dependent system reliability. <br\/><br\/>The intellectual merits include new methods for designing accurate on-chip temperature and current sensors with significant reductions in area and improvements in power efficiency and new methods for real-time thermal gradient surface temperature profiling. Merits also include introducing the concept of time-temperature stress history based conditional probability assessment for developing optimal power\/thermal management schemes. <br\/><br\/>Broader impact includes benefits consumers derive through lifetime and reliability improvements in a broad range of elevated temperature limited electronic systems. Significant participation in this project by female and\/or minority students will be maintained throughout this initiative. Research results on sensor design, reliability enhancement and statistical lifetime modeling will be integrated into existing and new courses that will be made available to both on-campus and remote access students. Timely dissemination of research results and technology transfer will be through conference and journal publications, WEB page postings, student industrial internships, and close collaboration with researchers at leading semiconductor companies both in the US and abroad.","title":"Lifetime Electrothermal Stress Management for Multi-core Systems","awardID":"0903530","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":[401071,"478440"],"PO":["565185"]},"153620":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Each node in a wireless ad hoc network can choose the power at which it makes its transmissions and thus control the topology of the network. Though well-studied in the research literature, the problem of topology control has been largely considered only in idealized wireless environments and in isolation as a graph-theoretic abstraction. This project focuses on the design of topology control algorithms for reduced energy consumption, reduced interference and higher capacity in real wireless environments in the presence of multipath fading, link failures, high error rates and many other radio irregularities. The methodology follows two key philosophical goals: (i) an environment-independent approach which makes no constraining assumptions about the wireless environment (as opposed to trying to achieve approximations of reality in the assumptions), and (ii) an integrated approach which does not merely abstract out the problem of topology control separated from routing and link scheduling but embraces these into the design at the outset. This research also explores the fundamental limits of environment-independent topology control. <br\/><br\/>An immediate impact of this project is new algorithmic strategies that speeds up the actual deployment of energy-efficient high-performance wireless ad hoc networks with benefits to many known applications. A yet broader impact is new generalized distributed algorithms that can be employed in contexts beyond wireless ad hoc networks a variety of educational activities including course enhancements and participation in NSF RET programs for high-school teachers.","title":"NeTS:Small:Collaborative Research: An Integrated Environment-Independent Approach to Topology Control in Wireless Ad Hoc Networks","awardID":"0915331","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["251870"],"PO":["557315"]},"163663":{"abstract":"Research has shown that Heterogeneous Sensor Networks (HSNs) can significantly improve the performance of sensor networks. To achieve better performance, we adopt an HSN model consisting of a small number of powerful high-end sensors (H-sensors) and a large number of low-end sensors (L-sensors). The objective of this project is to investigate innovative network architectures of HSNs, and develop energy-efficient, self-healing schemes and routing protocols for HSNs. We plan to build an integrated research and education program. The research components of the project consist of the following two parts: <br\/>. Investigating efficient and robust network architectures of HSNs.<br\/>We will investigate innovative network architectures for two different types of HSNs: HSNs where the locations of H-sensors are controllable and NOT controllable. We will determine the optimal density of H-sensors and L-sensors, and the optimal locations of H-sensors to minimize the cost of sensor nodes while ensuring a network lifetime and coverage requirement. We propose a novel Density-Varying-Deployment scheme for H-sensors. We will also design robust clustering schemes that can tolerate H-sensor failures and provide reliable network structures.<br\/>. Designing self-healing and energy-efficient schemes and routing protocols for HSNs.<br\/>The primary functionality of wireless sensor networks is to sense the environment and transmit the acquired information to a base station for further processing. Thus, routing is an essential operation in sensor networks. Typical sensor nodes are small, unreliable devices with limited energy supply. The routing protocols should be energy-efficient and robust to sensor failures, and be able to find new paths when nodes fail. By utilizing powerful H-sensors, we will design self-healing, energy-efficient routing protocols for HSNs which take into consideration of data fusion. <br\/>The research is tightly coupled with an educational program that includes the following four themes, <br\/>1) Mentoring graduate and undergraduate students, and recruiting students of underrepresented groups in North Dakota and Tennessee to participate in the project. <br\/>2) Developing a new graduate course-Wireless Sensor Networks. <br\/>3) Field study of sensor networks. Sensor networks have been deployed in several farms in North Dakota for agricultural monitoring and several chemical\/nuclear plants in Tennessee for hazard monitoring. We will take students to the farms and plants to study how to improve the performance of these real sensor networks by applying our research results. <br\/>4) Integrating research and education together by setting up a Heterogeneous Sensor Network Lab. <br\/>The Intellectual Merits include:<br\/>1) In this research, we will develop innovative network architectures for two different kinds of HSNs, i.e., the locations of H-sensors are controllable or not. <br\/>2) We will design energy-efficient and self-healing routing protocols for HSNs, which are robust to node failures and prolong network lifetime. <br\/>The Broader Impacts are:<br\/>Recruiting students of underrepresented groups, including female, low incoming, first generation, Native American, and African American students in North Dakota","title":"NeTS NOSS: Collaborative Research: Towards Robust and Self-Healing Heterogeneous Wireless Sensor Networks","awardID":"0963578","effectiveDate":"2009-08-17","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["563625"],"PO":["565303"]},"150364":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009(Public Law 111-5).\"<br\/><br\/>Project ID: 0903191<br\/>PI names: Sandip Kundu and Israel Koren<br\/>Title: A Design Framework for Improving Reliability, Debug and Security of Multi-Core Systems<br\/>Inst: University of Massachusetts, Amherst<br\/><br\/>ABSTRACT:<br\/>Today?s computer chips feature multiple cores in the same substrate where all cores may perform concurrent tasks, improving overall performance. However, multi-core systems exacerbate some problems such as power dissipation, system and software debugging, security and long term system reliability. Power consumption in computer systems is a major concern. For example, Google server plants, reportedly consume about 103 megawatts of electricity ? enough to power a city of the size of Tacoma, Washington.<br\/><br\/>Debugging multi-core hardware\/software in a multitasking, multithreading, multi-core environment is very complex as an individual core may crash and communication may deadlock. Computer reliability and security are increasing concerns, as society becomes ever more dependent on the availability of computer systems and on the security of the data that they process and store. Continuous monitoring of the health of the computer system to allow fast recovery from faults, and protecting critical and private data from tampering attempts are thus necessary.<br\/><br\/>The project envisions designing a simple dedicated supervisory core integrated into chip multi-processors that is always alive. This core supports execution of commands for rebooting individual cores and allows query of internal states of any core on the same substrate. Such a core adds little to system cost but adds a number of run time capabilities that allow us to solve the above problems and also allow improved remote system management, which has emerged as a major challenge in computer data centers.<br\/><br\/>The broader impact of this project is two fold. At a technical level, it provides solutions to mitigate societal problems such as energy consumption, advancing computer security and improving computer up-time. At a curriculum level, it trains researchers in a discipline that is extremely important for US industrial competitiveness. This project is actively supported by major US industries through technical collaboration.","title":"A Design Framework for Improving Reliability, Debug and Security of Multi-Core Systems","awardID":"0903191","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7786","name":"MCDA"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":["553614","509294"],"PO":["562984"]},"153642":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\"<br\/><br\/>The proliferation of multiple cores on the same die has given rise to communication-centric systems, wherein the design of the interconnection network has become extremely important. To address the growing wire delay problems and improve performance in CMP architectures, a growing number of multi-core designs have adopted a more flexible, scalable, packet-switched architecture called Network-on-Chip (NoC). Of the several challenges facing current NoC designs, the three prominent ones are power dissipation, die area, and overall performance. In this research, we propose to develop energy-efficient, area-efficient, high-performance, and fault-tolerant NoCs by exploiting innovative technological (circuit) optimizations and architectural design space. On the technology side, we will develop and design novel circuit techniques that will achieve significant power savings, fault-tolerance and considerable reduction in area requirements. On the architectural side, we will develop novel NoC designs that incorporate the proposed circuit design techniques and further improve network performance. This research is an organized effort that will combine circuit analysis, architecture study, performance evaluation and design synthesis. We will develop a comprehensive NoC design platform which will analyze the trade-offs among various parameters of interest ? power, area and performance.<br\/><br\/>The success of this research is likely to have a significant impact on the design of NoC architectures for CMPs. The proposed research will tackle some of the major limitations of NoC design, namely power consumption and reliability, and will make significant advances in understanding the interplay between performance, energy, and reliability for NoC architectures. Realistic solutions to these problems will provide the ability to continue the improvements in computational performance that the information technology sector of our economy depends on. This multi-disciplinary research will also play a major role in education by integrating discovery with teaching and training.","title":"SHF: Small: Collaborative Research: Design of Power and Area Efficient, Fault-tolerant Network-on-Chip Circuits and Architectures","awardID":"0915418","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["559859"],"PO":["366560"]},"153554":{"abstract":"This study of the function of deception in electronic communications is designed to develop new theories and tools that will significantly improve collaboration in virtual organizations of all types. Virtual organizations - aggregations of individuals, facilities and resources that span geographic and institutional boundaries - are having transformative effects on the ways in which people socialize and collaborate. They enable interaction between individuals with diverse perspectives who might not otherwise work together, the sharing of expensive and scarce resources, and novel ways of accomplishing tasks and solving problems. Despite the unique capabilities that virtual organizations provide to distributed groups, many have faced difficulties in working together at a distance. While virtual organizations provide basic communication tools (e.g., instant messaging or video conferencing), these tools lack support for the subtlety and nuance of initiating and exiting conversations. In particular, systems fail to support the narrative accounts that people use to explain their behavior and availability. <br\/><br\/>The result of this disconnect between social practice and technical implementation is a flood of unwanted interruptions and painstaking decisions about what personal information one is willing to share and with whom. This research addresses this fundamental problem by developing a narrative approach to interpersonal awareness, and by focusing on the role of deception in managing these narratives. Preliminary evidence suggests that one fifth of all lies told in instant messaging are used to initiate or conclude a conversation. These lies represent potentially valuable \"hotspots\" that signal trouble in one's interpersonal awareness narrative. Focusing on these hotspots, this work addresses 3 issues: 1) How do people use deception to manage their interactions and avoid unwanted interruption? 3) Are there linguistic and sensor-based attributes that indicate deception may be likely? 3) Can this knowledge be used to design and evaluate tools for managing interpersonal awareness narratives and enabling interaction in virtual organizations? <br\/><br\/>This work builds on substantial research in the area of interpersonal awareness and fostering informal interaction in geographically distributed groups. It makes several unique contributions through a focus on interpersonal awareness narratives: 1) systematically examining the conditions under which deception is used as a resource with existing awareness technologies, 2) conceptualizing deceptions as an indicator of a \"hot spot\" that can be drawn on in supporting interpersonal awareness, 3) identifying behavioral predictors of deception to design systems that reduce unwanted interruptions without blocking those that are useful or important. By managing attentional and awareness needs more fluidly, members of virtual organizations will be able to coordinate their activity and achieve their tasks more effectively, and the organizations as a whole will be better able to meet their business, educational, social or other goals.","title":"HCC-Small: Deception Hotspots as a Resource for Supporting Interpersonal Awareness Narratives","awardID":"0915081","effectiveDate":"2009-08-15","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["517608","561930","561930"],"PO":["564456"]},"153686":{"abstract":"In this project new discrete geometry processing algorithms based on simple and intuitive discretizations of low order differential forms will be developed, along with the supporting theoretical foundations, and it will be shown that the proposed approach unifies and extends a number of existing mesh relaxation algorithms used for denoising, subdivision, and interactive shape deformation. In the classical theory of surfaces, a surface patch is defined by a smooth 3D-valued parameterization function of two parameters, which in the language of differential forms is referred to as a 3D-valued differential 0-form. The two partial derivatives of one of these 0-forms are three dimensional vector fields which define a 3D-valued differential 1-form. A simple approach to surface deformations is to modify this 1-form by locally stretching and rotating its two component vector fields, and then solve for a parameterization function whose partial derivatives match the component vector fields of the modified 1-form. The discrete analog of this approach for deformations of graph embeddings and polygon meshes will be developed. The first fundamental form measures distances and angles on a smooth surface, and the second fundamental form measures how the surface normal varies, i.e., curvature. The two fundamental forms are invariant to rigid body transformations of the surface, and satisfy the Gauss-Codazzi-Mainardi (CDM) equations. Conversely, given two second order symmetric tensor fields satisfying together the CDM equations, the Fundamental Theorem of Surface Theory asserts that: 1) there exists a surface immersed in three-dimensional Euclidean space with these fields as its first and second fundamental forms; and 2) the surface is unique modulo rigid body transformations. The analog theorem for polygon meshes will be formulated and proven, including extensions to manifold meshes of arbitrary topology, meshes with border, and even non-manifold meshes. New contributions to the mesh compression literature will be made by exploiting the relationship between reconstruction algorithms and connectivity-preserving mesh compression schemes.","title":"AF: Small: Fundamental Geometry Processing","awardID":"0915661","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7929","name":"COMPUTATIONAL GEOMETRY"}}],"PIcoPI":[408988],"PO":["565157"]},"151024":{"abstract":"The goal of this project is to make dynamic exhibits in informal learning environments (ILEs), such as zoos, science centers, and aquaria, accessible and engaging for visitors with vision impairments by providing real-time audio interpretations. Our efforts will also enhance the exhibit experience for all visitors, regardless of visual ability. We focus on the aquarium domain, since virtually every exhibit is dynamic, and the aquatic nature of the facility provides unique and interesting challenges to bio-tracking. The principles and techniques we develop will be immediately applicable to zoos, museums, and other ILEs with dynamic exhibits, potentially leading to a dramatic increase in the educational and entertainment opportunities for people with vision impairments. The project will employ focus groups and innovative simulations to test prototype exhibits during the development stages. The tracking and auditory displays will then be evaluated through laboratory studies and field testing in exhibits in a large public aquarium.<br\/><br\/>The ability to design exhibits and interpretation materials that are accessible to visitors with vision impairments is a growing concern. In addition to persons with specific vision impairments, the underserved population includes their family members, as well as the millions of older adults who have some vision loss that impacts their ability to read signage, see artifacts, and follow the activity in a dynamic exhibit. The results of our project will also enhance the experience for those with full vision, but for whom mobility, height, or other problems make it hard to see traditional signage. Indeed, all visitors will benefit from an audio enhancement that allows them to learn about the exhibit, while keeping their visual attention on the exhibit itself.","title":"HCC: Medium: The Accessible Aquarium Project: Access to Dynamic Informal Learning Environments via Advanced Bio-Tracking and Adaptive Sonification","awardID":"0905516","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[402599,"436270","529975","409620","561054"],"PO":["565227"]},"153697":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Historical static spectrum assignment has led to a critical spectrum shortage. While new prominent wireless technologies starve for spectrum, large chunks of spectrum remain idle most of the time under their current owners. With proper economic incentives, spectrum redistribution based on an open market can eliminate the artificial shortage. This project develops S-TRADE, an auction-driven spectrum trading platform to implement the spectrum marketplace. S-TRADE differs significantly from conventional FCC-style spectrum auctions that target only a few large corporate players and take months or years to conclude. Instead, S-TRADE serves many small players and enables on-the-fly spectrum transactions. In essence, S-TRADE selectively buys idle spectrum pieces from providers and sells them to a large number of buyers matching their individual demands. By effectively multiplexing spectrum supply and demand in time and space, the proposed marketplace also significantly improve spectrum utilization. The design of S-TRADE focuses on achieving spectrum multiplexing\/reuse to improve spectrum utilization while guaranteeing economic robustness to encourage player participation and minimize market manipulation. This project focuses on tightly integrating novel algorithms of dynamic spectrum allocation with economic mechanism design. The research outcomes deepen our understanding of the way spectrum should be distributed and the role of economics in distributing it. By integrating economics mechanism design with wireless networking, this project forms an integral part of interdisciplinary training programs at both undergraduate and graduate levels.","title":"NeTS: Small: A Practical and Efficient Trading Platform for Dynamic Spectrum Distribution","awardID":"0915699","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["551126"],"PO":["557315"]},"151277":{"abstract":"This proposal will be awarded using funds made available by the American Recovery and Reinvestment Act of 2009 (Public Law 111-5), and meets the requirements established in Section 2 of the White House Memorandum entitled, Ensuring Responsible Spending of Recovery Act Funds, dated March 20, 2009. I also affirm, as the cognizant Program Officer, that the proposal does not support projects described in Section 1604 of Division A of the Recovery Act. <br\/><br\/><br\/> Enabling Transformational Science and Engineering through Integrated Collaborative Visualization and Data Analysis for the National User Community<br\/><br\/>Visualization is one of the most important and commonly used methods of analyzing and interpreting digital assets. For many types of computational research, it is the only viable means of extracting information and developing understanding from data. However, non-visual data analysis techniques, statistical analysis, data mining, data reduction, etc. also play integral roles in many areas of knowledge discovery. This award will, for the first time, provide a comprehensive suite of large-scale visualization and data analysis (VDA) services to the open science community. By leveraging existing tools and techniques, integrating state-of-the-art research products, and providing exceptional user support, we will deploy a national, general-purpose visualization and data analysis discovery environment. The deliverables include:<br\/>o a remote visualization resource of extreme capability (Longhorn):<br\/>o 256 nodes (2048 processor cores, 24 Tflops peak) with 512 GPUs, 12 terabytes of aggregate memory, 200 terabytes of local system storage<br\/>o tightly integrated with Ranger (the TeraGrid's inaugural Track2 system) to handle digital assets at the largest scale (and potentially future TACC HPC systems);<br\/> 1. a comprehensive collection of open source and commercial end-user VDA software tools;<br\/> 2. expert visualization support, including advanced interactive user support and training, from a team comprising many of the leading visualization researchers in the US; and<br\/> 3. a framework for rapidly integrating new visualization technologies from leading research teams (including our own) to increase user capabilities throughout the project.<br\/>aborative Visualization and Data Analysis for the National User Community","title":"Enabling Transformational Science and Engineering Through Integrated Collaborative Visualization and Data Analysis for the National User Community","awardID":"0906379","effectiveDate":"2009-08-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7476","name":"ETF"}}],"PIcoPI":[403201,"499748",403203,"548347"],"PO":["558595"]},"158911":{"abstract":"Existing data storage systems based on the hierarchical directory-tree organization do not meet the scalability and functionality requirements for exponentially growing datasets and increasingly complex metadata queries in large-scale Exabyte-level file systems with billions of files. This project focuses on a new decentralized semantic-aware metadata organization that exploits semantics of file metadata to improve system scalability, reduce query latency for complex data queries, and enhance file system functionality. <br\/><br\/>The research has four major components: 1) exploit metadata semantic-correlation to organize metadata in a scalable way, 2) exploit the semantic and scalable nature of the new metadata organization to significantly speed up complex queries and improve file system functionality, 3) fully leverage the semantic-awareness of the new metadata organization to optimize storage system designs, such as caching, prefetching, and data de-duplication, and 4) implement the new metadata organization, complex query functions, and system design optimizations in large-scale storage systems. This project has broader impact to data-intensive scientific and engineering applications, graduate and undergraduate education, and K-12 education through its contributions to storage system research and its integration with an existing NSF-REU site award and an NSF-ITEST award.","title":"Collaborative Research: HECURA: A New Semantic-Aware Metadata Organization for Improved File-System Performance and Functionality in High-End Computing","awardID":"0937988","effectiveDate":"2009-08-15","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7952","name":"HECURA"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["486060"],"PO":["565272"]},"153114":{"abstract":"This project addresses several basic research issues related to solid state device (SSD) based flash memory to lay out a foundation and technical basis for efficiently integrating SSDs into the storage hierarchy. The research will be done in a sequence of three steps. First, the PI will conduct intensive experiments and measurements on different types of state-of-the-art SSDs, from low-end to high-end devices aiming at providing insights into unexpected performance dynamics and uncertain behavior. Second, the investgation will collect and place dynamic information of applications, SSDs, and hard disks, including data access patterns and their localities, onto the map of operating systems, and consider their inherent features (both merits and limits) for systems design and implementation. A set of caching algorithms and storage management policies will be designed. Finally, implemention, testing, and evaluation of a hybrid storage prototype will be done by using the profiled and monitored information and developed algorithms.<br\/><br\/>The broader and transformative impact of the project can be significant: (1) It can provide critical guidance to system designers and data-intensive application users; (2) The research can provide technical solutions to narrow the speed gap between CPU operations and storage accesses;(3) The developed techniques and source code will be available online for other researchers; and (4) The research will facilitate undergraduate and graduate student traing to prepare future computer science talents in academia and industries.","title":"Basic Research for Developing SSD-based Caching and Hybrid Storage Systems","awardID":"0913150","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["551992"],"PO":["366560"]},"146602":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Cognitive radios and multi-antenna systems are two recent components that each offers a great potential for improving spectrum efficiency. The former enables opportunistic spectrum access (OSA), while the latter enables multiple-input, multiple-output (MIMO) capability. This project develops theoretical and practical frameworks for wireless mesh networks when they are both MIMO-enabled and OSA-capable. <br\/><br\/>The objective of this research is three-fold. First, it takes a bottom-up, cross-layer approach to understand, model, and characterize the optimal end-to-end network throughput while accounting for physical-layer limitations and link-layer contention constraints. Second, the project develops efficient networking algorithms by investigating new paradigms that shift away from traditional ones to suit these OSA-capable, MIMO-enabled networks. Third, this project implements the thus-developed techniques in a real, experimental wireless mesh network that is built from off-the-shelf commercial components. This demonstrates both the feasibility and the effectiveness of the developed concepts.<br\/><br\/>This project provides scientific solutions to the spectrum scarcity problem. The results are disseminated via publications, software releases, and seminars. It involves undergraduate students in research activities during their class and independent study projects; (ii) creates the opportunity for K-12 and minority students to work on real-life problems and excites them to pursue engineering careers, and enriches teaching and learning curricula by integration into new course development.","title":"CAREER: Optimization and Design of Next-Generation Cognitive Mesh Networks: From Theory to Practice","awardID":"0846044","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["508426"],"PO":["565303"]},"143346":{"abstract":"The University of New Mexico (UNM) will develop and deploy DataNetONE (Observation Network for Earth), a sustainable long-term data preservation and access network, with related search and discovery, data integration, and user services and analytic tools. The goal of the DataNetONE (Observation Network for Earth) project is to enable scientists, decision-makers, and citizens to understand the nature and pace of change on Earth and to address associated environmental, social, and technological challenges. The initial focus will be on multi-disciplinary observational data collected by biological and environmental scientists, national and international research networks, and environmental observatories. DataNetONE will be extended to serve a broader range of science domains both directly and through interoperability with other DataNet deployments. The project is under the direction of Dr. William Michener at the UNM. DataNetONE is designed to enable the long-term preservation of diverse and complex multi-scale, multi-discipline, and multi-national science data by providing open, persistent, robust, and secure access to well-described and easily discovered Earth observational data. Expected users include scientists, educators, librarians, resource managers, and the public. <br\/><br\/>The potential impact of long-term preservation and integrated access to diverse and complex multi-scale, multi-discipline, multinational science data is transformative in the speed with which researchers will be able to assemble and analyze data sets and in the types of problems they will be able to address. Scientific investigations that will be greatly facilitated by DataNetONE include understanding the relationships among human population density, atmospheric nitrogen and carbon dioxide, energy consumption and global temperatures; understanding and predicting the emergence and spread of diseases like avian flu; critical areas where local or regional changes may have strong effects on earth system interactions, feedbacks, or teleconnections; the impact of \"megapolitan-ization\" on ecological systems; and the interrelationships among coupled human and natural systems.","title":"DataNet Full Proposal: DataNetONE (Observation Network for Earth)","awardID":"0830944","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7726","name":"DATANET"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7785","name":"ITR - DATANET"}}],"PIcoPI":["553472","501071","498189","488657"],"PO":["565292"]},"154016":{"abstract":"NSF Proposal 0916919 <br\/><br\/>New approaches to the design and analysis of graphical models for linear codes and secret sharing schemes<br\/><br\/>Abstract<br\/><br\/>Error-correcting coding enables one to design reliable systems of transmission and storage of information and is used universally for sending packets over the web, in writing data on CD's and flash memory devices, and other similar means of modern communication. A very efficient method of encoding information for error protection is the so-called \"iterative decoding,\" which assumes that every binary digit of transmission is recovered based on its realiblity and the realibility of a few other, carefully selected bits of the encoded message. This method of error correction is analyzed based on the representation of the encoding as a graph in the plane in which recovery from errors proceeds by successive exchange of information between the nodes of the graph in an iterative procedure performed in a number of rounds. One of the main goals of this research is to reduce complexity (the number of rounds) needed for reliable recovery of the transmission from errors in the communication medium.<br\/><br\/>Graphical models of linear codes have so far been restricted to trellises, i.e., cycle-free graphs, and graphs with exactly one cycle (tail-biting trellises). This research studies complexity of realization of codes and iterative decoding algorithms on connected graphs with cycles, deriving complexity estimates from the tree-decomposition of graphs. One of the goals of this research is to find methods of constructing low-complexity realizations of codes for such well-known code families as Reed-Muller and Reed-Solomon codes, and explore the optimality gap of these representations. Methods of matroid theory used in the study of graphical models will also be explored in the analysis of access structures of secret sharing schemes and secure multi-party computation protocols.","title":"CIF: Small: New Approaches to the Design and Analysis of Graphical Models for Linear Codes and Secret Sharing Schemes","awardID":"0916919","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["518024"],"PO":["564924"]},"148945":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>This project is deploying two community wireless network test facilities that use real-time signal propagation emulation to implement the N-by-N interfering channels connecting the wireless devices. Since signal propagation is controlled in software, experiments are easy to control and are fully repeatable. This allows thorough testing and evaluation of research results, fair, side-by-side comparison of wireless solutions, and the emulation of very diverse wireless environments (e.g. residential, office, mesh, vehicular, etc.) on a single platform. The testbeds operate in the 2.4 GHz ISM band and support for the 5GHz band and for MIMO devices is being added. Endpoints consist of WiFi devices and USRP software radios by default, although other devices can be supported. A set of 'world models' that model specific wireless environments (mesh and vehicular) is being added. This makes the testbed easier to use, and simplifies sharing of experiments and comparing of results. To support and encourage such sharing, a repository for shared experiments is maintained. <br\/><br\/>The wireless emulator testbed allows researchers to run repeatable and fully controlled wireless networking experiments, which significantly improves the quality of the research evaluation. By sharing experiments, researchers are able to more thoroughly evaluate and compare their research on a realistic platform, which otherwise would not have been possible. The emulator also improves education in wireless networking by enabling exciting hands-on assignments and projects.","title":"CI-ADDO-EN: A Community Testbed for Controlled and Repeatable Wireless Experiments","awardID":"0855137","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[396979,"463128"],"PO":["557315"]},"148868":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Software Defined Radio (SDR) offers an ideal platform for research and development with wireless communications systems. While there have been numerous successful SDR efforts, none of these platforms have the capability to implement high data rate radio frequency ultrawideband (UWB) (multicarrier and impulse radio) and wireless optical (diffuse and line-of-sight) communications systems. Software Defined Radio, and more broadly ?Software Defined Communications? (SDC) (i.e., implementing software defined concepts using propagation media beyond radio) can be enhanced by multiple input multiple output (MIMO) signaling techniques. However, until now, the technology did not exist to demonstrate these systems in prototype hardware.<br\/><br\/>The SDC testbed leverages modular FPGA hardware to form a reconfigurable baseband processing system. In addition, modular transceivers are being constructed to implement UWB multicarrier, UWB impulse radio, line-of-sight optical, and diffuse optical modalities. <br\/><br\/>The educational components of this project fosters technical innovation and design among undergraduate students and encourages high school outreach. Undergraduate students at all levels benefit from projects developing or using the SDC Testbed. The developed testbed is being incorporated into demonstrations for high school students and teachers. <br\/><br\/>The main contribution of this project is the realization of a software defined testbed for rapidly prototyping high speed wireless networks. The impacts of such a system are vast, but most significantly, this system enables a large variety of different wireless architectures to be prototyped. A project website enables the dissemination of information about the testbed architecture and insights from these prototypes.","title":"II-NEW: MIMO Software Defined Communication Testbed for UWB Radio and Free Space Optics","awardID":"0854946","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["563559","429743","543563","543564","503250"],"PO":["557315"]},"148219":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>This CRI proposal is designed to enhance the community's computing research infrastructure in support of smart environments. The goal of this program is to equip physical smart environment testbeds, and disseminate the data and software tools that are collected using the testbeds to the computer science community. Specifically, we will create one long-term and four short-term smart environment smart environment testbeds. The testbeds will facilitate research and education projects in modeling and simulation, machine learning of resident behaviors, middleware design, health monitoring, energy conservation, and sensor network design. Performing data collection and research in the testbeds will also rely upon the design of a number of software tools. We will make all data, software tools, and related educational materials available online as part of our CASAS repository. The infrastructure represents a part of the CASAS smart environment project. The infrastructure will enable a number of research advances at Washington State University and will facilitate advances in smart environments research around the world. Disseminating the data will also enable world-wide collaboration in related areas of research.","title":"II-EN: Smart Environment Infrastructure for Resident and Environment Modeling","awardID":"0852172","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["547675"],"PO":["564456"]},"150430":{"abstract":"The objective of the proposed research is to design innovative algorithms and tools for energy-aware scheduling and mapping of tasks onto homogeneous and heterogeneous multi-core processor (HeMP) architectures. The plan is to develop a new theoretical and experimental framework, called multi-element and multi-objective (MEMO) optimization, that will simultaneously and flexibly optimize the goals of energy minimization and performance maximization, while taking into account constraints due to multiple architectural elements such as cores and caches of current and emerging multi-core processors. The researchers will develop CorePac, a toolkit that will provide a flexible and friendly environment to schedule task-parallel applications on HeMPs under various performance\/energy trade-offs. The usefulness of the algorithms and CorePac will be demonstrated on a diverse suite of scientific, multimedia, and bioinformatics applications.<br\/><br\/>Through its production of new algorithms and software toolkit, this work will have a direct and immediate impact on a number of communities. At the home institutions, this project will have an educational impact by involving undergraduate and graduate students. This situation also presents excellent opportunities for interaction with postdoctoral researchers as well as with colleagues in academic, government and industry research labs. The CorePac software toolkit will be the basis for subsequent development of production quality software for energy-performance tradeoffs. Developing means to manage energy consumption in computers is imperative from both environmental and economical perspectives. Reductions in energy consumption of multi-core processors will contribute to system-wide energy and cost savings.","title":"MCDA: Collaborative Research: A Multi-Element and Multi-Objective Optimization Approach for Allocating tasks to Multi-Core Processors","awardID":"0903439","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7786","name":"MCDA"}}],"PIcoPI":["558550"],"PO":["559883"]},"163751":{"abstract":"This project will develop advanced Information<br\/>Technology tools, mathematical models, and prototype infrastructure for disaster modeling and management. The project will bring comprehensive information and numerical prediction where it is needed, at the disaster command center, in real time. The system will incorporate large volume of information from data streams, e.g., as maps, sensor, surveyance, and weather data, and the mathematical model will run on remote supercomputers. The model will be controlled by dynamically available data, and the results visualized in distributed devices, like laptops and palmtops connected to the Internet by wireless ethernet and a broadband satellite link. Other sensors and airborne imagers will also be networked wirelessly. The core of the envisioned modeling system will be an existing computer model of wildland and weather around the area, adn these models will be rewritten from scratch using modern software engineering methodology as a data driven application, and enhanced by new mathematical modeling techniques together with advanced statistical techniques will be used to manage uncertainty. High-performance middleware will be used to connect omputational nodes, sensor nodes, surveyance nodes, and visualization nodes into a distributed information and modeling system. New network software technologies will make the communication between the nodes secure and provide quality of service guarantees. The system will be designed to tolerate interruptions of communication, increased latencies, and node disappearances.","title":"ITR\/NGS: Collaborative Research: DDDAS: Data Dynamic Simulation for Disaster Management","awardID":"0963973","effectiveDate":"2009-08-20","expirationDate":"2011-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["453727"],"PO":["564777"]},"153961":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>This project addresses the design and utilization of high-capacity data networks, with the goal of increasing throughput, network security, and reliability. These are issue of paramount importance in the current development of high-speed networks as a computation and communication infrastructure.<br\/><br\/>The research is using routing methods that employ multi-paths to enhance throughput and security. Techniques from optimization and approximation algorithms are being applied for designing efficient algorithms that optimize throughput with latency, jitter, reliability, and costs constraints. Multi-paths also allow protection against attackers attempting to either eavesdrop or disrupt communications. Efficient algorithms for the computation of the Nash and Stackelberg equilibria in the resulting two-player designer-attacker games are being designed to provide strategies (selection of routes) for the network administrator and insight for the design of a network of low set-up cost and high throughput.<br\/><br\/>This project contributes to more secure and better utilized high-speed networks, which find applications in collaborative computations for astronomy, bioinformatics, and high-energy physics. The results of the project will lead to the design of provably efficient algorithms for routings which achieve desired throughput and security, and for computing exact or approximate equilibria in designer-attacker games. Simulations will illustrate the benefits on both synthetic and real-life backbone networks. This will open the way for implementation of multi-path routing. The results will be published in technical conferences and journals. A significant part involves training of undergraduate and graduate students in computer networks.","title":"NeTS: Small: Secure and Efficient Multipath Based Network Utilization: A Game Theoretic and Optimization Approach","awardID":"0916743","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[409680,409681,"426849"],"PO":["564993"]},"150452":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009(Public Law 111-5).\"<br\/><br\/><br\/>CCF - 0903408 <br\/>Collaborative Research - MCDA: Formal Analysis of Multicore Communication APIs and Applications<br\/>Gopalakrishnan, Ganesh L. <br\/>University of Utah <br\/><br\/>CCF - 0903491 <br\/>Collaborative Research: Formal Analysis of Multicore Communication APIs and Applications<br\/>Mercer, Eric G. <br\/>Brigham Young Univ<br\/><br\/><br\/>ABSRTACT<br\/>This project contributes tools to engineer future information processing systems so that they operate reliably and efficiently. Given that many of these systems will be produced on single micro-chips, and given the increasing demands for rapid turn-around times of designs, manufacturers are standardizing on methods by which the central processing units in these chips may communicate. Such standards will eliminate duplication of labor and allow components originating from different manufacturers to be mixed and matched. Since such standards will govern the construction of millions of future systems, one has to apply rigorous engineering principles accompanied by mathematically sound analysis methods to ensure that the standards are not flawed. This is one of the important goals of this project. The other key goals are to ensure that the manufacturing of these systems proceeds as per the standard definition and that testing methods to check the correctness of manufacture will be in place in a timely manner. The complementary strengths of the principal investigators, one of whom is from the School of Computing, University of Utah, Salt Lake City, and the other from Brigham Young University in Provo Utah will help drive this project forward in unique ways. The first year of this project will investigate rigorous specification methods for this standard called MCAPI. The second year will involve the research design of a variety of analysis tools for programs written using MCAPI. The third year will involve pilot testing of our tools at the manufacturer sites of systems on chips.","title":"Collaborative Research: Formal Analysis of Multicore Communication APIs and Applications","awardID":"0903491","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7786","name":"MCDA"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":["542012"],"PO":["562984"]},"150694":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Over the past decade, new and exciting technologies have created opportunities for developing rich open-ended learning environments that combine a number of different learning paradigms and resources. Students can complete quests in game environments, engage in inquiry, interact with virtual agents, run science simulations, take quizzes, access the web, and more generally make choices about different learning activities. Our basic insight is that these choices can be extremely informative about student learning and diagnostic of what students can learn once they leave highly scripted curricula. We can use machine learning methods, such as hidden Markov Models and other sequence analysis algorithms to analyze student choices in relatively open learning environments and determine whether students are showing (sub) optimal behavior patterns. The environment can then adapt intelligently by encouraging (alternative) choices and better learning behaviors. Our primary hypothesis is that helping students develop the metacognitive abilities to make learning choices will have strong effects on their subsequent abilities to learn in the future in unstructured and unsupervised but resource-rich environments. Our goals for this project are to create: a) Choice adaptive intelligent learning environments and computational methodologies that help students develop strategies to enable them to learn on their own; b) Novel automated assessment tools for both teachers and students that link choice and learning behaviors to learning performance; and c) Research studies that will establish whether our interventions that combine choice with guidance is beneficial for both strong and weak learners in science domains.<br\/><br\/>The broader impacts of this work span multiple dimensions. First, it provides an encompassing computer science framework for bringing together a number of technology-rich, interactive environments that are proliferating for education into a common choice filled and adaptive architecture. Second, this choice-based framework provides a paradigm shift in that tracking and theorizing about choice is applied in the context of learning, which, in the past, has been dominated by characterizations of the knowledge construct. Characterizing learning by choice not only connects learning research to a larger body of social science research, it is also a fundamentally new way to characterize and guide learning that is closer to the goal of much instruction, namely intelligent future choice. Third, the computer environment should permit the collection and analysis of large log files by many researchers, and conceivably lead to a new database of common choice patterns and their effects on learning. We will create the framework that enables others to incorporate intelligence into their virtual worlds and help achieve these proposed outcomes.","title":"HCC: Medium: Collaborative Research: Formal Analysis of Choice-Adaptive Intelligent Learning Environments (FACILE) that support Future Learning","awardID":"0904324","effectiveDate":"2009-08-01","expirationDate":"2013-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["556816"],"PO":["564456"]},"153972":{"abstract":"Computational complexity theory classifies computational problems into various complexity classes based on the amount of resources needed to solve them. This classification is done by measuring various resources such as time, space, nonuniformity, nondeterminism, and randomness. A better understanding of the relationships among these various resources shed light on the computational difficulty of the problems that are encountered in practice.<br\/><br\/>This project explores several central questions regarding nonuniformity, complete problems, and space bounded computations. This project attempts to discover improved upper bounds for problems with high circuit complexity. Regarding complete sets, non-relativizing properties of complete sets will be explored. Space bounded computations will be investigated in the context of planar graph reachability problems.<br\/><br\/>This project addresses several basic questions in computational complexity theory. The results from this project will further our understanding of computational resources such as nonuniformity, nondeterminism, and space. Research results will be published in peer-reviewed journals and will be presented at national and international conferences, thus enabling broad dissemination of the the results to enhance scientific understanding. New courses will be created and taught along the themes of this project, thus integrating teaching and research. The project supports various human resource development activities such as supporting and mentoring graduate students and inviting visitors.","title":"AF:Small:Collaborative Research:Studies in nonuniformity, completeness, and reachability","awardID":"0916797","effectiveDate":"2009-08-15","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}}],"PIcoPI":[409713],"PO":["565157"]},"152641":{"abstract":"An active line of algorithmic research over the past decade has developed techniques for analyzing systems of self-interested agents. A crucial challenge in analyzing such systems is to predict aggregate properties at large scales; this requires drawing conclusions about global phenomena in systems whose behavior is currently only well-understood at the level of individual agents or pairs of agents. Deriving conclusions about macroscopic properties of systems described at a microscopic level is important in both computing and the social sciences. Market prices, for instance, arise from the microscopic interactions of individual traders. Understanding both the normal functioning of markets and their failure requires methods that can bridge the gap between these different scales of resolution.<br\/><br\/>This project uses ideas about networks and learning from algorithmic game theory to bridge the micro-macro gap. The research on networks considers theories of bargaining and trade in which participants are constrained by a network structure. This includes models for the distribution of power among agents in a network, as well as models in which prices in a market arise strategically through the interaction of market-making intermediaries in a network. The research develops models of market failures, particularly the kinds of cascading breakdowns of trust that played a crucial role in the global financial crisis in 2008. The project employs learning models to capture how perceived counterparty risk -- the ability of one's trading partner to complete a transaction --- spreads through a market.<br\/><br\/>The research on trust in financial markets can potentially contribute to broader policy debates about methods for restoring trust in markets. Currently there is a lack of analytical techniques that can tractably manipulate non-trivial learning dynamics to uncover the resulting network-level consequences, such as cascades. The research will provide tools for analyzing the determinants and evolution of trust in financial markets.<br\/><br\/>The project will also inform the development of introductory courses that cut across many disciplines, providing undergraduates from a wide range of backgrounds with a computationally grounded perspective for reasoning about the behavior and consequences of networks of interacting agents.","title":"AF: Large: Networks, Learning and Markets with Strategic Agents","awardID":"0910940","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7932","name":"COMPUT GAME THEORY & ECON"}}],"PIcoPI":["429234","429235","516907","450550",406684],"PO":["565251"]},"153863":{"abstract":"The project integrates graduate research activities in hybrid, accelerated computing applications with undergraduate computer and computational science curricula, preparing undergraduates for graduate school and industry professions with application development experience in technologies essential to emerging high-performance computing and peta-scale systems. Curriculum enhancements across multiple computer science and engineering courses are investigated using real research activities to identify specific improvements needed at the undergraduate level. The research focuses on the use of leading accelerator technologies (multi-core CPUs, GPUs, and FPGAs) in real scientific computing challenges and translating the insights, concepts, and examples for use in undergraduate computer science and engineering instruction. The significance of pairing research investigations with curricular development affords the opportunity to bring real experiences into the undergraduate classroom. Research level investigations will help to characterize the unique inter-dependency of computer architectures and high-performance applications. The resources, strategies and examples created in this project are available to undergraduate programs across the country that wish to provide instruction on the next generation hardware and software environments. The project also reaches several underrepresented populations through outreach efforts at local high schools, regional HBCUs, and leverages existing REU programs.","title":"SHF: Small: RUI: Collaborative Research:Accelerators to Applications - Supercharging the Undergraduate Computer Science Curriculum","awardID":"0916387","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["521243"],"PO":["565272"]},"153643":{"abstract":"The Internet is now the world's dominant information infrastructure. Numerous requests from Internet users and their applications compete for shared resources in multiple ways. It is therefore critical to efficiently allocate limited network resources in order to provide high quality services. Improving the performance of the Internet in this manner has the potential to have extremely broad impact. <br\/><br\/>Resource management becomes even more challenging when mobile devices connecting to the Internet are considered. Designing efficient algorithms is difficult mainly due to the following factors: (1) diverse and unpredictable resource requests; (2) physical limitations on Internet links, on buffer space in network switches, on capacity of wireless channels, and on battery power in mobile devices. <br\/><br\/>This project aims to provide solutions for several fundamental algorithmic problems in networked systems and applications. Robust and insightful online algorithms will be developed for network switches forwarding prioritized packets and energy management in mobile devices. The objective is to understand the mathematical structure of these problems, to design elegant and easy-to implement online algorithms, to provide rigorous analysis on their performance bounds, and to integrate these algorithms into the real systems to achieve better performance.","title":"AF: Small: Collaborative Research: Online Scheduling Algorithms for Networked Systems and Applications","awardID":"0915425","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":["562721"],"PO":["565251"]},"155711":{"abstract":"Proposal #: CNS 09-23050<br\/>PI(s): Jones, Jim; Jacher, Steven M.; Wang, Ke-Gang; Zhang, Ming <br\/>Institution: Florida Institute of Technology <br\/> Melbourne, FL 32901-6975<br\/>Title: MRI\/Acq.: Acq. of a Computational Science and Engineering Parallel Cluster<br\/>Project Proposed:<br\/>This project, acquiring a new computational science and engineering cluster, seeks to provide the faculty and students regular access to a modern, on-campus parallel computer for their research. Servicing Mechanical and Aerospace Engineering, Physics and Space Science, Marine and Environmental Engineering, Oceanography, and Mathematical Sciences, the project aims to continue conducting research involving parallel computing in a wide variety of disciplines. Due to its age, an existing Beowulf Cluster acquired in 2001 has proved insufficient to conduct the current research and more powerful computing resources are sought. The proposed instrument consists of a 48 node cluster where each node has 2 quad-core 2 GHz CPUs. The computing power of this machine will enable the large-scale simulations needed in the application areas of ocean modeling, space weather, and material science. In these areas researchers have simulation codes, but need increased computing power to do the required runs. The new machine is expected to allow greater fidelity simulation on important application, such as the impact of space radiations on astronauts and electronic components on satellites. Other applications need the increased computing power and are beginning to parallelize their codes.<br\/><br\/>Broader Impacts: This project contributes to increase on-campus access for students to develop their parallel programming skills. Building on past experience, careers in high performance and parallel computing will be encouraged. The students will be trained more in depth in the area and Parallel Computing will continue to be part of research at the institution.","title":"MRI: Acquisition of a Computational Science and Engineering Parallel Cluster","awardID":"0923050","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["529194",414805,414806,414807],"PO":["557609"]},"153676":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>This research develops novel techniques for applying the heterogeneous execution model, where a general-purpose processor is accelerated by a special-purpose co-processor, to optimization-based scientific computations. The result of this research is a library of computational building blocks that perform fundamental operations used in genome analysis, as well as a new design tool that uses this library to systematically synthesize complete co-processor architectures that are optimized for the characteristics of the input dataset of interest.<br\/><br\/>Traditional development methodologies for heterogeneous computing have focused on computations that are based on data-parallelized O(n) algorithms. This project demonstrates the use of heterogeneous computing for non-O(n) algorithms, which have complex behavior, internal state, temporal locality, and a high ratio of computation versus communication. Adapting this class of computation to heterogeneous platforms provides high-performance computing without the need for maintenance-intensive and power-inefficient traditional shared-memory and cluster-based supercomputers.<br\/><br\/>This project targets optimization-based phylogeny reconstruction as a application case study. This application uses combinatorial optimization for its search for optimal phylogenetic (evolutionary) trees, as well as for its procedure for scoring candidate trees.","title":"SHF: Small: Co-Processors for High-Performance Genome Analysis","awardID":"0915608","effectiveDate":"2009-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}}],"PIcoPI":[408962],"PO":["565272"]},"154105":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Much of the Internet's growth occurs in domains beyond the reach of current measurement techniques and platforms, such as behind NAT boxes and firewalls or in regions of the Internet not exposed by public BGP feeds. This work is motivated by the observation that, collectively, peers in large-scale P2P systems have a unique and valuable perspective on network conditions, one to which today's researchers, operators and users have limited or no access. P2P systems are an ideal vehicle for accessing these views, being among the largest services and covering most of the Internet. As passive monitors of the Internet, different P2P systems can provide different, complementary views of the network, over partially overlapping space and time domains. The goal of this effort is to explore the potential for reusing such valuable view, investigating techniques for gathering, sharing, and exploiting it. The work focuses on: identifying useful metrics regarding network conditions collected by these peers and evaluating their potential for reuse (over time and across multiple systems' perspectives), designing approaches for maintaining this information and making it accessible to other large-scale distributed systems in a decentralized manner while preserving the privacy of the participating peers, and exploring potential applications that could benefit from this information.<br\/><br\/>Access to end-host views of the network will help in the understanding and characterization of the underlying network and address the needs of new emergent Internet services and applications.","title":"NeTS: Small: Parallax -- Leveraging the Perspective of Ten Million Peers","awardID":"0917233","effectiveDate":"2009-08-01","expirationDate":"2012-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["518224","477110"],"PO":["564993"]},"149914":{"abstract":"GOALI: NANOTHERMITE BASED MICRO SHOCKWAVE GENERATORS AND<br\/>NANOPARTICLES FOR TARGETED AND EFFICIENT DRUG DELIVERY<br\/><br\/><br\/>The objective of this research is to develop a novel digitally controlled micro shockwave<br\/>generator by integrating nanothermites with microelectromechanical systems (MEMS). The<br\/>approach is based on shockwaves from redox reactions of nanothermites. The shockwaves are<br\/>used to deliver genes and\/or drugs into cells with high transfection efficiency and cell survival.<br\/>Furthermore, organosilicate nanoparticles synthesized on site will be utilized as an effective and<br\/>targeted delivery vehicle via the shockwave.<br\/>Intellectual Merit. The proposed miniaturized systems will cover the large impulse range<br\/>necessary for permeabilization of a variety of cells and tissues with different mechanical<br\/>properties and\/or environments. Unlike physical gene delivery methods which rely on bulky and<br\/>expensive instrumentation or chemical delivery methods that exhibit low transfection efficiency,<br\/>the proposed MEMS-based shockwave generator -- alone or in combination with nanoparticles -<br\/>- will produce shockwave interactions and drug delivery at the single cell level, providing<br\/>unprecedented control over cell transfection processes.<br\/>Broader Impacts. The proposed research is expected to transform the study and understanding<br\/>of biological processes in health and disease, and enable novel diagnostics and interventions.<br\/>Educational objectives include recruitment of students from regional college programs, including<br\/>those with predominantly Black and Hispanic enrollment and a summer ?Nano Camp? for high<br\/>school students. Undergraduate and graduate students, particularly from rural areas of Missouri<br\/>will be trained to develop leadership, ownership, mentoring, career skills and entrepreneurship to<br\/>prepare them for the 21st century work force.","title":"GOALI: Nanothermite Based Micro Shockwave Generators and Nanoparticles for Targeted and Efficient Gene\/Drug Delivery","awardID":"0901566","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"J265","name":"Defense Intelligence Agency"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"1504","name":"GRANT OPP FOR ACAD LIA W\/INDUS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":[399556,"478368","523669"],"PO":["564454"]},"148946":{"abstract":"Event-driven software (EDS) spans multiple domains, from industrial embedded devices and robotic controllers to web interfaces. Researchers experimenting with new software testing techniques for EDS do not have benchmarks that they can use to compare their techniques. This project investigates the requirements for a community infrastructure of event-based testing researchers to provide uniformity in experimentation. It uses the results of the requirements analysis to develop a preliminary prototype called COMET: COMmunity-Event-based Testing. COMET will consist of a core set of requirements for EDS testing that provides a repository of both logical and concrete test artifacts. This includes processes and models to standardize the way experiments are conducted as well as on- line web services for common computational components. Techniques developed in this project will have a broad impact: COMET has the potential to bring EDS testing techniques to a broader community and will promote greater transferability of ideas. Artifacts for EDS testing will be available to other disciplines such as computer human interaction researchers who are interested in EDS usability.","title":"II-NEW: Collaborative Research: COMET-COMmunity Event-based Testing","awardID":"0855139","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["511534"],"PO":["564388"]},"148968":{"abstract":"Experimental investigations are important in the development of wireless network protocols. While the widely used simulation approach for experimental investigations is good for studying large-scale network-level performance, simulators cannot represent the real physical environment and hardware implementation precisely. On the other hand, the testbed approach can address the realism drawback of the simulation approach, but faces serious repeatability and control issues. A recent trend on evaluating wireless network protocols is to use wireless emulators. Emulators can achieve both a high degree of realism and fine-grained repeatability. <br\/><br\/>This project develops a versatile hardware-based emulator supporting controllable, repeatable, and scalable experiments over a wide range of ISM-band wireless networks (2-6GHz), including IEEE 802.11 a\/b\/g\/n, IEEE 802.15.4, and Bluetooth networks. The hardware emulator is a particularly convenient research tool for investigating the unique interference issue in ISM bands by providing a controllable interference environment. It enables experimental investigations in a number of research projects, including wireless network protocol development, interference mitigation techniques, and resource management. <br\/><br\/>This project impacts the implementation, evaluation, and development of next-generation wireless networks. The designed emulator from this project has general applicability to many commercial and civilian applications. The emulator also provides a natural tool for instructional use, assisting effective classroom teaching and inductive learning.","title":"II-NEW: Versatile Hardware Emulator for ISM-band Network Management","awardID":"0855200","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["407583","560198"],"PO":["557315"]},"159737":{"abstract":"This is a sociological study of the ways in which people voluntarily develop \"virtual civility\" and trustworthy identities in 3-dimensional virtual communities such as Second Life. This exploratory project will develop a comparative ethnographical study of several carefully chosen virtual sites in which what might be called \"spirituality\" or \"self-help\" plays an important role. These virtual sites are intriguing because when people share their inner experiences - which are usually considered highly private - this would normally indicate a deep trust of others. But in 3D virtual worlds, avatar-actors' real identities are often hidden. The project is intended to clarify how these virtual sites manage to create virtual civility and trust among geographically-distanced \"strangers,\" and what specific cultural mechanisms prompt and enable these avatars to develop trustworthy identities. <br\/><br\/>Studies to date of virtual worlds tend to be dominated by approaches that emphasize technological and regulatory aspects of ensuring trustworthiness. In contrast, this research is sociological because it locates the civility and trust that emerge within the interactional context of collaborative knowledge projects in particular cultural settings. For example, the ways that communities accomplish the actual building of a virtual culture of civility might in part depend on shared images of transcendence associated with 'spiritual approaches.' This observation is entirely in line with the classical but still-influential theories of sociologists like Max Weber and Emile Durkheim, yet its implications have not yet been explored in virtual, online environments. The project will study relational processes in which the development of such site-specific cultures and the emergence of individual avatars' civilized behavior, as well as the developments of their trustworthy identities, are intimately connected. <br\/><br\/>This project will contribute to the knowledge required to make virtual worlds with user-created contents positive grounds for socially meaningful collaborative knowledge productions. The study's potential import may go beyond virtual community dynamics, because it is possible that the new social forms shaped by the unique characteristics of virtual worlds may then in turn migrate back out into real life, becoming the new standard forms of trust and civility in human interactions generally.","title":"Virtual Civility, Trust, and Avatars: Ethnology in Second Life","awardID":"0942997","effectiveDate":"2009-08-01","expirationDate":"2011-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["497001"],"PO":["564456"]},"148858":{"abstract":"The primary objective of the project is to develop and deploy a repository that supports the sharing and transition of model-driven development (MDD) experience and knowledge to a broad community of researchers, practitioners, and educators. MDD research focuses on developing techniques and technologies that enable generation of dependable software from abstract models. The Repository for Model Driven Development (ReMoDD) will contain documented MDD case studies, models illustrating good and poor modeling practices, and educational material. The ReMoDD platform will provide interfaces and interchange mechanisms that users and tools can use to retrieve and submit artifacts. MDD researchers can use ReMoDD artifacts to evaluate research results, and to perform comparative and empirical MDD studies. Practitioners and students can use the resource to gain better understanding of MDD practices and techniques, while educators can use ReMoDD to share teaching experience and materials. The development of ReMoDD is a collaborative effort involving teams from Colorado State University (CSU) and Michigan State University (MSU). The teams will interact with the MDD community to collect and evaluate candidate ReMoDD artifacts. An Advisory Board of leading MDD researchers and practitioners has been established to ensure that ReMoDD becomes a useful and sustainable community resource.","title":"Collaborative Research: CI-ADDO-NEW: Research Repository for Model-Driven Software Development (REMODD)","awardID":"0854931","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["543568"],"PO":["564388"]},"148979":{"abstract":"This project is significantly enhancing available software infrastructure, the graphical models toolkit (GMTK), for graphical-model based time series modeling. While GMTK is currently widely used for speech recognition, the extensions being performed, however, are optimized not just for speech recognition but for all time-series applications. New infrastructure is also being developed that significantly enhances GMTK?s abilities, speed, documentation, source code availability, and pedagogical structure. This work will give to both the student and the researcher an enormous number of dynamic graphical model facilities. With its new features, GMTK will be able to perform computationally difficult time-series processing on extremely large and diverse data sets.","title":"CI-ADDO-EN: Software Infrastructure for Temporal Modeling","awardID":"0855230","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["508528",397091],"PO":["562760"]},"160793":{"abstract":"Abstract:<br\/><br\/>The Travel Grant Request:<br\/>Research Partnership with Romanian Universities<br\/>Communications and Training Simulations in Disaster Management & Mitigation written by Pamela McCauley Bush, Ph.D., C.P.E.; University of Central Florida; Orlando, FL (mcbush@mail.ucf.edu) is recommended for funding for the amount requested of $6,635; co funded by both ENG and CISE directorates.<br\/><br\/>The objective of this grant is to establish an international collaboration with two female engineering faculty members in Romania to further the research being conducted in by the Human Factors and Simulation in Disaster Management Research team at the University of Central Florida. The UCF HFDM Research is lead by Dr. Pamela McCauley Bush and the collaborative partners are Dr. Valentina Balas and Dr. Mihaela Albu. The long term goals of the collaboration are to further research in an international environment that has similarities to the current research environment in the state of Florida in order to validate results and extend activities. Additionally, the goals include faculty interaction for creating broader reaching outcomes, student exchange and international dissemination.<br\/><br\/>Specific Travel Requested:<br\/><br\/>Trip A:<br\/>a. Meet with Professor Valentina Balas for research discussions<br\/>b. Plenary Speaker at IEEE SOFA Conference: Topic Advances in Simulation<br\/>Technologies for Disaster Management<br\/>- The PI has been invited to provide a plenary speech on my research for the upcoming conference, IEEE International Workshop on Soft Computing Applications (SOFA)<br\/>- Location: Szeged - Hungary and Arad - Romania.<br\/>- Date: July 29 - August 1, 2009<br\/>Trip B:<br\/>a. Meet with Professor Mihaela Albu for research discussions<br\/>b. Participate in Research Committee Meeting in September 2009 in Cypress<br\/>- The PI has been nominated by Dr. Albu for participation on the European Cooperation on Science and Technology (COST) Committee on Intelligent Monitoring, Control and Security of Critical Infrastructure Systems. As a result of the UCF research on communications in disaster management, Dr. Albu has recommended the PI for participation on the Information and Communication Technologies (ICT) sub-committee.<br\/>- Location: Cyprus<br\/>- Date: September 2009<br\/><br\/><br\/><br\/><br\/>Omnia El-Hakim, Ph.D.-Program Director <br\/>For Diversity and Outreach<br\/>National Science Foundation<br\/>Directorate for Engineering<br\/>4201 Wilson Blvd., Suite 505N<br\/>Arlington, VA 22230<br\/> Tel: (703) 292- 2149<br\/>Fax: (703) 292- 9013<br\/>E-Mail: oelhakim@nsf.gov","title":"Romania Travel Grant","awardID":"0948297","effectiveDate":"2009-08-01","expirationDate":"2010-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0700","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"7680","name":"ENG DIVERSITY ACTIVITIES"}}],"PIcoPI":["533425"],"PO":["461803"]},"160683":{"abstract":"\"Crowdsourcing\" is the idea of using the \"wisdom of crowds\", that is, combining large numbers of judgments by non-experts, to produce reliable answers to complex problems. In the field of natural language processing(NLP), annotating sentences to show what events they express (and which parts of the sentence express which participants) is such a complex task. For example, the sentence \"Maria rides the bus from home to her office\" should be recognized as a Ride_vehicle event, with \"Maria\" as Mover, \"the bus\" as the Vehicle, \"from home\" as the Source and \"to her office\" as the Goal; NLP systems should also be able to recognize the same event with the same participants in the sentence \"Maria's bus ride from home to her office takes 40 minutes\", but most current systems cannot.<br\/><br\/>FrameNet (http:\/\/framenet.icsi.berkeley.edu) is building a lexical database of hundreds of event types (called \"semantic frames\") and examples of each in annotated sentences, which can be used to train NLP systems. But expert annotation of sentences is slow and expensive; this project is testing whether crowdsourcing can speed up the creation of such databases, specifically by exploring two crowdsourcing techniques to see which works better for these tasks: (1) online games, where players compete to see who can annotate rapidly and accurately (similar to the \"Verbosity\" game) and (2) a system in which people are paid small amounts of money to complete such tasks, using Amazon's \"Mechanical Turk\" (www.mturk.com). If successful, these techniques could be used to build better databases for new NLP systems that really understand \"who did what to whom\", thus improving question answering and web searching.","title":"EAGER: CISE\/IIS\/RI\/Program Element 7495: Crowdsourcing for NLP: Exploring Two Approaches","awardID":"0947841","effectiveDate":"2009-08-15","expirationDate":"2013-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["561714"],"PO":["565215"]},"160452":{"abstract":"Greenberg (0946385)<br\/><br\/>This Workshop is to define the future research directions for computer graphics and visualization. Over the past two decades, computing environments have radically changed in terms of processing power, parallelization, bandwidth, storage, and computer architectures. More recently, with the introduction of touch panel displays and the availability of large area screens, new user interfaces are now possible. Yet there does not appear to be any long-term research strategy which is compatible for future computing environments. According the workshop is bringing together computer graphics leaders and visionaries, as well as innovators from closely related fields, to define broader, more fundamental, longer term research areas. The workshop will establish an appropriate set of research challenges to help guide the National Science Foundation in their mission. A broad range of topics and unsolved problems will be identified, each with a set of specific goals.<br\/><br\/>The workshop is being organized by:<br\/><br\/>? Professor James Foley ? Stephen Fleming Chair in Telecommunications, Georgia Institute of Technology<br\/>? Professor Donald P. Greenberg ? Jacob Schurman Professor of Computer Graphics, Director, Program of Computer Graphics, Cornell University<br\/>? Professor Pat Hanrahan ? Canon USA Professor, Computer Graphics Laboratory, CSEE Dept., School of Engineering, Stanford University<br\/>? Professor Jessica Hodgins ? Computer Science and Robotics, Associate Director for the Faculty in the Robotics Institute Carnegie Mellon University, part-time Director of the new Disney Research, Pittsburgh Laboratory<br\/><br\/>During the two-day workshop, each participant will be assigned the responsibility of making a brief presentation during the first day. For each sub-area one participant will be selected and will have the responsibility for the documentation of the summary findings. At the conclusion of the workshop, the four primary investigators will edit and compile the results.","title":"Workshop Proposal to Define Future Research Areas in Computer Graphics","awardID":"0946385","effectiveDate":"2009-08-15","expirationDate":"2011-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[429027],"PO":["532791"]},"150420":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\"<br\/><br\/>CCF - 0903408 <br\/>Collaborative Research - MCDA: Formal Analysis of Multicore Communication APIs and Applications<br\/>Gopalakrishnan, Ganesh L. <br\/>University of Utah <br\/><br\/>CCF - 0903491 <br\/>Collaborative Research: Formal Analysis of Multicore Communication APIs and Applications<br\/>Mercer, Eric G. <br\/>Brigham Young Univ<br\/><br\/><br\/>ABSRTACT<br\/>This project contributes tools to engineer future information processing systems so that they operate reliably and efficiently. Given that many of these systems will be produced on single micro-chips, and given the increasing demands for rapid turn-around times of designs, manufacturers are standardizing on methods by which the central processing units in these chips may communicate. Such standards will eliminate duplication of labor and allow components originating from different manufacturers to be mixed and matched. Since such standards will govern the construction of millions of future systems, one has to apply rigorous engineering principles accompanied by mathematically sound analysis methods to ensure that the standards are not flawed. This is one of the important goals of this project. The other key goals are to ensure that the manufacturing of these systems proceeds as per the standard definition and that testing methods to check the correctness of manufacture will be in place in a timely manner. The complementary strengths of the principal investigators, one of whom is from the School of Computing, University of Utah, Salt Lake City, and the other from Brigham Young University in Provo Utah will help drive this project forward in unique ways. The first year of this project will investigate rigorous specification methods for this standard called MCAPI. The second year will involve the research design of a variety of analysis tools for programs written using MCAPI. The third year will involve pilot testing of our tools at the manufacturer sites of systems on chips.","title":"Collaborative Research: MCDA: Formal Analysis of Multicore Communication APIs and Applications","awardID":"0903408","effectiveDate":"2009-08-01","expirationDate":"2012-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7786","name":"MCDA"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":["561775"],"PO":["562984"]},"150794":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>This research proposes a new network architecture, SCAFFOLD, that directly supports the need of wide-area services. SCAFFOLD treats service-level objects (rather than hosts) as first-class citizens and explores a tighter coupling between object-based naming and routing. A clean-slate, scalable version of the federated SCAFFOLD architecture is being designed and prototyped. System components include programmable routers\/switches, resolution services for object-based lookup and forwarding, and integrated end-hosts.<br\/><br\/>The center of people's \"digital lives\" today are online services -- not the networks or computers on which they run. The research ultimately explores what abstractions and mechanisms that will make the future network a powerful, flexible hosting platform for wide-area services (the so-called ``cloud''). In doing so, SCAFFOLD would lower the barrier to deploying networked services that are scalable, reliable, secure, energy-efficient, and easy to manage. <br\/><br\/>The project includes a summer-camp outreach activity with schools serving under-represented groups to build services on top of SCAFFOLD, new special course development, and technology transfer with industry.","title":"NeTS: Medium: A SCAFFOLD for Service Centric Networking","awardID":"0904729","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["533300","531675"],"PO":["565090"]},"152620":{"abstract":"Despite heroic efforts in testing, static analysis, specification, and verification, all real-world software -- desktop applications, servers, and transportation systems---deploys with defects and missing functionality, costing the US economy billions and threatening our well-being. This project proposes a transformative paradigm shift to \"perpetually available software systems\" (PASS) that will make software more available and robust by directly addressing errors in deployed software. PASS innovations will (1) improve user experience by keeping real-world software running longer; (2) ensure good performance; (3) assist developers in fixing errors while allowing patches to be safely deployed on running software, to avoid downtime. The project will mine error reports in open source software repositories to derive error classes and test suites. It will evaluate system effectiveness by comparing with bug reports and patches in repositories. Innovations will include (1) detection and remediation elements that target common errors, (2) semantic foundations for remediation and on-line updating, and (3) integration of elements to exploit synergy among the components. The project will explore and analyze novel safe, probabilistically-safe, and extended-semantics remediations\/updates. The project will develop both C\/C++ and Java runtimes, because they are the most widely used languages and pose unique challenges. Methods will include combining dynamic, static, and remediation\/update analysis and results. The project will train graduate, undergraduate, and post doctoral students, and participate in outreach to under-represented groups. The tools will be made publicly available, adding to the national research infrastructure.","title":"SHF: Large:Collaborative Research: PASS: Perpetually Available Software Systems","awardID":"0910883","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["562740"],"PO":["564388"]},"150442":{"abstract":"The focus of this project is on designing robust multi-core systems at lowest cost that are resilient to hardware failures. It is motivated by an imminent paradigm shift in hardware design resulting from the growing problem of hardware failures in future process technologies. The central vision is to develop techniques and tools for designing hierarchical robust multi-core systems that are globally optimized across multiple abstraction layers ? circuit, architecture, runtime, and application ? without incurring the high cost of expensive redundancy techniques. An inter disciplinary approach will integrate research and education required to enable future robust systems. Because of its cross-cutting nature, the proposed research has the potential of having a major impact on future systems, enabling future technology scaling, thus making everyday lives better.","title":"Collaborative Research: Globally Optimized Robust Systems on Multi-Core Hardware","awardID":"0903459","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7786","name":"MCDA"}}],"PIcoPI":["559405"],"PO":["559883"]},"152510":{"abstract":"Computation has revolutionized the study of historic documents and is growing rapidly in terms of use and importance to interdisciplinary technology\/domain groups and individual scholars and researchers. An interdiscipinary team at the University of Illinois proposes to research and develop cyber tools for exploratory visual studies and quantitative analyses of large volumes of midieval manuscipts. The project will focus on visual imagery embedded in thes manuscripts and where the analysis tools will require large amounts of computational resources and scalable algorithms. The test collection will be digitized copies of Froissart's Chronicles, a set of midieval manuscripts available for reserch and teaching over the Worldwide Universities Network grid and accessible through Virtual Vellum ( developed at the University of Sheffield, UK, and funded by the UKs Arts and Humanities and Engineering and Physical Sciences experimental e-Science program.) The broader scientific impacts resulting from the proposed activities are expected to be in new methodologies, scalable algorithms. The work will also provide new exploratory frameworks that will support questions related to studying broad, difficult and complex topics such as the composition and structure (codicology) of manuscripts as cultural artifacts of the book trade in later medieval Paris and identifying the characteristic styles and iconographic signatures of particular artists. The research will contribute to a body of recent scholarship that seek to define how books were made, how they circulated, and what their cultural value was in the late medieval period.","title":"III: Small: Medieval Unicorn: Toward Enhanced Understanding of Virtual Manuscripts on the Grid in the Twenty-First Century","awardID":"0910562","effectiveDate":"2009-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["473994","528808","410514"],"PO":["563751"]},"153962":{"abstract":"The successive innovations in semiconductor manufacturing over the last 35 years of Moore's law have turned what used to be a room-sized computer system into a single chip composed of billions of transistors. These levels of integration have forced a change toward parallelism in computer system design, including both single-chip multiprocessors and systems-on-a-chip. Today, these chips have a few tens of individual processors but future scaling will make possible hundreds or thousands of them on a chip. Two important challenges have emerged which threaten to hinder performance scaling in multicore systems. First, while technology scaling will continue to enable increased transistor counts for the foreseeable future, power and thermal limitations will prevent all but a small fraction of them to be operating simultaneously at full speed. Second, the speed of the communication paths from the multicore chip to its external memory and to other processors is increasing at a slow rate. Because these communication paths must be shared by more and more on-chip processing cores, the paths must be used as efficiently as possible to prevent them from becoming a bottleneck in the system.<br\/><br\/>This project seeks to develop new computer hardware and software mechanisms that exploit data locality in high performance systems, including repeated use of a data item as well as use of multiple data items that lie near one another in memory. In particular, the project will develop hardware mechanisms for bulk data transfers that support renaming, packing, and integration into the virtual memory system. The PI will also develop hardware mechanisms in the on-chip memory system that will allow it to adapt to different programming primitives as well as to different coherence needs among the processing cores. The mechanisms will be evaluated in terms of effectiveness and programmability using a range of applications.<br\/><br\/>This research aims to develop technologies critical to emerging parallel multicore chips, without which such chips will not be able to meet performance and power goals. Enabling enhanced performance in a power-efficient manner is critical to all deployments of future computing platforms, including those for science, commerce, and national security. The broader impact of this research will include training graduate and undergraduate students as researchers, while also working to increase participation of underrepresented groups in computing. The primary outreach activity will include participation in a summer camp to attract high-school girls to computer science.","title":"SHF:Small: Locality-Driven Architectures for Scalable Multicore Systems","awardID":"0916745","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["424003"],"PO":["366560"]},"153973":{"abstract":"This award is funded under the American Recovery and Reinvestment Act<br\/>of 2009 (Public Law 111-5). <br\/><br\/>This project architects high-performance wireless local area networks (WLANs) by understanding the impact of physical layer attributes on performance and incorporating them in the design and control of next generation WLANs. The research is comprised of three parts. The first part develops models of spatial diversity, the dominant physical layer feature, that help understand and predict the performance of infrastructure mode WLANs. The second part integrates spatial diversity with cross-layer protocol analysis that allows evaluation of the influence of physical layer attributes on both lower- and higher-layer protocols. The third part investigates new network controls that harness opportunities provided by spatial diversity that help mitigate, and in some cases, transcend their detrimental performance effect including unfairness and throughput degradation. The control dimension extends to large-scale WLANs covering city blocks and campuses that inject complex spatial coupling. The project employs a combination of simulation, experimentation, and analysis to achieve its goals. The broader impact of this project lies in narrowing the performance gap between wireless and wired networks, which facilitates ubiquitous high-speed Internet access. The project also helps educate students in the fundamentals and intricacies of wireless communication. The results from the project will be disseminated at conferences, seminars, and through the project web site where data and tools are made publicly available.","title":"NeTS: Small: Toward High-Performance WLANs: Bridging the Physical Layer Divide","awardID":"0916802","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[409715],"PO":["565303"]},"153622":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Each node in a wireless ad hoc network can choose the power at which it makes its transmissions and thus control the topology of the network. Though well-studied in the research literature, the problem of topology control has been largely considered only in idealized wireless environments and in isolation as a graph-theoretic abstraction. This project focuses on the design of topology control algorithms for reduced energy consumption, reduced interference and higher capacity in real wireless environments in the presence of multipath fading, link failures, high error rates and many other radio irregularities. The methodology follows two key philosophical goals: (i) an environment-independent approach which makes no constraining assumptions about the wireless environment (as opposed to trying to achieve approximations of reality in the assumptions), and (ii) an integrated approach which does not merely abstract out the problem of topology control separated from routing and link scheduling but embraces these into the design at the outset. This research also explores the fundamental limits of environment-independent topology control. <br\/><br\/>An immediate impact of this project is new algorithmic strategies that speeds up the actual deployment of energy-efficient high-performance wireless ad hoc networks with benefits to many known applications. A yet broader impact is new generalized distributed algorithms that can be employed in contexts beyond wireless ad hoc networks a variety of educational activities including course enhancements and participation in NSF RET programs for high-school teachers.","title":"NeTS:Small:Collaborative Research: An Integrated Environment-Independent Approach to Topology Control in Wireless Ad Hoc Networks","awardID":"0915335","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["418075"],"PO":["557315"]},"153743":{"abstract":"ID: 0915912<br\/>Title: Virtual Probe: A Statistically Optimal Framework for Affordable Monitoring and Tuning of Large-Scale Digital Integrated Circuits<br\/>PI: Xin Li and Rob Rutenbar, Carnegie Mellon University<br\/><br\/>Abstract<br\/><br\/>On-chip variability monitoring and post-silicon tuning have emerged as a joint-strategy to combat the deleterious effects of nanoscale process variations, to maintain the aggressive scaling of integrated circuits (ICs). However, the design overhead (e.g., die area, power consumption, etc.) of these new techniques is a growing problem as devices continue to shrink, and the relative magnitude of critical process fluctuations continues to grow. This project proposes to develop a novel statistical framework called virtual probe (VP) to minimize the overhead of variability monitoring and post-silicon tuning. VP accurately predicts full-chip spatial variation from the smallest possible set of measurement data, thereby enabling lowest-cost \/ highest-accuracy silicon testing, characterization and tuning as IC technologies move further into the nanoscale regime.<br\/><br\/>The proposed project aims to create a radically improved platform for on-chip statistical monitoring and tuning of large-scale digital ICs; it is expected to yield 5-10 times performance improvement for advanced ICs in a broad range of applications, from consumer electronics to aerospace controllers. In addition, the proposed mathematical framework is applicable to many other scientific and engineering problems and, hence, offers a new avenue to study and understand these. Finally, given its broad coverage over multiple research areas, the proposed project motivates close collaboration among statistician, computer scientists and circuit designers, thereby creating enormous opportunities for interdisciplinary innovations. The interdisciplinary nature of this project also offers an excellent opportunity to train the next generation of U.S. researchers in multiple science and engineering domains.","title":"SHF: Small: Virtual Probe: A Statistically Optimal Framework for Affordable Monitoring and Tuning of Large-Scale Digital Integrated Circuits","awardID":"0915912","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["531467","542045"],"PO":["562984"]},"153864":{"abstract":"The project will seek efficient algorithms for extracting the structure of interaction networks: systems consisting of finite populations of elements in which the state of each element may change as a result of interactions with a small set of other elements according to specific rules of interaction. Such networks are ubiquitous in the physical and social sciences, and include standard models such as Boolean circuits, Bayesian networks, social networks, chemical systems, gene regulation networks, and epidemiological models of the spread of disease. The research carried out will apply methods of active learning based on recent progress by the principal investigators on determining the structure of certain kinds of Boolean, analog and probabilistic circuits and social networks using experiments.","title":"AF: Small: Algorithms for Active Learning of Interaction Networks","awardID":"0916389","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":[409428,409429],"PO":["565157"]},"153512":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Traditionally collisions of transmitted packets in wireless networks have been treated as a hindrance. If however the information contained in the packets is recovered even after the packets collide, significantly higher transmission rates can be attained in wireless systems. The project is developing a novel network-friendly approach for resolving collisions. <br\/><br\/>The relevant information is being extracted from collided packets through sophisticated signal processing and higher layer resource allocation schemes that function in conjunction with the physical layer techniques. The signal processing techniques recover the relevant information by exploiting source of diversity that are present in a collision, such as small user delays and carrier frequency offsets. The higher layer resource allocation techniques maximize the throughput and minimize the delay in end-to-end delivery of information through the exploitation of collision resolution capabilities at the physical layer. <br\/><br\/>This research will lead to a quantum leap in performance of wireless systems which will in turn facilitate a plethora of advanced applications such as high quality multimedia transmission over wireless networks, rescue and recovery operations, etc. Results will be disseminated through (i) publications of scholarly papers in premier journals and conferences and available through the world-wide-web, and (ii) direct interactions with wireless industry and non-profit organizations which will facilitate the design of wireless systems that can be effectively used in daily lives.","title":"CNS: NETS: SMALL: Collaborative research: Collision: Friend or Foe?","awardID":"0914955","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["517945"],"PO":["565303"]},"153996":{"abstract":"This project focuses on developing algorithms and datasets that can transform photometric reconstruction systems from hand-designed systems into learning-based systems that are optimized on real-world data. <br\/>Photometric reconstruction systems derive cues from the perceived intensity of different locations on a surface. Shape-from-shading, where the surface is assumed to have a diffuse reflectance, is a well-known example of photometric reconstruction. This project produces the datasets and methods necessary to use machine learning techniques to build models for photometric reconstruction.<br\/><br\/>This learning-based approach enables systems to be optimized on real-world data so that they produce the most accurate results possible. In addition, this learning-based approach enables the development of more sophisticated methods with more parameters than typically used in hand-designed systems. The ability to find optimal parameters in an automated fashion can not only improve existing approaches, such as by incorporating image data more effectively, but can also enable the development of algorithms that push the boundaries of current systems. In particular, algorithms are developed for estimating the shape of objects without knowing the illumination or even trying to explicitly model it.<br\/><br\/>The power of the learning approach cannot be realized without data for training and testing. A major task in this work is the construction of a database of images and ground-truth 3D reconstructions of the objects in the images. The 3D models can be found using an example-based photometric stereo technique.","title":"RI: Small: Learning-Based Systems for Single-Image Photometric Reconstruction","awardID":"0916868","effectiveDate":"2009-08-15","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"I331","name":"Defense Intelligence Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["515762","515762","515763"],"PO":["564316"]},"152665":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The burgeoning revolution in high-end computer architecture has far reaching implications for the software infrastructure of tools for performance measurement, modeling, and optimization, which has been indispensable to improved productivity in computational science over the past decade. The heart of the problem is that new multicore processors are the foundation of next generation systems, ranging from workgroup clusters to petascale supercomputers. The main motivation by chip manufacturers for the movement to multicore processors is better performance per watt than the traditional single core processor. Hence, multicore processors are not equivalent to multiple CPUs that traditional tools addressed. While significant work is underway on understanding performance tradeoffs with multicores, much of this work is ad hoc and needs a unifying framework to which the community can contribute in a systematic manner. Furthermore, little work has been done on understanding performance-power tradeoffs in supercomputer systems for large-scale applications. It is important to understand performance and performance-power tradeoffs in the context of the significant resource sharing that occurs in multicore systems.<br\/><br\/>This proposal is focused on developing the Multicore Application Modeling Infrastructure (MAMI) that will facilitate systematic measurement, modeling, and prediction of performance, power consumption and performance-power tradeoffs in multicore systems. In addition to developing MAMI, the proposed work will use MAMI to model, analyze and optimize performance and power consumption of key benchmarks and applications on multicore systems.","title":"CSR: Large: Collaborative Research: Multi-core Applications Modeling Infrastructure (MAMI)","awardID":"0911023","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["541641"],"PO":["565255"]},"168923":{"abstract":"Low-cost, portable lab-on-a-chip systems capable of rapid automated biochemical analysis can impact a wide variety of applications including biological research (genomics, proteomics, glycomics, drug discovery), genetic analysis (medical diagnostics, newborn screening, DNA fingerprinting), in vitro biomolecule production (e.g., heparin), and biochemical sensing (pathogen detection, air and water monitoring, chemical explosives detection). Since the simultaneous coordination of even tens of droplets on the array is extremely difficult to program manually, algorithms to automatically enable the flexible coordination of hundreds or even thousands of droplets are essential. This project will develop algorithms that will be the automation enabler of digital microfluidic system technology. The droplet coordination algorithms, integrated with digital microfluidic hardware, will provide unprecedented spatial and temporal control over biochemical reactions using nanoliter droplets. An interdisciplinary team of computer scientists, biochemists, and biomedical engineers will develop algorithms for the control of devices, and apply these devices. The proposed research will develop specialized routing and scheduling algorithms for the coordination of droplets on a microfluidic biochip. General principles for designing scalable grid layouts and droplet coordination algorithms that work across different hardware implementations will be developed. The algorithms will enable robust and user friendly operation of digital microfluidics systems, offering end users flexibility and the ability to exercise precise spatial and temporal control over reactions. The proposed research will involve undergraduate and graduate students in research, and will be integrated into graduate courses taught by the PIs. Outreach activities include after-school Lego robotics activities and summer robotics camps for middle school students in collaboration with RPI's Center for Initiatives in Pre-College Education.","title":"III-CXT: Enabling Automated Digital Microfluidic Biochips for Combinatorial Biosynthesis and Screening","awardID":"1019160","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["553786"],"PO":["565136"]},"153677":{"abstract":"This project extends the semantical foundations of object-oriented (OO) <br\/>languages to cover methodologies for modular reasoning. Modular reasoning <br\/>means verifying software components assuming the specification of each <br\/>used component. Modularity is important for productivity and scalability, <br\/>but is difficult to achieve for OO software. To support modular reasoning, <br\/>researchers have proposed several methodologies that restrict programs and <br\/>their specifications. The goal of this project is to provide a theoretical <br\/>basis that supports practical techniques for justifying and using <br\/>methodologies.<br\/><br\/>This project provides guidance for the designers of programming and <br\/>specification languages, verification logics, and associated tools. The <br\/>results will improve the utility and extensibility of verification tools <br\/>--- a key goal of the Verified Software grand challenge. Software <br\/>developers may benefit from the integration and harmonious interoperation <br\/>of best-practice methodologies. This project is potentially <br\/>transformative: it aims to enable combinations and customizations of <br\/>methodologies by tool users, scalable to real applications.<br\/><br\/>Improved OO programming methodologies may greatly improve programming <br\/>practice, especially in applications needing high assurance, reliability, <br\/>and security. This will benefit society, which increasingly depends on <br\/>computing systems built using OO components. Unification of methodologies <br\/>and streamlining of tools also facilitates the education of software <br\/>developers.","title":"SHF: Small: Collaborative Research: Specification Language Foundations for Modular Reasoning Methodologies","awardID":"0915611","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":["521696"],"PO":["565264"]},"153798":{"abstract":"The MyDome project will bring 3D virtual worlds for group interaction into planetaria and portable domes. Advances in computing have evolved the planetarium dome experience from a star field and pointer presentation to a high-resolution movie covering the entire hemispherical screen. The project will further transform the dome theater experience into an interactive immersive adventure. MyDome will develop scenarios in which the audience can explore along three lines of inquiry: (1) the past with archeological reconstructions, (2) the present in a living forest, and (3) the future in a space station or colony on Mars. These scenarios will push the limits of technology in rendering believable environments of differing complexity and will also provide research data on human-centered computing as it applies to inquiry and group interactions while exploring virtual environments.<br\/><br\/>The project proposes to engage a large portion of the population, with a special emphasis on the underserved and under-engaged but very tech-savvy teenage learner. Research questions addressed are: 1. What are the most engaging and educational environments to explore in full-dome? 2. What on-screen tools and presentation techniques will facilitate interactions? 3. What are the limitations for this experience using a single computer, single projector mirror projection system as found in the portable Discovery Dome? 4. Which audiences are best served by exploration of virtual hemispherical environments? 5. How large can the audience be and still be effective for the individual learner? What techniques can be used to provide more people with a level of control of the experience and does the group interaction enhance or diminish the engagement of different individuals? 6. What kind of engagement can be developed in producing scientific and climate awareness? Does experiencing past civilizations lead to more interest in other cultures? Does supported learning in the virtual forest lead to greater connection to and understanding of the real forest? Does the virtual model space experience excite students and citizens about space exploration or increase the understanding of the Earth's biosphere?<br\/><br\/>The broader impacts of the project are (1) benefits to society from increasing public awareness and understanding of human relationships with the environment in past civilizations, today?s forests and climate change, and potential future civilizations in space and on Mars; (2) increasing the appeal of informal science museums to the tech-savvy teenage audience, and (3) significant gains in awareness of young people in school courses and careers in science and engineering. The partners represent a geographically diverse audience and underserved populations that include rural (University of New Hampshire), minority students (Houston Museum of Natural Science) and economically-distressed neighborhoods (Carnegie Museum of Natural History). Robust evaluation will inform each program as it is produced and refined, and will provide the needed data on the potential for learning in the interactive dome environment and on the optimal audience size for each different type of inquiry.","title":"HCC: III: Small: MyDome - Defining the Computational and Cognitive Potential of Interactive Simulations in an Immersive Dome Environment","awardID":"0916098","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["495142",409270,409271],"PO":["564456"]},"151026":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\"<br\/><br\/>This project addresses fundamental and challenging questions that are common to robotic systems that build their own maps and solve monitoring tasks. In particular, the work contributes to our general understanding of the interplay between sensing, control, and computation as people attempt to design systems that minimize costs and maximize robustness.<br\/><br\/>Powerful new abstractions, planning algorithms, and control laws that accomplish basic mapping and monitoring operations are being developed in this effort. This is expected to lead to improved technologies in numerous settings where mapping and monotoring are basic components.<br\/>Ample motivation is provided by technological challenges that involve searching, tracking, and monitoring the behavior of people, wildlife, and robots. Examples include search-and-rescue, security sweeps, mapping abandoned mines, scientific study of endangered species, assisted living, ground-based military operations, and even analysis of shopping habits. <br\/><br\/>The work is particularly transformative because it lives outside of the traditional boundaries of algorithms, computational geometry, sensor networks, control theory, and robotics. Furthermore, national interest continues to grow in the direction of developing distributed robotic systems that combine sensing, actuation, and computation. By helping to break down traditional academic and scientific barriers, it is expected that the work will transform the way we think about robotics algorithms, the engineering design process, and the education of students across the robotics, computational geometry, and control disciplines.","title":"RI: Medium Collaborative Research: Minimalist Mapping and Monitoring","awardID":"0905523","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["553248"],"PO":["562760"]},"151268":{"abstract":"This proposal will be awarded using funds made available by the American Recovery and Reinvestment Act of 2009 (Public Law 111-5), and meets the requirements established in Section 2 of the White House Memorandum entitled, Ensuring Responsible Spending of Recovery Act Funds, dated March 20, 2009. I also affirm, as the cognizant Program Officer, that the proposal does not support projects described in Section 1604 of Division A of the Recovery Act.<br\/><br\/>In recent years, researchers from a growing range of scientific domains have<br\/>experienced a widening gap in their abilities to generate data on complex biological and physical systems and translate these data into scientific discovery. Our data analysis and visualization capabilities have failed to keep pace with advances in both the capacity of our computing infrastructure and the resolution and throughput of our data acquisition systems.<br\/>Translating raw data generated by detailed simulation or collected by advanced<br\/>instruments into scientific discovery requires a coherent suite of powerful hardware and software capabilities that is fully integrated into our national computational infrastructure. The volume of the data and the complexity of the underlying phenomena require an infrastructure that allows scientists to develop and operate flexible, and the same time dependable, end-to-end data analysis and visualization capabilities that span local and national resources. A 2007 report composed by data analysis, management,<br\/>and visualization experts concluded that datasets being produced by experiments and simulations are rapidly outstripping our ability to explore and understand them.<br\/>One of the most significant challenges to scientific discovery today is the extraction of knowledge and meaning from this vast array of data and the understanding of the correlations, trends, patterns, and interrelationships among disparate elements from an ever-growing array of data sources. Visualization, data analysis, and knowledge discovery are more vital than ever because they generate the data insight and intuition that enable scientific discovery. Scientific simulation has become the third pillar of<br\/>science, supporting frameworks and experimental studies in our understanding of<br\/>natural phenomena. As simulations become larger, more numerous, more complex, and as the scientific problems we seek to unlock become more challenging, so does the task of understanding the data generated.<br\/>This award presents a data visualization and analysis center, based at the University of Tennessee and coupled with the NSF TeraGrid Kraken supercomputer, that will narrow this gap by bringing together a unique team, proven software technologies, and advanced computing and data-handling capabilities. The center will provide the eyes of the TeraGrid XD, our national cyberinfrastructure, as it evolves to the XD era by<br\/>empowering scientists to see and understand very large collections of measured or simulated datasets.<br\/>The hardware that undergirds the center is a large shared memory SGI UltraViolet system, able to provide 1,024 processors with 4 TB of shared memory for processing large datasets. No other system in the world has this level of shared memory concurrency for analysis and visualization.<br\/>Supported by a large (1 PB) filesystem directly connected to the Kraken supercomputer and the TeraGrid network, this system will provide NSF researchers with an unparalleled data understanding resource.<br\/>The team of people comprising the center will draw upon experience in visualization,statistical analysis, workflow delivery, portal and dashboard development, remote access, and application development to provide software resources for large scale data understanding. This team will also be supported by dedicated user assistance, system support, education, and application discovery staff.","title":"NICS Remote Data Analysis and Visualization Center","awardID":"0906324","effectiveDate":"2009-08-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7476","name":"ETF"}}],"PIcoPI":[403178,"429678","540170","513541","495443"],"PO":["525727"]},"153699":{"abstract":"This proposal focuses on the development of motive and persuasive technologies (MPT) for personal health and health decision making. In particular persuasive technologies could help influence mothers to make better health choices. Motive technologies can improve community health worker job performance. MPT is a relatively new area and much foundational work remains to be done. This project draws on classical theories of persuasion from psychology, economics, rhetoric, and the recent literature on persuasive technologies to inform the approach. The nascent MPT literature has shown that many classical influence mechanisms ?work? via information and communication technology. But relatively little work has compared the relative power of these mechanisms, which is important for MPT to grow as a design science. And very little work has been done on persuasion in developing regions where MPT has great potential impact - the diffusion of innovation literature has shown that personal choice is the main challenge to development in many poor communities. The goal of this project is to compare the relative power of different persuasive mechanisms in the context of maternal and infant health care.<br\/><br\/>The results of this work will have profound impacts on underserved communities in the US. For example, recent work by the PI on language learning among immigrant farm workers in the US suggests that they face many of the challenges that the poor in developing regions face. There are estimated to be 13 million such workers in the US. Poor education, lack of trust and participation in the formal health system, conflicts with traditional practices, all reproduce the challenges seen in health care in developing regions. Maternal and infant health are among the most basic indicators of social development. They comprise two of the eight Millennium Development Goals defined by the United Nations. The research will shed light on the challenges in delivering maternal and infant health care to poor communities, and on finding practical means to overcome them. Success in the project would pave the way to widespread use of MPT in health care, and will inform its application to other areas such as agriculture, education, and sustainable development.","title":"HCC: Small: First Days: Improving Maternal and Infant Health with Persuasive Technology","awardID":"0915705","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[409023],"PO":["564456"]},"151048":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111- 5). <br\/><br\/>The fundamental differences between multi-hop networks and point-to-point settings indicate that leveraging MIMO gains in multi-hop networks requires a paradigm shift from high SNR regimes to interference-limited regimes. This project undertakes a broad research agenda centered around developing fundamental theory towards achieving optimal throughput and delay performance in wireless networks. The first key step is to take a bottom-up approach for solid model abstraction of MIMO links while taking into account interference, and to extract a set of feasible rate\/reliability requirements, corresponding to meaningful MIMO stream configurations. Under a common thread of MIMO-pipe scheduling, this project focuses on tackling the following challenges: 1) Developing rate\/reliability models for ``MIMO-pipes'' in multi-hop networks; 2) MIMO-pipe scheduling for throughput maximization and delay minimization; and 3) Real-time scheduling of MIMO-pipes with delay constraints (for time-critical traffic). <br\/><br\/>This project contributes to the formulation of new fundamental theories for multi-hop MIMO networks, which have direct impacts on many wireless applications. Particularly, real-time scheduling sheds much light on leveraging MIMO gains in VANET to deliver timely information reliably to save lives and improve quality of life. Underrepresented undergraduate students as well as graduate students participate in this project.","title":"NeTS: Medium: Collaborative Research: MIMO-Pipe Modeling, Scheduling and Delay Analysis in Multi-hop MIMO Networks","awardID":"0905603","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["517891","518327"],"PO":["557315"]},"158803":{"abstract":"The primary goal of this research is to explore new methodologies that support building reliability into the design of software product families. This enables a sufficient formal foundation to compare design alternatives early and throughout the software development. There are several notable challenges, among them the unsuitability of existing reliability modeling approaches for product families due to their inability to handle architectural change and leverage reuse effectively. The relationships and dependencies among products within the family further complicate the matter. The project will: 1) Extend existing (primarily) structural product line architecture modeling and analysis approaches with rich behavioral constructs, and corresponding analyses; 2) develop architecture-based approaches to reliability modeling of software product families; 3) research the interactions between different products reliabilities within a family of software products; 4) develop a decision support system that embodies these principles to compare alternative design choices based on their impact on the reliability of specific products, as well as the reliability of other products within the family. Evaluation of the methods will be performed in collaboration with NASA\/JPL to demonstrate broader impacts.","title":"Reliability Analysis for Software Product Line Architectures","awardID":"0937472","effectiveDate":"2009-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[424381],"PO":["564388"]},"143249":{"abstract":"A signal, when transfered over a long distance, is likely to be corrupted. Error-correcting codes have been designed to solve this problem, so modern communications are possible as we see today. Algebraic codes are mathematically interesting and intriguing, and they form the backbone of coding theory and its applications. The best algorithms for many algebraic codes are very powerful but not very practical. Also, the exact decoding complexity is not well understood for these codes, including the simple but extremely important Reed-Solomon codes. The project will strive to identify the complexity of decoding algebraic codes and to design more efficient algorithms for a large class of algebraic codes. <br\/><br\/>The main focus is on algebraic codes with natural parameters. The complexity results for these natural codes thus are more relevant to communication practice. It is expected that the project will lead to a number of substantial new results linking coding theory, computer sciences and mathematics. The project is also expected to develop graduate courses and train students in this cross-disciplinary research area.","title":"Complexity and Algorithms of Decoding Algebraic Codes","awardID":"0830581","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}}],"PIcoPI":["445138"],"PO":["565157"]},"150982":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Significant progress has been made on technical solutions for implementing security while preserving varying degrees of privacy for mobile electronic devices. A largely unsolved problem involves knowing what type of technical solutions to implement and under what circumstances. This challenge arises because in actuality there is in general no such thing as a clear \"optimal\" or \"right\" solution. One way to view this problem is by focusing on the fact that such devices potentially play an integral role in people's lives and impact important human values: security and privacy of course, but also other values such as autonomy, trust, and physical well-being. Further, these values are often in tension. This project will develop a principled and systematic conceptual framework for analyzing these value implications and tensions in the context of two archetypical examples of future mobile devices: implantable medical devices and mobile phone safety applications. A key component of our approach will be the application and extension of the Value Sensitive Design theory and methodology. Researchers will develop and evaluate new technology, as well as undertake empirical work with a range of stakeholders, including Futures Workshops and semi-structured interviews. Expected outcomes include a framework for analyzing the relationships and trade-offs among privacy, security, autonomy, and other values for mobile devices that accounts for both situational and embodied dimensions of these values; a pallet of key technical solutions to these problems; a set of case studies; and finally design recommendations for use by other researchers and practitioners.<br\/><br\/>Results of this work will not only develop technical mechanisms for providing the \"right\" level of security and privacy for new mobile technologies, but can help influence the definition of what \"right\" means in the context of the broader set of goals and values. In society more generally, there is an increasing use of technologies that are focused upon here: implantable medical devices and highly capable cell phones used for personal safety. Improving human health and personal safety, while not significantly undermining other key values such as privacy, trust, and autonomy, will be important in the development of such technologies. It is anticipated that the ways of analyzing such problems will be applicable to other technologies as well, such as RFID tags on personal possessions, Smart Cards for paying for tolls or transit fares, and many others.","title":"TC:Medium:Collaborative Research: Mobile Personal Privacy and Security - A New Framework and Technology to Account for Human Values","awardID":"0905384","effectiveDate":"2009-08-15","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["440155","542095","559051"],"PO":["565227"]},"153831":{"abstract":"Mathematical programming techniques like linear programming and semide&#64257;nite programming have &#64257;rmly established themselves as valuable tools in the approximation algorithm design toolkit. They are often used as tractable relaxations to hard combinatorial optimization problems and as design guides to obtain approximation algorithms. This project attempts to enhance our understanding of the strengths and weaknesses of mathematical programming techniques for several fundamental optimization problems and proposes to investigate general methods to strengthen our currently known mathematical programming techniques.<br\/><br\/>The broad goals of this project are the following: (a) Attempt to devise better algorithms for unique games ? a constraint satisfaction problem that is known to capture the limitations of current semide&#64257;nite programming methods used in approximation algorithms. Beating the current best algorithms will necessarily involve developing new techniques that overcome the limitations of current SDP approaches. (b) Understand the structure of strengthened relaxations obtained by lift-and-project procedures and develop techniques to exploit the additional information provided by these stronger relaxations to obtain better approximation algorithms. (c) Work towards closing large gaps in our understanding of the approximability of fundamental optimization problems.<br\/><br\/>Successfully achieving the project goals will entail signi&#64257;cant advances in the state of the art for approximation algorithms. The research could potentially develop tools and techniques with broad applicability to several optimization problems. Course materials for graduate and undergraduate courses will be developed distilling research results of this project, as well as new developments in the &#64257;eld.","title":"AF: Small: Mathematical Programming Methods in Approximation","awardID":"0916218","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":["542007"],"PO":["565251"]},"160497":{"abstract":"This proposal addresses the synthesis of computations and signal processing operations in a novel context: protein-protein biochemistry where the inputs and outputs are quantities of different types of proteins. The project will demonstrate that biochemistry can implement simple and powerful digital signal processing (DSP) operations. Constructs like and decision feedback equalizers will be implemented: given input quantities of proteins, the system performs a decision to deliver a drug or not, adaptively and autonomously. Also band-pass filtering will be implemented: the quantity of output protein is a highly-tuned function of the frequency of the changes in the quantities of input proteins. Other DSP functions such as FFTs will be implemented. The design of such DSP functions will be investigated in an abstract framework, as a proof of concept. (At this time, the research will not attempt to address the experimental application of these ideas in vitro or in vivo). <br\/><br\/><br\/>Techniques for analyzing the dynamics of biological systems are well established. However, synthesizing computation with such mechanisms requires new techniques ? and an entirely new mindset. Success in this endeavor will open numerous opportunities in fields such as biochemical sensing and drug delivery. An important goal of the project is to communicate the goals and the impetus for interdisciplinary research to a wide audience. A new graduate-level course will be developed, titled \"Circuits, Computation, and Biology\" offered jointly through the ECE Department and the new Biomedical Informatics and Computational Biology Program at the University of Minnesota.","title":"EAGER: Synthesizing Signal Processing Functions with Biochemical Reactions","awardID":"0946601","effectiveDate":"2009-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["550262","528637"],"PO":["562984"]},"153721":{"abstract":"The project integrates graduate research activities in hybrid, accelerated computing applications with undergraduate computer and computational science curricula, preparing undergraduates for graduate school and industry professions with application development experience in technologies essential to emerging high-performance computing and peta-scale systems. Curriculum enhancements across multiple computer science and engineering courses are investigated using real research activities to identify specific improvements needed at the undergraduate level. The research focuses on the use of leading accelerator technologies (multi-core CPUs, GPUs, and FPGAs) in real scientific computing challenges and translating the insights, concepts, and examples for use in undergraduate computer science and engineering instruction. The significance of pairing research investigations with curricular development affords the opportunity to bring real experiences into the undergraduate classroom. Research level investigations will help to characterize the unique inter-dependency of computer architectures and high-performance applications. The resources, strategies and examples created in this project are available to undergraduate programs across the country that wish to provide instruction on the next generation hardware and software environments. The project also reaches several underrepresented populations through outreach efforts at local high schools, regional HBCUs, and leverages existing REU programs.","title":"SHF: Small: RUI: Collaborative Research: Accelerators To Applications - Supercharging the Undergraduate Computer Science Curriculum","awardID":"0915805","effectiveDate":"2009-08-01","expirationDate":"2014-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}}],"PIcoPI":["439788",409082],"PO":["565272"]},"153842":{"abstract":"The objective of this project is to understand, evaluate, and contribute towards the suppression of sensitive aggregates over hidden databases. Hidden databases are widely prevalent on the Web, ranging from databases of government agencies, databases that arise in scientific and health domains, to databases that occur in the commercial world. They provide proprietary form-like search interfaces that allow users to execute search queries by specifying desired attribute values of the sought-after tuple(s), and the system responds by returning a few (e.g., top-k) satisfying tuples sorted by a suitable ranking function.<br\/><br\/>While owners of hidden databases would like to allow individual search queries, many also want to maintain a certain level of privacy for aggregates over their hidden databases. This has implications in the commercial domain (e.g., to prevent competitors from gaining strategic advantages) as well as in homeland-security related applications (e.g., to prevent potential terrorists from learning flight occupancy distributions). The PIs' prior work pioneered techniques to efficiently obtain approximate aggregates over hidden databases using only a small number of search queries issued via their proprietary front-end. Such powerful and versatile techniques may also be used by adversaries to obtain sensitive aggregates; thus defending against them becomes an urgent task requiring imminent attention. This project investigates techniques to suppress the sensitive aggregates while maintaining the usability of hidden databases for bona fide search users. In particular, it explores a solution space which spans all three components of a hidden database system: (1) the back-end hidden database, (2) the query processing module, and (3) the front-end search interface. The intellectual merit of the project is two-fold: (1) problem novelty: it initiates a new direction of research in information privacy of suppressing sensitive aggregates over hidden databases, and (2) solution novelty: it investigates a variety of promising techniques across the three components. The outcomes of this research have broader impacts on the nation's higher education system and high-tech industries. Parts of the project will be carried out by students of the University of Texas Arlington and George Washington University as advanced class projects or individual research projects.","title":"III: Small: Collaborative Research: Suppressing Sensitive Aggregates over Hidden Web Databases, a Novel and Urgent Challenge","awardID":"0916277","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["560637"],"PO":["565136"]},"164501":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/>In recent years, graphics processing units( GPUs)have emerged as a powerful alternative to CPU based computing, especially for scientific computing. However, GPUs follow the stream programming model. It is completely different from traditional serial programming and requires the invention of entirely news set of algorithms to suit the architecture.<br\/><br\/>This project supports research into data-parallel algorithms to model multi-scale phenomena in biological systems using agent-based models (ABMs). ABMs capture system level behaviors of complex systems by simulating the local interactions of individual entities or agents. This project funds the acquisition of two graphics processing unit (GPU) racks and software development to support application of the previously developed algorithms in systems biology.","title":"CRI II-New: Data-Parallel Platform for Large-Scale Simulation of Agent-Based Models in Systems Biology","awardID":"0968519","effectiveDate":"2009-08-16","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["484022"],"PO":["565272"]},"150465":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\"<br\/><br\/>Many emerging and future electronics applications require large amounts of digital signal processing, and operate with very limited power budgets. Examples include: many types of wireless communications, medical imaging such as ultrasound, sensor networks, and portable multimedia devices. A very promising solution for the processing of these workloads is a single-chip platform containing one thousand or more simple and highly-efficient programmable processors. The goals of this project are to: develop architectural hardware concepts and software tools that enable high-performance and energy-efficient computational platforms, introduce results into several courses at UC Davis, and make results and tools widely and easily available to other researchers. <br\/><br\/>In particular, the project goals will be achieved by exploring: 1) novel inter-processor connection topologies and processor shapes, 2) new algorithms for mapping large collections of software tasks onto processor arrays, 3) specialized hardware processors for common tasks, and 4) architectures for efficient shared and configurable memories. The PIs are active in several campus-wide and national organizations that work to attract and retain members of under-represented groups to engage in research and complete graduate degrees in science and engineering. Research effort and results will be instrumental in the cross-disciplinary training of future scientists and engineers in the design of massive processing arrays.","title":"Architectures for Highly-Efficient 1000+ Core Chips for Compute and Data-Intensive Applications","awardID":"0903549","effectiveDate":"2009-08-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7786","name":"MCDA"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":["551167","561804"],"PO":["366560"]},"153513":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 <br\/>(Public Law 111-5).<br\/><br\/>Software bugs cost the U.S. economy over $60 billion each year. Promising bug-detection technology depends on high-performance logic solvers for Satisfiability Modulo Theories (SMT), which employ sophisticated algorithms to check large formulas efficiently. Sophistication has a price: the solvers themselves exhibit bugs, and are not trustworthy enough for safety-critical applications. To increase confidence, some SMT solvers can emit formal proofs for valid formulas. Checking these proofs with a simple proof checker confirms the solver's results. SMT's rich logic poses challenges for standardizing a single proof format for all SMT solvers. Furthermore, proofs produced by SMT solvers can be gigabytes long, requiring an optimized proof checker. <br\/><br\/>This collaborative project is developing a verified proof checker supporting a flexible format called the Edinburgh Logical Framework with Side Conditions (LFSC). LFSC is a meta-language for describing different proof systems, thus providing flexibility. Verification techniques are being applied to the proof checker itself to verify its optimizations, by writing it in a verified programming language called Guru. Support is also being added for LFSC proofs to the CVC3 solver. This research will greatly increase confidence in solver results through proofs, thus increasing the power of bug detection.","title":"SHF: Small:Collaborative Research: Flexible, Efficient, and Trustworthy Proof Checking for Satisfiability Modulo Theories","awardID":"0914956","effectiveDate":"2009-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["550906"],"PO":["564388"]},"153634":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Each node in a wireless ad hoc network can choose the power at which it makes its transmissions and thus control the topology of the network. Though well-studied in the research literature, the problem of topology control has been largely considered only in idealized wireless environments and in isolation as a graph-theoretic abstraction. This project focuses on the design of topology control algorithms for reduced energy consumption, reduced interference and higher capacity in real wireless environments in the presence of multipath fading, link failures, high error rates and many other radio irregularities. The methodology follows two key philosophical goals: (i) an environment-independent approach which makes no constraining assumptions about the wireless environment (as opposed to trying to achieve approximations of reality in the assumptions), and (ii) an integrated approach which does not merely abstract out the problem of topology control separated from routing and link scheduling but embraces these into the design at the outset. This research also explores the fundamental limits of environment-independent topology control. <br\/><br\/>An immediate impact of this project is new algorithmic strategies that speeds up the actual deployment of energy-efficient high-performance wireless ad hoc networks with benefits to many known applications. A yet broader impact is new generalized distributed algorithms that can be employed in contexts beyond wireless ad hoc networks a variety of educational activities including course enhancements and participation in NSF RET programs for high-school teachers.","title":"NeTS:Small:Collaborative Research: An Integrated Environment-Independent Approach to Topology Control in Wireless Ad Hoc Networks","awardID":"0915393","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["533237"],"PO":["557315"]},"153876":{"abstract":"The project will develop techniques for monitoring systems to check if their executions satisfy a property specified by an automaton or a temporal logic specification. Systems to be monitored are modeled as a stochastic system. The project proposes accuracy measures that denote how accurately the desired property is monitored. The research will implement the accuracy measures as monitors for such systems. The research will also develop active monitors that interact with the underlying system to ensure the correctness properties, as well as techniques for detection of failures from a system?s external behavior and static verification techniques based on model checking employing symmetry based reduction. The work will lead to mathematically rigorous and powerful techniques that will improve the reliability of increasingly complex systems.","title":"Runtime and Static Verification of Concurrent Systems","awardID":"0916438","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["550555"],"PO":["565264"]},"153656":{"abstract":"This project aims to expand the boundaries of computational topology to include fundamental problems in combinatorial optimization, by developing efficient, practical, combinatorial algorithms to compute maximum flows, minimum cuts, and related structures in graphs embedded on topological surfaces. Preliminary results reveal intimate connections between the linear-programming duality between flows and cuts, the combinatorial duality between graph embeddings, the equivalence between flows in the primal graph and shortest-path distances in the dual graph, and Poincare-Lefschetz duality between (relative) homology and cohomology. These connections allow maximum flows to be computed in near-linear time in graphs of any fixed genus, by optimizing the relative homology class of the flow rather than directly optimizing the flow itself. However, the running time of these algorithms depends exponentially on the genus of the surface; a major goal of the project is to bring this dependence down to a small polynomial.<br\/><br\/>The project aims to advance knowledge and understanding across multiple research areas, by developing novel connections between fundamental techniques in combinatorial and algebraic topology, algorithm design, and combinatorial optimization. This research will lead to faster algorithms for several basic optimization problems, develop new applications of topological methods, and potentially settle several long-standing open algorithmic questions. The project will support two PhD students at the beginning of their graduate careers. A broader goal of the research is to strengthen ties between the computer science and mathematics research communities; results will be disseminated broadly in venues visible to both communities.","title":"AF:Small:Optimization in surface-embedded graphs","awardID":"0915519","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":["468851"],"PO":["565157"]},"162126":{"abstract":"Only 35% of seniors (over 65 years of age) in the U.S. use the Internet, reflecting an age-based digital divide when compared with the fact that 90% adults in the ages of 19-29 use the Internet. This project will address this divide through a novel approach that employs conversational agent technology to reduce the critical cognitive and social-psychological barriers hindering older users in web-based consumer environments. The goal of this project is to broaden the engagement of the growing yet underrepresented senior population in Internet technology, a medium that can dramatically improve their quality of life. This goal closely aligns with the human-centered computing objective of transforming the human-computer interaction experience through the development of systems that are aware of the abilities and special needs of people that use them. Research on animated pedagogical agents has revealed promising results on the effectiveness of agents in learning and motivation. However, no previous research program has investigated how agent technology can be designed to promote autonomy and empowerment in the older population, particularly in web-based consumer environments, involving multi-dimensional information processing and complex decision-making. To address this critical gap in the research, this project will systematically investigate, three aspects of agent interactions with older users: 1) locus of control (agent vs. user), 2) interactional style (functional vs. relational), and 3) modality of exchange (unimodal-voice vs. unimodal-text vs. dualmodal-voice + text). This research program will apply a multi-phase, mixed-methods approach involving qualitative studies in the first phase, and a series of controlled experiments with over 400 older users in subsequent phases. The purpose is to examine the effectiveness of the three aspects of agent-user interaction in: 1) reducing cognitive barriers (reducing information load, increasing navigation convenience, enhancing information search and retrieval ease), 2) reducing social-psychological barriers (enhancing control and efficacy, increasing trust, enhancing perception of social support), and 3) increasing Internet technology use intent. The experimental studies will further determine whether users' gender, visual or hearing impairments, and prior Internet competency interact with the three aspects of agent-user interaction to affect the desired outcomes. The findings from this project will generate new knowledge on how multimodal systems employing conversational agents can be designed for the abilities and special needs of older users leading to a potentially transformative and empowering experience for this underrepresented population in information technology.<br\/><br\/>Seniors are increasingly finding the necessity to engage in web-based consumer environments (e.g., online banking, shopping, trading, travel reservations). While the functionality of agents in these domains merits examination, the broader significance of this project lies in its ability to inform the development of agent-mediated interfaces for other applications such as websites that provide important health and medical information to seniors. Anecdotal evidence gathered by the project team from a prototype system has revealed the transformative potential of this technology for older users. This pilot research funded by the Office of Outreach at Auburn University, has extended the impact of this project to constituents in the state of Alabama. In addition to research, outreach will also serve as an important mission in the dissemination of future findings from this project to stakeholders at local and national levels. With the goal of enhancing diversity in research and education, this project will also involve a greater representation of African-American (AA) study participants from surrounding counties in Alabama, and actively engage AA graduate students, who are already part of the PI's lab in the educational goal of this project. This project will further enhance the infrastructure for research and education across two disciplines through an interdisciplinary seminar course will be offered to graduate students in computer science and consumer affairs to enhance the understanding of the future researchers on how humans perceive and use computing artifacts such as conversational agents.","title":"HCC: Small: Conversational Agents in Web-Based Consumer Environments Designed for Older Users","awardID":"0955763","effectiveDate":"2009-08-07","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"7492","name":"CCLI-Type 2 (Expansion)"}}],"PIcoPI":["542299"],"PO":["565227"]},"158914":{"abstract":"Last Modified Date: 06\/29\/09 Last Modified By: Almadena Y. Chtchelkanova <br\/><br\/>Abstract <br\/>Existing data storage systems based on the hierarchical directory-tree organization do not meet the scalability and functionality requirements for exponentially growing datasets and increasingly complex metadata queries in large-scale Exabyte-level file systems with billions of files. This project focuses on a new decentralized semantic-aware metadata organization that exploits semantics of file metadata to improve system scalability, reduce query latency for complex data queries, and enhance file system functionality. <br\/><br\/>The research has four major components: 1) exploit metadata semantic-correlation to organize metadata in a scalable way, 2) exploit the semantic and scalable nature of the new metadata organization to significantly speed up complex queries and improve file system functionality, 3) fully leverage the semantic-awareness of the new metadata organization to optimize storage system designs, such as caching, prefetching, and data de-duplication, and 4) implement the new metadata organization, complex query functions, and system design optimizations in large-scale storage systems. This project has broader impact to data-intensive scientific and engineering applications, graduate and undergraduate education, and K-12 education through its contributions to storage system research and its integration with an existing NSF-REU site award and an NSF-ITEST award.","title":"Collaborative Research: HECURA: A New Semantic-Aware Metadata Organization for Improved File-System Performance and Functionality in High-End Computing","awardID":"0937993","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7952","name":"HECURA"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["485828","366560"],"PO":["564993"]},"153359":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Computing architectures are increasingly parallel, most relying on multi-core microprocessors. Trends are also towards increased heterogeneity, with systems combining diverse components ranging from multiple microprocessors, field-programmable gate arrays (FPGAs), graphics processing units (GPUs), among others, often resulting in speedups of 10x to 100x. <br\/><br\/>A number of research thrusts have focused on the challenges associated with utilizing parallelism and heterogenity in computing architectures, including languages aimed at simplifying parallel programming. Despite numerous compiler and synthesis studies, usage of such systems has largely been limited to device experts due to significantly increased application design complexity. <br\/><br\/>To reduce design complexity, this project will investigate elastic computing, which is a framework to automatically parallelize an application across numerous heterogeneous resources while dynamically optimizing for different runtime parameters such as input size, battery life, etc. Elastic computing overcomes limitations of compilers and synthesis tools by providing the optimization framework with extra knowledge of functions, thus enabling automatic exploration of thousands of possible implementations, even ones using different algorithms. This project establishes an underlying theory for elastic computing, validated for numerous architectures and application domains, thus laying the foundation for much future research. In addition, the project will enable scientists without programming expertise to more easily develop applications for powerful multi-core heterogeneous systems, thus enabling new simulations that may advance the state of science. The project will also integrate elastic computing into graduate curriculum and will involve collaboration with the South East Alliance for Graduate Education and the Professoriate (SEAGEP) to recruit underrepresented students for undergraduate research.","title":"CSR: Small: Elastic Computing - An Enabling Technology for Transparent, Portable, and Adaptive Multi-Core Heterogeneous Computing","awardID":"0914474","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["507808"],"PO":["565255"]},"154118":{"abstract":"Abstract ? Zhang\/Wonka<br\/><br\/>The research investigates theory and efficient algorithms for pattern design on surfaces. Patterns on surfaces appear in many natural phenomena such as leaves, animal textures, and terrains as well as man-made objects such as origami, glass ornaments, and facades. Patterns can also be used to describe networks, such as street layouts, power grids, aqueducts, and sensor networks. Pattern design has a wide range of applications in art and entertainment, architecture, engineering, medicine, and city planning. In addition, theory and techniques developed in the research can benefit domains such as computational geometry and vector and tensor field visualization.<br\/><br\/>There are several fundamental challenges when it comes to pattern design on surfaces. First, there is a lack of unified mathematical formulations of patterns in terms of both symmetries and orientations contained in the patterns. Consequently, the aforementioned applications are typically addressed as being unrelated despite the intrinsic links between them. Second, many past approaches to these problems lack hierarchical control. This is required so that the user can design high level information down to occasionally low level specifics and the layout algorithms fill in the rest procedurally. In this research, the investigators explore a unified framework that allows hierarchical design of patterns on surfaces. In this framework, orientation and symmetry information is specified everywhere in the domain through tensor field design. Next, the tensor field which contains desired orientation and symmetry information is used to generate a complex which can be a point set, a graph, a tiling, or any combination of them. Finally, additional details are added onto the complex through texture and geometry synthesis, or sub-patterns are added inside the cells of the complex. Ideas from various mathematical domains such as dynamical systems, tensor calculus, differential geometry, and algebraic topology are borrowed and applied in this research.","title":"HCC: Small: Collaborative Research: Graph and Pattern Design on Surfaces","awardID":"0917308","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["497248"],"PO":["565227"]},"146638":{"abstract":"Developing reliable software systems is a key challenge for our<br\/>society. Despite many years of effort, software systems still suffer<br\/>from catastrophic failures. All too often, software failures are<br\/>caused by the propagation of errors through critical components of the<br\/>system. Unfortunately, current software development tools and<br\/>practices actually encourage the introduction of unnecessary<br\/>dependencies that serve to propagate errors between conceptually<br\/>unrelated components.<br\/><br\/>The goal of this research is to explore a new approach for creating<br\/>software systems that are robust against failures. The approach<br\/>exposes the high-level structure of a software system to the compiler<br\/>and run-time environment to enable the automatic application of techniques that<br\/>appropriately manage error propagation to make software systems more<br\/>resilient. The foundation of this approach is a specification<br\/>language that allows the developer to identify tasks and describe when<br\/>tasks should be invoked and how each task changes the conceptual<br\/>states of objects. A set of techniques use this information to<br\/>monitor and analyze task execution to eliminate unnecessary<br\/>dependencies. The broader impact of this research is the potential to<br\/>mitigate the effects of software faults.","title":"CAREER: Language Features for Robust Software","awardID":"0846195","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":["550574"],"PO":["564388"]},"148959":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\"<br\/><br\/>The real world inspires much of computer graphics and visualization research. In our work, we seek to acquire models directly from the real world and validate our synthetic models against real-world data. Our project establishes an Acquisition and Rapid Prototyping Laboratory in the School of Computing at the University of Utah. The lab includes a heterogeneous set of acquisition and rapid prototyping equipment, including laser range scanners, high-resolution and high frame rate cameras, and a 3D printer. This lab enables a wide range of projects, including visual validation of physics-based simulations, the creation of a material library for physics-based simulations, quantifying reconstruction error through adversarial cases, and the creation of a carefully curated data repository of 3-D scans. All of our collected data is available on the internet so that researchers at other institutions may also benefit from the laboratory. In short, this infrastructure allows the real world to inspire, create and validate our computer models of the real world.","title":"II-NEW: The Utah Acquisition and Rapid Prototyping Laboratory","awardID":"0855167","effectiveDate":"2009-08-01","expirationDate":"2013-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["486565","521991","552996","548348"],"PO":["565136"]},"150620":{"abstract":"The goal of this project is to investigate the potential of fundamentally new modes of robotic manipulation using novel continuum robots in less-structured environments with large uncertainties and even unknowns. A continuum robot, such as a trunk\/tentacle robot arm, is in many senses ?dual? to a traditional robot manipulator (consisting of an articulated arm and a gripper or hand), featuring relatively low precision but high compliance: <br\/><br\/>* Its inherent flexibility and compliance offer greater promise to enable deft manipulation under imprecise and uncertain conditions of objects over a wider range (orders of magnitude) of size and weight, of many different shapes, and with widely different physical characteristics (rigid, soft, flexible, etc.).. <br\/><br\/>* On the other hand, its inherent lack of precision renders the traditional approaches to planning and control of robot manipulators unsuitable for manipulation with continuum robots. <br\/><br\/>This project pioneers the study of the basic problem of autonomous manipulation of an object with much uncertainty by a single continuum robot. It introduces a novel and holistic approach that integrates real-time adaptive planning and robust control schemes under real-time sensing and large environmental uncertainty. It next extends the basic approach to address multiple continuum robots working in a common environment, where each robot needs not know the motion of another robot. The research combines theoretical\/algorithmic development with real-world validation on an experimental test bed with real trunk\/tentacle robots equipped with sensors. The results will be actively disseminated through publications, free software, and real-world demos to impact research, education, and applications.","title":"RI: Medium: Collaborative Research: Real-Time Continuum Manipulation","awardID":"0904093","effectiveDate":"2009-08-01","expirationDate":"2015-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["475621"],"PO":["564316"]},"150994":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>It is widely recognized that current wireless spectrum policy has been an impediment to the continued growth of high-capacity wireless networks. This project is investigating the consequences of lifting current restrictions on spectrum allocation and ownership, and allowing for extensive spectrum markets for allocating spectrum across locations, times and diverse applications. Various market structures that may emerge in such a setting are being studied using multi-disciplinary techniques including ideas from micro-economics, optimization theory and wireless networking. A key issue being explored is how to define the spectrum assets that will be traded in such a market taking into account both the interference among different users of wireless spectrum and the performance of the resulting market mechanisms. This results in a characterization of the trade-offs, in terms of efficiency and complexity of different asset definitions and market mechanisms. These results provide new insights into market-based allocation for wireless spectrum. <br\/><br\/>Results disseminated via publications could help facilitate a transition to new market structures that may lower the barriers to entry into the wireless services market thereby facilitating competition and the introduction of new services. The infusion of the cross-disciplinary ideas developed through this project into graduate classes also broadens the training of graduate students.","title":"NeTS:medium: Design of Dynamic Spectrum Markets for Wireless Networks","awardID":"0905407","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560217","560216","560218"],"PO":["557315"]},"153931":{"abstract":"Multi-core processors provide the only way to continue improving peak performance without much increase in the power consumption. However, there are serious challenges not only in expressing all the parallelism in the application, but also in exploiting the available parallelism by efficient application management on modern multi-core architectures. These challenges are only compounded by the trend of the absence of memory virtualization in the hardware, that is observed in futuristic processors, like the IBM Cell, and the Intel experimental 80-core processor. Memory management cannot be supported in hardware, because cache coherency protocols do not scale to 100s or 1000s of cores, and also because memory management in hardware consumes significant energy. Memory management in software can exploit application and data characteristics to reduce the overhead, however, it increases the burden of the application programmer. This project aims to develop tools and techniques to automatically manage the limited local memories present in each of the cores of a multi-core processor. In addition to power-efficient execution, the main objective of the project is to relieve the application programmer of the burden of carefully crafting the application, dividing and mapping it onto the cores to ensure its correct execution and portability.","title":"CCF-SHF: CSR: Small: Compilation for Multi-core Processors with Limited Local Memories","awardID":"0916652","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["560263"],"PO":["565272"]},"152600":{"abstract":"Despite heroic efforts in testing, static analysis, specification, and verification, all real-world software -- desktop applications, servers, and transportation systems---deploys with defects and missing functionality, costing the US economy billions and threatening our well-being. This project proposes a transformative paradigm shift to \"perpetually available software systems\" (PASS) that will make software more available and robust by directly addressing errors in deployed software. PASS innovations will (1) improve user experience by keeping real-world software running longer; (2) ensure good performance; (3) assist developers in fixing errors while allowing patches to be safely deployed on running software, to avoid downtime. The project will mine error reports in open source software repositories to derive error classes and test suites. It will evaluate system effectiveness by comparing with bug reports and patches in repositories. Innovations will include (1) detection and remediation elements that target common errors, (2) semantic foundations for remediation and on-line updating, and (3) integration of elements to exploit synergy among the components. The project will explore and analyze novel safe, probabilistically-safe, and extended-semantics remediations\/updates. The project will develop both C\/C++ and Java runtimes, because they are the most widely used languages and pose unique challenges. Methods will include combining dynamic, static, and remediation\/update analysis and results. The project will train graduate, undergraduate, and post doctoral students, and participate in outreach to under-represented groups. The tools will be made publicly available, adding to the national research infrastructure.","title":"SHF: Large:Collaborative Research: PASS: Perpetually Available Software Systems","awardID":"0910818","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["519591"],"PO":["564388"]},"150785":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Wireless sensor networks (WSNs) are becoming pervasive in both civilian and military domains. Low cost and ease of deployment of these networks necessitate the use of batteries as the primary source of power. As a result, battery capacity has emerged as a critical design parameter for maximizing the operational lifetime of the network. In this project, a comprehensive battery-charge-oriented framework for energy management in WSNs is developed. Its key novelty is its accounting of unique nonlinear battery characteristics, including passive recharge, load-profile dependence, and capacity fading. Such characteristics have significant impact on the usable battery capacity, and consequently on the network lifetime. Novel, physically justified analytical models for battery charge\/discharge are exploited in designing adaptive control strategies for data processing and communications in a WSN, with the aim of maximizing the network lifetime. These strategies are used to operate individual nodes as well as a hierarchical network of nodes. Battery-aware adaptivity is performed on CPU voltage\/frequency, RF transmission power, transmission rate\/modulation scheme, sleep\/wakeup scheduling, cluster-head assignment, cover selection, etc. Models and algorithms developed in this project are validated and their feasibility demonstrated through simulations and experimentation. The activity includes an education component involving undergraduate and graduate students, and a strong technology transfer plan. The project is expected to lead to novel designs and control strategies for sensor networks, with significantly longer operational lifetime and highly efficient energy management.","title":"NeTS:Medium:Collaborative Research: Exploiting Battery-Supply Nonlinearities in Optimal Resource Management and Protocol Design for Wireless Sensor Networks","awardID":"0904681","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["540507"],"PO":["565303"]},"153711":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009<br\/>(Public Law 111-5).\"<br\/><br\/><br\/>Embedded systems, such as controllers in automotive, medical, and avionic systems, consist of a collection of interacting software modules reacting to a continuously evolving environment. The emerging theory of hybrid systems---systems with tightly integrated discrete and continuous dynamics, offers a foundation for model-based design of embedded systems. For analyzing hybrid systems models, there are two prominent trends: an integral component of industrial modeling environments is numerical simulation, while a number of academic tools support formal verification of safety requirements using symbolic computation of reachable states of models. The proposed research is aimed at developing symbolic analysis techniques for simulation trajectories so as to significantly improve the simulation coverage. For this purpose, a new instrumentation scheme that would allow simulation engines to output, along with the concrete simulation trajectory, the symbolic transformers, will be developed. For managing complexity of symbolic analysis using polyhedra, new approximation schemes will be explored. The proposed algorithms will be implemented and evaluated in an analysis tool built on top of the widely used Stateflow\/Simulink toolkit. The research results will be integrated in Penn's new Masters' program in Embedded Systems that will train students in fundamentals of embedded systems design and implementation.","title":"SHF: AF: SMALL: Scalable Symbolic Analysis of Hybrid Systems","awardID":"0915777","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7933","name":"NUM, SYMBOL, & ALGEBRA COMPUT"}}],"PIcoPI":["497082"],"PO":["565264"]},"153953":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\"<br\/><br\/>In the 21st century, the dominant computing platform has shifted to multicore chips that implement cache-coherent shared memory and run multi-threaded applications. Unfortunately, these chips do not provide a deterministic model to either software or hardware developers. Reasoning about and testing for multiple possible executions is much harder than reasoning about and testing for a single correct sequential execution, as was possible under the von Neumann model that dominated in the 20th century. Easing the burden of programming multicore chips is critical to provide society with the rapid, cost-effective performance gains that we have all come to expect. Moreover, broad impact requires practical solutions that do not ask industry to discard or rewrite billions of lines of existing general-purpose thread-based software.<br\/><br\/>To this end, research under this proposal will develop solutions for managing non-determinism with alterative implementation approaches that provide complementary benefits and opportunities. (1) Work will expand techniques of recording executions for deterministic replay to improve replay parallelism and extend the scope of record\/replay to hardware debugging and fault-tolerance. (2) Work will develop and advance a deterministic coherence model that eliminates a major source of non-determinism in shared-memory multiprocessor systems: memory races. (3) Work will develop both all-software and hardware-accelerated implementations of deterministic coherence, in part, through extensions to the Wisconsin GEMS simulation infrastructure. (4) Finally, work will explore rebuilding coherence upon a formal deterministic foundation. Broader impacts will include embodying the proposed work in public software releases (e.g., GEMS) as well as dissemination to students and through courses, talks, industrial affiliates, and commercial influence.","title":"SHF: Small: Managing Non-Determinism in Multithreaded Software and Hardware","awardID":"0916725","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["541916","541915"],"PO":["366560"]},"163754":{"abstract":"The focus of this project is on cyber-physical systems (CPS) -- physical and engineered systems whose operations are integrated, monitored, and controlled by a computational core. Applications of CPS include, for example, critical (physical) infrastructure control (electric power, water resources, gas and fuel distribution, transportation, etc.), highly dependable medical devices and systems, traffic control and safety, advanced automotive systems, process control, and manufacturing, energy conservation and environmental control, avionics, distributed robotics (tele-presence, tele-medicine), and manufacturing.<br\/><br\/>Traditional frameworks for designing and configuring computing and networking systems do not capture the complexity of CPS systems -- principally because many of the abstractions developed for computing and networking deliberately abstract away essential properties of the physical world. Existing real-time operating systems (mix of operating systems, middleware, and general-purpose virtual machines) are not sufficient to support the complexity challenges of emerging classes of cyber-physical systems because of the mismatch between traditional computation abstractions and properties of physical processes. Some current technical approaches partially bridge the abstraction gap (such as real-time operating systems, middleware technologies, specialized embedded processor architectures, and specialized networks). However, current research and development of cyber-physical systems calls for non-incremental, revolutionary approaches, where new abstractions are built from the ground up. These abstractions must enable reasoning at every level for high-confidence system composition and addresses issues such as time-criticality, safety, and security.<br\/><br\/>In response to the need for a CPS framework, this SGER project will investigate architectural models with the goal of helping the research community to develop a cyber-physical system vision that integrates both computer science (real-time systems; embedded systems; software and system verification, validation, and certification; computing technologies; wireless and wired networking; sensor nets) and the traditional physical sciences and engineering disciplines (control, physical sensors and actuators, physical system design and engineering, materials, even biology and nanotechnology). Such models are likely to provide a platform for future cyber-physical systems design that brings these interacting elements into a single focus.<br\/><br\/>This project will also sponsor several meetings (workshops, symposia, summit, etc) that aim at providing a forum for engineers and scientists in academia, industry and government to present their latest research findings in any aspects of cyber-physical systems, and, consequently, allow the community to define and enhance the research agenda for this important emerging field. <br\/><br\/>The primary intellectual merit of the proposal resides in analyzing existing cyber-physical systems and developing abstracted architecture models that will enable future cyber-physical systems design and realization. <br\/><br\/>The broader impact of the proposed work is on the research community at-large, through the project focus on issues related to cyber-physical systems. The advancement achieved through this Cyber-physical system research is expected to improve the research and development capabilities in the nation and contribute to increased global competitiveness.","title":"A Study of Architectural Models for Cyber-Physical Systems","awardID":"0963979","effectiveDate":"2009-08-26","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["453727"],"PO":["565255"]},"165833":{"abstract":"Wireless networks are increasingly popular as the last-mile solution for a ubiquitous communication infrastructure. This trend in combination with the users? growing interest and falling cost in accessing vast amount of resources in Internet wirelessly has driven the developments of hybrid wireless network architecture such as Internet-based mobile ad hoc networks (IMANETs) and Internet-based vehicular ad hoc networks (IVANETs). However, it brings critical challenges in terms of limited storage space, frequent disconnections due to mobility, as well as unreliability of communication links. Caching a frequently accessed data in a local storage is shown to be an effective technique not only to relieve the network but also to improve data accessibility and availability in the presence of such challenges. The specific goal of this project is to develop algorithms and communication protocols that allow efficient and correct data caching in Internet-based wireless mobile networks. This project investigates cache management and invalidation strategies for IMANETs, and cache invalidation and consistency strategies for IVANETs. The project will make significant advances in understanding and designing an efficient data caching schemes for Internet-based wireless mobile networks. The success of this project will have a much broader impact on Internet-based wireless mobile network education and the corresponding industry, and provide versatile research opportunities to both undergraduate and graduate students. The algorithms and techniques developed in this research will be integrated with the education curricula","title":"Collaborative Research: NEDG: Exploring Data Access in Internet-based Wireless Mobile Networks","awardID":"1004210","effectiveDate":"2009-08-28","expirationDate":"2011-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["528460"],"PO":["557315"]},"153975":{"abstract":"Endowing humanoid robots with the ability of skill learning will enable them to be versatile and skillful in performing various tasks. The problem of transferring human skills to humanoid robots raises tremendous research interest in studying human and robot motor skills. Our research aims at developing a quantitative measure of robot motor capability of a humanoid root motor system for the application of transferring human skills to a humanoid robot. An in-depth study of basic intrinsic properties of robot motor capability based on information theory will be performed to derive a pseudo index of motor performance. This pseudo index of motor performance is derived from robot kinematics, dynamics, and control with the speed-accuracy constraint taken into consideration. With the speed-accuracy constraint, the motor performance of a robot is optimized to accomplish a task. The research results demonstrate an increased understanding of robot motor capability that shows the capability and limitation of a robot for learning skills from human demonstration. The project plans to verify the result on an existing humanoid robot. The project results will provide new insights in humanoid robot motor learning and control, and launch a new research direction on human-robot interaction when both humans and robots better know their respective motor capabilities. The broader impacts include incorporation of research results into existing graduate and undergraduate robotics courses, and outreach activities of a weeklong robotics summer camp and a lab open house for high-school students. The research results will be disseminated in professional conferences, workshops and archival journal publications.","title":"RI Small: On Robot Motor Capability for Skill Learning","awardID":"0916807","effectiveDate":"2009-08-01","expirationDate":"2015-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["335186"],"PO":["534411"]},"152656":{"abstract":"The evolution of the \"human Web,\" powered by HTML and HTTP, has revolutionized the way that people find information, buy things, communicate, and collaborate. Web services and semi-structured data formats are having a similar impact on the \"machine Web.\" XML is enriching our ability to find and interchange information today; industry verticals have created XML-based data exchange standards; and XML backbones have gained adoption in support of service-oriented architectures and software-as-a-service initiatives. Other semi-structured formats, like JSON, are playing similar roles, and XML is increasingly being used for its original purpose of semantic document markup. As a result, the world will soon be awash in a sea of semi-structured information. <br\/><br\/>The ASTERIX project is developing new technologies for ingesting, storing, managing, indexing, querying, analyzing, and subscribing to vast quantities of semi-structured information. The project is combining ideas from three distinct areas - semi-structured data, parallel databases, and data-intensive computing - to create a next-generation, open source software platform that scales by running on large, shared-nothing computing clusters. ASTERIX targets a wide range of semi-structured information, ranging from \"data\" use cases - where information is well-tagged and highly regular - to \"content\" use cases - where data is irregular and much of each datum is textual. ASTERIX is taking an open stance on data formats and addressing research issues including highly scalable data storage and indexing, semi-structured query processing on very large clusters, and merging parallel database techniques with today's data-intensive computing techniques to support performant yet declarative solutions to the problem of analyzing semi-structured information.<br\/><br\/>Project website: http:\/\/asterix.ics.uci.edu\/","title":"DC: Large: Collaborative Research: ASTERIX: A Highly Scalable Parallel Platform for Semistructured Data Management and Analysis","awardID":"0910989","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["385755","543631"],"PO":["563727"]},"153877":{"abstract":"Association analysis finds patterns that describe the relationships among the binary attributes (variables) used to characterize a set of objects. A key strength of association pattern mining is that the potentially exponential nature of the search space can often be made tractable by using support based pruning of patterns i.e., eliminating patterns supported by too few transactions. Despite the well-developed theoretical foundation of association mining, this group of techniques is not widely used as a data analysis tool in many scientific domains. For example, in the domain of bioinformatics and computational biology, while the use of clustering and classification techniques is common, techniques from association analysis are rarely employed. This is because many of the patterns required in bioinformatics and other domains are not effectively captured by the traditional association analysis framework and its current extensions. Although such patterns can be found by techniques such as bi-clustering and co-clustering, these approaches suffer from a number of serious limitations, most notably, an inability to efficiently explore the search space without resorting to heuristic approaches that compromise the completeness of the search. To address the challenges mentioned above, the team will extend the traditional association analysis framework. They propose two novel frameworks for directly mining patterns from real-valued data that, unlike biclustering and co-clustering, are able to discover all patterns satisfying the given constraints and do not suffer from the loss of information caused by discretization and other data transformation approaches. They will also extend association analysis based approaches to work with data that has class labels by effectively using the available class label information for pruning the exponential search space and finding low-support patterns that discriminate between the two data classes. To evaluate the results of the work, they will develop robust evaluation methodologies for evaluating the patterns obtained from the proposed frameworks. The proposed work promises to extend the power of association analysis to a wide range of new applications in health and life sciences, such as the discovery of biomarkers and functional modules from single nucleotide polymorphism and gene expression data, with potential applications in personalized medicine and the development of drugs and bio-fuels.","title":"III: Small: Generalization of the Association Analysis Framework","awardID":"0916439","effectiveDate":"2009-08-01","expirationDate":"2012-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["563608","563607"],"PO":["565136"]},"153767":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Wireless Mesh Networks have emerged as a solution for providing last-mile Internet access. By exploiting advanced communication technologies, they can achieve very high rates. However, effectively controlling these networks, especially in the context of advanced physical layer technologies, realistic models for channel interference, and distributed operation, remains a major challenge. Hence, the project focuses on developing effective and practical network control algorithms that make efficient use of wireless resources through joint topology adaptation, network layer routing, MAC layer scheduling, and physical layer power, channel, and rate control. The design of the algorithms leverages recent developments in the control of dynamical systems and randomized algorithms, and takes into account realistic channel models. This includes: (i) topology adaptation algorithms that take advantage of channel allocation, power control, and the controlled mobility capabilities of some of the nodes to dynamically decompose the network into sub-networks in which low-complexity distributed scheduling and routing algorithms are guaranteed to achieve high throughput, (ii) randomized distributed algorithms that solve the scheduling and routing problems in a computationally efficient manner using only local topological and queue size information, and (iii) evaluation of the algorithms? performance in terms of throughput, delay, and complexity. The developed algorithms will enable highly efficient operation of wireless networks. The project incorporates training of graduate and undergraduate students, outreach activities to local high-school teachers, and technology transfer to industry and government laboratories.","title":"NeTS:Small:Collaborative Research: Effective control of wireless networks via topology adaptation and randomization","awardID":"0915988","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["517543"],"PO":["557315"]},"153657":{"abstract":"Proposal Number: 0915526<br\/>Title: T2T: A Framework for Amplifying Testing Resources<br\/>PIs: Sebastian Elbaum and Matthew Dwyer<br\/><br\/>Abstract:<br\/><br\/>Virtually every software development company invests in the <br\/>construction and maintenance of testing resources to validate their <br\/>products. These investments, however, can be very costly. <br\/>Consequently, not all testing resources are supported equally as <br\/>companies focus their testing efforts on specific and limited types of <br\/>tests, ultimately sacrificing timely fault detection. The work proposed will address this problem by investigating strategies for amplifying the power and applicability of testing resources. The strategies will transform existing tests into new tests that add complementary testing capabilities to the validation process. The developed strategies will be unique in their treatment of tests as data. This will require the development of test representations that can be efficiently manipulated, and test transformations to realize operations that generate new and valuable tests. Test representations that are expressive enough to efficiently encode common forms of software tests will be developed, and transformations that operate both on and across different test representations will be explored. These test representations and transformations will constitute the T2T (test to test) framework and the initial step towards treating tests as data. If successful, this work will help software development companies lower product costs and enhance dependability by amplifying their existing testing resources.","title":"SHF: Small: T2T: A Framework for Amplifying Testing Resources","awardID":"0915526","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["561782","518212"],"PO":["564388"]},"153789":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/>Using Ternary Content Addressable Memories (TCAMs) to perform high-speed packet classification has become the de facto standard in industry. Despite their high speed, TCAMs have limitations of high cost, small capacity, large power consumption, and high heat generation. The well-known range expansion problem in converting range rules to ternary rules significantly exacerbates these TCAM limitations. This project addresses TCAM limitations by developing new algorithms to transform a given rule set into an equivalent rule set that requires significantly fewer TCAM entries. This allows the use of smaller, faster, and more energy efficient TCAM chips. The algorithms developed by this project significantly outperform prior art because these new algorithms perform equivalent transformation at the list level whereas prior approaches only perform compression at the individual rule level. <br\/>Expected results of this project include effective equivalent transformation algorithms and potentially transformative concepts. Research results are broadly disseminated through publications, open source software releases, freely available course modules, and industry interaction. This project benefits society by decreasing the demand of modern routers for large TCAMs, lowering router prices and energy cost, enabling the use of small and cheap TCAMs on low end routers, and extending router life time. The technologies developed in this project greatly benefit the business of router manufacturers, TCAM chip providers, and Internet service providers. To promote education and learning, this effort actively engages high school, undergraduate, and graduate students, especially students from under-represented minorities.","title":"NeTS:Small:Algorithmic Approaches to Optimizing Hardware-Based Packet Classification Systems via Equivalent Transformation","awardID":"0916044","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["562295","562296"],"PO":["564993"]},"148905":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>The objective of this project is to inspire students at Tuskegee University and Auburn University in mathematics, aerospace science engineering, and networking by inviting them to contribute to a grand project: fly safely and efficiently, in a limited space, a fleet of autonomous UAVs on a cooperative mission with terrestrial vehicles. <br\/><br\/>The team of Dr. Sriram Vishwanath at the University of Texas (UT) Austin will deliver six Proteus modules (terrestrial vehicles) and will assist the team at Tuskegee University (TU) and Auburn University (AU) to build for this project six other Proteus modules adapted to the ultimate objective of this project. Dr. Biaz and his students will develop and implement at Auburn University the networking protocols that will allow all terrestrial and aerial vehicles to communicate with each other. The implementation will be made through series of laboratory exercises and research projects collaboratively conducted at Tuskegee University and Auburn University. <br\/><br\/>Intellectual Merit: This project will set up a research infrastructure that enables laboratory exercises in mathematics, aerospace and computer networking. For each discipline, students will contribute to the solution of challenging problems. To this day, most research on mobile ad hoc networks is conducted through simulation. This research infrastructure will allow students to test and evaluate the most promising networking protocols with hardware-in-the-loop. In mathematics, students will realize for example that solving a system of equations not only can obviously determine the position of a vehicle but also can be directly used to enable networking coding and improve communications efficiency. <br\/><br\/>Broader Impacts: <br\/>Tuskegee University is the only HBCU with an ABET-accredited Aerospace Engineering program and graduates the largest number of African-American aerospace engineers in the US. This research infrastructure will contribute to attract and retain students in STEM fields at Auburn University and Tuskegee University in general and under-represented minorities in particular. The multidisciplinary collaboration between Tuskegee University, UT Austin and Auburn University will benefit students from these institutions to work in a multi-disciplinary environment and will expose them to state of the art education and research. The results of the collaborative effort will be disseminated through presentations at engineering education and other professional conferences.","title":"Collaborative Research: CRI-RUI: II-NEW: ATTRACT: Aerial and Terrestrial Testbed for Research in Aerospace, Computing, and maThematics","awardID":"0855025","effectiveDate":"2009-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["539208"],"PO":["565090"]},"148916":{"abstract":"Event-driven software (EDS) spans multiple domains, from industrial embedded devices and robotic controllers to web interfaces. Researchers experimenting with new software testing techniques for EDS do not have benchmarks that they can use to compare their techniques. This project investigates the requirements for a community infrastructure of event-based testing researchers to provide uniformity in experimentation. It uses the results of the requirements analysis to develop a preliminary prototype called COMET: COMmunity-Event-based Testing. COMET will consist of a core set of requirements for EDS testing that provides a repository of both logical and concrete test artifacts. This includes processes and models to standardize the way experiments are conducted as well as on- line web services for common computational components. Techniques developed in this project will have a broad impact: COMET has the potential to bring EDS testing techniques to a broader community and will promote greater transferability of ideas. Artifacts for EDS testing will be available to other disciplines such as computer human interaction researchers who are interested in EDS usability.","title":"II-NEW: Collaborative Research: COMET-COMmunity Event-based Testing","awardID":"0855055","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["550281"],"PO":["564388"]},"148927":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\"<br\/><br\/>Storage system researchers have typically used I\/O traces from various sources to drive their analysis and research. However, these I\/O traces fail to adequately capture the effect of I\/O on application performance. Moreover, they do not scale with other parts of the overall system whether it be application, systems, or processor. As a result, it is difficult to replay the trace for use in storage systems evaluation. This is particularly problematic since many of the extant publicly available I\/O traces are quite old.<br\/><br\/>The focus of the project is to provide to the storage research community a set of traces that will allow for accurate replay and evaluation of storage technologies. The traces will be from real systems at different levels of the storage system hierarchy including network layer, file system, and low-level disk. These include traces that do not currently exist in the storage community such as iSCSI traces, virtual machine traces, and MS Exchange traces. The project will also provide a set of tools for tracing application dependent I\/O, replaying traces, and analysis. The tools and collected traces will be made available as a community resource through publicly available sources.<br\/><br\/>The broader impacts of this project include providing tools and traces that can assist storage system researchers in developing new I\/O system technologies. Since storage systems are critical to the current information-based economy, advances in understanding I\/O system behavior should be highly beneficial. It should also be useful to data-intensive applications of national interest such as the genome project, weather simulation, and digital libraries.","title":"CI-ADDO-NEW: Storage System Trace Collection","awardID":"0855090","effectiveDate":"2009-08-01","expirationDate":"2012-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["550180"],"PO":["565272"]},"159817":{"abstract":"Increasing numbers of scientific projects leverage mobile devices to monitor and at times interact with elements of the natural environment. This important emerging trend however is not paired with an adequate forum for publication and exchange of information among researchers as that of other disciplines. This workshop gathers a representative sample of researchers and practitioners with expertise and interest in human-environment, mobile-based interactions. It provides a forum to present current technology trends in areas such as networking, communication, sensing, data mining, data visualization and robotics as well as discussions on synergistic applications. In addition to the presentations, the workshop participants are meeting to identify and plan sessions for presentations at future conferences.<br\/><br\/>Impacts of this workshop are expected in mobile and sensing technologies as well as in application areas including biology, agronomy, environmental science, public health and citizen science. The workshop invitees are drawn from diverse areas and social-ethic backgrounds. The presentation abstracts of the workshop will be disseminated through the workshop website, http:\/\/hembi.media.mit.edu.","title":"Human-Environment Mobile-Based Interactions","awardID":"0943412","effectiveDate":"2009-08-15","expirationDate":"2010-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[427498],"PO":[427499]},"148938":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/><br\/>Developing security monitoring to robustly protect large sites against Internet attacks presents exceptionally difficult research challenges. There is a world of difference between detecting attackers in a small-scale environment such as a departmental LAN (as is often used for evaluation of academic studies) and doing so at the scale of a large site. Algorithms that work fine in the presence of a modicum of background traffic can be rendered completely useless when faced with two orders of magnitude more background traffic, for reasons of both performance and false positives induced by the much greater diversity. <br\/><br\/>The overall objective of this proposal is to greatly enhance our UC Berkeley infrastructure that monitors the campus border traffic in order to facilitate the continuation of security research tied to the operational requirements of one of the largest academic network environments in the country. The proposed new cluster will serve as a powerful research platform for many future studies, providing unprecedented capabilities for analyzing a large-scale operational network in depth. Furthermore, on a technical level it will allow the principal investigators (PIs) to systematically assess the scalability of the our clusterized approach to larger network loads and determine what is required to provide in-depth monitoring capabilities for other environments. Intellectual merit: <br\/><br\/>Intellectual Merit: The instrumentation infrastructure supported by this proposal will serve as the key enabler for a range of research otherwise not possible to undertake at an equivalent scale. These span: (1) detection algorithms that operate robustly in the presence of highly diverse background traffic, (2) indepth semantic analysis of the very broad range of modern network applications, (3) efficient recording of high-volume traffic streams for forensic analysis, (4) scalability assessment of clustering and multicore techniques for achieving high performance monitoring, and (5) ties with the UC Berkeley cybersecurity staff leading to investigation of new research problems that arise when deploying network defenses operationally. <br\/><br\/>Broader impact: The ability to richly monitor large traffic streams in real-time has major implications for Internet security, as it is a key component for securing large Internet sites. This effort will enable a range of research directly grounded in the operations of a high-performance, high-volume site, a type of environment only very lightly addressed in the field due to its significant logistical and technical difficulties. The monitoring system will realize an order of magnitude more power for such analysis than to our knowledge any existing deployment provides. As such, it will serve not only as a platform for network security research at scales previously unattainable, but also as an exemplar for how others can construct and operate such systems. Thus, this effort has the potential both to enable new discoveries regarding protecting high-volume network environments, and to facilitate the broader use of such technology for better securing and operating high-speed networks. Finally, the infrastructure from this grant will provide doctoral students with an unparalleled opportunity for undertaking research in an environment unmatched by any other in the field.","title":"II-EN: High-Performance Network Monitoring Infrastructure For Research in a Large-Scale Operational Environment","awardID":"0855125","effectiveDate":"2009-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["562327","562329"],"PO":["565090"]},"148949":{"abstract":"This CRI planning grant uses the theory of conceptual metaphor to plan<br\/>the creation of an on-line metaphor resource that covers multiple<br\/>types of language and corpora. Metaphor is pervasive in human language<br\/>and thought and is crucial for both linguistic expression and human<br\/>reasoning. Conventionalized as well as novel metaphorical expressions<br\/>can be routinely encountered in everyday life conversations, in<br\/>newspapers, and in many other text types including scientific,<br\/>technical, and literary writing.<br\/><br\/>The goal of this planning effort is to resolve issues related to<br\/>corpus selection and preparation, and to incorporate community wide<br\/>evaluative feedback in the iterative design and implementation of<br\/>metaphor annotations. Towards the end of the planning work, there will<br\/>be a workshop to evaluate the approach, to build support for the<br\/>corpus creation enterprise, and to establish a user community. This<br\/>corpus selection and metaphor annotation effort is also being<br\/>coordinated with the companion SGER effort underway (NSF IIS grant<br\/>0843275) that is exploring issues related to scalable metaphor<br\/>modeling and inference.<br\/><br\/>The multi-layer annotations will include conceptual relations and<br\/>metaphor domains, linguistic expressions and frame annotations of the<br\/>relevant lexical targets, and syntactic relations that obtain in the<br\/>annotated target text. The result will be the design of a<br\/>comprehensive, richly annotated resource of metaphoric languge.The<br\/>combination of this work, along with parallel efforts in semantic<br\/>analysis and inference should permit the development and testing of<br\/>large-scale systems capable of figurative language processing within a<br\/>few years.","title":"CI-P: The ICSI Metaphor Annotated Corpus","awardID":"0855143","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["142866"],"PO":["565215"]},"150863":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Wireless sensor networks (WSNs) are becoming pervasive in both civilian and military domains. Low cost and ease of deployment of these networks necessitate the use of batteries as the primary source of power. As a result, battery capacity has emerged as a critical design parameter for maximizing the operational lifetime of the network. In this project, a comprehensive battery-charge-oriented framework for energy management in WSNs is developed. Its key novelty is its accounting of unique nonlinear battery characteristics, including passive recharge, load-profile dependence, and capacity fading. Such characteristics have significant impact on the usable battery capacity, and consequently on the network lifetime. Novel, physically justified analytical models for battery charge\/discharge are exploited in designing adaptive control strategies for data processing and communications in a WSN, with the aim of maximizing the network lifetime. These strategies are used to operate individual nodes as well as a hierarchical network of nodes. Battery-aware adaptivity is performed on CPU voltage\/frequency, RF transmission power, transmission rate\/modulation scheme, sleep\/wakeup scheduling, cluster-head assignment, cover selection, etc. Models and algorithms developed in this project are validated and their feasibility demonstrated through simulations and experimentation. The activity includes an education component involving undergraduate and graduate students, and a strong technology transfer plan. The project is expected to lead to novel designs and control strategies for sensor networks, with significantly longer operational lifetime and highly efficient energy management.","title":"NeTS:Medium:Collaborative Research: Exploiting Battery-Supply Nonlinearities in Optimal Resource Management and Protocol Design for Wireless Sensor Networks","awardID":"0905035","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["525996"],"PO":["565303"]},"150885":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Significant progress has been made on technical solutions for implementing security while preserving varying degrees of privacy for mobile electronic devices. A largely unsolved problem involves knowing what type of technical solutions to implement and under what circumstances. This challenge arises because in actuality there is in general no such thing as a clear \"optimal\" or \"right\" solution. One way to view this problem is by focusing on the fact that such devices potentially play an integral role in people's lives and impact important human values: security and privacy of course, but also other values such as autonomy, trust, and physical well-being. Further, these values are often in tension. This project will develop a principled and systematic conceptual framework for analyzing these value implications and tensions in the context of two archetypical examples of future mobile devices: implantable medical devices and mobile phone safety applications. A key component of our approach will be the application and extension of the Value Sensitive Design theory and methodology. Researchers will develop and evaluate new technology, as well as undertake empirical work with a range of stakeholders, including Futures Workshops and semi-structured interviews. Expected outcomes include a framework for analyzing the relationships and trade-offs among privacy, security, autonomy, and other values for mobile devices that accounts for both situational and embodied dimensions of these values; a pallet of key technical solutions to these problems; a set of case studies; and finally design recommendations for use by other researchers and practitioners. <br\/><br\/>Results of this work will not only develop technical mechanisms for providing the \"right\" level of security and privacy for new mobile technologies, but can help influence the definition of what \"right\" means in the context of the broader set of goals and values. In society more generally, there is an increasing use of technologies that are focused upon here: implantable medical devices and highly capable cell phones used for personal safety. Improving human health and personal safety, while not significantly undermining other key values such as privacy, trust, and autonomy, will be important in the development of such technologies. It is anticipated that the ways of analyzing such problems will be applicable to other technologies as well, such as RFID tags on personal possessions, Smart Cards for paying for tolls or transit fares, and many others.","title":"TC: Medium: Collaborative Research: Mobile Personal Privacy and Security - A New Framework and Technology to Account for Human Values","awardID":"0905118","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["539283",402230,"421076"],"PO":["565227"]},"153811":{"abstract":"Mathematical group theory has wide applications to the sciences and to other branches of mathematics. Some important examples of current interest are fast matrix multiplication, search in the presence of symmetry, and symmetries to be found in physics and chemistry. Current algorithms do not always scale or are not always practical in implementation. Some levels beyond which current algorithms tend to become impractical are permutations of a million points, matrix group dimensions beyond a few tens, and coset methods (defining equations on groups) beyond 100 million cosets. We call such groups \"very large groups\".<br\/><br\/>This project will develop a new class of algorithms for very large groups. The new algorithms will take advantage of the experience of the P.I. and his lab in previous computations and algorithms using terabytes of parallel disk storage. The feasibility of a many-disk approach had previously been shown in a popular demonstration concerning Rubik's cube: Rubik's cube can be solved in 26 moves or less. Both that and more traditional problems will be used to further develop the disk-based language, Roomy.<br\/><br\/>Emphasis will be given to well-known problems not known to be in polynomial time (centralizer, group intersection, normalizer, etc.). These problems have seen little progress during the last decade. They are considered hard in part due to their close connection with the conjugate group action of a group on itself. In this conjugate action view, a group is seen as a permutation group acting on almost as many points as there are elements in the group itself. In this view, even moderate size groups quickly turn into very large groups under the conjugate action. Novel methods such as the biased tadpole, coupled with the power of the Roomy language, will enable a resumption of progress in this area.<br\/><br\/>The broader impact lies in the ability to harness these new algorithms and implementations in pursuit of applications outside of group theory such as those mentioned earlier. Researchers outside of group theory have long had the potential to generate groups beyond the capabilities of standard software, such as the free and open source GAP package. Extending the capabilities of GAP and other familiar tools will enable new discoveries. The further development of the Roomy platform is also an important byproduct, whose value will extend far beyond its group theory origins.","title":"AF:Small: Computation in Very Large Groups","awardID":"0916133","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":["521812"],"PO":["565251"]},"152601":{"abstract":"The evolution of the \"human Web,\" powered by HTML and HTTP, has revolutionized the way that people find information, buy things, communicate, and collaborate. Web services and semi-structured data formats are having a similar impact on the \"machine Web.\" XML is enriching our ability to find and interchange information today; industry verticals have created XML-based data exchange standards; and XML backbones have gained adoption in support of service-oriented architectures and software-as-a-service initiatives. Other semi-structured formats, like JSON, are playing similar roles, and XML is increasingly being used for its original purpose of semantic document markup. As a result, the world will soon be awash in a sea of semi-structured information. <br\/><br\/>The ASTERIX project is developing new technologies for ingesting, storing, managing, indexing, querying, analyzing, and subscribing to vast quantities of semi-structured information. The project is combining ideas from three distinct areas - semi-structured data, parallel databases, and data-intensive computing - to create a next-generation, open source software platform that scales by running on large, shared-nothing computing clusters. ASTERIX targets a wide range of semi-structured information, ranging from \"data\" use cases - where information is well-tagged and highly regular - to \"content\" use cases - where data is irregular and much of each datum is textual. ASTERIX is taking an open stance on data formats and addressing research issues including highly scalable data storage and indexing, semi-structured query processing on very large clusters, and merging parallel database techniques with today's data-intensive computing techniques to support performant yet declarative solutions to the problem of analyzing semi-structured information.<br\/><br\/>Project website: http:\/\/asterix.ics.uci.edu\/","title":"DC: Large: Collaborative Research: ASTERIX: A Highly Scalable Parallel Platform for Semistructured Data Management and Analysis","awardID":"0910820","effectiveDate":"2009-08-15","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["518657","525612"],"PO":["563727"]},"150434":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\"<br\/><br\/>The push toward heterogeneous architectures to increase performance, while reducing energy consumption creates considerable challenges for software development. For example, programmers must make non-trivial decisions about when to use special accelerators vs. powerful core CPUs and also become steeped in complex architectural details to tune effectively. The goal of this research project is to alleviate these challenges using a novel framework that enables a wide-range of computations to be expressed at a high-level and subsequently tuned automatically for the underlying heterogeneous platform. More specifically, the PIs propose Qameleon, a new programming environment that can cooperatively tune the program and the hardware configuration automatically and continuously using statistical machine learning techniques. <br\/>The proposed work will be the first in GPU programming to consider adaptively partitioning a computation on a heterogeneous platform at run-time. This work will also improve understanding of the trade-offs among programming features, architectural support, performance, and power in heterogeneous architectures. The research will also develop several metrics to characterize the application based on the outcome of the statistical modeling. <br\/><br\/>The proposed research brings together cross-disciplinary techniques?from architectures, compilers, machine learning, and applications ? and researchers from both academia and industry to build new common programming interfaces that can hide the complexity of heterogeneous architectures from the programmers, while still providing high-performance and energy-efficient execution. The Qameleon programming environment will be designed to teach at the undergraduate level by incorporating research results into new undergraduate courses aimed at both computer scientists and domain scientists alike.","title":"Qameleon: Hardware\/software Co-operative Automated Tuning for Heterogeneous Architectures","awardID":"0903447","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7786","name":"MCDA"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":["556658","558498"],"PO":["366560"]},"153602":{"abstract":"TITLE: Spectral analysis, spectral algorithms, and beyond<br\/><br\/> Spectral algorithms and spectral analysis form the basis for some of the most efficient and effective techniques in areas ranging from machine learning to scientific computing, from graphics to data mining, and from collaborative filtering to VLSI design. They also play a prominent role in combinatorial optimization, where they are used in algorithms for graph partitioning and constraint satisfaction.<br\/> Despite the apparent utility of spectral techniques and the intense effort devoted to their analysis, our ability to reason about them rigorously is still very limited. This project addresses the development of an algorithmically-centered theory of spectral analysis which draws upon tools from contemporary mathematics, and is inspired by experimental evidence which has, so far, eluded a satisfactory theoretical explanation. The project also addresses the relative power of spectral methods from the viewpoint of computational complexity.<br\/>This involves the both the study of what cannot be done using only information about eigenvalues and eigenvectors, as well as what can be achieved by combining spectral analysis with classical combinatorial approaches, like computation of graph flows.","title":"AF: Small: Spectral analysis, spectral algorithms, and beyond","awardID":"0915251","effectiveDate":"2009-08-15","expirationDate":"2013-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7933","name":"NUM, SYMBOL, & ALGEBRA COMPUT"}}],"PIcoPI":["517683"],"PO":["565251"]},"153746":{"abstract":"Hash-based data structures and algorithms are currently a booming industry in the Internet, particularly for applications related to measurement, monitoring, and security. Hash tables and related structures such as Bloom filters are used billions of times a day, and new uses keep proliferating. There remain, however, large gaps between the theoretical design and analysis of these structures and their use and implementation in practice. This research aims to bridge the gap between the theory and practice of algorithms and data structures that utilize hashing, with an emphasis on networking applications. The outcomes of this research will include tools and frameworks for translating theoretical results into real-world settings, better analyses and implementations of existing algorithms and data structures, and the development and analysis of new algorithms and data structures. Related educational efforts will focus on methods to make undergraduate students, graduate students, and the professional networking community more aware of the potential and power of hash-based approaches, thereby expanding the reach and influence of theoretical work in the area.","title":"AF : Small : The Theory and Practice of Hash-Based Algorithms and Data Structures","awardID":"0915922","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":["560092"],"PO":["565251"]},"153647":{"abstract":"Abstract ? O?Brien (0915462)<br\/> This research project focuses on numerical and geometric methods for physically realistic simulation of objects and materials whose shapes are grossly deforming or changing. These methods use several techniques for dynamic mesh generation, wherein unstructured tetrahedral volume meshes and triangular surface meshes evolve or change through time to accommodate the movement of a highly deformable material. This research is leading to unprecedented simulation capabilities to evolve the meshes used for numerical techniques such as finite element methods and finite volume methods, while maintaining high-quality tetrahedra and triangles. These new algorithms will enable the simulation of phenomena that could not previously be modeled well because of the difficulty of simulating materials whose shapes change radically, such as body tissues during surgery or ballistics undergoing high-speed impacts. The technical contributions of this research fall into two classes. The first contribution is numerical methods that use dynamic mesh generation to bring better accuracy to simulations of elastoplastic solids and viscous fluids undergoing plastic flow, cutting, and fracture. The simulation and dynamic mesher are being coupled so that they locally conserve mass, energy, and momentum as a mesh evolves, and so that the refinement and anisotropy of the mesh are tailored to the physical problem. The second contribution is extensions of dynamic geometry algorithms developed by the researchers that more accurately model surface evolution, that enable a finer surface resolution than volume resolution, and that easily handle topological changes and self-collisions.","title":"HCC: Small: Simulating and Animating Materials with Dynamic Geometry","awardID":"0915462","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["563370",408891],"PO":["532791"]},"153768":{"abstract":"Abstract ? Zhang\/Wonka<br\/><br\/>The research investigates theory and efficient algorithms for pattern design on surfaces. Patterns on surfaces appear in many natural phenomena such as leaves, animal textures, and terrains as well as man-made objects such as origami, glass ornaments, and facades. Patterns can also be used to describe networks, such as street layouts, power grids, aqueducts, and sensor networks. Pattern design has a wide range of applications in art and entertainment, architecture, engineering, medicine, and city planning. In addition, theory and techniques developed in the research can benefit domains such as computational geometry and vector and tensor field visualization.<br\/><br\/>There are several fundamental challenges when it comes to pattern design on surfaces. First, there is a lack of unified mathematical formulations of patterns in terms of both symmetries and orientations contained in the patterns. Consequently, the aforementioned applications are typically addressed as being unrelated despite the intrinsic links between them. Second, many past approaches to these problems lack hierarchical control. This is required so that the user can design high level information down to occasionally low level specifics and the layout algorithms fill in the rest procedurally. In this research, the investigators explore a unified framework that allows hierarchical design of patterns on surfaces. In this framework, orientation and symmetry information is specified everywhere in the domain through tensor field design. Next, the tensor field which contains desired orientation and symmetry information is used to generate a complex which can be a point set, a graph, a tiling, or any combination of them. Finally, additional details are added onto the complex through texture and geometry synthesis, or sub-patterns are added inside the cells of the complex. Ideas from various mathematical domains such as dynamical systems, tensor calculus, differential geometry, and algebraic topology are borrowed and applied in this research.","title":"HCC: Small: Collaborative Research: Graph and Pattern Design on Surfaces","awardID":"0915990","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["455161"],"PO":["532791"]},"153658":{"abstract":"Reading aloud is a complex motor, perceptual, cognitive and linguistic feat that takes years to learn and master. Text is problematic for developing readers because punctuation does not reliably mark phrase units or appropriate pause structure; commas do not always necessitate a pause, and question marks do not always necessitate rising intonation. Young readers who are learning these conventions are left to decode the author's intended prosody by trial and error; even those who have accurate decoding skills often experience difficulty chunking text into meaningful units. As a result, they read in a word-by-word manner with insufficient prosodic variation, which adversely impacts their ability to comprehend what they have read aloud. Traditional reading instruction and software programs emphasize rapid, accurate decoding and word recognition; little or no emphasis is placed on facilitating expressive, prosodic oral reading. Yet prosodic cues such as fundamental frequency F0 (perceived as pitch\/intonation), intensity (perceived as loudness), and duration (perceived as length), convey a wide range of linguistic and affective functions that link the speech code to underlying semantic and syntactic content, which is crucial for language comprehension. In this project, the PI will explore a number of innovations to enable developing readers to read aloud with expression. She will design an interactive reading interface that displays prosodically varying text to help children read aloud fluently with appropriate expression. Prosodic targets (F0 contour, intensity envelop, and word and pause duration) will be derived from recordings made by a fluent adult reader and translated into textual manipulations using novel semi-automated acoustic-to-graphic mappings. The software will provide auditory and visual cues corresponding to the model adult production; near-real time visual and auditory feedback of the child's own production will enable self-monitoring to further support learning. The resulting electronic media will resemble a children's book, displaying a story image along with the corresponding prosodic text, and will include additional listening and recording functions. The software will be assessed using a repeated measures design, in which 32 children aged 6-8 years will read age and grade-level appropriate stories with and without the prosodic text. The PI's hypothesis is that providing explicit visual cues pertaining to the underlying prosodic targets will improve oral reading fluency, including accuracy, rate, and expressiveness. The additional cues may also provide the scaffolding to support comprehension of spoken text. Efforts to scale the prosodic text rendering techniques to a larger set of spoken content will be undertaken. Project outcomes will contribute to the fields of, digital signal processing, speech acoustics, speech and language development, reading acquisition, visual typography, and human-computer interaction.<br\/><br\/>Broader Impacts: The ultimate goal of this project is to inspire young readers to make the words on the page \"come alive\" through their expressive realization of the text. The PI expects the tools and methodologies developed in this work will also be applicable to improving spoken prosody for non-native speakers, for individuals with speech impairments, and for those with learning disabilities.","title":"HCC-Small: Displaying Prosodic Text for Reading Aloud with Expression","awardID":"0915527","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["485923"],"PO":["565227"]},"150743":{"abstract":"Proposal Title: RI: Medium Collaborative Research: Minimalist Mapping and<br\/>Monitoring<br\/>Institution: University of Illinois at Urbana-Champaign<br\/>Abstract Date: 05\/05\/09<br\/>\"This award is funded under the American Recovery and Reinvestment Act of 2009<br\/>(Public Law 111-5).\"<br\/>This project addresses fundamental and challenging questions that are common to<br\/>robotic systems that build their own maps and solve monitoring tasks. In particular, the<br\/>work contributes to our general understanding of the interplay between sensing, control,<br\/>and computation as people attempt to design systems that minimize costs and<br\/>maximize robustness.<br\/>Powerful new abstractions, planning algorithms, and control laws that accomplish basic<br\/>mapping and monitoring operations are being developed in this effort. This is expected<br\/>to lead to improved technologies in numerous settings where mapping and monotoring<br\/>are basic components.<br\/>Ample motivation is provided by technological challenges that involve searching,<br\/>tracking, and monitoring the behavior of people, wildlife, and robots. Examples include<br\/>search-and-rescue, security sweeps, mapping abandoned mines, scientific study of<br\/>endangered species, assisted living, ground-based military operations, and even<br\/>analysis of shopping habits.<br\/>The work is particularly transformative because it lives outside of the traditional<br\/>boundaries of algorithms, computational geometry, sensor networks, control theory, and<br\/>robotics. Furthermore, national interest continues to grow in the direction of developing<br\/>distributed robotic systems that combine sensing, actuation, and computation. By<br\/>helping to break down traditional academic and scientific barriers, it is expected that the<br\/>work will transform the way we think about robotics algorithms, the engineering design<br\/>process, and the education of students across the robotics, computational geometry,<br\/>and control disciplines.<br\/>NATIONAL SCIENCE FOUNDATION<br\/>Proposal Abstract<br\/>Proposal:0905523 PI Name:LaValle, Steven<br\/>Printed from eJacket: 05\/06\/09 Page 1 of 1","title":"RI: Medium: Collaborative Research: Minimalist Mapping and Monitoring","awardID":"0904501","effectiveDate":"2009-08-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["536698","495278"],"PO":["562760"]},"153900":{"abstract":"Future communication networks are envisioned be dynamic reconfigurable at the physical, label and routing layers forming a multiple layer communication infrastructure. In the resulting hierarchical structure each layer is a network on its own, having the flexibility to change the formation dynamically. There are also structural dependencies due to the multilayer infrastructure. For example, a link failure at a lower layer can impact multiple links at an upper layer. With dynamic changes in traffic demand, reconfigurability, and structural dependencies, future multilayer networks present new design challenges. In this project, future multilayer network design is addressed by considering routing properties of different layer networks, layer dependencies, virtualization, topological reconfigurability, and resiliency. For this, new optimization models are developed. As the problems can be large due to interdependencies, new design algorithms are developed that exploit the special structure of the problems. The exploration of multilayer networks with emerging technological possibilities leads to key insights that would benefit future networks in terms of efficient and robust network design, deployment, and operations. Expected results include new design models and algorithms. Studies conducted will provide deeper understanding of the overall system dynamics in terms of interdependencies in layers and trade-offs on functionalities to be invoked in different layers. All research results will be made available to the scientific community.","title":"NeTS:Small: Multilayer Reconfigurable Network Design and Optimization","awardID":"0916505","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["541801"],"PO":["564993"]},"150765":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>A significant majority of current Internet traffic is due to distributing content, yet the Internet was designed to be largely agnostic to characteristics of the content flowing over it. This research investigates the design and operation of a content-aware Internet ecosystem, which thrives on the interaction between users (seeking seek fast and correct downloads), content providers (seeking to minimize network congestion and transit traffic), and network providers (who generate content, and seek the cost- and resource-efficient dissemination). <br\/><br\/>This research takes a two-pronged approach. On one hand, it explores novel analysis of fundamental performance limits for a content-aware Internet ecosystem that rigorously characterizes the benefits of an intelligently designed cross-layer architecture. On the other hand, it includes developing mechanisms and practical implementation of a content distribution system, by which involved parties can interact constructively to achieve these gains yet respect each others' interests. This approach combines a range of techniques, including modeling and theoretical analysis, measurement and data analysis, system design, simulation, and system implementation. Affordable and ready access to digital content helps inform, educate, and entertain society as a whole. Additionally, by developing cost- and resource-effective delivery techniques, the friction continuing to build between involved parties can be reduced and the technical side of the network neutrality debate can be better informed. To enhance this impact, the project includes an educational component involving local universities from under-represented groups, curriculum development and interactions with industry.","title":"NeTS: Medium: Collaborative Research: Designing a Content-Aware Internet Ecosystem","awardID":"0904609","effectiveDate":"2009-08-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560159"],"PO":["565090"]},"160456":{"abstract":"This project develops proof-of-concept examples for a novel graph visualization technique named Link Free Graph Visualization (LFGV). The research addresses problems in existing graph visualization techniques: (1) becoming cluttered when visualizing large graphs; (2) having limited applicability to complex graphs, such as graphs with high dimensional node attributes and time evolving graphs; (3) misleading users due to the information loss caused by 2D or 3D node layouts and efforts toward increasing scalability. <br\/><br\/>The research leads to new graph visualization techniques with better scalability, better applicability to complex graphs, and less misleading insights than NLDs. LFGV first projects a graph to a multidimensional space while preserving major graph topology information. LFGV then uses extended multidimensional visualization techniques to visualize the projection for exploring graph topology and other information carried by the graph, such as multidimensional node attributes. This project develops a working LFGV prototype for plain\/multivariate graphs and conducts evaluations to prove that LFGV is viable. It also develops a weblog visual analysis approach to provide a test bed and an application example for LFGV. <br\/><br\/>Graph visualization is widely used in lots of applications, such as social network analysis, bioinformatics, and web information exploration. LFGV impacts the application fields where large complex graphs need to be analyzed. The weblog visual analysis approach has a direct impact on online information browsing, retrieval, and analysis. The project publishes software for research and educational purposes.","title":"EAGER: Link Free Graph Visualization for Exploring Large Complex Graphs","awardID":"0946400","effectiveDate":"2009-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["536619","563306"],"PO":["564316"]},"152613":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Moore?s law promises consistent increasing transistor densities for the foreseeable future. However, device scaling no longer delivers the energy gains that drove the semiconductor growth of the past several decades. This has created a design paradox: more gates can now fit on a die, but cannot actually be used due to strict power limits. In this project, we will address this energy crisis through the universal application of ?near-threshold computing? (NTC), where devices operate at or near their threshold voltage to obtain 10X or higher energy efficiency improvements. To accomplish this we focus on three key challenges that to date have kept low voltage operation from widespread use: 1) 10X loss in performance, 2) 5X increase in performance variation, and 3) 5 orders of magnitude increase in functional failure. We present a synergistic approach combining methods from algorithm and architecture levels to the circuit and technology levels. We will demonstrate NTC for applications that range from sensor-based platforms which critically depend on ultra-low power (&#8804;mW) and reduced form factor (mm3) to unlock new applications, to high-performance platforms in large data-centers, which dissipate so much power that they require co-location near dedicated cooling facilities. Our end goal is to reduce national energy consumption and environmental impact by providing dramatic gains in energy efficiency while also opening up new application areas in health care by providing for in situ monitoring of biological functions with minimum intervention.","title":"CSR:Large:Collaborative Research:Reclaiming Moore's Law through Ultra Energy Efficient Computing","awardID":"0910851","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["535404","517834","517835"],"PO":["565255"]},"153713":{"abstract":"Audit logging is a fundamental component of a comprehensive data security and privacy infrastructure. It is complementary to other access control and security mechanisms, and is particularly useful for recording inappropriate data access by insiders. Recent legislation and regulatory oversight require organizations in a variety of domains to maintain audit logs tracking their use of data, and commercial database systems are beginning to provide support for automatically recording all data accesses.<br\/><br\/>The first main goal of this project is to develop tools to support easy and proactive analysis of logged information. The system will leverage the strengths of both declarative queries (e.g., SQL) and statistical anomaly detection. Using the new framework, for example, rather than simply flagging incoming queries as anomalous based on a pre-trained set of profiles or rules, an analyst will be able to craft custom exploratory queries and visual representations. In support of such a tool, the research team at RPI will design and build an independent subsystem, called Splash, which extends the functionality of a relational DBMS to incorporate support for managing statistical models.<br\/><br\/>Though audit logs are collected in the name of security and accountability, in certain situations the logs themselves may pose a risk to the privacy of users who access an underlying database. The second main goal of this project is to develop tools for managing the privacy risks associated with collecting and storing audit logs. Students will be engaged throughout the research program. The software will be distributed through open source software.","title":"TC: Small: Analysis and Privacy Tools for Enterprise Database Audit Logs","awardID":"0915782","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["451132","533266"],"PO":["565136"]},"152624":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>The burgeoning revolution in high-end computer architecture has far reaching implications for the software infrastructure of tools for performance measurement, modeling, and optimization, which has been indispensable to improved productivity in computational science over the past decade. The heart of the problem is that new multicore processors are the foundation of next generation systems, ranging from workgroup clusters to petascale supercomputers. The main motivation by chip manufacturers for the movement to multicore processors is better performance per watt than the traditional single core processor. Hence, multicore processors are not equivalent to multiple CPUs that traditional tools addressed. While significant work is underway on understanding performance tradeoffs with multicores, much of this work is ad hoc and needs a unifying framework to which the community can contribute in a systematic manner. Furthermore, little work has been done on understanding performance-power tradeoffs in supercomputer systems for large-scale applications. It is important to understand performance and performance-power tradeoffs in the context of the significant resource sharing that occurs in multicore systems. <br\/><br\/>This proposal is focused on developing the Multicore Application Modeling Infrastructure (MAMI) that will facilitate systematic measurement, modeling, and prediction of performance, power consumption and performance-power tradeoffs in multicore systems. In addition to developing MAMI, the proposed work will use MAMI to model, analyze and optimize performance and power consumption of key benchmarks and applications on multicore systems.","title":"CSR: Large: Collaborative Research: Multi-core Applications Modeling Infrastructure (MAMI)","awardID":"0910899","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["486078","486080"],"PO":["565255"]},"150446":{"abstract":"Microprocessor performance has doubled approximately every 18 months for several decades, making existing applications faster without much programming effort and allowing more demanding new applications to be developed. However, now the trend of steadily improving performance for existing applications has stalled. The performance potential of a microprocessor chip is still rapidly increasing, but the increase now mainly comes from packing more and more processor cores onto the chip, not from making each core faster. This provides little benefit to existing applications that can only utilize one core, so they must be re-designed to take advantage of multiple cores. Unfortunately, correct design of multi-core applications is much harder to achieve than was the case for single-core applications, and it is even harder for programmers to achieve scalability ? enabling applications to keep improving their performance as even more cores become available in the future. This problem threatens to disrupt the entire hardware-software ecosystem and possibly put an end to rapid improvements in computing performance, the information technology revolution, and the resulting productivity increases.<br\/><br\/>This research project will investigate hardware and software performance debugging mechanisms that would help programmers identify and alleviate performance problems in their many-core applications, both for use in application development and in education. This will help the information technology revolution stay on track by helping existing programmers and training new ones to write scalable many-core applications that will in turn create demand for even more cores, allowing rapid progress in computing performance to continue.","title":"Performance Debugging Support for Many-Core Processors","awardID":"0903470","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7786","name":"MCDA"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":["550974"],"PO":["559883"]},"153966":{"abstract":"Project ID: 0916752 <br\/>Title: The Chip Is the Network: Rethinking the Theoretical Foundations of Multicore Architecture Design<br\/>PI Name: Radu Marculescu<br\/>Institution: Carnegie-Mellon University<br\/><br\/>ABSTRACT<br\/>Recent advances in CMOS technology allow the integration of tens or hundreds of individually programmable processing elements, together with large amounts of dedicated memory, on the same system-on-chip (SoC). In such multiprocessor systems, individual processing nodes can communicate and coordinate via networks-on-chip (NoCs). Therefore, a major challenge is to determine the mathematical techniques for designing and optimizing such on-chip networks in a rigorous manner. Traditional queuing and Markov chain approaches to buffer allocation are helpful to a certain extent, but capturing the traffic variability represents a major problem. Starting from these overarching ideas, this project introduces a new statistical-physics approach for performance analysis in multiprocessor SoCs. More precisely, we develop a completely new mathematical description of network traffic using an analogy between a Bose gas and the information flow in the communication network. This new modeling paradigm where networks are seen as gases can be further used to develop efficient on-chip buffer assignment algorithms. <br\/><br\/>The new design methodology enables the development of more efficient multiprocessor SoCs which have a dramatic impact on society via applications ranging from entertainment to gaming to security and to bio- and gene engineering. More broadly, the results of this project impact significantly other research communities by improving the level of understanding of networking concepts needed to design and control complex systems.","title":"SHF: Small: The Chip Is the Network: Rethinking the Theoretical Foundations of Multicore Architecture Design","awardID":"0916752","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["554461"],"PO":["562984"]},"161249":{"abstract":"The requested amount of the revised budget is equal to $95,725.00 and the difference with the original budget will be covered by the cost share of $10,206.00 that Michigan Tech will provide. The total budget includes two months of summer salary for Dr. Ebnenasir and 18 months of graduate student support spanned over 12 months. One graduate student who has been involved in the preliminary investigations of this project during past 4 months will be supported by this project for the entire 12 months. Another PhD student -- who will participate in Task 3 -- will be supported for the final 6 months of the project.","title":"EAGER: Towards the Model Checking of the Partitioned Global Address Space (PGAS) Applications","awardID":"0950678","effectiveDate":"2009-08-15","expirationDate":"2012-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7933","name":"NUM, SYMBOL, & ALGEBRA COMPUT"}}],"PIcoPI":[431308,"485796"],"PO":["565251"]},"153538":{"abstract":"Although many different approaches to 3D displays have been explored for decades, the dominant technology in practical use has been of the stereoscopic type, which provides a sense of depth by presenting two perspective images, one for each eye, of a scene from two slightly different viewing positions. A problem inherent to this approach is the lack of correctly rendered focus cues, which stems from the fact that the pairs of stereoscopic images are typically presented on 2D flat surfaces at a fixed distance from the eye. As a result, retinal image blur does not vary with the distances from an eye fixation point to other points at different depths in the simulated scene, but remains consistent with the fixed distance of the display surface. And the eye accommodation depth tends to be at the fixed distance of the 2D display while the eyes are forced to converge at different distances to view objects at different depths. Psychophysical studies have suggested that these incorrect focus cues may contribute to the compressed depth perception and visual discomfort commonly reported when viewing stereoscopic images, which have profound implications for adopting stereoscopic displays for a wide range of applications. In this project, the PI will develop an alternative 3D display based on depth-fused multifocal plane technology that offers more accurate rendering of the focus cues than conventional stereoscopic displays. Instead of focusing on the engineering aspects of developing a better 3D display, she will pursue a human-centered approach wherein human observers participate in the design process for a multi-modal 3D display platform that allows flexible adaptation of the display along multiple display modalities with different levels of focus cue accuracy, from the basic stereoscopic display mode to advanced display modes with correct or partially correct focus cues. The PI will carry out pilot experiments to validate the functions of different display modalities and to evaluate the effects of focus cues on depth perception.<br\/><br\/>Broader Impacts: The new technology will offer a display solution with higher depth perception accuracy, higher stereo acuity, faster task performance, and less eye fatigue than currently available systems. Project outcomes will furthermore provide a much-needed research tool that supports investigation under controlled conditions of the various factors potentially contributing to depth perception accuracy and visual fatigue, as well as exploration of critical health issues such as the consequences for vision development in children of protracted viewing of stereoscopic images.","title":"HCC: Small: Enabling Focus Cues in Stereoscopic Displays","awardID":"0915035","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["485281"],"PO":["565227"]},"146509":{"abstract":"Software is comprised of a multitude of artifacts; some of them are intended to be read by the compiler, while many others are intended to be read by developers. The user centric information is often expressed in natural language and it is usually much larger in size than the source code. Given the amount of unstructured data present in existing software systems, tools are necessary for its storage, retrieval, and analysis, before it is delivered to the users. This type of information is essential during software evolution, when developers need it to understand the software.<br\/><br\/>The research will define and evaluate an infrastructure for the management of the textual information present in software systems. The infrastructure will make use of Information Retrieval techniques in combination with statistical and rule-based Natural Language Processing methods and other text analysis techniques. The infrastructure will be used do define a new type of conceptual model of a software system that will complement the structural, behavioral, and architectural models, which can be extracted and built with traditional analysis and modeling methods. The new conceptual model and infrastructure will be used to define novel methodologies and build tools to support a variety of software evolution tasks, such as: change propagation in software, traceability link recovery between software artifacts, error and change prediction, quality measurement, concept location, refactoring, and program comprehension in general. The planned infrastructure will offer a platform for researchers from different areas of computer science (such as, software engineering and computational linguistics) to use state of the art results from each field. The empirical work will result in a repository of software artifacts and analysis data of textual nature from software to be used to support rigorously controlled experimentation and benchmarking in the research community.","title":"CAREER: Management of Unstructured Information During Software Evolution","awardID":"0845706","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["511418"],"PO":["564388"]},"150711":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/><br\/>In the last few years, universally composable (UC) security, defined and extensively investigated by Ran Canetti, has become a popular and important topic in modern cryptography. Canetti's notion has enormous appeal, promising a unified framework under which one can define virtually any cryptographic protocol goal, and further promising that the resulting definitions will be composable in the sense that a protocol solution for some goal will comprise a suitable primitive to use within any other protocol that desires its abstracted functionality. But UC goals are definitionally complex--in fact, the definitions can take tens of pages of English prose to simply write down, and, even then, significant ambiguities may remain. <br\/><br\/>In this project, Dr. Phillip Rogaway explores an alternative descriptive language for specifying UC goals. Instead of describing the execution model in English, it will be described within the framework of code-based game-playing. Under this descriptive language, a UC definition will be described using a program, the program setting variables that induce a clear and precise notion of adversarial advantage. <br\/><br\/>Dr. Rogaway will demonstrate the feasibility and practical value of his approach by applying it to universally composable signature schemes. This will be an important first step towards making unambiguous and verifiable UC definitions accessible to the general cryptographic community and those they serve.","title":"TC: Medium: Reimagining Cryptography by Identifying its Culturally-Rooted Assumptions","awardID":"0904380","effectiveDate":"2009-08-15","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["548342","521666","548202"],"PO":["565264"]},"150997":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Probabilistic graphical models provide a powerful mechanism for representing and reasoning with uncertain information. These methods have been successfully applied in diverse domains such as bioinformatics, social networks, sensor networks, robotics, and web mining; in turn, such application areas have posed new computational challenges driving graphical model research. This project is motivated by challenges in emerging application areas such as epidemiological simulation, geoscience modeling, and studies of interacting proteins, where there are rich sets of information of multiple types and at multiple levels of granularity. While the methods developed will be general, the research will focus on protein-protein interactions, which drive the molecular machinery of the cell by forming transient or persistent complexes to propagate signals, catalyze reactions, transport molecules, and so forth. The mixed-mode information available includes amino acid sequences, three-dimensional structures and associated physical models, and binary, rank-ordered, or even quantitative interaction data. The proposed techniques address key challenges in information integration, prediction, and generation using graphical models. <br\/><br\/>Intellectual merits: <br\/>The intellectual merits of this work derive both from the new capabilities for information integration and for reasoning with probabilistic graphical models, as well as their application to the study of protein-protein interactions. Proteins offer, by far, some of the most complex, multi-faceted datasets for integration using computational methods; hence the lessons learned here can be applied to similarly rich information spaces, such as epidemiology and geosciences. These integrated models of interacting proteins and new algorithms for prediction and generation will also support significant applications such as protein engineering and systems biology, bridging interaction networks to the underlying residue-level interactions in order to better understand and control them. <br\/><br\/>Broader impacts: <br\/>This project will reach out to both the bioinformatics and larger computer science communities to maximize the impact of our contributions. An open-source integrator platform will be developed, aimed at integrating protein datasets and which can be extended to information integration in other domains as well. To stimulate community building and foster discovery, the research team will advocate situating computer science research in the context of concrete applications. Building on prior successes, the team will organize a workshop at a suitable venue such as ICML\/AAAI\/NIPS\/KDD focused on an 'information integration challenge' dataset involving protein modeling. Finally, through programs such as Women@SCS at Carnegie Mellon, WISP (Women in Science Program) at Dartmouth, Howard Hughes education grant internships at Purdue, and the MAOP\/VTURCS (Minority Academic Opportunities Program and VT Undergraduate Research in Computer Science) program at Virginia Tech, the team will provide cross-disciplinary training to undergraduate students from underrepresented groups. <br\/><br\/><br\/>Keywords: Probabilistic Graphical Models, Information Integration, Mixed-Mode Datasets, Bioinformatics, Proteins, Markov Chain Monte Carlo (MCMC) methods.","title":"III: Medium: Collaborative Research: Integration, Prediction, and Generation of Mixed Mode Information using Graphical Models, with Applications to Protein-Protein Interactions","awardID":"0905416","effectiveDate":"2009-08-15","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["461949"],"PO":["565136"]},"163944":{"abstract":"Alexey I. Ovchinnikov proposes to develop efficient algorithms that determine the differential, difference, and algebraic structure of solutions of difference equations using methods of differential, difference, and computer algebra. The investigator has successfully contributed to the development of computational differential ideal theory and the Galois theory of linear differential equations. He will apply these results and methods to give efficient algorithms that compute properties of systems of difference equations. These properties are reflected in characteristic sets and Galois groups of the equations. In particular, the investigator will develop algorithms to reduce systems of non-linear difference equations to simpler systems. These algorithms test consistency of the input system and eliminate variables from the equations of the system. He will also give a Galois theory of linear difference equations with difference parameters to study difference algebraic dependences among solutions of difference equations.","title":"CISE-CCF-AF-Algebra: SGER: Computational Methods for Systems of Difference Equations","awardID":"0964875","effectiveDate":"2009-08-16","expirationDate":"2010-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7933","name":"NUM, SYMBOL, & ALGEBRA COMPUT"}}],"PIcoPI":[438881],"PO":["550329"]},"153802":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Opportunistic communication leverages communication opportunities arising by chance to provide significant performance benefit or even enable communication where it would be impossible otherwise. This project develops algorithms, techniques, and protocols that optimize opportunistic communication to achieve good, predictable performance in wireless mesh networks and vehicular networks.<br\/><br\/>A key challenge involved is how to systematically optimize opportunistic communication to achieve good predictable wireless performance. The research addresses the challenge by making three major contributions. First, the PIs develop novel robust optimization techniques that systematically optimize opportunistic communication even in the presence of high uncertainty. Second, they design efficient models, measurement and inference techniques, and prediction algorithms to obtain the required inputs to the optimization algorithms. Third, they exploit inter-flow coding opportunities arising from multi-flow diversity to further enhance the efficiency of opportunistic communication. To demonstrate the effectiveness of the approaches, the PIs design, implement, and experiment in a wireless mesh network and a vehicular network testbed deployed at UT Austin.<br\/><br\/>The project produces publications in leading network conferences and journals, and software that is publicly available online. The resulting techniques and software significantly advance wireless mesh network and vehicular network technology, and benefit other wireless network environments. The research results are also integrated into undergraduate and graduate curricula as well as outreach activities.","title":"NeTS: Small: Predictable Optimization of Opportunistic Communication","awardID":"0916106","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["266247","560223"],"PO":["565303"]},"153956":{"abstract":"Today people make novel uses of social networking and other internet software to respond to tragic events in creative and dynamic ways. Since shortly after the April 16, 2007 shootings at Virginia Tech, this research group has integrated digital library, data and text mining, information visualization, and social network analysis techniques to help with understanding and recovery from this tragic school crisis. This proposal is meant to research and develop a next- generation domain specific digital library software suite, the Crisis, Tragedy and Recovery (CTR) -toolkit, building upon 17 years of work on digital libraries, as well as expertise in information retrieval, data and text mining, database management, human-computer interaction, and sociology. Advanced intelligent information integration methods have not been sufficiently applied to this domain. The impact of events is felt over extended periods, requiring longitudinal perspectives to understand their complexity and inter-dependencies. Consequently, with the Internet Archive and other partners, the group will begin to create CTRnet, an integrated distributed digital library network for providing a rich suite of CTR-related services. Such work will help ensure that further tragic events might be better understood and prevented.","title":"III:Small:Integrated Digital Library Support for Crisis, Tragedy, and Recovery","awardID":"0916733","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["550462","550463","550464","498314","550465"],"PO":["543481"]},"150447":{"abstract":"Recent trends in microprocessor design are shifting toward incorporation of heterogeneous core types onto the same die. However, current design techniques provision only a fixed set of cores and suffer from poor resource utilization when the workload is not a good match for those resources and the system cannot efficiently employ all resources simultaneously. Hardware should adapt the organization of the heterogeneous cores in response to dynamic behavior. <br\/>This project lays the groundwork for realizing such a dynamic heterogeneous processor - the field programmable core array (FPCA) - that is capable of simultaneously implementing many heterogeneous architectural configurations on a configurable, homogeneous platform. The required flexibility will be provided through a combination of architecture, circuit, and EDA advances. <br\/><br\/>The intellectual merit of this project is the technique of separating a processor's front end and functional units into homogeneous pools of building blocks, and development of a programmable interconnect allowing these building blocks to be coupled and decoupled dynamically, enabling efficient intra- and inter-core connectivity and the assembly of a variety of heterogeneous organizations. The broader impact will be the development of a new design paradigm that allows the same chip to be used for a wider range of markets and workloads. This reduces design and procurement costs, while improving programmer productivity - all of which will provide economic and social benefits. This project also includes education and outreach activities, including improved teaching of emerging programming models and outreach to high school students and underrepresented groups.","title":"Heterogeneous Multi-core Architectures from Homogeneous Arrays using Configurable Interconnect","awardID":"0903471","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7786","name":"MCDA"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":["489873","527785","485695"],"PO":["366560"]},"153725":{"abstract":"The objective of this project is to understand, evaluate, and contribute towards the suppression of sensitive aggregates over hidden databases. Hidden databases are widely prevalent on the Web, ranging from databases of government agencies, databases that arise in scientific and health domains, to databases that occur in the commercial world. They provide proprietary form-like search interfaces that allow users to execute search queries by specifying desired attribute values of the sought-after tuple(s), and the system responds by returning a few (e.g., top-k) satisfying tuples sorted by a suitable ranking function.<br\/><br\/>While owners of hidden databases would like to allow individual search queries, many also want to maintain a certain level of privacy for aggregates over their hidden databases. This has implications in the commercial domain (e.g., to prevent competitors from gaining strategic advantages) as well as in homeland-security related applications (e.g., to prevent potential terrorists from learning flight occupancy distributions). The PIs' prior work pioneered techniques to efficiently obtain approximate aggregates over hidden databases using only a small number of search queries issued via their proprietary front-end. Such powerful and versatile techniques may also be used by adversaries to obtain sensitive aggregates; thus defending against them becomes an urgent task requiring imminent attention. This project investigates techniques to suppress the sensitive aggregates while maintaining the usability of hidden databases for bona fide search users. In particular, it explores a solution space which spans all three components of a hidden database system: (1) the back-end hidden database, (2) the query processing module, and (3) the front-end search interface. The intellectual merit of the project is two-fold: (1) problem novelty: it initiates a new direction of research in information privacy of suppressing sensitive aggregates over hidden databases, and (2) solution novelty: it investigates a variety of promising techniques across the three components. The outcomes of this research have broader impacts on the nation's higher education system and high-tech industries. Parts of the project will be carried out by students of the University of Texas Arlington and George Washington University as advanced class projects or individual research projects.","title":"III: Small: Collaborative Research: Suppressing Sensitive Aggregates Over Hidden Web Databases: a Novel and Urgent Challenge","awardID":"0915834","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["464575"],"PO":["565136"]},"153967":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>This project will develop a novel tool, named Sunshine, to effectively support joint evaluation and design of sensor network (sensornet) hardware and software. <br\/><br\/>Intellectual Merit: <br\/>A critical roadblock to the success of sensornets is the prohibitively slow and energy-wise impractical software implementations of many important applications. On the other hand, specialized hardware implementation can outperform, energy-wise as well as performance-wise, equivalent software implementations by orders of magnitude. Hence, the joint software-and-hardware design of sensornet applications is a very appealing, yet unexplored, approach. The objective of this project is to develop an effective tool, named Sunshine, to support such codesign. This project may fundamentally transform the relationship between the hardware and software communities of sensornet research. These communities can use Sunshine to efficiently exchange mutual requirements and spread the latest technology advances in each other's fields. Such evolutionary change will greatly improve the state-of-the-art in sensornet technology. Novel hardware architecture and platforms that are unexplored in current designs can be created and tested through Sunshine's cross-domain design environment. <br\/><br\/>Broader Impact: <br\/>Serving as a valuable education tool, Sunshine will also foster the continued integration of research and education at the PIs' institution and benefit curriculum at other institutions. Sunshine can serve as the foundation for lab experiments and course projects in networking and embedded system engineering. Sunshine also offers the opportunity for innovative cross-domain education.","title":"NetSE: Cross-domain Design Tools for Sensor Network and Architecture","awardID":"0916763","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["548205","521677"],"PO":["564924"]},"153869":{"abstract":"Existing anti-spam techniques, such as spam filters and reputation systems, face growing difficulties due to spammers' use of multimedia content (which is hard to filter) and botnets (which mask true spammer identity and thus handicap reputation systems). Te goal of this project is to complement these existing efforts by targeting email address distribution channels, where lists of addresses are bought and sold among unscrupulous parties. <br\/><br\/>As a first necessary step, this project?s goal is to better understand the email trafficking phenomenon. This is a unique opportunity to study email spam in conjunction with email address trafficking. The team recently built a system for Internet users that, as a side effect, is able to collect the data that would contain information necessary for this analysis. Second, they secured cooperation from the Case Western Reserve University IT organization to test-deploy this system for up to 500 users and keep it in place for at least a year, which would allow them to collect a trove of data for a large-scale study and analysis. This proposal will study spam from a unique perspective ? email address trafficking. While previous studies characterize spam by considering email content and senders, address trafficking represents an important aspect of the spam problem, and better understanding of address trafficking can open new effective ways to combat spam. The broader impact includes its potential for better mechanisms to combat spam, for fostering collaboration with data mining faculty within the department, and for enhancing graduate and undergraduate education by adding material on application-level network security to, respectively ?Internet Applications? graduate course and to the ?Computer Networks? core undergraduate course.","title":"TC: Small: Understanding the Roots of the Spam Problem -- Email Address Trafficking","awardID":"0916407","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[409444],"PO":["565136"]},"153517":{"abstract":"This project will employ a cyclical two-step process to develop a computational model that embeds dynamic expression and socially engaging non-verbal gestures into talking avatars, and experimentally tests its usability within digital virtual environments involving human-digital agent interaction. Specifically, the research objectives of this project include: (1) synthesis of expressive talking faces and modeling of dynamic facial expressions, (2) synthesis of socially engaging non-verbal facial gestures, and (3) in-depth usability studies on resultant avatars. <br\/><br\/>Digital immersive virtual environment technology has enormous implications for human-computer interaction. Many qualities of digital human representations, particularly those of human-appearing agents, are important for social engagement and social influence. In particular, non-verbal behaviors play a critical role. Among such behaviors, arguably the most important are facial expressions of emotion, which are critical for meaningful renderings of digital agents. To date, computational models that would permit such renderings are less than optimal. Indeed, an applicable and systematic computational model for rendering spontaneous, on-the-fly non-verbal facial gestures and integrating them with speech has not been created. <br\/><br\/>The success of this proposed project will remove a major barrier to the widespread application of useful digital human representation technology for all applications in which computer-mediated communication can play a role, including commerce, education, health, engineering, and entertainment applications. In addition, it will have far-reaching scientific implications, providing a computationally tractable mechanism for embedding human qualities into computer-controlled entities that are used in other scientific and engineering fields.","title":"HCC:Small:Collaborative Research:Design and Evaluation of Socially Engaging Avatars","awardID":"0914965","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["421224"],"PO":["564456"]},"153649":{"abstract":"This project will employ a cyclical two-step process to develop a computational model that embeds dynamic expression and socially engaging non-verbal gestures into talking avatars, and experimentally tests its usability within digital virtual environments involving human-digital agent interaction. Specifically, the research objectives of this project include: (1) synthesis of expressive talking faces and modeling of dynamic facial expressions, (2) synthesis of socially engaging non-verbal facial gestures, and (3) in-depth usability studies on resultant avatars. <br\/><br\/>Digital immersive virtual environment technology has enormous implications for human-computer interaction. Many qualities of digital human representations, particularly those of human-appearing agents, are important for social engagement and social influence. In particular, non-verbal behaviors play a critical role. Among such behaviors, arguably the most important are facial expressions of emotion, which are critical for meaningful renderings of digital agents. To date, computational models that would permit such renderings are less than optimal. Indeed, an applicable and systematic computational model for rendering spontaneous, on-the-fly non-verbal facial gestures and integrating them with speech has not been created. <br\/><br\/>The success of this proposed project will remove a major barrier to the widespread application of useful digital human representation technology for all applications in which computer-mediated communication can play a role, including commerce, education, health, engineering, and entertainment applications. In addition, it will have far-reaching scientific implications, providing a computationally tractable mechanism for embedding human qualities into computer-controlled entities that are used in other scientific and engineering fields.","title":"HCC:Small:Collaborative Research:Design and Evaluation of Socially Engaging Avatars","awardID":"0915472","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[408895],"PO":["564456"]},"150712":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Over the past decade, new and exciting technologies have created opportunities for developing rich open-ended learning environments that combine a number of different learning paradigms and resources. Students can complete quests in game environments, engage in inquiry, interact with virtual agents, run science simulations, take quizzes, access the web, and more generally make choices about different learning activities. These choices can be extremely informative about student learning and diagnostic of what students can learn once they leave highly scripted curricula. By employing machine learning methods, such as hidden Markov Models and other sequence analysis algorithms to analyze student choices in relatively open learning environments and determine whether students are showing (sub) optimal behavior patterns, the environment can then adapt intelligently by encouraging (alternative) choices and better learning behaviors. The primary hypothesis is that helping students develop the metacognitive abilities to make learning choices will have strong effects on their subsequent abilities to learn in the future in unstructured and unsupervised but resource-rich environments. The goals for this project are to create: a) Choice adaptive intelligent learning environments and computational methodologies that help students develop strategies to enable them to learn on their own; b) Novel automated assessment tools for both teachers and students that link choice and learning behaviors to learning performance; and c) Research studies that will establish whether our interventions that combine choice with guidance is beneficial for both strong and weak learners in science domains.<br\/><br\/>The broader impacts of this work span multiple dimensions. First, it provides an encompassing computer science framework for bringing together a number of technology-rich, interactive environments that are proliferating for education into a common choice filled and adaptive architecture. Second, this choice-based framework provides a paradigm shift in that tracking and theorizing about choice is applied in the context of learning, which, in the past, has been dominated by characterizations of the knowledge construct. Characterizing learning by choice not only connects learning research to a larger body of social science research, it is also a fundamentally new way to characterize and guide learning that is closer to the goal of much instruction, namely intelligent future choice. Third, the computer environment should permit the collection and analysis of large log files by many researchers, and conceivably lead to a new database of common choice patterns and their effects on learning. We will create the framework that enables others to incorporate intelligence into their virtual worlds and help achieve these proposed outcomes.","title":"HCC: Medium: Collaborative Research: Formal Analysis of Choice-Adaptive Intelligent Learning Environments (FACILE) that support Future Learning","awardID":"0904387","effectiveDate":"2009-08-01","expirationDate":"2012-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["536406"],"PO":["564456"]},"160656":{"abstract":"Project Summary<br\/>Proposal #: 0947670<br\/>PI: Ashish Goel<br\/><br\/>We are used to thinking of DNA as a biological molecule. However, DNA, its cousin the RNA, and other associated molecules such as enzymes, are also engineering building blocks. Think of them as ?combinatorial Legos? which fit together and inter-operate not just by mechanics and geometry but also using the chemical sequence imprinted on them. This has many revolutionary potential applications. This also poses many mathematical and algorithmic questions which are both interesting in their own right and also provide a framework to devise useful experimental techniques. The PI proposes to conduct research in the emerging field of ?molecular algorithms?, i.e., algorithms which are meant to be implemented on molecules. This study will proceed in two broad directions: molecular machines and molecular circuits. The two areas are linked both thematically and in terms of techniques. We will constantly consult with practitioners in this field, so that the results of this research are both novel and useful.<br\/><br\/>Intellectual merit: Molecular algorithms require tools and techniques that are considerably different from traditional algorithms. We can not assume building blocks such as memories, actuators, sensors, transistors, processors etc; rather, these are often the things we are trying to devise using more basic primitives such as DNA hybridization, enzymatic reactions, and migration. Consequently, advances in molecular algorithms are likely to require novel mathematical techniques that will enrich the disciplines of coding theory, combinatorial algorithms, and probabilistic analysis.<br\/><br\/>Broad impact: Molecular machines have been proposed as sensors, actuators, and drug delivery mechanisms. Molecular circuits have the potential to finely control other molecular processes. Much of the hard work in developing these ideas is being done by experimentalists. However, theoretical tools such as the one we propose to develop also have an important role to play in realizing the full potential of this area and in deciding upon the most promising experimental directions. In addition, molecular algorithms could facilitate sophisticated tasks such as counting, shape recognition, precisely controlled crystal growth etc. at nano-scales.<br\/><br\/>The PI has developed a class in molecular algorithms which he will update and teach bi-annually. Also, many graduate students will receive valuable research experience in this important area.","title":"EAGER: Algorithmic aspects of molecular circuits and molecular machines","awardID":"0947670","effectiveDate":"2009-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7931","name":"COMPUTATIONAL BIOLOGY"}}],"PIcoPI":[429621],"PO":["565223"]},"150987":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111- 5). <br\/><br\/>The fundamental differences between multi-hop networks and point-to-point settings indicate that leveraging MIMO gains in multi-hop networks requires a paradigm shift from high SNR regimes to interference-limited regimes. This project undertakes a broad research agenda centered around developing fundamental theory towards achieving optimal throughput and delay performance in wireless networks. The first key step is to take a bottom-up approach for solid model abstraction of MIMO links while taking into account interference, and to extract a set of feasible rate\/reliability requirements, corresponding to meaningful MIMO stream configurations. Under a common thread of MIMO-pipe scheduling, this project focuses on tackling the following challenges: 1) Developing rate\/reliability models for ``MIMO-pipes'' in multi-hop networks; 2) MIMO-pipe scheduling for throughput maximization and delay minimization; and 3) Real-time scheduling of MIMO-pipes with delay constraints (for time-critical traffic). <br\/><br\/>This project contributes to the formulation of new fundamental theories for multi-hop MIMO networks, which have direct impacts on many wireless applications. Particularly, real-time scheduling sheds much light on leveraging MIMO gains in VANET to deliver timely information reliably to save lives and improve quality of life. Underrepresented undergraduate students as well as graduate students participate in this project.","title":"NeTS: Medium: Collaborative Research: MIMO-Pipe Modeling, Scheduling and Delay Analysis in Multi-hop MIMO Networks","awardID":"0905397","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["541861"],"PO":["557315"]},"150415":{"abstract":"High-end embedded systems such as smart phones, game consoles, GPS-enabled automotive systems, home entertainment centers, and other ?ambient intelligence? systems are becoming increasingly important in everyday life. Making such systems energy-efficient presents new challenges with broad implications for the economy and the environment. Such high-end embedded systems are multicore architectures, which require management of resources such as memory connectivity and scheduling. This proposal investigates the energy implications of system-level concurrency issues in high-end embedded systems that are not limited by real-time constraints. In particular, it aims to develop energy-efficient techniques of synchronizing memory accesses, and tries to understand the optimal division of tasks between hardware and software. <br\/><br\/>Embedded systems are an integral component of modern life, and is a continually growing market. As the computational needs of the products in this market becomes more sophisticated, there will be more challenges in meeting the tight constraints imposed by these systems. Improvements in the performance and in particular the energy efficiency of such devices would have a substantial impact in terms of improved functionality, device longevity, and resource conservation. This proposal involves collaboration between two disciplines, computer engineering and computer science, and two institutions. Broader impacts of the proposal include development of workshops focused on multicore and parallel computing with special emphasis on encouraging women and under-represented minorities to participate. In addition, the findings of this project will be integrated into existing courses, specifically aiming to introduce cross-cutting issues between the computer science and engineering courses.","title":"Collaborative Research: Energy-Aware Memory Synchronization for Embedded Multicore Systems","awardID":"0903384","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7786","name":"MCDA"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":["554181","550256"],"PO":["366560"]},"150426":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The objective of this research is to develop solutions that ensure reliable power delivery in high-performance multicore systems. Technology trends for multicore chips show increased on-chip noise sources, decreasing supply voltage levels, and reduced headroom for noise: together these make the problem of on-chip power supply noise, which can cause a circuit to be nonfunctional, acutely difficult. The approach is based on an integrated strategy that incorporates novel design techniques, bolstered by computer-aided design (CAD) strategies to build reliable on-chip power distribution systems.<br\/><br\/>The design thrust of the project will develop novel multicore-specific circuits, including switched decoupling capacitor (decap) circuits and active decaps, to actively cancel the supply noise in cores that suffer from large switching current. The modeling and CAD aspects will focus on analyzing multicore power grids containing a mix of these novel structures and traditional methods, and optimizing these grids using pre-silicon. Additionally, the PIs will develop CAD techniques to build adaptive structures into the circuit in the pre-silicon phase, in order to enable sensor-driven adaptive post-silicon power grid noise mitigation.<br\/><br\/>Solutions from this research will facilitate the design of next-generation high-performance, low-voltage systems for computing and communication applications, and will be demonstrated on prototype implementations. The PIs plan to transfer technology through direct industrial collaborations, particularly leveraging this project's connections with the Semiconductor Research Corporation. The PIs will proactively recruit and nurture students from under-represented groups and develop new course materials for the undergraduate and graduate curriculum in the areas of electronics, chip design, and CAD.","title":"An Integrated Design and CAD Approach for Efficient Power Delivery in Multicore Processors","awardID":"0903427","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":["541006","508418"],"PO":["565185"]},"152615":{"abstract":"The evolution of the \"human Web,\" powered by HTML and HTTP, has revolutionized the way that people find information, buy things, communicate, and collaborate. Web services and semi-structured data formats are having a similar impact on the \"machine Web.\" XML is enriching our ability to find and interchange information today; industry verticals have created XML-based data exchange standards; and XML backbones have gained adoption in support of service-oriented architectures and software-as-a-service initiatives. Other semi-structured formats, like JSON, are playing similar roles, and XML is increasingly being used for its original purpose of semantic document markup. As a result, the world will soon be awash in a sea of semi-structured information.<br\/><br\/>The ASTERIX project is developing new technologies for ingesting, storing, managing, indexing, querying, analyzing, and subscribing to vast quantities of semi-structured information. The project is combining ideas from three distinct areas - semi-structured data, parallel databases, and data-intensive computing - to create a next-generation, open source software platform that scales by running on large, shared-nothing computing clusters. ASTERIX targets a wide range of semi-structured information, ranging from \"data\" use cases - where information is well-tagged and highly regular - to \"content\" use cases - where data is irregular and much of each datum is textual. ASTERIX is taking an open stance on data formats and addressing research issues including highly scalable data storage and indexing, semi-structured query processing on very large clusters, and merging parallel database techniques with today's data-intensive computing techniques to support performant yet declarative solutions to the problem of analyzing semi-structured information.<br\/><br\/>Project website: http:\/\/asterix.ics.uci.edu\/","title":"DC: Large: Collaborative Research: ASTERIX: A Highly Scalable Parallel Platform for Semistructured Data Management and Analysis","awardID":"0910859","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["543515"],"PO":["563727"]},"153715":{"abstract":"People routinely encounter and seek to make sense of large collections of data that include both unstructured reports or stories and loosely-structured logs or spreadsheets. In many cases, information of relevance is scattered about a large number of documents and it is the task of an analyst to read the documents and \"put the pieces together.\" For instance, police investigators when sifting through a multitude of observations, case reports, and witness testimonies must develop a coherent view of the events that really occurred. Academic researchers investigating a new domain pour over large numbers of paper abstracts, citations, and articles to develop a better understanding of the state of work in that area. The process of connecting individual pieces of information such as those discussed above into a more coherent narrative is a component of investigative analysis, the main focus of this project. One common element of analytic sense-making activities is that they are cognitively very challenging, frequently involving large collections of data that tax a person's memory, deduction, reasoning, and general analytic capabilities. Investigative analysis today is made even more challenging by the ever-increasing torrent of data available in a world where one can access vast databases and conduct internet searches that in seconds return a quantity of documents no human can read and assimilate in a reasonable amount of time. But technological means of augmenting human memory and analytic reasoning hold great potential as investigative aids. This project explores the development of computational systems to make investigative analysts more effective and more efficient. The PI's approach centers on providing multiple visual representations of the individual pieces of data gathered during the investigation, to help highlight connections or potential connections among them and to help analysts determine the next pieces of data to examine from a large collection of evidence. The PI will draw upon his experience in information visualization and visual analytics to design and create a system to help analysts, and upon his experience in human-computer interaction to evaluate whether the system is effective. The work will include fundamental research on challenges such as the representation of reliability and uncertainty in a visualization display, the development of collaborative system capabilities so that analysts can work together, and the integration of sophisticated automated textual analysis capabilities with the human-directed exploration approach that visual interfaces provide. Careful evaluation of all the new analytic capabilities will accompany their design as well.<br\/><br\/>Broader Impacts: Investigative analysis is a fundamental activity in law enforcement and in intelligence activities that are important to our national security. This project will invent next-generation visual analytic techniques and technologies that can be used to develop investigative analysis systems in the future. Other domains such as news reporting, academic research, and business intelligence also require investigative analysis, so this project has the potential to impact those fields as well.","title":"III: Small: Supporting Investigative Analysts and Researchers in Sense-making across Large Document Collections through Visual Analytics","awardID":"0915788","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":["550876"],"PO":["565227"]},"153957":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Although there are several large-scale industrial deployments of peer-to-peer (P2P) live video systems, these existing systems have several fundamental performance problems, including huge channel switching delays, large playback lags, poor performance for less-popular channels, ISP unfriendliness. In these traditional systems, a peer only redistributes the video it is currently watching. In this research, the PIs are exploring a radically different approach to P2P live video streaming, View-Upload Decoupling (VUD). The main idea of VUD is to have each peer distribute one or more channels, with the assignments being made independently of what the peer is viewing. This novel approach has three major advantages over the traditional isolated-channel designs: channel-churn immunity; cross-channel multiplexing; and the enabling of structured streaming. The PIs are developing tractable analytical performance models for multi-channel P2P video streaming systems, for both VUD and traditional design approaches. The analytical results not only highlight the advantages of the VUD approach, but also provide important ``rules-of-thumb'' for the design of VUD systems. The PIs are developing dynamic VUD provisioning algorithms that are both robust with respect to channel churn and also adapt to dynamic channel popularity and flash crowds. The PIs are developing VUD provisioning, management and streaming schemes that take into account ISP locality and largely reduce the video streaming traffic imposed on ISP networks. The PIs and their PhD students are also developing an open-source VUD prototype.","title":"NeTS:Small:View-Upload Decoupling: A Redesign of Multi-Channel P2P Video Systems","awardID":"0916734","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["312698","550020"],"PO":["564993"]},"153968":{"abstract":"Future processor chips are expected to have hundreds or even thousands of processor cores. To take advantage of this massive computing power, programmers need to parallelize their applications. Parallel programming, however, is notoriously difficult. Almost all the production concurrent software systems used today contain bugs costing billions of dollars. To address this challenge, this research is developing parallel runtime mechanisms that could make it possible for even buggy software to run correctly in a production system.<br\/><br\/>The fundamental problem with the current parallel programming models is that they expose an unbounded number of thread interleavings to the parallel runtime system, and a majority of the interleavings in a production system remain untested. This research is exploring two directions to avoid incorrect interleavings from manifesting in a production run. The first approach uses a sampling-based low overhead data race detector for detecting incorrect interleavings, which are then avoided. The second approach constrains production run thread interleavings to a set of tested interleavings, which could provide comprehensive immunity against most types of concurrency bugs. Software tools developed as part of this research will help software developers and researchers. Students will also use these productivity tools in their course projects.","title":"SHF: Small: Interleaving Constrained Parallel Runtime System for Tolerating Concurrency Bugs","awardID":"0916770","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":["502231"],"PO":["564588"]},"153858":{"abstract":"This work will develop new methods for fast and scalable detection of anomalous patterns (subsets of the data that are interesting or unexpected) in massive, multivariate datasets. There will be a focus on real-world applications such as an emerging disease outbreak or a pattern of smuggling activity with complex, subtle, and probabilistic patterns that are difficult to spot with existing techniques. The research is based on two key insights. First, the pattern detection problem can be framed as a search over all subsets of the data, in which can be defined a measure of the \"anomalousness\" of a subset and then maximize this measure over all potentially relevant subsets. <br\/><br\/>Second, it has been discovered that, for many spatial detection methods (including Kulldor's spatial scan statistic and many recently proposed variants), one can perform an exact search which efficiently maximizes the measure of anomalousness over all subsets of the data. The research team will explore this new combinatorial optimization method, investigate how it can be extended to constrained subset scans and to more general multivariate pattern detection problems, and examine how it can be incorporated into a subset scan framework, enabling the creation a variety of fast, scalable, and useful methods for anomalous pattern detection. <br\/><br\/>Intellectual Merit<br\/>The research team will develop, implement, and evaluate a general probabilistic framework for efficient detection of anomalous patterns in both spatial and non-spatial datasets. The proposed work will address these challenging and important research questions:<br\/>1)How can one define a useful measure of the \"anomalousness\" of a subset of the data, and efficiently optimize this measure over all subsets to find the most anomalous patterns?<br\/>2) What are the necessary and sufficient conditions for a set function F (S ) to satisfy the \"linear- time subset scanning\" (LTSS) property, enabling exact unconstrained optimization of F (S ) over all 2 N subsets of N records while only requiring O(N ) subsets to be evaluated?<br\/>3) How can one extend fast subset scanning methods to general multivariate datasets, and incorporate search constraints such as proximity, connectivity, and self-similarity?<br\/>4) How can one deal with uncertainty about the effects of an anomalous pattern by searching over subsets of \"input\" and \"output\" attributes as well as subsets of records? <br\/><br\/>Broader Impact<br\/>Development and testing will be prioritized in three areas: 1) early detection of disease outbreaks, 2) detecting illicit container shipments, and 3) identifying anomalous trends in social networks. These applications will allow the demonstration the value of these methods across a wide spectrum of domains. Through existing collaborations, the algorithms will be incorporated into deployed systems for health and crime surveillance that contribute directly to the public good. The Principle Investigator's lab has over 5 years of history offering free machine learning software, and the software implementations of all algorithms developed through this grant will be made publicly available. The bulk of the funding will go to training graduate students who will become the next generation of researchers to explore new methods for anomalous pattern detection. <br\/><br\/>Key Words: anomalous patterns; pattern detection; fast subset scan; scan statistics; optimization.","title":"III: Small: Fast Subset Scan for Anomalous Pattern Detection","awardID":"0916345","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["432417"],"PO":["563727"]},"152527":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Moore?s law promises consistent increasing transistor densities for the foreseeable future. However, device scaling no longer delivers the energy gains that drove the semiconductor growth of the past several decades. This has created a design paradox: more gates can now fit on a die, but cannot actually be used due to strict power limits. In this project, we will address this energy crisis through the universal application of ?near-threshold computing? (NTC), where devices operate at or near their threshold voltage to obtain 10X or higher energy efficiency improvements. To accomplish this we focus on three key challenges that to date have kept low voltage operation from widespread use: 1) 10X loss in performance, 2) 5X increase in performance variation, and 3) 5 orders of magnitude increase in functional failure. We present a synergistic approach combining methods from algorithm and architecture levels to the circuit and technology levels. We will demonstrate NTC for applications that range from sensor-based platforms which critically depend on ultra-low power (\u00a1\u00dcmW) and reduced form factor (mm3) to unlock new applications, to high-performance platforms in large data-centers, which dissipate so much power that they require co-location near dedicated cooling facilities. Our end goal is to reduce national energy consumption and environmental impact by providing dramatic gains in energy efficiency while also opening up new application areas in health care by providing for in situ monitoring of biological functions with minimum intervention.","title":"CSR:Large:Collaborative Research:Reclaiming Moore's Law through Ultra Energy Efficient Computing","awardID":"0910606","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[406377],"PO":["565255"]},"153903":{"abstract":"Computational complexity theory classifies computational problems into various complexity classes based on the amount of resources needed to solve them. This classification is done by measuring various resources such as time, space, nonuniformity, nondeterminism, and randomness. A better understanding of the relationships among these various resources shed light on the computational difficulty of the problems that are encountered in practice. <br\/><br\/>This project explores several central questions regarding nonuniformity, complete problems, and space bounded computations. This project attempts to discover improved upper bounds for problems with high circuit complexity. Regarding complete sets, non-relativizing properties of complete sets will be explored. Space bounded computations will be investigated in the context of planar graph reachability problems. <br\/><br\/>This project addresses several basic questions in computational complexity theory. The results from this project will further our understanding of computational resources such as nonuniformity, nondeterminism, and space. Research results will be published in peer-reviewed journals and will be presented at national and international conferences, thus enabling broad dissemination of the the results to enhance scientific understanding. New courses will be created and taught along the themes of this project, thus integrating teaching and research. The project supports various human resource development activities such as supporting and mentoring graduate students and inviting visitors.","title":"AF: Small: Collaborative Research: Studies in Nonuniformity, Completeness, and Reachability","awardID":"0916525","effectiveDate":"2009-08-15","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}}],"PIcoPI":[409525],"PO":["565157"]},"153936":{"abstract":"This award is funded under the American Recovery and Reinvestment<br\/>Act of 2009 (Public Law 111-5).<br\/><br\/>The Internet has traditionally combined many orthogonal functions into transport protocols, creating significant technical and administrative hurdles to transport service evolution. New or specialized transport protocols are now nearly undeployable because they cannot traverse middleboxes such as NATs, firewalls, performance enhancing proxies, which have mushroomed in the past two decades; new congestion control schemes are restricted by the requirement to compete ?fairly? against traditional TCP flows; and deploying new features such as multi-homing is difficult because applications must be adapted to new naming and communication models.<br\/><br\/>Tng (\"Transport next generation\") is a new but incrementally deployable transport architecture that breaks the above evolutionary impasse by modularizing the transport layer. Tng breaks transports into four explicit layers - Endpoint Naming, Flow Regulation, Identity\/Security, and Semantics - plus a cross-layer Negotiation service. By separating the network-oriented functions of endpoint naming and flow regulation from application-oriented transport semantics, Tng enables middleboxes in the network to enforce network policies and optimize flow performance cleanly across diverse network technologies and administrative domains, without interfering with end-to-end semantics. Tng's identity\/security layer in turn enforces this separation<br\/>between network- and appliation-oriented functions, avoiding past conflicts between middleboxes and IPsec.<br\/><br\/>By developing a working prototype and analyzing its performance and adaptability across a variety of real and simulated network environments, we expect that Tng will prove an important step towards breaking long-standing deadlocks between operators, new network technologies, and end-users.","title":"NeTS: Small: Collaborative Research: Tng, a Next Generation Transport Services Architecture","awardID":"0916678","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[409612],"PO":["564993"]},"150427":{"abstract":"The objective of the proposed research is to design innovative algorithms and tools for energy-aware scheduling and mapping of tasks onto homogeneous and heterogeneous multi-core processor (HeMP) architectures. The research proposes to develop a new theoretical and experimental framework, called multi-element and multi-objective (MEMO) optimization, that will simultaneously and flexibly optimize the goals of energy minimization and performance maximization while taking into account constraints due to multiple architectural elements such as cores and caches of current and emerging multi-core processors. The project will develop CorePac, a toolkit that will provide a flexible and friendly environment to schedule task-parallel applications on HeMPs under various performance\/energy trade-offs and demonstrate the usefulness of the algorithms and CorePac. Benchmarking of the algorithms will be conducted using a diverse suite of scientific, multimedia, and bioinformatics applications.<br\/><br\/>Through its production of new algorithms and software toolkit, this work will have a direct and immediate impact on a number of communities. At the collaborating institutions, this project will have an educational impact by involving undergraduate and graduate students. This situation also presents excellent opportunities for interaction with postdoctoral researchers as well as with colleagues in academic, government and industry research labs. The CorePac software toolkit will be the basis for subsequent development of production quality software for energy-performance tradeoffs. Developing means to manage energy consumption in computers is imperative from both environmental and economical perspectives.","title":"MCDA: Collaborative Research: A Multi-Element and Multi-Objective Optimization Approach for Allocating tasks to Multi-Core Processors","awardID":"0903430","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7786","name":"MCDA"}}],"PIcoPI":["530024","518389"],"PO":["366560"]},"150449":{"abstract":"The focus of this project is on designing robust multi-core systems at lowest cost that are resilient to hardware failures. It is motivated by an imminent paradigm shift in hardware design resulting from the growing problem of hardware failures in future process technologies. The central vision is to develop techniques and tools for designing hierarchical robust multi-core systems that are globally optimized across multiple abstraction layers ? circuit, architecture, runtime, and application ? without incurring the high cost of expensive redundancy techniques. An inter disciplinary approach will integrate research and education required to enable future robust systems. Because of its cross-cutting nature, the proposed research has the potential of having a major impact on future systems, enabling future technology scaling, thus making everyday lives better.","title":"Collaborative Research: Globally Optimized Robust Systems on Multi-Core Hardware","awardID":"0903478","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7786","name":"MCDA"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":["548338"],"PO":["366560"]},"153738":{"abstract":"The broad goal of this line of research is to give a principled answer to the question, \"What sort of data is efficiently learnable, and by what algorithms?\" The current state-of-the-art in machine learning is that there is an overwhelming number of possible algorithms that can be tried on a new machine learning problem, with no clear understanding of which techniques can be expected to work on which problems. Further, it is often the case that machine learning algorithms that work well \"in theory\" do not perform as well \"in practice,\" and vice versa. The PIs have outlined a plan for resolving these difficulties, finding a unification of disparate methods via the Polynomial Method, and investigating how efficient this method can be. On a more immediate level the PIs will aim for broad impact through advising and guiding graduate students and widely disseminating research results.<br\/><br\/>Specifically, the PIs will investigate the effectiveness of the \"Polynomial Method\" in machine learning theory. The PIs observe that nearly all learning algorithms, in theory and in practice, can be viewed as fitting a low-degree polynomial to data. The PIs plan to systematically develop this Polynomial Method of learning by working on the following three strands of research:<br\/><br\/>1. Understand the extent to which low-degree polynomials can fit different natural types of target functions, under various data distributions and noise rates. This research involves novel methods from approximation theory and analysis.<br\/><br\/>2. Develop new algorithmic methods for finding well-fitting polynomials when they exist. Here the PIs will work to adapt results in geometry and probability for the purposes of identifying and eliminating irrelevant data.<br\/><br\/>3. Delimit the effectiveness of the Polynomial Method. The PIs will show new results on the computational intractability of learning intersections of linear separators, and on learning linear separators with noise.","title":"AF: Small : Collaborative Research: The Polynomial Method for Learning","awardID":"0915893","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}}],"PIcoPI":["550547"],"PO":["565157"]},"150824":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>A significant majority of current Internet traffic is due to distributing content, yet the Internet was designed to be largely agnostic to characteristics of the content flowing over it. This research investigates the design and operation of a content-aware Internet ecosystem, which thrives on the interaction between users (seeking seek fast and correct downloads), content providers (seeking to minimize network congestion and transit traffic), and network providers (who generate content, and seek the cost- and resource-efficient dissemination).<br\/><br\/>This research takes a two-pronged approach. On one hand, it explores novel analysis of fundamental performance limits for a content-aware Internet ecosystem that rigorously characterizes the benefits of an intelligently designed cross-layer architecture. On the other hand, it includes developing mechanisms and practical implementation of a content distribution system, by which involved parties can interact constructively to achieve these gains yet respect each others' interests. This approach combines a range of techniques, including modeling and theoretical analysis, measurement and data analysis, system design, simulation, and system implementation. Affordable and ready access to digital content helps inform, educate, and entertain society as a whole. Additionally, by developing cost- and resource-effective delivery techniques, the friction continuing to build between involved parties can be reduced and the technical side of the network neutrality debate can be better informed. To enhance this impact, the project includes an educational component involving local universities from under-represented groups, curriculum development and interactions with industry.","title":"NeTS: Medium: Collaborative Research: Designing a Content-Aware Internet Ecosystem","awardID":"0904860","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["533300"],"PO":["565090"]},"150967":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\"<br\/><br\/>This project aims to develop models, algorithms, and testbeds for robust intelligent manipulation that will enable supervisory control for robotic surgical assistants (RSAs). Drawing on the combined expertise of the investigators, the research is focusing on both analytic and empirical approaches.<br\/><br\/>Using analytic approaches, the investigators are defining mathematical models of system state, deformable tissue dynamics, and stochastic uncertainty. These models are used to develop robotic motion planning and control algorithms to plan and perform grasping and manipulation of deformable objects under uncertainty. Using empirical approaches, the investigators are developing machine learning techniques to efficiently find dynamic control policies and characterize performance metrics based on expert demonstrations. Simulation and hardware testbeds for a common set of benchmark problems are being developed to evaluate these algorithms and methods.<br\/><br\/>This project will advance basic scientific understanding by developing new analytic methods for robust grasping and manipulation of deformable objects. This project will also advance empirical approaches by developing controllers that learn deformable object manipulation skills by observing expert demonstrations. The project will extend, compare, and evaluate analytic and empirical methods and seek to develop new hybrid methods within the focused context of providing robust intelligence for RSAs.<br\/><br\/>Robust intelligent manipulation for RSAs will improve patient health and reduce costs by enhancing surgeon performance, reducing tedium, and decreasing operation time. Outreach to local girls' high schools and predominantly minority Cleveland high schools is pursued as part of the project to encourage participation of underrepresented groups in engineering and computer science.","title":"RI: Medium: Robust Intelligent Manipulation and Apprenticeship Learning for Robotic Surgical Assistants","awardID":"0905344","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["554067","520937","460484","520938","562687"],"PO":["562760"]},"150857":{"abstract":"Abstract (limited to 250 words): This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Our nation's infrastructure relies increasingly on networks that connect growing amounts of data and systems, including those that interact directly with the physical world. Increased connectivity leads to a higher degree of vulnerability to attacks, malfunctions, and failures that can cascade more rapidly along network links. The project develops techniques to improve the reliability of emerging networked infrastructure, where computation, communication, and sensing are intimately intertwined. Use of data mining techniques is investigated to determine and eliminate scenarios involving cascaded failures and propagation of performance problems. The complexity of emerging networked and pervasive computing systems increases maintenance cost, challenges classical design approaches, and makes traditional diagnostics and debugging tools less effective at catching problems. To reverse these trends, this project develops tools that are specifically suited to address three fundamental challenges of complex distributed systems; namely, non-reproducible stochastic behavior, high interactive complexity, and physical resource constraints. Other than improving reliability, this research is integrated with education curricula at the University of Illinois, offering real-world challenges to intellectually stimulate both graduate and undergraduate students, while seeking avenues to encourage cultural diversity and promote women and minority involvement in engineering. Laboratory modules allow students to experiment with and diagnose real-world design problems and cascading interaction anomalies in a hands-on fashion. The project will result in improved versions of a data mining textbook by the Co-PI, which is currently considered the standard reference in the field.","title":"NetSE: Medium: A Data Mining Approach to Diagnostic Debugging in Sensor Networks","awardID":"0905014","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["563535","553633"],"PO":["564924"]},"150747":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>A significant majority of current Internet traffic is due to distributing content, yet the Internet was designed to be largely agnostic to characteristics of the content flowing over it. This research investigates the design and operation of a content-aware Internet ecosystem, which thrives on the interaction between users (seeking seek fast and correct downloads), content providers (seeking to minimize network congestion and transit traffic), and network providers (who generate content, and seek the cost- and resource-efficient dissemination). <br\/><br\/>This research takes a two-pronged approach. On one hand, it explores novel analysis of fundamental performance limits for a content-aware Internet ecosystem that rigorously characterizes the benefits of an intelligently designed cross-layer architecture. On the other hand, it includes developing mechanisms and practical implementation of a content distribution system, by which involved parties can interact constructively to achieve these gains yet respect each others' interests. This approach combines a range of techniques, including modeling and theoretical analysis, measurement and data analysis, system design, simulation, and system implementation. Affordable and ready access to digital content helps inform, educate, and entertain society as a whole. Additionally, by developing cost- and resource-effective delivery techniques, the friction continuing to build between involved parties can be reduced and the technical side of the network neutrality debate can be better informed. To enhance this impact, the project includes an educational component involving local universities from under-represented groups, curriculum development and interactions with industry.","title":"NeTS: Medium: Collaborative Research: Designing a Content-Aware Internet Ecosystem","awardID":"0904520","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["525195"],"PO":["565090"]},"153805":{"abstract":"CSR: Small: Collaborative Research: Adaptive Applications and Architectures for Variation-Tolerant Systems<br\/><br\/>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The scaling of integrated circuits (ICs) into the nanometer regime has thrown up new challenges for designers, foremost among which are variations in the characteristics of IC components. Variations threaten to diminish the fundamental benefits of technology scaling, such as improvements in cost-per-transistor, performance and power consumption. Variation-aware design techniques that have been proposed thus far are being stretched to their limits, and cannot contain the incessant increase in variations. Therefore, it is important to develop new design approaches for systems that are inherently resilient to variations in the underlying components. <br\/><br\/>This project develops a framework based on adaptive applications and architectures for the design of variation-tolerant application-specific systems. It advances the state-of-the-art by (i) adopting a cross-layer approach at the system architecture and application layers, (ii) leveraging the inherent ?elasticity? of a wide class of applications to adapt to variations in the underlying hardware while still producing acceptable performance and maintaining end-user experience, and (iii) exploring a hybrid (design-time and post-fabrication) design methodology, enabling more accurate and effective system adaptation in response to variations. The developed technologies will significantly extend our ability to avail of the benefits of technology scaling in the face of increasing variations.<br\/><br\/>The efforts towards broader impact include working with the semiconductor industry to validate and transfer the developed technologies, new educational material incorporated in courses on SoC design and embedded systems, and undergraduate design projects.","title":"CSR: Small: Collaborative Research: Adaptive Applications and Architectures for Variation-Tolerant Systems","awardID":"0916117","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["551013"],"PO":["565255"]},"150428":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009<br\/>(Public Law 111-5).\"<br\/><br\/><br\/>Proposal ID: 0903432 <br\/>PI name: Xie, Yuan<br\/>Inst: PA St U University Park <br\/>Title: ADAMS: Architecture and Design Automation for 3D Multi-core Systems<br\/><br\/><br\/>ABSTRACT<br\/>Three-dimensional integrated circuits (3D ICs) are envisioned as a promising solution for future multi-core architecture design. This project will investigate two cross-cutting research thrusts related to architectural exploration and design-automation tools for future 3D multi-core systems. The stacking of memory components and the relationship between memory stacking and interconnect will be explored. The stacking of logic layers that provide distinct service to the system such as improved reliability and efficient power management will also be investigated. The PI will consider the interplay between different constraints such as thermal profiles, performance, and cost in these explorations. To facilitate such explorations, a set of design automation toolsets will be developed. In addition to validation using simulation and emulation environments, the project will fabricate and test some of these designs to demonstrate the feasibility of the ideas. <br\/><br\/>The research will be conducted in collaboration with industrial partners enabling direct transfer of technology to industry. The outcome of this research will, therefore, have a direct impact on future multi-core designs. Undergraduate and graduate students involved in this research will get versatile training. The tools and techniques developed in this research will be used in developing a new course on multi-core design. The PIs will also organize tutorials along with major conferences to disseminate the results from this work.","title":"ADAMS: Architecture and Design Automation for 3D Multi-core Systems","awardID":"0903432","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7786","name":"MCDA"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":["518504","549542"],"PO":["562984"]},"153948":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 <br\/>(Public Law 111-5).\"<br\/><br\/>ID: 0916714 <br\/>Papaefthymiou Marios <br\/>University of Michigan Ann Arbor <br\/>SHF:Small: Energy-Recycling VLSI Systems <br\/><br\/>This research project will investigate novel technologies for the design of very-large scale integrated (VLSI) computer systems that achieve unprecedented levels of energy-efficient operation through energy recycling. In contrast to conventional computer systems that consume all the energy supplied to them while computing, energy-recycling computers reclaim and reuse any energy that remains undissipated during their operation. Therefore, they have the potential to operate with substantially lower energy consumption than conventional computers. This project will encompass a broad spectrum of design technologies for energy-recycling computers, including circuitry, computing architectures, and design methodologies. The effectiveness of these technologies will be assessed through the design, fabrication, and experimental evaluation of proof-of-concept hardware prototypes.<br\/><br\/>With power consumption in high-performance microprocessors exceeding 100Watts, the design of energy-efficient computers has become a top priority in electronic design due to reliability concerns caused by excessive heat generation. Furthermore, energy-efficient computers play a key role in the development of new mobile applications due to battery-life considerations. And last, but not least, the power requirements of computing devices, including high-performance servers, desktops, and laptops, is placing an increasing burden on the power grid, with emissions from all these sources growing at a reported annual compound rate of 6% and thus posing a serious environmental concern. The outcomes of this research project can therefore be transformative, resulting in innovative design technologies for realizing next-generation computer systems that achieve unprecedented levels of reliable and energy-efficient operation, enable new mobile applications, and promote sustainability.","title":"SHF: Small: Energy-Recycling VLSI Systems","awardID":"0916714","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["550681"],"PO":["562984"]},"153838":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Wireless Mesh Networks have emerged as a solution for providing last-mile Internet access. By exploiting advanced communication technologies, they can achieve very high rates. However, effectively controlling these networks, especially in the context of advanced physical layer technologies, realistic models for channel interference, and distributed operation, remains a major challenge. Hence, the project focuses on developing effective and practical network control algorithms that make efficient use of wireless resources through joint topology adaptation, network layer routing, MAC layer scheduling, and physical layer power, channel, and rate control. The design of the algorithms leverages recent developments in the control of dynamical systems and randomized algorithms, and takes into account realistic channel models. This includes: (i) topology adaptation algorithms that take advantage of channel allocation, power control, and the controlled mobility capabilities of some of the nodes to dynamically decompose the network into sub-networks in which low-complexity distributed scheduling and routing algorithms are guaranteed to achieve high throughput, (ii) randomized distributed algorithms that solve the scheduling and routing problems in a computationally efficient manner using only local topological and queue size information, and (iii) evaluation of the algorithms? performance in terms of throughput, delay, and complexity. The developed algorithms will enable highly efficient operation of wireless networks. The project incorporates training of graduate and undergraduate students, outreach activities to local high-school teachers, and technology transfer to industry and government laboratories.","title":"NeTS: Small: Collaborative Research: Effective Control of Wireless Networks via Topology Adaptation and Randomization","awardID":"0916263","effectiveDate":"2009-08-01","expirationDate":"2012-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["470173"],"PO":["557315"]},"150913":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Probabilistic graphical models provide a powerful mechanism for representing and reasoning with uncertain information. These methods have been successfully applied in diverse domains such as bioinformatics, social networks, sensor networks, robotics, and web mining; in turn, such application areas have posed new computational challenges driving graphical model research. This project is motivated by challenges in emerging application areas such as epidemiological simulation, geoscience modeling, and studies of interacting proteins, where there are rich sets of information of multiple types and at multiple levels of granularity. While the methods developed will be general, the research will focus on protein-protein interactions, which drive the molecular machinery of the cell by forming transient or persistent complexes to propagate signals, catalyze reactions, transport molecules, and so forth. The mixed-mode information available includes amino acid sequences, three-dimensional structures and associated physical models, and binary, rank-ordered, or even quantitative interaction data. The proposed techniques address key challenges in information integration, prediction, and generation using graphical models. <br\/><br\/>Intellectual merits: <br\/>The intellectual merits of this work derive both from the new capabilities for information integration and for reasoning with probabilistic graphical models, as well as their application to the study of protein-protein interactions. Proteins offer, by far, some of the most complex, multi-faceted datasets for integration using computational methods; hence the lessons learned here can be applied to similarly rich information spaces, such as epidemiology and geosciences. These integrated models of interacting proteins and new algorithms for prediction and generation will also support significant applications such as protein engineering and systems biology, bridging interaction networks to the underlying residue-level interactions in order to better understand and control them. <br\/><br\/>Broader impacts: <br\/>This project will reach out to both the bioinformatics and larger computer science communities to maximize the impact of our contributions. An open-source integrator platform will be developed, aimed at integrating protein datasets and which can be extended to information integration in other domains as well. To stimulate community building and foster discovery, the research team will advocate situating computer science research in the context of concrete applications. Building on prior successes, the team will organize a workshop at a suitable venue such as ICML\/AAAI\/NIPS\/KDD focused on an 'information integration challenge' dataset involving protein modeling. Finally, through programs such as Women@SCS at Carnegie Mellon, WISP (Women in Science Program) at Dartmouth, Howard Hughes education grant internships at Purdue, and the MAOP\/VTURCS (Minority Academic Opportunities Program and VT Undergraduate Research in Computer Science) program at Virginia Tech, the team will provide cross-disciplinary training to undergraduate students from underrepresented groups. <br\/><br\/><br\/>Keywords: Probabilistic Graphical Models, Information Integration, Mixed-Mode Datasets, Bioinformatics, Proteins, Markov Chain Monte Carlo (MCMC) methods.","title":"III: Medium: Collaborative Research: Integration, Prediction, and Generation of Mixed Mode Information using Graphical Models, with Applications to Protein-Protein Interactions","awardID":"0905193","effectiveDate":"2009-08-15","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["499611"],"PO":["565136"]},"160637":{"abstract":"This project supports research by Paturi, his graduate students and collaborators on foundational questions about the exact complexity of NP-complete problems The core questions addressed concern the difficulty of exhaustive search, and to what extent an exhaustive search may be pruned to improve its effectiveness. The project will study the complexity of algorithms, especially for the fundamental problem of satisfiability, but also for other NP-complete problems such as the traveling salesman problem and k-colorability. The PI and his students will study probabilistic search algorithms that succeed with exponentially small probability. They will study self-reducibility among instances of the circuit satisfiability problem as well as the fundamental question of trade-off between time and probability for NP-complete problems.<br\/><br\/>Research on exact exponential-time algorithms for NP-complete problems not only has the potential to improve our understanding of fundamental limitations of feasible computability, but may possibly lead directly to new algorithms for satisfiability and other combinatorial optimization problems. The project will support graduate student education and research in computer science, especially in algorithms and complexity theory. The PI engages in teaching at the undergraduate and graduate level in computer science that will benefit from his research activities supported by the project.","title":"Exponential Complexity of NP-complete Problems","awardID":"0947262","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}}],"PIcoPI":["515841"],"PO":["565157"]},"150429":{"abstract":"Effective management of supply voltage is of critical importance to overcome power limitations in future highly parallel multi-core microprocessors. This project proposes a new approach to efficiently deliver power and manage voltage in chip multiprocessors through a technique, called flexible voltage stacking. Voltage stacking involves delivering a higher supply voltage to the chip (resulting in lower current draw for a fixed power budget), which can reduce IR losses and improve power delivery efficiency. By providing flexibility to the stack, individual cores can be stacked in such a way as to regulate the voltage to the desired core supply level. The PIs plan to explore a range of architectural and circuit techniques to mitigate issues related to voltage noise. Also, a prototype chip will be designed demonstrating the flexible voltage stack concept, driven by realistic workload traces from a combined software\/FPGA simulator of a multicore system. The work will have broader impacts through technology transfer to the computing industry and by providing training for both undergraduate and graduate students.","title":"Flexible Voltage Stacking for Chip Multiprocessors","awardID":"0903437","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7786","name":"MCDA"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":["518228","518229"],"PO":["366560"]},"153828":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009<br\/>(Public Law 111-5).<br\/><br\/>Even in the US, many regions suffer poor Internet connectivity, due to<br\/>high prices, capacity limitations, poor infrastructure, or low<br\/>population density. Rural communities may be underserved because of<br\/>DSL distance limits and the high cost of bringing fiber optic cable to<br\/>low-density regions. Even when businesses or schools can be connected<br\/>by DSL, its capacity limits may still provide poor end-user experience<br\/>when many people share the connection. This research is addressing these<br\/>problems by using intelligent software to enhance network<br\/>connectivity. By aggressive data caching and off-peak prefetching,<br\/>data can be stored on disk and retrieved locally instead of always<br\/>being fetched from the Internet. For environments with many users,<br\/>this system can reduce bandwidth consumption by an order of magnitude,<br\/>providing higher effective end-user bandwidth, or allow cost<br\/>reductions by purchasing less wide-area bandwidth. The expected<br\/>outcome of this research is an open-source system that can be deployed<br\/>at Internet gateways, which will transparently improve network<br\/>performance. Possible locations include schools, small businesses, and<br\/>Internet Service Providers (ISPs). In schools, when a classroom full<br\/>of students accesses a topic, only one copy is downloaded, and<br\/>the rest get it from the cache. For news sites that update during the<br\/>day, only the changed portions get downloaded, instead of whole<br\/>articles. Prefetching will also reduce latency, by determining user<br\/>patterns and preloading content before it is needed.","title":"NeTS:Small:Content Retrieval Networks: Network Access for Disadvantaged Regions","awardID":"0916204","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["533299"],"PO":["564993"]},"153949":{"abstract":"This project extends the semantical foundations of object-oriented (OO) languages to cover methodologies for modular reasoning. Modular reasoning means verifying software components assuming the specification of each used component. Modularity is important for productivity and scalability, but is difficult to achieve for OO software. To support modular reasoning, researchers have proposed several methodologies that restrict programs and their specifications. The goal of this project is to provide a theoretical basis that supports practical techniques for justifying and using methodologies.<br\/><br\/>This project provides guidance for the designers of programming and specification languages, verification logics, and associated tools. The results will improve the utility and extensibility of verification tools --- a key goal of the Verified Software grand challenge. Software developers may benefit from the integration and harmonious interoperation of best-practice methodologies. This project is potentially transformative: it aims to enable combinations and customizations of methodologies by tool users, scalable to real applications.<br\/><br\/>Improved OO programming methodologies may greatly improve programming practice, especially in applications needing high assurance, reliability, and security. This will benefit society, which increasingly depends on computing systems built using OO components. Unification of methodologies and streamlining of tools also facilitates the education of software developers.","title":"SHF: Small: Collaborative Research: Specification Language Foundations for Modular Reasoning Methodologies","awardID":"0916715","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":["521544"],"PO":["565264"]},"153729":{"abstract":"This research develops a transformative pulse switching framework for light-weight networking applications. It abstracts a single pulse, as opposed to data packets, as the information switching granularity. Pulse switching is shown to be sufficient for on-off style event monitoring applications such as building or bridge structural health monitoring with ultra-thin energy budgets, especially when the energy is harvested from structural vibrations, ambient temperature variations or the mechanical perturbations caused by an event itself. An observable event can be coded as a pulse, which is transported multi-hop while preserving sufficient amount of spatio-temporal information about the event in question. Zero collisions, zero buffering, no addressing, no packet processing, and an ultra-low energy budget makes the framework applicable for networking between embedded devices with ultra-tight energy budgets. This research involves: 1) developing a joint MAC-Routing abstraction for pulse switching, 2) mapping the pulse switching architecture on Ultra Wideband (UWB) impulse radio, 3) designing multi-sink and peer-to-peer pulse routing protocols, and 4) constructing a prototype pulse-switched network using UWB hardware. Impacts of this research includes a potential transformation of the area of low-information networking by replacing the traditional concept of packet switching by pulse switching in the realm of energy-constrained event monitoring. Expected results will include a joint MAC-routing architecture and its performance in an Ultra Wideband pulse networking system. This research is considered to be a key enabler for emerging cross-disciplinary research and applications including structural health monitoring, bio-medical body-area sensing, earthquake engineering, environmental monitoring, and disaster management through ultra-light packet-less communication.","title":"NeTS: Small: Pulse Switching: An Ultra-light Multi-hop Network Paradigm without Packet Abstraction","awardID":"0915851","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[409099,"451278"],"PO":["565303"]},"150958":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Probabilistic graphical models provide a powerful mechanism for representing and reasoning with uncertain information. These methods have been successfully applied in diverse domains such as bioinformatics, social networks, sensor networks, robotics, and web mining; in turn, such application areas have posed new computational challenges driving graphical model research. This project is motivated by challenges in emerging application areas such as epidemiological simulation, geoscience modeling, and studies of interacting proteins, where there are rich sets of information of multiple types and at multiple levels of granularity. While the methods developed will be general, the research will focus on protein-protein interactions, which drive the molecular machinery of the cell by forming transient or persistent complexes to propagate signals, catalyze reactions, transport molecules, and so forth. The mixed-mode information available includes amino acid sequences, three-dimensional structures and associated physical models, and binary, rank-ordered, or even quantitative interaction data. The proposed techniques address key challenges in information integration, prediction, and generation using graphical models. <br\/><br\/>Intellectual merits:<br\/>The intellectual merits of this work derive both from the new capabilities for information integration and for reasoning with probabilistic graphical models, as well as their application to the study of protein-protein interactions. Proteins offer, by far, some of the most complex, multi-faceted datasets for integration using computational methods; hence the lessons learned here can be applied to similarly rich information spaces, such as epidemiology and geosciences. These integrated models of interacting proteins and new algorithms for prediction and generation will also support significant applications such as protein engineering and systems biology, bridging interaction networks to the underlying residue-level interactions in order to better understand and control them. <br\/><br\/>Broader impacts: <br\/>This project will reach out to both the bioinformatics and larger computer science communities to maximize the impact of our contributions. An open-source integrator platform will be developed, aimed at integrating protein datasets and which can be extended to information integration in other domains as well. To stimulate community building and foster discovery, the research team will advocate situating computer science research in the context of concrete applications. Building on prior successes, the team will organize a workshop at a suitable venue such as ICML\/AAAI\/NIPS\/KDD focused on an 'information integration challenge' dataset involving protein modeling. Finally, through programs such as Women@SCS at Carnegie Mellon, WISP (Women in Science Program) at Dartmouth, Howard Hughes education grant internships at Purdue, and the MAOP\/VTURCS (Minority Academic Opportunities Program and VT Undergraduate Research in Computer Science) program at Virginia Tech, the team will provide cross-disciplinary training to undergraduate students from underrepresented groups. <br\/><br\/><br\/>Keywords: Probabilistic Graphical Models, Information Integration, Mixed-Mode Datasets, Bioinformatics, Proteins, Markov Chain Monte Carlo (MCMC) methods.","title":"III: Medium: Collaborative Research: Integration, Prediction, and Generation of Mixed Mode Information using Graphical Models, with Applications to Protein-Protein Interactions","awardID":"0905313","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["498314"],"PO":["565136"]},"150969":{"abstract":"Abstract:<br\/><br\/>Modern techniques giving the best performance for acquiring and processing signals\/images rely on repeatedly solving mathematical optimization problems which can be computationally expensive. This research involves advancing, by orders of magnitude, the state of the art for solving an important class of these problems. Rather than developing algorithms tailored to current digital computational platform, the investigators depart completely from this current line of research to study analog architectures for solving these problems. These analog architectures, when fully developed, have the potential for dramatic gains in speed and power efficiency over their digital counterparts. This research project is inherently multidisciplinary, as it combines recent advances in computational neuroscience, signal processing, and reconfigurable VLSI architectures. Among other applications, these systems enable reductions in the time needed to acquire a magnetic resonance image (MRI).<br\/><br\/>This project focuses primarily on solving optimization programs combining a mean-squared error data fidelity term with a sparsity inducing cost function (e.g., the L1 norm) via an analog dynamical system architecture. Specifically , the project contains two intertwined threads: circuit implementation and mathematical analysis. <br\/>The goal of the circuit implementation thread is to produce a analog circuit which solves significant optimization programs (e.g., tens of thousands of variables) substantially faster than state-of-the-art digital solutions. The investigators leverage recent advances in reconfigurable analog architectures to achieve efficient designs at this large scale. The analysis thread includes deriving bounds on the circuit convergence time and generalizing the architecture to include <br\/>other relevant signal processing problems. The research also involves <br\/>applying this analog architecture as a nonlinear \"filter\" which continuously reacts to changes in the input.","title":"CIF: Medium: Analog Architectures for Optimization in Signal Processing","awardID":"0905346","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7938","name":"SENSOR NETWORKS"}}],"PIcoPI":["558209","565105","562955"],"PO":["564898"]},"163916":{"abstract":"Embedded systems are computers within devices that are not generally recognized as computers, e.g., computers within automobiles, medical devices, and personal communication devices. The design of embedded systems is complicated by their numerous conflicting objectives, e.g., short design time, low price, low power consumption, high performance, and reliability. Manually designing embedded systems that meet all these goals is an arduous task. This project targets the automatic analysis, design, and control of embedded systems.<br\/><br\/>This project is developing optimization algorithms and software that automatically designs low-power, low-price, high-performance embedded systems and integrated circuits. A fast and accurate profiling and memory access tracing based infrastructure for detailed power and performance analysis of embedded applications and operating systems will be implemented. The theory for power-aware operating system scheduling and device control will be further developed and the results embodied and made public in a new version of a widely used embedded operating system.<br\/><br\/>Embedded systems (special-purpose computers) make it easier to communicate, improve the speed and safety of travel, manage information, and assist people with hundreds of other tasks. This project is making it possible to build better and less expensive embedded systems. In addition, software developed in this project is publicly released as a reference implementation to improve the battery lifespan of embedded systems that run open-source operating systems. This project is integrated with Northwestern University courses on embedded system design and real-time systems. Through it, undergraduate students are benefiting from, and actively participating in, academic research.","title":"CAREER: Analysis, Design, and Synthesis of High-Performance, Low-Power, Real-Time Embedded Systems","awardID":"0964764","effectiveDate":"2009-08-15","expirationDate":"2011-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}}],"PIcoPI":["550572"],"PO":["493916"]},"150628":{"abstract":"The goal of this project is to investigate the potential of fundamentally new modes of robotic manipulation using novel continuum robots in less-structured environments with large uncertainties and even unknowns. A continuum robot, such as a trunk\/tentacle robot arm, is in many senses ?dual? to a traditional robot manipulator (consisting of an articulated arm and a gripper or hand), featuring relatively low precision but high compliance: <br\/><br\/>* Its inherent flexibility and compliance offer greater promise to enable deft manipulation under imprecise and uncertain conditions of objects over a wider range (orders of magnitude) of size and weight, of many different shapes, and with widely different physical characteristics (rigid, soft, flexible, etc.).. <br\/><br\/>* On the other hand, its inherent lack of precision renders the traditional approaches to planning and control of robot manipulators unsuitable for manipulation with continuum robots. <br\/><br\/>This project pioneers the study of the basic problem of autonomous manipulation of an object with much uncertainty by a single continuum robot. It introduces a novel and holistic approach that integrates real-time adaptive planning and robust control schemes under real-time sensing and large environmental uncertainty. It next extends the basic approach to address multiple continuum robots working in a common environment, where each robot needs not know the motion of another robot. The research combines theoretical\/algorithmic development with real-world validation on an experimental test bed with real trunk\/tentacle robots equipped with sensors. The results will be actively disseminated through publications, free software, and real-world demos to impact research, education, and applications.","title":"RI: Medium: Collaborative Research: Real-Time Continuum Manipulation","awardID":"0904116","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["563342","530256"],"PO":["534411"]},"153906":{"abstract":"The energy consumed by the memory subsystem is increasing as a fraction of the overall server energy consumption. It is anticipated that upcoming low-power, byte-addressable, persistent-memory technologies, namely Phase-Change RAM (PC-RAM) and Spin-Transfer Torque RAM (STT-RAM), are likely to play a major role in conserving server energy. These technologies are far superior to Flash and, most interestingly, may actually replace DRAM as well.<br\/><br\/>The research will study hybrid memory subsystems by combining these technologies and DRAM, as well as DRAM-free memory subsystems. The outcomes of this investigation will be: (1) a body of knowledge about PC-RAM and STT-RAM and their potential benefits and limitations; (2) a collection of memory controller and operating system techniques for using these technologies to conserve energy, while bounding performance degradation to user-defined limits; and (3) a simulation and operating system infrastructure that can be used by others in their investigations of memory and energy issues. This work can promote a new direction in memory subsystem design and energ conservation, one that can have a profound impact on the design of future servers.","title":"SHF: Small: Energy-Efficient Memory Subsystems for the Many-Core Era","awardID":"0916539","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["556616"],"PO":["366560"]},"153917":{"abstract":"Monitoring of software's execution is crucial in numerous software development tasks. Current monitoring efforts generally require extensive instrumentation of the software or dedicated hardware---it resembles studying the software specimens in-vitro. To fully understand software's behaviors, the production software must be studied in-vivo---in its operational environment. To address these fundamental software engineering challenges, this research addresses a framework for in-vivo monitoring and observation of software-intensive systems.<br\/><br\/>Three fundamental requirements are placed on in-vivo monitoring<br\/>frameworks: non-intrusive, low-overhead, and predictable. These frameworks must also allow low-level monitoring and be highly flexible to enable a broad range of monitoring activities. To satisfy these requirements, this research changes how software is compiled and how hardware is designed by pursuing the following specific aims: (i) provide flexible architectural support shared by a variety of monitoring activities; (ii) develop a monitor-aware compiler that generates the monitor together with the software to be monitored; and (iii) develop state extraction optimizations to efficiently extract program states from an executing application and forward the states to the monitor. The resulting framework is empirically evaluated to assess its performance as compared to related solutions and assess its flexibility for a variety of software engineering monitoring tasks.","title":"SHF: Small: In Vivo Software Monitoring: Architectural and Compiler Support","awardID":"0916583","effectiveDate":"2009-08-15","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}}],"PIcoPI":["421080","421081"],"PO":["565272"]},"153807":{"abstract":"Protecting confidential information is a major concern for organizations and individuals alike, who stand to suffer huge losses if private data falls into the wrong hands. One of the primary threats to confidentiality is malicious software, which is estimated to reside on millions of computers. Current security solutions, such as firewalls, anti-virus software, and intrusion detection systems, are inadequate at preventing malware infection.<br\/><br\/>The main contribution of this project will be a novel mechanism, called Storage Capsules, that will allow users to protect confidential files on personal computers and servers. Storage Capsules are encrypted containers that will allow users on a compromised machine to securely read and write files on the container using standard applications without malware being able to steal confidential file data. Research themes include designing the system, analyzing its security and addressing the potential threats, improving its efficiency, and extending it to support user-defined access policies. Broader implications of this work include providing a new method for people to secure sensitive data on their personal computers and servers, even in the presence of malware.","title":"TC: Small: Capsule: Safely Accessing Confidential Data in a Low-Integrity Environment","awardID":"0916126","effectiveDate":"2009-08-15","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550044"],"PO":["565264"]},"150419":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The objective of this research is to develop an automated design environment for enabling the integration of emerging nanoscale silicon photonic optical interconnect device technologies in next-generation multicore computing architectures. The approach includes a comprehensive simulation framework capable of capturing low-level physical details of both optical and electronic components including, layout footprint, optical losses, and the energy consumption, while maintaining a cycle-accurate functional network simulation. <br\/><br\/>Intellectual Merit: The photonic technologies used to create interconnection networks are fundamentally different from electronic counterparts in how they are designed and perform to achieve interconnect and routing functionalities. Therefore, to exploit the potential advantages of photonic interconnection networks in multicore architectures, a novel design methodology and toolset is developed from scratch in a manner that incorporates the physically different behavior of photonics and provides accurate performance modeling for future multicore systems. Unique to this effort, the physical layer parameters are derived from the design, fabrication, and characterization of real passive and active silicon nanophotonic building blocks devices.<br\/><br\/>Broader Impact: The program advances multiple cross-disciplinary areas in networking, multicore computing architecture, interconnect capabilities and nanoscale silicon photonics. Included in the program are diversity outreach and educational training efforts that emphasize the cross-disciplinary nature of the field. The proposed suite of CAD tools will be made publicly available in an effort to improve the speed and realized complexity of nanophotonic enabled interconnection network development that are able to transform an abstract design concept into a physically-accurate, verified, complex photonic on-chip networks for multicore chip multiprocessors.","title":"Nanophotonic Interconnect CAD: Automated Design for Nanophotonic Enabled Interconnect in Multicore Architectures","awardID":"0903406","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}}],"PIcoPI":["477270","509533"],"PO":["565185"]},"153818":{"abstract":"Randomness is useful in many areas of computer science, including algorithms, Monte Carlo simulations, cryptography, and distributed computing. In practice, however, it is expensive or impossible to get truly random numbers. Therefore, computers rely on pseudorandom generators. However, scientists have reported problems with practical pseudorandom generators. Can we construct pseudorandom generators that are provably good? The PI proposes to address this question and the related question of how to extract high-quality randomness from low-quality random sources.<br\/><br\/>These questions have unexpected connections to error-correcting codes and distributed computing, which the PI proposes to explore further. He also proposes to attack fundamental questions in these areas. In coding theory, these questions relate to his recent results on decoding the important Reed-Muller codes. In distributed computing, he proposes to advance his work on network extractor protocols. These are protocols to extract high-quality randomness from low-quality random sources in a distributed setting. Such protocols could be very useful in cryptography.","title":"AF:Small:Pseudorandomness, Codes, and Distributed Computing","awardID":"0916160","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}}],"PIcoPI":["518438"],"PO":["565157"]},"153708":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>The project investigates statistical software analysis, which infers<br\/>relationships among program components by using statistical properties<br\/>derived from multiple program executions.<br\/><br\/>To motivate statistical techniques, it is useful to draw analogies to<br\/>static analysis methods. Static analysis is about inferring<br\/>dependencies between program components: If a value is changed in one<br\/>component, how does that affect a value in a different component?<br\/>Static analysis tends to work best for properties that are local,<br\/>meaning the pieces of the program we are trying to relate are not<br\/>separated by a great deal of other computation. The statistical analog<br\/>of dependencies is correlation. Instead of proving definitively via<br\/>static reasoning the presence or absence of dependencies, we can<br\/>observe at run-time that some properties of two components have high<br\/>or low correlation. Importantly, correlation is not affected by<br\/>syntactic or even dynamic locality: if two components have a<br\/>correlation, regardless of how much time or computation passes between<br\/>the execution of one component and the execution of the other, this<br\/>correlation can be detected if the appropriate statistical question is<br\/>asked.<br\/><br\/>The initial focus is on using cross-correlation, which which computes<br\/>the maximum correlation between two sequences of observations, to<br\/>formalize statistical correlation between software components that<br\/>have a direction in time. This idea gives rise to a natural graph that<br\/>captures the strength and direction of statistical influence one<br\/>component has upon another; these graphs are analogous to traditional<br\/>dependency graphs, but have unique and useful properties.","title":"SHF: Small: Statistical Analysis of Software","awardID":"0915766","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["507674"],"PO":["565264"]},"153808":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\" <br\/><br\/>Computer processor industry has moved fully into the multi-core era to enable continual scaling of performance, but at the cost of increased energy consumption and increased cooling costs due to higher temperatures and thermal gradients. This proposal describes three major research thrusts that address these costs in multiple ways: (1) New modeling and simulation tools: We will integrate performance, power, temperature, reliability and cooling estimation, so that the designers will be able to analyze the impact of design choices and runtime decisions over significant time spans. (2) Runtime thread scheduling policies: We will identify and demonstrate power and thermal scheduling mechanisms that maintain performance, reduce the total energy consumption, and eliminate or reduce hot spots, but also maximize processor lifetime. The policies will use the data from thermal sensors and performance counters to proactively drive the management decisions. (3) New cooling strategies: Our goal is to create thermal management and cooling control algorithms that work in tandem to reduce the overall energy consumption.<br\/><br\/>The proposed research forms the basis for discovery and learning in the areas of multi core processors, and, more generally, system design and management. Graduate and undergraduate students will be involved in various parts of the proposed research and help in connecting this work with other NSF sponsored projects. The results of research, tools and coursework materials developed will be freely and easily distributed to engineering community at large.","title":"SHF: Small: Reducing the Cost of Computation in CMPs","awardID":"0916127","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["560640"],"PO":["562984"]},"150916":{"abstract":"CIF: Medium: Collaborative Research: Cooperative Networking Across the Layers<br\/><br\/>This research goes beyond the physical layer in defining and analyzing cooperative techniques for wireless networks. By incorporating higher layer properties such as traffic dynamics and access control, the investigators develop a new theoretical framework for analyzing and designing cooperative networking algorithms across the layers, which includes existing cooperative techniques such as cooperative relaying and network coding. The basis of this research rests on two major points:: first, the realization that cooperative communication at the physical layer cannot be viewed in isolation, since it has implications at the access and network layers, and second, the recognition . that cooperation at the higher layers, in its own right, can significantly impact overall network performance. <br\/><br\/>This project has three inter-related thrusts: The first thrust studies resource allocation policies which stabilize the queues within various classes of cooperative networks, if stability is indeed attainable. The second thrust determines a family of scheduling algorithms which maximize the volume of traffic served by a cooperative network within a finite horizon. Finally, game theoretic models are developed for cooperative networks where nodes in the network are allowed to pursue differing objectives, and come to a distributed agreement on the (locally) optimal operating point for the overall network.<br\/>This research also considers non-stationary and non-ergodic environments that are more appropriate representations of the wireless channel in a network.","title":"CIF: Medium: Collaborative Research: Cooperative Networking Across the Layers","awardID":"0905200","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7937","name":"NETWORK CODING AND INFO THEORY"}}],"PIcoPI":["539208"],"PO":["564924"]},"150927":{"abstract":"CIF: Medium: Collaborative Research: Cooperative Networking Across the Layers<br\/><br\/>This research goes beyond the physical layer in defining and analyzing cooperative techniques for wireless networks. By incorporating higher layer properties such as traffic dynamics and access control, the investigators develop a new theoretical framework for analyzing and designing cooperative networking algorithms across the layers, which includes existing cooperative techniques such as cooperative relaying and network coding. The basis of this research rests on two major points:: first, the realization that cooperative communication at the physical layer cannot be viewed in isolation, since it has implications at the access and network layers, and second, the recognition . that cooperation at the higher layers, in its own right, can significantly impact overall network performance. <br\/><br\/>This project has three inter-related thrusts: The first thrust studies resource allocation policies which stabilize the queues within various classes of cooperative networks, if stability is indeed attainable. The second thrust determines a family of scheduling algorithms which maximize the volume of traffic served by a cooperative network within a finite horizon. Finally, game theoretic models are developed for cooperative networks where nodes in the network are allowed to pursue differing objectives, and come to a distributed agreement on the (locally) optimal operating point for the overall network.<br\/>This research also considers non-stationary and non-ergodic environments that are more appropriate representations of the wireless channel in a network.","title":"CIF: Medium: Collaborative Research: Cooperative Networking Across the Layers","awardID":"0905224","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7937","name":"NETWORK CODING AND INFO THEORY"}}],"PIcoPI":["560218"],"PO":["564924"]},"160519":{"abstract":"The foundations of computing science need rethinking. This group will convene a working group at the Annual Conference on Innovation and Technology in Computer Science (ITiCSE) in 2009 in Paris, France to articulate the fundamental properties of computing and computational thinking, and to explain what computing curricula built around this way of thinking might look like. Although much of the previous work in this area has focused on undergraduate majors, this project is equally important to pre-college, post-baccalaureate, and non-majors programs. As such, the program will directly address those creating high school sequences, new PhD programs, concentrations for non-majors who want or need to continue beyond CS 101 and those who are trying to reach students traditionally underrepresented in computing. Prior to the meeting, a group using electronic collaboration tools will draft a rough document describing the motivations for curricular change and the idea at its heart. We will use electronic collaboration tools for this phase. Each workshop member will circulate a description of at least one curriculum and the ways in which it supports or is supported by the model. At the meeting itself, members will discuss and refine the draft document. During part of the working group meeting, structured brainstorming techniques and facilitated discussions will aid in envisioning alternative curricula at all levels that might build on this idea. These visions, together with existing case studies will be part of the report. The working group is made of international scholars and members of industry as well as academics from the United States from a variety of institutions.","title":"International Travel: Working Group on (Re)Defining Computing","awardID":"0946665","effectiveDate":"2009-08-01","expirationDate":"2010-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["559402"],"PO":["565136"]},"153809":{"abstract":"IIS - 0916129 <br\/>HCC: Small: Collaborative Research: Asynchrony and Persistence for Complex Contact Simulations<br\/>Grinspun, Eitan <br\/>Columbia University<br\/><br\/>Collaborative Proposals<br\/>IIS - 0914833 <br\/>Guibas, Leonidas J <br\/>Stanford University<br\/><br\/>ABSTRACT<br\/>This proposal addresses the challenge of complex contact simulations by working entirely in an asynchronous setting. The project operates along three lines, combining tools from Asynchronous Variational Integrators (AVIs) and Kinetic Data Structures (KDSs) with a novel effort to perform and exploit qualitative analysis of contact simulation data. The first investigation will show that AVIs, meant to handle the continuous aspects of the physics, can be integrated well with KDSs, meant to handle discrete geometric events. The second research component addresses the fundamental problem of event scheduling when future trajectories are uncertain. Methods will be explored that improve event detection times, reduce the number of auxiliary events that have to be processed, and allow events to be processed in parallel. The third research task will be to initiate a study of the qualitative behavior of contact simulation by building a hierarchy of coarser models which can then be used for better resource allocation, for the validation of various approximations, and in improved simulation design to attain desired effects.","title":"HCC: Small: Collaborative Research: Asynchrony and Persistence for Complex Contact Simulations","awardID":"0916129","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["554341"],"PO":["565227"]},"150917":{"abstract":"CIF: Medium: Collaborative Research: Cooperative Networking Across the Layers<br\/><br\/>This research goes beyond the physical layer in defining and analyzing cooperative techniques for wireless networks. By incorporating higher layer properties such as traffic dynamics and access control, the investigators develop a new theoretical framework for analyzing and designing cooperative networking algorithms across the layers, which includes existing cooperative techniques such as cooperative relaying and network coding. The basis of this research rests on two major points:: first, the realization that cooperative communication at the physical layer cannot be viewed in isolation, since it has implications at the access and network layers, and second, the recognition . that cooperation at the higher layers, in its own right, can significantly impact overall network performance. <br\/><br\/>This project has three inter-related thrusts: The first thrust studies resource allocation policies which stabilize the queues within various classes of cooperative networks, if stability is indeed attainable. The second thrust determines a family of scheduling algorithms which maximize the volume of traffic served by a cooperative network within a finite horizon. Finally, game theoretic models are developed for cooperative networks where nodes in the network are allowed to pursue differing objectives, and come to a distributed agreement on the (locally) optimal operating point for the overall network.<br\/>This research also considers non-stationary and non-ergodic environments that are more appropriate representations of the wireless channel in a network.","title":"CIF:Medium:Collaborative Research: Cooperative Networking Across the Layers","awardID":"0905204","effectiveDate":"2009-08-01","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7937","name":"NETWORK CODING AND INFO THEORY"}}],"PIcoPI":["501350"],"PO":["564924"]},"153909":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\"<br\/><br\/>Robot hands are usually simple, with just two or three fingers, perhaps a single actuator, and most often no sensors at all. These simple hands are also very specific in their function, such as picking up a specific part. Research on more general robot hands usually focuses on complex hands, often resembling human hands. This project is developing simple hands with general capabilities. The approach is inspired by a variety of simple hands, such as a prosthetic hook, which have proven generality when controlled by a human, yet have never demonstrated great generality when controlled by an autonomous robot. In particular the project is developing hands that can blindly capture objects among clutter, and testing these hands both in a factory automation application and in a home assistive robotics application.<br\/><br\/><br\/>Results from this study will be broadly applicable. Every advance in hand design enables new applications, so development of new principles broadly advancing the generality of hands will be useful. Specific cases are advancing the nation's manufacturing workforce productivity, and enabling the elderly to live independently. Results will be disseminated by scholarly publication of new principles, analysis, and experimental results, as well as distribution of analytical software, planning and control software, and hand designs.","title":"RI: Small: A Simple but General Hand","awardID":"0916557","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["521687","560864"],"PO":["564069"]},"159191":{"abstract":"This EAGER grant explores early concepts of a new approach to computer programming. The semantic gap between what the programmer intends and what the code actually means significantly impedes efforts to improve programmer productivity, software reliability, and execution efficiency. To address the semantic gap, the project radically rethinks how to develop software. A new programming model, methodology, and system for ?gradual programming? will support the development of programs and programming language semantics in parallel. The vision advocates developing programs in a family of languages with varying semantics. Then, part of the development process involves nailing down the precise semantics of the program. A key issue involves the tradeoffs between expressiveness of a programming language and the ability to build tools capable of statically checking for programming errors. Such a vision is not without significant challenges and possible pitfalls, such as maintaining performance, and entrusting issues of programming language design to programmers. The project will study the sources of the semantic gap in the Java programming language to understand the problem better and articulate the approach more fully.","title":"EAGER: Exploratory Research on Gradual Programming","awardID":"0939991","effectiveDate":"2009-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":["461768","518195","564351"],"PO":["564388"]},"150919":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>Probabilistic graphical models provide a powerful mechanism for representing and reasoning with uncertain information. These methods have been successfully applied in diverse domains such as bioinformatics, social networks, sensor networks, robotics, and web mining; in turn, such application areas have posed new computational challenges driving graphical model research. This project is motivated by challenges in emerging application areas such as epidemiological simulation, geoscience modeling, and studies of interacting proteins, where there are rich sets of information of multiple types and at multiple levels of granularity. While the methods developed will be general, the research will focus on protein-protein interactions, which drive the molecular machinery of the cell by forming transient or persistent complexes to propagate signals, catalyze reactions, transport molecules, and so forth. The mixed-mode information available includes amino acid sequences, three-dimensional structures and associated physical models, and binary, rank-ordered, or even quantitative interaction data. The proposed techniques address key challenges in information integration, prediction, and generation using graphical models. <br\/><br\/>Intellectual merits: <br\/>The intellectual merits of this work derive both from the new capabilities for information integration and for reasoning with probabilistic graphical models, as well as their application to the study of protein-protein interactions. Proteins offer, by far, some of the most complex, multi-faceted datasets for integration using computational methods; hence the lessons learned here can be applied to similarly rich information spaces, such as epidemiology and geosciences. These integrated models of interacting proteins and new algorithms for prediction and generation will also support significant applications such as protein engineering and systems biology, bridging interaction networks to the underlying residue-level interactions in order to better understand and control them. <br\/><br\/>Broader impacts: <br\/>This project will reach out to both the bioinformatics and larger computer science communities to maximize the impact of our contributions. An open-source integrator platform will be developed, aimed at integrating protein datasets and which can be extended to information integration in other domains as well. To stimulate community building and foster discovery, the research team will advocate situating computer science research in the context of concrete applications. Building on prior successes, the team will organize a workshop at a suitable venue such as ICML\/AAAI\/NIPS\/KDD focused on an 'information integration challenge' dataset involving protein modeling. Finally, through programs such as Women@SCS at Carnegie Mellon, WISP (Women in Science Program) at Dartmouth, Howard Hughes education grant internships at Purdue, and the MAOP\/VTURCS (Minority Academic Opportunities Program and VT Undergraduate Research in Computer Science) program at Virginia Tech, the team will provide cross-disciplinary training to undergraduate students from underrepresented groups. <br\/><br\/><br\/>Keywords: Probabilistic Graphical Models, Information Integration, Mixed-Mode Datasets, Bioinformatics, Proteins, Markov Chain Monte Carlo (MCMC) methods.","title":"III: Medium: Collaborative Research: Integration, Prediction, and Generation of Mixed Mode Information using Graphical Models, with Applications to Protein-Protein Interactions","awardID":"0905206","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["511584"],"PO":["565136"]},"159193":{"abstract":"This award supports an Organizational Communication and Information Systems (OCIS) Doctoral Colloquium at the 2009 Academy of Management (AOM) Annual Meeting to be held August 7-12, 2009 in Chicago, IL. The OCIS division within the AOM conference brings together researchers in the areas communications and information systems and issues related to the contemporary information-based society. The focus of the OCIS Doctoral Consortium is the intellectual content of the students' doctoral dissertations. These represent cutting edge research in the field of organizational communication and information systems. The OCIS doctoral consortium brings together highly talented students and several senior researchers, facilitating the development of a social network that will play a major role in the career success of new researchers. Since both faculty and students are diverse on several dimensions (research topics, methodological approaches, national and cultural background), the students' horizons are broadened at a critical stage in their professional development.","title":"Workshop: Organizational Communication and Information Systems (OCIS) Doctoral Research Consortium","awardID":"0940002","effectiveDate":"2009-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["427342"],"PO":["565342"]},"159194":{"abstract":"Careers in High Performance Systems (CHiPS) Mentoring Workshop is a mentoring workshop to attract and encourage women and under-represented minority (URM) computer science undergraduate students (specifically those students in their sophomore and junior years) to obtain a Ph.D. in computer science.<br\/><br\/>The workshop will engage women and under-represented minority undergraduates specifically interested in HPC research. A set of mentoring panels will focus on motivating and preparing students to get a Ph.D. A tutorial session on GPU programming techniques taught by leading academic and industry experts is planned. This panel will be hands-on with the students actually doing coding. Researchers from several areas of HPC will hold panels discussing past research and the current state-of-art in HPC, and present a number of future problems that we, as a society, should be prepared to tackle in the coming decade.","title":"Careers in High Performance Systems (CHiPS) Mentoring Workshop","awardID":"0940003","effectiveDate":"2009-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["558848","557272"],"PO":["565272"]},"149283":{"abstract":"This project seeks to support and transform emergent practices of online creative collaboration, making new kinds of creative processes and products possible. Online communication can provide a source of support for creativity and collaboration. On the Internet today, amateur participants are already collaborating on creative projects. We focus on one creative domain: the creation of short, animated movies. In phase one of our research, we are studying existing practice, to gain insight into what aspects of online creative collaboration are challenging. Based on this understanding, we are creating Sandbox, a suite of tools to support creative collaboration online. Most existing practice uses a central creative leader or \"auteur\" model of production. Our tools are designed to make the leader's role easier, and also to make a new more decentralized\/leaderless mode of production possible. By comparing and contrasting centralized and decentralized project structures, we will gain insights into fundamental issues of the creative process and how to support it.","title":"Pilot: Supporting and Transforming Leadership in Online Creative Collaboration","awardID":"0855952","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":["517101"],"PO":["565342"]},"154090":{"abstract":"Facilities used in long-distance communications networks incorporate mechanisms to overcome failures, however, these result in the use of spare capacity (redundancy) to achieve relatively short restoration times (about 50 ms). Therefore, some providers have implemented proprietary network failure restoration techniques with a smaller degree of redundancy and with a larger restoration time. Restoration from network failures is particularly difficult for networks that employ routers and the Internet Protocol. This research is applying using network coding techniques for hitless (transparent to the user) restoration of services in the networks of future. The research is investigating topology and code design algorithms for actual networks, to understand their performance, to compare restoration time and extra capacity requirements of the new approach with conventional techniques, and to discover new protocols to implement the new technique. In this work, failure recovery design using network coding will be implemented in two steps. In the first step, for a given network, a failure recovery network will be designed using a linear program. In the second step, the needed Galois field size will be determined. The new hitless restoration technology will be compared with conventional failure recovery techniques using disjoint paths in terms of spare capacity, restoration speed, and operation complexity. The new technique will also enable packet loss recovery in the network, as opposed to on an end-to-end basis as performed conventionally. A special implementation for wireless networks is also under development. The successful outcome of this research can have a broad impact on future networks.","title":"NeTS: Small: Network Failure Recovery Employing Network Coding","awardID":"0917176","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["544661"],"PO":["564993"]},"149251":{"abstract":"This project compares three groups of programmers: open source software contributors, proprietary programmers, and novice coders, on three sets of variables: 1) aesthetic judgment criteria of software; 2) verbal protocol measures of cognitive processes occurring during creative problem solving while revising code; 3) ontogenetic quality trajectories as code is revised. This work has the strong potential to yield new psychological models of creativity by shedding light on the dynamic problem solving and evaluative processes that drive the ontogenesis of creative products. The comparison of two different groups of experts is also a novelty, certainly within the field of software design, and is atypical of cognitive studies of expertise more generally. This research also promises to help answer broader questions on the nature of creativity and to contribute to ongoing debates in computer science, software engineering, organizational behavior, cognitive psychology, and aesthetics, on how to promote innovation, on the kinds of mental processes contributing to creativity, and on the basic nature of quality of creative artifacts, such as software.","title":"Dynamic Cognitive Analyses of Creativity, Expertise, and Aesthetics in Software Development","awardID":"0855861","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7788","name":"CreativeIT"}}],"PIcoPI":["505732",397784],"PO":["565227"]},"149262":{"abstract":"Multidisciplinary teams composed of computer scientists, arts and computer science educators, and learning scientists from the University of Pennsylvania, MIT and Indiana University are researching how to encourage about 400 youth (ages 10-18) to creatively engage with computational textiles in afterschool and school settings. Computational textiles?textile artifacts that are computationally generated or that contain embedded computers?will capture youths? pre-existing interests in new media, fashion, and design while supporting learning and creativity in computer science, arts, design, and engineering.<br\/><br\/>The PIs are designing a new programming toolkit for 3D textile design to promote creativity and to study these tools in different workshop settings in afterschool and classroom programs. While previous efforts have focused on developing environments for 2D and 3D programming for novices, their goal is to expand these efforts to include 3D textile design to appeal to disadvantaged youth not normally drawn into computing. Moreover, they are developing an open, participatory website that allows youth to display their created artifacts and share, discuss, and remix their designs. These efforts build on our prior successes developing an online community around Scratch, which now hosts over 10,000 designers. They are engaging local youth communities and professional advisors from a variety of backgrounds to identify and encourage creative design solutions as part of their efforts to build this community, the first-ever youth community of computational textile designers.<br\/><br\/>The proposal leverages several successful developments: (1) a construction kit for building computational textiles called the LilyPad Arduino that makes this domain widely accessible for the first time; (2) research on a media-rich programming environment, Scratch, that is used by a worldwide community of designers of all ages; and (3) a conceptual framework of media arts in K-12 education that describes and analyzes creative digital production.<br\/><br\/>Using Csikszentmihalyi?s system model (1988, 1997), the PIs define creativity as the dynamic interaction between an individual?s contributions to a domain and community recognition within the field. To investigate the different components of creativity as a system, this project focuses on the technical, artistic and critical practices in youth? designs and interactions and employs a variety of assessment approaches including mixed methods data analyses of recorded group interactions, interviews with youth designers and professional artists, case studies of designers and artifacts, and log file data tracking online community participation and commentaries.<br\/><br\/>Intellectual Merit: This project presents a novel opportunity to study creativity within an emergent IT field (i.e., computational textiles and their applications) and will contribute to creativity research by providing empirically validated accounts of the system nature of creativity captured in interactions between individual designers and community feedback. Furthermore, they are developing tools for how to tailor programming to support 3D textile design, investigate an online community for sharing and validating creative computational textile designs, and investigate learning approaches in workshop models for computational textiles design for novice programmers.<br\/><br\/>Broader Impact: The proposed tools and activities broaden opportunities for youth from disadvantaged communities to develop advanced IT fluency skills by designing computationally enhanced materials and artifacts and contribute in meaningful ways to the emergent field of computational textile design. The implementation and assessment is conducted in workshops at after school sites that vary strategically in their technology experience to allow for a broader dissemination of the developed tools and activities. The findings from the work is shared with youth coordinators at professional development meetings, is presented at national conferences, and is disseminated further in academic journals and through their website.","title":"COLLABORATIVE MAJOR Computational Textiles as Materials for Creativity: Participatory Design Communities in Afterschool and Classroom Programs for Economically-Disadvantaged Youth","awardID":"0855886","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7788","name":"CreativeIT"}}],"PIcoPI":["552598"],"PO":["565227"]},"159096":{"abstract":"This proposal requests funding to support an exploratory workshop On Integrating Digital Library Content with Computational Tools and Services to bring together a cross-disciplinary group of researchers and stakeholders to examine the promise of combining cutting-edge high performance computing analytic tools and services with digital library content. It will bring together a cross-disciplinary group from several distinct communities including<br\/>o content scholars who wish to more fully exploit the content of digital libraries and similar repositories of digital materials<br\/>o content providers who wish to provide extended mechanisms for users in order to manipulate and analyze digital materials<br\/>o software developers and administrators<br\/>o researchers engaged in new tool development<br\/>The workshop has been accepted as an official full-day workshop of the 2009 ACM\/IEEE Joint Conference on Digital Libraries (JCDL 2009)","title":"Workshop on Integrating Digital Library Content with Computational Tools and Services","awardID":"0939253","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["559417"],"PO":["565136"]},"144092":{"abstract":"Large-enrollment courses are a practical necessity for introductory courses in science,technology, engineering and mathematics (STEM) at many institutions. Innovative technologies, such as audience response systems, can enhance instruction in large-enrollment classes, but the information that can be conveyed with these existing technologies remains quite limited. The goal of this project is to develop a new role for technology in large STEM classes, one that exploits advances in computer vision technology and the rapid proliferation of digital video. By building a multi-camera array to simultaneously observe all individuals in a large classroom, the investigators will pursue foundational research in both education and computer vision. For computer vision, large classrooms provide a convenient microcosm of social interaction in which individual activities are constrained but not controlled; this project will leverage this property to develop vision-based recognition systems for large group activites. Educationally, this new vision system will be used to systematically study learning in large classrooms---something that has not previously been possible.<br\/><br\/>Insights gained from research in these two areas will be used to create a radically new tool for computer-assisted collaborative instruction. This project will develop systems to automatically detect and summarize real-time activity information for course instructors, thereby enhancing their ability to make optimal use of interactive class time. These systems are viewed as prototypes that can ultimately be replicated at other institutions. In addition, the results of this research into the nature of learning in large classrooms will serve as a basis for improving instruction in large-enrollment STEM courses nationwide, regardless of their technological assets. More broadly, the project offers a new paradigm for education research, in which small-scale ecological observations are scaled up by automated visual activity recognition.","title":"Collaborative Research: Technological and Educational Foundations for Understanding and Improving Large-classroom Learning","awardID":"0835394","effectiveDate":"2009-08-15","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1707","name":"ADVANCED LEARNING TECHNOLOGIES"}}],"PIcoPI":["552443"],"PO":["564318"]},"159185":{"abstract":"Automatic summarization of spoken documents (e.g., everyday meetings, broadcast news, lectures, political speeches) provides an efficient way for information access in these data sources. Different summarization approaches have been developed and evaluated for speech data in different domains, such as meetings, broadcast news, and lectures. However, compared to text summarization, speech summarization is not as mature. There are no benchmark tests, the evaluation metrics are not clear, and there are not many annotated data sets available. Because of the recent increasing interest in speech summarization in the community, there is a need to gather researchers in the field to discuss various issues in this task and future research directions. This workshop brings together researchers dedicated to speech summarization in various aspects, helps build a research community for this task, and fosters discussions about open problems, future directions, data collection and sharing, algorithms and results. The topics discussed include the definition of speech summarization, data collection and annotation, data sharing, evaluation metrics, possible shared tasks, domain effect, summarization approaches, similarity and differences between text and speech summarization, and modality beyond speech in human communication. The discussions from this meeting will be disseminated using a dedicated website. This meeting will greatly help move forward the research in speech summarization. Students participating in this meeting will benefit from the discussions and be able to use them in their future research.","title":"Workshop on Speech Summarization","awardID":"0939966","effectiveDate":"2009-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["563325"],"PO":["565215"]},"149274":{"abstract":"Intellectual Merits: Analogy is a fundamental process of creativity. By definition, biologically inspired design is based on cross-domain analogies. This project is developing a computational model of creative analogies in biologically inspired engineering design, and building an interactive environment for enhancing biologically inspired design innovations. For a creative analogy to occur (e.g., design of nano-scale super-hydrophobic coatings inspired by the self-cleaning mechanism of lotus leafs), there must be significant similarity between the target problem and the source case at some deep level. For a creative analogy to work well, analogical transfer must take into account both the deep similarities and the dissimilarities between the target and the source. The hypotheses are that creative analogies in biologically inspired engineering design are <br\/>? enabled by knowledge of deep similarities in the abstract teleological mechanisms of biological and engineering systems, <br\/>? constrained by knowledge of deep dissimilarities between the physical structures in biological systems and the physical structures available to realize an abstract teleological mechanism in an engineering system, <br\/>? use an organizational schemata for the design cases that captures the relationships between teleological mechanisms and the physical structures in a biological system, <br\/>? use knowledge of specific design cases of biological systems (for problem understanding) and knowledge of general design patterns that capture their abstract teleological mechanisms (for solution generation), and <br\/>? use multimodal representations for the design cases in which the physical structures are represented both visually and verbally.<br\/>The computational model accounts for both problem-driven and solution-driven biologically inspired design, compound analogies in the design solution, and interactions between the process of problem decomposition and the processes of analogical retrieval, mapping and transfer. An interactive environment provides access to specific design cases of biological systems as well as general design patterns that capture the abstract teleological mechanisms of biological systems. It will organize knowledge of design cases in a drawing\/shape, structure\/behavior\/function schemata that captures the relationships between the teleological mechanisms and the physical structures in a biological system, and uses multimodal representations in which the physical structures are represented both visually and verbally.<br\/><br\/>The PIs are evaluating an interactive tool through in vitro and in vivo studies. In particular, they are conducting controlled experiments that vary the design problem and access to knowledge as independent variables, and measure reduction in cognitive errors and improvement in quality of design innovations as the dependent variables. Improvement in the quality of innovations will be measured in terms of the amount of problem evolution, the number of analogies in the design solution, and the degree of correctness and completeness of the design and its explanation.<br\/>At present, there are few computational models of biologically inspired design and few tools for supporting it. Although biological inspired design is promising, its practice today is ad hoc. By systemizing knowledge of the processes of biologically inspired design, and by developing computational models of creative analogy and computational tools for supporting analogy based design, this research has the potential for transforming the practice of biologically inspired design.<br\/><br\/>Broader Impacts: Biologically inspired design is an important and increasingly wide spread movement in many areas of engineering design ranging from robot design to technologies for environmentally conscious sustainable development. This research will contribute to multiple design domains in engineering. This research is based in part on cognitive studies conducted in classes on biologically inspired design, and the proposed interactive tool has the potential to revolutionize teaching and learning of biologically inspired design.","title":"MAJOR: Computational Tools for Enhancing Creativity in Biologically Inspired Engineering Design","awardID":"0855916","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7788","name":"CreativeIT"}}],"PIcoPI":["555889","530973","539354","440339",397849],"PO":["565227"]},"154081":{"abstract":"A primary goal of machine learning is to have computers \"learn\" from data, and to make predictions based on what they have learned. Machine learning has been used in many applications, such as identification of spam emails, detection of suspicious computer network traffic, and detection of malignant tumors. The use of machine learning is based on the implicit assumption that there is a mathematical function that describes, with some accuracy, the relation between the inputs to the prediction problem and the correct prediction. The function is not arbitrary; instead, it is of a certain restricted type. However, not all types of functions are efficiently learnable. Also, learnability depends crucially on the type of data that is available.<br\/><br\/>This project focuses on the learnability of Boolean functions, a central topic in computational learning theory. The research in this project falls into three main categories: learning from random examples, learning with costs, and DNF learning and minimization. Problems in the first category address core open questions in the standard PAC learning model and explore the extent to which access to data from different probability distributions can aid in learning. Problems in the second category are motivated by concrete problems in protein engineering, databases, and cyber-security, where there are costs associated with determining the value of inputs, or in obtaining data. The third category concerns problems of properly learning DNF formulas using DNF hypotheses, related complexity theoretic problems concerning DNF minimization, and problems concerning the complexity of certificates of DNF size.<br\/><br\/>Broadly, this project seeks to expand our understanding of which types of functions are efficiently learnable by computers, and under what conditions. The research on learning with costs can yield advances in the application areas that motivate it. DNF minimization is a central problem in both complexity theory and in the design of logic circuits; the research on DNF has the potential for impact in both these areas.","title":"AF: Small:Explorations in Computational Learning Theory","awardID":"0917153","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":["518057"],"PO":["565251"]},"147470":{"abstract":"This thematic program will explore the evolving interface between mathematics and computation. A wide variety of mathematical disciplines are involved, including computational algebraic geometry and symbolic computation, computational number theory, computational geometry, topology and dynamics, complexity and computability in real computation, computer science and optimization theory. Algorithms will be central, not only in their traditional role in the invention and analysis of numerical methods, but also as fundamental theoretical tools for mathematical experimentation and discovery, as proof techniques, and as models of computability and tractability. By assembling a large, broad group of participants, ranging from established mathematicians and computer scientists to graduate students, the program will transform our knowledge of computational mathematics well into the future.<br\/><br\/>The Fields Institute in Toronto will host this timely six-month program, capitalizing on rapidly evolving networks of international expertise linking mathematics and computation; NSF funding will support participation of junior U.S. researchers and graduate students. The impact of constantly increasing computational power on applied mathematics, science and engineering, motivated by new applications such as encryption, data mining, and web search, has inevitably led to the study of the computational tools themselves, creating and reinvigorating a rich spectrum of mathematical disciplines broadly represented at this special semester. The program involves three one-week focus workshops, special lecture series and graduate courses (delivered in particular by two distinguished U.S. female computer scientists, Eva Tardos and Lenore Blum), diverse senior and junior researchers and postdoctoral fellows making long- and short-term visits and engaging in day-to-day interaction, and extensive efforts to disseminate the emerging new science. These diverse activities will integrate cutting-edge research, interdisciplinary synergy, and learning and training opportunities for an array of participants as broad and inclusive as possible.","title":"Special Meeting: Foundations of Computational Mathematics","awardID":"0849383","effectiveDate":"2009-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1264","name":"ALGEBRA,NUMBER THEORY,AND COM"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1267","name":"TOPOLOGY"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7933","name":"NUM, SYMBOL, & ALGEBRA COMPUT"}}],"PIcoPI":[392859,"513231"],"PO":["410568"]},"149286":{"abstract":"One of the exciting recent directions for music and technology is interactive music performance, which requires advanced systems for sensing, listening, and understanding creative new human-computer cooperative interfaces, advances in real-time systems, and new models of music performance and synthesis. This project introduces a new computer music application: a virtual Performer that can fill the role of an accomplished musician performing popular music. This work will establish a new framework for music making, essentially a new genre.<br\/><br\/>The intellectual merit of this work lies in the scientific study of music and related research including reliable gesture sensing, signal analysis, and the study of how computers can support cooperative tasks. Results will have additional implications for music information retrieval, human-computer interaction, and complex sensing and recognition tasks. The broader impacts of this work include new music technology useful to millions of musicians, amateur and professional alike, providing a stimulus to creative musical practice, culture, and the economy. This new creative practice will also promote computational literacy, and the research itself will motivate a broader interest in computer science and related fields among new students.","title":"Pilot: The Performer: An Interactive Music System for Live Performance","awardID":"0855958","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":[397882],"PO":["565227"]},"144083":{"abstract":"Large-enrollment courses are a practical necessity for introductory courses in science, technology, engineering and mathematics (STEM) at many institutions. Innovative technologies, such as audience response systems, can enhance instruction in large-enrollment classes, but the information that can be conveyed with these existing technologies remains quite limited. The goal of this project is to develop a new role for technology in large STEM classes, one that exploits advances in computer vision technology and the rapid proliferation of digital video. By building a multi-camera array to simultaneously observe all individuals in a large classroom, the investigators will pursue foundational research in both education and computer vision. For computer vision, large classrooms provide a convenient microcosm of social interaction in which individual activities are constrained but not controlled; this project will leverage this property to develop vision-based recognition systems for large group activites. Educationally, this new vision system will be used to systematically study learning in large classrooms---something that has not previously been possible.<br\/><br\/>Insights gained from research in these two areas will be used to create a radically new tool for computer-assisted collaborative instruction. This project will develop systems to automatically detect and summarize real-time activity information for course instructors, thereby enhancing their ability to make optimal use of interactive class time. These systems are viewed as prototypes that can ultimately be replicated at other institutions. In addition, the results of this research into the nature of learning in large classrooms will serve as a basis for improving instruction in large-enrollment STEM courses nationwide, regardless of their technological assets. More broadly, the project offers a new paradigm for education research, in which small-scale ecological observations are scaled up by automated visual activity recognition.","title":"Collaborative Research: Technological and Educational Foundations for Understanding and Improving Large-classroom Learning","awardID":"0835338","effectiveDate":"2009-08-15","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1707","name":"ADVANCED LEARNING TECHNOLOGIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["538871","515747"],"PO":["564318"]},"148032":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>This REU site at the University of New Orleans (UNO) provides research experience for undergraduates in the area of integrated sensing and data processing for surveillance missions and automated scene understanding. The project recruits groups of diverse and talented undergraduate students from around the nation to actively engage in this cutting-edge Integrated Sensing and Automated Scene Understanding (ISASU) research, and to enhance the Electrical Engineering program at UNO.<br\/><br\/>Intellectual Merit<br\/>The participants are performing research that is expected to impact the field of ISASU, as well as other associated scientific disciplines such as Image Processing,<br\/>Artificial Intelligence, Pattern Recognition, Computer Vision, Bioinformatics, Data Mining, Knowledge Discovery, Automated Decision Making & Planning, and Information Fusion, among others. The REU PIs have extensive expertise in ISASU, as evidenced by their publications and current funded support. The student projects address cutting-edge research themes, directly stemming from the PIs? current research, and the PI has significant experience in student advising, as evidenced by the large number of graduate and undergraduate advisees. The proposed REU experience is expected to be successful in training undergraduates in ISASU; the goal is for this work to lead to significant results in the field.<br\/><br\/>Broader Impacts<br\/>The recruitment plan, in conjunction with strong commitment from faculties at affiliated institutions attracts undergraduate students, including females and under-represented groups, to the REU UNO site. The project engages in total a diverse group of 30 students, and two graduate students who will be involved in undergraduate teaching, research and mentoring activities. The REU research results will be published in peer reviewed conferences, and potentially, technical journals. These REU research advances are fed back and integrated into the teaching of related courses at UNO, and\/or affiliated institutions. Finally, the project leverages industrial contacts through the Information and Systems Technology Research Center (IST-RC) and UNO?s Research and Technology Park.","title":"REU Site: REU-University of New Orleans Site, TRACK: Training and Research in Computing Knowledge","awardID":"0851618","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1139","name":"RSCH EXPER FOR UNDERGRAD SITES"}}],"PIcoPI":[394538,394539],"PO":["564181"]},"149254":{"abstract":"Multidisciplinary teams composed of computer scientists, arts and computer science educators, and learning scientists from the University of Pennsylvania, MIT and Indiana University are researching how to encourage about 400 youth (ages 10-18) to creatively engage with computational textiles in afterschool and school settings. Computational textiles?textile artifacts that are computationally generated or that contain embedded computers?will capture youths? pre-existing interests in new media, fashion, and design while supporting learning and creativity in computer science, arts, design, and engineering.<br\/><br\/>The PIs are designing a new programming toolkit for 3D textile design to promote creativity and to study these tools in different workshop settings in afterschool and classroom programs. While previous efforts have focused on developing environments for 2D and 3D programming for novices, their goal is to expand these efforts to include 3D textile design to appeal to disadvantaged youth not normally drawn into computing. Moreover, they are developing an open, participatory website that allows youth to display their created artifacts and share, discuss, and remix their designs. These efforts build on our prior successes developing an online community around Scratch, which now hosts over 10,000 designers. They are engaging local youth communities and professional advisors from a variety of backgrounds to identify and encourage creative design solutions as part of their efforts to build this community, the first-ever youth community of computational textile designers.<br\/><br\/>The proposal leverages several successful developments: (1) a construction kit for building computational textiles called the LilyPad Arduino that makes this domain widely accessible for the first time; (2) research on a media-rich programming environment, Scratch, that is used by a worldwide community of designers of all ages; and (3) a conceptual framework of media arts in K-12 education that describes and analyzes creative digital production.<br\/><br\/>Using Csikszentmihalyi?s system model (1988, 1997), the PIs define creativity as the dynamic interaction between an individual?s contributions to a domain and community recognition within the field. To investigate the different components of creativity as a system, this project focuses on the technical, artistic and critical practices in youth? designs and interactions and employs a variety of assessment approaches including mixed methods data analyses of recorded group interactions, interviews with youth designers and professional artists, case studies of designers and artifacts, and log file data tracking online community participation and commentaries.<br\/><br\/>Intellectual Merit: This project presents a novel opportunity to study creativity within an emergent IT field (i.e., computational textiles and their applications) and will contribute to creativity research by providing empirically validated accounts of the system nature of creativity captured in interactions between individual designers and community feedback. Furthermore, they are developing tools for how to tailor programming to support 3D textile design, investigate an online community for sharing and validating creative computational textile designs, and investigate learning approaches in workshop models for computational textiles design for novice programmers.<br\/><br\/>Broader Impact: The proposed tools and activities broaden opportunities for youth from disadvantaged communities to develop advanced IT fluency skills by designing computationally enhanced materials and artifacts and contribute in meaningful ways to the emergent field of computational textile design. The implementation and assessment is conducted in workshops at after school sites that vary strategically in their technology experience to allow for a broader dissemination of the developed tools and activities. The findings from the work is shared with youth coordinators at professional development meetings, is presented at national conferences, and is disseminated further in academic journals and through their website.","title":"COLLABORATIVE MAJOR Computational Textiles as Materials for Creativity: Participatory Design Communities in Afterschool and Classroom Programs for Economically-Disadvantaged Youth","awardID":"0855868","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7788","name":"CreativeIT"}}],"PIcoPI":["526230"],"PO":["565227"]},"149078":{"abstract":"This work is aimed at bringing a micromechanical system into the fully quantum regime, which would result in a breakthrough in the field of opto\/nanomechanical systems. It would greatly broaden our notion of which physical systems can exhibit quantum effects and allow us to explore the physics associated with quantum optics and mesoscopic condensed matter in an entirely new type of system (i.e., mechanical), whose coupling to readout devices and the environment is qualitatively different from present-day quantum systems. The project uses ultrasensitive millimeter-scale membranes dispersively coupled to high-finesse optical cavities. This coupling is strong enough to laser-cool the membrane to its vibrational ground state, to observe the quantum back-action of displacement measurements, and to produce squeezed light. At the same time this coupling can be tuned to coax especially subtle quantum effects from the optomechanical system; by realizing a strong \"position squared\" readout we will observe the quantization of energy in the membrane's vibration and quantum jumps between the membrane's energy eigenstates. These goals cover a wide conceptual range, but they represent different facets of the same optomechanical coupling which can be realized in a single device. <br\/><br\/>These experiments are relevant to ultrasensitive instruments in a variety of fields. Quantum limited displacement measurements are relevant to astrophysical gravitational wave searches, as is the production of squeezed light. Micromechanical devices cooled to their ground state could serve as exceptionally sensitive detectors, particularly when coupled to a readout capable of registering the devices' individual quantum excitations. The conceptual simplicity of these systems, combined with the possibility of using them to explore exotic quantum phenomena on a macroscopic scale makes them appealing. The past few years have seen a rapid increase in the number of students, postdocs, and PIs working in this field, and an increased level of interest from scientific and general audiences. This work will serve as an excellent basis for training undergraduate, graduate, and postdoctoral students in important scientific techniques, and will prepare them for a wide range of careers in applied or fundamental research.","title":"Quantum Cavity Optomechanics","awardID":"0855455","effectiveDate":"2009-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"1290","name":"OPTICAL PHYSICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1710","name":"CONDENSED MATTER PHYSICS"}}],"PIcoPI":["511869"],"PO":["178795"]},"154061":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). <br\/><br\/>This project designs, analyzes, and implements a k-Cover-Sense-Inform (k-CSI) framework for heterogeneous and mission-oriented mobile wireless sensor networks, where connected k-coverage, scheduling, and data forwarding are jointly considered. It (a) builds a theoretical foundation to achieve connected k-coverage of a given a region of interest while minimizing the total number of heterogeneous sensors, (b) designs secure data routing and dissemination protocols on top of secure scheduling protocols for connected k-coverage while minimizing the energy consumption due to sensor mobility and their collaboration, and (c) develops a prototype for k-CSI and assesses its performance through simulations using network simulator TOSSIM, and implementation using mobility-enabled MICAz motes based test-beds while considering various mobility models and a variety of network configuration and missions.<br\/>These research efforts are integrated with development of courses on mission-oriented mobile wireless sensor networks. The project helps recruit graduate and undergraduate students, especially economically disadvantaged students, including minorities, and expand the perspectives of K-12 teachers and high-school students by illustrating aspects of scholarship and methodology through High School University Seminar Series offered to local school districts in Long-Island, New York. Results are disseminated through publications in conferences and journals.","title":"RUI: NetS:Small: A Collaborative and Secure k-Cover-Sense-Inform Framework (k-CSI) for Heterogeneous Deployment of Mission-Oriented Mobile Wireless Sensor Networks","awardID":"0917089","effectiveDate":"2009-08-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["519845"],"PO":["565303"]},"148891":{"abstract":"The primary objective of the project is to develop and deploy a repository that supports the sharing and transition of model-driven development (MDD) experience and knowledge to a broad community of researchers, practitioners, and educators. MDD research focuses on developing techniques and technologies that enable generation of dependable software from abstract models. The Repository for Model Driven Development (ReMoDD) will contain documented MDD case studies, models illustrating good and poor modeling practices, and educational material. The ReMoDD platform will provide interfaces and interchange mechanisms that users and tools can use to retrieve and submit artifacts. MDD researchers can use ReMoDD artifacts to evaluate research results, and to perform comparative and empirical MDD studies. Practitioners and students can use the resource to gain better understanding of MDD practices and techniques, while educators can use ReMoDD to share teaching experience and materials. The development of ReMoDD is a collaborative effort involving teams from Colorado State University (CSU) and Michigan State University (MSU). The teams will interact with the MDD community to collect and evaluate candidate ReMoDD artifacts. An Advisory Board of leading MDD researchers and practitioners has been established to ensure that ReMoDD becomes a useful and sustainable community resource.","title":"Collaborative Research:CI-ADDO-NEW: Research Repository for Model-Driven Software Development (REMODD)","awardID":"0854988","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["543603","557996"],"PO":["564388"]},"146394":{"abstract":"To improve disk I\/O performance, one may integrate multicore processors with parallel disk systems. Unfortunately, architectures and data processing algorithms for multicore-based parallel disk systems are still in their infancy. This motivates us to develop novel architectures for parallel disk systems, where significant multicore processing power and memory are integrated into parallel disk drives. This CAREER project provides the first parallel disk system in which large parts of data and I\/O processing are offloaded to multicore processors, embedded in disk drives. The proposed techniques and mechanisms are highly adaptive to dynamic workloads with both large and small disk requests, making modern parallel disk systems leverage multicore processors for better performance and scalability.<br\/><br\/>The overall objective of this CAREER Development project is to build hardware and software parallel disk architectures that put substantial multicore computing power on disks. The research consists of three basic tasks: (1) designing hardware and software architectures for multicore-based parallel disk systems, (2) developing multicore-based data processing techniques, and (3) building software performance models and an analysis toolkit. The educational plan include: (1) establishing a storage systems laboratory; (2) developing new courses; (3) implementing the concept of a mini-conference to educate students; and (4) increasing underrepresented student involvement in research activities. In addition, the project would benefit society by developing hardware and software modules for next-generation parallel disk systems, where multicore processors and disk drives are tightly integrated to boost disk I\/O performance.","title":"CAREER: Multicore-Based Parallel Disk Systems for Large-Scale Data-Intensive Computing","awardID":"0845257","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["409962"],"PO":["366560"]},"149221":{"abstract":"Multidisciplinary teams composed of computer scientists, arts and computer science educators, and learning scientists from the University of Pennsylvania, MIT and Indiana University are researching how to encourage about 400 youth (ages 10-18) to creatively engage with computational textiles in afterschool and school settings. Computational textiles?textile artifacts that are computationally generated or that contain embedded computers?will capture youths? pre-existing interests in new media, fashion, and design while supporting learning and creativity in computer science, arts, design, and engineering.<br\/><br\/>The PIs are designing a new programming toolkit for 3D textile design to promote creativity and to study these tools in different workshop settings in afterschool and classroom programs. While previous efforts have focused on developing environments for 2D and 3D programming for novices, their goal is to expand these efforts to include 3D textile design to appeal to disadvantaged youth not normally drawn into computing. Moreover, they are developing an open, participatory website that allows youth to display their created artifacts and share, discuss, and remix their designs. These efforts build on our prior successes developing an online community around Scratch, which now hosts over 10,000 designers. They are engaging local youth communities and professional advisors from a variety of backgrounds to identify and encourage creative design solutions as part of their efforts to build this community, the first-ever youth community of computational textile designers.<br\/><br\/>The proposal leverages several successful developments: (1) a construction kit for building computational textiles called the LilyPad Arduino that makes this domain widely accessible for the first time; (2) research on a media-rich programming environment, Scratch, that is used by a worldwide community of designers of all ages; and (3) a conceptual framework of media arts in K-12 education that describes and analyzes creative digital production.<br\/><br\/>Using Csikszentmihalyi?s system model (1988, 1997), the PIs define creativity as the dynamic interaction between an individual?s contributions to a domain and community recognition within the field. To investigate the different components of creativity as a system, this project focuses on the technical, artistic and critical practices in youth? designs and interactions and employs a variety of assessment approaches including mixed methods data analyses of recorded group interactions, interviews with youth designers and professional artists, case studies of designers and artifacts, and log file data tracking online community participation and commentaries.<br\/><br\/>Intellectual Merit: This project presents a novel opportunity to study creativity within an emergent IT field (i.e., computational textiles and their applications) and will contribute to creativity research by providing empirically validated accounts of the system nature of creativity captured in interactions between individual designers and community feedback. Furthermore, they are developing tools for how to tailor programming to support 3D textile design, investigate an online community for sharing and validating creative computational textile designs, and investigate learning approaches in workshop models for computational textiles design for novice programmers.<br\/><br\/>Broader Impact: The proposed tools and activities broaden opportunities for youth from disadvantaged communities to develop advanced IT fluency skills by designing computationally enhanced materials and artifacts and contribute in meaningful ways to the emergent field of computational textile design. The implementation and assessment is conducted in workshops at after school sites that vary strategically in their technology experience to allow for a broader dissemination of the developed tools and activities. The findings from the work is shared with youth coordinators at professional development meetings, is presented at national conferences, and is disseminated further in academic journals and through their website.","title":"COLLABORATIVE MAJOR Computational Textiles as Materials for Creativity: Participatory Design Communities in Afterschool and Classroom Programs for Economically-Disadvantaged Youth","awardID":"0855773","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":["469513"],"PO":["565227"]},"159298":{"abstract":"This proposal requests funding to assist approximately 40 US-based researchers to attend the First Workshop on Deterministic Multiprocessing (WoDet) in Seattle, WA, in the first week of October 2009. The goals of the workshop are to initiate a discussion in the areas of deterministic multiprocessing from languages all the to hardware and tools and to spark funding for new research programs. While there is a growing consensus that determinism would greatly help with the programmability challenges of multicore systems, there is still little consensus on many important questions. <br\/>The support requested enables the participation of both academic and industry researchers. The PIs also open the workshop to a select set of students who are already working in the area.","title":"Travel Support for the First Workshop on Deterministic Multiprocessing (WoDet)","awardID":"0940512","effectiveDate":"2009-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}}],"PIcoPI":["555936"],"PO":["565272"]},"159188":{"abstract":"Proposal ID: CCF - 0939976 <br\/>Proposal Title: Design Automation Summer School 2009<br\/>PI Name: Shang Li <br\/>Title: University of Colorado at Boulder <br\/><br\/><br\/>A group of active researchers in the field of Electronic Design Automation is organizing a summer school in the form of a workshop for young researchers in the field. The summer school will be co-located with the annual Design Automation Conference (DAC) to be held in San Francisco in July 2009. DAC is the main annual event and a major conference in the field that is to be expected to be attended by most active researchers in the field. <br\/><br\/>The workshop speakers will be mostly established and prominent researchers in the field of microelectronic design automation. The fact that the summer school is co-located will be an added advantage in that the most speakers at the workshop will not need to spend additional effort for their travel.<br\/><br\/>In the past similar groups have organized very similar events that have been very successful in bringing young generation of researchers up to speed with state of the art tools and techniques in modern electronic design automation. <br\/>This workshop is expected to have a similar impact.","title":"Design Automation Summer School","awardID":"0939976","effectiveDate":"2009-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["485555"],"PO":["562984"]},"159078":{"abstract":"This CPATH Project extends the Small Footprint model, successfully pioneered and developed at the Franklin W. Olin College of Engineering, to four other institutions, Massachusetts Amherst, Harvard, Colby, and Rensselear Polytechnic. The principal investigator will work with other academic institutions to adapt the lessons learned at Olin to a broader set of schools, specifically addressing the diverse needs of different kinds of educational institutions. Among the virtues of the small footprint curriculum are: a reduced core that concentrates on the particular elements that are required in order to learn the rest of computing; an emphasis on teaching students to learn more on their own; room for and an emphasis on active, hands-on, project-based and inquiry-driven projects, often carried out in teams; opportunities to collaborate with other disciplines and to build genuinely joint curriculum; and contextualization of the core of computing education. A diverse initial group of pioneer collaborators have are committed to immediate curricular reform. A series of workshops and town hall meetings as well as an online consultation will be used to identify and recruit additional partner institutions and to create a national shift in understanding of what is necessary to the revitalization of computing education.<br\/><br\/>Intellectual Merit: Widespread change in computing curricula requires careful construction of viable models. The approaches of this project should provide opportunities for multi-disciplinary collaboration as the core computing curriculum is refactored to emphasize computing's durable bones. The PI brings a unique background including prior successes in growing curricula outwards from single institutions and extensive experience developing both a small footprint curriculum for computing and an engineering educational program. The first round partner schools have been carefully selected to provide diverse models from which to bootstrap a national conversation and community.<br\/><br\/>Broader Impact: The primary focus of this project is the content and style of teaching, training, and learning in computing. The project will engage many educators in active conversation and then transformation of undergraduate computing programs. In turn, these curricular reforms will change the educational experiences of students in traditional computing disciplines and create new opportunities for students through the development of interdisciplinary programs. Initially the project is geographically centered but over time the project will broaden its reach through workshops, town hall meetings, publications, electronic and in-person consultation by the PI, and hands-on curricular revision. Eventually, every university in the nation should be able to look to at least one successful adaptation of the small footprint curriculum at a peer institution, so that curricular reform moves from radical innovation to the easier processes of emulation and adoption.","title":"CPATH-1: Spreading Small Footprints","awardID":"0939128","effectiveDate":"2009-08-15","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["434524"],"PO":["564181"]},"154051":{"abstract":"Dynamic thermal management is the process of controlling surges in the operating temperature especially of a multi-core processor during runtime, based on limited measurements by on-chip thermal sensors. Managing thermal sensors and processing their measurements presents a rich vein of theoretical and practical challenges including: deciding on the number, location and type of thermal sensors; estimating the thermal profile; and characterizing the fundamental performance tradeoffs between sensor quantity and complexity in guaranteeing estimate accuracy. In this interdisciplinary project, we propose a new approach to the problem of thermal profile estimation in multi-core processors which relies on fundamental information theoretic principles. Our approach rests on new problems in information theory that capture the salient features of on-chip thermal profile estimation. Our new formulations are inspired notably by rate distortion theory and also bear a similarity to compressed sensing. Furthermore, our approach has wider applicability to general problems of parameter estimation based on limited sampled and quantized measurements.<br\/><br\/>The project has a home in computer architecture, VLSI design as well as one in information theory and compressed sensing. Its potential impact is twofold: (a) improvement in the performance and reliability of multi-core processors; and (b) new models and problem formulations in the fields of information theory and compressed sensing. The broad reach of this project will provide a valuable learning environment for the investigators and their graduate and undergraduate students. The basic elements of the technical approach will be discussed in Special Topics courses and seminars with the participation of graduate students.","title":"CIF: SMALL: Information Theoretic Multi-Core Processor Thermal Profile Estimation","awardID":"0917057","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["561385","541967"],"PO":["562984"]},"154084":{"abstract":"Tuning software for improved performance\/power is often extremely difficult because one cannot easily observe the entire inner workings and power consumption of running hardware at a fine time resolution. Thus, determining the root cause of performance and power issues can often only be done by careful crafting of experimental code, running that code, and measuring the limited information that can be observed.<br\/><br\/>This proposed research is aimed at designing a new class of very fast and accurate simulators that, with proper instrumentation, can provide significantly more visibility than the modeled hardware. However, such simulators can result in information overload, making finding the issues difficult. Thus, the PI proposes to investigate methods to effectively and automatically find such issues so that they can more quickly and easily be addressed. Such methods could result in more efficient computer systems that can solve problems faster and\/or use less energy, potentially impacting hardware and software developers and users alike.","title":"SHF:Small:Multicore Hardware\/Software CoDesign using Fast, Cycle-Accurate Simulators","awardID":"0917158","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["535119"],"PO":["366560"]},"148100":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>This REU Site hosts ten students each year to engage in software language engineering research for eight weeks in the summer. This builds research and technical communication skills in the students through training and practice during the summer program and through experience at their home institutions. The students also engage in a professional conference after the summer program concludes. At the beginning of the summer program the students are provided with orientation and team building exercises to embolden students to initiate team projects and to engage with the faculty mentors and their graduate students.<br\/><br\/>Intellectual Merit: Software language engineering is the application of a software engineering approach to the development, use, and maintenance of software languages. Specific student projects are involved with the maintenance of multi-language software systems, the development of pedagogical functional programming languages, and language constructs and libraries for programming embedded systems. The PIs have a strong track record of research in this area and have demonstrated experience in leading undergraduate student research.<br\/><br\/>Broader Impacts: A principal objective of this REU Site is the recruitment of a diverse group of talented students. Via a focused recruitment effort this site engages students from underrepresented groups and undergraduate institutions in computer science research. During the recruitment process, the PIs establish contact with faculty and students at community colleges, undergraduate institutions, women's colleges, and historically black colleges and universities and give presentations about opportunities available at the REU site and, more generally, in computer science research. Once students are accepted for participation in the REU Site, the faculty mentors and their graduate students guide the participants through research projects and also encourage them to consider attending graduate school and remaining active in the computer science research community. After returning to their home institutions the participants give presentations to their fellow undergraduate students, further broadening the group of students impacted by the proposed REU Site. In addition, all participants have the opportunity to attend a professional conference and to disseminate the results of their research, either informally through conversations with other attendees, or formally through an oral or poster presentation.","title":"REU Site: Software Language Engineering","awardID":"0851824","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1139","name":"RSCH EXPER FOR UNDERGRAD SITES"}}],"PIcoPI":[394731,"543615"],"PO":["523800"]},"149794":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>In the last few years, Huang has proved the Verlinde conjecture and the Verlinde formula which play a fundamental role in Conformal Field Theory and related subjects and has proved the rigidity and modularity of the ribbon category of modules for vertex operator algebras satisfying certain natural conditions. He has investigated other problems in the mathematical foundation of two-dimensional conformal field theory. His interest is in tackling some of the still-unsolved hard problems in that field. The proposed research of Huang is expected to give results on general orbifold conformal field theories and higher-genus conformal field theories, a mathematical understanding of the connection between certain orbifold conformal field theories and certain Calabi-Yau manifolds, a solid foundation to a mathematical theory of deformations of conformal field theories, a better understanding of the geometry of Calabi-Yau manifolds related to conformal field theories and new insight into the mathematics underlying problems in physics. <br\/><br\/>Broader impacts arise from the PI's teaching, mentoring, advising, lecturing, expository writing, conference-organizing, seminar-organizing, volume-editing and other such activities. In particular, he will continue to devote a large amount of time to train REU undergraduate students and Ph.D. students. Huang will continue to encourage the participation of women and members of underrepresented minority groups in their areas of study. Besides studying the theoretical aspects of two-dimensional conformal field theory, Huang is also interested in finding applications of his results and approaches to problems in physics, such as problems related to quantum computing and string theory.","title":"Two-dimensional conformal field theories and their moduli space.","awardID":"0901237","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"1287","name":"MATHEMATICAL PHYSICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0507","name":"Division of SCIENCE EDUCATION RESOURCES IM","abbr":"SER"},"pgm":{"id":"1264","name":"ALGEBRA,NUMBER THEORY,AND COM"}}],"PIcoPI":["480278"],"PO":["563190"]},"146880":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br\/><br\/>Future discovery and control in biology and medicine will come from the mathematical modeling of large-scale molecular biological data, such as DNA microarray data, just as Kepler discovered the laws of planetary motion by using mathematics to describe trends in astronomical data. In prior work, generalizations of the matrix computations that underlie theoretical physics were developed, and their use was pioneered in creating models from DNA microarray data. These models have been used to predict mechanisms that govern the activity of DNA and RNA, including a previously unknown mechanism of regulation that correlates DNA replication initiation with RNA expression during the cell cycle, the first mechanism to be predicted from mathematical modeling of microarray data. Preliminary experimental results verify this computational prediction, demonstrating for the first time that mathematical modeling of microarray data can be used to correctly predict previously unknown cellular mechanisms. This work will now be extended by creating the first tensor algebra models, integrating and comparing different types of cell cycle data from different studies and organisms and under different conditions. This project will result in innovative mathematical frameworks for large-scale data analysis, as well as new insights into the cellular program of cell division. For example, one preliminary tensor model is the only mathematical framework to date that enables comparison of data from multiple organisms without being limited to similar genes among these organisms. This model promises to reveal universality and specialization of evolutionary, biochemical and genetic pathways that are truly on genomic scales. Another preliminary model enables integration of data from time courses under different perturbations into a coherent picture of the effects of these perturbations on cell cycle progression. This model promises to uncover previously unrecognized causal coordination of cellular activities.<br\/><br\/>Recently developed high-throughput technologies, such as the DNA microarray, make it possible for the first time to record the complete molecular biological signals that guide the progression of cellular processes, i.e., tell cells what to do and when and where to do it. Biology and medicine today may be at a point similar to where physics was after the advent of the telescope. The rapidly growing number of large-scale data sets holds the key to the discovery of cellular mechanisms, just as the astronomical tables compiled by Galileo and Tycho enabled accurate predictions of planetary motions and, later, the discovery of universal gravitation. Just as Kepler and Newton made these predictions and discoveries by using mathematical frameworks to describe trends in astronomical data, so future discovery and control in biology and medicine will come from the mathematical modeling of large-scale molecular biological data. In this project, mathematical frameworks for large-scale data analysis are developed and used to create models from microarray data, and predict cellular mechanisms. For example, earlier work predicted a previously unknown mechanism of regulation that correlates the beginning of DNA replication with RNA transcription, the process by which the information in DNA is transferred to RNA, during the cell division cycle. This is the first mechanism to be predicted from mathematical modeling of microarray data. Preliminary experimental results verify this computational prediction, demonstrating for the first time that mathematical modeling of microarray data can be used to correctly predict previously unknown cellular mechanisms. This project will now extend this work by creating models that integrate and compare different types of cell cycle data from different studies and organisms and under different conditions. Models such as these may become the foundation of a future where physicians model and control biological systems as readily as engineers model and control physical systems today. In this future, cancer and disease can be stopped or reversed, damaged tissues can be engineered to regenerate, and aging can be slowed or even halted altogether.","title":"CAREER: Integrative and Comparative Tensor Algebra Models of DNA Microarray Data from Different Studies of the Cell Cycle","awardID":"0847173","effectiveDate":"2009-08-15","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7334","name":"MATHEMATICAL BIOLOGY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7933","name":"NUM, SYMBOL, & ALGEBRA COMPUT"}}],"PIcoPI":[391432],"PO":["230845"]},"154030":{"abstract":"Over recent decades, power and complexity challenges have limited the ability to derive continued growth in computing performance through clock frequency scaling. Future growth will come through implementing systems with many independent processors on the same chip. Challenges lie, however, in writing software for these systems, and in creating software that is portable across several hardware generations. For parallel software to smoothly exploit a chip's computation and communication capabilities, hardware needs better information regarding software's structure and resource requirements. Analogous to the traditional, fine-grained instruction set architecture (ISA), this research proposes a higher-level, coarse-grained System-level ISA or SISA. SISA provides information on computational chunks and the data or synchronization dependencies between them. Expressing software as a coarse-grained directed graph, SISA enables efficient, adaptive scheduling of parallel computation and communication. It also offers other benefits for reliability, energy-efficiency and portability. <br\/><br\/>The proposed research program will have broad impact in several ways. First, the PI has a solid track record of knowledge dissemination and technology transfer. This includes extensive collaborative relationships with industry, and several patents. In addition, the PI has a track record of releasing high-impact software tools for external use. The Wattch power modeling tool is one of five major tools distributions from her group, in use by thousands of computing researchers worldwide. The PI also has a strong track record of support for undergraduate research and underrepresented groups, and has also advised summers of undergraduate research with women and under-represented minorities through CRA-W and Princeton programs. She has been involved in teaching non-STEM students and multidisciplinary efforts, and will continue and broaden such activities through this research.","title":"SHF: Small: SISA: A System-Level ISA for Power-Performance Management in CMPs","awardID":"0916971","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["495323"],"PO":["366560"]},"143272":{"abstract":"Designing suitable network pricing mechanisms is important for both (i) recovering the cost of providing existing network services and (ii) encouraging deployment of new services and expansion of network capacities. Since service providers are often selfish private entities, the problem of network pricing is studied using tools from economics, in particular, game theory.<br\/><br\/>When there exists uncertainty regarding the payoff (i.e., profit) of the service providers, called players, recent findings show that risk averse players can behave very differently and change the interaction among the players considerably. As a result, even a pricing scheme that seems rather natural can provide them with an incentive to lie about their private information. This in turn causes a loss in the overall benefit and a significant drop in the profits to the players, discouraging the deployment of new services. Thus, this calls for a careful look at the consequences of uncertainty in payoffs and risk aversion by players on the overall social welfare and the payoffs to the players.<br\/><br\/>The goal of the project is to take the first step towards identifying suitable frameworks for designing efficient and fair network pricing mechanisms: The first part of the project will carry out a thorough investigation of the impacts of uncertainty in payoffs of the players and risk averse players on likely equilibria in a set of well formulated and targeted scenarios and their implications on the design of pricing mechanisms. The second part will examine how much of social welfare can be lost due to the selfish nature of the players and the uncertainty and aims to find suitable bounds when possible.<br\/><br\/>Expected outcomes from the project will help service providers identify more suitable pricing schemes that will encourage the deployment of new services through fair profit sharing and improved efficiency. This will promote collaboration among selfish service providers and bring more network services and lower prices to the consumers, while increasing the overall social benefits\/welfare.","title":"TF: Network pricing with uncertainty: risk aversion and incomplete information","awardID":"0830675","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7932","name":"COMPUT GAME THEORY & ECON"}}],"PIcoPI":["381525"],"PO":["565251"]},"148992":{"abstract":"The objective of this project is to acquire and set up a wireless measurement infrastructure and use it to research new wireless link signatures and their applications. The signature of a wireless link between a wireless transmitter and a receiver represents the wireless link's unique physical characteristics. Wireless link signature applications include secret key establishment between a wireless transmitter and a receiver without ever communicating the secret key, and location distinction which is the ability to detect at one or more receivers when a transmitter changes its location.<br\/><br\/>The intellectual merit of this research includes (i) extensive measurements of wireless link characteristics under (a) heterogeneous indoor and outdoor settings, (b) a variety of wireless standards with different types of transmitters, and (c) different frequency bands with the help of highly capable spectrum analyzers, (ii) development of novel methodologies for different wireless link signature applications including location distinction, and secret key establishment, using these measurements, and (iii) evaluation of the methodologies through implementation.<br\/><br\/>This research impacts the development and deployment of wireless link signature-based applications. It also contributes a vast amount of measurement data that is useful for understanding unique wireless link characteristics, and also traditional wireless link performance modeling and evaluation. This research activity is integrated in the education curriculum through new measurement and inference projects in the networking and security classes. Furthermore, this research is used in conjunction with an existing NSF STEP project for high school outreach.","title":"II-NEW: An Infrastructure for Researching Wireless Link Signatures","awardID":"0855261","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["542075","464564"],"PO":["565136"]},"157594":{"abstract":"CCF - 0930477 <br\/>NSF Workshop; Electronic Design Automation -- Past, Present, and Future<br\/>Cong, Jason <br\/>University of California-Los Angeles <br\/><br\/>ABSTRACT<br\/>Electronic design automation (EDA) of very large-scale integrated (VLSI) circuits and systems is an important field in computer science and engineering. It has made a significant impact on the development of information technology?in particular in supporting the successful scaling of Moore?s Law over the past 40 years, which in turn has created the performance and cost-efficient information technology infrastructure that has transformed our lives and all of society. The success of the EDA is inspiring for many scientific and societal reasons.<br\/><br\/>At the same time, the EDA field is facing serious challenges. For example, Non-Recurring Engineering (NRE) costs associated with VLSI circuit design are skyrocketing with estimates of over $30M per ASIC design undertaken. The rapid increase in the number of transistors available on a single chip leads to system-on-chip integration, with complex interactions between software and hardware, digital and analog, etc. Moreover, the field of applications enabled by semiconductor technology is growing at a rapid rate?ranging from very high performance microprocessors and signal processors to a broad array of low-power portable devices to micro sense\/communicate\/actuate networks of chips driven by very low per-unit cost and extremely low operating power. Designers must create chips that function properly in conventional digital and mixed-signal operation, as well as comprehend sensors that respond to signals from many physical domains such as pressure, temperature, chemical, and optical. The design problem is further compounded by the introduction of many new physical phenomena determining the performance of severely scaled semiconductor devices. For example, the power and performance characteristics of transistors are becoming statistical in nature. The probability of soft or permanent errors is much higher in the new generation of CMOS devices at 32nm or below or in new emerging non-CMOS devices. These present unprecedented challenges.<br\/><br\/>In an earlier workshop jointly held in 2006 by the NSF and SRC a recommendation was made that research in design technology and tools be increased through a National Design Initiative. Such an effort was deemed to be critical ?to maintain U.S. leadership in design for integrated nano- and Microsystems.? The present workshop is to review the progress made under the National Design Initiative and evaluate whether new directions and topics should be added to the Initiative. The recommendations from this workshop will help to influence the design automation funding programs at the NSF.","title":"NSF Workshop; Electronic Design Automation -- Past, Present, and Future","awardID":"0930477","effectiveDate":"2009-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["518632","558485"],"PO":["562984"]},"154096":{"abstract":"Proposal ID: 0917204 <br\/>Pi name: Li Peng <br\/>Inst: Texas Engineering Experiment Station <br\/>Title: System-Theoretic Analysis and Design for Dynamic Stability of Memory Devices in Nanoscale CMOS and Beyond<br\/><br\/>Abstract<br\/><br\/><br\/>Data storage is essential to a broad range of electronic and biological systems. Static random access memories (SRAMs) provide essential on-chip data storage for many electronic applications including microprocessors, ASICs, DSPs and SoCs. There also exists a growing effort in developing engineered genetic memory circuits to facilitate new understanding of cellular phenomena in natural organisms, cellular control and biocomputing. This work intends to facilitate the understanding, analysis and enhancement of dynamic stability, a key system property, for semiconductor SRAMs, emerging memristor and biological memories. Conventional static SRAM stability metrics are unable to capture intrinsic dynamic circuit operations and hence inherently limited in their applications. This work addresses the need for a rigorous understanding of dynamic stability in semiconductor and genetic memories via a system-theoretic approach. Nonlinear system theory will be exploited to construct new dynamic noise margin concepts and design metrics with theoretic rigor and design insights. Novel system theoretically motivated numerical algorithms will be developed to facilitate analysis and optimization with significantly improved efficiency. <br\/><br\/> This work will facilitate the design of nanoscale computing systems as well as the development of synthetic gene-regulatory networks. Interdisciplinary explorations will provide new opportunities for solving research problems of practical significance and offer educational opportunities to students. The PIs will promote the research participation from undergraduate students and students from underrepresented groups and engage in high-school teacher enrichment programs. The research outcomes will be integrated into undergraduate and graduate curriculum and disseminated in the research community and major semiconductor companies.","title":"SHF: Small: System-Theoretic Analysis and Design for Dynamic Stability of Memory Devices in Nanoscale CMOS and Beyond","awardID":"0917204","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":[410011,"486370"],"PO":["562984"]},"146484":{"abstract":"The most commonly used methodology for validating the quality of software is testing. Conceptually, testing is simple. In practice, however, testing has two key limitations: it is expensive, often amounting to over a half of the development cost, and ineffective, often failing to find crucial bugs that can cause significant damage.<br\/><br\/>This project addresses these limitations by developing a novel test automation framework based on test summaries -- abstract properties of desired tests. Developers write summaries as logical constraints that define desired inputs and properties to check, and the tools perform testing against dense suites that are likely to find many bugs. The project develops: (1) core algorithms for effective systematic testing, which generate high quality inputs, perform deep white-box checking, and synthesize executable test oracles; (2) optimization strategies for efficient systematic testing, which scale it to large applications; (3) incremental techniques for supporting evolution, which provide efficient test updates with respect to code changes; and (4) infrastructure support for enhancing usability, which assists developers with writing test summaries. Case studies using a variety of applications are used for evaluation.<br\/><br\/>Systematic testing using test summaries will substantially increase test coverage and accuracy, which will significantly improve software quality. The PI's industrial collaborations and participation in UT's Executive Masters program enable a swift technology transfer to industry.","title":"CAREER: Scalable and Systematic Test Authoring and Maintenance","awardID":"0845628","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["550525"],"PO":["564388"]},"153580":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5. <br\/><br\/>This grant supports research in adapting and optimizing Markov Chain Monte Carlo methods to compute Bayesian models on large data sets resident on secondary storage, exploiting database systems techniques. The work will seek to optimize computations, preserve model accuracy and accelerate sampling techniques from large and high dimensional data sets, exploiting <br\/>different data set layouts and indexing data structures. The team will develop weighted sampling methods that can produce models of similar quality as traditional sampling methods, but which are much faster for large data sets that cannot fit on primary storage. One sub-goal will study how to compress a large data set preserving its statistical properties for parametric Bayesian models, and then adapting existing methods to handle compressed data sets. <br\/><br\/>Intellectual Merit and Broader Impact <br\/><br\/>This endeavor requires developing novel computational methods that can work efficiently with large data sets and numerically intensive computations. The main technical difficulty is that it is not possible to obtain accurate samples from subsamples of a large data set. Therefore, the team will focus on accelerating sampling from the posterior distribution based on the entire data set. This problem is unusually difficult because stochastic methods require a high number of iterations (typically thousands) over the entire data set to converge. However, if the data set is compressed it becomes necessary to generalize traditional methods to use weighted points combined with higher order statistics, beyond the well-known sufficient statistics for the Gaussian distribution. Developing optimizations combining primary and secondary storage is quite different from optimizing an algorithm that works only on primary storage. This research effort requires comprehensive statistical knowledge on both Bayesian models and stochastic methods, beyond traditional data mining methods. A strong database systems background in optimizing computations with large disk-resident matrices is also necessary. This research will enable a faster solution of larger scale problems compared to modern statistical packages to solve stochastic models. Bayesian analysis and model management will be easier, faster and more flexible. <br\/><br\/>Broad Impact <br\/><br\/>This research will occur within the context of three separate application areas: cancer, water pollution, and medical data sets with patients having cancer and heart disease. The educational component of this grant will enhance current teaching and research on data mining. In an advanced data mining course students will apply stochastic methods to compute complex Bayesian models on hundreds of variables and millions of records. Data mining research projects will be enhanced with Bayesian models, promoting interaction between statistics and computer science. <br\/><br\/>Keywords: Bayesian model, stochastic method, database system","title":"III: Small:Collaborative Research: Bayesian Model Computation for Large and High Dimensional Data Sets","awardID":"0915196","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[408728],"PO":["563751"]},"154020":{"abstract":"This award is funded under the American Recovery and Reinvestment Act<br\/>of 2009 (Public Law 111-5). <br\/><br\/>The project will develop efficient mechanisms for deploying and managing wireless self-organizing networks (WSONs). These networks are able to manage themselves with little or no human intervention and consequently can be deployed in remote, difficult-to-access areas, under adverse conditions, and\/or when users have little or no network administration skills. As such, WSONs can have significant societal and scientific impact as key enablers of numerous applications, including emergency response, disaster relief, community networking, environmental monitoring, and surveillance.<br\/><br\/>Intellectual Merit: This work will develop theoretical foundations for efficient WSON node placement and trajectory control based on geometric computation and optimization. The technical approach explores the synergy among a variety of disciplines, including wireless communications, facility location, geometric and distributed optimization, and systems and control theory. The project will (i) explore, develop, and evaluate novel geometric computing strategies for WSON placement, management, and control in order to optimize system performance for a range of applications, and (ii) deploy the proposed strategies in real-world environments motivated by our ongoing collaborations with biologists and oceanographers.<br\/><br\/>Broader Impact: The WSON deployment and management strategies developed in this work will be key enabling technology for a variety of applications with considerable societal and scientific significance. The project also includes an important educational component. It will produce exciting MSc and PhD theses, incorporate results into graduate classes, and engage undergraduate students via field experiments, senior design projects and summer REUs.","title":"NetSE: Small: Collaborative Proposal: A Geometric Computational Approach to Efficiently Deploy and Manage Self-Organizing Wireless Communication Networks","awardID":"0916941","effectiveDate":"2009-08-15","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["551159"],"PO":["564924"]},"154141":{"abstract":"The semiconductor industry is at an interesting crossroads, where traditional scaling of CMOS devices is beginning to confront significant challenges that are threatening to derail the more than four-decades old Moore?s law. 3D integrated circuits (3D ICs) offer an exciting alternative, where in lieu of scaling, continuous increase in functionality, performance and integration density can be sustained indefinitely by stacking semiconductor layers on top of each other in a ?monolithic? manner. A 3D IC is comprised of two or more active (semiconducting) layers that have been thinned, bonded and interconnected using special vertical wires drilled through the active layers known as ?Through Silicon Vias (TSV)?. When TSVs (10-100 micrometer long) are used to replace the longest (several millimeters) on-chip horizontal wires as well as some chip-to-chip connections (on printed circuit boards), significant reduction in wire delay and chip power dissipation can be achieved. Moreover, 3D ICs also offer the most promising platform to implement ?More-than-Moore? technologies, bringing heterogeneous materials (Silicon, III-V semiconductors, Graphene, etc) and technologies (memory, logic, RF, mixed-signal, MEMS, optoelectronics, etc) on a single chip. <br\/><br\/>However, modeling and analysis of interconnects in 3D ICs present new and significantly more complex problems. In contrast with traditional interconnects, the modeling of high aspect-ratio TSVs embedded in a semiconducting material with non-uniform currents in the third dimension, and electromagnetic coupling of interconnects with multiple conductive substrates at high-frequencies, constitute new challenges for design and design-automation methods. Furthermore, the high power-density in 3D ICs due to multiple active layers and their limited heat removal options give rise to large three-dimensional thermal gradients, making it important to consider the coupling between thermal and electromagnetic properties of interconnects and the surrounding media. Finally, the need for accuracy is accompanied by the computational challenge of handling a large number of coupled interconnects at the system level, as 3D integration further exacerbates the size of the interconnect problem.<br\/><br\/>This project will develop the necessary foundations for coupled electrical-thermal modeling and analysis of interconnects and passives in 3D ICs, considering the electromagnetic coupling of general 3D interconnects with multiple substrates at ultra-high frequencies as well as the physical attributes of high aspect-ratio TSVs (including geometry, material and density), using thermally-aware and inherently efficient techniques to enable full-chip modeling of the large system of interconnects. The overall program also ties research to education at all levels besides focusing on recruitment and retention of underrepresented groups in nanoscience and engineering.","title":"SHF:Small: A CAD Framework for Coupled Electrical-Thermal Modeling of Interconnects in 3D Integrated Circuits","awardID":"0917385","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["508555"],"PO":["562984"]},"148960":{"abstract":"\"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\"<br\/><br\/>One of the grand challenges in robotics is to achieve dexterity, especially dexterity in manipulation. The equipment funded by this project ? a robot torso, two arms, and a custom designed robot hand, supports investigation of manipulation tasks, with a particular focus on two-handed dexterous manipulation. <br\/><br\/>Primary projects include (1) task transfer of two-handed manipulation tasks from human demonstrations and (2) application domain specific designs for a non-dominant robot hand. For task transfer, this project explores a combination of task understanding, planning and learning, and direct user interaction, following along the lines of our previous research in one handed grasping and manipulation. For hand design, this project pursues design optimization to develop the simplest possible robot hand capable of accomplishing a suite of everyday tasks, operating as the non-dominant hand. This approach promises new insights into the required number of degrees-of-freedom of the hand, the required number of drive motors, required sensing, and the geometry of critical but often ignored parts of the hand, such as the palm.<br\/><br\/>Broader impact includes forming a better understanding of human motion. We believe that we can only successfully transfer a task from a human demonstration to a robot performance if we understand a great deal about why a person chooses to perform a task in a certain way. Our proposed robot hand design project also has great implications for prosthetic design, as our robot hand design process will be driven with goals of simplicity in design and ability to perform tasks from everyday life.","title":"II-EN: Robotic Equipment for the Investigation of Dexterous Two-Handed Manipulation","awardID":"0855171","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["560865"],"PO":["543539"]},"143284":{"abstract":"A signal, when transfered over a long distance, is likely to be corrupted. Error-correcting codes have been designed to solve this problem, so modern communications are possible as we see today. Algebraic codes are mathematically interesting and intriguing, and they form the backbone of coding theory and its applications. The best algorithms for many algebraic codes are very powerful but not very practical. Also, the exact decoding complexity is not well understood for these codes, including the simple but extremely important Reed-Solomon codes. The project will strive to identify the complexity of decoding algebraic codes and to design more efficient algorithms for a large class of algebraic codes. <br\/><br\/>The main focus is on algebraic codes with natural parameters. The complexity results for these natural codes thus are more relevant to communication practice. It is expected that the project will lead to a number of substantial new results linking coding theory, computer sciences and mathematics. The project is also expected to develop graduate courses and train students in this cross-disciplinary research area","title":"Collaborative Research: Complexity and Algorithms of Decoding Algebraic Codes","awardID":"0830701","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}}],"PIcoPI":[381522],"PO":["565157"]},"154064":{"abstract":"The objective of this research is to systematize the derivation of algorithms in the field of iterative linear system solving: iterative methods, preconditioners, multigrid. The approach is by extending the Formal Linear Algebra Methods Environment (FLAME), a system originally developed for deriving dense matrix algorithms.<br\/><br\/>The merit of this research lies firstly in the fact that it facilitates experimentation, since it makes derivation of new algorithms essentially simpler than the lengthy induction arguments that are traditionally necessary. Secondly, it will lead to algorithms being proved correct by the very mechanism of derivation. Finally, a complete systematization of FLAME may take the form of a symbolic system, where algorithm implementations are derived mechanically, steered by the user but otherwise autonomously, from a specification of their properties rather than from an algorithmic description.<br\/><br\/>The impact of this research will be on the computational community, since it lowers the threshold to exploring new algorithmic strategies, and on software developers, since it makes it easier to derive correct implementations of algorithms. Additionally, it will impact the way the subject of iterative linear system solving is taught, since FLAME worksheets offer a simpler and more insightful description of algorithms than is used traditionally.","title":"AF: Small: Toward mechanical derivation of Krylov space algorithms","awardID":"0917096","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7933","name":"NUM, SYMBOL, & ALGEBRA COMPUT"}}],"PIcoPI":["556801","501527"],"PO":["565251"]},"154086":{"abstract":"Abstract <br\/>This award is funded under the American Recovery and Reinvestment Act <br\/>of 2009 (Public Law 111-5). <br\/><br\/>The project will develop efficient mechanisms for deploying and managing wireless self-organizing networks (WSONs). These networks are able to manage themselves with little or no human intervention and consequently can be deployed in remote, difficult-to-access areas, under adverse conditions, and\/or when users have little or no network administration skills. As such, WSONs can have significant societal and scientific impact as key enablers of numerous applications, including emergency response, disaster relief, community networking, environmental monitoring, and surveillance. <br\/><br\/>Intellectual Merit: This work will develop theoretical foundations for efficient WSON node placement and trajectory control based on geometric computation and optimization. The technical approach explores the synergy among a variety of disciplines, including wireless communications, facility location, geometric and distributed optimization, and systems and control theory. The project will (i) explore, develop, and evaluate novel geometric computing strategies for WSON placement, management, and control in order to optimize system performance for a range of applications, and (ii) deploy the proposed strategies in real-world environments motivated by our ongoing collaborations with biologists and oceanographers. <br\/><br\/>Broader Impact: The WSON deployment and management strategies developed in this work will be key enabling technology for a variety of applications with considerable societal and scientific significance. The project also includes an important educational component. It will produce exciting MSc and PhD theses, incorporate results into graduate classes, and engage undergraduate students via field experiments, senior design projects and summer REUs.","title":"NetSE: Small: Collaborative Research: A Geometric Computational Approach to Efficiently Deploy and Manage Self-Organizing Wireless Communication Networks","awardID":"0917166","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7794","name":"NETWORK SCIENCE & ENGINEERING"}}],"PIcoPI":["553514"],"PO":["564924"]},"153570":{"abstract":"Logic attempts to describe the nature of sentences that have descriptions in some restricted format. Computational complexity investigates the number of steps needed on a computer to solve a given mathematical problem. Despite the seemingly disjoint nature of the topics, Logic and Computational Complexity have had a rich history of interactions in the past. Fagin's classical theorem giving a logical definition of NP is probably one of the first connections in the area. Other celebrated results in the nexus of finite logic and computational complexity include the Immerman-Szelepsenyi theorem showing non-deterministic logspace is closed under complementation; and Ajtai's work on certain formulae on finite structures, which shows that parity is not first-order definable (which turns out to be equivalent to Furst, Saxe, and Sipser's result that parity does not have constant depth, polynomial size circuits). These results have advanced logic as well as computational complexity.<br\/><br\/>This research project is inspired by recent work by the student investigators on this project, Swastik Kopparty and Ben Rossman who have unearthed new connections between these areas leading to several new results. This project outlines novel further questions in the intersection of logic and computational complexity and outlines methods that may be employed to make progress on these questions. Some specific questions include:<br\/><br\/>- Size lower bounds for uniform logarithmic depth circuits.<br\/>- Explicit functions that are hard for first-order logic augmented with arbitrary modular counting quantifiers (modulo composites in particular).<br\/>- Choiceless algorithms for solving linear systems.<br\/>- Decidability of the containment problem for conjunctive queries under multiset semantics.","title":"AF: Small: Logic and Computational Complexity","awardID":"0915155","effectiveDate":"2009-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}}],"PIcoPI":["425345"],"PO":["565157"]},"153482":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5.<br\/><br\/>This grant supports research in adapting and optimizing Markov Chain Monte Carlo methods to compute Bayesian models on large data sets resident on secondary storage, exploiting database systems techniques. The work will seek to optimize computations, preserve model accuracy and accelerate sampling techniques from large and high dimensional data sets, exploiting <br\/>different data set layouts and indexing data structures. The team will develop weighted sampling methods that can produce models of similar quality as traditional sampling methods, but which are much faster for large data sets that cannot fit on primary storage. One sub-goal will study how to compress a large data set preserving its statistical properties for parametric Bayesian models, and then adapting existing methods to handle compressed data sets. <br\/><br\/>Intellectual Merit and Broader Impact<br\/><br\/>This endeavor requires developing novel computational methods that can work efficiently with large data sets and numerically intensive computations. The main technical difficulty is that it is not possible to obtain accurate samples from subsamples of a large data set. Therefore, the team will focus on accelerating sampling from the posterior distribution based on the entire data set. This problem is unusually difficult because stochastic methods require a high number of iterations (typically thousands) over the entire data set to converge. However, if the data set is compressed it becomes necessary to generalize traditional methods to use weighted points combined with higher order statistics, beyond the well-known sufficient statistics for the Gaussian distribution. Developing optimizations combining primary and secondary storage is quite different from optimizing an algorithm that works only on primary storage. This research effort requires comprehensive statistical knowledge on both Bayesian models and stochastic methods, beyond traditional data mining methods. A strong database systems background in optimizing computations with large disk-resident matrices is also necessary. This research will enable a faster solution of larger scale problems compared to modern statistical packages to solve stochastic models. Bayesian analysis and model management will be easier, faster and more flexible. <br\/><br\/>Broad Impact<br\/><br\/>This research will occur within the context of three separate application areas: cancer, water pollution, and medical data sets with patients having cancer and heart disease. The educational component of this grant will enhance current teaching and research on data mining. In an advanced data mining course students will apply stochastic methods to compute complex Bayesian models on hundreds of variables and millions of records. Data mining research projects will be enhanced with Bayesian models, promoting interaction between statistics and computer science.<br\/><br\/>Keywords: Bayesian model, stochastic method, database system","title":"III: Small-Collaborative: Efficient Bayesian Model Computation for Large and High Dimensional Data Sets","awardID":"0914861","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["528486"],"PO":["563751"]},"143230":{"abstract":"A signal, when transfered over a long distance, is likely to be corrupted. Error-correcting codes have been designed to solve this problem, so modern communications are possible as we see today. Algebraic codes are mathematically interesting and intriguing, and they form the backbone of coding theory and its applications. The best algorithms for many algebraic codes are very powerful but not very practical. Also, the exact decoding complexity is not well understood for these codes, including the simple but extremely important Reed-Solomon codes. The project will strive to identify the complexity of decoding algebraic codes and to design more efficient algorithms for a large class of algebraic codes.<br\/><br\/>The main focus is on algebraic codes with natural parameters. The complexity results for these natural codes thus are more relevant to communication practice. It is expected that the project will lead to a number of substantial new results linking coding theory, computer sciences and mathematics. The project is also expected to develop graduate courses and train students in this cross-disciplinary research area.","title":"Collaborative Research: Complexity and Algorithms of Decoding Algebraic Codes","awardID":"0830522","effectiveDate":"2009-08-15","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["518429"],"PO":["565157"]},"143351":{"abstract":"Abstract<br\/><br\/>The Data Conservancy, A Digital Research and Curation Virtual Observatory<br\/>PI: Sayeed Choudhury of Johns Hopkins University<br\/><br\/>Johns Hopkins University (JHU) will create The Data Conservancy (DC), which will research, design, implement, deploy and sustain data curation infrastructure for cross-disciplinary discovery, with an emphasis on observational data. The Data Conservancy project is led by Sayeed Choudhury, Associate Dean for University Libraries at JHU, which has a strong track record for leading the research library community in new directions. The Data Conservancy is creating a new model in which libraries regard digital data as a special collection that must be maintained and served like their other collections. Participating organizations include Cornell University, University of California Los Angeles (UCLA), the University of Illinois at Urbana-Champaign (UIUC), the National Center for Atmospheric Research (NCAR), University Corporation for Atmospheric Research (UCAR), Marine Biological Laboratory (Encyclopedia of Life), the National Snow and Ice Data Center (NSIDC), Space Telescope Science Institute, Fedora Commons, Portico, University of Queensland, and Tessella Support Services. <br\/><br\/>Besides defining a new role for research libraries in curating and serving special collections of scientific digital data, expected contributions of the Data Conservancy include<br\/>* Defining of new educational curricula an other opportunities in data curation; <br\/>* User centered studies that will help the community and NSF better understand how scientists use, share, and preserve data now and what factors motivate them to or inhibit them from preserving and sharing data.<br\/><br\/>Through collection, preservation and semantic integration of data that are now very difficult to assemble and analyze together, the project is also expected to have transformative impact on the ability of scientists to answer grand challenge questions that are as important to the nation and the world, such as three that relate to the production of greenhouse gases: <br\/>* What are the current geographical and temporal distributions of the major pools and fluxes in the global carbon cycle? <br\/>* What are the control and feedback mechanisms - both anthropogenic and non-anthropogenic - that determine the dynamics of the carbon cycle? <br\/>* And what are the dynamics of the carbon-climate-human system into the future, and what points of intervention and windows of opportunity exist for human societies to manage this system?<br\/><br\/>The Data Conservancy begins with data spanning anthropology, applied mathematics, astronomy, atmospheric sciences, chemistry, earth sciences, crop and soil sciences, ornithology, psychology, physics, theoretical and applied mechanics. International partnerships augment this initial collection. Evolutionary development of this collection will be guided by the user centered design process.","title":"DataNet Full Proposal: The Data Conservancy (A Digital Research and Curation Virtual Organization)","awardID":"0830976","effectiveDate":"2009-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7726","name":"DATANET"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7785","name":"ITR - DATANET"}}],"PIcoPI":["499893","541699","563069",381713,"559805"],"PO":["565292"]},"159961":{"abstract":"The eighteenth international conference on parallel architectures and compilation techniques (PACT) will be held in Raleigh, North Carolina, September 12-16, 2009. PACT is a multi-disciplinary conference that brings together researchers from hardware and software areas to present ground-breaking research in parallel systems ranging across instruction-level parallelism, thread-level parallelism, multiprocessor parallelism and large scale systems.<br\/>This award is to make travel scholarships available to students and universities not typically represented at PACT in order to improve the impact and outreachof this conference.","title":"Parallel Architectures and Compilation Techniques (PACT) 2009 Student Travel Scholarships","awardID":"0944044","effectiveDate":"2009-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}}],"PIcoPI":[427918],"PO":["565272"]},"154054":{"abstract":"This award is funded under the American Recovery and Reinvestment Act of 2009 <br\/>(Public Law 111-5).<br\/><br\/>The performance of network users' best effort flows, e.g., file transfer delays and web browsing responsiveness, depends on the resources they are allocated over time. When varying traffic loads share these resources and\/or wireless nodes' transmission capacities depend on each other through interference, the allocated resources and thus flows' performance are coupled through the traffic and interference dynamics. This project investigates such performance coupling in data networks and, in turn, how it affects protocol and network design. This is a significant problem, as most data networks share these characteristics, and we currently have no robust tools to effectively predict and thus optimize performance. Expected results include new theory, approximations and performance bounds enabling the analysis of such systems which are also applicable to other domains. Expected results also include using these tools to investigate: (1) the benefits of, and capacity allocation, in networks supporting multipath transport and\/or shared wireless access networks; and (2), the development of improved protocols and algorithms that are sensitive to such performance coupling, e.g., preliminary work suggests the state-of-the-art base station association policies can be substantially improved by factoring the performance coupling resulting form interference. The work's impact will be assured through broad dissemination in the research community, and by leveraging industry partners in evaluating practical applications and technology transfer opportunities.","title":"NeTS:Small:Dynamic Coupling and Flow-Level Performance in Data Networks: From Theory to Practice","awardID":"0917067","effectiveDate":"2009-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560221"],"PO":["564993"]}}