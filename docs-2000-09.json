{"52717":{"abstract":"In this project, algebraic techniques are in use two to tackle <br\/>two classes of problems related to improving the throughput and\/or<br\/>reliability of a communication link are under study. The first class<br\/>of problems under study is the design of long and efficient<br\/>error-correcting codes. Such codes are of interest as longer<br\/>error-correcting codes tend to ``average'' out the noise and hence<br\/>provide better performance. The second class of problems relates<br\/>to the design and analysis of families of signature sequences that are<br\/>used to distinguish between the signals of different users in a<br\/>multi-user environment. Examples of multi-user environments include<br\/>Code Division Multiple Access (CDMA) cellular and personal<br\/>communication systems. More details on example problems drawn from<br\/>each class are provided below. <br\/><br\/>Since the early 80's, the promise of algebraic geometric (AG) codes<br\/>has been the delivery of a sequence of error-correcting codes of<br\/>increasing length whose asymptotic performance exceeds the<br\/>Gilbert-Varshamov bound and for which efficient and practical <br\/>encoding and decoding algorithms are available. Computationally<br\/>efficient decoding algorithms for AG codes are now available and there<br\/>now exist explicit descriptions of algebraic curves of the type<br\/>required to construct these long codes. Construction of good codes on <br\/>these curves requires the determination of a basis for a certain type<br\/>of vector space of functions defined on these curves. The<br\/>investigators study efficient methods of generating such bases. The<br\/>use of novel algebraic geometry techniques to generate pseudo-random<br\/>sequences is an example of the type of problem belonging to the second<br\/>class. The investigators examine methods of generating sequences<br\/>having pseudo-random properties such as low correlation and large<br\/>linear span. Also under investigation are more efficient means of<br\/>assessing the performance of pseudo-random sequences in a multi-user<br\/>setting, for example, more efficient means of determining the minimum<br\/>Euclidean distance between adjacent multi-user signals. The<br\/>performance in a multi-user setting, of a a specific sequence family,<br\/>known as family S(2) and previously co-designed by the PI is also<br\/>under study.","title":"Topics in Pseudonoise Sequence Design and Error-Correcting Codes","awardID":"0073555","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["562301"],"PO":["223414"]},"54917":{"abstract":"Future information appliances are expected to become increasingly mobile and operate under highly fluctuating workloads, thus imposing stringent design constraints on their energy dissipation, size, cost, performance, and quality of service. This project explores algorithmic and design automatin technologies for creating computing systems that dynamically adapt their operation to their workloads with the objective to maximize thieir energy efficiency and resource utilization. In the area of algorithms, research is conducted on the design and analysis of precomputation schemes that can be used to predict the load of a computation in the future and adapt system resources accordingly. In the area of design automation, the project is concerned with behavioral-level transformations and scheduling algorithms that rely on precomputation to generate energy-efficient hardware or software implementations of general computations.","title":"ITR: Adaptive Information Processing through Precomputation","awardID":"0082876","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["550681"],"PO":["562984"]},"54928":{"abstract":"Despite significant advances in recent years in speech recognition generation technology and statistical language modeling, existing natural language systems are still limited to very specific, narrow domains, and totally lack common sense - the ability to \"see the obvious\" when interacting with a user. A major reason for this is the lack of a broad base of general world knowledge in current AI systems - knowledge such as that a sandwich is food (for. humans), while dinnerware is not; that dwellings usually have doors and walls; or, that when one person is killed by another, it is often with a gun; etc. This project will use previous work on mining linguistic knowledge from text as a springboard for tackling the problem of mining general world knowledge from texts. The methodology depends neither on \"deep\" text understanding nor on explicit occurrence of the desired general facts in the targeted corpora. Rather, the PI's approach elaborates on the idea that regularities observed in patterns of predication in texts generally reflect regularities in the world, particularly regularities in the way certain types of entities jointly participate in various events and relationships. While absolute statistical frequencies of such patterns can be severely misleading (people do not commit crimes, or have accidents or hold public office nearly as often as scanning of newspapers might suggest), the techniques that will be employed rely on conditional frequencies to obtain factually reliable hypotheses. The knowledge extracted will be cast in a formally interpretable propositional form, lending itself to certain and uncertain inference. This in turn will help \"sanitize\" the extracted knowledge, by revealing and helping to remedy apparent contradictions. Suitable corpora for this work include not only newspapers and other factual sources, but also realistic novels and writings for children - in fact, almost all electronically accessible texts are potentially useful, and no annotation will be required. While not all kinds of common-sense knowledge can be acquired in this way, the knowledge that can be acquired is very extensive, is essential to language understanding and common-sense reasoning, and is relatively close at hand. The kind of general knowledge to be mined from text corpora is not only useful, but essential in the long run for intelligent systems with some general linguistic competence and a modicum of common sense. Thus the work will bring a step closer the prospect of computers that genuinely understand their users.","title":"ITR: Mining Text for General World Knowledge","awardID":"0082928","effectiveDate":"2000-09-01","expirationDate":"2003-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["227957","409565","450916"],"PO":["246649"]},"52508":{"abstract":"This project addresses new techniques to break pure dependencies for horizontal (EPIC, VLIW) microarchitectures. The ultimate limit to schedule length is the longest chain through the computation. The research presents techniques for dependence chain splitting, which attack pure dependence chains using methods presented earlier for superscalar microarchitectures. The techniques for superscalar processors are not directly applicable to VLIW or EPIC architectures, since such architectures have no or little dynamic speculation mechanisms. Essentially, they execute code that is statically speculated by the compiler. The core idea of this work is to break a chain at a beneficial split point, and then speculatively execute the second half of the chain. This project develops techniques to find the best split point(s) of a region of code, develop hardware-based very low overhead value profiling, study VLIW\/EPIC-specific value predictor designs, investigate heuristics to address the penalty branches to patch-up code, look into methods for adding confidence prediction for VLIW\/EPIC value speculation, and study the potential of software-only value speculation. Issues such as register pressure impact and branch insertion for value speculation across control flow are also being explored.","title":"Value Speculation for VLIW and EPIC Architectures","awardID":"0072926","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["517778"],"PO":["325495"]},"54818":{"abstract":"Network simulation is an indispensable tool for researchers seeking to understand the principles of network architecture and protocol design. A key parameter in any moderate to large-scale simulation is the topology, i.e., the way the nodes of the network are organized and connected to each other. \"Good\" models for topology are essential for good simulations.<br\/> The PIs have developed graph modeling software that currently is widely used as a tool for generating topologies, particularly models of large internetworks. The Georgia Tech Internet Topology Models (GT-ITM) package allows researchers to construct model topologies whose structure arguably resembles the node-level structure of the Internet: routers or switches, connected by (bidirectional) links, and grouped into domains. The GT-ITM software is included with \"ns2\" [2], the defacto open-source standard for network simulation.<br\/> Despite the wide-spread use of GT-ITM, in general, and its transit-stub model, in particular, a number of critical and fundamental questions remain unanswered about network topology modeling. For example,<br\/> 1)Topology models. Recent data indicates that the current Internet topology has some properties that are not well reflected in the transit-stub model of GT-ITM [17]. For example, features such as the exchanges where many transit domains come together are lacking. Are there \"better\" techniques to generate topologies intended to model the Internet? More fundamentally, how should a topology generation technique be evaluated (i.e., how is \"better\" measured)?<br\/> 2)Topology scaling. Although strides are being made in supporting large-scale simulations [33], most researchers will continue to simulate their protocols on topologies that are smaller than the target operational large-scale networks. How should smaller topologies be configured so that they reasonable reflect their larger counterparts? Is there a theory of topology scaling that can provide the fundamental grounding for configuring topologies of various sizes?<br\/> 3)Topology use. The PIs primary interest in topology modeling is to provide a foundation for large-scale simulations. Facilitating the use of topologies in simulations must go beyond providing theoretically sound models, however, and include a set of complementary tools for graph visualization, routing table construction, etc. What visualization tools are useful to researchers and assist in accurate intuitive understanding of underlying topology? How can different routing policies be effectively reflected in routing table construction?<br\/> The researchers propose (1) to address these and other fundamental questions in the area of topology modeling and (2) to reflect their understanding in a set of topology tools and benchmarks made available to the research community at large. This work will build on the PIs prior experience in modeling internetworks. The proposed work will contribute to fundamental understanding in the area of topology modeling. The work will include a set of evaluation criteria to assess the quality of a topology generation method and improvements in topology models. The work will also produce an evolutionary theory of topology scaling, with implications for efficient simulation using topologies that are smaller than the target. In addition to contributions to fundamental understanding, a central component of the proposed work is a set of tools and benchmarks to be made available to the research community at large, following in the tradition of the GT-ITM suite. These tools will allow other researchers to generate topologies, assess the quality of candidate topology modeling methods, utilize benchmarks based on current and future technologies, and interact with a visualization of topology.","title":"ITR: Collaborative Research in Internet Topology Models - A Foundation for Large-Scale Simulations","awardID":"0082318","effectiveDate":"2000-09-01","expirationDate":"2005-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["483390"],"PO":["7594"]},"54708":{"abstract":"The East Pacific Rise (EPR) is currently our best-studied section of fast-spreading mid-ocean ridge, yielding a wealth of observational data and results spanning many scientific fields. However, this information has not yet been fully utilized. Most of it exists in noninteractive form (e.g. journal publications) or as incompatible datasets and models. To make the most of this data, scientists will need a wide range of sophisticated programming support to coordinate the use of data, computational tools, and numerical models across distributed networks of computers. This project will develop that support.<br\/><br\/>Technically, this project will develop the computational infrastructure needed to support data sharing, tool composition, and model coupling for the use of large scale, interdisciplinary data archives. It will then apply that infrastructure to build a domain-specific environment called the Virtual Research Vessel 1 (VRV-1). The VRV-1 will facilitate the use of data, maps, and models related to the EPR. The project will address fundamental issues of integrated middleware for scientific data management and computational science. In particular, it will support data sharing by merging three technologies: geographic information systems, database management systems, and electronic notebooks. It will support tool composition through an extension of an existing electronic notebook. Finally, it will support model coupling by developing support for exploring model correlations and relationships at a very high, domain-specific level in a fast prototyping environment.","title":"ITR: Computational Environment Infrastructure with Applications to Mid Ocean Ridge Research: The 'Virtual Research Vessel' Prototype","awardID":"0081487","effectiveDate":"2000-09-01","expirationDate":"2005-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["561855","555188","474015","413474"],"PO":["551992"]},"54719":{"abstract":"Platform-Independent Computing, as popularized by Java, is a key<br\/>technology for developing and executing next generation software on<br\/>distributed and heterogeneous computing platforms. The current<br\/>state-of-the-art mobile-code system is built around the Java Virtual<br\/>Machine Language (JVML). Unfortunately, JVML does not support other<br\/>programming languages well and is notoriously inefficient, complex,<br\/>and hard to extend. This research focuses on developing a new<br\/>mobile-code infrastructure that eliminates all of these weaknesses.<br\/>The infrastructure will be based on the FLINT typed common<br\/>intermediate format (also developed by the PI) and will provide<br\/>support to multiple programming languages such as Java, ML, and C. The<br\/>research will investigate new techniques on building certifying<br\/>compiler, smaller virtual machine, and more extensible runtime system<br\/>for compiling and running the FLINT mobile code. The resulting<br\/>infrastructure will be made publicly available to support other<br\/>cutting-edge research on proof-carrying code and secure internet<br\/>programming.","title":"ITR: FLINT---A Mobile-Code Infrastructure for Advanced Languages","awardID":"0081590","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["550517"],"PO":["564388"]},"56908":{"abstract":"The PI is exploring applications of decision theory to large, complex systems, both from the theoretical and practical point of view. From the theoretical end, he plans to use his previously-introduced concept of plausibility measures as a tool for exploring qualitative decision making. Plausibility measures generalize probability measures, and provide an elegant framework for understanding what properties of an uncertainty measure are necessary to use that uncertainty measure for various purposes (e.g., as a model of belief revision or to apply the techniques of Bayesian networks). The PI hopes plausibility measures will enable him to \"fine-tune\" approaches to decision making in applications where one does not have complete probability distributions and only rough utilities. As far as practical applications go, the PI plans to extend his initial work on applying decision theory to query optimization in databases. When a user poses a query, there are in general many different plans that can be used to compute the answer. While all the plans will compute the answer correctly, they may differ wildly in running time. What will be the best plan will in general depend on the values of certain random variables (how much memory the system has available when the query is run and the selectivity of various predicates). Current query optimization algorithms just use a particular value (e.g., the expected value) for these variables. The PI has previously shown how to modify these algorithms to allow for there being a probability distribution associated with each of these variables in order to compute the plan with the least expected running time. In theory, this approach should substantially outperform the competition, but it remains to be determined experimentally whether the theoretical results hold up in practice.","title":"SGER: Decision-making In Complex Systems","awardID":"0090145","effectiveDate":"2000-09-01","expirationDate":"2002-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["516488"],"PO":["564456"]},"55709":{"abstract":"The project researches a new form of operating system to manage a model of<br\/>computing called an Active Space. It integrates physical spaces that contain<br\/>ubiquitous computers into a computational environment that supports human<br\/>activity and applications. With anytime\/anywhere ubiquitous devices, the<br\/>users' view of the computational environment is extended beyond the physical<br\/>limits of a computer and is placed into the surrounding physical space,<br\/>augmented with computers that sense and affect that space around the user.<br\/>Applications become mapped not just to views associated with specific<br\/>windows in a monitor but instead to the physical environment. Therefore,<br\/>the physical space, augmented with communicating computer devices, becomes a<br\/>distributed computing system.<br\/>Active Spaces have the potential for creating multi-billion dollar<br\/>industries. Automated surgery, collaboration and engaged learning are a few<br\/>of the compelling examples. Gaia, an operating system for Active Spaces,<br\/>will accommodate diversity by exploiting standards for interoperation and<br\/>cooperation. System services track, authenticate and support mobile users<br\/>with reconfigurable graphics, multimedia and Active Space applications. A<br\/>unifying object bus, component model, and adaptive stream model extends plug<br\/>and play to distributed mobile ubiquitous computers cooperating to support a<br\/>computational environment within physical spaces like cities, buildings and<br\/>rooms.","title":"ITR: Active Information Spaces based on Ubiquitous Computing","awardID":"0086094","effectiveDate":"2000-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["563534","426630","561784","561785","289744"],"PO":["309350"]},"54907":{"abstract":"One of the most important classes of programs today is large-scale adaptive and time-dependent simulations. These are increasingly important for solving important scientific problems such as particle dynamics and boundary element problems. An equally important environment for running any code is a cluster of workstations. Such a system may include single-processor and SMP nodes supporting a hybrid message passing\/shared address space programming paradigm. This project will provide automated and semi-automated tools for optimizing serial performance, parallel performance, and overall resource utilization when those complex codes are run in such complex environments.<br\/><br\/>Technically, the goal of the project is to develop a comprehensive dynamic code enhancement, resource management, scheduling, and performance monitoring framework. This is accomplished by relegating a number of code optimization and scheduling decisions to run-time, where they can rely on performance traces. The framework generalizes the process-thread model to a schedulable entity model in which processes and threads are treated as free and bound entities respectively. Either the programmer or the compiler can create these entities. In addition, the dynamic code enhancer performs optimizations at run-time granularity control for threads, and transformations between free and bound entities to improve performance. The overhead of dynamic code enhancement is amortized over several computation steps. An aggregate scheduler\/resource manager maps the specified entities to hosts, using performance data to optimize its decisions for CPU, memory system, network, and parallel code performance. The dynamic code enhancer\/scheduler framework is triggered by online performance monitoring that is automatically instrumented into the code.","title":"ITR: Dynamic Code Enhancement and Scheduling Techniques for Complex Simulations","awardID":"0082834","effectiveDate":"2000-09-01","expirationDate":"2005-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["408878","540776"],"PO":["551992"]},"54918":{"abstract":"A common theory of information fusion across multiple text sources is to be developed. Three main tasks are undertaken: (a) robust techniques for identifying structure across sets of related textual documents in arbitrary domains are developed and used to produce graph representations of the document sets, (b) an environment in which users can specify their summarization preferences is created, and (c) graph-based methods are applied to produce personalized multi-document summaries of clusters of the related documents based on the users' priorities.<br\/><br\/>Cross-document structure is based on features such as paraphrasing, contradiction, change of perspective, and complementation. A large-scale taxonomy of cross-document links is being investigated.<br\/><br\/>Providing users with personalized abstracts of large amounts of critical textual information is expected to speed up and otherwise facilitate their access to the Web. Large-scale deployment of a Web-based summarization system based on cross-document structure is planned and is expected to be used by millions of users.","title":"ITR: Information Fusion Across Multiple Text Sources: A Common Theory","awardID":"0082884","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["466946"],"PO":["562519"]},"54929":{"abstract":"The n-body problem - i.e. simulating the motion of many particles that attract or repel each other - is a classic one with many applications. N-body algorithms are the computational means of solving this problem. The many users of these algorithms include biophysiologists and biochemists studying biological phenomena, pharmaceutical researchers dealing with drug structures and interactions, astrophysicists studying the structure of the cosmos, and engineering researchers studying hydrodynamics. The algorithms are also interesting in their own right to computer scientists. This project will develop an innovative approach to n-body algorithms called self-scheduling n-body algorithms. This family of algorithms promises not only reduced computational complexity, but also a straightforward implementation.<br\/><br\/>Technically, the research will use a multiple time step method where each pairwise interaction is evaluated using a dynamic schedule that attempts to equalize the error of each interaction, drastically reducing the computational cost. The fundamental new idea is to equalize the impulses for all interactions, rather than equalizing the time steps for all interactions (which is too conservative in most cases). Mathematically, the constant time step t is traded for a constant impulse I, defined as Fij tij, where Fij is the force between particles i and j and tij becomes the time step used to re-evaluate Fij. This leads to an expected execution complexity of O(n4\/3) per simulation step. Algorithmic improvements that rely on the first and second derivatives of force reduce the per step computational complexity to O(n log n) and O(n), respectively. The project will fully explore these algorithms, analyze their error bounds and computational complexity, implement prototype versions, and explore additional topics (such as efficient parallelization and cache-efficient memory layouts) as time permits.","title":"ITR: Self-Scheduling N-Body Algorithms","awardID":"0082931","effectiveDate":"2000-09-01","expirationDate":"2004-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["426282","235605","547942","184104","396781"],"PO":["551992"]},"54919":{"abstract":"During the last decade, researchers in our Scientific Visualization Group at Stanfor University<br\/>have been developing general data analysis techniques for vector and tensor fields<br\/>based on rigorous mathematical approaches. The work has systematically explored direct<br\/>visualizations and feature extractions of both vector and tensor fields in two and three<br\/>dimensions using computers. Recently, we have been developing the next stage of our<br\/>visualization efforts: automated atad comparisons.<br\/><br\/>Traditional techniques for vector field comparison fall into three basic categories: image,<br\/>data, and feature based comparison. In most instances, comparisons are made visually,<br\/>not automatically. In addition, there are fundamental limitations with these existing comparison<br\/>techniques. Image base comparisons suffer from difficulty in representing datasets<br\/>beyond two-dimensional vector fields, data based comparisons suffer from grid alignment<br\/>problems, and feature base comparisons, while providing excellent location of specific features,<br\/>may not show all the global information in the field.<br\/><br\/>Our new approach to this problem is essentially a feature-based comparison technique,<br\/>with the important stipulation that our features attempt to represent the topological structure<br\/>of the field. This ensures that we do not overlook any important structures in the<br\/>field. Our paradigm is to analytically study vector and tensor fields to extract topologically<br\/>critical information, transfer this knowledge into effective computer programs, and then to<br\/>visualize the fields using the results of our analysis.<br\/><br\/>We have successfully implemented our ideas for two-dimensional vector fields and for<br\/>three-dimensional vector fields. We now intend to study tensor fields associated with white<br\/>matter brain functions.<br\/><br\/>Our fundamental technique for the comparison of vector and tensord ata would be<br\/>applicable to almost every field of science and engineering, ranging from the magnetic field of<br\/>the sun to airflow over a wing. In addition, time varying fields can be studied by comparing<br\/>a field at a fixed time with its state at later times. Our approach is unique in the field of<br\/>scientific visualization because it is based on rigorous mathematical analysis, and it is the<br\/>only approach available to quantitatively study NMR tensor brain data. Our methodology<br\/>in the analysis of tensor and vector datasets allows better design of air vehicles, better<br\/>understanding of electromagnetic problems, and provides substantial time savings when<br\/>dealing with large experimental datasets. Quantitative understanding of white matter brain<br\/>functions has the potential to open up a whole new area of medical research.","title":"ITR: Procedures for the Rigorous Comparison of Vector and Tensor Fields","awardID":"0082898","effectiveDate":"2000-09-01","expirationDate":"2003-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["456858"],"PO":["381214"]},"48192":{"abstract":"The marriage of the personal computer and the Internet has led to explosive growth in the contacts between separately administered computing resources, creating new opportunities and risks. Applets, agents, viruses, email attachments, and downloadable software are escaping the confines of their original systems and spreading through communications networks. Computers are disabled by network-borne infections; browsers crash due to unforeseen interactions between an applet and a language implementation; application programs are broken by operating system upgrades. This computation in the wild is a far cry from the carefully isolated, controlled, and managed computer systems of the past. The connections between computer systems and living systems are superficially obvious and yet deep in their implications. This proposal argues that networked computer systems can be better understood, controlled, and developed when viewed from the perspective of living systems, treating the rich and dynamic network computer environment formed by diverse benign and malicious software collectively as a software ecosystem. <br\/><br\/>Taking seriously the analogy between computer systems and living systems encourages rethinking many aspects of current computing practice ranging from operating system design to communications mechanisms to computer security. This project is aimed at developing design strategies from biology, constructing software that can survive in the wild, and developing a better understanding of the current and emerging software ecosystems. Like many researchers, we believe that the current crisis of software development is unlikely to improve significantly through incremental research using traditional methods. New approaches must be tried, and new ways of thinking about computing must be developed. Biological principles stand to unify many scattered current research efforts addressing robust operation, survivability and security, while also suggesting new avenues for research. In addition, as the size and scope of software systems continues to grow, and global computer networks continue to expand, tools and methodologies from biological research will be increasingly relevant for understanding and monitoring the results.<br\/><br\/>The proposal takes the investigators' ideas and insights about living systems online, emphasizing concrete implementations that demonstrate new approaches to solving real problems. Specifically, the following projects centered on and exploring computation in the wild are proposed: Homeostasis for improved operating system survivability, Beyond network intrusion detection, Toward a living networked operating system, Software diversity for species survivability, and Tools and techniques from biology. The homeostasis project will augment a computer operating system with mechanisms similar in spirit to those of biological systems, which maintain homeostasis, by coupling system-call based process monitoring to feedback mechanisms. The second project will generalized and extend an existing prototype TCP-based intrustion-detection systems based on immunological principles. The third project differs from the first two by relaxing the constraint of staying within the bounds of operating system architectures and technology. Rather, it will pursue promising directions for robust operation and computer security based on living systems principles, even where they involve possibly significant levels of incompatibility with existing software and designs. The software diversity project will investigate methods by which software can be made more diverse, and the fifth project will apply quantitative methods from biology to the study of the current software ecosystem.","title":"Understanding and Surviving Computation in the Wild","awardID":"9986555","effectiveDate":"2000-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":[123164,"461864"],"PO":["7594"]},"69270":{"abstract":"","title":"Data-Driven Control of Humanoid Robots","awardID":"0196089","effectiveDate":"2000-09-01","expirationDate":"2004-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["438709"],"PO":["234178"]},"69292":{"abstract":"","title":"MRI: Development of State-of-the-Art Instrumentation for Advanced Distributed Computing Systems for Research and Research Training","awardID":"0196111","effectiveDate":"2000-09-01","expirationDate":"2004-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":[179404,179405],"PO":["241298"]},"48890":{"abstract":"Because improved parallel computing requires introduction of quality of service and security into cluster computing environments, the following study and research is incorporated in this effort: QoS for intracluster scheduling is studies and prototyped; Intrusion Detection Integration with a single cluster environment is studied and prototyped. Furthermore, since ubiquitous middleware offers a powerful paradigm for integrating resources in common operating environments, Proposers study CORBA interoperation with QoS and parallel computing.<br\/><br\/>Several specific themes facilitate new science in this work. Background study on existing QoS-oriented research for LANs and clusters are brought to bear on the current work, including previous work of Proposers involving RSVP and cluster admission controls. Furthermore, lower middleware for delivering admission-based messaging for clusters is prototyped on a Myrinet SAN (single cluster configuration). A high-quality implementation of the MPI\/RT standard messaging middleware is integrated with QoS-based middleware. CORBA is studied as a possible parallel processing notation and environment, including potential for peer-to-peer constructs such as in MPI. Intrusion detection methodologies are converted for use in SAN-based settings, such as Myrinet. Finally, CORBA uses in hard realtime settings are considered. New middleware prototyped in this effort are promulgated through the worldwide web.","title":"A QoS-based Approach to Clustering and Interclustering with a Unified Methodology for Scalability, Security, Performance, Fault-handling and Co-scheduling","awardID":"9988524","effectiveDate":"2000-09-01","expirationDate":"2002-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["527384","528453"],"PO":["209879"]},"48791":{"abstract":"Caching and replication of objects on the Internet and the World Wide Web are frequently used techniques to reduce latencies for clients accessing these objects while reducing network and server load. This work investigates the potential of managing objects where servers supply more complete information to client caches and use the information to manage replicated content. The idea is to exploit composite objects, which group a set of distinct objects where each object has a uniform type and change characteristic. Relationships between these objects can be \"compiled\" at a server into information that the server can pass to clients. Such information ranges from explicit expiration times for caching\/replicating a list of objects to invalidations based on the object membership in a volume of related objects.<br\/><br\/>A client\/server environment consisting of objects with different types and relationships will be used to test the approach. It is expected to yield more effective and predictable caching as well as drive placement and removal of replicated content, particularly when combined with client access counts. The work will have continued impact as distributed object environments continue to grow in size with increasing diversity in the type of objects grouped together and served.","title":"Exploiting Object Relationships for More Deterministic Management of Distributed Objects","awardID":"9988250","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["435447"],"PO":["241298"]},"46184":{"abstract":"This interdisciplinary team (Psychology, Computational and Applied Mathematics, Statistics, Economics, Computer Science) has a goal of overcoming the weaknesses in inference engines in expert systems, decision support systems or in knowledge discovery systems that often work in environments with uncertain characteristics. The current techniques rely on Baysian theory and do not perform well in situations in which conditional independence cannot be guaranteed, or the probabilities provided by experts may not be sound. Since inferences based on probability calculations offer the best guarantee of sensible assessments of chance, efficient schemes have been developed for computing probabilities over complex event spaces. Underlying all such algorithms is a \"probability model,\" i.e., a representation of the chances of various combinations of events. In turn, probability models are constructed from an initial set of facts about uncertainty in the environment. These facts can sometimes be extracted from databases, using relative frequency as probability. Often, however, the needed probabilities must be obtained from an expert, who responds intuitively. Reliance upon experts raises the specter of incoherence, i.e., judgments that cannot be reconciled with any probability model at all. Indeed, maintaining coherence across a large set of judgments is both computationally and psychologically taxing, and seldom achieved. Incoherent judgment on the part of a single judge is compounded when it is desired to integrate the opinions of several judges. To exploit potentially incoherent and inconsistent judgments, special optimization algorithms are used to construct a compact probability model that best approximates all the judgments in play. The algorithms are tested by applying them to a body of expert opinion in some complex domain. Development of the algorithms will facilitate the automatic construction of artificial expert systems. Whenever a body of expert judgment can be assembled, the algorithms can be applied in view of creating a compact representation of the collective wisdom of the judges. The results of the theoretical research on the probability models will be applied to the analysis of air quality policy in Houston. A large probabilistic database will be established by culling measurements from air quality control stations around the city, expert judgements in environmental science and medicine, and the output of econometric and environmental models of the region. The project has the potential to have a significant intellectual impact in probability, applied learning, and datamining research communities and also provide a useful tool to environmental researchers and Houston decision-makers.<br\/><br\/>http:\/\/www.ruf.rice.edu>\/~osherson","title":"Constructing Probability Models for Large Corpora of Well-Informed but Probabilistically Incoherent Judgments","awardID":"9978135","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["249657","379633","353894","565263",117785],"PO":["563751"]},"48131":{"abstract":"CCR-9986308<br\/> Reps, Thomas W.<br\/> University of Wisconsin-Madison<br\/> Investigation of a New Compressed Representation of Boolean Functions<br\/><br\/> The goal of the proposed project is to advance the state of the<br\/> art in symbolic model checking by investigating the properties of<br\/> a new compressed representation of Boolean functions, called<br\/> CFLOBDDs, which are an alternative to the now-standard Ordered<br\/> Binary Decision Diagrams (OBDDs). CFLOBDDs share many of the<br\/> good properties of OBDDs, but can lead to data structures of<br\/> drastically smaller size -- exponentially smaller than OBDDs, in<br\/> fact. That is, an OBDD is a data structure that -- in the best<br\/> case -- yields an exponential reduction in the size of the<br\/> representation of a Boolean function (i.e., compared with the<br\/> size of the decision tree for the function). In contrast, a<br\/> CFLOBDD -- again, in the best case -- yields a doubly exponential<br\/> reduction in the size of the representation of a Boolean<br\/> function. Although not every Boolean function has such a highly<br\/> compressed representation, the project with see how far this<br\/> idea can be pushed. The hope is that doubly-exponential compression <br\/> is a tool that would (a) permit verification to be performed much <br\/> faster, and (b) allow much larger verification problems to be attacked <br\/> than has heretofore been possible.","title":"Investigation of a New Compressed Representation of Boolean Functions","awardID":"9986308","effectiveDate":"2000-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["401760"],"PO":["564388"]},"54390":{"abstract":"EIA-0080123<br\/>Andrews, Gregory R.<br\/>University of Arizona<br\/><br\/>CISE Research Infrastructure: Optimization of Distributed and Networked Systems: A Spectrum of Techniques<br\/><br\/>This project is exploring a variety of complementary techniques for optimizing distributed and networked systems ---from client interfaces, through middleware and servers, to the communication infrastructure---and they examine a variety of optimization criteria---including time, space, power, quality of service, and utility.<br\/><br\/>Client-level projects are investigating ways to reduce power consumption and memory requirements, and ways to protect clients and mobile code from each other. The middleware projects are examining ways to support interactive visualization of geographical databases and ways to optimize evaluation of temporal queries. The server projects focus on optimizing the computational and I\/O behavior of large, typically parallel server systems connected to many disks; applications include database servers<br\/>and parallel scientific programs. The final set of projects examines ways to optimize network performance; topics include routing and forwarding in high-speed networks, more efficient protocols for wireless networks and mobile computations, and a new approach called network-resident storage.","title":"CISE Research Infrastructure: Optimization of Distributed and Networked Systems: A Spectrum of Techniques","awardID":"0080123","effectiveDate":"2000-09-15","expirationDate":"2006-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["560601","241298","550173","217789","549718","549718"],"PO":["297837"]},"43291":{"abstract":"The goal of this research is to solve algorithmic problems from application<br\/>areas by visualizing the problem data in terms of a related geometric<br\/>space, using this visualization to develop an improved mathematical<br\/>understanding of these problems, and combining this understanding with the<br\/>techniques of computational geometry to develop efficient algorithms for<br\/>the problems. Particular problem domains targeted by this project include<br\/>(1) generation of unstructured quadrilateral and cuboid meshes for the<br\/>finite element method; (2) robust methods for fitting hyperplanes or other<br\/>geometric shapes to sets of data points; and (3) adaptive user interface<br\/>problems, for example tuning the relative weights of parameters such as<br\/>distance, travel time, or scenic value in a vehicle routing system, to make<br\/>it produce routes that more closely match driver preferences. All of these<br\/>areas relate to fundamental geometric problems of partitioning spaces by<br\/>arrangements of curves or surfaces. A further connecting theme in the<br\/>proposed research is the use of topological methods to separate global<br\/>shape properties from local geometric attributes, and to provide a precise<br\/>language for discussing these properties. The investigator will apply a<br\/>conscious focus on computational topology to accelerate progress in<br\/>geometric computing.","title":"Geometrics Algorithms in Statistics, Meshing, and Parametric Optimization","awardID":"9912338","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["517727"],"PO":["321058"]},"49661":{"abstract":"EIA-0000536<br\/>Scheuermann, Peter<br\/>Northwestern University<br\/><br\/>CISE Postdoctoral Associates in Experimental Computer Science: An<br\/>Architecture for Mining of Semi-Structured Data on the Web<br\/><br\/>With the explosion of the Web and the advent of digital libraries, the<br\/>demand for knowledge discovery techniques for semi-structured data has<br\/>increased greatly. Semi-structured HTML documents are characterized by a<br\/>rich data model, i.e., they contain both structured values and unstructured<br\/>concepts. Exploring the semantic knowledge about the relationships among<br\/>these unstructured concepts is important but costly as an on-line process.<br\/><br\/>The postdoctoral associate will assist in developing a prototype Web mining<br\/>system that will allow its users to specify a set of constraints, either<br\/>data values or concepts, and obtain a set of rules that contain the given<br\/>constraints and other items related to the constraint set. In order to<br\/>derive these rules, the system makes use of a concept library that<br\/>differentiates between general concepts and concepts associated with<br\/>specialized domains. Specifically, the associate will 1) develop new<br\/>methods for generating partially constrained association rules and<br\/>classifications rules that make use of the extended concept hierarchies<br\/>kept in the library, 2) investigate the various lexical tools available and<br\/>see how to integrate them into Wordnet (which forms the basis of the<br\/>concept library), 3) explore various heuristic methods for deciding when a<br\/>given concept belongs to a specialized concept library or to the general<br\/>concept library, and 4) explore the use of sampling techniques in reducing<br\/>the search space of rule generation.","title":"CISE Postdoctoral Research Associateships in Experimental Computer Science - An Architecture for Mining of Semi-Structured Data on the WEB","awardID":"0000536","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["406694"],"PO":["371077"]},"47120":{"abstract":"This project will initiate collaboration between ELDA\/ELRA and LDC that includes networking and cross-agreements between the two organizations for the production, acquisition, normalization, certification and distribution of novel language data resources for research, education and technology development. A reciprocity agreement to be negotiated between LDC and ELRA will take into account both European and American constraints on the distribution of data. The parties will implement the legal agreement in a concrete manner through the production of a large-scale broadcast news corpus encompassing data in over 45 languages, where the legal, technical, and distribution issues will be sorted out in accordance with the cross-agreement. The production process will be conducted in accordance with best practices in this area as defined by ELRA's and LDC's previous work, and in particular will take advantage of LDC's previous experience in the collection of single language broadcast news collections and Internet-based distribution of language resources. The joint undertaking will provide a concrete test case for transatlantic cooperation between the two organizations while simultaneously developing a unique resource to facilitate the other projects sponsored under this joint EC\/NSF initiative.","title":"Networking Data Centers","awardID":"9982201","effectiveDate":"2000-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"T026","name":"DARPA-TRANSTAC PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V242","name":"CIA-MACHINE TRANSLATION(MT)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"W171","name":"DARPA-ROBUST MULTI MODEL & LOW"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"X496","name":"DARPA-MLIAM"}}],"PIcoPI":["507484","501444"],"PO":["565227"]},"48154":{"abstract":"This proposal seeks funding to investigate a number of basic research problems within the general framework of network-aware server protocols and services. Tackling these problems is critical for the continued scalability of the Internet.<br\/> Mass servers are popular Internet servers which produce a substantial fraction of the traffic flowing through the network. Currently, such Mass servers are tuned to optimize their own performance (e.g. capacity, latency, I\/O utilization), while overlooking the opportunity to monitor network conditions and to use that information advantageously. This information could be used both to improve network behavior (e.g. alleviate the problems resulting from congestion) and in further optimizing the performance of servicing requests. Thus, Mass servers are uniquely positioned (1) to observe and diagnose network conditions by tracking the flows that they generate, and (2) to manage and control network resources by better regulating and scheduling the traffic they inject into the network. These goals must be pursued over a wide spectrum of time scales to maximize the beneficial impact that can be achieved.<br\/> On the shortest time scales, a Mass server can minimize packet loss by smoothing the otherwise bursty process of injecting packets into the network. At medium time scales, a Mass server can perform aggregate congestion management by bundling like connections to avoid the burstiness that results from competition among flows. At even longer time scales, a Mass server can map persistent hotspots in the network and optimize scheduling of connections to mitigate the impact of overusing those resources. These objectives are representative of projects which the researchers intend to undertake on these various time scales. <br\/> The research work outlined in this proposal aims at achieving these benefits through the derivation of new measurement and analysis techniques to enable diagnosis of network conditions, and the development of new services and protocol to enable efficient network resource management and control.<br\/> Proposed work in network measurement and diagnosis at Mass servers focuses on the use of passive and active probing techniques for the identification of network bottlenecks (e.g. congestion conditions) along various time scales. The techniques to be used range from multi-resolution analysis using discrete wavelet transforms, to maximum likelihood estimators for packet loss estimation.<br\/> Empowered with such diagnostic information, the proposed work in network resource management and control at Mass servers focuses on alleviating the problems associated with network bottlenecks (e.g. large delays and jitters, low and unfair resource utilization) along various time scales. The techniques to be used range from the development of traffic pacing protocols to alleviate burstiness at the sub-round-trip-time scale, to aggregate congestion control algorithms for improving utilization of network resources and reducing jitter.<br\/> A key component of the proposed work is implementation and prototyping. To that end, the utility of the tools and protocols developed will be demonstrated by integrating them into three modular components for distribution to the research community, namely: (1) BEACON: A collection of network measurement and diagnosis tools, (2) TURNPIKE: A collection of network management and control protocols and services, and (3) BACKBAY: A platform that supports the integration of BEACON and TURNPIKE functionality into a high performance web server architecture.<br\/> The pursuit of the research goals outlined in this proposal is timely. Achieving these goals will leapfrog current piecemeal attempts aiming at supporting Internet growth. The research team assembled to pursue these ambitious goals has made significant, nationally-recognized contributions to the understanding of Internet traffic characteristics and has an established record in software development and technology transfer. Boston University is committed to supporting this team through substantial financial and infrastructural commitments that complement and leverage the support sought from NSF.","title":"Diagnosis and Control of Network Variability by Massively Accessed Servers","awardID":"9986397","effectiveDate":"2000-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["562061","486062","313342"],"PO":["7594"]},"49012":{"abstract":"This is a joint effort with Prof. Caetano Traina from the University of Sao Paulo, Brazil. It strengthens the existing collaboration between Prof. Christos Faloutsos at CMU and Prof. Traina and his group, which has already contributed fast indexing methods for metric and video datasets. CMU brings expertise in video indexing (the Informedia DL-II project), in power laws, and in data mining. The benefit of the collaboration will be faster methods for indexing multimedia and metric datasets, and for finding patterns in such collections. This project focuses on indexing multimedia data and on developing new tools to find patterns and correlations in such data. Multimedia objects can often be mapped to n-dimensional points through feature extraction. If not, then they can be treated as metric data, when we are provided a pair-wise distance function. The methods will be applicable to multimedia, metric and spatial data alike. Typical questions include: \"find video clips similar to a given video clip\"; \"how strong is the correlation (or anti-correlation) between the locations of schools and the locations of libraries?\"; \"how many schools are within 5 miles from libraries?\". For indexing, the goals are (a) to provide formulas to estimate the selectivities for similarity queries and (b) to build faster searching structures. Preliminary joint work showed that the distribution of distances in spatial and metric datasets often follows a \"power-law\", which are useful to design better search strategies. For data mining, the goals are to provide tools for detection of spatial correlations and to develop fast visualization algorithms for spatial and multimedia datasets. The developed tools will be able to show whether there are clusters in a dataset, how many they are, and whether two groups of points (e.g. \"schools\" and \"libraries\") are \"attracting\" or \"repelling\" each other.","title":"CNPq: IMiMD-Indexing and Data Mining in Multimedia Databases","awardID":"9988876","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"5977","name":"AMERICAS PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["548220"],"PO":["563751"]},"54391":{"abstract":"EIA-0080124<br\/>Nelson, Randal C.<br\/>University of Rochester<br\/><br\/>CISE Research Infrastructure: Spatial Intelligence for Computer-Enhanced Interaction with Physical Environments<br\/><br\/>Intelligent computer systems have considerable potential to augment human abilities, not only in accessing abstracted information, but also in dealing with physical environments (both real and virtual). A canonical example of such a system, though certainly not the only one, is a robot with which one can converse. To mediate between people and a physical environment, an intelligent system must perceive spatial structure of various sorts and competently execute physical actions. At the same time, it must communicate with human users to provide information, accept instruction, or assist interactively with complex tasks. <br\/><br\/>The term \"spatial intelligence\" can be used to capture the overarching ability to perceive, act in, and communicate about a physical environment. Implementing spatial intelligence depends on integrating a variety of enabling technologies in AI, distributed systems, and human interfaces. Some of the most critical of these technologies, particularly in machine perception and natural language communication are currently crossing a threshold that promises to make useful, end-to-end, spatially intelligent systems viable for the first time.<br\/><br\/>The overall goal of the project is to enable creation of flexible spatial intelligence with which human users can interact naturally to carry out a variety of collaborative tasks. The project will create and equip a laboratory resource specifically designed to advance the state of the art in the various enabling technologies, and facilitate and demonstrate their integration into end-to-end systems.","title":"CISE Research Infrastructure: Spatial Intelligence for Computer-Enhanced Interaction with Physical Environments","awardID":"0080124","effectiveDate":"2000-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["540805","564815","214928",138901,"450767"],"PO":["565272"]},"48881":{"abstract":"CCR 9988491<br\/>Smith, Scott<br\/>Johns Hopkins University<br\/>Type Systems for Secure Programming<br\/><br\/>Security in language design is a rising concern due to increased<br\/>portability of code. Most language-level security mechanisms have<br\/>been afterthoughts to language designs. One widely known language<br\/>security system is the Java Security Architecture, found in the JDK<br\/>1.2. There, access control mechanisms are written as code in the<br\/>program itself, and it is difficult to determine what access controls<br\/>are actually in place. The goal of this research is to develop a<br\/>declarative security architecture for programming languages. In this<br\/>project, a novel static type system for guaranteeing safety with<br\/>respect to certain security properties at run-time will be developed.<br\/>The research consists of two main components,<br\/><br\/>* a novel static type system in which security information decorates program<br\/> types (so-called security access types), and the type system properly <br\/> enforces propagation of this information;<br\/><br\/>* a novel module system which includes security access types as part of the<br\/> interface, and for which program linking will entail validating security<br\/> properties.<br\/><br\/>The aim is an expressive, flexible security discipline which allows<br\/>static verification that security checks are met, allowing run-time<br\/>security checks to be avoided. The advantages of static over dynamic<br\/>enforcement of properties forms one of the basic pillars of<br\/>programming language design and software engineering: the types<br\/>themselves serve as concise readable specifications of program<br\/>behavior, and the lack of a class of run-time errors gives more<br\/>reliable execution behavior. In the context of secure programming,<br\/>\"more reliable\" directly translates to \"more secure\". The long-term<br\/>aim of this research is a more secure internet.","title":"Type Systems for Secure Programming","awardID":"9988491","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["562016"],"PO":["564388"]},"48771":{"abstract":"This project will study the computational complexity of number-theoretic problems, which is relevant to both the theory and practive of computing. On the practical side, computational problems in number theory arise in the design of systems for random number generation, cryptography, and computer algebra. On the theoretical side, many of the classic questions about the relative power of various computational resources are crucial to number theory. For example, if randomization is not necessary for polynomial-time computation, then there is a fast deterministic test for primality. <br\/><br\/>This work falls into four categories:<br\/><br\/>a) designing improved models for the analysis of number-theoretic algorithms,<br\/><br\/>b) improving statistical tests of heuristic models for number-theoretic algorithms,<br\/><br\/>c) applying analytic and algebraic number theory to computations in number theory, and<br\/><br\/>d) incorporating efficient algorithms into the teaching of elementary cryptography.","title":"Algorithms in Number Theory","awardID":"9988202","effectiveDate":"2000-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["321051"],"PO":["321058"]},"47451":{"abstract":"EIA-9983510<br\/>Baru, Chaitanya K<br\/>University of California<br\/><br\/>Digital Government: 12T An Information Testbed for Digital Government<br\/><br\/>This project will address one of the major problems in government information systems, the inability to integrated information from various heterogeneous data sources. Usually these data are collected and managed by different agencies at different levels of government, providing more impediments to integration. Partners from the Bureau of the Census, National Archives and Records Administration, US Geological Survey, the State of Pennsylvania, and the San Diego Association of Governments will work with researchers from the San Diego Supercomputer Center, the University of California at San Diego, the University of Michigan, and the University of Pennsylvania.<br\/><br\/>Building upon the initial work of the Mediation of Information using XML (MIX) project, this grant has four major technical thrusts:<br\/><br\/>1. allow for an extension of MIX's wrapper technology to the domain of geospatial information,<br\/>2. develop data transfer protocols for lightweight network-based agents,<br\/>3. investigate new interfaces to the data, and<br\/>4. build wrapper toolkits for geospatial and statistical survey metadata.","title":"Digital Government: I2T: An Information Integration Testbed for Digital Government","awardID":"9983510","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["559496","525612","560510"],"PO":["371077"]},"55074":{"abstract":"This project will perform fundamental investigations of the strenghts and limitations of the low-level human visual system. It will seek to identify image properties that people can see quickly, to test how those properties interact with one another, and to determine how to harness those properties. Understanding how we perceive the world around us will benefit many research areas including information display, image generation, image analysis, and the simulation of vision. This project will apply this knowledge to an important area of computer graphics: the visualization of large, complex, multidimensional datasets. The goal in this area is to design visualizations that support rapid and accurate exploration and analysis of such complex data. To do this, the project must display all of the data without overwhelming the viewer's visual system. It will solve this problem by constructing a perceptual visualization architecture, which will inclued a \"visualization assistant\". This assistant will use artificial intelligence search techniques to help viewers choose perceptually optimal methods of converting their data into effective visualizations.","title":"A Perceptual Visualization Architecture","awardID":"0083421","effectiveDate":"2000-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}}],"PIcoPI":["530056"],"PO":["565272"]},"69396":{"abstract":"","title":"CADRE: Digital Muybridge: A Repository for Human Motion Data","awardID":"0196217","effectiveDate":"2000-09-01","expirationDate":"2006-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4725","name":"EXPERIMENTAL SYSTEMS\/CADRE"}}],"PIcoPI":["438709"],"PO":["297837"]},"55690":{"abstract":"Life at its most detailed level depends on the geometric shape of molecules. Nevertheless, geometric methods are relatively uncommon in computational biology, primarily because of difficult and unsolved issues in applying geometric computing to biology. This project will address these causes by investigating geometric representations and developing novel geometric methods. It will incorporate these into software that helps structural biologists with their work and integrates with their current tools. The key research issues include: 1)representation and classification of geometric shape; 2)synthesis of geometric, physical, and statistical information; 3)computation and representation of motion; 4)organization of shapes for rapid searches; and 5) hierarchies for everything.<br\/><br\/>This research is expected to shed light on some of the most important unsolved biological puzzles: prediction of protein structure, simulation of protein folding, and analysis of ligand to protein docking. These processes link form to function. Understanding them will pave the way to a post-genomic era in biological research, in which the wealth of DNA sequence information is complemented by corresponding knowledge of geometric shape. Together, sequence and shape will provide a description of the biological function so critical for all life.","title":"ITR: Computational Geometry for Structural Biology and Bioinformatics","awardID":"0086013","effectiveDate":"2000-09-15","expirationDate":"2007-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["478348","554177","521232",142752,"554471"],"PO":["549626"]},"54293":{"abstract":"EIA-0079830<br\/>Desai, Jaydev P.<br\/>Drexel University<br\/><br\/>MRI: Acquisition of a Complete Whole Arm Manipulator (WAM) Robot System<br\/><br\/>The goal of this work is to acquire a whole arm manipulator (WAM) robot which will greatly enhance the development of the medical robotics program, combining haptic and visual information for object exploration in unstructured environment. The robot will also be an invaluable tool for developing and testing novel nonlinear control models at Drexel University. The equipment will also have significant impact on the undergraduate and graduate education at Drexel in the mentioned research areas.","title":"MRI: Acquisition of a Complete Whole Arm Manipulator (WAM) Robot System","awardID":"0079830","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["241709",138647,"554760","379044","366025"],"PO":["557609"]},"48893":{"abstract":"Dr. Brett D. Fleisch, University of California, Riverside<br\/><br\/>PROJECT ABSTRACT:<br\/>This research examines architectures, hardware, software, and algorithmic<br\/>techniques to conserve energy in a distributed system cluster. The research focuses on<br\/>improvement for better energy conservation. The research encompasses 1) monitoring and analysis and 2)<br\/>improvement for better energy conservation including local optimizations and cluster-wide <br\/>optimizations. For 1), the research will quantify power consumption costs for <br\/>various configurations of networked systems. The research will gather and observe traffic in cluster systems that affects energy consumption and performance. For 2), the research will consider both local optimizations and cluster-wide optimizations that will improve energy conservation. For local optimizations, there will be<br\/>low level improvements in device management, base-level communication algorithms, <br\/>system daemons, drivers and systems applications. For cluster-wide optimizations, <br\/>the research will consider a global process manager (GPM) similar to a load <br\/>balancer that will move applications between sites based on criteria that includes <br\/>both performance and power savings. <br\/><br\/>The expected outcome of the research could suggest model topologies, networking technology, and <br\/>software modifications for energy efficient distributed systems of the future. Lastly, the research could <br\/>lead to improved algorithms for conventional systems software to operate in a more power-efficient <br\/>manner.","title":"Power Management for Computing Clusters","awardID":"9988527","effectiveDate":"2000-09-01","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["309350"],"PO":["209879"]},"47474":{"abstract":"This project focuses on developing efficient techniques for implementing<br\/>fault-tolerant distributed systems. Even though checkpointing and<br\/>rollback recovery have been known techniques for achieving fault-tolerance<br\/>in distributed systems, the intricacies involved in designing efficient<br\/>checkpointing and recovery protocols has been thoroughly addressed and<br\/>understood only recently. Based on this theoretical foundation,<br\/>(i) it is proposed to develop efficient checkpointing and<br\/>recovery techniques; (ii) implement a simulation testbed for evaluating<br\/>the performance of the newly developed as well as existing checkpointing<br\/>and recovery techniques; (iii) integrate the findings<br\/>of our research as well as the existing research work on fault-tolerance in the<br\/>graduate curriculum. The important expected outcomes from this work are:<br\/>(i) an improved understanding of the issues involved in building reliable<br\/>distributed systems; (ii) improved techniques for fault-tolerance in<br\/>distributed systems based on the hard experimental data as well as strong<br\/>theoretical foundation; (iii) integration of the results of our research<br\/>in an advanced course in distributed systems which would facilitate<br\/>the students not only understand the intricacies involved in building<br\/>reliable distributed systems but also help them acquire the necessary<br\/>tools and techniques for building such systems.","title":"CAREER: Design and Implementation of Fault-Tolerant Distributed Computing Systems","awardID":"9983584","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["250084"],"PO":["309350"]},"48222":{"abstract":"The researchers propose to investigate and to demonstrate an optical networking technique that offers extremely high performance and flexibility, targeting the goals of the Next Generation Internet and beyond. In particular, the researchers will study the Optical-Label Switching technique which offers the following unique properties: 1) Accommodates signals of any protocol and format, 2) Achieves ultra-low latency transport of high burst rate packets, 3) Requires no network or packet synchronization, 4) Interoperates with both circuit-switched and packet-switched traffic, 5) Automatically detects and restores network failures, and 6) Provides on-demand Quality of Service (QoS) and priority based differentiated services.<br\/> The proposed effort makes comprehensive studies of the Next Generation Internet, and seeks<br\/>innovations in both hardware and software. Specifically, the researchers will pursue an integrated effort of the following research activities: 1) NGI architecture and protocol studies, which will design and simulate an optimum network, architecture and protocol to transport optical packets over multi-wavelength signals, 2) NGI network control & management (NC&M), and signaling, which will pursue efficient and rapid routing of packets while intelligently reflecting the network traffic conditions, 3) NGI network element design and optical technologies, which will design, simulate, and prototype network elements that effectively route packets while resolving packet contentions, and 4) NGI Testbed Integration and Demonstration, which will bring network elements and NC&M together to implement a testbed and to experimentally demonstrate broad aspects of networking research covered in this proposed effort. The designed architecture, protocol, and network elements will be put to test at this step and the simulation results will be experimentally verified.","title":"Protocol Agile Optical Networking for the Next Generation Internet","awardID":"9986665","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"5980","name":"WESTERN EUROPE PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["518063","542106","542107"],"PO":["7594"]},"48497":{"abstract":"Programs written in non-object-oriented languages often include conceptual objects. Making the objects explicit makes the program easier to understand and to maintain, and increases opportunities for code reuse. However, manually transforming a non-objected -oriented program into an object-oriented one is a difficult and time-consuming task. <br\/><br\/>The goal of this project is the design and implementation of a software-reengineering tool that will improve legacy code by making it more object-oriented. In particular, given a set of variables that are to become the fields of a class, the tool will identify code segments that should be \"extracted out\" to become methods of the class. This process will be guided by a set of heuristics for identifying candidate code segments, a set of correctness criteria for determining which candidates are feasible (i.e., can be extracted into methods while preserving program semantics), and a set of evaluation criteria for choosing the best candidates.","title":"Software Reengineering via Method Extraction","awardID":"9987435","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["331999"],"PO":["564388"]},"48057":{"abstract":"Biological research involves synthesizing information from previous experiments with new data. Because much new biological data is in digital form, and literature describing previous research is becoming increasingly available electronically, doing biological research entirely within a computer becomes a possibility. Indeed, as the volume of data increases, using advanced computational tools as an adjunct to wet-lab experiments is crucial. This research aims to integrate biological sequence, structure and literature within a consistent framework based on relationships between biological data such as bibliographic citations (literature-literature), functional descriptions of proteins (literature-sequence), and protein sequences underlying structures (sequence-structure). The interface of bioinformatics and information retrieval is not only a ripe area for research, but also a critical area for educational development. This project involves the development of remedial materials for biology and computer science students to prepare these two different constituencies for a first course in bioinformatics. It also provides for organization of a series of workshops for computer scientists to discuss application of their work to biology. Finally, in information retrieval, faculty, students and research software have been drawn increasingly to industry, leaving a vacuum of instructional staff and materials. A new course combining material on distributed computing and information retrieval techniques is therefore planned. The system for automatically exploring connections between biological objects as well as new initiatives for graduate education in bioinformatics and information retrieval will allow biologists to investigate higher-level questions, as well as suggesting novel avenues for research based on interactions that might otherwise have been ignored.<br\/>http:\/\/www.cs.rutgers.edu\/~nevill","title":"CAREER: The Biological Digital Library: Information Retrieval Meets Bioinformatics","awardID":"9986085","effectiveDate":"2000-09-15","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":[122839],"PO":["563751"]},"54690":{"abstract":"Ad-hoc networks are a new networking paradigm, in which the network nodes create a network \"on demand.\" There is a number of characteristic attributes associated with the ad-hoc networking approach: highly dynamic network architecture (nodes join and leave the network often and without warning), totally distributed architecture, and multi-hop routing.<br\/> Due to the high reconfiguration rate of the ad-hoc network architectures, many, if not most of the conventional routing protocols do not perform well in this type of environment. Consequently, a number of novel routing protocols, specifically suited for the ad-hoc networks, were proposed. A new Internet Engineering Task Force working group, the MANET Working Group, has been established to address the issues of routing in ad-hoc networks.<br\/> One topic that has not been adequately covered in the context of routing in ad-hoc networks is the issue of QoS-routing for multimedia applications, in general, and the issue of routing for real-time traffic, in particular. More specifically, an ad-hoc network may undergo frequent and unpredictable changes in the network topology, which results in relatively short lifetime of the network paths. Thus, paths become frequently invalid, and, what is more of a problem, there may be little warning of a path going down. Although this might not be a substantial problem for non real-time applications, such frequent path invalidation will most often lead to severe degradation of real-time communication. Thus, a mechanism is needed that will compensate for this behavior of ad-hoc networks. <br\/> A number of approaches have been previously proposed in the technical literature. For instance, maintaining a secondary route, so that when the primary route fails, the system can fall back onto the secondary route as soon as the failure is detected, has proven a good strategy. However, the secondary route mechanism is insufficient in many cases, as the state of paths in the network is usually highly correlated. Thus, failure of the primary path usually means that the secondary path may not be available as well. Also, the change-over time may last too long , so as to cause a perceptible degradation of the signal quality during this period.<br\/> One characteristic of the ad-hoc networks is that there are many paths between a source and a destination. Thus, a mechanism that takes advantage of these multitude of paths is bound to perform better (i.e., in supporting QoS for real-time traffic) than the above two-path approach. Moreover, rather than selecting a single path at any time to use for a specific connection, a better scheme would be to always distribute the information among multiple paths, possibly with some correlation between the information on the various paths, so as to protect against failure of some subset of the paths. The proposed mechanism thus consists of four steps: i) discovery of multiple paths between the source and the destination nodes and evaluation of the correlation in the paths' availability; ii) selection of a subset of the paths into an Active Path Set (APS), based on some \"goodness'' measures (such as the expected availability of the path, the capacity of the path, the delay and jitter of the path, etc), and a scheme that allows to evaluate these measures for the network paths; iii) a method of coding and spreading the information among the paths<br\/>(including matching the paths with the specific requirements of a traffic type); iv) a scheme to monitor the APS paths, estimate their QoS parameters, and update the APS based on the state of the paths and their correlation.<br\/> The above approach is general and can be applied to a variety of real-time traffic types. However, to make the study more realistic, the researchers chose video communication as the real-time test application. Thus, the researchers intend to propose a specific set of algorithms\/protocols that addresses the four steps as outlined above, in the context of video communication. For instance, they will determine what are the parameters relevant to transmission of compressed video traffic over unstable paths and propose schemes to code video source into multiple correlated descriptions that can be spread over multiple paths.<br\/> The researchers intend to integrate the above multi-path transport scheme for video traffic into a comprehensive simulation of the ad-hoc networking environment, that will include a radio propagation model, nodal mobility model, MAC protocol, and a routing algorithm (to discover the network paths). The researchers will gather performance measures from the simulation that will allow them to determine the quality of video at the application level depending on the parameters of the models used. The researchers expect to be able to answer questions, ranging from the very basic issue of viability of supporting real-time traffic in an ad-hoc networking environment to what type of routing protocol is most suitable for real-t","title":"ITR: Support for Video Traffic in Ad Hoc Networks","awardID":"0081357","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["525973","491898","438934"],"PO":["250082"]},"55680":{"abstract":"This is the first year funding of a five-year continuing award. This project is based on the belief that, to be more accessible to the general population, computers must be more proactive in their interactions with people. In human interaction, someone who waits for each command before making any communication attempt would be regarded as uncooperative and unhelpful. In order for a computer to be more proactive and, thus, to bear its part of the burden of initiation in interactions, it must have (1) much more real-time information about its user, and (2) algorithms that select actions based on this information rather than simply on user commands. The computer needs information about the user's current and past emotional, motivational and cognitive state as well as the state of the task at hand. A theory, is needed to guide the development of algorithms that select appropriate actions based on user and task state. This research constitutes the next steps in an attempt by the PI's multidisciplinary team to develop this capability.<br\/><br\/>Proposed research includes: (1) further development of methods to sense user postures, movements, expressions and speech; (2) analysis and fusion of this information to identify and track user states; (3) task state tracking; (4) creating a corpus of emotion- and action-labeled videotapes for use with computer learning; (5) further development of affective communication; (6) development of the basis for human-centered state-based action decisions; and (7) evaluation of computer proaction on human behavior and response. The testbed is an environment for hands-on education in science and engineering, using the Lego Mindstorms construction and robotics environment, with children of middle school age. An emphasis will be on developing proactive computing methods for encouraging interest and conceptual development of minority children and females, who often show lower achievement in science. Although the work will be conducted within an educational environment, the methods developed and studied will be broadly applicable, and this project should serve as an exemplar of the type of work that is needed in other computer-aided situations.","title":"ITR: Multimodal Human Computer Interaction: Toward a Proactive Computer","awardID":"0085980","effectiveDate":"2000-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[142702,"550184","513826","426630","145824","555866"],"PO":["565227"]},"55691":{"abstract":"EIA-0086015<br\/>Reif, John H. <br\/>Duke University<br\/><br\/>ITR: Self-Assembly of DNA Nano-Scale Structures for Computation<br\/><br\/>This project is a multi-institutional effort to investigate the use of DNA self-assembly to do massively parallel computations at the molecular scale. The main goal is to develop a proof-of-concept demonstration of the application of DNA self-assembly to various basic computational tasks, such as sequences of arithmetic and logical computations executed in massively parallel fashion, and the application of this method to computational problems such as integer factorization. The research involves testing of various input\/output methods, development of novel DNA tiles with properties that facilitate the self-assembly and their visualization by imaging devices such as an atomic force microscope, and methods to minimize errors in self-assembly. Specifically, the experiments are being conducted to evaluate the speed and error rates of the various types of self-assembly reactions. In addition, experimental testing of massively parallel DNA self-assembly on particular problems, such as arithmetic and Boolean vector operations, is being performed. Some of the technological areas that could be impacted are the application of DNA Lattices as a substrate for surface chemistry and as a substrate for layout of nano-scale circuit components, the construction of 3D DNA lattices, and DNA motors and their application to DNA computations.","title":"ITR: Self-Assembly of DNA Nano-Scale Structures for Computation","awardID":"0086015","effectiveDate":"2000-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["550822","554823","293343","506031"],"PO":["521045"]},"52061":{"abstract":"Sullivan<br\/>0071520<br\/><br\/> The investigator, with his collaborators, studies geometric optimization problems like finding minimum-energy shapes for surfaces and knots in space. They extend their recent classification of embedded constant-mean-curvature surfaces with three ends to the more general case of surfaces with any number of coplanar ends, and also investigate in detail surfaces with truncated ends. In addition, the investigator computes these surfaces numerically, in order, for instance, to create interactive computer graphics. This project uses Willmore's elastic bending energy, and its gradient flow, to discover new minimal surfaces in euclidean and spherical space. The Willmore flow has been recently shown to have short-time solutions, but the investigator considers whether it can fail to have long-time solutions. This project also studies configurations for knots which minimize ropelength, giving new lower bounds for the ropelength of small knots, and new asymptotic bounds on the growth of ropelength with crossing number. Finally, the investigator uses his experience with numerical modeling of curves and surfaces to give new understanding of geometrically natural discretizations for quantities related to curvature.<br\/><br\/> Many real-world problems can be cast in the form of optimizing some feature of a shape; mathematically, these become variational problems for geometric energies. For instance, thin films, like those in foams, usually minimize their area and thus are constant-mean curvature surfaces. Cell membranes are more complicated bilayer surfaces which minimize an elastic bending energy known mathematically as the Willmore energy. Knotted curves achieve an optimal shape when a rope is pulled tight, or if a charged knotted wire repels itself electrostatically; understanding such configurations helps explain the behavior of biological molecules like DNA. This project explores such phsically natural problems, which remain challenging from both theoretical and computational standpoints.","title":"Optimal Geometry: Theory and Computation","awardID":"0071520","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1265","name":"GEOMETRIC ANALYSIS"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["340351"],"PO":["565027"]},"55130":{"abstract":"In sequential decision tasks such as resource optimization, robot control, and game playing, several decisions must be made before the outcome can be evaluated. Such reinforcement feedback depends on the entire sequence of decisions, and it is difficult to determine which of the decisions were responsible for the outcome. This project aims at developing better techniques for learning in domains with such sparse feedback, based on evolving neural networks with genetic algorithms. The goal is both to be able to solve existing problems faster, and to be able to solve problems that have not been feasible as sequential decision tasks before. Our previous work showed that neuroevolution is most powerful when individual neurons are evolved to cooperate and form good networks. In this project, such cooperative coevolution methods are studied in depth. The research aims at answering three main questions: Where does the power of cooperative coevolution come from and what are the best ways of making use of it? How do the evolutionary reinforcement learning methods differ from the traditional value function methods in learning sequential decision tasks? Does evolutionary reinforcement learning have the accuracy and flexibility required in real-world applications? If successful, the project will result in cooperative coevolution algorithms that will solve existing sequential decision tasks faster, and will allow solving more difficult tasks than before. We will know how to decide between evolutionary and value function methods for a given reinforcement learning task, and also how to use each method most effectively. Finally, the project will demonstrate how learning in general, and cooperative coevolution of neural networks in particular, can be used to save resources and achieve complex behavior in challenging real-world tasks.","title":"Cooperative Coevolution of Neural Networks in Sequential Decision Tasks","awardID":"0083776","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["408627"],"PO":["491702"]},"43294":{"abstract":"Proposal Number: 9912342<br\/>PI: Madhu Sudan<br\/>Institution: MIT<br\/><br\/>One of the broad goals of the theory of computer science is to identify functions that seem hard to compute, and if possible to prove that they are indeed hard. A further goal is to quantify how hard a function is to compute, for some appropriate measure of hardness, and to find functions that are very hard under this measure. For example, in the most common application of computational hardness, namely cryptography, one needs to know that a given hard function, such as the discrete logarithm or RSA decryption, is hard on almost all inputs (rather than on some adversarially chosen inputs). In order to formalize such statements, one needs to find good measures of hardness and develop tools to analyze them.<br\/>In the recent pasta number of research articles have proposed different notions of hardness and analyzed them. Many of these results can be thought of as abstracting quantitative notions of information based on computational complexity. The results show that given a hard function, one can construct a much harder one, in the sense that computing even a small amount of information about the harder function allows for efficient perfect computation of the given function. Further these results share a common theme of relying on state-of-the-art results on the efficient listdecodability of error-correcting codes.<br\/>This research project will perform a systematic study of the influence of decoding algorithms on complexity theory. It will examine a series of topics where a connection may prove to be fruitful. The research project will also examine new questions in coding theory influenced by the search for new tools in complexity theory. The most ambitious element of the project is the exploration of a coding theoretic approach to average case hardness of problems in NP. The search for average-case hard problems within NP is one of the fundamental quests of complexity theory. Existence of problems that are hard on the average is a necessary condition for cryptography. It also explains seeming contrast between worst-case hardness and empirically observed easiness of some optimization problems. Thus progress in this direction would be of great impact to computer science.","title":"Computational Complexity and Information Theory","awardID":"9912342","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["425345"],"PO":["543507"]},"48872":{"abstract":"Wide-area distributed computing systems represent the future of scientific and commercial computing.<br\/>Such systems will enable a wide range of futuristic applications with the potential for enormous economic<br\/>and social impact applications such as distributed multimedia services, Web-based collaboration,<br\/>distributed supercomputing, and teleimmersion. Before this vision can be realized, however, extensive<br\/>research will be required in virtually all aspects of software system design, implementation, and evaluation.<br\/>Discrete-event simulation has been an essential tool for the design and analysis of traditional computational<br\/>systems and applications. Realistic simulation of applications executing on wide-area distributed systems,<br\/>however, is a challenging task because of the scale of the software, hardware and network subsystems that<br\/>must be simulated. Nevertheless, the intricacy of these components and their complex, closed-loop<br\/>interactions require the components and their interactions to be modeled in sufficient detail to appropriately<br\/>predict their impact on overall system performance.<br\/>In recent work, the PIs have collaboratively obtained some exciting but preliminary results showing that<br\/>specific compiler information can greatly enhance the efficiency and scalability of simulation of message-passing programs. For instance, it was shown that simulation of a scalable ASCI kernel benchmark<br\/>application called SWEEP3D executing on up to 128 processors could be simulated faster than real-time by<br\/>using parallel simulations together with the type of compiler optimizations that are the subject of this<br\/>proposal. Also, the compiler-optimized simulation can evaluate very large data sets on thousands of<br\/>processors: it was possible to simulate the performance of a 40 million-problem size Sweep3D for up to<br\/>10,000 processors. There are potentially a number of other strategies to dramatically improve simulation<br\/>scalability and performance by using compiler information, none of which have been studied so far. A<br\/>comprehensive program of research is required to develop their potential and evaluate their impact on<br\/>simulation of real world applications.<br\/>The focus of the current proposal is to develop compiler-based techniques for improving the efficiency of<br\/>parallel discrete event simulation, and to use these techniques to evaluate application and system software<br\/>performance for wide-area distributed systems. There are three key components to this proposal:<br\/>1. To explore a range of compiler-supported strategies for highly efficient simulation of dynamic, large-scale systems and applications.<br\/>2. To use these strategies in developing a practical performance tool for wide-area distributed systems, by<br\/>extending our existing compiler and simulation infrastructure. This requires addressing additional<br\/>challenges raised by the dynamic nature of these systems and the lack of well-defined metrics to<br\/>measure effective application level performance in such environments.<br\/>3. To evaluate the effectiveness of these strategies for real world distributed applications such as SF-Express, a large-scale distributed interactive simulation (DIS) environment, and a distributed video-on-demand server (a distributed multimedia application).<br\/>The proposed research program builds on a collaboration of several years between the PIs' research groups,<br\/>and brings together key strengths in parallel simulation of large-scale parallel programs, parallel simulation of wide-area networks, and in parallelizing compilers and their use for supporting performance evaluation.<br\/>This program of research also complements the ongoing software efforts for wide-area systems that are<br\/>aimed at developing operating system services (e.g., Globus, Legion, and WebOS) and programming<br\/>environments (e.g., Legion, Globe, and GrADS). As such, the proposed research program represents an<br\/>essential third leg of software support for the development and deployment of successful wide-area<br\/>distributed systems.","title":"Collaborative Research: Compiler-Supported Simulation of Scalable Applications for Wide-Area Distributed Computing Systems","awardID":"9988471","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["231158"],"PO":["241298"]},"56011":{"abstract":"EIA-0087076<br\/>Kavi, Krishna M.<br\/>University of Alabama Huntsville<br\/><br\/>Digital Government: SGER: Exploratory Research for Correlating and Data Mining Flight Data From NSTB Accident Investigations<br\/><br\/>This grant will support preliminary explorations of the design of intelligent wireless flight data recorders and real-time monitoring systems using modern computer and information science concepts and technologies. The partnership is with the National Transportation and Safety Board (NSTB). Previously collected flight data held by NSTB will be standardized for purposes of data mining. Potential uses of such a system would be to predict and provide early warning of potentially unsafe conditions for pilots.","title":"Digital Government: SGER: Exploratory Research for Correlating and Data Mining Flight Data from NTSB Accident Investigations.","awardID":"0087076","effectiveDate":"2000-09-15","expirationDate":"2001-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["13545"],"PO":["371077"]},"55043":{"abstract":"This project will develop machine learning algorithms, prototype tools, and supporting theory for solving complex machine learning problems. Existing theory and algorithms have focused on learning simple classifiers that take a description of an object and assign it to one of a small number of classes (e.g., taking an image of a character and classifying it as one of the 26 letters of the alphabet). Emerging applications in science and industry require learning much more complex functions that map from complex inputs (e.g., 2D maps, time series, and strings) to complex outputs (e.g., other 2D maps, time series, and strings). Despite the lack of theory covering such cases, many practical systems have been built that work well in particular applications. These systems all employ some form of divide-and-conquer, where the inputs and outputs are divided into smaller pieces (\"windows\"), classified, and then the results are merged to produce an overall solution. This project will develop a general formulation of machine learning for divide-and-conquer problems, a collection of algorithms for solving these problems, and a prototype tool kit for solving new learning problems via the divide-and-conquer approach. In addition, theoretical models will be developed to understand the tradeoffs that affect the design of divide-and-conquer systems. The resulting algorithms and theory will extend the range of problems that can be solved via machine learning methods and make it easier to construct new divide-and-conquer machine learning applications. This will lead to improved performance of existing machine learning applications, for example, in text processing, intrusion detection, and the analysis of sensor data to signal alarms.","title":"Divide and Conquer Methods for Machine Learning","awardID":"0083292","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["554550"],"PO":["564456"]},"47552":{"abstract":"Internet attackers gain access to computers in two ways. The first way<br\/>is by monitoring and imitating the Internet activities of an authorized<br\/>user. There are well-known cryptographic algorithms that protect against<br\/>eavesdroppers, but today's cryptographic software is too slow to be<br\/>universally deployed. The second way is by locating and exploiting bugs<br\/>in communications software. The security community has been working for<br\/>years to find these bugs before the attackers do, but programmers are<br\/>adding bugs to security-critical software faster than security experts<br\/>can fix them.<br\/><br\/>This CAREER award project spans five areas: (1)<br\/>cryptographic algorithms fast enough to be used for all Internet<br\/>communications; (2) cryptographic protocols to protect specific Internet<br\/>services against espionage and sabotage; (3) educational tools to help<br\/>programmers learn how to write correct software; (4) tools to reduce the<br\/>amount of software in which bugs can produce security problems; (5)<br\/>secure replacements for widely used Internet servers that are habitually<br\/>plagued by security problems.","title":"CAREER: Computational number theory, cryptography, and computer security","awardID":"9983950","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["548359"],"PO":["321058"]},"69211":{"abstract":"","title":"PECASE: Universal Access to the Graphical User Interface: Design for the Partially Sighted","awardID":"0196030","effectiveDate":"2000-09-08","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"5342","name":"Gen & Age Rel Disabilities Eng"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"5345","name":"BIOMEDICAL ENGINEERING"}}],"PIcoPI":["333704"],"PO":["317420"]},"55197":{"abstract":"The goal of this research is to investigate and develop computational methods for supporting automated negotiation of contracts in business-to-business E-commerce applications. Such processes require the ability to negotiate over contracts that have scheduling constraints, interact with a highly distributed web of suppliers with different capabilities through the completion of the contracted work, and deal with failures in contract execution. These problems are modeled using a community of self-interested agents with limited rationality, each representing a business entity or a decision-maker. Algorithms and decision strategies will be developed for effective bid construction, bid evaluation, supplier selection, execution monitoring, and renegotiation of contracts among multiple agents. A distributed computational testbed will be developed and used for simulation, and analysis. The results of this research will contribute to the development of general computational models for multi-agent contracting. The research efforts will also produce a highly distributed market infrastructure with an agent population that can be used by industry and researchers for further investigations, as well as by educators as a tool for training the next generation of e-commerce specialists. The potential payoff of the research is high, given the projected size of the business-to-business and make-to-order e-commerce.","title":"Collaborative Research: A Computational Framework for Agent-Based Contracting","awardID":"0084202","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["561562"],"PO":["495796"]},"48795":{"abstract":"Abstract<br\/><br\/><br\/>Circuit Complexity: Grid Graphs, Planar Circuits, and Lower <br\/>Bounds<br\/><br\/>David Mix Barrington<br\/>Computer Science Department<br\/>University of Massachusetts<br\/><br\/>Project Description<br\/><br\/>Complexity theory is the mathematical study of the resources needed for computational problems. In circuit complexity theory these resources are the size, depth, and other parameters of boolean circuit families that solve the problems. The basic results are upper bounds (algorithms solving the problem while obeying certain resource constraints) and lower bounds (proofs that no such algorithm can do so).<br\/><br\/>This project takes a qualitative approach to circuit complexity. The basic object is a complexity class, which is the set of problems that can be solved within certain resource constraints. For most natural and robust choices of constraints, the resulting class has complete problems --- problems whose solution requires a fundamental algorithmic technique that suffices to solve all the problems in the class. Upper and lower bounds for the complete problems then give us results about the classes. This project studies two specific computational problems: grid graph reachability and monotone planar circuit value. Given a graph embedded on a rectangular mesh, and two nodes, is there a path from one node to the other? What is the value computed by a given circuit of AND and OR gates, where no wires cross, and a given input? In each case recent work of the PI and others have improved upper bounds for versions of the problem. The goal here is to improve these algorithmic results and explore the various versions, relating them to each other and to standard problems. <br\/><br\/>This exploration will be carried out in the context of prior work by the PI and others in qualitative complexity theory. This work has identified a set of standard complexity classes that are robust across a variety of models, and developed a single framework characterizing these classes in term of the syntactic resources needed to express their problems in first-order logic.<br\/><br\/>In addition, further work will apply the logical framework to lower bound problems in low-level complexity. The outstanding problem in this area, open for a decade, is to prove some natural problem to be outside of a circuit class such as $ACC^0$. Here two new approaches, developed in recent work of the PI and others, offer some hope: counting circuit classes and intermediate levels of uniformity.","title":"Circuit Complexity: Grid Graphs, Planar Circuits, and Lower Bounds","awardID":"9988260","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["513561"],"PO":["279077"]},"49521":{"abstract":"The definitions of P and NP are based on polynomial time computations. It has been a long-time concern whether one should call a problem with computational complexity Q (n100) 'tractable\". A commonly accepted explanation is that in practice most problems in P in fact can be solved in time O(n3) or better. However, recent research has shown that some very important practical problems seem to require algorithms whose complexity is bounded only by very high degree polynomials. <br\/><br\/>On the other hand, there are many NP-hard problems, described in a parameterized version, for which it is desired to construct the precise solutions deterministically, while a wide range of applications is only interested in solving these problems with a small or moderate value for the parameters. The point is how to take advantage of this fact and develop most efficient algorithms for these intractable problems in practice.<br\/><br\/>The research studies the refinement of the classification of tractability and intractability, based on the recently developed theory of parameterized complexity, with the aim of identifying \"impractical\" polynomial time algorithms and \"efficient\" exponential time algorithms for practical problems. The following specific issues in algorithm theory are investigated:<br\/><br\/>developing efficient parameterized algorithms for intractable problems. This includes two steps: identifying fixed-parameter tractable problems, and development of most efficient parameterized algorithms for the problems.<br\/><br\/>identifying \"hard\" polynomial time solvable problems, based on the framework of the W[1]-hardness. Problems from other practice will also be studied based on this framework.<br\/><br\/>investigating the relationship between parameterized complexity and approximability. Parameterized complexity suggests new techniques for proving non-approximability for certain optimization problems that may otherwise be not easy or even impossible based on classical complexity theory.","title":"Parameterized Computation and Applications","awardID":"0000206","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["410068"],"PO":["543507"]},"54790":{"abstract":"This project is a collaboration between members of the global optimization computer science and the computational biology communities to develop new methods for protein structure prediction and ligand docking. If successful, the methods developed here will help solve two important problems in computational biology - the need for fast conformational searching to predict the structures of proteins or complexes of proteins with other proteins and ligands, and the need to improve folding and docking models. Both problems are fundamental to understanding how the molecules of life work. This project will not solve these problems itself, but will develop new computational methods that can contribute to their solution.<br\/><br\/>Technically, there are two specific aims: (1) To develop efficient methods for searching conformational spaces to find globally optimal (native) conformations on energy landscapes. (2) To develop efficient methods for searching parameter spaces to find optimal parameters for the large, complex models that are common in computational biology. This work is based on Underestimator methods that do not search over the tops of energy landscapes like Monte Carlo, Simulated Annealing, and Molecular Dynamics, the current standard methods.","title":"ITR: Global Optimization in Computational Biology","awardID":"0082146","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["560705","490060"],"PO":["551992"]},"54691":{"abstract":"The Internet is used by a rapidly expanding and changing set of applications. The need for the network to evolve and even to provide application specific processing is significant. However the current network infrastructure is hard to evolve and does not readily support customizability. The goal of Active Networking [21, 3, 2] is to facilitate this evolution and customization by making the network infrastructure programmable. One way of adding programability is to allow code to be down-loaded into the routers, thus enabling the addition or modification of services. A more radical approach is to allow the packets themselves to carry programs to be executed selectively on the network's routers. Among other issues, these two approaches increase the possibility of denial of service attacks whereby a user places excessive demands on network resources in order to deny access to another user. However, they also enable new approaches to handling such attacks and to addressing the general problem of allocating resources within the network.<br\/><br\/>The proposed research focuses on issues involving programmable, or active, packets. Active packets facilitate denial of service attacks in several ways. First, unlike conventional data transport packets, an active packet may require processor cycles and memory at the routers beyond those needed to simply forward the packet. Second, in general, the execution of an active packet at a router may cause more than one active packet to be transmitted from the router. Such behavior is useful, since it allows a packet to fan out across the network, but it is potentially dangerous since it can lead to an exponential growth in the resources used by a single initial packet. Experience with active packet-based systems [9, 8, 23, 22, 24] suggests that denial of service is the single biggest obstacle which must be overcome before such systems are feasible.<br\/><br\/>The proposed research tackles this problem along various fronts. First, the researchers propose to design packet programming languages that make some types of behavior intrinsically impossible. For example, in PLAN [9], packet programs are guaranteed to terminate and thus can never use an un-bounded number of router cycles. The researchers will explore tradeoffs between restricting behavior in terms of resource requirements and limiting the expressibility and thus the flexibility of active packets. However, not all potentially harmful behaviors can be eliminated in this manner. Thus, on a second front, the researchers will consider mechanisms that explicitly account for a packet's resource usage in the network. For example, each packet may carry a resource bound, which is decremented as resources are used, and which triggers termination when the bound is used up. The proposed research combines both implicit and explicit mechanisms for controlling resource usage, with algorithms to control the flow of traffic into the network to decrease the likelihood of denial of service. More generally, one can envisage assessing costs to active packets that execute on congested resources. Thus, on a third front, the researchers propose to investigate mechanisms based on congestion costs to achieve more efficient resource allocations and how they can be facilitated via active packets.<br\/><br\/>Three methodologies will be used to validate proposed solutions. First, the researchers will draw on mathematical modeling to motivate the benefits and investigate the characteristics of the proposed solutions. Second, the researchers will leverage expertise and past work on implementing active networks to demonstrate what is feasible to build, and explore the constraints each solution will place on eventual applications. Finally, the researchers will use network simulation to investigate systems on a scale not achievable on the experimental testbeds.","title":"ITR: Collaborative Research: Resource Allocation and Denial of Service Prevention in Active Networks","awardID":"0081360","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["560221","316328"],"PO":["250082"]},"55670":{"abstract":"This is the first year funding of a four-year continuing award. This project addresses issues relating to the construction of a system for answering questions about information contained in a collection of spoken documents. It focuses on the key scientific questions that arise in the integration of prosodic information, speech recognition and parsing in the retrieval of spoken documents, but will not involve implementation of a complete system. There are four key themes in the research: utilizing parsing in information retrieval; integrating prosodic information in parsing spoken language; incorporating uncertainty in parsing to handle speech recognition errors; and improvements to speech recognition of spontaneous speech. All components will share a probabilistic formulation, thereby affording a systematic framework for integrating the information they provide. A primary project goal is to better understand how information provided by one of these components might be effectively utilized to improve he performance of other components in the information retrieval task. Absent a corpus tailored to the information retrieval topics the PI and his team plan to study, progress will be evaluated using existing annotated text collections such as Switchboard and LDC's Broadcast News collections. The work will lead to advances in information extraction from telephone messages, conversations, university lectures, or from any text (such as encyclopedias), and should potentially serve as the basis for a sorely needed sophisticated web browser technology and data mining applications, which in turn would enable people who currently under-utilize computers to become full participants in the information revolution.","title":"ITR: Information Access to Spoken Documents","awardID":"0085940","effectiveDate":"2000-09-01","expirationDate":"2006-12-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"5977","name":"AMERICAS PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"W210","name":"DEFENSE-HUMAN COMPUTER INTERAC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"X813","name":"DEFENSE-IMPROV SEITCHBOARD COR"}}],"PIcoPI":["562965","527631","543480","445172","516082"],"PO":["565215"]},"55692":{"abstract":"Second and third generation wireless systems have been designed primarily for voice, so they are connection oriented, delay sensitive, and provide fixed bit rates. Additionally, since service is desired \"any-time\/anywhere,\" these systems must provide ubiquitous coverage. This coverage is achieved through relatively uniform grids of cell sites, which are placed to control interference and minimize outage rather than to maximize throughout. As a result, such systems deliver low bit rates and are relatively expensive when used for large amounts of information. At the same time, wireline connection to the Internet has encouraged uses (and users) that depend upon bits being virtually \"free.\" We contend that this \"economic\" mismatch between wired and wireless access is the primary obstacle to the dramatic growth of a wireless Internet. <br\/> The solution may lie in designing systems specifically for wireless data, recognizing that data services are often connectionless, delay insensitive and have no specific bit rate requirements. These differences suggest that ubiquitous (anytime\/anywhere) coverage is not a strict requirement for wireless data networks and makes possible systems in which small, separated coverage areas facilitate transfers of megabytes of data in fractions of a second, and for a fraction of the cost associated with conventional ubiquitous coverage.<br\/> Communication theory and simple link budget calculations tell us that it is possible to build such systems, but the signal processing challenges are numerous and distinct from the historical challenges offered by connection-oriented wireless services. When a mobile user passes an Infostation, there will be a window of opportunity, perhaps as short as a fraction of a second, in which the user will have access to a high-rate communication channel. A key task is to identify that window and transmit at an appropriate rate. The mobile must make these decisions based on measurements of a wideband radio channel in which there is frequency selectivity and time variation in the fading as well as in the interference. In the specific context of an Infostations system, we plan to divide our research into four components:<br\/><br\/>Radio Channel Modeling: The characterization of typical Infostation radio channels.<br\/><br\/>Transceiver Design: The analysis and performance evaluation of transmitters and receivers for both<br\/>single carrier and multicarrier systems.<br\/><br\/>Radio Resource Management Transmitter power and rate adaptation policies derived from receiver<br\/>measurements.<br\/><br\/>Algorithm Development Testbed A platform employing DSP and FPGA technology for the practical<br\/>evaluation of transmitter and receiver algorithms.<br\/><br\/> The activities of this project will encompass three research institutions in New Jersey (New Jersey Institute of Technology, Princeton University, Rutgers University) under the auspices of the N.J. Center for Wireless Telecommunications (NJCWT). The NJCWT is an inter-institutional research and educational organization sponsored and funded by the N.J. Commission on Science and Technology. The focus of the center is a multi-year effort in Digital Radio Technology for Computing, Communications and Information Systems. This effort is supportive of and will enhance the present proposed project in wireless networks.","title":"ITR: Collaborative Research:'Free' Bits: The Challenge of the Wireless Internet","awardID":"0086017","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["560130","424601"],"PO":["223414"]},"54251":{"abstract":"EIA-0079710<br\/>Fulton, Charles T.<br\/>Florida Institute of Technology<br\/><br\/>MRI: Parallel Algorithm Development on an Upgraded Beowulf Cluster<br\/><br\/>It is proposed to update an existing 5 processor BEOWULF system to 32-workstations, each having two processors, for a total of 64 processors. The upgrade is motivated by the needs of the radiative heat transfer group at Florida Tech for a more powerful computing capability, and the development of parallel numerical algorithms for various large scale numerical linear algebra problems which have been under investigation by the applied mathematics and computer science groups for more than 10 years. Both research activities require the parallel capability and the large amount of RAM proposed on each node.","title":"MRI: Parallel Algorithm Development on an upgraded Beowulf Cluster","awardID":"0079710","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["159328",138468,"156364","228890"],"PO":["557609"]},"54273":{"abstract":"EIA-0079770<br\/>Cassel, Lillian N.<br\/>Villanova University<br\/><br\/>MRI: Web Host Access Tools<br\/><br\/>This is a cooperative effort among computing faculty at Villanova University and the College of New Jersey and the objective is the acquisition of web host access tools. The combined research activities address important questions in artificial intelligence, information gathering, human-computer interface and networking all in the context of a common problem. The problem that joins these topics is assisting a user retrieving and using information obtained from the World Wide Web. The actives involve an integration of research and education with an explicit goal to introduce students to a significant research project while advancing the state of the art in enhanced web resource access.","title":"MRI: Web Host Access Tools","awardID":"0079770","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":[138562,"471780","83531",138565,"557468"],"PO":["557609"]},"54394":{"abstract":"EIA-0080134<br\/>Singh, Ambuj<br\/>University of California - Santa Barbara<br\/><br\/>CISE Research Infrastructure: Digital Campus: Scalable Information Services on a Campus-Wide Wireless Network<br\/><br\/>Researchers at the University of California at Santa Barbara will implement a wireless-networked, distributed heterogeneous environment on campus and use it to conduct research in databases, networking, distributed systems, and multimedia. The PIs will focus on large-scale systems in which data is the critical resource and system services are based on various data manipulation functions including data collection, movement\/delivery, aggregation\/processing, and presentation. A significant part of the research will be conducted using a digital classroom, a remote classroom, and individual and team kiosks. Services such as lecture on demand, virtual offices, and remote learning will be provided using this infrastructure. Specific research issues that will be investigated include content-based access, personalized views, multi-dimensional indexing, smart end-to-end applications, joint source-network coding, scalable storage, reliable network service, information summarization, distributed collaboration, multimedia annotation, and interactivity.","title":"CISE Research Infrastructure: Digital Campus: Scalable Information Services on a Campus-wide Wireless Network","awardID":"0080134","effectiveDate":"2000-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["536697","500153","426604","486626","549356"],"PO":["550859"]},"54295":{"abstract":"EIA-0079842<br\/>Yablonovitch, Eli<br\/>University of California Los Angeles<br\/><br\/>MRI: Acquisition of Equipment for Quantum Information Processing<br\/><br\/>The focus of this proposal is acquisition of a Hitachi S-4700-II field emission scanning electron microscope (FESEM) with resolution (secondary emission mode) of 1.5nm at 15kV. The proposed equipment will help make an optical communications receiver and transmitter technology that can transfer quantum coherence and entanglement from photons, to spins in a semiconductor and back to photons again. Since the photo-electron spin is reasonable long-lived, the quantum information can be stored and act as quantum memory. If this technology is successful, it can become the front end for more complex semiconductor based quantum processors in the future, perhaps even a full-fledged quantum computer.","title":"MRI: Acquisition of Equipment for Quantum Information Processing","awardID":"0079842","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["545047","425389","455118","366560"],"PO":["557609"]},"55176":{"abstract":"The explosive growth of computer networks has created the potential to access a great deal of computing power and information, but new models of distributed computing are required to fully utilize these resources. Cooperative distributed problem solving (CDPS) is concerned with solving large-scale problems using systems of intelligent software agents, distributed among networked computers, working cooperatively. CDPS approaches can produce highly flexible and reliable systems, and can be used for a wide range of potential applications. The goal of this project is to make it easier to to build CDPS systems for real-world applications, by improving the understanding of how system and domain characteristics interact to affect the performance of CDPS systems, and by identifying CDPS strategies that perform well under particular conditions. This will allow CDPS techniques to be more widely applied than they currently are. The project will pursue this goal by: developing formalisms for modeling CDPS systems as distributed search processes; implementing software tools that use these models to predict the performance of CDPS systems; identifying generic domain characteristics that are critical for predicting CDPS performance; and performing a broad range of experiments to build up a suite of effective abstract CDPS strategies.","title":"Formalizing Distributed Search in Cooperative Distributed Problem-Solving Systems","awardID":"0084135","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["250152"],"PO":["495796"]},"48895":{"abstract":"PI: Kfoury, Assaf J.<br\/>Proposal Number: 9988529<br\/>Institution: Boston University<br\/><br\/>The proposed research is, broadly speaking, in type theory and rewriting theory, separately and in com-bination, motivated by issues of design and implementation of programming languages. Topics of special interest include: automated type inference, expressiveness of language features, efficiency of implementations, reliability, and analysis of tradeoffs between all of the preceding.<br\/><br\/>Building on past research by the 2 principal investigators and their collaborators in typed lambda calculi, functional languages and rewriting systems, the proposed research will extend to richer typed lambda calculi, mostly based on intersection and union types, towards supporting better design and implementation of higher-order typed languages. This is a shift from the use of universal and existential types in addressing the same issues in the past. The proposed shift is justified by several complications resulting from the use of universal types, discovered by the 2 principal investigators and many other researchers since the early 1990's; by contrast, very recent research shows that these complications are not encountered in typed lambda calculi based on intersection types.<br\/><br\/>The ultimate goal of the proposed research is to provide a rigorous and formal foundation for the imple-mentation of a type-directed and flow-directed compiler using an explicitly typed intermediate language. Such a compiler will observe the invariant that at each stage of the compilation process the intermediate representation of the program will be well typed. A typed intermediate language is currently developed, based on a design to facilitate both flow-directed and type-directed optimization.","title":"A Paradigm Shift in Program Analysis and Transformation via Intersection and Union Types","awardID":"9988529","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["526817","161738"],"PO":["564388"]},"69223":{"abstract":"","title":"Stretchable Architecture and Application-Driven Spectrum Allocation for 4G Wireless Networks","awardID":"0196042","effectiveDate":"2000-09-16","expirationDate":"2004-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["518079",179250],"PO":["565090"]},"48785":{"abstract":"Open-Source software has proven to be an exciting and productive<br\/>alternative to traditional, process-driven software development. But<br\/>Open Source has an inherent limitation--it has been most successful in<br\/>those situations where a strong individual has served as a unifying<br\/>force. Ectropic software design is proposed as a way of sustaining<br\/>conceptual integrity in the absence of such a unifying force;<br\/>ectrospaces are proposed as a collaboration technology to support<br\/>ectropic design. The term ectropic is intended to describe software<br\/>systems that maintain or increase their structuredness, as opposed to<br\/>the more typical, entropic, case in which the structure and conceptual<br\/>integrity of a system degrade as it evolves. Besides precisely<br\/>defining the ectropic design process and building a prototype<br\/>ectrospace, this project studies the power and practicality of<br\/>ectropic software. It also investigates it in the setting of a<br\/>sophomore-level, object-oriented development class. The class will<br\/>undertake an Open-Source development effort using ectropic design and<br\/>supported by an ectrospace. The resulting software and documentation<br\/>will be distributed in Open Source form to the Internet community.","title":"Ectropic Design: Intelligent Collaboration Spaces for Open-Source Software","awardID":"9988235","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["521278","397849"],"PO":["564388"]},"54890":{"abstract":"In 1998 academic researchers combined with the National Geographic Society (NGS) to design and implement \"Survey2000: Charting Communities and Change,\" an effort that explores the potential and limits of web-based survey research. A second survey effort to be hosted by the NGS website in the fall of the year 2001 is the cornerstone of this project. The substantive focus of Survey2001 centers on the impact of information technology on changing perceptions of global and local spheres in contemporary society. In particular, the survey examines respondents' perceptions and understanding of \"global\" and \"local\" in three areas: community, culture and conservation. The survey explores the extent to which new information technology has redefined the distinction between global and local. A second aim is to consider methodological issues related to web survey research, in particular the non-random nature of a web survey sample. Toward this end, the project calls for a parallel telephone survey effort using standard random digit dialing techniques to replicate the web survey. Beyond questions of sampling and validity, Survey2001will pursue issues regarding web survey instrument development and implementation, as well as instrument and design effects in web surveys. Collaboration with the NGS assures that the results will receive broad public dissemination.","title":"ITR: Survey2001: Information Technology's Impact on Community, Culture and Conservation","awardID":"0082750","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["441455","289727"],"PO":["495796"]},"55770":{"abstract":"EIA-0086251 <br\/> Guha University of Central Florida<br\/>Guha, Ratan K.<br\/><br\/>CISE Educational Program: Introducing Fundamental Concepts and Evaluation Methods for Distributed Systems and Applications in the Computer Science Undergraduate Curriculum<br\/><br\/>This CISE Educational Innovation award supports the development of innovative curricula for teaching contemporary concepts of distributed computer systems, computer network technologies, and principles of distributed applications to undergraduate students at the University of Central Florida and three collaborating institutions. The focus of the project is on the development of modules, course materials, courses, a delivery infrastructure, faculty enhancement workshops, and web-based data collection. Module topics include: networks and the Internet, mobile and wireless computing, network management, concepts of distributed systems, network security, performance evaluation, distributed applications, and parallel and distributed simulation. This project provides a web and CD-ROM based mechanism for distribution of modules, courses, support-software and evaluation instruments. A one-week workshop for faculty, government, and industry covering these topics will be conducted in 2002 and 2003. In addition to transferring current research in distributed systems into the undergraduate curriculum at the University of Central Florida, the project also enables three partner institutions with underrepresented student populations (Grambling State University, Florida A&M University, and the University of Houston) to actively participate in the project. The collaborating institutions are involved in development and evaluation of the instructional modules and use them in their programs either as new courses or thread the modules through existing undergraduate courses.","title":"CISE Educational Innovation: Introducing Fundamental Concepts and Evaluation Methods for Distributed Systems and Applications in the Computer Science Undergraduate Curriculum","awardID":"0086251","effectiveDate":"2000-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["385408","182731","385409"],"PO":["551712"]},"54681":{"abstract":"This project will discover novel scheduling techniques for large scale applications on parallel computers, and will develop new parallel algorithms using those scheduling techniques to calculate quantum trajectories for electron scattering problems. Such research is important to help enable theoretical models as close as possible to real events, so that simulations of physical phenomenal derive accurate predictions. Since many application problems in science and engineering are irregular, large and computationally intensive, finding their best solution in terms of numerical properties and parallel performance represents an important contribution to the development of advanced computational science. <br\/><br\/>Technically, this project will develop new models for dynamic scheduling strategies used in scientific computing based on probabalistic and statistical analysis, and will evaluate their effectiveness on an analytical and experimental basis. The project specifcally addresses the following general issues: (1) to develop novel dynamic scheduling strategies that can accommodate applications with unpredictable behavior in load distribution, and evaluate their competitiveness with respect to existing technology; (2) to develop new parallel numerical algorithms using those strategies for the study of scattering from an Eckart potential barrier in one dimension and electron scattering in three dimensions from the ground state hydrogen atom and one, two, three and four electrons bound to a hydrogen-like one and two dimensional multicharged ion; (3) to analyze the performance of this parallel application via new and predictive performance metrics. In addition, visualization methods will be applied to the calculation of quantum trajectories, leading to the possible identification of visual and quantified signatures of \"quantum chaos.\" This is chaos in quantum mechanical systems defined in terms of the behavior of quantum trajectories.","title":"ITR: Collaborative Research in Novel Dynamic Scheduling Methods with Application to Computation of Quantum Trajectories","awardID":"0081303","effectiveDate":"2000-09-01","expirationDate":"2004-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["554891","388441","491915"],"PO":["551992"]},"55660":{"abstract":"The problem of attaining peak performance--which has dominated the research agenda for the past 20 years--will be secondary to concerns of availability, maintainability, and evolutionary growth (AME) in the PostPC era, where computers must cope with the flood of new data and yet be much more dependable and maintainable. This project develops fault insertion techniques to test for graceful recovery from hardware and software failures; self-scrubbing data structures that check and repair themselves to improve software reliability; and the ability to isolate subsets of live systems to test AME in the field. A large-scale prototype is being constructed, with the help of industrial partners, to demonstrate these ideas. This research is being carried out in collaboration with Matthew Merzbacher of Mills College.\"","title":"ITR: Taming the Data Flood: Systems that Evolve, are Available, and Maintainable (SEAM)","awardID":"0085899","effectiveDate":"2000-09-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["559805","436421","211900"],"PO":["325495"]},"55671":{"abstract":"Vast musical databases are currently accessible over computer networks (e.g., the Web), creating a need for sophisticated methods to search and organize these databases. Because music is a multifaceted, multi-dimensional medium, it demands specialized representations, abstractions and processing techniques for effective search that are fundamentally different from those used for other retrieval tasks. By exploiting reductionist theories of musical structure and performance (i.e., musical style), this project will develop hierarchical, stochastic music representations and concomitant storage and retrieval mechanisms that are well-suited to music's unique characteristics, and are both musically and psycho-acoustically plausible. A software system exploiting these representations and retrieval mechanisms will be developed that accepts sonic input, compares abstractions of this input to those in a database of digital recordings, returns sonic samples of the database that best match the query, and allows the user to refine the query using music\/acoustic-based interfaces of varying degrees of complexity. This research will yield a working music-search engine will application to e-commerce and will provide new scientific knowledge in terms of algorithms and mathematic models in the fields of databases, information retrieval, artificial intelligence, signal processing and perception, for music search and retrieval, which will generalize to other multimedia processing tasks.","title":"ITR: Exploiting Style as Retrieval and Classification Mechanism","awardID":"0085945","effectiveDate":"2000-09-01","expirationDate":"2005-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":[142659,142660,142661,"533266"],"PO":["563751"]},"54230":{"abstract":"EIA-0079639<br\/>Walker, William F.<br\/>University of Virginia<br\/><br\/>MRI: Development of a Next-Generation Ultrasound Research Platform<br\/><br\/>This application proposes the development of an advanced experimental system to support ultrasonic imaging research. The proposed system will be capable of continuing acquisition over a period of 1.6 seconds, the equivalent of roughly 50 image frames. The system will also incorporate a data interface to allow future connection to custom processing units, ultimately enabling real-time processing of aperture domain data. The system will be constructed around AgilentTechnologies SONOS 5500 ultrasonic imaging system to enable real-time imaging and preserve broad signal bandwitdth, high signal to noise ration, and wide dynamic range.","title":"MRI: Development of a Next-Generation Ultrasound Research Platform","awardID":"0079639","effectiveDate":"2000-09-01","expirationDate":"2004-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0504","name":"Division of MICROELECTRONIC INFOR PROCESS","abbr":"MIP"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[138376,"328588",138378],"PO":["557609"]},"55682":{"abstract":"With the explosion in connectivity of computers and in the size of data sets available for analysis, mathematically sophisticated algorithms are becoming increasingly crucial for a wide range of real-world applications. Unfortunately, it often takes many years for an algorithm to make it from theory into applications. In fact, the trend has been for different areas to develop their own algorithms independently, with the result that similar techniques reinvented many times in different contexts, and radically new approaches that require an algorithmic level of abstraction take a long time to make it into applications. <br\/>The intellectual core of this proposal is to create a coordinated effort in \"Algorithms from Theory to Practice\" that connects the basic development of fundamental algorithms and data structures to their many disparate uses. This work will address critical needs by connecting relevant algorithms to application areas, by exposing and tackling important issues that are common to multiple applications, and by developing fundamentally new approaches to solving key problems via the connections made. <br\/> This proposal aims to provide impact at a number of different levels. At the lowest level are specific research projects that target key application domains. These include algorithms for mesh generation with applications to scientific simulations and graphics, algorithms for indexing and searching needed for a number of data analysis tasks, and protocols that connect machine learning with cryptography to produce a fundamentally new way for people to securely authenticate to their computers. At a higher level, this proposal will create a center to which researchers in application areas can come to build connections and integrate algorithmic techniques and principles into their own projects. At the highest level, this proposal will create tools to improve the process of moving algorithms from theory to applications more broadly. As one example, the course \"Algorithms in the Real World\" run by PI Blelloch has already developed a set of web pages detailing how algorithms are used in various applications and what turn out to be the crucial issues involved. A new, extensible version of this database would provide support for theoreticians, practitioners, and educators. We hope the end result to be both a faster pipeline from algorithm design to application, and improved sharing of algorithm techniques across application areas. In addition, we expect the students supported by this effort to fulfill the highest-level goals of this project becoming the next generation vertically-integrated algorithm researchers.<br\/> The PIs each have a strong track-record in algorithms, both theoretical and applied. Guy Blelloch is developer of the NESL parallel programming language, as well as fast parallel algorithms for a number of core problems. Arvin Blum is known for his work in machine learning and approximation algorithms, and is developer of the Graphphan planning algorithm, used as the basis of many AI planning systems. Manuel Blum is winner of the ACM Turning Award for his work in the foundation of computational complexity theory and its applications to cryptography and program checking. John lafferty is known for his work in language modeling and information retrieval, and is co-developer (along with PI Sleator)of the Link Grammar natural-language parser. Daniel Sleator is winner of this year's ACM Kanellakis \"Theory and Practice\" award for the development of the Splay Tree data structure, and more recently been developing algorithms for natural language applications.","title":"ITR: Algorithms: From Theory to Application","awardID":"0085982","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["485891","168133",142715,"554195","548200"],"PO":["543507"]},"55693":{"abstract":"Implanted biomedical devices have the potential to revolutionize medicine. The types of procedures that are being proposed could greatly improve the health and vitality of persons in ways previously not possible. Information technology is a critical component of this endeavor, requiring both novel hardware and software design. The limited power and computational capabilities of these biological implants present challenging research issues. As progress is made on these topics, there is great promise of long-term benefits. Multidisciplinary research, drawing on the expertise of researchers in a wide array of areas is required. This proposal assembles a multi-institutional team of researchers in computer science and engineering, solid state devices, and medicine. The combined talents of this team will be required to realize the goal of this proposal - small biomedical devices composed of smart sensors that are implanted for long-term use. These devices require the ability to communicate with an external diagnostic computer system via a wireless interface.<br\/> A large-scale research program on smart sensors is on-going at Wayne State University, covering all aspects from materials characterization through integrated circuit design and simulation to hybrid device fabrication. This major research initiative requires a multidisciplinary team involving faculty, researchers, and students from the Colleges of Engineering, Science, and Medicine. All are members of the Smart Sensors and Integrated Microsystems (SSIM) research group. The research in this proposal adds a new dimension to the currently funded research of the SSIM program by providing wireless communication capabilities to the implanted microsensors. This additional capability is possible because of the close collaboration among researchers at Wayne State University and Colorado State University.<br\/> The proposed work will take an integrated hardware and software approach to developing solutions for wireless networking of human-embedded microsensors. These solutions will be bio-compatible, energy-efficient, fault-tolerant, and scalable. In addition, they would support continuous operation and provide diagnostic capabilities. The proposed work will address several fundamental questions for the wireless networking of embedded microsensors, including those arising due to the need for low-powered, low-maintenance, highly-reliable, and scalable solutions. As a demonstration of our proposed techniques, an artificial retina prosthesis and related visual cortical implant will be developed. The goal is to design wireless network protocols for energy-efficient communication between multiple retinal sensor array\/cortical implants and an external base station. The research in this proposal provides the building blocks for this wireless network. The severe limits on the computational and memory capabilities of the smart sensor implants place tight constraints on the communication protocol. For this reason, an external communication device, contained in a pair of eyeglasses, for example, will provide the additional resources necessary for protocol-compliant communication, and increased range and bandwidth. Software to display the message contents will be developed in order to validate the network protocols and the sensor communication. The software to perform image analysis and recognition will be also be developed by our research team. The developed solution will be evaluated, through both simulation and pro-totyping, for various performance and functionality criteria including bio-compatibility, energy-efficiency, reliability, and scalability<br\/> Upon completion, the proposed work will have several benefits in the area of wireless networking of low-powered microsensors, which are suitable for biomedical applications. Other biomedical applications where this technology are useful is limited only by our imagination. For example, patients with Parkinson's disease and epilepsy could benefit from the ability to implant sensors in the neural pathways of the brain to alter the undesired signals and restore proper functioning. Existing technology is very crude and not suitable for chronic implanted devices or complex signal stimulation and detection. Another example is acoustic and optical biosensor arrays for blood analysis currently under development at Wayne State University. Similar sensors are being developed to detect cancer cells by implanting a smart sensor in the body of a recovering cancer patient. One of the main contributions of this project would be a framework for developing scalable wireless networking and powering solutions for biomedical applications.<br\/> The integration of advances in wireless networking and smart sensor technology have great potential in several other applications such as the monitoring of distributed environmental sensors. It is envisioned that networked smart sensors will revolutionize our world in ways beyond our current imagination.","title":"ITR: Wireless Networking Solutions for Smart Sensor Biomedical Applications","awardID":"0086020","effectiveDate":"2000-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["151982","311939","501549","535238",142767],"PO":["292741"]},"54395":{"abstract":"EIA-0080146<br\/>Nutt, Gary<br\/>University of Colorado - Boulder<br\/><br\/>CISE Reserach Infrastructure: The Digital CommonSpace<br\/><br\/>This research program addresses symbiotic computing environments in which people use small, communicating computers (SCCs) to collect and use information and tools in their personal information space. This information space, which we call a Digital CommonSpace, is managed by a broad spectrum of computing and network equipment: SCCs, laptops, personal computers and workstations, and servers all interconnected by a spectrum of networks. This research addresses devices, systems, and networks; dynamic interconnection facilities; and general applications. There is an emerging computing model for symbiotic computing environments in which traditional computer science domains have become blurred: The OS must be tailored to meet the needs of application support tools and the applications themselves. The application support software must exploit the OS design and while providing custom support to the applications. Applications must use new software paradigms to take advantage of the application support tools and OS. The individuals for this research program have conducted research in each of these traditional domains, and they are now focusing on the Digital CommonSpace as the mechanism to advance the state-of-the-art symbiotic computing.","title":"CISE Research Infrastructure: The Digital Commonspace","awardID":"0080146","effectiveDate":"2000-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["143021","236644","263691","494943","543625"],"PO":["550859"]},"54164":{"abstract":"EIA-0079466<br\/>Richards, Bradley<br\/>Vassar College<br\/><br\/>MRI: Acquisition of an Eight-Processor Sun 3500 Parallel Computer<br\/><br\/>This proposal is to improve the scientific and pedagogical computational capabilities at Vassar College. Also, it is proposed to purchase an eight-processor Sun Enterprise 3500 shared-memory parallel computer with 4 gigabytes of RAM and 72 gigabytes of disk space. This machine will assist research groups focusing on the following problems: (i) parallel computing with the goal of improving the performance of parallel Java programs, (ii) hydrodynamics simulations of stellar interactions, and (iii) simulations to investigate reactions between BaCeO3 and water vapor. In addition to supporting faculty research, the new machine will also be invaluable for fostering and expanding student research and training.","title":"MRI: Acquisition of an Eight-Processor Sun 3500 Parallel Computer","awardID":"0079466","effectiveDate":"2000-09-01","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["547494","351137","411375"],"PO":["557609"]},"55022":{"abstract":"This project is concerned with the problem of recovery, representation, and recognition of shapes in images. The PI <br\/>proposes to use the symmetry map, the shock graph of an edge map, as an intermediate-level representation for 2D shape. Deformations of shape are then expressed as a sequence of symmetry transforms which correspond to the inherent instabilities of skeletons (shock transitions). The optimal deformation path between two shapes is found using an edit distance approach to finding the least action sequence of transforms, or edits, on the shock graph. The cost of this path is used as a dissimilarity measure for indexing into image databases. This approach also allows for shape modeling and design, the construction of morphing sequences, and deformable templates. In 3D, The PI proposes to reduce the three-dimensional skeleton to a shock scaffold consisting of 1D space curves on which the 3D skeleton can be analytically constructed, leading to significant savings in recovery and storage of complex shapes, e.g., Michelangelo's Pieta, human lungs, etc. The research is generic and can potentially significantly impact a number of industrial and medical applications, including shape-based retrieval and construction of computational atlases.","title":"Symmetry Map and Symmetry Transforms for Shape Recovery and Object Recognition","awardID":"0083231","effectiveDate":"2000-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["550631"],"PO":["317663"]},"48764":{"abstract":"PI: Henzinger, Thomas<br\/>Proposal Number: 9988172<br\/>Institution: University of California-Berkeley<br\/><br\/>Abstract<br\/><br\/>Model checking is a method for determining automatically if a computer system<br\/>meets its requirements. Prompted by its successes in the hardware industry,<br\/>model-checking techniques have been developed for analyzing requirements of<br\/>distributed and embedded systems that go beyond classical safety and liveness<br\/>properties. These richer requirements include game properties, timing<br\/>properties, and probabilistic properties. All three classes of properties<br\/>have in common that the underlying system model is no longer the Kripke<br\/>structure, but a structure equipped with multiple players (the game graph),<br\/>with clocks (the timed automaton), or with probabilities (the Markov decision<br\/>process). While these three structures are reasonably well-understood, and<br\/>corresponding model-checking tools have been implemented, any combination of<br\/>the three features --games, time, and probabilities-- gives rise to genuinely<br\/>new phenomena.<br\/><br\/>First, consider the combination of games and probabilities. The resulting<br\/>model of a system is the concurrent game, where the players choose, in each<br\/>configuration, their moves simultaneously, independently, and possibly at<br\/>random. We develop algorithms for solving concurrent games, in order to<br\/>improve the compositional (divide-and-conquer) approach to model checking.<br\/>For example, game-theoretic methods facilitate the early detection of error<br\/>scenarios, and the automatic synthesis of environment assumptions for system<br\/>components. Second, consider the combination of games and time. The<br\/>resulting model of a system is the timed game, where the players choose, in<br\/>each configuration, their moves together with delays that indicate when the<br\/>moves are played. We develop algorithms for solving timed games in order to<br\/>provide a method for synthesizing software controllers of physical plants.<br\/>Third, consider the combination of time and probabilities. The resulting<br\/>model of a system is the timed probabilistic system, where in each state,<br\/>every enabled action has associated with it both a probability distribution<br\/>over successor states and an expected delay before the state transition<br\/>occurs. Timed probabilistic systems permit the analysis of performance and<br\/>reliability properties. We develop a temporal-logic framework for<br\/>classifying performance properties and practical (iterative) algorithms for<br\/>their analysis. Finally, the combination of games, time, and probabilities<br\/>results in timed concurrent games. We study define and these systems in<br\/>order to facilitate the compositional analysis of real-time systems and the<br\/>automatic synthesis of randomized controllers.<br\/><br\/>The algorithms developed in this project are implemented in the<br\/>model-checking environment Mocha and applied to case studies from<br\/>component-based design (compositional model checking), embedded systems<br\/>(controller synthesis), and network protocols (performance evaluation).","title":"Games, Time, and Probabilities in Model Checking","awardID":"9988172","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["226709"],"PO":["279077"]},"58202":{"abstract":"The proliferation of Application Service Providers (ASPs) and software developed through the Open Source Software (OSS) approach offer enormous potential to non-profit, community-serving organizations. OSS could allow these organizations to share their limited software development resources while ASPs could allow for more reliable, lower cost and sustainable information technology infrastructures to be developed and shared by them. Together, they offer important synergies in increasing the effectiveness of community-serving organizations. However, the barriers to sustainable infrastructure are particularly acute in smaller non-profit organizations due to their limited financial and technical resources. Further, generating the requirements for shared systems is difficult. The PI and graduate students will engage in preliminary field studies with agencies delivering social services to the elderly in Detroit. These agencies are considering the use of ASPs and OSS applications and need to develop requirements. Aside from the direct and practical impacts this research may have on those agencies, new, generalizable approaches will be developed for requirements generation for information infrastructures for community-serving organizations.","title":"SGER: Exploration of new Approaches to Sustainable Infrastructure for Information Sharing","awardID":"0095233","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["433915"],"PO":["565227"]},"69224":{"abstract":"","title":"Time-Space Multicast in Wireless Ad Hoc Networks","awardID":"0196043","effectiveDate":"2000-09-16","expirationDate":"2003-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["518079"],"PO":["234222"]},"47697":{"abstract":"Portable computer and communication systems are all around today and<br\/>they will only become more prevalent in the days to come. The design of<br\/>such mobile electronic systems involves a number of significant engineering<br\/>challenges. Because they operate from batteries, they must both consume<br\/>very little power and operate on a low power-supply voltage. Moreover,<br\/>because they are always on the move, such systems must be able to<br\/>dynamically adapt their performance to an ever-changing environment. This<br\/>research involves the development of a unified framework for systematically<br\/>designing and implementing efficient adaptive signal-processing systems<br\/>that consume very little power and can operate on a low power-supply<br\/>voltage with applications in the areas of mobile communication systems and<br\/>enhanced human-computer interfaces.<br\/> The class of dynamic translinear circuits implements the feed-forward<br\/>signal processing functions needed for continuous-time linear, polynomial,<br\/>and rational-function adaptive filters with very few devices. Such<br\/>circuits are capable of operating with low power consumption and on a low<br\/>power-supply voltage. This research involves the design an implementation<br\/>of continuous-time linear and nonlinear adaptive filtering algorithms with<br\/>dynamic translinear circuits with applications in the areas of mobile<br\/>communication systems and enhanced human-computer interfaces. The primary<br\/>focus of this research is on the efficient hardware implementation of such<br\/>adaptive filters, assessing how device nonidealities and noise impact<br\/>system performance and developing robust architectures and adaptive<br\/>algorithms.","title":"CAREER: Translinear Adaptive Filtering","awardID":"9984625","effectiveDate":"2000-09-01","expirationDate":"2004-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["142436"],"PO":["564898"]},"69477":{"abstract":"","title":"CAREER: Multithreaded Algorithms, Models, and Runtime System Tools for Multimedia Applications","awardID":"0196365","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["532978"],"PO":["309350"]},"49644":{"abstract":"EIA-0000484<br\/>Satyanarayanan, Mahadev<br\/>Carnegie Mellon University<br\/><br\/>Post-doctoral Training in Mobile Information Access<br\/><br\/>CISE Postdoctoral Associates in Experimental Computer Science: Postdoctoral<br\/>Training in Mobile Information Access<br\/><br\/>Postdoctoral training in the broad area of mobile information access will<br\/>be offered that has four research thrusts:<br\/><br\/>1) Systematic and thorough evaluation of the performance characteristics of<br\/>the Odyssey mobile computing platform and the Coda File System, including<br\/>identification of appropriate performance metrics, design of synthetic<br\/>workloads and benchmarks, instrumentation to collect usage data, and<br\/>analysis of results.<br\/><br\/>2) Exploring the scalability of Odyssey and Coda involving the design of<br\/>carefully controlled experiments that stress the limits of these systems.<br\/><br\/>3) Designing and implementing mechanisms in Odyssey and Coda that<br\/>opportunistically exploit compute servers and intermediate caches in the<br\/>infrastructure close to a mobile computer.<br\/><br\/>4) Developing a methodology and a set of techniques and tools for<br\/>generating system configurations that are well-fitted to the unique<br\/>characteristics of mobile computing hardware.<br\/><br\/>In addition, opportunities will be offered to participate in the mentoring<br\/>of graduate and undergraduate students and guest lecture in courses.","title":"Post-Doctoral Training in Mobile Information Access","awardID":"0000484","effectiveDate":"2000-09-15","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["475390"],"PO":["564318"]},"48797":{"abstract":"Clusters of symmetric multiprocessors (SMPs) are emerging as one of the most cost- effective ways for high performance computing. However, delivering their full potential heavily relies on efficient cluster-wide resource management systems. This project focuses on run-time scheduling techniques for irregular applications on SMP clusters. Since an SNIP cluster deploys a hierarchical organization, it is the depth of the memory hierarchy with its different access primitives and costs at each level that makes dynamic scheduling on the cluster challenge.<br\/><br\/>The first objective of this project is to develop scheduling proxy architecture to take advantage of the hierarchical organization of the clusters. The architecture designates one of the processors in each SMP, either statically or dynamically, for scheduling among the nodes. The scheduling proxy balances the workload in proportional to the nodal<br\/>capacities and enhances the communication locality. The scheduling proxy architecture facilitates the use of distributed scheduling algorithms between the nodes. The second objective of this project is to develop parametric algorithms, based on existing ones for massively parallel computers, to reflect the possible heterogeneity of the nodes and the communication links. Major undertaking is a rigid analysis of the adaptivity of the parametric algorithms. The scheduling proxy architecture and adaptive algorithms ease the burden of parallel programming and ensure the efficiency of cluster computing.","title":"Scheduling Proxy and Adaptive Algorithms for Irregular Applications on SMP Clusters","awardID":"9988266","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["451038"],"PO":["551992"]},"49655":{"abstract":"ABSTRACT<br\/>PROPOSAL NUMBER: 0000518<br\/>PI: Ahmed Louri, University of Arizona<br\/><br\/>Optical interconnection technology has the potential to provide efficient and adequate solutions to the fundamental communication problems facing high-performance scalable parallel systems. For several years, progress in inserting optical interconnection technology into computer systems was hindered by the relatively high cost of optoelectronic components and devices as compared to electronic devices. However, more recently, there have been significant developments in optical and optoelectronic devices, and packaging technologies, which make optical interconnection technology a viable and cost-effective option for building high bandwidth, low latency, and scalable interconnection networks.<br\/><br\/>This research investigates into the application of the recent advances in optical interconnection technology to the communication problems facing scalable parallel computing systems. The ultimate goal is the development and design of high bandwidth, low latency, and high connectivity optical interconnection networks that will not only enable parallel computing systems to be size scalable but also generation scalable. These networks will allow the system to increase in size as well as the ability to use successive, faster generations of processors in a cost-effective manner, and with minimal redesign.<br\/><br\/>The approach consists of combining the unique advantages of optical systems with architectural innovations into an integrated solution. On the architectural side, the proposed research develops crossbar-connected networks that can scale to a large number of processors yet still have close to constant network diameter, very low node degree, high bisection bandwidth, and a reasonable cost. On the technology side, implementation methods that will utilize the large bandwidth of wavelength division multiplexing, the inherent benefits of low-power, high-speed, and compact size of free-space optics, and the flexibility of optical fiber and waveguides will be investigated in order to greatly reduce network and remote memory access latencies. Each optical interconnection technology (free-space, waveguide, fiber) will be used where it is most appropriate.","title":"Optical Crossbar-based Interconnection Networks for Highly Scalable Parllel Computing Systems","awardID":"0000518","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["559883"],"PO":["180163"]},"58136":{"abstract":"This is a twenty-four month standard award to support an extended, computer-mediated workshop on technical, cognitive, and social processes and infrastructures for distributed collective practices (DCP). DCP is conceptualized along the dimensions of social organization, cognitive processes, and technical infrastructures. A fourth crosscutting area of considerable emerging importance is the development of very large distributed, shareable information bases, community memory projects, and data warehouses, that create computer-mediated collective memory practices. This workshop brings together computer scientists, cognitive scientists, library and information scientists, artificial intelligence researchers, and social scientists, with the aim of strengthening and focusing the emergent multidisciplinary, international research community in this area. The workshop will be structured as a two-year web-based discussion, punctuated with two face-to-face meetings. The first year will establish a seed community, elaborate an international research program, and involve international scientific communities and the general public. The second year will assess progress, synthesize the results of discussions and joint work, develop and refocus the program's objectives, and produce documentation. This project involves four participating groups from France and the US, including the CNRS Laboratoire d'Informatique pour la Mecanique et les Sciences de l'Ingenieur (LIMSI); the Ecole Nationale Superieure des Telecommunications (ENST); the University of Illinois at Urbana-Champaign, and the University of California at San Diego (UCSD). Collaborative funding is being provided by the UNESCO Management Of Social Transformations Program and the Societe Francaise des Sciences de l'Information et de la Communication.","title":"Workshop: Distributed Collective Practices","awardID":"0094989","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["503214"],"PO":["495796"]},"52680":{"abstract":"The Java Virtual Machine (JVM) is the corner stone of Java technology, and its efficiency in executing the portable Java bytecodes is crucial for the success of this technology. Interpretation, Just-In-Time compilation, and hardware realization are well known solutions for implementing the JVM, and previous research has proposed optimizations for each of these techniques. However, each technique has its pros and cons and may not be uniformly attractive for all hardware platforms. Instead, an understanding of the architectural implications of JVM implementations with real applications can be crucial to the development of enabling technologies for efficient Java runtime system development on a wide range of platforms (from resource-rich servers to resource-constrained embedded systems). Towards this goal, this proposal examines architectural issues, from both the hardware and JVM implementation perspectives. The key to an efficient Java virtual machine implementation is the synergy between well-designed software, an optimizing compiler, supportive architecture, and efficient runtime libraries. This research will essentially provide an insight into this hardware -software interaction and contribute a set of tools, software and hardware methodologies, and architectural features that will be vital for supporting efficient JVM implementations over a spectrum of devices. The results from this research will also be useful for providing efficient implementations in other object-based and dynamically compiled languages and environments.","title":"Designing Efficient Java Runtime Systems","awardID":"0073419","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["549542"],"PO":["241298"]},"52691":{"abstract":"Coherent pulse-Doppler radar systems typically transmit pulse-trains made up of identical pulses. While these pulses may contain complex modulation that enhances their ability to separate closely spaced scatterers in delay (range) or Doppler (radial velocity), the fact remains that the pulses making up the pulse-train are usually identical. The aim of this research is to investigate the advantages of pulse-trains made up of pulses that are distinctly different from pulse-to-pulse. This research involves the design of waveform sets and associated signal processing that yield enhanced ability to separate closely spaced scatterers and increase the accuracy of pulse-echo measurements. The problems of diversity waveform measurement (using a fixed set of different pulse-waveforms) as well as adaptive selection of pulse waveforms based on past measurements of the scattering scenario will be considered. The significance of this work lies in the fact that it allows for higher resolution imaging or discrimination of radar scatterers than is possible using a single waveform. Applications that could benefit from this enhanced resolution include synthetic aperture radar imaging, earth based radar astronomy, Doppler weather radar, ionospheric radio sounding, active sonar imaging systems, and monostatic and multistatic radar and sonar tracking systems.","title":"Diversity and Adaptive Waveform Techniques for Pulse-Doppler Radar and SAR","awardID":"0073475","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":[134351],"PO":["564898"]},"54792":{"abstract":"The embedded processor of the future will have multiple heterogeneous processors on a single chip integrated with a large shared memory. Many of the applications for this processor will have strict real-time requirements. This project investigates novel architectural and system software features that can allow such a processor to support complex real-time applications. Architectural features that limit shared memory contention and reduce synchronization overhead will be studied in order to reduce latencies and make thread execution times more predictable. The project will also explore the use of specialized I\/O processors having direct and equal access to shared memory in order to minimize interference of I\/O operations on real-time thread execution. Novel techniques for scheduling real-time threads on a heterogeneous multiprocessor-on-a-chip will also be studied.","title":"ITR: Real-Time Systems-on-a-Chip","awardID":"0082164","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["562577",140002],"PO":["562984"]},"55661":{"abstract":"This award provides support for a collaborative project involving two computer scientists and a plant geneticist who will develop new methods, efficient algorithms, and software tools for several important problems in the field of bioinformatics. This supported work includes research into computational paradigms such as quartet methods, interactive systems, and approximation algorithms as applied to the evolutionary analysis of gene sequences, gene duplication, and horizontal transfer events in the genomes of chloroplasts, a DNA-containing organelle found in all plants. Additional studies will examine the information content of genomes by improving and testing a recently developed sequence entropy estimator and a distance metric for genomic sequences. Work in this area will include the application of the improved methods to sequence data from the genomes of mitochondria, viruses, chloroplasts and bacteria. Other efforts will address the important problem of simultaneous multiple sequence alignment and evolutionary tree reconstruction. The multiple sequence alignment approaches to be developed are based on the use of conserved blocks that have few or no gaps, and multiple alignments within a constant band. Work in a fourth area will develop efficient algorithms for computing short and long interspersed nuclear elements (SINES and LINES) in genomic sequences of lengths up to billions of nucleotides. Because of the large amounts of data that must be analyzed, this will require the development or adaptation of appropriate external memory algorithms. <br\/><br\/>Biological, biomedical and pharmaceutical research is undergoing a major revolution as new analytical technologies produce unprecedented amounts of genetic data. The exploration of this information is critically dependent upon the development of advanced computational and software techniques for data analysis, storage and retrieval. From this dependency, a new interdisciplinary research field, bioinformatics (or computational molecular biology) has emerged in recent years. The work supported through this award is expected to make both fundamental and applied contributions to the field. The fundamental research will explore and explicate new ideas and methods for solving algorithmic problems in bioinformatics and the applied research will involve the development and evaluation of software tools in the practice of plant genomics. Although the efforts are aimed at improving the understanding of the evolution of chloroplast genomes, the approaches should be readily extensible to analysis of all other genomes.","title":"ITR: Computational Techniques for Applied Bioinformatics","awardID":"0085910","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["271545","538402"],"PO":["551992"]},"55672":{"abstract":"EIA-0085946<br\/>Soloway, Elliot<br\/>University of Michigan<br\/><br\/>Title: Information Technology Research: Learning-Centered Design Methodolodgy: Meeting the Nation's Need for Computational Tools for K-12 Science Education (Engineering Scaffolded Work Environments)<br\/><br\/>Learning while working in the knowledge-work professions can be supported<br\/>by appropriately-designed \"scaffolded work environments (SWEets).\" Several<br\/>researchers have assembled a unique team of 10 senior researchers from four<br\/>major universities to develop a principled engineering process for<br\/>constructing SWEets. The work will be based in the knowledge work context<br\/>of \"science inquiry\" using an engineering process to construct SWEets for<br\/>fourth through eleventh graders learning science via scientific<br\/>investigations in Detroit and Chicago classrooms. The results of the<br\/>proposed research will be explicit guidelines on how to build effective,<br\/>computationally-based work environments that scaffold and support<br\/>individuals engaged in knowledge work. The aim of this effort is to<br\/>transform what presently appears to be the art into a principled, software<br\/>engineering approach.","title":"ITR: Learning-Centered Design Methodology: Meeting the Nation's Need for Computational Tools for K-12 Science Education (Engineering Scaffolded Work Environments)","awardID":"0085946","effectiveDate":"2000-09-15","expirationDate":"2005-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1359","name":"RES EXP FOR TEACHERS(RET)-SITE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"1666","name":"RESEARCH ON LEARNING & EDUCATI"}}],"PIcoPI":["561136","549235","467756","521278","495168"],"PO":["564318"]},"52163":{"abstract":"EIA-0071841<br\/>Amarasighe, Saman P.<br\/>MIT<br\/><br\/>CISE Experimental Partnerships: Partnerships: MIT Raw Machine<br\/><br\/>Rapidly evolving technology places a billion transistors on a chip within reach of the computer architect. Several approaches to utilizing the large amount of silicon resources have been put forth, with the single important goal of obtaining the most performance out of approximately one square inch of silicon. These approaches exploit more parallelism in one or more instruction streams. Examples include more aggressive superscalars, multiscalars, processor-coupled designs, simultaneous multi-threading processors, multiprocessors on a chip and VLIWs. The goal of this project is to discover, implement and evaluate simple architectural mechanisms that scale with increasing VLSI clock speed, and software techniques that orchestrate high-level computations on the low-level architectural resources for maximum efficiency.","title":"CISE Experimental Partnerships: MIT Raw Machine","awardID":"0071841","effectiveDate":"2000-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4725","name":"EXPERIMENTAL SYSTEMS\/CADRE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["467768","382922","497068"],"PO":["297837"]},"55683":{"abstract":"An interdisciplinary team, bridging academia and industry, proposes a united effort to study the dynamics of the global Internet, moving beyond the traditional single-timescale, single-network, single-protocol paradigm to a description that compactly incorporates a wide range of time-scales, a broad spectrum of spatial network topology structures, andmultiple protocols interacting with one another and across the different networking layers. Achieving such a global, multi-scale, and multi-layer understanding of complex large-scale networks is imperative for the successful design and development of the next-generation Internet protocols and engineering tools, where issues related to robustness,scalability, and efficiency take center stage.<br\/> In this united effort, there are three main ingredients. First, the researchers plan to fully exploit a new breed of datasets of network-wide measurements - unprecedented in volume and quality - that are the result of recent exciting networking research projects, such as the National Internet Measurement Infrastructure project (NIMI). Another source of such data will be various Internet Service Providers (ISPs), such as AT&T, employer of one of the PIs, which will also provide supplementary funding if this proposal is accepted. Second, the researchers will rely on a new breed of network simulation tools, such as SSFNET, largely developed by another of our PIs, and capable of simulating internetworks unprecedented in scale and detail. All these new measurements, whether real or virtual, will constitute huge datasets with very high and networking-specific semantic content, creating completely novel challenges for data analysis. This is where the third ingredient comes in: multiscale and multiresolution\/wavelet techniques, developed by several of the PIs, will take center stage when it comes to analyzing, visualizing, and uncovering the rich information that is contained in these network measurements. Although the flexibility and the speed of wavelet decompositions have been put to good use in the past in many applications, including the empirical observation of certain types of time-scaling behaviors in measured network traffic, the technology as it is known and used today cannot yet cope with the fascinating new challenges posed by the available and anticipated Internet data. A central objective of this project is to develop Internet-appropriate multiresolution techniques that match the multiscale nature of the underlying Internet structure and can be validated step-by-step against measurements. The researchers expect that tools and theories that have been developed in the context of computer graphics, irregular sampling, and scattered data approximation will be utilized to this end.<br\/> The ultimate goal of the proposed research effort is to identify interesting patterns that can be extracted from the measured data via fast algorithms, that are linked to physical concepts and are meaningful in the networking context, that characterize different states or behaviors of the network, and that can aid the development of novel network measurement analysis and visualization techniques in support of a new generation of monitoring and engineering tools for future Internet architectures. Given that so much of this area is still uncharted, it may be not realistic to hope to attain this goal in a few years' time. Nevertheless, we are convinced that only an interdisciplinary effort like ours can hope to achieve anything in this direction; we expect that our collaboration will lead to deeper insights and understanding; a first identification of models, patterns, the influences of various external factors and protocols; and an initial glimpse at the underlying \"physics of the Internet\" - a solid understanding of how basic networking mechanisms and user behaviors contribute to the fascinating dynamic observed in today's Internet.","title":"ITR: A Multiresolution Analysis for the Global Internet","awardID":"0085984","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["403485","551079","550948",142722,"408589"],"PO":["7594"]},"53263":{"abstract":"0075407<br\/>Hammer<br\/><br\/><br\/>This grant provides funding for developing fundamental theory and methodologies to support integrated operation of decentralized networks of firms producing goods under short lead times and variable demand. Research under this grant is directed towards specifying a complete decision support and information architecture that enables automated negotiation among firms and improves overall performance of these Flexible Production Networks (FPNs). In support of this objective, the investigators have identified four high-impact research areas:<br\/>1) Simulation, modeling, and analysis of FPN operation under imperfect information; 2) Capacity and cost models for firms that exist in multiple FPNs; 3) Generation of information 'wrappers' that tie firms' existing information systems to an information hub infrastructure; 4) Information models for representing complex FPN operations. Each of these four areas is critical to achieving a feasible computational infrastructure that represents the diverse production technologies within the FPN, while addressing issues of scalability, rapid deployment, and decentralized operation.<br\/><br\/>Successful conclusion of this research will generate advances in operational support for firms existing within FPNs, as well as broader advances in theory concerning the deployment of information and decision support systems in a multi-firm environment. Current industrial initiatives in extended-enterprise resource planning systems are a positive step towards deployment and simplification of electronic transactions; however, they lack a framework for analysis and decision support for production involving a network of firms. Research under this grant provides such a framework, with a focus on low overhead, dynamic deployment of a computational, and flexible and scalable decision support for decentralized, multi-firm operations. Research in these areas will also broaden existing theory in decision support and computer science, where current models tend towards exact analysis and representation of limited or highly specific systems. In a broad sense, this work will re-focus current capabilities towards supporting more complex, flexible systems.","title":"Scalable Enterprise Sytems: Theory and Methodologies to Support the Operation of Flexible Production Networks","awardID":"0075407","effectiveDate":"2000-09-01","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1631","name":"CIVIL INFRASTRUCTURE SYSTEMS"}}],"PIcoPI":["530418","337768","418721","361065",135703],"PO":["410447"]},"55694":{"abstract":"Power consumption, thermal issues, and battery lifetimes are primary design issues in many computer systems. To address the needs for effective and efficient power management in current computer systems, this project studies unified methodologies for creating power-aware hardware and software. A key underlying philosophy in this work is the notion of \"real-power\" systems. Drawing an analogy to real-time computer systems, real-power systems seek to maintain predictable and manageable levels of power consumption with the best possible performance, rather than simply reducing power consumption regardless of performance. A multi-level approach spanning operating systems, compilers, and hardware brings leverage to a problem that is difficult to address at the hardware level alone.","title":"ITR: Designing \"Real-Power\" Systems: Static and Dynamic Techniques for Managing Power\/Performance Tradeoffs","awardID":"0086031","effectiveDate":"2000-09-15","expirationDate":"2006-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["213414","489472","495323"],"PO":["562984"]},"47862":{"abstract":"The proposed research project is focused on Internet telephony and novel ad-hoc data distribution<br\/>techniques.<br\/> In the area of Internet telephony research, the research proposes to focus on the following topics:<br\/><br\/> Programming Internet telephony services: The research proposes new mechanisms for programming In-ternet telephony services, usable by both end users and service providers. The mechanisms<br\/>are designed to be robust, offer predictable performance and allow a large set of users to<br\/>safely share server resources. The programming facilities are to be enhanced with a graphical<br\/>service creation environment for Internet telephony.<br\/> Feature interaction: The research plans to investigate the problem of feature interaction in Internet telephony, as the feature interaction problem differs significantly from that encountered in traditional<br\/>telephony.<br\/> Collaborative call filtering: The research plans to design, implement and analyze a system that allows Internet users to collaborate in filtering undesirable calls, based on group preferences. This<br\/>avoids the current reliance on unlisted phone numbers and answering machines for call filtering.<br\/> Scaling Resource Reservation: Particularly for the large number of small flows anticipated for<br\/>Internet telephony, associated with their stringent delay and loss requirements, scaling resource<br\/>reservations is of vital importance. The research proposes to investigate the performance of two<br\/>new scaling mechanisms, sink-tree reservations as part of the Border Gateway Reservation<br\/>Protocol (BGRP) and partial reservations.<br\/> Performance prediction: The research plans to investigate simple statistical characterizations that predict<br\/>the performance of a variety of standard forward error correction and playout delay algorithms<br\/>for packet voice.<br\/> 911 services: Internet telephony offers the opportunity to significantly enhance emergency call<br\/>services compared to existing mechanisms. The research plans to investigate how to reliably identify<br\/>users and grant temporary access to personal data to medical personnel, without having to<br\/>store medical data in centralized locations.<br\/> Mobility: The research proposes to investigate application-layer mobility mechanisms to complement traditional IP-layer mobility, potentially affording greater security and faster hand-off, with no<br\/>network infrastructure modifications required.<br\/> In addition, the research proposes a new data and media distribution system, e*meme, that allows data to<br\/>propagate in ad-hoc networks where network nodes are only sporadically connected to the wide-area<br\/>network, as is the case in areas where wireless connectivity is spotty. The research plans to investigate<br\/>efficient, popularity-based cache replication algorithms, taking into account the particular considerations<br\/>of power- and storage-limited mobile computers.","title":"CAREER: Internet Telephony Services and Mobile Multimedia Services","awardID":"9985325","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["518545"],"PO":["565090"]},"69400":{"abstract":"","title":"PostDoc: Parallel Search Algorithms for Automating the Animation of Human Motion","awardID":"0196221","effectiveDate":"2000-09-01","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["438709"],"PO":["301532"]},"54154":{"abstract":"EIA-0079443<br\/>Tiwari, Sandip<br\/>Cornell University-Endowed<br\/><br\/>MRI: Equipment for Remote Usage, Access and Learning at NNUN<br\/><br\/>This CISE\/MRI proposal will research The National Nanofabrication Users Network (NNUN) which proposes the acquisition of equipment and software to enhance the ability of the network to communicate between sites with remote users, and to provide remote training and fabrication-specific information, while providing remote computer aided design (CAD) capabilities. Specifically NNUN proposes acquisition of software and hardware for: (1) video conferencing between sites and external user institutions, (2) production of multimedia training and (3) allowing users to develop the bulk CAD pattern files remotely before arriving on-site.","title":"MRI: Equipment for Remote Usage, Access, and Learning at NNUN","awardID":"0079443","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["492139"],"PO":["289456"]},"55023":{"abstract":"This project seeks to develop a novel class of computer interfaces centered on a vision-based interaction paradigm, and human augmentation using a range of panoramic sensors and intelligent controllers to provide assistive technology to disabled users. The goal of such interfaces is to enable people with physical disabilities such as impaired limbs, paralysis, or tremors to overcome difficulties associated with accessing computers and products with embedded computers such as wheelchairs, household and office electronic equipment, and robotic aids with traditional input devices. The goal is to create the framework, architecture, scientific algorithms, and augmentative hardware and software to facilitate (a) interaction; (b) control and tasking; and (c) programming of computers and computer-controlled smart devices. There are two main sets of research problems that need to be solved: (a) the development of novel, flexible, portable, adaptable interfaces that allow users with physical disabilities to interact with computers and computer controlled devices by touching and feeling; and (b) human augmentation via a combination of inexpensive sensors and controllers, along with a set of algorithms and software for computer mediated control. This research will result in the next generation of interfaces for users to interact with computers and robot assistants, and more generally, devices with embedded controllers. Although the immediate goal is to develop the basic framework, methods, and algorithms using the smart wheelchair as a test product, the basic ideas will be applicable to a wider range of products.","title":"Customized Interfaces for Assistive Technology","awardID":"0083240","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6846","name":"UNIVERSAL ACCESS"}}],"PIcoPI":["553286","554983","456808"],"PO":["565227"]},"48621":{"abstract":"Avi Wigderson<br\/>9987845<br\/>This project will explore the mathematical depth of the abstract notion of computation, as well as explore its connections to other sciences. The cross-fertilization between theoretical computer science and the other sciences and the education of scientists prepared for the science of the future will be major goals of a new program of the School of mathematics at the Institute for Advanced Study. The grant mainly supports postdoctoral visitors.<br\/>Postdoctoral education at the Institute for Advanced Study is unique in that the Institute's small size, coupled with the extraordinary dedication of the permanent Faculty to their roles as mentors of young scientists, creates an unusually productive atmosphere for interaction. The research environment at the Institute is intellectually challenging because it is both deep and sustained. The intense and extended process that occurs at the Institute cannot happen in the course of a short-term exposure of computer scientists to mathematicians and to other scientists in other situations. What happens at the Institute is extended immersion, and we feel that there is no institution where this challenging and unusual educational process can occur as well as at the Institute.","title":"Basic Research in Theoretical Computer Science and Discrete Mathematics","awardID":"9987845","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["384098"],"PO":["187585"]},"48765":{"abstract":"Algorithms and Experimentation in Computational Geometry<br\/><br\/>The project mixes central theoretical investigations in <br\/>geometric computing together with experimentation with geometric codes.<br\/>A major part of the effort will be devoted<br\/>to problems of multi-scale representation and simplification<br\/>of shapes in 3D, with applications to computer graphics<br\/>and virtual reality, sampling and optimization, algorithm animation and <br\/>visualization. On the theoretical side, it is anticipated that the work<br\/>will draw mostly from complexity theory, discrepancy theory, and <br\/>algorithm design, while the experimental aspect will emphasize<br\/>software building using available geometric codes and<br\/>animation tools","title":"Algorithms and Experimentation in Computational Geometry","awardID":"9988173","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["450650","213809"],"PO":["321058"]},"48886":{"abstract":"This is accomplished through an interlocking collection of textual and graphical discourse engines, a plan recognition system, and an interaction manager that harnesses the power of these tools. Users begin by asking questions about the data stored in their dataset. The system answers using a combination of text and graphics. Text responses are built by a discourse engine, while graphical images are constructed using a perceptual visualization assistant. The collection of all possible responses is evaluated to select the most effective answer, be it text, graphics, or a combination of the two. A plan recognition system is used to analyze the users' queries and their reactions to the responses they receive. This allows the system to anticipate future queries, cache relevant statistics, and guide the discourse and visualization systems during the evaluation and selection of appropriate answers to each user query. Results from this project will include: (1) plan recognition and interaction plan construction performed by the system to identify and model current and future analyses conducted by the users; (2) presentations that are sensitive to both the current and anticipated future state of users' investigations; (3) assisted navigation techniques; (4) methods for evaluating the effectiveness of the use of text and\/or graphics; and (5) perceptual visualization techniques. Results will be disseminated through journal and conference publications, online datasets with results and analysis, and online software demos of relevant research components. Although this project will study applications from the oceanography and public school domains, these results are relevant in any situation where interactive exploration of large, complex datasets is required.<br\/>http:\/\/www.csc.ncsu.edu\/faculty\/healey\/NSF-IDM-00","title":"Interactive Exploration of Complex Datasets Via the Effective Generation of Text and Graphics","awardID":"9988507","effectiveDate":"2000-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6857","name":"DIGITAL LIBRARIES AND ARCHIVES"}}],"PIcoPI":["289699","550629","530056"],"PO":["563751"]},"47445":{"abstract":"EIA-9983481<br\/>Prudhomme, Thomas I.<br\/>University of Illinois Urbana-Champaign<br\/><br\/>Digital Government: Defining a Motion Imagery R&D Program<br\/><br\/>This is an award to support a workshop to identify a research agenda in motion imagery as related to the infrastructure requirements of government (military and civilian) agencies. National leaders in the use of motion imagery will be identified, white papers will be solicited, and the workshop will bring users and researchers together to develop recommendations for related R&D. A final report will be written and published in hard copy and on the Web. This workshop will be jointly supported by NSF and by the National Image and Mapping Agency","title":"Digital Government: Defining a Motion Imagery Research and Development Program","awardID":"9983481","effectiveDate":"2000-09-15","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["249524"],"PO":["371077"]},"45157":{"abstract":"Chan<br\/>9973341<br\/><br\/> The investigator and his colleaques study modeling and computational questions that arise in applying variational and partial differential equation methods to problems of image processing, and they develop effective new algorithms. These problems are computationally intensive and accurate and efficient methods are needed. They consider dual methods for image restoration by total variation, blind deconvolution of multi-channel images, ENO-wavelet compression of images with sharp edges, reduced Mumford-Shah models and multi-channel extensions for image restoration and segmentation, and new active contour models without edge-stopping. Topics of study include image restoration, compression, multispectral images, segmentation, and active contours. Applications in medical and chemical imaging, astronomical imaging, and multispectral automatic target recognition are pursued.<br\/><br\/> Image processing arises across engineering disciplines and the physical and medical sciences. Applications in the medical sciences and biotechnology field range from computer tomography to processing of microscopic images of molecular structures. In the enviromental area, satellite imaging has been used to map natural resources as well as enviromental pollution. In the area of manufacturing, imaging systems are used to detect defects automatically. In all of these applications, a key process is that of image restoration, namely, cleaning up an image polluted by noise and blurring. This is a central subject of this project. These problems are very computationally intensive due to the large number of pixels and the possibility of sequences of images (e.g. videos). Solving them requires clever mathematical algorithms as well as high performance computers. Beyond this, in the current revolution in commmunication and the use of the information highway, more images are being transmitted and better mathematical algorithms are needed to compress and remove noise and other distortions occuring in the transmission.","title":"Variational PDE Models and Computational Methods in Image Processing","awardID":"9973341","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}}],"PIcoPI":["306467"],"PO":["380707"]},"48798":{"abstract":"Formal deductive systems play a central role in the areas of programming languages<br\/>and logics. Firstly, they are used to define languages and their semantics at a very<br\/>high-level of abstraction (e.g., type systems or operational semantics). Secondly,<br\/>they form the basis for the implementation of algorithms pertaining to languages<br\/>(e.g., type inference or interpretation). Thirdly, they provide a common basis for<br\/>the study of meta-theory of programming languages and logics (e.g., preservation of<br\/>types under evaluation).<br\/><br\/>Motivated by the tremendous variety of deductive systems of interest in com-<br\/>puter science and logic, general meta-languages for their specification have been<br\/>investigated by the author and others. These meta-languages are often referred to<br\/>as logical frameworks. When they emphasis is placed meta-theoretic reasoning they<br\/>have been called meta-logical frameworks. The primary objective of the proposed<br\/>work is to further the theory and practice of logic-independent, computer-assisted<br\/>formal reasoning and meta-reasoning.<br\/><br\/>This is a renewal of the current NSF Grant CCR-9619584. Prior relevant work<br\/>by the proposer and the results from the current grant include the design and im-<br\/>plementation of the logic programming language Elf based on the logical framework<br\/>LF, released in September 1998 under the name Twelf. Extensive case studies have<br\/>confirmed the wide range of applicability of the methodology underlying Twelf and<br\/>its extension to a linear type theory. The primary emphasis of the work proposed<br\/>under this renewal will be applications in education and research, and the practical<br\/>and theoretical issues suggested by these applications.","title":"Meta-logical Frameworks","awardID":"9988281","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["339844"],"PO":["321058"]},"69489":{"abstract":"","title":"CAREER: Determining Parallel Complexity of Numerical Computation Problems via Dependency Graphs","awardID":"0196377","effectiveDate":"2000-09-15","expirationDate":"2003-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":[179869],"PO":["321058"]},"48369":{"abstract":"Avi Wigderson<br\/>9987077<br\/>This project will support three senior researchers to participate in a special year on computational complexity theory at the Institute for Advanced Studies. These researchers will attract the participation of other top researchers in computational complexity. <br\/>Computational complexity theory has opened up one of the most exciting fields of scientific and mathematical research over the last 20 years, with dramatic achievements and fundamental understandings appearing at a high rate. One obvious explanation for the recent progress in this field is that this research is guided by a few clear and focused questions, deeply motivated on scientific, practical and philosophical grounds. The most central of these are:<br\/>P=NP?, or more generally, are the many natural computational problems we can't solve really difficult?<br\/>NP=coNP?, or more generally, what constitutes a difficult theorem to prove:<br\/>P=BPP?, or more generally, does randomization really help efficient computation?<br\/>BPP=QP?, or more generally, can quantum mechanics be efficiently simulated classically?<br\/>Resolving any of these questions is clearly very long term goal, but each has stimulated the development of concepts, problems, proof techniques and results which start paving a path towards a possible resolution.<br\/>But what really characterized the progress, and explained much of the successes so far, was the unveiling of many rich and beautiful connections between the sets of concepts and sub-problems each of these major questions gave rise to. There is little doubt that such connections are, and will be, the foundation for understanding the major questions of complexity theory. Indeed, these connections are what is making the complex world of computational complexity into a theory. The focus of this special year at the Institute will be to better understand these connections and their implications, to unify and extend them, and to look for new ones.","title":"Special Year in Computational Complexity Theory","awardID":"9987077","effectiveDate":"2000-09-01","expirationDate":"2001-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["384098"],"PO":["187585"]},"52670":{"abstract":"The goal of this project is to develop techniques to reduce the memory footprint of executable code, so as to allow more and more sophisticated applications to be executed on limited-memory devices, such as hand-held computers, personal digital assistants, and embedded processors. Recent years have seen the incorporation of computers and computational devices into many aspects of our everyday lives. In many cases, the amount of memory available for such processors is limited by considerations such as space, weight, and power consumption. At the same time, there is a desire to run more and more sophisticated applications on such processors. Since an application that occupies more memory than is available on such a processor will not be able to run on that processor, it is desirable to develop techniques to reduce the memory footprint of applications. Moreover, it is necessary that the compressed applications remain executable, since for the application domains under consideration it is not feasible to decompress the executable in order to execute it. This project investigates the construction of tools and techniques for code compression in a manner that preserves executability.","title":"Compiler Techniques for Code Compression","awardID":"0073394","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["550173","540163"],"PO":["551992"]},"54870":{"abstract":"The goal of this research is to reduce the cost and improve the<br\/>performance of observation-based branch characterization mechanisms in<br\/>the compiler and hardware. Often, correlation discovered at great cost<br\/>or missed entirely through execution can be determined in a simple<br\/>algebraic fashion at compile time. Relationships between program<br\/>structures can be inferred from these algebraic expressions and<br\/>subsequently conveyed to compiler optimizations and to the hardware<br\/>through appropriate mechanisms to be developed by this research. Once<br\/>employed, these relationships can refocus the efforts expended by<br\/>observation-based mechanisms, or can eliminate the need for them<br\/>altogether.","title":"ITR: Collaborative Research--Ascertaining Runtime Branch Characteristics through Algebraic Analysis of Programs","awardID":"0082630","effectiveDate":"2000-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["511660","489472"],"PO":["551992"]},"54991":{"abstract":"Recently, a novel approach for runtime verification of complex superscalar processors has been proposed. In this approach, every computation is dynamically verified by hardware using a form of complete induction. This project focuses on extending the notion of inductive dynamic verification to the general case of parallel distributed systems. The principles of dynamic inductive checking for parallel semantics are investigated. This includes an understanding of the characteristics and properties of systems, where the approach can be used effectively. The initial vehicles used for developing such techniques are the problems of cache coherence and support for sequential consistency in shared-memory multiprocessors. As a natural extension of this research, the project formulates a method for state machine abstraction, which can be applied in the general case. This method rests on the separation of architected state from additional implementation state, and the identification of that subset of state transitions that correspond to changes in the architected state only.","title":"ITR: Techniques for Dynamic Verification of Parallel Distributed Systems","awardID":"0083126","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["552216","549841"],"PO":["180163"]},"52692":{"abstract":"This project investigates the compiled communication technique on <br\/>commodity networks. In compiled communication, high performance <br\/>communication is achieved by using the compiler to analyze the communication <br\/>requirement of a program and to manage network resources statically to <br\/>support the communications. As a result, runtime communication overheads, <br\/>such as buffer management, are reduced and\/or amortized over a number of <br\/>communications, and the communication performance is improved. Compiled<br\/>communication is more powerful than traditional communication optimization <br\/>techniques in that it performs communication optimizations in both the<br\/>compiler and the hardware\/operating system\/runtime system. The outcome<br\/>of the proposed research is an extension of the MPI library that supports<br\/>the compiled communication model, a SUIF based restructure compiler that <br\/>can generate communication code using the compiled communication model,<br\/>an experimental demonstration of how much performance improvement can be<br\/>achieved by using the compiled communication model, and a clear <br\/>identification of the advantages and limitations of the compiled communication<br\/>model.","title":"Supporting Compiled Communication on Commodity Networks","awardID":"0073482","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["554071"],"PO":["241298"]},"54881":{"abstract":"Considerable information is known to exist in the form of \"soft\" information such as the hunches, opinions, beliefs and expectations distributed across many individuals. When individuals are differentially located in time and space and receive signals in the form of complex patterns from a common source, such information can aggregate into a reliable statistic. Tools for extracting such information, called Information Aggregation Mechanisms (IAMs), have evolved naturally but the scientific foundation for their successes has not been explored. IAMs involve subtleties because they depend upon incentives and the ability of individuals to update their opinions\/beliefs by observing others. Through the application of new laboratory experimental methods, this research will isolate the principles that lead to the successes. Then, using the behavioral principles together with modern communications and computational technology, the research will produce new types of IAMs unlike any that are found occurring naturally. Potential applications range widely across almost any complex system in which the need for information is continuous or reoccurring, the state is not clearly observed from any single vantage point and observation requires human interpretation. Presumably, this would include anything ranging from epidemics, pending systems failures, the outcome of complex decision processes in an organization, or social tendencies.","title":"ITR: Technology for Information Aggregation Mechanisms: The Rapid Collection and Aggregation of \"Soft\" Information Distributed Across Remotely Located Individuals and Groups","awardID":"0082689","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["220803"],"PO":["495796"]},"51031":{"abstract":"The explosive growth of computer networks has created the potential to access a great deal of computing power and information, but new models of distributed computing are required to fully utilize these resources. Cooperative distributed problem solving (CDPS) is concerned with solving large-scale problems using systems of intelligent software agents, distributed among networked computers, working cooperatively. CDPS approaches can produce highly flexible and reliable systems, and can be used for a wide range of potential applications. The goal of this project is to make it easier to to build CDPS systems for real-world applications, by improving the understanding of how system and domain characteristics interact to affect the performance of CDPS systems, and by identifying CDPS strategies that perform well under particular conditions. This will allow CDPS techniques to be more widely applied than they currently are. The project will pursue this goal by: developing formalisms for modeling CDPS systems as distributed search processes; implementing software tools that use these models to predict the performance of CDPS systems; identifying generic domain characteristics that are critical for predicting CDPS performance; and performing a broad range of experiments to build up a suite of effective abstract CDPS strategies.","title":"Formalizing Distributed Search in Cooperative Distributed Problem-Solving Systems","awardID":"0004112","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["485591"],"PO":["495796"]},"56850":{"abstract":"Institution: University of Pittsburg<br\/>Proposal Number: EIA 0089963<br\/>PI: Sandra Katz<br\/>Title: Learning Behaviors and Background Characteristics that Promote Retention of Women and Minorities in Undergraduate Computer Science Programs<br\/><br\/>This CISE Information Technology Workforce (ITW) proposal requests funds to study how students' learning strategies and behaviors affect their performance in undergraduate computer science programs. Since programming is one of the first skills that computer science students learn, and a stumbling block for many, the study will focus on students' programming learning strategies. The study will consist of three main activities. The first will be the identification of learning and programming behaviors that distinguish successful from unsuccessful CS students; and the determination of which behaviors, if any, are more characteristic of males than females (and the reverse) and Caucasian students than African American students (and the reverse). The second activity will be the development and evaluation of an intervention to train effective learning and programming behaviors. The third activity will be a survey of students and successful computer scientists to determine whether certain pre-college experiences predict effective learning behaviors and success in computer science. This project has the potential to provide valuable insights into the recruitment and retention of women and underrepresented minorities in computer science majors.","title":"ITW: Learning Behaviors and Background Characteristics that Promote Retention of Women and Minorities in Undergraduate Computer Science Programs","awardID":"0089963","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["438734","290833"],"PO":["289456"]},"55761":{"abstract":"This project, carried out in close conjunction with the Software Engineering Research Center (SERC, an NSF-sponsored IUCRC Center), establishes a Software Engineering Technology Watch to track trends in Research, Technology, and the Market as relates to software engineering. The results of the these Watch activities-reports and studies-inform the respective communities about the state of the art, promising directions, and apparent failures. As part of laying the foundation for the modeling of trends, data is compiled on various aspects of the national software engineering enterprise. Example case studies would be the Internet, the Web, Java, Unix, Ada, and Linux. The activity also serves to define and refine the best strategies for collecting, analyzing, and disseminating the information, thus providing a feasibility study to determine the process to follow. Issues to address include: What cost factors guide trends, What lifecycle do technologies follow, and What aspects of technology evolution are controllable? The research develops a synthetic model of a \"technology trend,\" a synthetic comparative survey of other existing tech-watch initiatives in software engineering, an identification of relevant indices and sources of information, and a report including factual information pertaining to the evolution of the field.","title":"SGER: Software Engineering Technology Watch","awardID":"0086226","effectiveDate":"2000-09-01","expirationDate":"2001-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["309212",142994],"PO":["150697"]},"54672":{"abstract":"The memory model for a programming language specifies<br\/>the relationship between the order in which data accesses<br\/>appear in a program and the order seen during execution by<br\/>the different program components With the advent of parallel<br\/>programming environments like Posix threads, Java, and OpenMP, multi-<br\/>threaded explicitly parallel programs have become much more<br\/>frequent. This increases the need for memory models that<br\/>are easy to understand and efficient so that correct pro-<br\/>grams can be developed and still give good performance.<br\/>Unfortunately, the usability of memory models, their impact<br\/>on performance, and the compiler technology needed to per-<br\/>form optimizations of parallel programs are poorly under-<br\/>stood. The result is that current memory models tend to<br\/>favor performance over usability by restricting the programs<br\/>that can be written with them, or by being difficult to<br\/>understand. The objective of this project is to study com-<br\/>piler techniques to optimize explicitly parallel programs by<br\/>using optimizations and analysis algorithms structured to<br\/>handle a broad class of consistency models. The techniques<br\/>studied will be implemented in a compiler that will serve<br\/>as a testbed for prototyping and studying programming<br\/>language memory models and for studying the optimization<br\/>and analysis of explicitly parallel programs.","title":"ITR: An Optimizing Compiler for Languages with Programmable Memory Models","awardID":"0081265","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["533380","550995"],"PO":["565272"]},"55651":{"abstract":"This is the first year funding of a five-year continuing award. This research program is geared towards making significant advances to the science and engineering of visual information processing, and addresses fundamental problems in the fields of computational vision, computer graphics, and human-machine interactions. Today, images and video clips are ubiquitous on the internet, digital video is changing the way entertainment is produced, distance learning is used in various facets of education, and advanced visual interfaces to machines are around the corner. However, at present there are severe limits to the extent to which a user can benefit from visual information, because virtually all of this information is presented in its raw form, that is, the way it was captured. The goal of this project is to develop the technical tools needed to achieve a variety of complex manipulations of visual data. These tools will enable a user to freely explore, interact with, and create variations of the physical world being presented. For instance, a user may remove and add objects to an image of a scene, vary lighting conditions, change the materials of surfaces, or view the scene from a novel perspective.<br\/><br\/>This project encompasses a comprehensive research program for creating the science and technology base required to enable such advanced manipulations of visual data. The general research problem may be stated as follows: Capturing, understanding, and predicting the appearance of our everyday world. Success in this domain of research necessitates a unified approach to open problems in two fields: computational vision and computer graphics. The research effort will focus on five pertinent areas: sensing, modeling, estimation, generation, and evaluation. The tangible contributions will be in the form of sensors that provide new types of visual information; complex models of materials, reflectances and textures; estimation algorithms that use the team's new models to recover scene properties from minimal data; advanced rendering techniques; and a set of comprehensive image\/video databases for evaluation of work in this field. The results will impact numerous application domains, including digital imaging, entertainment, virtual environments, distance learning, e-commerce, interactive product design, art restoration, architectural modeling, restorative surgery, and surface inspection.","title":"ITR: Interacting with the Visual World: Capturing, Understanding, and Predicting Appearance","awardID":"0085864","effectiveDate":"2000-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["515703","438618","483871","519250","174830"],"PO":["317663"]},"55772":{"abstract":"EIA-0086255<br\/>Waite, William M.<br\/>University of Colorado at Boulder <br\/><br\/>CISE Educational Innovation: A Tool-Supported Programming Languages Curriculum<br\/><br\/>This project integrates research and development in software tools development into the undergraduate computer science program at this institution with special emphasis on computer-supported cooperative work and decision support. The project strategy involves \"scaffolding\" content-related problem solving skills and process-related group interaction skills by integrating a suite of tools, developed by the research community, into a three-course sequence required of all computer science majors. The key idea is that students are involved in realistic projects, beginning with their introductory courses, but an infrastructure selectively hides complexity from students. As students progress to more advanced courses, more of the complexity is revealed, until finally, students are involved in realistic projects involving significant collaborative work. The project has two components: (i) a software infrastructure that manages the complexity that students are exposed to, and (ii) a collection of tools that allow students to undertake larger projects than would normally be possible in a classroom setting. Students also use a web-based journal tool to keep track of significant milestones, problems, and other issues related to tasks assigned to them. The backbone of the collaborative system used in this project consists of a repository that contains code and implementation monitors for student projects, tools that students use when interacting with the materials in the repository, and a set of policies that control how students can interact with the repository contents. This project addresses the national need of educating software practitioners who can work on large, complex software systems in teams.","title":"CISE Educational Innovation: A Tool-Supported Programming Languages Curriculum","awardID":"0086255","effectiveDate":"2000-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":[143021,143022,"461768"],"PO":["551712"]},"54683":{"abstract":"Advances in processor technology, both in increased processing power and decreased energy<br\/>consumption, have led to the creation of a new breed of small intelligent devices from tiny<br\/>laptops, to PDAs, to smart phones, to wearable computers made from a collection of small<br\/>independent devices. The advent of such devices and wearable computers brings to light new<br\/>possibilities and new needs, specifically: cooperation among devices and elimination of cables.<br\/>The development of short-range radio technology, such as Bluetooth, enables the cooperation of<br\/>such devices over wireless links. As users collect multiple small computing devices, the amount<br\/>of communication resources available to the user increases and so the demand for coordination of<br\/>resources between these devices increases. The overhead of this coordination may tax the<br\/>available bandwidth and energy resources of the devices. The goal of this research is to support<br\/>such cooperation and coordination through intelligent communication management with an<br\/>emphasis on the efficient use of available resources.<br\/><br\/>As the user moves between different environments, these MObile grouPEd Devices (MOPEDs)<br\/>cooperate as a coordinated local area network that provides the user the desired mobile services.<br\/>This cooperation and coordination between a single user's devices changes the definition of what<br\/>it means to communicate with a user. With a MOPED, communicating with any of the devices in<br\/>the MOPED represents a successful connection to the local area network, and so to the individual.<br\/>In order to better support the needs of the user, the MOPED may interact with networks in the<br\/>current environment surrounding the user in order to determine the availability of local services.<br\/><br\/>The researchers' approach relies on decision algorithms; services and protocols for determining what communication channels are available to which devices, as well as resource and quality<br\/>information about such channels. The researchers address four major challenges faced in the design of such a solution.<br\/><br\/>1) Channel Discovery: The researchers propose the design of intelligent service discovery protocols based on the requirements of the user and the tradeoff between having current<br\/>information about the availability of communication channels with the overhead in<br\/>resources (i.e. bandwidth and power) used to acquire that information.<br\/>2) Resource Monitoring: The researchers propose the design of a distributed resource information<br\/>repository, which is a database internal to the MOPED. The algorithms governing the<br\/>dissemination of resource information to devices in the MOPED must take into<br\/>consideration the topology of the network, the energy and bandwidth availability of each<br\/>device, and the priority at which each device actually needs the information.<br\/>3) Resource Allocation: The researchers propose the design of intelligent transport and routing<br\/>protocols able to use the resource availability information to determine which and how<br\/>many of the MOPED's external channels to use to complete a specific connection.<br\/>4) Mobility Management: The researchers propose mobility management techniques to provide the ability for external users to communicate with the user, and so the devices of the<br\/>MOPED, wherever it is currently connected to the Internet and propose the design of<br\/>mobility management protocols based on the current technology for host mobility.<br\/><br\/>The results of the research will enable simultaneous connections through all available<br\/>communication channels. This creates a very robust environment, where it becomes easier to<br\/>guarantee complete communication coverage. It allows using MOPEDs for critical tasks such as<br\/>patient monitoring where it is important to maintain connectivity at all time, through there may be<br\/>some flexibility in the amount of data that is transferred as well as the importance of that data. If<br\/>the communication patterns of such a MOPED are not well monitored, certain devices may<br\/>unacceptably lose power due to inefficient connection management.","title":"ITR: Environment-Aware Communication for Mobile Grouped Devices","awardID":"0081308","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["561785"],"PO":["250082"]},"55673":{"abstract":"This project investigates techniques and tools for assuring software<br\/>quality: finding and removing defects in software systems, as well as<br\/>improving current methodology for designing high-quality software<br\/>systems at the outset. The project consists of both experimental<br\/>and theoretical components.<br\/><br\/>The experimental effort is focused on designing and building tools to<br\/>improve the quality of Open Source software. Open Source is<br\/>attractive as a research vehicle in software quality because of the<br\/>critical role it plays in the nation's economy and precisely because<br\/>it has the unique feature that it is a real-world system that is<br\/>completely open and available for study. Because of the Open Source<br\/>tradition of incorporating useful new techniques and tools into the<br\/>Open Source environment, there is also an opportunity for direct and<br\/>widespread impact.<br\/><br\/>The foundational work in this project combines expertise in the three<br\/>branches of the discipline of the analysis of software: formal<br\/>verification and theorem proving, model checking, and large-scale<br\/>software analysis. These three areas have developed rapidly in recent years, seeing both significant theoretical and practical advances. A central thesis of this project is that significant further advances are possible by bringing together these areas to work on a common set of problems.","title":"ITR: The Open Source Quality Project","awardID":"0085949","effectiveDate":"2000-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["507674","226709","451874"],"PO":["564388"]},"55684":{"abstract":"Second and third generation wireless systems have been designed primarily for voice, so they are con-nection oriented, delay sensitive, and provide fixed bit rates. Additionally, since service is desired \"any-time\/anywhere,\" these systems must provide ubiquitous coverage. This coverage is achieved through rela-tively uniform grids of cell sites, which are placed to control interference and minimize outage rather than to maximize throughout. As a result, such systems deliver low bit rates and are relatively expensive when used for large amounts of information. At the same time, wireline connection to the Internet has encouraged uses (and users) that depend upon bits being virtually \"free.\" We contend that this \"economic\" mismatch between wired and wireless access is the primary obstacle to the dramatic growth of a wireless Internet. The solution may lie in designing systems specifically for wireless data, recognizing that data services are often connectionless, delay insensitive and have no specific bit rate requirements. These differences suggest that ubiquitous (anytime\/anywhere) coverage is not a strict requirement for wireless data networks and makes possible systems in which small, separated coverage areas facilitate transfers of megabytes of data in fractions of a second, and for a fraction of the cost associated with conventional ubiquitous coverage. Communication theory and simple link budget calculations tell us that it is possible to build such sys-tems, but the signal processing challenges are numerous and distinct from the historical challenges offered by connection-oriented wireless services. When a mobile user passes an Infostation, there will be a window of opportunity, perhaps as short as a fraction of a second, in which the user will have access to a high-rate communication channel. A key task is to identify that window and transmit at an appropriate rate. The mobile must make these decisions based on measurements of a wideband radio channel in which there is frequency selectivity and time variation in the fading as well as in the interference. In the specific context<br\/>of an Infostations system, we plan to divide our research into four components: <br\/><br\/>Radio Channel Modeling: The characterization of typical Infostation radio channels. <br\/><br\/>Transceiver Design: The analysis and performance evaluation of transmitters and receivers for both single carrier and multicarrier systems.<br\/><br\/>Radio Resource Management Transmitter power and rate adaptation policies derived from receiver measurements.<br\/><br\/>Algorithm Development Testbed A platform employing DSP and FPGA technology for the practical evaluation of transmitter and receiver algorithms. <br\/><br\/>The activities of this project will encompass three research institutions in New Jersey (New Jersey In-stitute of Technology, Princeton University, Rutgers University) under the auspices of the N.J. Center for Wireless Telecommunications (NJCWT). The NJCWT is an inter-institutional research and educational or-ganization sponsored and funded by the N.J. Commission on Science and Technology. The focus of the center is a multi-year effort in Digital Radio Technology for Computing, Communications and Information Systems. This effort is supportive of and will enhance the present proposed project in wireless networks.","title":"ITR: Collaborative Research: 'Free' Bits: The Challenge of the Wireless Internet","awardID":"0085986","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["463100","475434","466323"],"PO":["223414"]},"55695":{"abstract":"This project studies the integration of heterogeneous resources into a system-on-chip (SOC) solution. Heterogeneous SOC integration supports the fabrication of RF, analog, high performance digital, and re-configurable subsystems within a single piece of silicon, and includes issues of simulation, design, integration, test, and education. An example SOC is a human\/machine transducer chip that provides a speech recognition interface to a ubiquitous wireless network. Such a system represents a standard interface modality. Multiple topics are being researched including low-power speaker identification, speech processing algorithms, and hardware implementations. Low power, high performance wireless protocols are also being developed to support the asymmetric communication loads, sending low bandwidth control messages produced from the recognized speech and receiving high-bandwidth information return for visual, audio, and other feedback to the user.","title":"ITR: Heterogeneous System Integration in System-on-a-Chip Designs","awardID":"0086032","effectiveDate":"2000-09-15","expirationDate":"2007-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["508528","52879","485670","431529","485671"],"PO":["562984"]},"48963":{"abstract":"This research project investigates the design and analysis of market-based mechanisms for decentralized scheduling. Market price systems are well known to effectively decentralize decisions in idealized situations, but real scheduling problems present constraints and interdependencies that can defeat simple market schemes. In this project, market failures arising from the inability to couple interdependent resources are addressed through more sophisticated market structures that allow traders to express complex contingencies. The resulting system will be analyzed using game-theoretic and evolutionary techniques. Results from this work will lead to novel practical scheduling mechanisms that can be deployed within e-commerce and other distributed contexts. New design and analysis methodologies will demonstrate how to extend the resulting mechanisms to other classes of decentralized allocation problems.","title":"Computational Markets for Decentralization of Complex Time-Dependent Activities","awardID":"9988715","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V050","name":"NSA-WORLD RENOWNED EXPERTS FRO"}}],"PIcoPI":["361939","563733"],"PO":["564456"]},"55145":{"abstract":"Computer graphics has made great advances in producing realism and detail in synthetic scenes, yet these techniques have not been applied to scientific visualization. A realistic-looking 3D scene is immediately and viscerally apprehended, which promotes understanding of its contents. Fidelity of shading is important to a person viewing an already-familiar architectural environment. Such fidelity is even more important for a person viewing the complicated and unfamiliar geometry of isosurfaces and field lines that reveal the features in a dataset resulting from computational simulation or from physical measurement. This project will develop global illumination techniques for isosurfaces and field lines in 3D data, with applications to medical data and engineering data.","title":"Realistic Illumination for Scalar Field and Vector Field Visualization","awardID":"0083898","effectiveDate":"2000-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}}],"PIcoPI":["480998","550080"],"PO":["565272"]},"43287":{"abstract":"Abstract<br\/><br\/>This project seeks to develop an Internet accessible software broker to match scientists and engineers (or companies of such) offering algorithms, and\/or their use, for a fee to algorithm users. To this end this project includes a theoretical investigation into scheduling, accounting and pricing related to electronic brokers for open electronic markets for algorithmic intellectual property. The technology for developing this broker would make use of the capabilities of the Internet, interoperable software such as JAVA and CORBA as well as new scheduler and accounting advances to be made in this research program.","title":"Open E-Market Technology for Algorithmic Intellectual Property","awardID":"9912331","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":[109588,"410651"],"PO":["309350"]},"55035":{"abstract":"This project addresses new methods to generate collision-free paths for robots that operate in environments that change over time. Typical applications of this research include robot arms mounted on mobile platforms, arms that operate in factory settings, or any other manipulation systems that operate in environments that are either unknown a priori or may change over time.<br\/>The proposed approach comprises preprocessing and on-line stages. Preprocessing produces a representation of the configuration space that can be easily modified in real-time to account for changes in the environment. A one-dimensional roadmap is constructed for an obstacle-free workspace, and the mapping from workspace cells to<br\/>nodes and arcs in the roadmap is encoded. In the on-line stage, when the environment changes, this mapping is used to make the appropriate modifications to the roadmap, and plans can be generated by searching the modified roadmap. At the heart of the method is the encoding for the mapping from workspace obstacles to configuration space obstacles. To make the proposed approach truly viable, a major component of the proposed research will focus on robustness and complexity issues. These issues will be addressed by using tools from the fields of image processing, information theory, graph theory, computational geometry, and incremental algorithms.","title":"Real-time Path Planning in Changing Environments","awardID":"0083275","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["421048"],"PO":["234178"]},"43298":{"abstract":"The planning project permits the Principal Investigator to participate in activities for developing a competitive research project in programming languages. In particular, the Principal Investigator participates in national and international conferences to learn about results from new research in <br\/>theoretical and applied aspects of programming languages. The Principle Investigator is using this knowledge to conduct preliminary research for determining the effectiveness of using domain-specific languages for program interoperability. Program interoperability allows one program to use the services of another program automatically. The preliminary research focuses on developing the formal semantics of a meta-language for domain-specific languages and implementing a prototype of a software tool for rapidly developing interpreters of domain-specific languages.","title":"Achieving Program Interperability Using Domain-Specific Languages","awardID":"9912349","effectiveDate":"2000-09-01","expirationDate":"2003-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":[109619],"PO":["564388"]},"48876":{"abstract":"Wide-area distributed computing systems represent the future of scientific<br\/>and commercial computing. Such systems will enable a wide range of futuristic<br\/>applications with the potential for enormous economic and social impact<br\/>applications such as distributed multimedia services, Web-based collaboration,<br\/>distributed supercomputing, and teleimmersion. Before this vision can be<br\/>realized, however, extensive research will be required in virtually all<br\/>aspects of software system design, implementation, and evaluation.<br\/><br\/>Discrete-event simulation has been an essential tool for the design and<br\/>analysis of traditional computational systems and applications. Realistic<br\/>simulation of applications executing on wide-area distributed systems,<br\/>however, is a challenging task because of the scale of the software, hardware<br\/>and network subsystems that must be simulated. Nevertheless, the intricacy of<br\/>these components and their complex, closed-loop interactions require the<br\/>components and their interactions to be modeled in sufficient detail to<br\/>appropriately predict their impact on overall system performance.<br\/>In recent work, the PIs have collaboratively obtained some exciting but<br\/>preliminary results showing that specific compiler information can greatly<br\/>enhance the efficiency and scalability of simulation of message-passing<br\/>programs. For instance, it was shown that simulation of a scalable ASCI kernel<br\/>benchmark application called SWEEP3D executing on up to 128 processors could<br\/>be simulated faster than real-time by using parallel simulations together<br\/>with the type of compiler optimizations that are the subject of this proposal.<br\/>Also, the compiler-optimized simulation can evaluate very large data<br\/>sets on thousands of processors: it was possible to simulate the performance<br\/>of a 40 million-problem size Sweep3D for up to 10,000 processors. There are<br\/>potentially a number of other strategies to dramatically improve simulation<br\/>scalability and performance by using compiler information, none of which have<br\/>been studied so far. A comprehensive program of research is required to<br\/>develop their potential and evaluate their impact on simulation of real world<br\/>applications.<br\/><br\/>The focus of the current proposal is to develop compiler-based techniques for<br\/>improving the efficiency of parallel discrete event simulation, and to use<br\/>these techniques to evaluate application and system software performance for<br\/>wide-area distributed systems. There are three key components to this<br\/>proposal:<br\/>1. To explore a range of compiler-supported strategies for highly efficient<br\/>simulation of dynamic, large-scale systems and applications.<br\/>2. To implement and evaluate these strategies for wide-area distributed<br\/>systems, by extending our existing compiler and simulation infrastructure.<br\/>This requires addressing additional challenges raised by the dynamic nature<br\/>of these systems and the lack of well-defined metrics to measure effective<br\/>application level performance in such environments.<br\/>3. To evaluate the effectiveness of these strategies for real world <br\/>distributed<br\/>applications that have already been developed, such as a distributed <br\/>multimedia<br\/>application and distributed versions of tightly coupled applications such as<br\/>Sweep3D and the NAS parallel benchmarks.<br\/><br\/>The proposed research program builds on a collaboration of several years <br\/>between<br\/>the PIs' research groups, and brings together key strengths in parallel<br\/>simulation of large-scale parallel programs, parallel simulation of wide-area<br\/>networks, and in parallelizing compilers and their use for supporting<br\/>performance evaluation.<br\/><br\/>This program of research also complements the ongoing software efforts for<br\/>wide-area systems that are aimed at developing operating system services<br\/>(e.g., Globus, Legion, and WebOS) and programming environments (e.g., Legion,<br\/>Globe, and GrADS). As such, the proposed research program represents an<br\/>essential third leg of software support for the development and deployment<br\/>of successful wide-area distributed systems.","title":"Collaborative Research: Compiler-Supported Simulation of Scalable Applications for Wide-Area Distributed Computing Systems","awardID":"9988482","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["542046"],"PO":["309350"]},"79489":{"abstract":"9818287<br\/>Hodgins, Jessica K.<br\/>Atkeson, Christopher G.<br\/>Georgia Institute of Technology<br\/><br\/>CISE Research Instrumentation: Data-Driven Modeling for Real-time Interaction and Animation<br\/><br\/>This research instrumentation enables research projects in:<br\/><br\/>- Perception of Action<br\/>- Learning from Demonstration<br\/>- Animating with Experimentally Determined Parameters, and<br\/>- Modeling Facial Expressions<br\/><br\/>To support the aforementioned projects, for the capture, modeling, recognition, and generation of human motion, this award contributes to the purchase of motion capture equipment, graphics workstations, and digital cameras at College of Computing in Georgia Institute of Technology. The equipment will be used for several projects aimed at making it easy to create, control, and interact with artificial humans in interactive<br\/>environments for training and entertainment. The cameras and motion capture equipment will capture full body and facial motion of the users. The processing power of the graphics workstations and other available<br\/>multi-processors will be used to create data-driven models for recognition and generation of human actions ranging from full body motions such as a tennis swing to subtle facial expressions. The power of this technology will be demonstrated by constructing interactive environments in which the cameras and motion capture equipment will be used for on-line recognition of user actions and the graphics workstation will be used to animate human figures in real-time, based on the models derived off-line. The prototype applications will be environments where interactivity and realism are key, such as training environments for physical tasks and animation of highly interactive and responsive characters.","title":"CISE Research Instrumentation: Data-Driven Modeling for Real-Time Interaction and Animation","awardID":"0242482","effectiveDate":"2000-09-01","expirationDate":"2003-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["438709"],"PO":["557609"]},"48887":{"abstract":"The amount of work required to keep software artifacts consistent contributes significantly to the time and costs of a software project. In particular, it is difficult to share and integrate information between artifacts due to the bewildering number of tools and data formats used to create and maintain them. This project performs basic research on the issue of information integration to enable development of techniques and mechanisms that reduce the time and costs associated with performing this task in large-scale software development projects. The chosen approach develops an environment that provides first-class support for information integration. New experimental XML-based data formats are designed to facilitate integration. An environment of generators and translators are designed and developed to translate information into the new data formats, making that information available for integration. New hypermedia services are developed to capture and specify artifact relationships. Finally, infrastructure for addressing these issues in heterogeneous software development environments, where multiple organizations may be involved in a software development project, are designed and experimentally prototyped.","title":"Supporting Information Integration in Large-Scale Software Development","awardID":"9988517","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["530768"],"PO":["564388"]},"48777":{"abstract":"Computing with Shapes: Reconstruction and Decimation<br\/>Tamal Dey<br\/>Ohio State<br\/><br\/><br\/>Computations with shapes are prevalent in a number of application areas ranging over CAD\/CAM, medical imaging, physical simulations and so on. We propose studying two of these computations, namely, reconstruction and decimation. The choice of these two operations is prompted by their imminent relevance in applications, our ongoing research on them, and their rich theoretical challenges. We focus mainly on low dimensional shapes such as curves and surfaces in two and three dimensions. These shapes are ubiquitous in applications and their understanding is essential to move forward to higher dimensional shapes.<br\/><br\/>By reconstruction we mean computing a piecewise linear approximation of a shape from a set of sample points. Modern technology with laser scanners has made it easy to obtain a dense set of sample points from the boundary of an object. A piecewise linear approximation from these sample points help to model the object for prototyping, visual inspection, and further reengineering. The problem has been studied by graphics community who used numerical approaches to the problem. Computational geometers attacked the problem with ideas from discrete and differential geometry. Although a considerable success has been made by these approaches, there are growing demand from the industry to handle shapes with boundary, sharp features, noise which cannot be tackled robustly with the current methods. <br\/><br\/>Decimation of a shape is the process of reducing the size of the data structure representing the shape. The model reconstructed from a sample may have a large number of elements such as triangles since the input sample set is typically large. Such a model with large number of elements becomes unwieldy for further processing such as graphic rendering or physical simulations. A standard strategy is to reduce the number of triangles by edge contractions. In this method selected edges are contracted to a new vertex. All incident simplices are contracted accordingly. Different kinds of demands on the geometry and topology of the shapes during decimation are put forward by multitude of applications. While some of the applications need to preserve the topology, the others want to change it in a controlled manner. The investigator with other researchers in the community studied the problem of preserving topology during edge contractions. The question of allowing topology change in a controlled manner is still largely unsolved. <br\/><br\/>The geometry of the shape depends on the location of the new vertex replacing the contracted edge. An effective numerical tool used for this purpose is the quadric error measure that tries to optimize the the sum of distances of the new vertex from the planes of the neighboring triangles. This strategy tends to produce an anisotropic mesh whose triangles are elongated according to the curvature of the shape. Although anisotropic meshes are preferred in some applications, there are others who favor isotropic meshes that have triangles with bounded aspect ratio. Can we produce an isotropic mesh after reconstruction and decimation? Instead of decimating the model after reconstruction, is it possible to decimate the sample itself? In a recent work, the investigator tries to address this issue. This work is far from complete and we propose to continue it for new results.<br\/><br\/>Theoretical studies proposed for this project would require combining ideas from topology and geometry, a central issue in the emergent field of Computational Topology. New algorithms will be developed as a result of our theoretical study, but their ultimate proof of performance will be tested through implementation which is also part of our agenda.","title":"Computing with Shapes: Reconstruction and Decimation","awardID":"9988216","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["549998"],"PO":["532791"]},"54750":{"abstract":"The last decade has witnessed a significant research thrust aimed at handling very large models in computer graphics. This project will extend those efforts by focusing on means to efficiently visualize, interact with, and manipulate large-scale graphics datasets over networks. The PI plans to develop techniques that will decrease latency, reduce bandwidth, and increase the interactivity for large graphics datasets over networks. The technical vision is to build a distributed rendering system that (a) takes advantage of the respective powers of image-based and object-based rendering for visualization of large-scale graphics datasets, (b)is well-suited for visualization-assisted collaboration and interaction across limited bandwidth links, and (c) takes into account the client, server, and network resources to deliver the best overall performance including times to transfer and render a dataset. Towards these ends the PI will explore techniques for high compression, progressive transmission, rendering from compressed data, handling time-varying datasets, and resource- aware rendering. The project work plan also seeks to develop tools for annotation, navigation, and sharing of educational spaces for use in synchronous and asynchronous learning environments that use three-dimensional datasets. This research will help push network-based collaborative design to the next level in a variety of science, engineering, and medical applications.","title":"ITR: Visualization and Interaction with Large Graphics Datasets over Networks","awardID":"0081847","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["543581"],"PO":["564456"]},"54871":{"abstract":"The goal of this project is to develop a methodology and set of prototype tools to enable \"associative\" mining of very large scientific data sets. The researchers will use content, such as solution features, patterns, and shapes, to examine the data and retrieve required information. Unlike other approaches that use index-based coordinates, this lets scientists answer the kinds of questions that they typically ask - such as \"Have I seen this evolution before?\" and \"Is it similar to any experimental observations?\" The tools developed by this project will operate on distributed time-varying data and will act as templates for other methods. Specific technical objectives include developing distributed multi-resolution techniques for cataloging interesting phenomena and searching both run-time and archived data for interesting phenomena. The research will specifically target two domains that are representative of other scientific areas and have a pressing need for scientific mining tools: fluid dynamics (large-scale, high-accuracy Direct Numerical Simulation of compressible turbulence) and oceanography (comparison of simulation data with acoustic observations of hydrothermal plumes).","title":"ITR: Associative Mining of Large Datasets","awardID":"0082634","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["183349","524497",140208,"558205"],"PO":["551992"]},"52693":{"abstract":"Christian Collberg<br\/><br\/>This research investigates four techniques for <br\/>the intellectual property protection of software:<br\/>watermarking, fingerprinting, obfuscation, and <br\/>tamper-proofing.<br\/><br\/>Watermarking and fingerprinting defend against <br\/>software piracy by embedding a copyright notice <br\/>or identification number into a program. This <br\/>asserts ownership and allows tracking of copyright violators. <br\/>Effective watermarks are unobtrusive, have high <br\/>data-rates, and are resilient to de-watermarking attacks.<br\/><br\/>Obfuscation defends against malicious<br\/>reverse engineering by transforming a program into <br\/>an equivalent one that is harder to analyze. <br\/>Effective obfuscating transformations are<br\/>semantics-preserving, have low computational<br\/>overhead, and are based on intractable problems<br\/>that prevent them from being undone.<br\/><br\/>Tamper-proofing causes a program to malfunction when it <br\/>detects that it has been modified. Tamper-proofing code<br\/>can be added to an application to protect a watermark<br\/>from being removed, to prevent a virus from being added, <br\/>or to ensure that the security-sensitive code of an<br\/>e-commerce application has not been altered.<br\/><br\/>The goal of this research is to implement many of <br\/>the currently known algorithms for software <br\/>protection and to construct benchmarks against <br\/>which these techniques can be evaluated. An additional<br\/>objective is to build theoretical models that help to gain<br\/>a deeper understanding of the limits of intellectual <br\/>property protection of software.","title":"Software Watermarking, Obfuscation, and Tamper-Proofing for Software Protection","awardID":"0073483","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["550175"],"PO":["551992"]},"54772":{"abstract":"This is the first year funding of a three-year continuing award. A demanding application area of virtual or augmented environment is multi-user collaborative environment where multiple users at either a local site or remote sites communicate with each other and interact with a synthetic or virtual scene. Among the necessary sensors and devices, an effective visualization device and a real-time image acquisition system are two main challenges. The objective of this project is to develop a novel visualization device referred to as head-mounted projective display (HMPD), build a multi-user interactive workbench by integrating the developed HMPD technology with a unique real-time image acquisition system known as an omni-focus camera, and evaluate and quantify the system as an effective tool for remote collaboration. The head-mounted projective display (HMPD) proposed is coupled with a supple, non-distorting and durable projection surface as an alternative to current visualization devices. Its novel concept suggests solutions to part of the problems of state-of-art visualization devices, such as large distortion with wide field of view, occlusion contradiction between virtual and real objects, and brightness conflict with background illumination. Several properties of the proposed HMPD make it extremely suitable for multiple-user collaborative applications. Research efforts will be made to design and implement a lightweight and compact head-mounted prototype by introducing diffractive optical element (DOE) and plastic materials, and investigate approaches to optimize the illumination of the display and retro-reflective material properties for imaging purpose. At one site, a multi-user interactive bench prototype with tele-presence capability will be built by using the HMPD concept and adding an image acquisition system developed from a unique omni-focus camera system. At the other site, a mural display system will be built with conventional stereoscopic video system located near the mural display, where one or several collaborators will also gather. Tele-collaborative work will be tested between the Beckman Institute at the University of Illinois--Urbana Champaign and the School of Optics-CREOL at the University of Central Florida through the Internet II connection linking our laboratories. Finally, the PIs will quantify the depth and size representation and perception accuracy, evaluate occlusion perception aspects, and set up a comprehensive calibration procedure for the HMPD and the workbench and mural prototypes. The results are expected to impact a wide range of applications such as collaboration\/tele-collaboration, tele-presence, tele-manipulation, and visualized education\/tele-education.","title":"ITR: Collaborative Research: Development of Head-mounted Projective Displays for Distance Collaborative Environments","awardID":"0082016","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["561621"],"PO":["565227"]},"54893":{"abstract":"EIA-0082771<br\/>Walters, Deborah<br\/>SUNY at Buffalo<br\/><br\/>ITR: Women-Friendly Environments for Learning Information Technology<br\/><br\/>There is currently an unsatisfied national demand for people trained in<br\/>information technology (IT) with a minority of the students enrolled in IT<br\/>programs being female. The proposed project is to develop an educational<br\/>approach that will appeal to women and provide them with an appropriate<br\/>learning environment for IT courses. There are four components to the<br\/>project. First, will be efforts to build upon results of investigations on<br\/>how to use technology to increase learning and decrease costs as taught<br\/>within an IT fluency course. Second, will be research on learning styles<br\/>to provide quantitative evidence to explore the validity of learning styles<br\/>in general, and the consistency of women's learning styles, particularly,<br\/>correlations between learning styles, learning environments and<br\/>performance. Third, will be research on how to improve Web-based<br\/>collaborative experiences. Fourth, will be the testing of findings through<br\/>comparisons of learning achieved in a traditional environment with learning<br\/>in an environment restructured to take into account the project's findings<br\/>and those of other researchers in the field. The specific application of<br\/>the project will be the development an a women-friendly information design<br\/>and technology undergraduate certificate program that is accessible to<br\/>students of any major. The introductory courses of the certificate program<br\/>will be designed so that students can move easily into either a traditional<br\/>computer science or media studies program.","title":"ITR: Women-friendly Environments for Learning Information Technology","awardID":"0082771","effectiveDate":"2000-09-01","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[140271,"496273",140273],"PO":["564181"]},"55641":{"abstract":"The emergence of new applications has fostered a number of attempts to add functionalities to the minimalist Internet core. However, the adoption of enhancements to the Internet has either been slow, failed entirely, or limited to special-purpose private networks. The key reasons for this failure are extensibility and scalability: First, IP networks were not designed to be extensible at the internetworking level. Second, proposals for new network layer services often require that vast amounts of state information be managed in the core network infrastructure, thus, introducing scalability bottlenecks which exacerbate the existing scalability problem of the growing Internet.<br\/> Today, the development and deployment of advanced services on the Internet has reached a crossroads: efforts to add new services have quickly encountered scalability problems, yet new services are in critical demand and must be rapidly and widely deployed.<br\/> The research goal is to develop truly scalable services for each of the three fundamental components of the Internet's infrastructure: information communication, replication, and storage. Taking a new and unified approach to the seemingly conflicting requirements for scalability and sophisticated network services, the researchers propose to develop:<br\/> 1. Scalable Performance-Predictable Communication: a new foundation for quality-of-service communication via a scalable edge-based architecture.<br\/> 2. Scalable Multicast for Efficient Data Dissemination: a self-organizing multicast infrastructure scalable to many spontaneously-formed groups.<br\/> 3. Scalable Storage for Next Generation Information Services: an infrastructure which brings information<br\/>closer to users and enables scalable third-party information storage services.<br\/> 4. Design Principles of Scalable Services: a multi-faceted approach for the development and deployment<br\/>of scalable services in the global Internet, under consideration of economic models, industrial structure,<br\/>theories and algorithms, engineering, and deployment.<br\/> Thus, this project proposes to develop architectures and methodologies for deploying scalable services in the global Internet. The impact of this project will be to provide the theoretical underpinnings, basic architecture, and a prototype implementation for the information communication of the global Internet of the 21st century. An integral part of this project is the dissemination of results and the infiltration of standard organizations with the concepts developed within this project, and innovative approaches to educate the next generation of engineers for the future Internet.","title":"ITR: Collaborative Research: Scalable Services for the Global Network","awardID":"0085842","effectiveDate":"2000-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["548310"],"PO":["543507"]},"54673":{"abstract":"With the widespread dissemination of digital video, images, audio and other data on the Internet and other media, information protection and copyright protection have become areas of vital importance. These applications have generated an extraordinary level of interest in digital watermarking techniques in recent years. Whereas novel watermarking algorithms and novel ways to defeat them have been developed, fundamental principles of information theory have barely skimmed the surface of this field, and recent results by the PI have shown that existing schemes operate far below the ultimate achievable limits. We intend to develop our ideas for a theory of watermarking codes and to construct codes that approach capacity. We also plan to develop a closely related thrust of research on robust watermarking and authentication techniques for images and video. Our research will be guided by extensive body of knowledge (much of it developed in the last decade) developed in the context of modern communication systems on one hand, and image analysis on the other hand. Our plan is to explore the following topics:<br\/><br\/>Codes for Gaussian channels. We have recently derived closed-form solutions for the hiding capacity of channels involving Gaussian sources and squared error distortion metrics. Our first goal in this research is to develop codes whose performance approaches capacity for such channels. This model, in addition to being useful in the context of practical watermarking applications, will shed light on the fundamental issues involved in constructing watermarking codes. Hence its implications go beyond the particular model studied.<br\/><br\/>Estimation of Attack Channel Parameters. In blind watermarking applications, the decoder does not have access to the original data, and does not know the particular attack that may have been used to corrupt the data. Desynchronization attacks such as scaling, shifting, rotating or warping of image data can then be deadly. We will explore fundamental mechanisms for the decoder to estimate the parameters of such attacks.<br\/><br\/>Codes for arbitrary channels. While Gaussian channels are the worst channels under certain conditions, watermarking codes need to be robust against a variety of attacks. One of our goals is to develop codes and decoding techniques that perform well not only against Gaussian noise attacks, but also against desynchronization attacks, erasures, and other attacks.<br\/><br\/>Application to Image and Video Watermarking. While information theory and coding theory provide fundamental guiding principles to the design of watermarking systems, application of these principles presents unique challenges in specific situations such as image and video watermarking. These two applications will be investigated in detail.<br\/><br\/>Fingerprinting and Authentication Codes. There are several information-hiding problems closely related to watermarking that we intend to explore.<br\/><br\/> Many graduate students are interested in moving into such an attractive research area, which combines breadth and strong emphasis on fundamentals with practical relevance. We intend to train these students for leadership roles in information technology. We also plan to involve undergraduate students, as they find this subject to be a truly enjoyable learning experience.","title":"ITR: Theory and Design of Watermarking Codes","awardID":"0081268","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["518625","320975"],"PO":["564898"]},"56862":{"abstract":"Institution: University of Michigan<br\/>Proposal Number: EIA 0090006<br\/>PI: Sandra Gregerman<br\/>Title: Information Technology Pathways in Academe: Identifying Barriers for Women and Minority Students<br\/><br\/>This CISE Information Technology Workforce (ITW) proposal requests funds to study the factors that contribute to the small numbers of women and underrepresented minorities who obtain degrees in computer science (CS) and computer engineering (CE) at a major research university. Both quantitative and qualitative protocols will be used to determine why diverse students do not elect to follow academic career paths in CS and CE fields. Specifically, the project will consist of five parts: the Academic\/Career Pathways Study, the Student Perceptions and Perspective Study, the Student Beliefs and Attitudes Study, the Course-taking Pattern and Retention Study, and the Faculty Perceptions and Attitudes Study. The first four studies will also look at the influence of program interventions such as the Undergraduate Research Opportunity Program and the Women in Science and Engineering Residence Program. This project has the potential to provide valuable insights into the recruitment and retention of women and underrepresented minorities in IT majors.","title":"ITW: Information Technology Pathways in Academe: Identifying Barriers for Women and Students of Color","awardID":"0090006","effectiveDate":"2000-09-15","expirationDate":"2006-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["303970","537184","507869",146322],"PO":["564181"]},"54332":{"abstract":"This project examines the educational impact of computing and information technologies, both at school and in the home, for middle and high-school students. It investigates a second stage of the Digital Divide, one that goes beyond lack of access to information technology (IT). It examines whether there are different educational benefits to computing when comparing whites to minorities, boys to girls, and more affluent to poorer children. The research combines statistical analyses of survey data with fieldwork observations of children using computers at school, after-school programs, and at home. The goal of the research is to gain insight into the processes by which some children gain more than others in terms of educational benefits from computing. It seeks to document the educational benefits that are occurring, to identify what kinds of students are missing out on these benefits and why, and to identify what kinds of educational applications yield greatest benefits. This research is intended to aid policymakers who are concerned with equity issues in education, educators involved in providing effective information technology in schools, and to inform citizens about the educational consequences of the Digital Divide.","title":"ITR: The Educational Consequences of the Digital Divide","awardID":"0079976","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["529626",138749],"PO":["495796"]},"55663":{"abstract":"Research proposed here deals with the problem of reliable control of geographically distributed complex real-time systems over a heterogeneous communication network. It is aimed at developing thefoundations of network-based control, from theory to applications. The overall objectives are: <br\/><br\/> the design, analysis, implementation, and performance characterization of distributed and decen-<br\/>tralized control algorithms and middleware that are affected through hierarchical and heteroge-neous networks comprised of wired and wireless subnets, and<br\/> the specification and implementation of network services and support required for the development and deployment of distributed control algorithms over hierarchical heterogeneous networks, and demonstration of efficient and fault tolerant remote control using such networks for a number of emerging commercial and scientific\/engineering applications.<br\/>Our research agenda will cover the following domains:<br\/> Research toward a network based control theory that emphasizes and accounts for decentralized, distributed and delay aspects of information transmission dictated by speciffic network structures, and bandwidth limitations.<br\/> Basic research to leverage the latest developments in distributed robust fault-tolerant control, and to build a new theory for multifaceted control of remote objects over heterogeneous networks, using also the framework of dynamic games.<br\/> Development of dynamic and adaptive methods for representation of large systems and computation of associated control strategies, using of hierarchical, adaptive graphs and distributed agents.<br\/> Design and implementation of algorithms and middleware that will interact with the host-node communication protocols and provide the necessary support for the implementation of coordinated distributed control applications. Furthermore, design and implementation of an embedded real-time operating system kernel which will support hard deadlines and stringent QoS guarantees.<br\/> Development of a demonstration prototype to be deployed on a small-scale heterogeneous hierarchical network comprised of a wireless subnetwork and campus-wide nodes of local area and Internet hosts.<br\/>In addition to the development of new analytical paradigms and approaches, a component of the research program is the development of reusable simulation and design software, so that the research output can be parlayed to other researchers, practitioners, and industry. We envision numerous future scenarios where the results from this research program will apply. Among these are satellite control, air traffic control, congestion control over highways, remote guidance of airplanes, power networks, electronic commerce, and remote surgery.","title":"ITR: Hierarchical and Reconfigurable Schemes for Distributed Control over Heterogeneous Networks","awardID":"0085917","effectiveDate":"2000-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["483572","421048","456451","553663"],"PO":["564898"]},"54695":{"abstract":"The researchers propose to design, implement, analyze and evaluate mechanisms that will enable mobile clients to opportunistically exploit computing, data and communication resources in the fixed infrastructure to facilitate information access. A mobile client typically faces many resource challenges. These include unpredictable variation in wireless network quality; wide disparity in the availability of remote services; limitations imposed by weight and size constraints on CPU power, memory size and disk capacity; and concern for battery power consumption. The goal is to exploit remote infrastructure, such as transient caching sites or compute servers, to overcome these challenges. When such infrastructure is unavailable or would be too expensive or slow to access in terms of battery power or bandwidth, the researchers wish to be able to continue operation relying solely on local resources. The challenge is to come up with the adaptive mechanisms, algorithms and policies that can be effectively implemented on a resource-limited mobile client, yet function smoothly and seamlessly from a user's viewpoint. <br\/> The research will span both experimentation and analysis. On the one hand, the researchers plan to design, implement, and evaluate mobile computing systems embodying innovative solutions to the challenges described above. This will give the researchers the hands-on experience and insights needed to elucidate sound design principles for this domain. In parallel, the researchers plan to conduct an analytical and modelling effort to obtain a deeper understanding of fundamental tradeoffs in adaptation, and to explore a much broader region of the design space than feasible experimentally. <br\/> This effort will be organized into three major thrusts:<br\/> 1.Efficient file cache management for mobile clients<br\/> 2.Offloading computation for energy and bandwidth savings<br\/> 3.Modelling and analysis of adaptation tradeoffs<br\/> In the first thrust, the researchers plan to explore the use of intermediate caching sites in the infrastructure to improve the efficiency of cache management in mobile file systems. The importance of caching for mobile information access is widely acknowledged, but what specific form it should take in the mobile systems of the future remains an open question. In the second thrust, the researchers will explore techniques for mobile clients to adaptatively offload computation on servers in the infrastructure. Such offloading may be useful for improved performance as well as enhanced battery life. In the third thrust, the researchers will analytically investigate a wide range of policies for the mechanisms developed in the other thrusts. The mobile computing systems of the future are likely to encounter considerable variability in environmental conditions, user preferences, and application characteristics. Characterizing this large multi-dimensional space analytically, and understanding its implications for alternative policies will be critical to the development of successful systems.<br\/> If successful, the research will bring mobile computing one step closer to reality. Although commercial deployment of mobile computing systems is an enormous potential market for industry, many difficult technical problems remain to be solved. Incremental efforts by industry to extend today's widely-deployed commercial off-the-shelf systems to mobile environments will not solve these problems. The researchers proposed effort, combining experimentation and analysis on a key set of challenging problems, thus represents a high-risk, high-payoff venture.","title":"ITR: Exploiting Remote Infrastructure for Mobile Information Access","awardID":"0081396","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["555524","475390"],"PO":["543507"]},"55674":{"abstract":"Collaboratories are new organizational forms to help scientists who are geographically dispersed to work closely together. A number of collaboratories have been built, and their successes and failures have been due to a combination of technical and social factors not yet fully synthesized. This project will define, abstract, and codify the underlying technical and social mechanisms that lead to successful collaboratories. It will provide the vocabulary, associated principles, and design methods for propagating and sustaining collaboratories across a wide range of circumstances. This project will enhance both the practice of science and the training of new scientists. These goals will be achieved through three coordinated activities: (1) The qualitative and quantitative study of collaboratory design and usage, examining both technical and social aspects of performance; (2) creation and maintenance of a Collaboratory Knowledge Base, a Web-accessible archive of primary source material, summaries and abstracts, and relevant generalizations and principles, a database of collaboratory resources, and other related material; and (3) the abstraction and codification of principles, heuristics, and frameworks to guide the rapid creation and deployment of successful collaboratories, including principles of design or customization.","title":"ITR: Sustainable and Generalizable Technologies to Support Collaboration in Science","awardID":"0085951","effectiveDate":"2000-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["551830","551829","209323","498457","397790"],"PO":["564456"]},"55685":{"abstract":"This project will develop a formal, but practical information technology infrastructure to make government regulations more effectively available to the public. The topic area is hazardous waste management. Federal and California state environmental protection agencies will be engaged in the project. The infrastructure to be developed will include distributed data repositories, and also tools to locate, merge, compare, and analyze the information. Project phases are 1) textual storage, 2) semi-structured indexed storage, 3) means to resolve semantic ambiguities, 4) cross-referencing appropriate for automated access from relevant legal documents, and 5) on-line compliance checking of government regulations. This is an interdisciplinary project with the involvement of experts in law, computer science, and civil\/environmental engineering.<br\/><br\/>=================================================","title":"ITR\/IM-SII: A Distributed Information Management Framework (REGNET) for Environmental Laws and Regulations","awardID":"0085998","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}}],"PIcoPI":[142729,"370768","540494",142732],"PO":["371077"]},"41055":{"abstract":"Many high schools use graphing scientific calculators to assist students in math and science courses. These calculators perform scientific functions and have a built-in screen to display graphs. These calculators are used widely in higher math (Algebra and beyond) and science courses. They are valuable tools both for teachers and students. Unfortunately, the graphing scientific calculators are not usable by visually impaired students. This project will attempt to design, develop, and test a system, which provides better access for visually impaired students to graphs and scientific expressions.<br\/> The Haptic Audio Scientific Graph Analysis Project (HASGAP) involves research, development, and testing. Real time, interactive, independent comprehension of two-dimensional graphs by visually impaired students is the goal of the project. This project will increase the knowledge base in interactive graph analysis and interactive scientific calculation research for visually impaired people. <br\/> The force feedback WingMan Mouse from Logitech will be used. This is a haptic two-dimensional mouse that became commercially available in January 2000. Automated Functions, Inc. (AFI) has been using the prototype WingMan Mouse that was designed and developed by Immersion Corporation and called the FEELit Mouse for the past 1.5 years. AFI was a beta tester of the FEELit Mouse and suggested many functions that were placed in the commercial WingMan Mouse product. The price for the WingMan Mouse is only $100. This is significant to HASGAP since the WingMan is a vital part of the system which includes custom PC software, synthetic speech, stereo sound, and the haptic WingMan Mouse. <br\/> The WingMan Mouse will be used as the graph input peripheral. Stereo sound will be used to represent the graph(s). AFI will design, develop, and test different haptic effects in order to increase the ability of the visually impaired user to comprehend two-dimensional graphs. <br\/> The researchers will design and develop custom software that runs on a PC using Windows 98, the operating system platform supported by the WingMan Mouse. The speech and sound will be created using an internal sound card to augment the haptic feedback provided by the WingMan Mouse. <br\/>HASGAP uses a screen reader to speak what is typed and to verbalize the different menu options and graphic controls. The system has been designed and developed around the Henter-Joyce JAWS For Windows screen reader. Other screen readers will be tested with HASGAP to assure compatibility. <br\/> The project will be field tested by visually impaired students who attend a local Virginia school system. <br\/> If HASGAP is successful, visually impaired students will be able to interpret graphs and perform scientific calculations independently. This project may significantly affect the ability of visually impaired students to succeed in math and science courses.","title":"PPD: Haptic Audio Scientific Graph Analysis Project (HASGAP)","awardID":"9906143","effectiveDate":"2000-09-01","expirationDate":"2001-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6846","name":"UNIVERSAL ACCESS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1106","name":"Division of HUMAN RESOURCE DEVELOPMENT","abbr":"HRD"},"pgm":{"id":"1545","name":"RES IN DISABILITIES ED"}}],"PIcoPI":[103939],"PO":["565049"]},"55696":{"abstract":"Asynchronous (or clockless) circuits have become the focus of renewed interest because of their potential to alleviate a number of challenging problems in future-generation chip design: clock distribution, power management, and design reuse. To overcome the limitations of current asynchronous design methodologies, this project is developing an automated CAD framework for the synthesis and optimization of large-scale asynchronous systems. In addition to basic high-level scheduling, binding and allocation, and Hardware Description Language support (Verilog HDL), the project is exploring the open and challenging problems of: (a) high-performance pipeline synthesis and optimization; (b) architectural exploration (targeted to the frequent common-case operations); (c) distributed controller synthesis and optimization; (d) system-level performance and power analysis; and (e) the synthesis of mixed asynchronous\/synchronous systems. The tool framework is being applied to a number of commercial examples and validated through chip design, fabrication, and test.","title":"ITR: A CAD Framework for the Design and Optimization of Large-Scale Asynchronous Digital Systems","awardID":"0086036","effectiveDate":"2000-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["518562","485748"],"PO":["562984"]},"53287":{"abstract":"This research will investigate a theoretical foundation for a major responsibility of enterprise systems to ensure that the right information about the enterprise is available to decision makers at the right time. The Internet and e-commerce are rapidly creating an environment in which businesses can be usefully likened to organisms which must tap into the relevant features of their environments to make rapid life\/death decisions-where even what is relevant is continually in flux. The primary focus of this project is to formulate an approach to incorporating flexibility in connecting decision-makers (brain) to dynamically relevant data sources (internal and external environment) to support time-critical decisions. Within this framework, the research will study the application of model-driven data acquisition, filtering and attention mechanisms to achieve flexible sensor-to-decision maker connectivity.<br\/><br\/>Enterprise resource planning (ERP) systems are a response to the realization that manufacturing control systems cannot function in isolation from other major enterprise functions. The objectives of ERP systems should also include standardization of principal functional modules to minimize customization and enhance reusability. The ultimate result of this research would be a framework for scalable enterprise system development that does not constrain the continued development of the framework as would a pure software code-based approach. Based on a mathematical formalism, the modules developed would not be bound to any one technology but would be amenable to transition to scalable network infrastructures as they evolve. The development of a model-based framework for goal-driven data delivery could ultimately guide the design of scalable data management as well as other standardized modules in flexible corporate enterprise systems.","title":"Scalable Enterprise Systems: Discrete Event System Specification (DEVS) as a Formal Modeling Framework for Scaleable Enterprise Design - Case Study: Model-Driven Data Management","awardID":"0075557","effectiveDate":"2000-09-01","expirationDate":"2001-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"5376","name":"INNOVATION & ORG SCIENCES(IOS)"}}],"PIcoPI":["524966"],"PO":["210331"]},"48821":{"abstract":"This project proposes to develop efficient network- and application-aware data-driven communication and synchronization primitives for geographically distributed computing clusters connected over dynamically configured non-uniform bandwidth links. Synchronization and communication primitives are the backbone of any non trivial parallel computation and performance in cluster systems crucially depends on the efficiency of such primitives. The goal is to effectively incorporate diverse and dynamically varying network characteristics into the proposed solutions while taking advantage of the application characteristics. The solutions will be based on methods that detect and limit avoidable congestion and hotspots. The techniques employed will include collecting global information, sampling, and randomization. Examples of synchronization primitives to be investigated include barrier, eureka, and termination synchronizations for different application-motivated models. Data-driven communication primitives include data-dependent forms of many-to-many broadcast, multicast, and many-to-many transport operations. The experimental aspects of the proposed research will be carried out on a collection of high performance computing clusters and platforms spread across Purdue University, University of Illinois at Chicago, and NSF\/DOD sponsored HPC centers, interconnected via different bandwidth links in the Internet. Data-intensive applications such as data mining\/warehousing and multimedia will be used as a vehicle to study data-driven synchronization and communication issues. The proposed work will facilitate the design of such parallel applications on cluster systems.","title":"Data Driven Communication and Synchronization in Non-Uniform Bandwidth Computing Clusters","awardID":"9988339","effectiveDate":"2000-09-01","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["425109"],"PO":["209879"]},"48832":{"abstract":"Abstract<br\/><br\/><br\/>PI: Marek Chrobak<br\/>Proposal Number: 9988360<br\/>Institution: University of California-Riverside<br\/><br\/><br\/><br\/>Optimization problems that arise in practice are often inherently (online); that is, the input data is not available prior to computation but, instead, is given as a sequence of requests each of which must be served before the next one is received. A classical example is the (catching) problem in two-level memory systems. Modern computer architectures enhance memory performance by storing the most frequently accessed data items in a cache, which is a small buffer memory with very short access time. When a requested item r is not in the cache -- an event referred to as a (fault) -- the caching algorithm stores r in the cache. If the cache is full, the algorithm needs to decide which item to evict from the cache to make room for r. This decision is made (online), without the knowledge of future requests. Naturally, the goal is to minimize the number of faults. <br\/><br\/>Due to incomplete information, online algorithms cannot, in general, compute optimal solutions. This brings up the issue of performance evaluation: how do we tell good algorithms from bad ones? One measure of the quality of online algorithms is their (competitive ratio), defined as the maximum, over all request sequences, and of the ratios between the solution computed by the online algorithm and the optimal (offline) solution. Thus, an algorithm with competitive ratio, says, 1.5, always computes a solution that is within 50% of the minimum. <br\/><br\/>This research deals with the competitive analysis of online algorithms and is divided into three projects. The first project is to study several known, specific online problems, including the k-server problem, file caching, and others. The objectives of this work are to develop efficient competitive algorithms for these problems and to establish matching lower bounds on their competitive ratios. More fundamental issues in competitive analysis are addressed in the second project. The main focus here is on the techniques for the design and analysis of online algorithms. The most promising, emerging ideas in this direction include the work-function algorithm (and its extensions) and the primal-dual method. Both of these techniques, as well as some other, have been successfully applied to specific online problems, but the mechanism behind their success is still poorly understood, and they still require an in-depth study to determine their applicability to other problems. The third project is to explore some extensions of the competitive analysis that have been recently introduced for the caching problem: access graphs, diffuse adversaries, and loose competitiveness. In addition to work on some remaining open problems in this area, this project will also focus on adapting these new models to online problems other than caching (for example, file migration), and, if appropriate, on designing and studying other problem-specific models.","title":"On-Line Competitive Algorithms","awardID":"9988360","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"5977","name":"AMERICAS PROGRAM"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"5979","name":"CENTRAL & EASTERN EUROPE PROGR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["517719"],"PO":["543507"]},"57797":{"abstract":"The field of information hiding includes steganography, where a message is concealed in another data stream, and watermarking, where ownership data is included in a digital object to be protected. A third field of information hiding is the field of data embedding, wherein additional information is incorporated in the transmitted data stream by using a key and distorting (slightly) the original object. The embedded information cannot be reconstructed without the key. We propose an entirely new approach to data embedding based upon the method of types and universal receiver design. In our approach, a new data sequence is embedded in the original data stream using the method of types, and the embedded data is extracted using a type-based universal receiver. The choice of type and rate for the embedded data is based upon an analysis of portions of the original data stream. The universal receiver learns the type from the received data alone, and hence, there is no side information as in previous data embedding techniques. The embedding process and the receiver are both data adaptive, so the original data stream can be reconstructed without error.<br\/><br\/>We investigate the fundamental limits of this approach to data embedding by analyzing the characteristics of the original data stream that facilitate data embedding, by studying which techniques allow the highest data rates to be embedded, and by examining the tradeoffs between embedded data rate and errors in the embedded data. This approach to data embedding offers the possibility of expanding the delivered data rate of many existing telecommunications links, both wired and wireless, without changing allocated bandwidths.","title":"Data Embedding, the Method of Types, and Universal Receivers","awardID":"0093859","effectiveDate":"2000-09-01","expirationDate":"2002-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["410030"],"PO":["564898"]},"49701":{"abstract":"The Dublin Core metadata process began in 1995 and has brought together a multidisciplinary spectrum of practitioners and theoreticians to address issues related to standards for resource description of electronic resources on the internet.<br\/><br\/>Progress in metadata definition and standards adoption is critical to building large scale, distributed digital libraries. Metadata is essential to providing contextual data through which information objects gain meaning and usability. The Dublin Core metadata process has been particularly successful in defining the metadata agenda and building international consensus. It has spawned projects incorporating its basic element sets in about 25 countries, covering numerous disciplinary subject materials.","title":"Workshop: Dublin Core Metadata Initiative Workshop Support","awardID":"0000628","effectiveDate":"2000-09-15","expirationDate":"2001-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6857","name":"DIGITAL LIBRARIES AND ARCHIVES"}}],"PIcoPI":[127055],"PO":["433760"]},"54299":{"abstract":"EIA-0079871<br\/>Dimotakis, Paul E.<br\/>California Institute of Technology<br\/><br\/>MRI: Development of the Distributed Teravoxel Data System: Acquisition, Networking, Archiving, Analysis, and Visualization<br\/><br\/>This project addresses the problem of handling very large datasets through the development of generic acquisition and processing capabilities to be hosted at Caltech and made available to both Caltech and outside collaborators. Driven by investigations of flow turbulence, the project is designed to handle both laboratory and numerical-simulation data. The infrastructure will support analysis and visualization of terascale experiment or simulation datasets and their comparison to validate theories and simulation results.","title":"MRI: Development of the Distributed Teravoxel Data System: Acquisition, Networking, Archiving, Analysis, and Visualization","awardID":"0079871","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[138666,138667,"140656","285304","453840"],"PO":["557609"]},"48877":{"abstract":"PI: Lutz, Jack<br\/>Proposal Number: CCR-9988483<br\/>Institution: Iowa State University<br\/><br\/>Abstract<br\/><br\/><br\/>This project will investigate measure-theoretic and information-theorectic aspects of central questions in computational complexity. Resource-bounded measure will be axiomatized using higher-type complexity theory and will be extended to low-complexity (including finite-state) classes and function classes. A variety of information-theoretic tools, including Shannon entropy, Kolmogorov complexity, and instance complexity, will be studied and applied in conjunction with measure to investigation in average-case complexity, completeness and weak completeness, derandomization, and propositional proof systems. Weak completeness will be a major focus, especially in connection with natural examples and derandomization. The explanatory power and reasonableness of the hypothesis that NP does not have p-measure 0 will be further be examined. Related aspects of information and complexity that will investigated include computational depth and its variants, efficient algorithms for betting successfully on unpredictable data, and the feasible effectivization of classical results in probability, stochastic processes, and information theory. The project will involve students and other young investigators in progress toward the long-term objective of a greater synthesis between information theory and the theory of computing.","title":"Measure and Information in Computational Complexity","awardID":"9988483","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["531355"],"PO":["543507"]},"69568":{"abstract":"","title":"CAREER: Automated Analysis of Security and Fault-Tolerance of Distributed Systems","awardID":"0196456","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["531979"],"PO":["564388"]},"48888":{"abstract":"The rapid growth in the number of experimentally determined protein structures has accentuated<br\/>the need for theoretical and computational methods that can make this data useful. The proposed<br\/>research aims to provide tools for important applications in computational molecular biology, such<br\/>as protein engineering and structure-based drug design, as well as scientific explorations of<br\/>structure-function relationships. This goal can be achieved through the ability to predict the<br\/>conformational changes that occur when proteins and ligands interact. Protein engineering to alter<br\/>enzyme specificity or to enhance stability under adverse conditions can also benefit from a<br\/>predictive understanding of the motions involved in protein folding, unfolding, and catalysis. An<br\/>attack on this wide range of challenging problems requires algorithmic breakthroughs, enormous<br\/>computing power, and powerful techniques for visualization.<br\/><br\/>Computational molecular biology uses information at the atomic level to study biologically<br\/>relevant phenomena. Interpolating from the behavior of individual atoms to the collective behavior<br\/>of complex biological molecules such as proteins presents a significant theoretical and<br\/>computational challenge. Unfortunately, the available computational methods to study protein<br\/>dynamics over long ranges of time are far from satisfactory due to a number of severe difficulties,<br\/>including: (1) The time scales involved in theoretical\/computational prediction span an enormous<br\/>range: about fifteen orders of magnitude. (2) The conformation space of relevant protein shapes has<br\/>very large dimension (> 10000) and the corresponding energy functions are quite jagged, making<br\/>calculations expensive and difficult. (3) Algorithms for comparing\/manipulating molecular shape<br\/>are expensive in terms of both implementation difficulty and computational time.<br\/><br\/>To resolve these difficulties the investigators are applying a variety of ideas centered on the<br\/>theme of multiscaling: for time scales, for energy landscapes, and for measuring structural<br\/>similarity at different levels of resolution. Algorithm development in the proposed area requires a<br\/>unique blend of interdisciplinary expertise that is found within this team of investigators. The team<br\/>includes a theoretical chemist who is an expert in protein dynamics, a theoretical physicist who is an<br\/>expert in molecular biology and biophysics, and three computer scientists who bring expertise in<br\/>geometric and combinatorial algorithms at both theoretical and experimental levels. This combined<br\/>expertise is reinforced by a supportive interdisciplinary environment and excellent parallel<br\/>computing resources.<br\/><br\/>This research has three primary goals: (1) to broaden the range of time-scales for which<br\/>meaningful Molecular Dynamics simulations of proteins are possible; (2) to improve our<br\/>understanding of protein conformation space and the associated energy functions through the use<br\/>of hierarchical multiscaling techniques; and (3) to enable the processing of proteins-as-shapes to<br\/>proceed as easily as proteins are now processed as strings (over the 20-symbol alphabet of amino<br\/>acids). Advances in these areas will significantly improve protein understanding, allowing<br\/>computational experiments involving protein dynamics over wide ranges of time. Such improved<br\/>computational abilities can potentially lead to important advances in the understanding of biology<br\/>and the design of medicinal drugs.","title":"Multiscale Hierarchical Analysis of Protein Structure and Dynamics","awardID":"9988519","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["309332","517321",125136,"450550"],"PO":["321058"]},"49625":{"abstract":"EIA-0000433<br\/>Betty H. Cheng<br\/>Michigan State University<br\/><br\/>TITLE: Meridian: An Integrated Toolkit for Developing Interactive Distributed Applications<br\/><br\/>The proposed project involves the integration and validation of MERIDIAN, a collection of tools designed to help automate the development of IDAs. Collectively, these tools will support diagram-based modeling, rigorous correctness analysis, software reuse, automated code generation, and software visualization. Moreover, they will interact with one another through explicit design representations with formally defined semantics, enabling requirements to be traced from high-level models to low-level code.<br\/><br\/>Interactive distributed applications (IDAs) are those that involve direct interaction with users and whose processing and data components are distributed across a network. Examples of IDAs include distributed data management systems, on-board driver\/pilot navigation assistance systems, computer-supported cooperative work environments, distance education tools, and a variety of public safety systems. The increasing interest in IDAs is fueled by several factors, including the advent of the World-Wide Web, the development of new middleware technologies, the introduction of scripting languages for graphical user interfaces, and the availability of new network services and protocols.","title":"Experimental Partnership - Meridian: An Integrated Toolkit for Developing Interactive Distributed Applications","awardID":"0000433","effectiveDate":"2000-09-15","expirationDate":"2007-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4725","name":"EXPERIMENTAL SYSTEMS\/CADRE"}}],"PIcoPI":["531512","472159","543568","332348"],"PO":["564388"]},"49537":{"abstract":"Recent development in parameterized complexity theory has revealed abundant sophisticatd local solution structures for many intractable combinational optimization problems. Techniques and results developed in the area have given rise to the consideration that these solution structures can be closely related to neighborhoods in local search heuristics. This project is to investigate such a relationship and, based on which, to develop innovative techniques for the design of effective local search: computational complexity and performance guarantee.<br\/><br\/>Parameterization on neighborhoods is introduced to scrutinize the relationship between neighborhoods and the computational complexity of local search algorithms. This approach will essentially show what quantities in a sophisticated neighborhood make the algorithms converge fast. It is also expected to demonstrate how difficult in terms of complexity to improve the effectiveness of a simple neighborhood. A systematic technique is also investigated to derive neighborhoods from existing techniques used in parameterized tractibility. This will result in a general framework for the design of effective local search algorithms for various parameterized tractable optimization problems.","title":"Local Search via Parameterizations","awardID":"0000246","effectiveDate":"2000-09-01","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["409364"],"PO":["528421"]},"48228":{"abstract":"The researchers envision that within the next few years mobile and wireless access to the Internet will very likely become the norm, rather than the exception as is seen today. This proposal describes the plans to develop and deploy iMASH, a network system that supports anytime, anywhere, on any platform access to the electronic patient records database for healthcare providers. The objective is to provide the capability for real-time, multimedia communication, so that a physician may access, on the move, the patients record and other relevant information as filtered by the physician's user profile, and may migrate ongoing application sessions seamlessly to different platforms that range from a high performance diagnostic workstation in the physician's office to hand held PDAs in the examination room. While the proposed techniques are general and extend to a range of mobile applications, the specific target of this project is healthcare applications. To this end, the researchers will develop a clinical testbed, which will serve as a laboratory for developing, testing, and evaluating advanced information technology in the context of patient care. The testbed will provide the user requirements to drive the iMASH architecture design, and will permit direct, realistic validation of the research results.<br\/> The researchers expect to make the following contributions from this research and development effort:<br\/> 1) Development of a middleware infrastructure that provides support for anytime, anywhere, on any platform access to the Internet<br\/> 2) A suite of wireless networking protocols and algorithms that provide quality of service support in a mobile, heterogeneous networking environment<br\/> 3) A deployment of iMASH within the UCLA Medial School and a controlled study to evaluate its effectiveness in reducing healthcare costs and improving physician effectiveness<br\/> 4) A system emulation capability that can be used to evaluate the performance and scalability of the middleware services and protocols across multiple dimensions including number of users, number of devices, types of applications, and geographical area. The emulator will be used to 'test drive' novel protocols and applications prior to deployment on the physical testbed.<br\/> The researchers have assembled a strong research and development team to undertake the iMASH effort. The team possesses the necessary expertise in the related areas of networking (Zhang, Gerla), wireless communications (Gerla, Lu), parallel and distributed systems (Bagrodia, Gerla), performance evaluation (Bagrodia), computerized medicine (Valentino, McCoy), clinical evaluation of technological innovations in improving heath care (Fiske), and campus computing and communication technology (Solomon).<br\/> A longer term goal of this effort is to deploy iMASH-like technology widely within the UCLA campus to support ubiquitous multimedia access for students and faculty, and to support wireless distance education. To enable appropriate technology transition, the team also includes two key members from the university administration: the CIO for the medical school (McCoy) and the Associate Vice-chancellor of Administrative Services with line responsibility over campus telecommunications (Solomon). The UCLA Hospital has recently embarked on a historical reconstruction with a $1 billion endowment. An integral part of the reconstruction is availability of complete wireless connectivity within the hospital. The UCLA campus is also engaged in a project to upgrade the network connectivity throughout the campus with the aim of providing a minimum of 10Mbps bandwidth from desktop to desktop within any two locations on campus. Planning is underway to further enhance this capability with wireless connectivity. These two technology initiatives provide a unique opportunity to insert the iMASH technology in widespread use within the UCLA campus, and subsequently to other locations.","title":"iMASH: Adaptive Middleware and Networking Support for the Nomadic Healer","awardID":"9986679","effectiveDate":"2000-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["231158","558959",123263,"543560","451118"],"PO":["250082"]},"54740":{"abstract":"X-ray crystallography is a fundamental technique for determining the structure of proteins. However, the physics of this process means that information about the relative phases of the thousands of x-ray beams used in the process is lost. The recovery of phases is referred to as \"phase retrieval.\" Essentially all modern algorithms for phase retrieval are iterative, including the well-known \"Shake and Bake\" algorithm. However, a general problem with iterative approaches is that the iterates are drawn to attractors that are not true solutions. This project will investigate a significantly different, non-iterative approach that does not share this drawback. If successful, the result will be a computing environment that will benefit a variety of disciplines that engage in phase retrieval.<br\/><br\/>The new algorithm exploits techniques in optimization theory that have never been used in phase retrieval before. One key idea is to use a different objective function from past approaches: the zero-frequency component, or \"charge\" Q. A key property of Q is linearity, which avoids the many local minima that stagnate iterative methods for other objective functions. In the language of optimization theory, the objective function Q permits a direct translation of the phase retrieval problem into a mixed-integer program (MIP). Decades of research on solving MIPs can thus be applied to solve difficult instances of phase retrieval encountered in crystallography.","title":"ITR: Phase Retrieval Algorithms","awardID":"0081775","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["291821"],"PO":["551992"]},"54630":{"abstract":"Despite impressive gains in realism over the last decade, computer graphics is currently unable to effectively generate images of objects and environments that look large. This is mostly because computer graphics is poor at conveying information about absolute depth. The goal of this project is to demonstrate that it is possible to significantly improve the sense of depth and scale in computer graphics if rendering methods are developed with specific attention to the need to convey cues for absolute depth. Accomplishing this goal will require new insights into the 3D information extractable from 2D images, modifications to graphics algorithms in order to better render salient information, and sophisticated perceptual experimentation to validate that people can actually see the intended 3D space. The PI's approach will be to draw upon the results and methods of computational vision in ways that have not previously been done in the computer graphics community. Computational vision provides insights into the intrinsic constraints on how information about 3D space can be recovered from 2D images. In particular, the computational analysis of vision points out the important distinction between relative depth judgments and absolute depth judgments. Surprisingly few of the commonly studied image cues are in fact sufficient to provide information about absolute depth. Of those that do, several cannot be exploited in computer graphics due to fundamental limitations in display technology and our inability to precisely control viewing conditions except in immersive environments. The research will impact a broad range of graphics applications in which accurate spatial information needs to be conveyed, including education and training, design and prototyping, and telepresence.","title":"ITR: Collaborative Research: Generating an Accurate Sense of Depth and Size Using Computer Graphics","awardID":"0080986","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["291712"],"PO":["564456"]},"54872":{"abstract":"EIA-0082635<br\/>Williams, Ronald<br\/>University of Virginia<br\/><br\/>ITR: Security Education in Embedded Computing<br\/><br\/>Education and research will be tightly coupled as this effort focuses upon<br\/>security in networked embedded computer systems. The vulnerability of<br\/>networked computers to malicious or mischievous attack has become apparent<br\/>with several recent incidents. With the present trend to connect more<br\/>embedded systems to global networks, security is a growing concern. The<br\/>investigators on this project seek to identify aspects of well-studied<br\/>embedded computing characteristics that can be extended and applied to<br\/>issues of security. <br\/><br\/>The primary objectives of this work are to develop a theoretical foundation<br\/>for embedded system security and to expand the base of security education<br\/>for computer engineers. The theoretical foundation will build upon the<br\/>body of knowledge developed over past decades in availability, reliability,<br\/>and safety research. Educational modules will be made available and can be<br\/>used in the future to form the basis for a more extensive educational<br\/>program in this area. The potential impact of this effort will include a<br\/>significant increase in the sensitivity to embedded system security issues<br\/>among those computer engineers who participate in the project or are<br\/>exposed to the educational modules. Further, new applications of existing<br\/>techniques will improve the evaluation and design of embedded systems to<br\/>include security considerations. Both of these impacts are significant to<br\/>increase the integrity of networked embedded computer systems.","title":"ITR: Security Education in Embedded Computing","awardID":"0082635","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["229722","385689"],"PO":["564318"]},"54641":{"abstract":"A typical auditory scene contains multiple simultaneous events, and a remarkable feat of the auditory nervous system is its ability to disentangle the acoustic mixture and group the acoustic energy from the same event. This fundamental process of auditory perception is called auditory scene analysis. Of particular importance in auditory scene analysis is the separation of speech from interfering sounds, or speech segregation. Speech segregation remains a largely unsolved problem in auditory engineering and speech technology. In this project, the P1 seeks to develop a dynamics-based system for speech segregation using perceptual and neural principles. Auditory grouping will be based on oscillatory correlation, whereby phases of neural oscillators encode the binding of auditory features. The investigation will consist of subsequent stages of computation, starting from simulated auditory periphery composed of cochlear filtering and hair cell transduction. A mid-level representation will be formed by computing auto- and cross-correlation of filter channels. A stage of segment formation then creates individual elements of a represented auditory scene, each of which is a dynamically evolving, connected time-frequency structure that may overlap with other elements. Operating on auditory segments from the segment formation stage, both simultaneous organization and sequential organization will be incorporated. For simultaneous organization, grouping will be based on periodicity, location, onset and offset analyses, while for sequential organization grouping will be based on pitch, spectral, and location continuities. In particular, two pitch maps corresponding to two ears and one location map will be computed for auditory organization. All of the employed grouping cues are consistent with perceptual principles of auditory scene analysis. These cues guide the connectivity of neural oscillator networks, which perform grouping and segregation of auditory segments. The proposed system will be evaluated using real recordings of speech and interfering sounds, where speech can be both voiced and unvoiced. The success of the system will be quantitatively assessed using two measures: changes in signal-to-noise ratio and speech recognition rate. This project is expected to make significant contributions to automatic speech recognition in unconstrained environments.","title":"ITR: Dynamics-based Speech Segregation","awardID":"0081058","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["290043"],"PO":["246649"]},"54762":{"abstract":"This is the first year funding of a three-year continuing award. This project aims at addressing basic issues for enabling an augmented reality interface using computer vision. Augmented Reality has the goal of enhancing a person's perception of the surrounding world, offering the potential for the computer to be integrated into the activities of a user, serving as a personalized helper. There are two key challenges to enable such an interface. The first is \"sensing\", which would allow the augmentation to be matched to the state of the world as the user interacts with it. The second challenge is that of developing systematic \"augmentation schemes\" that result in user-centered information flow. To aid in the conceptualization of the problem and for experimental verification, the main focus of the project is on an \"assembly domain\". The context is that of a human engaged in assembling a mechanical object from its components. The focus on the \"assembly domain\", allows us to suitably formulate and address the sensing, augmentation, and other issues in the novel human-computer interface. At the same time, it allows us to examine specific interactive assembly tasks using augmented reality, such as guiding and training during assembly and for evaluation of prototype assembly sequences. To address the key problem of tracking the \"context\", the project seeks to advance the state of art of computer vision techniques for recognizing assembly states. A combination of appearance-based and CAD-based approach will be used for addressing the problem of simultaneously tracking a large number of known assembly parts. A probabilistic approach is proposed to improve the performance of assembly state recovery over time as the assembly task progresses. Another focus is to look for efficient approaches for building the model spaces for subassemblies with larger number of parts. Geometric modeling and analysis of the assembly domain will be utilized in the development of systematic flow of augmentation to aid various assembly tasks. Two experimental setups will be used, involving a see-through head-mounted display and a computer monitor with graphics overlaid on live video. Specific assembly task scenarios will be devised to determine the practical feasibility of augmented reality interface for the assembly domain. Another goal will be to experimentally evaluate the effectiveness of augmented reality interface as a training tool compared to other means of instructions. The resulting augmented reality interface is expected to impact many applications that benefit from the on-line, scene-dependent presentation of multimodal information, such as assembly prototyping, aircraft maintenance, repair of space vehicles, cost-effective training of factory workers, and perhaps guiding inexperienced users through complex repair of machinery.","title":"ITR: Augmented Reality and Computer Vision for Enhancing Human Assembly Skills","awardID":"0081935","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["254458"],"PO":["565227"]},"43300":{"abstract":"CCR-9912352<br\/>Pierce, Benjamin C. <br\/>University of Pennsylvania<br\/>Modular Type Systems<br\/><br\/>This project explores the use of FEATURE-BASED COMPOSITION to address<br\/>issues of MODULARITY in the design, implementation, and formal<br\/>analysis of type systems and related deductive systems. The ultimate<br\/>goal is to build and disseminate a \"type system designer's workbench\"<br\/>named TinkerType: a conceptual framework, tool, and component library<br\/>supporting the design and analysis of type systems. It will include a<br\/>substantial library of ``type system components'' covering a wide<br\/>range of familiar typed lambda-calculi, as well as a tool for<br\/>assembling from these components both formatted mathematical<br\/>specifications and executable implementations of systems. More<br\/>ambitiously, we intend to incorporate modularized proofs of properties<br\/>such as soundness and decidability in the form of fragments of proof<br\/>script for a mechanical proof checker. Potential applications of<br\/>TinkerType include experimentation with new type systems in the form<br\/>of typed lambda-calculi, as well as structured presentations of<br\/>families of typed assembly languages, object calculi, etc. Moreover,<br\/>the proposed mechanisms for statically checking the reasonableness of<br\/>particular combinations of features are relevant to other<br\/>feature-based approaches to constructing systems (for example, using<br\/>the aspect- or subject-oriented programming languages being designed<br\/>at Xerox or IBM or the microprotocol approach to distributed systems<br\/>advocated by the Ensemble project). TinkerType is also a crucial<br\/>enabling technology for a planned textbook on type systems.","title":"Modular Type Systems","awardID":"9912352","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["563479"],"PO":["564388"]},"55642":{"abstract":"Second and third generation wireless systems have been designed primarily for voice, so they are con-nection oriented, delay sensitive, and provide fixed bit rates. Additionally, since service is desired \"any-time\/anywhere,\" these systems must provide ubiquitous coverage. This coverage is achieved through rela-tively uniform grids of cell sites, which are placed to control interference and minimize outage rather than to maximize throughout. As a result, such systems deliver low bit rates and are relatively expensive when used for large amounts of information. At the same time, wireline connection to the Internet has encouraged uses (and users) that depend upon bits being virtually \"free.\" We contend that this \"economic\" mismatch between wired and wireless access is the primary obstacle to the dramatic growth of a wireless Internet. The solution may lie in designing systems specifically for wireless data, recognizing that data services are often connectionless, delay insensitive and have no specific bit rate requirements. These differences<br\/>suggest that ubiquitous (anytime\/anywhere) coverage is not a strict requirement for wireless data networks and makes possible systems in which small, separated coverage areas facilitate transfers of megabytes of data in fractions of a second, and for a fraction of the cost associated with conventional ubiquitous coverage. Communication theory and simple link budget calculations tell us that it is possible to build such sys-tems, but the signal processing challenges are numerous and distinct from the historical challenges offered by connection-oriented wireless services. When a mobile user passes an Infostation, there will be a window of opportunity, perhaps as short as a fraction of a second, in which the user will have access to a high-rate communication channel. A key task is to identify that window and transmit at an appropriate rate. The mobile must make these decisions based on measurements of a wideband radio channel in which there is frequency selectivity and time variation in the fading as well as in the interference. In the specific context<br\/>of an Infostations system, we plan to divide our research into four components: <br\/><br\/>Radio Channel Modeling: The characterization of typical Infostation radio channels. <br\/><br\/>Transceiver Design: The analysis and performance evaluation of transmitters and receivers for both single carrier and multicarrier systems.<br\/><br\/>Radio Resource Management Transmitter power and rate adaptation policies derived from receiver measurements.<br\/><br\/><br\/>Algorithm Development Testbed A platform employing DSP and FPGA technology for the practical evaluation of transmitter and receiver algorithms. <br\/><br\/>The activities of this project will encompass three research institutions in New Jersey (New Jersey In-stitute of Technology, Princeton University, Rutgers University) under the auspices of the N.J. Center for Wireless Telecommunications (NJCWT). The NJCWT is an inter-institutional research and educational or-ganization sponsored and funded by the N.J. Commission on Science and Technology. The focus of the center is a multi-year effort in Digital Radio Technology for Computing, Communications and Information Systems. This effort is supportive of and will enhance the present proposed project in wireless networks.","title":"ITR: Collaborative Research: \"Free\" Bits: The Challenge of the Wireless Internet","awardID":"0085846","effectiveDate":"2000-09-01","expirationDate":"2005-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["316235","316236","279647"],"PO":["223414"]},"54674":{"abstract":"The goal of this project is to develop advanced algorithms for visualizing the sources of noise and vibrations of complex vibrating structures based on simple measurements of acoustic pressures. The software developed will provide an efficient, robust, and user-friendly tool to practicing engineers concerned with identification and control of noise and vibration. For example, this will allow aircraft designers to reduce the amount of noise inside the passenger cabin of an airplane, or make quieter cars. <br\/><br\/>This project will address mathematical, computational, and engineering issues related to finding the source of acoustic radiation from a vibrating structure, also known as acoustic holography. This process involves determining the vibrational patterns in a structure based on simple acoustic pressure measurements from an array of microphones near the structure. The mathematical part of acoustic holography is an inverse problem, the direct problem being to determine the radiated acoustic pressure field in the fluid medium, given the vibration responses of the structure. Inverse problems such as this are ill-posed, thus requiring effective regularization techniques as filters. In this project, the researchers will pool their expertise and experience in advanced computational science, mathematical analysis, and mechanical engineering to elevate the acoustic holography to a higher level for solving engineering noise and vibration problems in a cost-effective manner. The algorithms and regularization techniques will be firmly based on current work in numerical linear algebra, mathematical analysis, and engineering practice. Iterative methods will be developed to provide fast computational techniques for both the single layer and Helmholtz-Kirchhoff integral equation methods. Estimates of stability and accuracy will be established to provide guidance for optimal regularization strategies, measurement locations, and number of expansion functions for the Helmholtz Equation Least Squares (HELS) method and combined HELS (CHELS) method. Experimental validation of the methods will be carried out for both interior and exterior regions on an aircraft cabin and a vehicle front end.","title":"ITR\/ACS :Collaborative Research: Advanced Algorithms for Visualizing Sources of Noise and Vibrations of Complex Structures","awardID":"0081270","effectiveDate":"2000-09-01","expirationDate":"2005-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["447061",139665,"278132",139667],"PO":["565272"]},"43311":{"abstract":"This grant will develop novel high performance numerical algorithms and codes for critical problems in large dynamical systems. This includes reducing models to fewer degrees of freedom, better eigenvalue solvers, and parallel implementations. This project has applications ranging from control systems to electric power systems, circuit simulations, earth sciences (meterology, hydrology), and filtering.<br\/><br\/>This is a joint project together with CCR-9912415 by Kyle Gallivan of Florida State University.","title":"Efficent Algorithms for Large-Scale Dynamical Systems","awardID":"9912388","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["501195"],"PO":["321058"]},"54201":{"abstract":"EIA-0079557<br\/>Smith, Scott R.<br\/>Southern Illinois University Edwardsville<br\/><br\/>MRI: Acquisition of Immersive WorkWall System for Campus-wide Visualization Research<br\/><br\/>This proposal requests funds to provide Southern Illinois University at Edwardsville with the visualization capabilities of an Immersive WorkWall System. The particular Immersive WorkWall consists of a single screen stereoscopic projection system and a workstation rendering dual graphic images onto a six by eight foot screen. Viewers wearing special glasses experience real depth effects. The new equipment capability will significantly enhance the on-going research activities concerning animated simulation models of scientific and engineering concepts.","title":"MRI: Acquisition of Immersive WorkWall System for Campus-wide Visualization Research","awardID":"0079557","effectiveDate":"2000-09-01","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["562016","367467"],"PO":["557609"]},"55774":{"abstract":"EIA- 0086262<br\/>Bruch, John C.<br\/>University of California - Santa Barbara<br\/><br\/>CISE Educational Innovation Program: HPC Diagnostics for Scientific Computing in the Undergraduate Curriculum<br\/><br\/>This project transfers results of research in parallel algorithms into the undergraduate engineering curriculum at this university. The overall objective of the research component is the generation of learning tools that demonstrate how to analyze numerical algorithms for parallel processing for two important and realistic classes of engineering problems involving free and moving boundaries. Course modules enable students to easily and proficiently engage in high-performance parallel computing. A variety of software helps students analyze and understand execution behavior including problem partitioning, module communication patterns, processor load balancing, computation versus communication ratios, timing characteristics, and processor idle time. Specifically, the modules demonstrate the use of the computing diagnostic software applied to typical runs on a parallel computer for fixed and free and moving boundary value problems. The transfer of this research into the undergraduate curriculum enhances students' understanding of the capabilities of parallel computers for solving difficult engineering problems and enhances the computational infrastructure in engineering and other areas.","title":"CISE Educational Innovation: HPC Diagnostics for Scientific Computing in the Undergraduate Curriculum","awardID":"0086262","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":[143031],"PO":["551712"]},"54685":{"abstract":"This project will address the needs of researchers involved in solving large nonlinear problems, which exhibit multiple solution paths, or large-scale minimization problems with multiple local minima. It will develop a library of visualization and computational steering tools to address path following problems efficiently on Beowulf computer clusters. It will also provide tools for optimization of the cluster communication. It will produce tools that are integrated with the CUMULVS steering and visualization environment. The software libraries will be open source and provided to the community of researchers and users.","title":"ITR: Cluster Based Computational Techniques for the Modelling of Problems Involving Bifurcations","awardID":"0081324","effectiveDate":"2000-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["375530","187937","375531"],"PO":["565272"]},"50087":{"abstract":"Survivability and secure communications are essential in a mobile<br\/>computing environment. We propose to conduct a series of experiments<br\/>that will lead to the development of new authentication and key management<br\/>techniques for wireless communications. We study the implementation of<br\/>various authentication schemes on the overall system performance. We<br\/>propose a technique to achieve fault-tolerant mobile node authentication<br\/>in an efficient way. We plan to identify guidelines for authentication<br\/>between an upstream domain and a DiffServ ingress router in a QoS enabled<br\/>network. We will evaluate how various secure group communication and<br\/>access control techniques fit into the wireless world by conducting <br\/>scientific experiments in a systematic way. We will solve the problem of <br\/>providing secure multimedia communication under mobile environments where<br\/>the resources available to mobile hosts such as CPU power and network<br\/>bandwidth are very limited. We have developed a series of light-weight<br\/>video encryption algorithms which encompass video compression and video<br\/>encryption in one step. This will lead towards an adaptable<br\/>encryption system.","title":"Secure Mobile Systems","awardID":"0001788","effectiveDate":"2000-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["540775"],"PO":["543507"]},"43322":{"abstract":"This research develops advanced methodologies and tools to enable the design of low-energy embedded system-on-nanochips for future wireless appliances. A system-level power analysis technique is developed which considers the effects of wireless protocols, architectural choices, and nanometer technologies on the energy consumption of the hardware, software, and RF components of a wireless embedded nanochip. Since adaptive on-chip communication is fundamental to such heterogeneous component-based nanochips, analysis and optimization techniques are developed for low-energy on-chip communication architectures and protocols. Static and adaptive analysis and management techniques are developed to extend the battery life of the mobile systems. The techniques are being applied to the design of an adaptive single-chip radio that is being developed to enable wireless multimedia communications.","title":"Power Analysis and Optimization Methodologies for Wireless Embedded Nanochips","awardID":"9912414","effectiveDate":"2000-09-01","expirationDate":"2004-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["507608"],"PO":["562984"]},"55664":{"abstract":"The emergence of new applications has fostered a number of attempts to add functionalities to the minimalist Internet core. However, the adoption of enhancements to the Internet has either been slow, failed entirely, or limited to special-purpose private networks. The key reasons for this failure are extensibility and scalability: First, IP networks were not designed to be extensible at the internetworking level. Second, proposals for new network layer services often require that vast amounts of state information be managed in the core network infrastructure, thus, introducing scalability bottlenecks which exacerbate the existing scalability problem of the growing Internet.<br\/> Today, the development and deployment of advanced services on the Internet has reached a crossroads: efforts to add new services have quickly encountered scalability problems, yet new services are in critical demand and must be rapidly and widely deployed.<br\/> The research goal is to develop truly scalable services for each of the three fundamental components of the Internet's infrastructure: information communication, replication, and storage. Taking a new and unified approach to the seemingly conflicting requirements for scalability and sophisticated network services, the researchers propose to develop:<br\/> 1. Scalable Performance-Predictable Communication: a new foundation for quality-of-service communication via a scalable edge-based architecture.<br\/> 2. Scalable Multicast for Efficient Data Dissemination: a self-organizing multicast infrastructure scalable to many spontaneously-formed groups.<br\/> 3. Scalable Storage for Next Generation Information Services: an infrastructure which brings information<br\/>closer to users and enables scalable third-party information storage services.<br\/> 4. Design Principles of Scalable Services: a multi-faceted approach for the development and deployment<br\/>of scalable services in the global Internet, under consideration of economic models, industrial structure,<br\/>theories and algorithms, engineering, and deployment.<br\/> Thus, this project proposes to develop architectures and methodologies for deploying scalable services in the global Internet. The impact of this project will be to provide the theoretical underpinnings, basic architecture, and a prototype implementation for the information communication of the global Internet of the 21st century. An integral part of this project is the dissemination of results and the infiltration of standard organizations with the concepts developed within this project, and innovative approaches to educate the next generation of engineers for the future Internet.","title":"ITR: Collaborative Research: Scalable Services for the Global Network","awardID":"0085920","effectiveDate":"2000-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["435983"],"PO":["292741"]},"54223":{"abstract":"EIA-0079617<br\/>Meleis, Waleed M.<br\/>Northeastern University<br\/><br\/>MRI: A Memory Intensive Compilation Environment Targeting VLIW and DSP Architectures<br\/><br\/>This proposal is to acquire Linux\/Unix TRU64 and Linux\/X86 compute servers to enable the support of memory intensive compiler research at the Electrical and Computer Engineering Department of Northeastern University. The research projects that will use the requested compute servers include Optimization-centered code restructuring and scheduling, memory coloring and compaction targeting DSPs, and dynamic profiling, compilation and evaluation environments.","title":"MRI: A Memory Intensive Compilation Environment Targeting VLIW and DSP Architectures","awardID":"0079617","effectiveDate":"2000-09-01","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["557272",138361,138362],"PO":["557609"]},"55686":{"abstract":"In 2015, for a few hundred dollars a year, everyone will have a personal petabyte database (PetDB) that can be accessed from any point of connection, with any device from a high-powered workstation to a PDA. Each individual's PetDB will be their evolving and customized view of all the on-line digital data that exists anywhere. It will store and organize any kind of digital data, without losing structure or information. All this data will be queryable and arranged by type, content, structure, association and multiple categorizations and groupings. The PetDB is an example of what could be done with a new generation of software infrastructure we term Net Data Managers (NDMs). The object of this research is not to build a PetDB per se; but to design and implement the NDM technology upon which PetDBs and other applications could be readily built. NDMs are a departure from current database management systems. They focus on data movement, rather than data storage and must handle data of arbitrary types, without necessarily having a matching database schema. They must execute queries over tens of thousands of information sites, while monitoring possibly millions of triggers over rapidly changing information sources. The first exploratory steps have been taken towards NDMs with initial work on XML querying, text in context indexing and searching, multi-trigger planning and data stream processing. This work has demonstrated some of the basic capabilities of NDMs. Continued research will address the challenging fundamental problems that must be solved to extend these capabilities to exploit the full capabilities of NDMs. At the same time, the scale at which NDMs operate will be extended, in terms of numbers of users, tasks and sites, as well as data volumes, through distributed and parallel implementations.","title":"ITR: A Petabyte in Your Pocket","awardID":"0086002","effectiveDate":"2000-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["335067","451905"],"PO":["469867"]},"54597":{"abstract":"This project describes network patterns among email users in the United States, identifying how electronic relations form and the implications of such relations for behavior. In the first of three stages, the project identifies the global features of electronic communication networks by identifying sets of people linked through email exchange. This sample provides the information needed to identify network features such as social distance, social cohesion, small-world properties, social balance, and segregation. Stage two examines the dynamic details of electronic networks by collecting in-depth information about online activity, social behaviors, and demographic characteristics over a year for a sample of the original study population. Using these data, researchers can model the stability of online relationships and the effect of network position on social behaviors. The third stage of the project re-contacts members of the original sample a year later. Data from this stage allows researchers to develop network-contextual models of social behavior that situate individual behavior within both local and global network contexts. The three stages of this project provide social network researchers and information technology specialists with an unprecedented ability to model network effects on social behavior and patterns of social relations in the rapidly changing electronic social context.","title":"ITR: The Structure and Dynamics of Electronic Social Networks","awardID":"0080860","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["508293"],"PO":["495796"]},"55697":{"abstract":"EIA -0086038<br\/>Kimble, H.J.<br\/>California Institute of Technology<br\/><br\/>Title: Information Technology Research: Institute for Quantum Information<br\/><br\/>An interdisciplinary team of researchers in Physics, Applied Physics, Electrical Engineering and Computer Science are establishing an Institute for Quantum Information (IQI) to facilitate the investigation of quantum information science to provide new capabilities in the revolutionary field of quantum computing. To this end, efforts are being made to develop new algorithms for the manipulation, processing, and distribution of quantum information (including information capacities of communication channels, reliable schemes for distributed computation, efficient quantum error correcting codes). Investigations of physical systems for the implementation of quantum computation and communication, as well as coherent nanotechnology, principally by the way of theoretical models and analysis, are being performed. The team is also pursuing techniques to develop active control of quantum effects in nanoscale integrated circuits involving systematic approaches to the suppression of unwanted quantum effects via on-chip feedback networks and methods for stabilizing and exploiting emergent quantum behaviors in the context of analog\/hybrid VLSI.","title":"ITR: Institute for Quantum Information","awardID":"0086038","effectiveDate":"2000-09-01","expirationDate":"2006-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["490112","511760","490256","550549","438201","365875"],"PO":["565223"]},"48811":{"abstract":"This research is on developing models and algorithms for design and analysis of optoelectronic systems to encompass micro-scale systems that integrate optical, electrical, and mechanical components. It is focused on five main topics: light propagation models for micro-optics, mixed-domain component models, a corresponding mixed-domain simulation environment, a 3D user interface, and design and analysis techniques that directly incorporate the additional performance concerns of mixed-technology systems. The algorithms being developed include new hybrid methods to model optical propagation in the micro-scale environment, techniques for creating consistent component level models across domains, and multi-time base simulation techniques. For the methodologies for mixed-technology design, the definition of performance is expanded beyond speed, power and area to include the additional concerns of mixed-technology systems such as noise, crosstalk and tolerancing. The research team is creating software tools, which will be made available to other research groups in both industry and academia.","title":"Design Automation Tools for Micro-Scale Mixed Technology Systems","awardID":"9988319","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["560649","549458"],"PO":["562984"]},"52199":{"abstract":"EIA-0071954<br\/>John R. Kender<br\/>Columbia University<br\/><br\/>TITLE: Experimental Partnership: Adaptive Interactive Team Video<br\/><br\/>This project will create a collaborative virtual environment for group work and\/or group study, in which semantically structured videos concerned with instruction, design, or prior discussion of a team effort are delivered over heterogeneous Internet links to heterogeneous platforms in an efficient and adaptive manner. The proposed system will enable: the measurement of the effectiveness of semantic summarization and indexing on the access and use of video resources, the measurement of the effectiveness of semantic summarization and indexing on the access and use of video resources, the measurement of the quality of service effects which heuristic forecasting and monitoring of team work actions will have on video delivery, and the measurement of the degree of success of system resource management algorithms for the perfecting and progressive refining of video segments into the caches of clients with varying capabilities from a server cluster subject to resource contention under varying loads. Additionally, this project will provide an efficient distributed environment useful for collaborative and educational purpose in its own right-one that will be tested in the PI's own courses.","title":"Experimental Partnership - Internet Interactive Team Video","awardID":"0071954","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4725","name":"EXPERIMENTAL SYSTEMS\/CADRE"}}],"PIcoPI":["337904","541922","508477"],"PO":["565223"]},"46666":{"abstract":"The proposed project will investigate a number of problems in the efficient support of different qualities of service (QoS). Due to the scarcity of network resources and the emergence of new applications, it is considered crucial that the current internet evolve from a best effort service to one that supports different QoS. This problem was explored in the IETF first in the context of integrated services and more recently in the context of differentiated services. One of the key problems with the work in integrated services was the lack of scalability of per-microflow scheduling in the core of the network, and the basic tenet of differentiated services has been to move per-microflow operations to the edge of the network and deal with only macroflows in the interior of the network. Nevertheless, some of the key traffic elements such as regulators (to shape, police, and mark microflows at the edge as well as macroflows at the boundary of different subnetworks) and schedulers (across different macroflows and service classes) are still needed to provide the different QoS. Higher multiplexing gains are also sought by looking at flows statistically rather than in the worst case. Moreover, schemes that use a combination of end-to-end flow control and policing\/marking at the microflow level and dropping (RIO)\/scheduling at the macroflow level have also been proposed to provide a combination of assured QoS along with the ability to use additional available bandwidth. The objective of this proposal is to engineer these key traffic control elements - regulators, schedulers, and flow control mechanisms - so as to not only deliver the different QoS desired, but to do so in a manner that maximizes the network utility.<br\/> In order to accomplish this objective, the project will rely on a modeling and analysis framework that has recently been developed by the researcher and his collaborators. This framework provides a unified mathematical model (based on the notion of traffic envelopes\/ service curves \/ service processes) for regulators and schedulers as well as an easy way to analyze fork-join networks of such elements with (or without window\/rate flow control). In particular, the researcher's prior work has shown how the impact of the entire network may be reduced to that of an equivalent single element with an (end-to-end) service curve given in terms of the service curves of the individual elements using an easy composition rule. Furthermore, the worst-case and probabilistic end-to-end performance for such networks is then easily obtained in terms of this end-to-end service curve. Since the framework is analyzable, one can \"invert\" the results of the analysis to derive rules for the design of efficient traffic control elements. More interestingly, the framework allows for the representation of a sophisticated service curve for a single traffic control element, as a network of simple service curves. This representation can then be exploited to synthesize complex but highly efficient regulators and schedulers. This modeling framework therefore provides a systematic way to analyze, design, and synthesize traffic control elements for differentiated services networks.<br\/> In particular, the proposed project will lead to the following: It will result in the synthesis of more efficient regulators and schedulers. It will develop other guaranteed services (besides leased line emulation) in the context of differentiated services networks. It shall produce better admission control schemes for probabilistic service. For both guaranteed and probabilistic service, it will also lead to efficient allocation of network resources into service curves for different flows via pricing. In the case of adaptive service with certain minimum requirements, it will lead to a better understanding of the interplay between the in-profile and out-of-profile traffic, and how this interplay may be exploited to enhance existing adaptive mechanisms such as TCP.","title":"Regulation, Scheduling, and Flow Control for Quality of Service Support","awardID":"9980526","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["491949",119323,"553458"],"PO":["565090"]},"55378":{"abstract":"This project supports a two-day workshop addressing topics in the general area of hierarchical scientific visualization. This includes topics such as hierarchical data representation and approximation; using hierarchical data representations for the purposes of interactive visualization emphasizing level-of-detail, adaptive, and view- dependent strategies; hierarchical data representations as they relate to distributed, remote, and collaborative visualization applications; and hierarchical visualization in immersive and virtual reality environments. The workshop will take place at Lake Tahoe, NV, on October 15-17, 2000.","title":"WORKSHOP: Lake Tahoe Workshop on Hierarchical Visualization Methods - Oct. 15-17, 2000","awardID":"0084843","effectiveDate":"2000-09-01","expirationDate":"2003-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}}],"PIcoPI":["495182","279394"],"PO":["551992"]},"53079":{"abstract":"EIA-0074790<br\/>Lerman, Kristina<br\/>University of Southern California<br\/><br\/>POWRE: Mathematical Modeling of Multi-Agent Systems<br\/><br\/>This POWRE proposal outlines a novel physics-based approach to solving computer science problems. The proposed activity leverages the author's training in physics, particularly the physics of complex systems, and applies to the study of multi-agent systems. The goal of the research is to propose a feasible mechanism in which interactions between agents with simple local strategies lead to desirable group behavior in each of the two domains: coalition formation in a multiagent system and dynamic routing in a sensor network. The proposed mechanism is then analyzed and a mathematical model of the process is constructed. The model is expressed as a series of coupled differential equations. For the coalition formation problem, for instance, the model describes how the number and distribution of coalitions change with time. The solutions of the equations describe collective behavior, and they can be analyzed for different values of the parameters.","title":"POWRE: Mathematical Modeling of Multi-Agent Systems","awardID":"0074790","effectiveDate":"2000-09-01","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1592","name":"PROF OPPOR FOR WOMEN IN RSCH"}}],"PIcoPI":["517887"],"PO":["289456"]},"69228":{"abstract":"","title":"NSF Young Investigator: Coordination and Control of DynamicPhysical Systems","awardID":"0196047","effectiveDate":"2000-09-01","expirationDate":"2001-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["438709"],"PO":[179262]},"54950":{"abstract":"This is the first year funding of a three-year continuing award. A demanding application area of virtual or augmented environment is multi-user collaborative environment where multiple users at either a local site or remote sites communicate with each other and interact with a synthetic or virtual scene. Among the necessary sensors and devices, an effective visualization device and a real-time image acquisition system are two main challenges. The objective of this project is to develop a novel visualization device referred to as head-mounted projective display (HMPD), build a multi-user interactive workbench by integrating the developed HMPD technology with a unique real-time image acquisition system known as an omni-focus camera, and evaluate and quantify the system as an effective tool for remote collaboration. The head-mounted projective display (HMPD) proposed is coupled with a supple, non-distorting and durable projection surface as an alternative to current visualization devices. Its novel concept suggests solutions to part of the problems of state-of-art visualization devices, such as large distortion with wide field of view, occlusion contradiction between virtual and real objects, and brightness conflict with background illumination. Several properties of the proposed HMPD make it extremely suitable for multiple-user collaborative applications. Research efforts will be made to design and implement a lightweight and compact head-mounted prototype by introducing diffractive optical element (DOE) and plastic materials, and investigate approaches to optimize the illumination of the display and retro-reflective material properties for imaging purpose. At one site, a multi-user interactive bench prototype with tele-presence capability will be built by using the HMPD concept and adding an image acquisition system developed from a unique omni-focus camera system. At the other site, a mural display system will be built with conventional stereoscopic video system located near the mural display, where one or several collaborators will also gather. Tele-collaborative work will be tested between the Beckman Institute at the University of Illinois--Urbana Champaign and the School of Optics-CREOL at the University of Central Florida through the Internet II connection linking our laboratories. Finally, the PIs will quantify the depth and size representation and perception accuracy, evaluate occlusion perception aspects, and set up a comprehensive calibration procedure for the HMPD and the workbench and mural prototypes. The results are expected to impact a wide range of applications such as collaboration\/tele-collaboration, tele-presence, tele-manipulation, and visualized education\/tele-education.","title":"ITR: Collaborative Research: Development of Head-mounted Projective Display for Distance Collaborative Environments","awardID":"0083037","effectiveDate":"2000-09-01","expirationDate":"2003-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["499628","485281"],"PO":["565227"]},"54961":{"abstract":"The researchers envision a future where a universal network connects every human being and most human-made electronic devices. The universal network spans locations engaged in every human endeavor, including the home, workplace, transportation vehicles, public facilities, and space facilities. The wide availability of open computing power, bandwidth, and natural interfaces such as speech recognition and brain-computer interfaces will allow the user or organization to merge with the network into a unified, ubiquitous entity.<br\/> To realize this vision, the researchers believe a radical shift in network design paradigms is necessary. The PI proposes a new network architecture called the Bio-Networking Architecture. The Bio-Networking<br\/>Architecture is inspired by the observation that the biological world has already developed the mechanisms<br\/>necessary to achieve such key requirements as self-organization, scalability, adaptation and evolution,<br\/>security, and survivability necessary for our envisioned universal network. In the biological world, each<br\/>individual entity (e.g., a bee in a bee colony) follows a simple set of behavior rules (e.g., migration,<br\/>replication, reproduction, pheromone emission, energy exchange, mutation, death), yet a group of entities<br\/>(e.g., a bee colony) exhibits complex, emergent behavior and characteristics (e.g., self-organization,<br\/>scalability, adaptation and evolution, security and survivability). The researchers believe if a network is modeled after biological concepts and mechanisms, it may be able to achieve the desirable properties of self-organization, scalability, adaptation and evolution, security, and survivability.<br\/> In the Bio-Networking Architecture, network services and applications are implemented by a<br\/>distributed, adaptive, and self-organizing collective entity called the super-entity, which consists of a large<br\/>number of autonomous entities called cyber-entities (analogous to a bee colony consisting of multiple<br\/>bees). Each cyber-entity implements a functional component related to the overall service or application<br\/>and follows simple behavior rules (e.g., migration, replication, reproduction, pheromone emission, energy<br\/>exchange, mutation, death) similar to biological entities. Useful behaviors and characteristics arise from<br\/>the behavior and interaction of individual cyber-entities. The innovative features of the Bio-Networking<br\/>Architecture include:<br\/>1)Application of Biological Concepts. The proposed Bio-Networking Architecture is the first attempt to<br\/> apply the biological concepts of emergent behavior, adaptation, evolution, diversity, social networking,<br\/> and food (energy) to the design of a network architecture.<br\/>2)User-Network Unification. The Bio-Networking Architecture represents a paradigm shift in the<br\/>relationship between a user or an organization and the network. It merges the network and the user or<br\/>organization into a unified entity, giving the user or organization a ubiquitous presence.<br\/>3)Emergent Behavior and Evolution. The Bio-Networking Architecture enables the construction of<br\/>complex services and applications with the inherent properties of self-organization, scalability,<br\/>adaptation, evolution, security, and survivability. Because the Bio-Networking Architecture adapts and<br\/>evolves to accommodate short and long term changes in network conditions, system designers,<br\/>administrators, and users are free from managing and tuning network applications.<br\/>4)Self-Organization. The proposed Bio-Networking Architecture is a self-organizing, administration-free,<br\/>and scalable networking architecture which vertically integrates the protocol stack from the<br\/>network layer upward, eliminating duplication of functionality among protocol layers.","title":"ITR: The Bio-Networking Architecture: A Biologically Inspired Approach to the Design of Scalable, Adaptive, and Survivable\/Available Network Applications","awardID":"0083074","effectiveDate":"2000-09-01","expirationDate":"2005-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["409909"],"PO":["250082"]},"52431":{"abstract":"Photorealistic image synthesis is one of the most fundamental problems in computer graphics, with<br\/>a wide variety of applications. In recent years, tremendous progress has been made in the<br\/>simulation of light transport and the resulting lighting effects. Unfortunately, the underlying<br\/>material models are, by comparison, primitive and assume that the materials are both pristine and<br\/>immutable, even though real materials are neither. This severely limits the range of appearances<br\/>that can be produced. This research program will focus on the development of computer graphics<br\/>models for materials, which will be suitable for the requirements of image synthesis.<br\/><br\/>During the award period, the research will address two key aspects of this problem: (1) Taxonomy<br\/>of materials: a study of a wide variety of materials will be conducted in order to devise a<br\/>classification of materials that is appropriate for computer graphics. (2) A measurement device: a<br\/>portable device for measuring surface appearance properties in the field will be designed,<br\/>simulated, and eventually constructed.<br\/><br\/>The research program will be integrated with a training plan that will afford the postdoctoral<br\/>associate a variety of opportunities for professional development.","title":"CISE Postdoctoral: Modeling and Measuring the Appearance of Materials for Computer Graphics (ECS Associate)","awardID":"0072690","effectiveDate":"2000-09-15","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["548698"],"PO":["532791"]},"52673":{"abstract":"Dramatic advances in the technologies, coupled with economic factors, have given rise to a new modality of parallel computing wherein workstations are connected together to act cooperatively as a single parallel computer - a Network of Workstations (NOW). Many algorithmic devices that ensured efficient interprocessor communication and coordination in a tightly coupled parallel computing environment no longer guarantee efficiency within a NOW. This project derives theoretical understanding of factors that enhance - and detract from - efficiency of parallel computing in NOWs. It also develops algorithmic techniques that translate such understanding into practically efficient scheduling strategies. The scheduling algorithms that emerge from research will provide provably predictable performance for large, significant classes of computations, such as those that arise in many scientific applications.","title":"Scheduling Parallel Computations in Clusters of Workstations","awardID":"0073401","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["518069"],"PO":["180163"]},"52794":{"abstract":"With the shrinking size of tetherless computing devices and increasing diversity in capabilities, the value of ubiquitous computing is rapidly becoming real. As these devices proliferate in number, their configuration, management, and organization as ad-hoc networking environments proves to be a challenging research domain. In most scenarios the interaction of these devices enables a broad range of applications. A group of such devices can communicate with each other to achieve a goal specific to the application, i.e., they perform a higher-level task or service by communicating intelligently with each other. This proposal is to investigate and develop a distributed framework for executing complex tasks not by using pre-configured devices but by selecting suitable computing elements based on task requirements and device characteristics. A prerequisite and enabling component for this work is the creation of a set of self-organization protocols for connecting and managing these computing elements with minimal application intervention during the lifetime of the task. Such protocols are referred to as \"smart\" protocols.<br\/> Existing protocols for organizing devices are constrained by their dependence on available infrastructure<br\/>primarily because of the use of directory-based service discovery and are therefore less valuable for a truly ad-hoc computing environment. A key premise of this proposal is that the nature of the task can be exploited<br\/>to organize ubiquitous computing devices into logical task based groups. Tasks are then represented by<br\/>dependency or task graphs that describe how devices interact with each other. A distributed mechanism is<br\/>proposed for constructing and embedding a task graph on a network of computing elements for\"\\smart\" task<br\/>execution. Additionally, a task-aware routing protocol for reducing routing delays is proposed. An expected<br\/>outcome of this approach is the ease with which larger, more complex services can be composed from smaller<br\/>services. These protocols can thus be rapidly deployed in ad-hoc environments enabling new applications in<br\/>diverse areas such as smart homes and offices, distributed robotics, sensor networks, large scale distributed<br\/>computing, smart battlefields, crisis management, etc.<br\/> Specific tasks of this research are: (1) the development of efficient distributed algorithms for discovery<br\/>of suitable devices that can together perform a distributed task from within a sea of tethered or tetherless<br\/>devices, and protocols for execution of those distributed tasks; (2) the development of task aware routing<br\/>protocols using key link-state information; (3) specification for the use of state augmentation techniques for<br\/>handling nomadicity of users and devices as seamlessly as possible; (4) the simulation of the above protocols<br\/>using public domain network simulators; and (5) the implementation of a proof-of-concept prototype using<br\/>commodity hardware and software.","title":"Rapid Task-based Self-Organization in Distributed Ad-hoc Spaces","awardID":"0073843","effectiveDate":"2000-09-01","expirationDate":"2004-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["371069"],"PO":["565090"]},"50253":{"abstract":"EIA-0002197<br\/>Aldebol, Sylvia<br\/>Inter American University of Puerto Rico<br\/><br\/>CISE Minority Institutions Infrastructure: A CISE Planning Proposal for Inter American University of Puerto Rico<br\/><br\/>The purpose of this project is to prepare a five-year plan that will improve the quality of learning experiences, increase research activities, and attract more students to the computer science program. In this five-year plan, activities will be developed to promote active student learning through inquiry and project-based laboratory and classroom experiences. The strategy used in developing the activities will be to identify and develop focus areas in computer science that will impact course and curriculum, research activities, laboratory improvement, faculty enhancement, and industry partnership. The two main focus areas to be developed are (1) computing on a network and (2) data acquisition.","title":"MII: A CISE Planning Proposal for Inter American University of Puerto Rico","awardID":"0002197","effectiveDate":"2000-09-15","expirationDate":"2001-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":[128390,128391,"168543"],"PO":["557609"]},"54862":{"abstract":"CCR-0082560<br\/>Static Checking in an Extended Type System<br\/><br\/>PIs: Natarajan Shankar and Sam Owre<br\/><br\/>Abstract: <br\/>A safe programming language is one whose type system can, at compile time,<br\/>detect potential runtime errors such as null dereferences, out-of-bounds<br\/>array indices, division by zero, and inapplicable method invocations. Few<br\/>widely used programming languages are safe in this sense. Specification<br\/>languages like PVS, however, contain safety features such as predicate<br\/>subtypes and dependent types that can be used to ensure the absence of<br\/>runtime errors. The design of safe programming languages requires an <br\/>integration of specification and programming languages through the use <br\/>of enriched type systems. These types increase the expressiveness<br\/>and naturalness of both executable descriptions (programs) and<br\/>non-executable descriptions (mathematical specifications).<br\/><br\/>We extend the type systems for widely used languages, such as Java, with<br\/>PVS-like specification constructs. We develop an effective static<br\/>typechecker for this type system that detects many common programming<br\/>errors. The research builds on advances in programming languages, type<br\/>theories, program optimization techniques, decision procedures, and<br\/>program analysis methods, and tools such as LCLint, ESC, and BANE. An<br\/>extended type system for programming languages can be a foundation for the<br\/>design and development of well-specified, efficient, and safe programs.","title":"ITR: Static Checking in an Extended Type System","awardID":"0082560","effectiveDate":"2000-09-01","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["555363","226190"],"PO":["564388"]},"50264":{"abstract":"EIA-0002217<br\/>Kim, Jung H.<br\/>North Carolina A&T State University<br\/><br\/>MII: Infrastructure for Intelligent Mobile Information Systems<br\/><br\/>This proposal involves the creation of an infrastructure for research and graduate education in Intelligent Mobile Information Systems (IMIS) at North Carolina A&T State University. The infrastructure will support the efforts by the Department of Computer Science, the Department of Electrical Engineering and t he College of Engineering to enhance the effectiveness of North Carolina A&T State University as a pipeline to graduate study by African-Americans in computer science and computer engineering. The proposal outlines an aggressive mentoring program oriented toward encouraging African-American students to continue to graduate school. This will involve identifying undergraduate students with high academic performance and recruiting them to participate in the IMIS research program.","title":"MII: Infrastructure for Intelligent Mobile Information Systems","awardID":"0002217","effectiveDate":"2000-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7399","name":"CISE MINOR INST INFRA (MII) PR"}}],"PIcoPI":["541775","381508",128418,"536010","554881","526637","269338"],"PO":["550859"]},"54631":{"abstract":"Despite impressive gains in realism over the last decade, computer graphics is currently unable to effectively generate images of objects and environments that look large. This is mostly because computer graphics is poor at conveying information about absolute depth. The goal of this project is to demonstrate that it is possible to significantly improve the sense of depth and scale in computer graphics if rendering methods are developed with specific attention to the need to convey cues for absolute depth. Accomplishing this goal will require new insights into the 3D information extractable from 2D images, modifications to graphics algorithms in order to better render salient information, and sophisticated perceptual experimentation to validate that people can actually see the intended 3D space. The PI's approach will be to draw upon the results and methods of computational vision in ways that have not previously been done in the computer graphics community. Computational vision provides insights into the intrinsic constraints on how information about 3D space can be recovered from 2D images. In particular, the computational analysis of vision points out the important distinction between relative depth judgments and absolute depth judgments. Surprisingly few of the commonly studied image cues are in fact sufficient to provide information about absolute depth. Of those that do, several cannot be exploited in computer graphics due to fundamental limitations in display technology and our inability to precisely control viewing conditions except in immersive environments. The research will impact a broad range of graphics applications in which accurate spatial information needs to be conveyed, including education and training, design and prototyping, and telepresence.","title":"ITR: Collaborative Research: Generating an Accurate Sense of Depth and Size Using Computer Graphics","awardID":"0080999","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["560997",139560],"PO":["564456"]},"54752":{"abstract":"The vast majority of data used by scientists, engineers, and decision makers resides in a poorly structured collection of reports, memos, and other documents in a myriad of file formats. The increasing densities and falling prices of storage devices make it practical to store for perpetuity all such data that crosses a scientist's electronic desktop. The resulting Information History has the potential to serve as an intelligent assistant by detecting trends and patterns, suggesting potential collaborators, uncovering relevant documents and data from diverse sources, etc., resulting in dramatic increases in the effectiveness of information use. However, current technology, which focuses on either fully structured or completely unstructured databases, cannot be effectively adapted to extracting knowledge from a large historical semistructured database. The goal of the proposed research is to develop suitable formulations of the knowledge discovery problem for historical semistructured databases and to develop, implement, and evaluate solutions. The research thrusts are: (1) devising knowledge discovery operators for semistructured data and an algebra for them; (2) developing efficient methods for implementing these operators; (3) determining methods to incorporate structure incrementally and flexibly; and (4) incorporating differential processing. A Personal Information History Assistant application serves as a test-bed for this research.","title":"ITR: Knowledge Discovery in Historical Semistructured Data","awardID":"0081860","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["456688"],"PO":["563751"]},"54873":{"abstract":"`The PIs will investigate and develop software and computational methods to address one of the most challenging current problems in molecular dynamics (MD) simulations - large proteins, consisting of tens of thousands of atoms in solution over the physiological range of at least a microsecond of folding time. This will be accomplished using a reduced basis approach based on singular value decomposition (SVD) of the MD trajectory.<br\/><br\/>The work will entail:<br\/><br\/>- developing a block SVD updating scheme that will enable new trajectory information to be adjoined to a current truncated SVD approximation to a prior trajectory and avoid having to store the entire trajectory <br\/>- developing, analyzing, and implementing a reduced basis integrator that will work in concert with the SVD updating scheme to compute the reduced basis simulation more rapidly<br\/>- adapting the fast marching algorithms developed for latent semantic indexing to develop the rapid graphical query tools to locate sites that potentially match local structures of interest<br\/>- developing the I\/O support and visualization capabilities to handle the extremely large data manipulation and representation problems that will be generated<br\/><br\/>The result of the research will be an efficient time integration scheme that can drastically limit storage and yet resolve detail on multiple scales. It will be demonstrated on a fully solvated protein molecule over a time scale of a microsecond, and the high order, low frequency motions will be visualized.","title":"ITR: Reduced Basis Methodologies for Computation, Analysis and Visualization of Bio-Molecular Simulations","awardID":"0082645","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["551029","426166"],"PO":["551992"]},"55731":{"abstract":"Proposal Number: 0086160<br\/>Title: Static and Dynamic Tools for Software Design<br\/>PIs: Monica Lam and Dawson Engler<br\/><br\/>This project aims to develop a new programming methodology whereby the<br\/>programmer, the compiler and the runtime system all cooperate in<br\/>maintaining the integrity of a software program. The proposed system<br\/>allows programmers to capture application-level semantics and<br\/>invariants of interest at a high abstract level. Whereas specific<br\/>tools have been developed by compiler writers to detect specific<br\/>common programming errors, this system will allow programmers to<br\/>formulate the correctness property or safety criterion that they wish<br\/>to check in their programs. It places the full power of sophisticated<br\/>static and dynamic analyses in programmers' hands, allowing them to<br\/>analyze and manipulate the program at ease. Success of this reserach<br\/>will have a significant impact on improving software reliability.<br\/><br\/>Expected results of this research include (1) a high-level interface<br\/>with which the programmers communicate information to the system, (2)<br\/>technology for creating new application-specific program analysis, (3)<br\/>deep program analysis techniques such as pointer alias analysis and<br\/>path-sensitive analysis to improve the precision of the static<br\/>checker, and (4) new ways to combine static and dynamic analysis to<br\/>locate violations of the stated properties in the code. A prototype<br\/>system will be developed and tested on general-purpose codes such as<br\/>open-source operating systems, compilers and browsers as well as<br\/>embedded systems such as routers and telephone switches.","title":"ITR: Static and Dynamic Tools for Software Design","awardID":"0086160","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["448745","382726"],"PO":["551992"]},"55621":{"abstract":"A necessary step towards the goal of building more reliable software systems, on time and within budget, is to establish an institutionalized empirical discipline for understanding causal relationships among the processes, components, and technologies that affect the building of systems. As in the physical and natural sciences, experimentation in software engineering requires a community with support for collaboration, experimental replication and refinement, and sharing of experimental data and results.<br\/>For these reasons the Center for Empirical Software Engineering Research (CESER) undertakes original empirical research and is developing a prototype system for sharing and evolving the results of such research with a community of affiliated researchers and practitioners. CESER develops and refines techniques to increase the descriptive and predictive power of empirical models, and studies specific software development technologies to enable industrial organizations to understand the benefits and drawbacks of those technologies in their specific context. The Center provides courses and symposia on empirical methodologies and results, and assists the use of empirical knowledge in software engineering education. The Center's initial focus is on empirical studies of software COTS integration and software quality improvement phenomenology.<br\/>The center is initially organized as a collaborative effort among the University of Maryland, the Fraunhofer Center - Maryland, the University of Southern California, the University of Nebraska at Lincoln, and Mississippi State University.","title":"ITR: Collaborative Research Proposal for a National Center for Empirical Software Engineering Research","awardID":"0085788","effectiveDate":"2000-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["356244"],"PO":["564388"]},"54774":{"abstract":"The primary thrusts of this research are to help improve human-computer interaction methodologies, develop new interface modes, make physics-based interaction accessible to all users, and enhance the capabilities of graphical modelers. To these ends, the PI is focusing on the interactive manipulation and direct sculpting of Subdivision Splines (S-splines) through the integration of physics-based interaction with powerful subdivision geometry, both in terms of its theoretical aspects and its practical aspects in visual computing applications. The novel, dynamic framework of s-splines will not only augment well-established NURBS-based design technologies but also generalize newly developed theory and methodology of physics-based modeling in the practice of modeling and design. The ultimate goal is to develop software environments that can greatly facilitate human-computer interaction through the physics-based modeling of graphical entities. This work will broaden the accessibility of graphical modeling by combining conventional geometric models with computational physics and applied mathematics, thus offering novel interactive methodologies based on realistic model behavior.","title":"ITR: An Interactive Graphical Modeling System based on Dynamic Subdivision Splines","awardID":"0082035","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["416071"],"PO":["564456"]},"54301":{"abstract":"EIA-0079874<br\/>McCormick, Bruce H.<br\/>The Texas A&M University System-HSC Research Foundation<br\/><br\/>MRI: Development of Brain Tissue Scanner<br\/><br\/>The proposed study is a pilot study for imaging the microstructure of brain tissue to visualize brain development and connectivity. The brain tissue scanner, a new instrument for mapping brain microstructure, will be developed for the rapid and massive data acquisition necessary to investigate cytoarchitectural developmental patterns of mammalian brain. Volume scanning rates of 1 teravoxel\/day are anticipated.","title":"MRI: Development of Brain Tissue Scanner","awardID":"0079874","effectiveDate":"2000-09-01","expirationDate":"2001-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[138675,"561154","496841"],"PO":["557609"]},"55632":{"abstract":"The problems associated with building complex heterogeneous systems <br\/>composed of computer, human, and electromechanical components are starting<br\/>to overwhelm system and software engineers, resulting in failed projects<br\/>and accidents related to software behavior. As the complexity of the <br\/>systems grows, so does the difficulty of ensuring safety. <br\/><br\/>Model-based system and software engineering is an approach to building <br\/>complex systems that is based on common models and specification languages <br\/>that are understandable and reviewable by all the engineers on the project <br\/>and by those who must interact with and use the automation as well. The <br\/>research topics to be investigated are: (1) enhancing requirements <br\/>specification reviewability, (2) assisting engineers in creating large, <br\/>complex specifications, (3) minimizing the disruptions caused by changes <br\/>in requirements, and (5) specifying and analyzing safety-related <br\/>properties using the models.<br\/><br\/>To ground the research, the new approaches will be applied experimentally<br\/>to the advanced air traffic control systems being developed and<br\/>validated by Eurocontrol (the European Organization for the Safety of<br\/>Air Navigation). ATC provides a challenging testbed but the results<br\/>of the research should be equally applicable to medical, defense,<br\/>transportation, manufacturing, and other complex, real-time systems.","title":"ITR: A Center for Safety-Critical Embedded Software","awardID":"0085829","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["296879"],"PO":["180163"]},"54664":{"abstract":"This is the first year funding of a three-year continuing award. Access to non-textual<br\/>material for persons with visual impairments has become increasingly important in recent years. Tactile or haptic displays hold considerable advantages in term of non-textual information transfer, particularly for navigating in GUIs and in the transfer of graphic and<br\/>spatial information (plots, bar graphs, etc.). This project will evaluate a new type of haptic display based on electrostatic stimulation (as opposed to the more common electrocutaneous or vibrotactile modes of stimulation). Electrostatic displays have the potential to overcome many of the problems of electrocutaneous and vibrotactile displays. Electrostatic displays can be easily batch fabricated using micro fabrication techniques, the percept is one of texture (there is negligible direct current flow into the skin) and there are no moving parts to stick or wear. The project will focus on the evaluation of the display for use in practical situations and will also lead to a better understanding of the perceptual mechanisms in electrostatic stimulation. Specifically,<br\/>the work will focus in two areas: (1) evaluation of the display including learning effects, young vs. old, visually impaired vs. non-impaired, comparison to raised line drawings, pattern recognition, academic\/business graphics and dynamic range, (2) development of improved display technology guided by continuous evaluation experiments.","title":"ITRI: An Electrostatic Haptic Display for the Visually Impaired","awardID":"0081201","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["495891"],"PO":["565227"]},"54785":{"abstract":")One of the most significant achievements of the last century has been the development of accurate methods to predict the electronic and structural properties of matter. These methods, based on density functional theory and pseudopotentials, allow us to explore the properties of materials without resort to experiments. We can now predict new materials and their properties based on numerical calculations. The only inherent limitations of these methods are computational constraints; current electronic structures methods have a very high computational cost. While the use of modern high-performance computers has enabled tremendous progress in raw computational power for these problems, gains on the algorithms side are also necessary to accommodate more complex materials.<br\/><br\/>This project will introduce new methods, based on efficient algorithms, for bypassing the computational limitations mentioned above. It will seek novel solution methodologies that improve efficiency without sacrificing accuracy and functionality. In particular, one goal will be to avoid the use of eigenvectors, the primary cost for both computation and memory. The project will do this by examining the fundamental physics of the problem, which reveals that a different basis for the subspace spanned by the same eigenvectors can be computed and used instead. The project will find efficient and robust methods for computing these bases, find efficient solutions to the time-dependent and self-consistent Kohn-Sham equations, develop effective out-of-core parallel methods for solving these very large systems, and use these methods to perform pioneering calculations of real materials.","title":"ITR: New Algorithms for Scalable Modeling in Materials Science","awardID":"0082094","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["550000","466762","518256"],"PO":["551992"]},"55643":{"abstract":"Today's Internet owes its great success to the simple, \"hour-glass\" IP network protocol architecture laid<br\/>out twenty-five years ago. With rapid advances in networking technologies and explosive growth of rich<br\/>multimedia content in recent years, the networking community finds itself at an important crossroads: what<br\/>should be the next generation Internet architecture for controlling network resources and provide the quality<br\/>of service (QoS) needed by emerging multimedia applications? There is a multidimensional spectrum of<br\/>possible approaches to providing QoS guarantees. The choice of a QoS solution for the next generation<br\/>Internet will have a substantial impact on both the evolution of the Internet itself, and on what it enables.<br\/>Making the \"right\" choices requires the development of a fundamental understanding of the scalability of<br\/>QoS controls and the impact of these controls on the efficacy of QoS provisioning.<br\/><br\/>The goal of the proposed research is to develop a comprehensive, quantitative understanding of the<br\/>fundamental trade-offs involved in various approaches toward providing scalable QoS guarantees. To this<br\/>end, the researchers will develop coherent theories to systematically address the issue of scalability in QoS controls. The research program divides broadly into four areas:<br\/><br\/>Aggregate network calculus for guaranteed flows: To gain a thorough understanding of the fine time-scale<br\/>(e.g., packet-level) behavior of a network system in providing QoS performance guarantees, the researchers<br\/>will develop an aggregate network calculus to study the impact of aggregate QoS control mechanisms<br\/>on the performance and complexity of data plane operations. This theory is developed for guaranteed<br\/>flows - flows which require the network to commit, either at a per-flow or an aggregate level, a<br\/>certain amount of resources (e.g., bandwidth and buffer) throughout their life time, regardless of the<br\/>network congestion status. The aggregate network calculus will provide a mathematical framework<br\/>to quantify the impact of aggregate QoS controls on the fundamental trade-offs in QoS provisioning.<br\/>It will also yield insights into the design of scalable data plane QoS control mechanisms.<br\/><br\/>End-to-end QoS controls for responsive flows: The researchers will develop fluid models to study the impact of aggregate QoS control mechanisms on the end-to-end performance of responsive flows. A responsive<br\/>flow responds to signs of network congestion, such as loss, by adapting its transmission rate. These<br\/>models will enable us to develop a better understanding of the behavior of responsive flows such as<br\/>TCP coupled with different aggregate QoS mechanisms and to design end-to-end QoS services for<br\/>responsive flows.<br\/><br\/>QoS control laws and control plane aggregation rules. The researchers will develop QoS control laws for capturing the slow time-scale, system-wide behavior of a network and aggregation rules that address the performance and complexity of control plane operations under aggregate QoS controls. These QoS control<br\/>laws and aggregation rules will lead us to the design of distributed and centralized algorithms for<br\/>scalable control plane operations.<br\/><br\/>Scalable QoS mechanisms and service architectures as an integral part in developing these theories, the researchers will also design effective and scalable QoS mechanisms, and tools and techniques for quantifying and evaluating the trade-offs of various QoS solutions. Based on the results from these efforts, the researchers will study how various QoS solutions can be combined to construct meaningful end-to-end services.<br\/><br\/>The research will blend formal modeling\/analysis, experimentation\/implementation, and evaluation. The<br\/>understanding and insights gained as a result of the research will lead to the establishment of the theory,<br\/>design principles, and guidelines for building scalable QoS controls for the future Internet. This, in turn,<br\/>will allow reasoned and informed choices to be made as the next generation Internet takes shape.","title":"ITR: Collaborative Research:Scalable Quality-of-Service Control for the Next Generation Internet: Fundamental Challenges and Effective Solutions","awardID":"0085848","effectiveDate":"2000-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["499259","564706","545655"],"PO":["7594"]},"55764":{"abstract":"EIA- 0086230<br\/>Chen, Su-Shing<br\/>University of Missouri - Columbia<br\/><br\/>CISE Educational Innovation: Integrating Agent Technology into CISE Curriculum Using Lecturelets<br\/><br\/>This project integrates research results from agent technology into both course delivery mechanisms and course content in computing curricula. Specific \"smart\" learning materials for individual subjects, including definition\/description, examples, exercises, quizzes, projects, and supplemental information are developed and implemented into lecturelets (active XML documents with Java code) for customized interactive presentation of subjects. The lecturelets are self-contained and can be integrated into a wide range of courses. They contain both the XML documents and the instructions (templates\/agents) on how documents should be processed or displayed according to the profile and model of a student. In addition to developing the lecturelets delivery system, the project also provides course materials (i.e. a collection of lecturlets) on agent technology that can be used as a stand-alone course or integrated into existing courses in such fields as software engineering, distributed systems, communication systems, and AI-related courses.","title":"CISE Educational Innovation: Integrating Agent Technology into CISE Curriculum Using Lecturelets","awardID":"0086230","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["257164","498256","564156"],"PO":["551712"]},"54675":{"abstract":"As computers become pervasive in the home and community, new applications<br\/>will emerge that will make daily living easier by automating <br\/>or assisting in a variety of human activities. Such<br\/>applications will be information rich and they will create and manipulate<br\/>sensitive information about the activities of their users, and <br\/>the environment in which they live and work. At the Georgia <br\/>Institute of Technology, an information rich \"Aware Home'' has<br\/>been built to explore many such applications. Clearly, it is important<br\/>that such applications be secured if they are to be deployed successfully.<br\/>This project will undertake a range of research activities to<br\/>secure future applications. These include new security policies <br\/>for such applications, and intuitive and flexible access <br\/>control models. A variety of automatic user identification <br\/>techniques will also be investigated to authenticate sources<br\/>of requests without requiring burdensome participation from the users <br\/>making the requests. New notions of integrity for information accessed from <br\/>outside sources will be developed. The authorization, authentication and <br\/>integrity mechanisms will be used to build security services<br\/>for emerging applications. The use of formal models <br\/>will be explored to study important properties of the new security <br\/>policies and access control models.","title":"ITR: Mechanisms for Securing Emerging Applications","awardID":"0081276","effectiveDate":"2000-09-01","expirationDate":"2004-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["549757","186547","508256"],"PO":["309350"]},"43312":{"abstract":"The mainstream approach to improving the quality of IC testing is to develop better tests that target more realistic failure mechanisms. This project is investigating an orthogonal approach that promises significant improvements in the effectiveness of any given testing procedure by employing wafer based spatial test information as additional input in interpreting test results. This spatial information is useful in making the best possible judgement about circuit quality because of the widely observed clustering of defects on semiconductor wafers, and the fact that circuit parameters track closely for adjacent dice on the same wafer. Early results indicate the potential for defect level improvements up to an order of magnitude in screening for high quality circuits, and the possibility of screening out potential early-life failures, without expensive burn-in tests. On-going research aims at validating these findings on new, more voluminous, industrial test data, and also developing analytical models to estimate the test quality improvements. The new approach is also being investigated for developing neighborhood-based thresholds for optimally interpreting test results in non-Boolean test approaches, such as IDDQ and very low voltage testing.","title":"Wafer Oriented Trend Analysis for VLSI Test Opitmazation","awardID":"9912389","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["335880","550443"],"PO":["562984"]},"56864":{"abstract":"Interconnect has been recognized one of ten hardest problems in nano technologies. A basic observation underlying this project is that nano-interconnect issues are much similar to that in real-world communication. Much research has been conducted to ensure the reliable, fast and secure communication over a noisy and stochastic environment. Therefore, the research is exploiting communication-theoretic principles and developing innovative signaling concepts in solving the stochastic nature of nano interconnect. The primary focus is on nano silicon technologies in CMOS with feature sizes below 100nm, and the goal is to explore ways to achieve reliable and fast signaling over the noisy and stochastically limited nano-interconnect environment. The specific objectives are<br\/>1. to develop realistic-yet-simple communication models for various nano interconnect scenarios,<br\/>2. To study fundamental signaling limits dictated by communication theory (estimates of achievable rates indicate up to Tbits\/sec.),<br\/>3. to demonstrate interconnect design techniques for nano-signaling that can potentially approach the theoretical signaling limits<br\/>This is being made possible by a combination of several innovations that include (i) multi-wire (differential) full-duplex signaling, (ii) signal modulation, coding and equalization, and (iii) utilization, instead of avoiding, very-deep-submicron (VDSM) effects such as wave transmission for potential signaling.","title":"SGER: Application of Communication-Theoretic Principles to Nano Interconnect Research","awardID":"0090012","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["529904","431529","182786"],"PO":["562984"]},"55775":{"abstract":"Institution: William Marsh Rice University<br\/>Proposal Number: EIA 0086264<br\/>PI: Moshe Y. Vardi<br\/>Title: Collaborative Research: Integrating Logic in the Computer Science Curriculum<br\/><br\/>This CISE Educational Innovation (EI) proposal requests funds to develop a series of modules that seamlessly integrate logic and logic-based software tools into existing, widely taught computer science (CS) courses. Few undergraduate computer science curricula prepare students adequately in logic. The typical student sees a few weeks of truth tables and propositional logic in discrete practical work. These modules would allow CS departments to easily modify their curricula to rectify this situation. By supplying modules, complete with lecture notes, presentations, problem sets, and tools, the investigators hope to facilitate curricular treatment of applied logic at all levels of college education, particularly in CS departments with scarce resources. This project has the potential to have a major impact on the way that CS is taught.","title":"Educational Innovation: \"Collaborative Research:\" Integrating Logic in the Computer Science Curriculum","awardID":"0086264","effectiveDate":"2000-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["475166","565263","393034"],"PO":["551712"]},"54686":{"abstract":"EIA-0081327<br\/>Krishnamurthy, Prashant<br\/>University of Pittsburgh<br\/><br\/>ITR: Educating a Wireless Information Systems Workforce<br\/><br\/>The primary objective of this project is to develop and implement a<br\/>wireless information systems degree track that provides a unique education<br\/>in the development, design, and deployment of wireless information systems<br\/>with an emphasis on emerging wireless data technology. The goal is to<br\/>produce information technology (IT) professionals with the knowledge to<br\/>address the special challenges (e.g. user mobility, adverse communications<br\/>channels, limited battery life) posed by emerging wireless information<br\/>systems. A secondary objective is to develop innovative instructional<br\/>methods and tools using wireless devices in the classroom and laboratory<br\/>that extend through K-16 education. The research and coursework associated<br\/>with this educational track are needed to help meet the explosive demand<br\/>for IT professionals from wireless service providers, wireless equipment<br\/>manufacturers, applications developers using wireless systems, and wireless<br\/>information systems users.","title":"ITR: Educating a Wireless Information Systems Workforce","awardID":"0081327","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1359","name":"RES EXP FOR TEACHERS(RET)-SITE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["531589","466424",139706],"PO":["564318"]},"43323":{"abstract":"This grant will develop novel high performance numerical algorithms and codes for critical problems in large dynamical systems. This includes reducing models to fewer degrees of freedom, better eigenvalue solvers, and parallel implementations. This project has applications ranging from control systems to electric power systems, circuit simulations, earth sciences (meterology, hydrology), and filtering.<br\/><br\/>This is a joint project together with CCR-9912388 by Ahmed Sameh of Purdue University.","title":"Efficient Algorithms for Large Scale Dynamical Systems","awardID":"9912415","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["538628","225569"],"PO":["321058"]},"55665":{"abstract":"EIA-0085921<br\/>Kortemeyer, Gerd<br\/>Michigan State University<br\/><br\/>Information Technology Research: Investigation of a Model for Online Resource Creation and Sharing in Educational Settings<br\/><br\/>The advent of widely accessible networked computer technology has opened<br\/>new avenues for educators, yet the creation of appropriate resources for<br\/>this medium is extremely time and effort intensive. To truly become more<br\/>effective than a textbook, a resource needs to take advantage of its medium<br\/>by being interactive and part of a learner-centered, adaptable and<br\/>individualizing whole. This research project is designed to address<br\/>questions of resource pooling and sharing across content areas. The<br\/>investigators will incubate multi-institutional collaboration and bring<br\/>together stakeholders to address content issues such as reuse,<br\/>customization, online community building, quality, and effectiveness. An<br\/>existing software system under development will be used as a model to<br\/>support the formation and study of an online collaborative community,<br\/>including workshops, conferences, support, evaluation, and dissemination.","title":"ITR: Investigation of a Model for Online Resource Creation and Sharing in Educational Settings","awardID":"0085921","effectiveDate":"2000-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1359","name":"RES EXP FOR TEACHERS(RET)-SITE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"7444","name":"NATIONAL SMETE DIGITAL LIBRARY"}}],"PIcoPI":[142632,"490497","340620",142635,"473916"],"PO":["564181"]},"54697":{"abstract":"Parallel computing has promised very high performance, but has delivered it only in a narrow range of applications. Exploiting parallelism at the level of large distributed-memory systems is hampered by the cost of message-passing, while shared-memory systems remain mostly small-scale. With the advent of symmetric multiprocessors (SMPs), however, shared-memory on a modest scale is becoming the standard for desktop scientific and engineering applications. Yet very little has been done yet to support effective parallel computing on an SMP beyond basic linear algebra and fast Fourier transforms. Fortunately, preliminary work by the investigators indicates that it is possible to design and implement algorithms for irregular (i.e. graph-based) computations that provide efficient, scalable performance on SMPs. This project will further develop, implement, assess, and refine those algorithms.<br\/><br\/>Technically, the project will focus on science-driven problems that are graph- or geometry-based (e.g. phylogeny tees and watershed modeling) and thus involve irregular computation. It will provide three main benefits for these problems. First, it will develop new algorithms and a library of basic routines to support graph and computational geometry algorithms, leveraging insights from nearly twenty years of theoretical work on Parallel Random Access Memory (PRAM). Second, it will produce an assessment methodology for SMP-based computations using both generated test instances and real-world data, extending recent developments in algorithmic engineering and experimental algorithmics. Finally, it will provide a practical demonstration of high performance computing on desktop SMPs for scientific problems.","title":"ITR: Algorithms for Irregular Discrete Computations on SMPs","awardID":"0081404","effectiveDate":"2000-09-01","expirationDate":"2004-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["229244","558497"],"PO":["551992"]},"48900":{"abstract":"Image synthesis is an important problem for such diverse fields as architecture, lighting and industrial design, scientific visualization, simulation systems, entertainment, and advertising. An important, largely unexplored area of computer image generation is the simulation of weathering and its effects on appearance. Weathering results from the interaction of the environment with the materials in the world. <br\/><br\/>Current computer graphics models of materials are based on the physics of idealized surfaces that exhibit ideal diffuse, glossy, or specular reflection. However, such idealized materials rarely exist and are hard to produce. In order to make such idealized materials look realistic, animators and modelers often apply many textures. Unfortunately, this use of texture maps is very ad hoc and labor intensive, and it is in conflict with the use of idealized models. What is needed are physically-based models of real materials that incorporate their possible life histories, and hence, possible appearances. <br\/><br\/>The goal of this project is to devise new computer models of materials that can sustain a range of appearances over time. Through an NSF-CAREER award, we have made significant headway on this problem and built critical infrastructure for future work. In this Accomplishment-Based Renewal (ABR) proposal, we provide a brief summary of several new directions that build on our initial work, including the study and modeling of several additional materials, simulations of environmental factors that affect appearance, surface representations and modes of interaction, a measurement device, and techniques for rendering light transport in materials with complex internal structures. <br\/><br\/>This work has the potential to greatly expand the visual realism of synthetic images and reduce the reliance on tedious ad hoc techniques by providing fundamental, sophisticated models for materials and the processes that affect their time-varying appearance. In addition to the work's importance in computer graphics, this research should benefit such applications as scientific visualization, architecture and preservation, advertising, entertainment, art restoration, automotive design, geology, civil engineering, and environmental sciences. <br\/><br\/>Because the project draws on material from several other disciplines such as applied math, geology, materials science, optics, and physics, it promises to add new dimensions to the field of computer graphics.","title":"Computer Graphics Techniques for Modeling and Rendering Weathered Materials","awardID":"9988535","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["548698"],"PO":["532791"]},"55676":{"abstract":"The emergence of new applications has fostered a number of attempts to add functionalities to the minimalist Internet core. However, the adoption of enhancements to the Internet has either been slow, failed entirely, or limited to special-purpose private networks. The key reasons for this failure are extensibility and scalability: First, IP networks were not designed to be extensible at the internetworking level. Second, proposals for new network layer services often require that vast amounts of state information be managed in the core network infrastructure, thus, introducing scalability bottlenecks which exacerbate the existing scalability problem of the growing Internet.<br\/> Today, the development and deployment of advanced services on the Internet has reached a crossroads: efforts to add new services have quickly encountered scalability problems, yet new services are in critical demand and must be rapidly and widely deployed.<br\/> The research goal is to develop truly scalable services for each of the three fundamental components of the Internet's infrastructure: information communication, replication, and storage. Taking a new and unified approach to the seemingly conflicting requirements for scalability and sophisticated network services, the researchers propose to develop:<br\/> 1. Scalable Performance-Predictable Communication: a new foundation for quality-of-service communication via a scalable edge-based architecture.<br\/> 2. Scalable Multicast for Efficient Data Dissemination: a self-organizing multicast infrastructure scalable to many spontaneously-formed groups.<br\/> 3. Scalable Storage for Next Generation Information Services: an infrastructure which brings information<br\/>closer to users and enables scalable third-party information storage services.<br\/> 4. Design Principles of Scalable Services: a multi-faceted approach for the development and deployment<br\/>of scalable services in the global Internet, under consideration of economic models, industrial structure,<br\/>theories and algorithms, engineering, and deployment.<br\/> Thus, this project proposes to develop architectures and methodologies for deploying scalable services in the global Internet. The impact of this project will be to provide the theoretical underpinnings, basic architecture, and a prototype implementation for the information communication of the global Internet of the 21st century. An integral part of this project is the dissemination of results and the infiltration of standard organizations with the concepts developed within this project, and innovative approaches to educate the next generation of engineers for the future Internet.","title":"ITR: Collaborative Research: Scalable Services for the Global Network","awardID":"0085955","effectiveDate":"2000-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["263351","540768"],"PO":["543507"]},"55687":{"abstract":"Current software design concepts for products, processes, projects, programs, portfolios, and policies largely overlook a simple but fundamental idea: the goal of software design decision making is to create the maximum value added for any given investment of valuable resources. In a business context, profit and opportunities to profit are most valued. In other context, other measures of value apply, such as the solution of major social problems by philanthropic foundations. The investigation will focus on developing and enhancing scientific foundations for software design decision-making models, methods and tools explicitly tied to value-maximization objectives. Strategic approaches to value creation under conditions of uncertainty, incomplete knowledge, competition, and the need for cooperation among self-interested stakeholders will receive particular attention. The research is a joint effort of the University of Virginia, Carnegie Mellon University, the University of Washington, and the University of Southern California.","title":"ITR: Strategic Software Design: Value-Driven Software Definition, Development, Deployment and Evolution","awardID":"0086003","effectiveDate":"2000-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["262262","504468","450771","469318"],"PO":["564388"]},"52189":{"abstract":"EIA-0071924<br\/>Gurindar S. Sohi<br\/>University of Wisconsin-Madison<br\/><br\/>Experimental Partnership-Experimental Research in Speculative Multithreading<br\/><br\/>Speculative threads do not depend on conservative guarantees of safe data communications among threads. Rather, threads are dispatched speculatively, and data can be communicated speculatively. i.e. by assuming that it is correct. Incorrect speculations are detected later, and whenever they occur, recovery is under taken to assure correctness. This less conservative approach to defining and dispatching threads find parallelism in ways that conservative methods cannot.<br\/><br\/>In this research, the principal investigators will build a comprehensive, integrated experimental infrastructure and use it to carry out an investigation of issues related to the design of speculative multithreaded processors. Along with their graduate students the principal investigators will conduct experimental research in speculative multithreaded processors. Modern parallel processing systems decompose a program into multiple threads that execute in parallel to provide high performance. The convention method is to specify parallel threads where all communication of data is carefully synchronized to guarantee correctness a priori. This approach often means that a conservative approach must be used to provide the necessary guarantees, there by constraining parallelism. <br\/><br\/>Using this infrastructure, the investigators will conduct experimental research in three primary areas.<br\/><br\/>(1) Speculative Thread Identification and Usage. This will include conventional \"control-driven\" threads where the focus will be on new opportunities provided by object-oriented programs and commercial workloads. It will also include \"data-driven\" threads, a new form of speculative thread, which promises to open new opportunities for extracting parallelism from conventional programs.<br\/><br\/>(2) Software\/Hardware Interaction. Dynamic program characteristics of threads are likely to be critical<br\/>for managing their identification, scheduling, and data communication. Dynamic linking will be done as well, in many large network-based applications and will very much limit the static compiler's view. The investigators will research new methods by which hardware and software can interact to compile and execute speculative multithreaded programs. This will include architecture features to permit efficient communication and the use of dynamic profiling and re-compilation techniques.<br\/><br\/>(3) Hybrid \"Mixed Thread\" Processing. In future processors and systems, it is likely that several thread types will co-exist. This includes the speculative threads that are the central focus of the proposed research. It also includes the traditional non-speculative threads, which may be either explicitly programmed or implicitly extracted b software compilation tools and\/or hardware. Consequently, processors and systems that integrate the complementary thread types into a cohesive \"mixed thread\" processing model will be developed and studied.","title":"Experimental Partnership-Experimental Research in Speculative Multithreading","awardID":"0071924","effectiveDate":"2000-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4725","name":"EXPERIMENTAL SYSTEMS\/CADRE"}}],"PIcoPI":["552216","438221"],"PO":["297837"]},"55588":{"abstract":"Proposal Number: 0085670<br\/>Title: Interactions of Multithreaded Computing and Operating System Design<br\/>PIs: Henry M. Levy and Susan J. Eggers<br\/><br\/>Abstract:<br\/><br\/>Over the next decade, highly scalable computer systems consisting of<br\/>hundreds or thousands of nodes will become necessary to meet the<br\/>demands of emerging global applications, such as Web and database<br\/>servers used for Internet commerce. These applications must be<br\/>multithreaded to handle the thousands of simultaneous requests. One<br\/>promising technology for this scalable server domain is the use of<br\/>multithreaded processors; for example, Compaq has announced<br\/>Simultaneous Multithreading (SMT) support for its Alpha processor <br\/>in the 2002\/2003 time frame.<br\/><br\/>Unfortunately, no research has been conducted on multithreading<br\/>support for operating systems or on how to structure operating systems<br\/>for multithreaded CPUs. Yet the OS may be crucial in this environment;<br\/>e.g., measurements show that a loaded web server can spend 75% of its<br\/>time in the OS. The proposed research will develop the software<br\/>environment to complement the multithreaded hardware environment<br\/>provided by SMT and other fine-grained parallel processors. The<br\/>research sits squarely between architecture and operating systems,<br\/>examining (1) the design and performance of multithreaded processors<br\/>to support OS needs, and (2) the structure of operating systems in<br\/>light of the capabilities of multithreaded processors. The research<br\/>will focus on these questions in the domain of highly parallel,<br\/>request-driven workloads, such as Web servers and database servers.","title":"ITR: Interactions of Multithreaded Computing and Operating System Design","awardID":"0085670","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["450764","450774"],"PO":["223414"]},"48823":{"abstract":"The goal of this research project is to make it possible to process approximate queries on combinatorial structures such as trees and graphs in a fast (i.e., sublinear with respect to the number of objects being searched) and efficient manner. The ultimate goal is to be as fast as approximate keyword search in text documents. The approach consists of: (1) discovering the best heuristics for answering these NP-complete problems in polynomial time with high quality, and (2) discovering data structures to make queries on thousands or millions of such objects fast. The results of this project will provide techniques and software to search for patterns among graph and tree structured data. Possible applications of such a search engine include searches among proteins, chemical compounds, neuroanatomical structures, Web\/text filters and XML documents. The techniques developed in this research are in particular suitable for bioinformatics and biocomputing applications. Professors Shasha and Wang plan to collaborate with five additional researchers in these areas: Jack Collins, National Cancer Institute working in small molecule-protein docking for drug design; Michael Donohue, Professor of Biology and Director of the Harvard University Herbaria planning to apply this research to phylogenic trees; Bruce Shapiro, National Cancer Institute developing algorithms and computational systems for determining structure\/function of nucleic acids; Cathy Wu, National Biomedical Research Foundation doing research in analysis and classification of protein sequences; and Daniel Zaharevitz, National Cancer Institute whose goal is to make biological and structural data more available to the research community via better search capabilities. These collaborators help to motivate and validate the tree and graph matching tools and algorithms development for biological applications.<br\/>http:\/\/www.cis.njit.edu\/~jason\/sigmod.html","title":"Collaborative Research: ASES: An Approximate Search Engine for Structure","awardID":"9988345","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["563679"],"PO":["563751"]},"54389":{"abstract":"EIA-0080119<br\/>Towsley, Donald F.<br\/>University of Massachusetts<br\/><br\/>CISE Research Infrastructure: Infrastructure to Support Research on Mixed Wired\/Wireless Information<br\/><br\/>The goal of this project is research and development of control strategies, and services required by application suites executing over mixed wired\/wireless networks. The future of networking will introduce a setting where individuals and embedded processes will communicate among themselves and with multimedia information servers over a network made up of diverse network technologies, including ad-hoc and cell-based wireless, and wired segments. This network will seamlessly provide a diverse range of information-based services. This reflects a fundamental shift in the way users will compute and communicate in the future, moving from today's wire-based network where users are immobile and know where to obtain services to an environment in which users are mobile, may be connected through wireless, perhaps even in an ad-hoc manner, and request and receive services in a transparent manner. <br\/><br\/>The project will produce the fundamental advances required in the areas of coding and modulation, access protocols, routing, quality of service, operating systems (OS), database systems, security, and performance evaluation, that will be needed to produce this next generation network. These advances will occur as the result of an integrated, collaborative, and multidisciplinary effort spanning a wide range of disciplines in computer science and electrical engineering at the University of Massachusetts.","title":"CISE Research Infrastructure: Infrastructure to Support Research on Mixed Wired\/Wireless Information Systems","awardID":"0080119","effectiveDate":"2000-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["226157","558563","545655","443993","545656"],"PO":["297837"]},"69415":{"abstract":"","title":"Intelligent Data Analysis for Identifying Protein Disorder","awardID":"0196237","effectiveDate":"2000-09-01","expirationDate":"2002-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["438166","486283"],"PO":["564456"]},"55016":{"abstract":"Surround perception is crucial for an immersive sense of presence in communication and for efficient navigation and surveillance in robotics. To enable surround perception, new omnidirectional systems<br\/>provide a new impetus for us to rethink the way images are acquired and analyzed. This project will be focused on two fundamental issues: the intrinsic geometric properties of catadioptric omnidirectional sensors and the space-variant signal analysis of omnidirectional images with non-uniform resolution. The PI has proven in the preliminary work that every catadioptric system can be shown to be equivalent to a generalized stereographic projection from a virtual sphere to the real image plane. He intends to develop a unifying framework for all catadioptric systems, where conventional perspective cameras will be just a special case, and exhaustively study invariants of the projections on reflective urfaces as well as efficient representations for reconstruction and<br\/>motion estimation. Catadioptric designs need a new signal-theoretic treatment since<br\/>shift-invariant processing does not apply in the non-uniform resolution of omnidirectional images. This research will make use of integral transforms that map the 2D signal to<br\/>the spatial-frequency domain of a plane with virtually uniform resolution. The investigation will be extended from the simple edge detection to template matching and to the computation of optical flow in omnidirectional images.","title":"Omnidirectional Vision","awardID":"0083209","effectiveDate":"2000-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["549664"],"PO":["234178"]},"55258":{"abstract":"Research has shown that for some tasks computer input is best performed by manipulating physical objects. This project will explore the integration of paper and pixels for collaborative web design. The PI will investigate tangible and pen interaction techniques to support collocated collaboration for creating information hierarchies, as well as tools and interactions that support versioning of a physical artifact as well as manipulation of the artifact when all or part of the physical representation is unavailable. The PI will try to better understand virtual representations of a tangible information space for remote collaboration by creating a desktop GUI that allows remote users to see and manipulate the information space. He will explore the use of a \"two-board UI\" for hybrid tangible\/virtual interaction, where designers in physically distant places can collaborate through the artifact under design. A strength of this project lies in its foundation in actual work practice, as observed by both the PI's research group and others. To insure the utility of the prototype system, the PI will conduct extensive evaluation of different areas of the system, and iterate system design based on these evaluations. He will have designers create actual information architectures on the prototype running in the lab, and will also perform long term usability studies by deploying a working prototype of the system in a web design firm. An outcome of the project will be a publicly available vision toolkit that can be used for tracking physical objects on a flat surface, and which will enable HCI researchers to create vision-based tangible user interfaces absent domain knowledge in computer vision. The work will contribute a better understanding of techniques for combining tracked physical objects with an interactive display surface, and will also contribute new techniques for collocated and remote collaboration, as well as a better understanding of the means of interacting with large, physical information architectures.","title":"The Designer's Outpost: A Task-centered Tangible Interface for Web Site Information Design","awardID":"0084367","effectiveDate":"2000-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6846","name":"UNIVERSAL ACCESS"}}],"PIcoPI":["483342"],"PO":["565227"]},"55038":{"abstract":"This project focuses on ibots, interface agents that interact with software applications through the graphical user interface, through the same medium as human users. The project will have two main thrusts. First, the PI will define a taxonomy of tool use in the user interface, based on descriptions of user behavior in a variety of common applications, and he will build a computational model of agent tool use that integrates work on visual routines and cost-based user modeling. An environment for agent exploration and evaluation will then be developed, to include sets of tools in three distinct task areas: support for the construction of domain descriptions and the incremental build\/test cycle for agent development; support for the exploration of different control strategies in carrying out these tasks; and support for the evaluation of interface agent performance. As this environment is completed, the PI will evaluate it along two parallel tracks, as a mechanism allowing cognitive models to interact with off-the-shelf software, focusing on models in the ACT-R, Soar, and LICAI frameworks, and as a testbed for developing new problem domains for planning algorithms. This work will have an impact in several areas. It will allow cognitive modeling researchers to evaluate their models in actual (not simulated) environments, a long-standing goal for researchers in this area. It will provide a comparable benefit to planning researchers, who also need domains that are both real and tractable for their planning algorithms. It will produce novel interface agents and domain descriptions, with opportunities to test the adequacy of existing agent designs against real-world problems at a relatively low development cost; the project also has the potential to increase the visibility of interface agents research, by allowing agents to work in previously inaccessible areas. Finally, it will result in a model and implementation of agents specialized for tool use, an area of ecological research that remains unexamined to date, and which should contribute significantly to our understanding of complex software environments.","title":"User Interface Softbots","awardID":"0083281","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["289699"],"PO":["491702"]},"47438":{"abstract":"EIA-9983463<br\/>Bostian Charles W.<br\/>Virginia Polytechnic Institute<br\/><br\/>Digital Government: Testbed for High Speed \"End to End\" Communications in Support of Comprehensive Emergency Management<br\/><br\/>This project will explore the use of rapidly deployable \"last mile\" aerostat-based wireless high-speed communications in the environment of emergency management. The technology base will be Local Multipoint Distribution Service radio. An important element of the work will be rapid deployment, so equipment must be portable and able to access remote databases and GIS engines; a base station and two field units will be constructed. The primary partner agency initially will be the National Response Center, which is responsible for responding to chemical spills, toxic agent release, and related environmental problems. Other agencies, such as the Federal Emergency Management Agency, will be targets for future partnerships","title":"Digital Government: Testbed for High-Speed 'End-to-End' Communications in Support of Comprehensive Emergency Management","awardID":"9983463","effectiveDate":"2000-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"X759","name":"JUSTICE-WORLD WIDE WEB"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1100","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}}],"PIcoPI":["282036","296385"],"PO":["371077"]},"69229":{"abstract":"","title":"(EGB) Development and Compilation of Geochemical Kinetic and Biochemical Data Base and Numerical Modeling of Reactive Transport in Subsurface Media","awardID":"0196048","effectiveDate":"2000-09-01","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0603","name":"Division of EARTH SCIENCES","abbr":"EAR"},"pgm":{"id":"1584","name":"ENVIRO GEOCHEM AND BIOGEOCHEM"}}],"PIcoPI":[179263],"PO":["376131"]},"52751":{"abstract":"This research is concerned with algorithmic, performance, and hardware issues related to reduced-rank adaptive filtering. Reduced-rank filters project the incoming received signal onto a lower dimensional subspace, which reduces the amount of training data needed relative to a conventional full-rank algorithm.<br\/> Algorithmic techniques will be studied initially within the context of interference suppression for Direct Sequence (DS)-Code-Division Multiple Access (CDMA), although they can be applied to any adaptive linear filter. The focus of the research is on a recently developed class of reduced-rank adaptive algorithms based on the multi-stage Wiener filter of Goldstein and Reed. This technique can achieve full-rank performance<br\/>with a very low filter rank, which enables rapid convergence and tracking. Furthermore, these algorithms<br\/>do not rely on an explicit estimate of the signal subspace. The project is multi-disciplinary in that it combines the expertise of the two co-PIs in the areas of adaptive signal processing and low power VLSI design.<br\/>The main objective of the research is to build a low-power special purpose hardware prototype, which can serve as the computational engine for reduced-rank filtering in a variety of applications. Algorithmic issues to be studied include selection of filter rank, performance in different adaptive filtering applications, such as equalization, and numerical stability and dynamic range problems.","title":"Adaptive Reduced-Rank Interference Suppression: Algorithms, Performance, and Low Power VLSI","awardID":"0073686","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["547185","560216"],"PO":["564898"]},"54830":{"abstract":"The fundamental project hypothesis is that management and control of the Internet is the ideal<br\/>application of active networks; the researchers propose a system architecture to test this.<br\/>Active Networks are constructed from elements, such as packet routers, allowing programmability<br\/>on a per-user or even per-packet basis. With the new software capabilities available from systems such as Caml and Java, active networks offer the promise of more rapid adaptation to changes in technology or requirements, and more rapid introduction of new services. These potential advantages come with the disadvantages of increased complexity, and its consequences for performance and security.<br\/> Early prototype systems (ANTS, CANES, Smart Packets, SwitchWare and others) illustrated<br\/>various points in the design space, trading off among usability, performance, and security. The<br\/>prototypes demonstrated first, that such systems could be built, that applications did indeed exist,<br\/>(e.g., Active Bridging and Active Reliable Multicast), and second, that they performed well enough<br\/>(10-100 Mbps) to handle the throughputs of almost all current Internet access points. Thus much<br\/>of the \"edge\" of the Internet can add active network capabilities with minimal performance impact.<br\/> A more interesting possibility exists, that of using active networking technology to incrementally<br\/>activate the IP Internet. The researchers believe this can be achieved, as described within the proposal, by<br\/>co-locating programmable elements with IP routers capable of fast packet forwarding. The researchers have<br\/>experimented with this idea on a small scale and it offers considerable promise for increasing the<br\/>manageability of the Internet with its exponential increases in scale.<br\/> The Global Active IP Network (GAIN) project represents the University of Pennsylvania's<br\/>research program as part of a larger 10M Euro research effort (FAIN). FAIN was considered and<br\/>top-ranked within the E.U. IST Programme competition. European members were funded, with the<br\/>expectation that Penn would seek funding from U.S. sources. The consortium includes University<br\/>College London (UK), the Jozef Stefan Institute (Slovenia), the National Technical University of<br\/>Athens (Greece), the Universitat Politecnica de Catalunya (Spain), Deutsche Telekom Berkom<br\/>(Germany), France Telecom\/CNET (France), KPN (Netherlands), Hitachi Europe Ltd. (UK),<br\/>Hitachi Ltd. (Japan), SAG ICN (Germany), ETH Zurich (Switzerland), GMD Forschungszentrum<br\/>Informationstechnik (Germany), IKV++ (Germany), INTEGRASys (Spain), and U. Penn in the<br\/>United States. This proposal to NSF is a request for funds to support Penn in this international<br\/>consortium.<br\/> Penn's focus with GAIN is applications of Active Networks to IP network resource management<br\/>and security. The researchers will investigate the prevention and mitigation of sophisticated \"denial of service\" attacks on security. The researchers are playing a strong role in experiment definition and evaluation for FAIN. This proposal to NSF provides background on Active Networking, outlines the research goals for an active IP network, sets this work with the context of FAIN, and argues the importance of providing U.S. participation in a truly global consortium with European and Japanese collaborators.<br\/>( The FAIN proposal has been provided to NSF.)","title":"Global Active IP Networks (GAIN): Support for U.S. Participation in International FAIN Consortium","awardID":"0082386","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["527253","276437"],"PO":["250082"]},"54720":{"abstract":"Reasoning about the behavior of large component-based software systems demands a \"modular\" or \"compositional\" reasoning system, in which summary properties of a system's pieces are composable to deduce properties of the entire system without delving into the internal details of those pieces. This research focuses on contributing principles for how to design component-based software that supports modular reasoning, and to help bring this new knowledge into practical application with commercial distributed component technologies. Specifically, the project investigates: (1) developing and describing detailed principles for designing the interfaces of software components so that they support both modular reasoning about system behavior and effective and efficient distribution and execution; (2) showing how to write human-understandable behavioral specifications for the interfaces of components designed using the above principles; (3) demonstrating additional practical benefits from having formal specifications available to software engineering tools. The generality and efficacy of the results will be evaluated through construction of prototype tools that support distributed component-based software design and development in a programming-language-neutral environment, and by observing the effects of using such tools in the classroom to see how much students benefit from the tools' new specification-enabled capabilities as they<br\/>design and develop distributed component-based software systems.","title":"ITR: Principles of Distributed Component-Based Software","awardID":"0081596","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["508443","502515","418679",139808,"420959"],"PO":["564388"]},"54962":{"abstract":"This study will develop empirically grounded models and theories of the social processes, technical system configurations, organizational contexts, and interrelationships that give rise to open software. \"Open software\", or more narrowly, open source software, represents a new approach for communities of like-minded participants to develop software systems that are intended to be shared freely, rather than offered as commercial products. While there is a growing popular literature attesting to open software, there is little in the way of careful systematic empirical study that informs how such communities produce software; how they coordinate software development across different settings; and what social processes, work practices, and organizational contexts are necessary to their success. Thus, to the extent that science research communities and commercial enterprises seek the supposed efficacy of open software, they will need better grounded theories of use to allow effective investment of their resources. This study investigates four communities engaged in open software. Field study methods will be employed to examine each community from both a technical and social viewpoint. Studying both social and technical arrangements allows the examination of the continual emergence of both within a joint social-technical ecology. Case study methods will be used to compare across communities.","title":"ITR: Understanding Open Software Communities, Processes and Practices: A Socio-Technical Approach","awardID":"0083075","effectiveDate":"2000-09-01","expirationDate":"2005-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["535599","430298"],"PO":["564456"]},"54610":{"abstract":"CCR-0080898 <br\/> PI: Sebastian Elbaum Univ. of Nebraska - Lincoln<br\/> ITR:SW: Collaborative Research: A New Generation of Scalable,<br\/> Cost-Effective Regression Testing Techniques <br\/> Collaborating PI: Gregg Rothermel (CCR-0080900)<br\/><br\/>This project is carried out in collaboration with Gregg Rothermel (CCR-0080900)of Oregon State University. Regression testing is an expensive process performed on modified software to provide confidence that modifications have not impaired its quality. To help with this process, previous research has considered various test-suite reuse techniques. Despite progress with these techniques, they remain limited along several dimensions. For example, they typically assume that test cases have equivalent costs, faults have equivalent severities, and fault likelihood is constant across portions of a program. These assumptions are unrealistic in practice, and limit the applicability and effectiveness of techniques. The proposed research will address these limitations. The research will provide: (1) comprehensive regression testing cost models that capture the necessary factors; (2) regression testing techniques that account for these factors; (3) more precise understanding of the effects these factors have on regression testability, program and test design, and software engineering practice; and(4) guidelines that help software engineers select and create cost-effective regression testing tools and processes. In addition to providing models, algorithms, and processes, the research includes a substantial empirical component, and will provide a publicly available base of empirical data about techniques and factors. Together, these contributions will support more efficient and effective regression testing, and improve the quality of software.","title":"ITR: Collaborative Research: A New Generation of Scalable, Cost-Effective Regression Testing Techniques","awardID":"0080898","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["518212"],"PO":["564388"]},"54731":{"abstract":"The worldwide expansion of network access is driving an increase in interactions among people, among businesses, and between people and businesses. Such interactions are the staple of major Internet uses such as electronic commerce and virtual communities. Successful interaction relies heavily upon trust. Whereas security seeks to prevent illegal actions, trust goes beyond security in seeking assurance of accountability (of intent and capability) even for legal actions. However, figuring out whom to trust and to what extent is extremely difficult in an open networked environment such as the Internet. This project will study distributed, scalable computational approaches for trust management taking into account the different forms in which trust is exhibited in networked environments. Such approaches rely less on centralized authorities and more on community policing through reputation mechanisms. This project will evaluate the approaches based on criteria such as how easily a given approach can be bootstrapped, how efficient it is in helping members find competent and good peers, and how immune it is to invasion by untrustworthy members. This project will also study aggregate phenomena such as the emergence of subcommunities, linkages among subcommunities, and the sensitivity of a community to change in membership.","title":"ITR: Computational Principles of Trust","awardID":"0081742","effectiveDate":"2000-09-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["565158"],"PO":["564456"]},"55710":{"abstract":"Large-scale networked software systems are hard to design, and even more<br\/>difficult to validate. Validation of such systems is increasingly<br\/>important, since they are more and more being called on to perform critical<br\/>functions. This validation difficulty stems from the inherent complexity of<br\/>these systems, and often is due to the fact that they are often designed to<br\/>adapt to variable workloads and operating conditions at the process, node,<br\/>and network levels. Incorrect operation during periods of dynamic<br\/>adaptation can lead to unpredictable and potentially hazardous<br\/>consequences. In order to ensure that such systems operate correctly in<br\/>critical environments, one must perform validations to confirm that they<br\/>will function reliably in the presence of faults\/failures, have predictable<br\/>performance, and will continue to operate when intrusions occur. Validation<br\/>of multiple behavior dimensions (e.g., reliability\/availability,<br\/>performance, and survivability) is also critical. This research will<br\/>develop the theory, methodology, and tools necessary to experimentally<br\/>validate the reliability\/availability, performance, and survivability of<br\/>large-scale networked software systems. The intention is to develop a<br\/>comprehensive framework for experimentally validating large-scale networked<br\/>software systems. Taken as a whole, this work will provide a sound and<br\/>fundamental approach to validation of networked software and applications.","title":"ITR: Experimental Validation of Large-Scale Networked Software Systems","awardID":"0086096","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["542482","557160","345579","557162"],"PO":["180163"]},"54742":{"abstract":"The study of interacting fermions is fundamentally important to a wide range of physics research, including fields as diverse as electronic structure theory of solids, strongly correlated electron physics, quantum chemistry, and the theory of nuclear matter. Among other applications, the understanding of high-temperature superconductors depends on these interactions. This project will develop a new computational method for the controlled approximate solution of interacting fermion models. The method combines Monte Carlo (MC) summation techniques with self-consistent high-order Feynman diagram expansions. The implementation of the MC diagram summation method poses major algorithmic and computational challenges in several distinct areas of computational science and, by its very nature, requires a multi-disciplinary approach.<br\/><br\/>Technically, the project will develop novel computational graph theory algorithms and employ them to achieve a computationally efficient representation, generation and classification of Feynman graph topologies. New MC updating, scoring and variance minimization approaches will be implemented to carry out the simultaneous stochastic summation over diagram topologies and over internal momentum-energy variables. For the two-particle calculation, a novel combination of Lanczos matrix inversion and MC techniques is used to achieve efficient solutions of the Bethe-Salpeter equations with the full high-order irreducible interaction vertex. The efficient parallel implementation of the MC code is achieved by software pipelining and ring message passing approaches. These parallel applications are supported by novel parallel run-time systems that provide dynamic performance optimization.","title":"ITR: Stochastic Summation of High-Order Feynman Graph Expansions","awardID":"0081789","effectiveDate":"2000-09-01","expirationDate":"2007-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["564736","375746","517411",139870],"PO":["565272"]},"55721":{"abstract":"EIA- 0086142<br\/>Slator, Brian<br\/>North Dakota State University, Fargo<br\/><br\/>Title: Information Technology Research: Systems for Learning Science and Assessing Student Learning<br\/><br\/>This five-year project to study science learning in authentic, immersive,<br\/>virtual environments involving 1) simulated environments for teaching<br\/>science topics, each framed according to a theoretical approach, role-based<br\/>learning, 2) an innovative, integrated, distributed software platform for<br\/>developing and hosting virtual environments, 3) empirical studies using an<br\/>innovative protocol, scenario-based assessment, for measuring student<br\/>learning in virtual worlds, and 4) a graduate-level summer school course<br\/>for in-service teachers who will be trained, beginning in year three, to<br\/>use virtual environments in their classrooms. This interdisciplinary<br\/>project, in part, depends on fundamental computer science research in the<br\/>areas of distributed systems, software agents and intelligent tutoring, and<br\/>virtual environments. The intent of this research is to produce a large,<br\/>controlled study demonstrating the statistical significance of the impact<br\/>of the above methods on student learning.","title":"ITR: Systems for Learning Science and Assessing Student Learning","awardID":"0086142","effectiveDate":"2000-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["411407","537855","411408","411409","437989"],"PO":["564181"]},"52696":{"abstract":"Two problems that constrain big computations<br\/>appear to relax in the face of a different<br\/>representation for matrices and their constituent blocks.<br\/>Morton (or Z) order represents the elements<br\/>of a matrix in computer memory consecutively<br\/>by larger and larger blocks. This locality contrasts<br\/>with row-major (or column-major) order,<br\/>which stores only elements in the same row<br\/>(column) close to one another.<br\/><br\/>This project explores compilers for Morton order as<br\/>the default representation for arrays in higher-level programming<br\/>languages.<br\/>It develops techniques to recompile existing programs<br\/>to code that uses Morton-order internally<br\/>and respects modern memory hierarchies and superscalar processors.<br\/>These will interface cleanly to future programs that<br\/>use Ahnentafel indices, a generalization of Morton order,<br\/>to control divide-and-conquer algorithms to descend<br\/>blocks of a matrix recursively.<br\/>So, it also supports the design of parallel algorithms<br\/>that decompose a computation into disjoint, memory-local processes.<br\/><br\/>Morton order, and block algorithms that use it,<br\/>implicitly improve access patterns<br\/>into hierarchical memory:<br\/>from registers, through caches, to RAM, to swapping disk.<br\/>That is, Morton order enhances locality of reference<br\/>of one process,<br\/>while it helps to schedule multiple processes<br\/>that don't interfere with each other.","title":"Compiler Support for Morton-order Matrices","awardID":"0073491","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["430172"],"PO":["551992"]},"56942":{"abstract":"0090252<br\/>Inadequate long-term durability of civil engineering<br\/>infrastructure has been a major problem with enormous<br\/>economic loss to many countries. So far, progress<br\/>towards solving the problem has been hampered by the<br\/>lack of mathematical approaches among classical-type<br\/>durability researches, and lack of interest or<br\/>understanding of the qualitative mechanisms among<br\/>mathematician and mechanicians. The Workshop will<br\/>stimulate dialog between these two groups. The<br\/>workshop will be held at Czech Technical University,<br\/>Prague, in March or April 2002. Duration of the<br\/>Workshop is planned to be 2.5 to 3 days. About 40<br\/>participants are expected, of which 15 to 20 will be<br\/>from the U.S. Complementary funding from NATO and from<br\/>local sources in Prague will be applied.***","title":"NATO-NSF Workshop on Model-Based Simulation of Durability of Materials and Structures","awardID":"0090252","effectiveDate":"2000-09-15","expirationDate":"2003-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1281","name":"ANALYSIS PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1630","name":"MECHANICS OF MATERIALS"}}],"PIcoPI":["398834"],"PO":["371937"]},"55732":{"abstract":"With the advances in embedded processors, low cost sensor technologies, and wireless communication, unprecedented amounts of diverse types of information about the real world and its activities are being generated. Much of the information is spatio-temporal in nature; concerning objects dispersed in space and time, and interacting and communicating with each other and their surroundings. An infrastructure that facilitates real-time capture, storage, processing, display, and analysis of the information generated will truly revolutionize a wide variety of application domains. Examples of domains that will benefit from this technology include avionics, ground traffic, commercial applications such as ship-ping and transportation, emergency response and disaster relief operations, physical phenomenon such as weather and storm tracking, forest fire tracking, migration patterns of animals\/birds, command and control, smart environments, etc. Applications in the above domains require real-time monitoring, tracking and analysis of objects\/events\/phenomena in space and time. <br\/><br\/>An integral component of such sensor enriched communication and information infrastructure is a database management technology that allows seamless access to information dispersed across a hierarchy of storage, communication and processing units - from sensor devices, where data originates, to large data banks where the information generated is stored for analysis and mining. This research will explore next generation database management system technology that provides effective support for information processing in highly distributed and dynamic sensor-enriched environments. The approach taken will be end-to-end - that is, research will be conducted on all aspects of the system ranging from representation, data modeling, query languages, data structures, query optimization, query processing, distribution, and concurrent accesses. A prototype database management infrastructure that supports highly dynamic geographically dispersed spatio-temporal data, multi-resolution representation of data, and provides effective support for visualization and analysis will be developed.","title":"ITR: Collaborative Research: Real-time Capture, Management and Reconstruction of Spatio-Temporal Events","awardID":"0086162","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["551003"],"PO":["563751"]},"54764":{"abstract":"The explosive growth of biological information sources, available over the Internet, has given rise to both opportunities and challenges for biological and medical researchers. The opportunities they provide are both scientific (e.g., understanding the information encoded in elementary biological structures) as well as technological (e.g., new drug discovery). The challenges, on the other hand, lie in how to efficiently discover, among the vast volume of information, the items that are relevant or interesting to a given researcher. The objective of the proposed research is to investigate related basic research problems and develop a biological information delivery system in a collaborative project between computer scientists, information scientists, and biological researchers. The specific plans include developing methods to make the proposed system pro-active (surveying evolving on-line sources for relevant information), personalized (cognizant of a particular researcher's interests), adaptive (able to react to changes in the information sources as well as user interests or objectives), and capable of integrating multi-format data. The impact of this research is a significant enhancement in the ability of students and researchers in biological sciences to efficiently utilize on-line resources, while generating methods for computerized analysis of biological data and providing computerized support for new scientific discovery.","title":"ITR: An Active, Personalized, Adaptive, Multi-format Biological Information Delivery System","awardID":"0081944","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["496785","449790","355556","486226",139929],"PO":["564456"]},"55622":{"abstract":"Object-oriented programming languages, notably Java, are gaining broad use<br\/>because of their benefits, which come largely from their flexibility. But<br\/>this same flexibility makes Java programs more difficult to optimize in<br\/>advance. One sample collection of programs, optimized in advance, spent<br\/>40-95% of their time on an aggressive processor waiting for the memory to<br\/>provide data, illustrating the need to improve memory behavior. Future<br\/>processors will only make the problem worse.<br\/><br\/>The project makes an integrated attack on this problem, incorporating new<br\/>program analyses and optimizations, profile feedback, run-time techniques<br\/>including adaptive garbage collection algorithms, and ways of communicating<br\/>high-level predictions and observations of program behavior to the<br\/>hardware.<br\/><br\/>The project aims to design and build a compiler, run-time system, and<br\/>enhanced architectural and operating system features that react quickly and<br\/>gracefully to compiler predictions and actual run-time behavior to achieve<br\/>high performance. The goal is synergy via cooperation between the system<br\/>components versus solving each problem within an individual component.<br\/><br\/>While the research focuses on improving memory performance, the project's<br\/>envisioned framework is suited to a wide range of performance optimization<br\/>techniques, so the expected research results and software products have<br\/>broader impact.","title":"ITR: Dynamic Cooperative Performance Optimization","awardID":"0085792","effectiveDate":"2000-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["550864","517880","519591"],"PO":["325495"]},"54775":{"abstract":"EIA-0082041<br\/>Kitts, Christopher<br\/>Santa Clara University<br\/><br\/>ITR: An Internet Robotics Learning Testbed<br\/><br\/>This research involves the implementation of a project-based learning strategy through the development and use of an Internet Robotics Learning Testbed (IRLT). The IRLT will consist of a network of robots and control centers. The robotic devices will be used for exploratory missions ranging from ocean archeology to space science and the control centers will provide wireless communication with the remote robotic devices in order to send commands and receive data. Several IT learning challenges that emerge include human-computer interfaces, task planning, resource scheduling, fault detection and diagnosis, and goal-directed commanding. The IRLT will enable students to understand the need for specific IT applications, iteratively develop such applications, test application functionality in an operational environment, and experience application value in a mission setting. The IRLT will include a suite of services to support collaborating IT educators. These services will include an educator support program to train faculty in the use of the IRLT as an educational resource, several pre-packaged educational modules permitting the rapid and low-cost use of the testbed, and Web-based documentation providing engineering details, user manuals, guides for new experiments, and libraries of past IT applications. The IRLT will be centered in an undergraduate engineering curriculum and its high school outreach program. It will draw stakeholders from multiple universities and research laboratories who will serve as advisors and mentors.","title":"ITR: An Internet Robotics Learning Testbed","awardID":"0082041","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["428845","530335"],"PO":["564318"]},"55512":{"abstract":"HomeNetToo is a research project designed to address two fundamental questions: What causes people to use or not use the Internet? What effect does Internet use have on people? A model of Internet use is proposed that addresses these questions by considering motivational, affective, and cognitive factors as antecedents and consequences of Internet use. Participants in HomeNetToo will be low-income African American and European American families who will be introduced to the Internet as a communication tool or an information tool. On-line surveys and computer-logged measures of Internet use will be used to test hypotheses about the antecedents and consequences of Internet use over an 18-month trial. Relationships between cognitive style and interface design will also be examined. Results will have implications for how to reduce the digital divide, how to design user interfaces to accommodate diverse cognitive styles, and for identifying factors that influence whether Internet use will have desirable personal, social and professional consequences.","title":"ITR: HomeNetToo: Motivational, affective and cognitive factors and Internet use: Explaining the digital divide and the Internet paradox","awardID":"0085348","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["286162","286163","286164","345982",142146],"PO":["564456"]},"54665":{"abstract":"Object-oriented programming is the mechanism of choice for implementing high-end applications. However, the architectures supporting these applications continue to be biased toward array- rather than object-based<br\/>paradigms, where proximity of storage layout does not necessarily imply contemporaneous access.<br\/>Object-oriented programs do exhibit repeated patterns of storage access. Thus, a dynamic approach that can <br\/>facilitate intelligent pre-fetching of data into Caches or TLB's can better support object-oriented programs.<br\/><br\/>This research investigates the use of intelligent storage systems, such as Intelligent RAM (IRAM) and Processor in Memory (PIM) devices, to improve the performance of object-oriented programs in the following three ways. Storage management functions, such as allocation and garbage collection, are migrated to intelligent memory devices using algorithms that are not only efficient in execution time, but also simple in logic design. Storage prefetch functions, such as memory forwarding and jump-pointers, are migrated away from the CPU and its cache and into the intelligent storage system. Storage access idioms are captured, compressed, and sent to the intelligent storage system for execution.<br\/><br\/>The result of this research is the liberation of the CPU and its data cache from the overhead associated with the dynamic, garbage-collected storage of modern object-oriented languages.","title":"ITR: Intelligent Storage Systems for Object-Oriented Programs","awardID":"0081214","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["511555","525751"],"PO":["309350"]},"54786":{"abstract":"Optimization is the process of finding the smallest (or largest) value that a function can return. The demand for advanced optimization software tools is increasing sharply as the importance of optimization methodology in engineering, basic science, and finance is becoming more widely recognized. The dramatic increase in computing power, and the improvements in supporting technologies such as modeling languages and automatic differentiation, are fueling demand for optimization codes. These codes must solve more and more computationally challenging problems, including integer programming and nonlinear optimization problems.<br\/><br\/>This project will develop new algorithms and advanced software for large-scale nonlinear, nonconvex constrained optimization, with special emphasis on interior-point methods. Specific goals include (1) fundamental research on interior-point methods that have appealing convergence properties and robust behavior; (2) development of modern software that is well suited to implementation on advanced computing platforms and interoperable with relevant high-performance software; (3) integration of interfaces to modeling languages and automatic differentiation tools; and (4) free distribution of the software to the manufacturing, engineering, and scientific community through the NEOS web site.","title":"ITR: Collaborative: Innovative Software for Large-Scale Nonlinear Optimization (linked to NSF#0082065)","awardID":"0082100","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["549932"],"PO":["551992"]},"54797":{"abstract":"The PI has previously developed several variants of a new statistical framework based on the principle of maximum entropy (ME) for learning the joint probability mass function associated with a discrete (possibly high-dimensional) feature space. Although excellent results which surpass those attainable with competing approaches have been obtained, the PI is currently limited to handling small-to-intermediate feature spaces (up to 30 dimensions), and has only considered artificial general inference problems. The main objective in this project is to develop a large-scale extension of the new methods capable of handling hundreds, or even thousands, rather than tens of features, and to then apply the approach to emerging domains such as multiple topic retrieval from document databases and collaborative filtering. Applications to diagnosis and marketing will also be explored. Successful completion of this work will result in a practical set of ME tools that outperform existing methods and thus have a significant impact on large-scale inference tasks. The work will also develop principled methods within the ME framework for treating mixed continuous\/categorical data and arbitrary patterns of missing features. By attacking large-scale problems, heterogeneous data, and missing features, the work addresses some key challenges encountered in machine learning in practice.","title":"Maximum Entropy Model Learning for Classification and More General Inference Tasks: Large-scale Applications and Extensions","awardID":"0082214","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["556038"],"PO":["491702"]},"46701":{"abstract":"Multiuser Coding and Signal-Processing for Fiber-Optic WDM<br\/>Communication Systems<br\/>by Maite Brandt-Pearce<br\/>University of Virginia<br\/><br\/>Abstract:<br\/><br\/><br\/>The need for high speed data transmission has motivated the desire to<br\/>utilize the full capacity of optical fibers. The fiber optic channel<br\/>holds the potential for information transfer orders of magnitude faster<br\/>(in bits per second) than is currently exploited. Signal degradation<br\/>through the fiber channel is a key problem in accomplishing high<br\/>capacity, especially in long-haul links (transcontinental or<br\/>transoceanic) and large networks. This research explores pre- and<br\/>post-fiber coding and signal processing possible to reduce the effect of<br\/>channel degradation. Mastering these physical limitations of the fiber<br\/>medium can translate into a tremendous increase in the capacity of<br\/>existing infrastructure.<br\/><br\/>This research addresses the design and optimization of multi-channel<br\/>wavelength division multiplexed (WDM) fiber-optic systems. Multiuser<br\/>systems are typically broadband and high power, sometimes leading to<br\/>severe linear and nonlinear degradation in the signal due to properties<br\/>inherent to the fiber. The approach taken is a communications theoretic<br\/>approach, considering signal constellation, coding, channel<br\/>equalization, and joint signal detection. The research is to be<br\/>performed in three phases. The first is to identify best and worst<br\/>time\/wavelength sequences for WDM. Effective jointly optimal line-codes<br\/>for WDM systems will then be designed. The research will conclude with<br\/>a study of nonlinear equalization methods for crosstalk cancellation.<br\/>The tools used for optimization and system performance analysis are<br\/>input\/output descriptions of the fiber nonlinearity and system<br\/>simulation.","title":"Multiuser Coding and Signal-Processing for Fiber-Optic WDM Communication Systems","awardID":"9980618","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["523508"],"PO":["223414"]},"43324":{"abstract":"In all graph algorithms, graphs are encoded by binary strings.<br\/>The problem of encoding graphs by binary strings is a fundamental<br\/>problem in computer science. To be useful in graph algorithms,<br\/>an encoding of a graph G should be as short as possible and<br\/>support various graph queries and operations. The well known<br\/>adjacency-matrix and adjacency-lists representations are used by<br\/>virtually all existing graph algorithms. However, they do not satisfy<br\/>all of these requirements. New graph encoding schemes satisfying all<br\/>of these requirements for various graph families will be developed.<br\/>Once such an encoding scheme for a graph family is found, it will be<br\/>possible to improve and\/or simplify existing algorithms for solving<br\/>problems on this graph family. In addition to graph algorithms, the<br\/>short encoding of plane triangulations (i.e. triangular meshes) has<br\/>important applications in Computer Graphics.<br\/><br\/>A planar graph may have many plane embeddings. For some applications,<br\/>it is often required to find an embedding such that certain properties<br\/>are satisfied. These problems arise from areas such as VLSI design,<br\/>Geographic Information Systems, and some graph optimization problems.<br\/>Existing algorithms for solving these problems rely on dynamic<br\/>programming and are not efficient. In this research project we will<br\/>develop more efficient algorithms and explore their applications.<br\/><br\/>A common technique is used in several recent algorithms for solving<br\/>graph drawing and floor-planning problems: Labeling vertices or edges<br\/>of a graph so that certain regular properties are satisfied; then<br\/>solving the problems by using the combinatorial structures resulting<br\/>from the labeling. We will extend this technique and use it to solve<br\/>other problems in these fields.","title":"Graph Encodings, Embeddings, Labelings and Applications","awardID":"9912418","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["550545"],"PO":["543507"]},"55666":{"abstract":"EIA-0085922<br\/>Arnold J, Dahm<br\/>Case Western Reserve University<br\/><br\/>Title: ITR: QUANTUM COMPUTING USING ELECTRONS ON HELIUM FILMS<br\/><br\/>This project is a combined experimental and theoretical research effort to manufacture and investigate a system of interacting quantum bits (qubits) based on electrons on a helium film which covers an array of micro electrodes, and to develop methods for controlling this system. In particular, the team is studying the lifetimes and coherence times of the excited state in configurations suitable for qubit operation, including effects of electron-electron interaction, in-plane confinement, and a magnetic field. Problems of broad physical interest, such as quantum localization and chaos in a controlled system with interacting excitations is also being investigated. The project is focused on 1) trapping the electrons over micro dots, 2) controlling the energy-level spacing of targeted electrons by the microdot potential, 3) selective writing of information on individual qubits by appropriately tailored pulses of resonant microwave radiation and microdot potential 4) logical operations on a system of two qubits and 5) reading out the quantum register by detecting single electrons released from the surface or determining the electron distribution over energy levels with underlying micro dots, with a hope of building a system with a large number of qubits to be used as a multi-qubit quantum computer. If successful, such a computer can be manufactured using mainly conventional technologies and can operate at a temperature accessible with commercial refrigerators.","title":"ITR: Quantum Computing Using Electrons on Helium Films","awardID":"0085922","effectiveDate":"2000-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["303296",142639,"398856"],"PO":["565157"]},"54698":{"abstract":"In this project an integrated fault recovery system is developed that<br\/>quickly isolates faults in programmable digital components and<br\/>determines new device programming configurations to return them<br\/>to full functionality. After detection of a hardware fault in a digital<br\/>component such as a digital signal processor or a field-programmable<br\/>gate array, an attempt to recover from the fault is made at the local <br\/>embedded system affected by the fault. If the local system is unable <br\/>to complete the recovery effort, a computational-superior remote system<br\/>may be accessed via a local network to aid in the recovery effort.<br\/>In either case, the result of the recovery procedure is a new device<br\/>configuration (instruction sequence or configuration bitstream). This <br\/>configuration allows the affected system to perform the same logical <br\/>function as the original configuration while avoiding the detected <br\/>functional hardware fault.<br\/><br\/>The direct result of this work is a set of compilation techniques for<br\/>both DSPs and FPGAs that produce instruction and bitstream<br\/>configurations that avoid detected hardware faults.<br\/>These tools are directly integrated into a networked<br\/>environment through the use of TCP\/IP transfer mechanisms built into<br\/>operating systems frequently used for scientific computing.","title":"ITR: Adaptive Fault Recovery for Networked Digital Systems","awardID":"0081405","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["549952"],"PO":["241298"]},"55314":{"abstract":"EIA-0084541<br\/>Maier, David<br\/>Oregon Graduate Institute of Science & Technology<br\/><br\/>Digital Government: Workshop on Biodiversity Informatics<br\/><br\/>Many Federal agencies are involved in research, monitoring, and management of biodiversity. Together with partners and cooperators in state and local government agencies, academia and non-profit organizations, and private industry, these agencies have a need for advancing the development of a national data and information infrastructure to better support the collection, management, dissemination and application of biodiversity data and information. To a great extent, the vision of this enhanced 21st century biodiversity data and information system is described in the 1998 Teaming with Life report of the President's Committee of Advisory in Science and Technology (PCAST) which called for developing the \"Next Generation\" of the National Biological Information Infrastructure of NBII. The development of this next generation NBII has also been endorsed by the Office of Science and Technology Policy's Committee on Environment and Natural Resources (CENR) as a key component of the multi-agency science strategy called \"Integrated Science for Ecosystem Challenges.\" The need now is to convey the informatics research issues and requirements involved in developing the next generation NBII to computer science and information technology researchers and developers in academia, industry and government laboratories. This workshop will bring together a broad spectrum of people from the CS\/IT community in pursuing the research agenda and applying that technology.","title":"Digital Government: Workshop on Biodiversity Informatics","awardID":"0084541","effectiveDate":"2000-09-01","expirationDate":"2001-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"X594","name":"INTERIOR-DIGITAL GOVT PROG"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0603","name":"Division of EARTH SCIENCES","abbr":"EAR"},"pgm":{"id":"1580","name":"INSTRUMENTATION & FACILITIES"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"1165","name":"ADVANCES IN BIO INFORMATICS"}}],"PIcoPI":["483300"],"PO":["371077"]},"55677":{"abstract":"The Archimedes Project will create a testbed for developing and exploring model interactive environments for the history of mechanics. It will also serve as a proof-of-concept project for open digital libraries for topics in the history of science designed to integrate research and knowledge dissemination in new ways. The project is a join endeavor of the Classics Department at Harvard University, the Max-Planck-Institute for the History of Science (MPIWG) in Berlin, Germany, the English Department at the University of Missouri at Kansas City, and the Perseus Project at Tufts University. It also engages wider network of scholars supported in particular by Project International de Cooperation Scientifique (PICS). Numerous treatises on mechanics as well as other forms of documentation of mechanical knowledge and practices constitute the corpus of the testbed. Ongoing research at the MPIWG on the long-term development of mental models of mechanical thinking and their manifestation in technical terminologies, inferences of practitioners, engineers, and scientists plays an important role in the testbed design. The testbed also requires a powerful, linguistically based information technology for handling the variety of languages occurring in the source materials. Source documents must be prepared with tools such as automatic morphological analysis of Latin, Greek and Italian, and semantic linking of sources to general and technical, historical and modern dictionaries and reference works.","title":"The Archimedes Project: Realizing the Vision of an Open Digital Research Library for the History of Mechanics","awardID":"0085960","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6857","name":"DIGITAL LIBRARIES AND ARCHIVES"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"7444","name":"NATIONAL SMETE DIGITAL LIBRARY"}}],"PIcoPI":[142689],"PO":["433760"]},"55688":{"abstract":"The 1990's have witnessed explosive, if not revolutionary, growth in wireless telecommunications, fueled in large measure by the technology scaling of digital processing power. Third-generation (3G) wire-less systems promise even more with high-bit-rate data services, such as video and Internet access, with wide-band spread-spectrum modulation. Yet, despite the continued benefit of technology scaling below<br\/>0.1am in the next decade, these mobile 3G systems will demand digital processing power, along with programmability and energy efficiency, which are not achievable with conventional digital design techniques. Reconfigurable and flexible software radios, which implement digital IF as well as baseband function, will be essential for 3G systems because of the need to support multiple modulation waveforms and multiple air interface standards. These systems can be expected to demand 1000 MIPS of digital IF-processing<br\/>power and up to 2000 MIPS of baseband DSP power. To achieve power levels necessary for mobile sys-tem, energy efficiency of better than 0.15 mW\/MIPS while deliever 3000 MIPS of processing power will be necessary, an order of magnitude better than what can be achieve today with conventional design practices. In this extensive three-year research effort, we will consider asynchronous design techniques for achieving<br\/>energy-efficient, high-performance digital signal processing for 3G wireless applications. We will fully exploit the inherent high-performance and low-power properties of asynchronous design, to consume power only where needed and to \"adapt\" to the actual data inputs. Specifically, we will combine fine-grained asynchronous micropipelines with adaptive (or programmable) power-supply control and a dataflow-driven microarchitecture to provide a funcadmental leap in complex programmable digital <br\/>signal processing power and energy efficiency, unachievable using existing synchronous techniques. We in-tend to develop an asynchronous programmable DSP that is capable of supporting a significant fraction of the IS-95 and W-CDMA standards in software, including the performance- and power-intensive I and Q modulation and demodulation at less than 400 mW of peak power dissipation.","title":"ITR: Asynchronous digital signal processing for the software radio","awardID":"0086007","effectiveDate":"2000-09-01","expirationDate":"2005-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["518562","529662"],"PO":["564898"]},"48802":{"abstract":"Software tools based on data-flow analyses can automate many software engineering tasks. These tools, however, are rarely used in practice because existing data-flow analyzers are prohibitively expensive or too imprecise for use with large software systems written in languages that contain complex language constructs such as pointers, arrays, and function-valued variables. The primary goal of this research is to develop data-flow analyses that are sufficiently efficient and precise in practice to analyze programs when those programs are under development, testing, and maintenance. The research involves three primary efforts: development of efficient and effective data-flow analyses for C Programs; performance of large-scale experimentation to evaluate the algorithms and to guide the direction of the later work; and investigation of the application of the techniques to object-oriented languages. The proposed research will have several tangible results: it will provide information about how practical data-flow analyses can be created; it will construct prototypes and assemble a set of experimental subjects for use in evaluation of the results of the research and demonstration of the practicality of the algorithms; and it will use discoveries about data-flow analyses as a starting point for developing such techniques for object-oriented programs.","title":"Data-Flow Analysis of Large Software Systems","awardID":"9988294","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["530729"],"PO":["564388"]},"53279":{"abstract":"ABSTRACT<br\/><br\/>This research involves the general area of error control coding for digital communication and storage systems. In particular, it describes a number of fundamental research topics related to a powerful new method of error control coding called turbo coding. The research has two major goals: (1) to propose new turbo coding schemes with performance and\/or complexity advantages compared to the current state-of-the-art, and (2) to advance the fundamental state of knowledge regarding this exciting new approach to error control coding. Although still very new, turbo coding is beginning to be applied in numerous areas that require error control techniques, including deep space communication, satellite communication, and digital cellular telephony, to name just a few. Because of its ability to perform close to theoretical limits with reasonable implementation complexity, it is anticipated that turbo coding and related techniques will have an enormous impact on virtually all applications of error control coding over the next 10 years or so.<br\/><br\/>Turbo coding can achieve moderate bit error rates (in the range of 10-4 to 10-6) at signal-to-noise ratios very close to channel capacity. However, there is still room for improvement in turbo coding performance, particularly in applications that require bit error rates below 10-6. Further, there is considerable theoretical interest in achieving a more complete fundamental understanding of the key properties of turbo codes that result in such excellent performance. The investigators study several new basic research problems in turbo coding. Among the topics to be investigated are (1) several new turbo code designs capable of achieving even better performance than existing schemes, (2) the introduction of a more general class of turbo codes that has the potential to yield better codes and\/or reduced decoding complexity compared to standard turbo coding methods, and (3) the development of a new sub-optimum soft-in, soft-out decoding approach that can be used with more codes, thus offering the promise of near capacity performance at very low bit error rates, say below 10-10.","title":"Collaborative Research - New Directions in Turbo Coding","awardID":"0075514","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["508186","466234","184035"],"PO":["223414"]},"48824":{"abstract":"Parallel Algorithms and Software for Steepest Descent Fast Multipole Method<br\/><br\/>Srinivas Aluru & Shanker Balasubramaniam <br\/>Iowa State<br\/><br\/>The goal of this project is to develop theoretically rigorous and practically efficient parallel algorithms for the steepest descent fast multipole method (SDFMM) and to build a parallel software library for the solution of a wide variety of complex problems related to electromagnetic scattering and radiation by quasi-planar surfaces. Several important applications that can be studied with the use of this software include soil and ocean modeling, remote sensing, long range communications, applications in radio astronomy, full-wave analysis of electrical circuits and the design and analysis of antennas, diffractive optical gratings, solar cells and quantum well infrared detectors. Classical iterative integral techniques for solving such applications require quadratic work per iteration. SDFMM drastically reduces this computational complexity, to linear time, in the case of uniform distributions, by exploiting the redundancy in the classical representation of fields and the geometric structure of quasi-planar surfaces. Efficient sequential and parallel algorithms will be developed for solving non-uniform problems and for solving problems involving multiple, mutually interacting quasi-planar regions. Particular emphasis will be placed on developing distribution-independent algorithms, i.e., provably efficient algorithms for which the run-time is independent of the distribution without making any assumptions on either the range of distributions or the limited precision of computer arithmetic. Research will also be carried out in developing numerical methods that have a demonstrable order of accuracy. The software library will be written using the Message Passing Interface (MPI). Validation of the software will be carried out via comparisons against experimental data as well as numerical results obtained from slower, established solvers. This is an interdisciplinary research project involving the knowledge of algorithm development, computational electromagnetics, numerical methods and parallel computing. The research will be carried out by a group of three PI's (two from Iowa State University and one from the University of Illinois, Urbana Champaign), representing a mix of expertise and research interests that is vital to the success of this project. All the PIs have access to high-performance parallel computers and clusters, required for the software development and experimental validation of its practical efficiency.","title":"Parallel Algorithms and Software for Steepest Descent Fast Multipole Method","awardID":"9988347","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["565135","532976"],"PO":["562362"]},"56326":{"abstract":"0088086<br\/>Bebis, George<br\/>University of Nevada Reno<br\/><br\/>Combined Research-Curriculum Development in Computer Vision<br\/><br\/>This project integrates recent and ongoing research in computer vision into this institution's computer science and engineering curriculum. There are several objectives for this project. One is the design, implementation, and testing of innovative approaches for integrating teaching with research, leading to a comprehensive instructional program offering systematic and constant research experiences to as many students as possible. To this end, students are included in summer research programs involving computer vision. Another objective of the project is the integration of computer vision principles into several core courses and the introduction of a new course in mathematical methods for computer vision to support the integration of vision research into core courses. The final objective is the development of a new course in object recognition that includes current research advances and evolving principles of object recognition. The evaluation of the success of educational techniques and the dissemination of the results of this activity are critical elements of the project.","title":"Combined Research-Curriculum Development in Computer Vision","awardID":"0088086","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":[144663,"421302",144665,144666],"PO":["551712"]},"69329":{"abstract":"","title":"A General and Powerful Method for Program Optimization","awardID":"0196148","effectiveDate":"2000-09-01","expirationDate":"2001-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["552012","531979"],"PO":["250083"]},"54820":{"abstract":"The project explores the possibility of whether application-specific customizations of embedded processor cores can preserve the fundamental benefits of a processor architecture, while alleviating the associated deficiencies, such as reduced performance and excessive power consumption. The fundamental approach undertaken is the identification of application properties during compile time and their dynamic exploitation during program execution by the embedded processor. The basic characteristic of these properties is that their existence can be statically identifiable by the compiler, and that they lead to significant improvements in performance when exploited dynamically. Extended transfer to the microarchitecture is to occur by embedding performance-boosting knowledge, rather than communicating it through narrow ISA channels. Microarchitectural features that can be enhanced with such application-specific information include the branch predictor, the cache subsystem and the dynamic scheduling hardware. While the proposed approach aims at processor customization based on application-specific knowledge, it does so without violating the flexibility offered by processor architectures. Late customization through microarchitectural reconfigurability exploits application and architecture characteristics, thus boosting performance, reducing power and area, while keeping intact the volume and flexibility benefits of general purpose architectures.","title":"ITR: Application-Specific Reconfigurable Microarchitectural Enhancements for Embedded Processors in High-Performance Hardware\/Software Codesigns","awardID":"0082325","effectiveDate":"2000-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[140071],"PO":["562984"]},"54710":{"abstract":"Ray tracing methods are an important tool in computational geophysics, and are used regularly both for simulating seismic wave propagation and for generating images of subsurface geologic structures in inversion and imaging methods. For example, these are some of the basic tools in oil exploration. However, even recent high-efficiency ray tracing implementations have some potentially important limitations. On the other hand, wavefront construction algorithms are another class of solutions that do compute all of the relevant physical information. This project will develop these methods. They will find use in a wide range of activities ranging from fundamental studies of the nature of the Earth's deep interior to analysis and characterization of oil reservoirs in the petroleum industry.<br\/><br\/>Technically, this project will develop new wavefront construction methods for seismic ray tracing in 3-D, anisotropic models of the Earth. This allows more general and realistic Earth models than are currently possible. At the same time, this is an important problem in advanced computational science, because the 3-D mesh constructed in the course of the simulation will have geometries and features not usually considered in other common mesh construction algorithms. Another important aspect of the research will be the development of self-tuning components in the software to allow the algorithm to automatically adapt itself for maximum computational speed on hardware configurations ranging from small desktop workstations to massively parallel supercomputers.","title":"ITR: An Adaptive Wavefront Construction Algorithm for Optimal Seismic Ray Tracing","awardID":"0081510","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["561154",139779],"PO":["565272"]},"55700":{"abstract":"This research addresses the problem of adding data management facilities to inherently autonomous, distributed information sources such as those that occur in the web. Here, by data management, is meant the allocation and structuring of resources to provide more responsive access to data for applications. In this kind of environment, data management must be superimposed through an independently controlled service that exists between the data sources and the applications. This is facilitated through the introduction of architecture based on data centers, a collection of machines that prestage and distribute data for its clients. Client applications submit profiles describing their overall data needs, and the data center gathers data and organizes it on behalf of their clients in order to provide efficient data access. This research explores systems issues and techniques for the design and operation of data centers. This includes the management of large numbers of profiles, heuristics for balancing the needs of large numbers of users against the available resources of the data center, and the efficient processing of future client data needs against the data that is managed by the data center.","title":"ITR: Data Centers - Managing Data with Profiles","awardID":"0086057","effectiveDate":"2000-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["448702","483625","497162","518052"],"PO":["433760"]},"54611":{"abstract":"CCR-0080900 <br\/> PI: Rothermel, Gregg<br\/> Oregon State University<br\/> ITR:SW: Collaborative Research: A New Generation of Scalable,<br\/> Cost-Effective Regression Testing Techniques <br\/> Collaborating PI: Sebastian Elbaum (ITR-0080898)<br\/><br\/><br\/>This project is carried out in collaboration with Sebastian Elbaum (CCR-0080898)of the University of Nebraska - Lincoln. Regression testing is an expensive process performed on modified software to provide confidence that modifications have not impaired its quality. To help with this process, previous research has considered various test-suite reuse techniques. Despite progress with these techniques, they remain limited along several dimensions. For example, they typically assume that test cases have equivalent costs, faults have equivalent severities, and fault likelihood is constant across portions of a program. These assumptions are unrealistic in practice, and limit the applicability and effectiveness of techniques. The proposed research will address these limitations. The research will provide: (1) comprehensive regression testing cost models that capture the necessary factors; (2) regression testing techniques that account for these factors; (3) more precise understanding of the effects these factors have on regression testability, program and test design, and software engineering practice; and(4) guidelines that help software engineers select and create cost-effective regression testing tools and processes. In addition to providing models, algorithms, and processes, the research includes a substantial empirical component, and will provide a publicly available base of empirical data about techniques and factors. Together, these contributions will support more efficient and effective regression testing, and improve the quality of software.","title":"ITR: Collaborative Research: A New Generation of Scalable, Cost-Effective Regression Testing Techniques","awardID":"0080900","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["548132"],"PO":["564388"]},"54853":{"abstract":"One of the most theoretically challenging and practically important<br\/>problems in modern computer science is the analysis of cryptographic<br\/>authentication protocols, which play an essential role in Internet<br\/>privacy and security. There is a general cryptographic protocol<br\/>specification environment developed at SRI that includes a high-level<br\/>specification language, CAPSL, and an intermediate language, CIL,<br\/>based on a multiset rewriting rule model. The objective of this<br\/>project is to write a translator to generate prototype protocol<br\/>implementations in Java from CAPSL specifications. The translator<br\/>will use existing Java classes and APIs (application program<br\/>interfaces) for communication and encryption tasks. Concrete<br\/>interface routines will be generated from the CIL representation. The<br\/>advantage of this approach is that the originally specified protocol<br\/>can be shown to be free of design flaws through analysis of the CIL<br\/>using other tools.","title":"ITR: Cryptographic Protocol Transformations","awardID":"0082500","effectiveDate":"2000-09-01","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[140158],"PO":["241298"]},"54743":{"abstract":"For large-scale simulation problems, experience shows that, despite the rapid evolution of microprocessor and parallel computing technology, only a small fraction of peak performance from high-performance computing systems is generally realized. This is so because there are typically critical mismatches between the architecture of high-performance computing systems and the fundamental structure of the target simulations. This is clearly a problem of critical importance to information technology. It represents both an opportunity and a challenge to the disciplines of system-level design, targeting special-purpose architectures for high-performance computing, and algorithm and data structure design for large-scale engineering and software applications. Accordingly, this project will investigate systematic methodologies for designing the systems and algorithms for high performance applications. On the system design side, the project will focus on specialized billion-transistor chip multiprocessor architectures and a hierarchically distributed organization of resources tailored to the needs of the application. On the algorithm and application side, it will focus on finite element simulation applications, including representative problems from semiconductor device design and coupled flow and heat transfer processes.","title":"ITR: Integrated Design of High-Performance Clustered Computing Systems and Algorithms for Large Scale Finite Element Simulation","awardID":"0081791","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[139872,"293070"],"PO":["551992"]},"52565":{"abstract":"Object-oriented programs contain many \"class invariants\": propositions that are true of all objects of a given class, and remain true even as the objects change. These class invariants are the focus of this research. There are two broad areas of applications for class invariants. First, class invariants can enable compiler<br\/>optimizations, allowing programs to run faster. Second, information about class invariants can be of direct use to programmers, reducing the number of software defects. Research goals include building a categorization of class invariants that are tractable for static analysis, developing static analysis algorithms for class invariants, implementing systems that apply class invariants in compiler-style optimization and in verification of user-supplied invariants, and empirically evaluating the techniques as implemented, with particular attention to their speed and the usefulness of the results for standard compiler optimizations.","title":"Class-Invariant Assertions in Object-Oriented Programs","awardID":"0073070","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":[134059],"PO":["565272"]},"52686":{"abstract":"Value locality, a recently discovered program attribute that describes the likelihood of the recurrence of previously seen program values, has been studied enthusiastically in the published literature. This project investigates a new domain for the exploitation of value locality, namely shared-memory multiprocessor (SMP) systems running commercial workloads. Initial results from a recent study of store value locality indicate that significant potential exists for reducing multiprocessor data and address bus traffic by identifying and squashing silent and stochastically silent stores. This project describes and evaluates exact mechanisms for store squashing techniques, investigates alternative approaches for exploiting value locality, and finally, develops focused mechanisms for attacking the specific problem of read\/write data sharing and synchronization in SMP systems. The project demonstrates that overcoming the performance bottlenecks caused by data sharing requires speculative techniques based on value locality, since other more conventional approaches to speculative execution are guaranteed to fail. This research realizes the potential of speculative techniques that exploit value locality to improve performance and\/or reduce implementation cost and complexity in future generation shared-memory multiprocessor systems that are designed to run commercial workloads.","title":"Exploiting Value Locality in Shared Memory Multiprocessors","awardID":"0073440","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["549841"],"PO":["180163"]},"56932":{"abstract":"In response to a request to CSTB from the United States Government's Chief Counselor for Privacy, CSTB has framed an assessment of emerging approaches to authentication in computing and communications systems that focuses on the implications of authentication technologies for privacy. This assessment of authentication technologies would examine the state of the art and relevant trends. It would put the technology into a larger context: it would consider technical and nontechnical trends, addressing both the nature of capabilities and their implementation, and the nature of procedural and other nontechnical protections and their enforceability. It would examine differences in concerns associated with public sector versus private sector uses of authentication technologies. Attention would be paid to the likelihood of different mixes of options (e.g., diverse techniques to accommodate, a diverse population and set of needs versus narrower standardization for economic reasons.<br\/> A report will be produced by the committee and subject to NRC approval. It will describe authentication technologies, the interplay of technical and nontechnical aspects of authentication, and the implications of alternative approaches for privacy; it will make recommendations about fostering relevant research and shaping appropriate policy. It will be distributred to the computer science and privacy communities, associated organizations, consumer organizations, and government agencies and the congress. Web distribution, briefings, discussions at key conferences and in relevant National Academies venues, and articles and announcements in journals and newsletters would be important to getting the word out and furthering discussion. The dissemination process would be launched by a public briefing about the report.","title":"Authentication Technologies and Their Privacy Implications","awardID":"0090219","effectiveDate":"2000-09-01","expirationDate":"2004-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}}],"PIcoPI":["298189","234699"],"PO":["565090"]},"55722":{"abstract":"This project will coordinate several efforts to test competing theories and hypotheses about the Internet's impact on society, including functional equivalence and time displacement, declining social capital, classic innovation diffusion, and reconfigured social networks. This work will be carried out in three ways:<br\/><br\/>1) Enhancing an interactive statistical website at the University of Maryland (www.bsos.umd.edu\/webuse) that would make publicly available on-line the latest national data sets (from both the U.S. and other countries), research articles and research findings related to Internet use and its possible impact; <br\/><br\/>2) Having up to 50 graduate and undergraduate students from across the country participate in a multi-week Summer Webshop in which they discuss with leading research scholars current theories, hypothesis and expectations concerning the Internet; and<br\/><br\/>3) Undertaking new data collections to address controversies or missing variables in existing data sets. The major vehicle for this purpose is the General Social Survey (GSS), which has been monitoring social change for the past 27 years and for which a new Internet module was included in the year 2000 GSS. <br\/><br\/>This project will educate young researchers in studies of Information Technology. It will make available new national data sets for dissertations and other research studies. And it will extend and refine the GSS to include questions on Internet impact and use.","title":"ITR: Understanding the Social Impact of the Internet: A Multifaceted Multidisciplinary Approach","awardID":"0086143","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["228577"],"PO":["564456"]},"54875":{"abstract":"Parallel programs using MPI are widely used in compute-intensive scientific and engineering applications. They perform well on dedicated distributed memory machines and workstation clusters. However, their performance can deteriorate on multiprogrammed shared memory machines (SMMs) or clusters of those machines. This project will optimize execution of parallel programs through both program transformation and efficient run-time support. The resulting programs will deliver robust performance in both dedicated and multiprogrammed SMM clusters.<br\/><br\/>Technically, the work has three aspects:<br\/><br\/>It will study compile-time code transformations to achieve threaded execution of parallel code on a cluster of SMMs, allowing each MPI node to be executed safely as a thread.<br\/>It will study thread-safe run-time execution and fast lock-free communication that takes advantage of address space sharing among threads within an SMM.<br\/>It will evaluate and model a variety of scientific applications (including sparse-matrix algorithms with irregular computation, PDE computations with coarse-grain computation, and data-intensive applications) to verify the proposed techniques.","title":"ITR: Optimizing Execution of Parallel Programs on a Cluster of Shared Memory Machines","awardID":"0082666","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["486626"],"PO":["551992"]},"54996":{"abstract":"The project focuses on the problem of recognizing objects in outdoor images acquired under unknown conditions when only a few pixels are available on the object. The development of this capability would enable the recognition of small or partially obscured objects at large distances thereby enhancing the performance of systems for many applications such as wide-area search and image registration. A recognition system that operates in an uncontrolled outdoor environment must overcome several substantial challenges. The appearance of an object in an outdoor scene is highly variable due to spatial and temporal variation in the illumination and atmospheric conditions. Also, in images of distant or obscured objects, modeled object surfaces may appear at subpixel scale therefore reducing the usefulness of<br\/>geometric features. This project will address several important scientific issues. Methods will be developed to build hyperspectral subspace models for materials of interest and backgrounds using physical models and the underlying image data. Models will also developed that describe the statistical properties of these subspaces. These models will be the basis of statistical algorithms for recognition that are invariant to the scene conditions. The models and algorithms will be evaluated using a range of<br\/>hyperspectral data acquired under different conditions in different environments. An important goal is to determine the fundamental bounds on recognition performance in unknown environments as spatial resolution degrades.","title":"Physics-Based Recognition in Outdoor Hyperspectral Images Using Small Image Samples","awardID":"0083133","effectiveDate":"2000-09-15","expirationDate":"2005-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":[140597],"PO":["317663"]},"54765":{"abstract":"With many communications applications, such as mobile computing, as well as in data storage, data compression is essential for large sets of digital information such as images, video, and multi-media. Adaptive methods that can in real time \"learn\" about the data to compress it well are the most powerful, but can have the drawback that a single error can propagate and corrupt all data to follow. Based on past work by the PI, this project will study error resilient communication protocols and adaptive real-time data compression where error propagation is essentially prevented. This new work is targeted at both lossless and lossy applications, including image and video compression. The project will consider how the proposed techniques can be implemented in a way consistent with existing video compression standards. It will study how these techniques can be combined with reversible variable length codes (used in the MPEG-4 standard) to improve recovery from a catastrophic error burst. Although reversible codes have been studied by a number of authors in the past, there is much that is not known about efficient optimal methods. The project will also investigate how the learning employed by error resilient adaptive compression methods can provide a filtering mechanism that can be used for fast browsing of large data over a noisy channel, a situation that is increasingly important. The work will include theoretical analysis, algorithms design, and experimental work.","title":"ITR: Error Resilient Communication and Adaptive Data Compression over Wireless and Noisy Channels","awardID":"0081952","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":[139931],"PO":["223414"]},"54886":{"abstract":"The automatic conversion of text to speech provides a means to achieve universal access to on-line information. However, except for simple messages, speech generated by current synthesizers is both unpleasant and hard to understand: even though words presented individually are quite intelligible, listeners are generally unable to comprehend longer or more complex messages without intense concentration. A key reason for this \"incomprehensibility\" is the lack of proper prosody in synthetic speech. Prosody refers to the rhythmic and melodic characteristics of speech, which are used by the speaker to structure information for the listener. That is, prosody conveys to the listener which words or phrases are important prominence, and which words belong together in some semantic or syntactic sense (phrasing). Prosody involves a host of acoustic features, such as variations in fundamental frequency (F0), timing, and features that are related to the speaker's level of effort. Current synthesizers have poor prosody for two main reasons: (i) accurate prediction from text of timing and F0 is intrinsically difficult, and (ii) they can neither predict nor control features in speech that correspond to the speaker's articulatory effort. While many techniques exist for control of segmental duration (one aspect of timing) and F0 characteristics of speech, little attention has been paid to control of this second category of effects, and the quality of current synthesizers is poor as a result.<br\/><br\/>The PI has defined a concept of \"degree of articulation\" to refer to the fact that, at a given speaking rate, speakers can control the precision and speed of the motions of their tongue, lips, velum, etc. with varying degrees of effort, from \"hypo-articulate\" (sloppy) to \"hyper-articulate\" (precise). Acoustic correlates of degree of articulation have been shown to covary with linguistic factors such as word emphasis and syllabic stress. While clearly important, this concept is nevertheless vague and its static and dynamic acoustic correlates have not been well established. Moreover, no quantitative models exist that predict degree of articulation from text or that provide a sufficiently precise quantitative description of these acoustic correlates for implementation in a synthesizer. The overarching goal of this project is to develop principled quantitative models for the prediction of acoustic features associated with degree-of-articulation, and to implement these results in a speech synthesizer. The strategy will be (a) to use text materials that systematically vary in prominence-related factors in order to elicit varying levels of degree of articulation in read speech; (b) to analyze speech signal, laryngograph signal, and jaw\/lip articulatory data; and (c) to use the analysis results to generate mathematical descriptions of the relationship between prosodic structure and spectral features of the speech signal.<br\/><br\/>The outcomes of this project will include the following: Improved understanding of the acoustic, glottal, and articulatory correlates of degree of articulation, including both static and dynamic features. This knowledge will impact not only basic science, but also technologies like speech synthesis and automatic speech recognition; Accurate prediction of spectral features of the speech signal from prosodic structure, based on a principled model that incorporates both acoustic and articulatory knowledge; Techniques for more natural-sounding speech synthesis that requires a lower attentional demand on the listener. This will lead to greater user acceptance of synthesized speech in applications including voice-based information access, language training, and tools for visually or vocally disabled persons.","title":"ITR: Modeling Degree of Articulation for Speech Synthesis","awardID":"0082718","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[140250,"483791"],"PO":["246649"]},"52235":{"abstract":"EIA-0072102<br\/>Josep Torrellas<br\/>Univ. of Illinois-Champaign<br\/><br\/>TITLE: Experimental Partnership: FlexRAM: An Advanced Intelligent Memory System<br\/><br\/>Dramatic increases in the number of transistors that can be integrated on a single chip have enabled both microprocessor performance and memory chip capacity to rise spectacularly. However, they have also led to an increasingly constraining data transfer bottleneck between processor and memory system. Recognizing the need for new architectural approaches that alleviate this bottleneck, researchers have proposed the integration of processor and DRAM in a single chip. This architecture is popularly known as intelligent memory (IRAM) or processor-in-memory (PIM).<br\/><br\/>Unfortunately, simple integration of current microprocessors and DRAM on a single chip often delivers only modest performance improvements-it moves an off-chip bottleneck on chip. Furthermore, the resulting system is often very hard to program. Finally, Little effort has been invested trying to identify a wide range of applications that can exploit this architecture effectively.","title":"Experimental Partnership - FlexRAM: An Advanced Intelligent Memory System","awardID":"0072102","effectiveDate":"2000-09-15","expirationDate":"2006-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4725","name":"EXPERIMENTAL SYSTEMS\/CADRE"}}],"PIcoPI":["562707","533380","485665"],"PO":["325495"]},"54897":{"abstract":"Rapid advances in computation and communication technologies are giving rise to an ever wider use of automation in the monitoring and control of dynamic engineering and computing systems in<br\/>manufacturing, communication networks, transportation, and electric power systems, to mention but a few key areas. The software programs that monitor and control these systems are responsible for various functions, including start-up and shut-down procedures, monitoring and control, detection and isolation of significant events, system reconfiguration, etc. We refer to all of these software programs as the \"supervisory control software\". This proposal is focused on systems that are distributed over several sites and where the supervisory control software is distributed as well. The goal is to conduct fundamental research on novel formal generic methodologies for designing distributed software systems that monitor and control systems with decentralized information. We propose to bring the concepts and techniques of Systems, Control, and Decision Theory to bear on the problem of designing distributed software systems that are provably correct and efficient. As part of this effort, we will educate computer science and engineering students at the University of Michigan and Wayne State University on the fundamental issues associated with distributed software design.","title":"ITR: Design of Supervisory Control Software for Dynamic Systems with Decentralized Information","awardID":"0082784","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["526786","497008","377641"],"PO":["564388"]},"55876":{"abstract":"This project will explore three avenues in reasoning and knowledge representation: development of new approximation methods that incorporate user-adaptive and any-time features; development of hybrid knowledge-bases that combine deterministic information (constraints) and probabilistic information (belief networks), and which are both semantically coherent and computationally effective; and application of hybrid languages and algorithms to temporal reasoning problems in the domains of planning, scheduling, and diagnosis. The outcome of this research will include a system of algorithmic tools which address issues of non-tractability in an innovative and practical manner, and which are applicable to a new knowledge-based framework that allows the expression of both causal and constraint-like information, thus facilitating tasks such as planning, diagnosis and design. Parameterization will allow users to control the algorithms and adjust them to their own domains and resources. The computational tools will support the solution of challenging problems at the frontiers of diverse areas of science and industry such as robotics, planning and scheduling, bioinformatics (linkage analysis and protein secondary structure prediction), and e-commerce (multi-agent combinatorial auctions).","title":"Advanced Approximation Methods and Specification Schemes for Automated Reasoning","awardID":"0086529","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["475511"],"PO":["491702"]},"54666":{"abstract":"The topic of trust and its influence on consumer behavior has received growing attention of late with respect to electronic commerce, especially with regard to establishing and evaluating the trustworthiness of a single web site. However, consumers who rely on the Internet for information gathering are better served by tools that integrate information from many different sources and measure the trustworthiness of the integrated body of information. We propose to develop a methodology that addresses this problem of assembling an information product from many sources and evaluating its trustworthiness. Drawing on techniques in text analysis, knowledge acquisition, graph theory and visualization, and statistical inference, we will enable the user to generate an automated summary from a group of web pages, evaluate its trustworthiness, and visually navigate the information models. The final deliverable is a software package that implements the methodology. The proposed research will benefit the Internet community by providing a new technology that fills the void left by current information retrieval and trust assessment technologies. In addition, the techniques we propose to develop have the potential to contribute to a wide variety of fields confronted with the problem of analyzing samples of graph-valued data.","title":"ITR: Trust and the Information Consumer: A Graph Theory Approach","awardID":"0081219","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["548125"],"PO":["495796"]},"52488":{"abstract":"Modern processors improve instruction level parallelism by speculation. The outcome of data and control decisions is predicted, and the operations are speculatively executed and only committed if the original predictions were correct. There are a number of other ways that processor resources could be used, such as threading or eager execution. As the use of speculation increases, more processors will need some form of speculation control to balance the benefits of speculation against other possible activities. This research examines a set of microarchitectural features that can benefit from speculation control, including trace formation; instruction fetch management, execution resource management and memory access prioritization. The research also explores how out-of-order processor designs can use multi-voltage levels to reduce energy, and how the processor can provide feedback to an operating system that further controls energy use via dynamic voltage scaling. This work is done using a microarchitectural model that supports multithreading and multiprocessor simulations. This work is part of a broader effort that includes experimentation with existing computers, design and modification of operating systems for energy efficiency and the adoption of microarchitectural models designed for comparing energy efficient processor designs.","title":"Speculation Control Execution for Energy Efficiency","awardID":"0072870","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["543625"],"PO":["180163"]},"55645":{"abstract":"This research examines the global diffusion of Internet-based electronic commerce, how national environments and policies influence e-commerce use within countries, and the economic and social impacts of e-commerce. The project employs both quantitative and qualitative methodologies, including a comparative study of diffusion across 42 countries and detailed case studies in eight countries that look at the growth of e-commerce nationally, and also in three critical industry sectors: high-technology, financial services and retail. These studies will identify key trends in diffusion, critical environmental and policy factors that influence the diffusion, and major impacts of e-commerce. The project will be carried out by researchers from computer science, social systems and management and will involve data collection collaboration with experts from a total of eight countries, including Brazil, Denmark, France, Japan, Mexico, Singapore, Taiwan, and the United States. The outcomes of the research include 1) new scientific understanding of the use and impacts of e-commerce in different countries, 2) baseline benchmarks for future studies of industry, national and global trends, 3) strategic insights for business executives involved in global e-commerce, 4) policy insights for governments to promote and maximize the benefits of global commerce, and 5) extension of the research community through the education of graduate students.","title":"ITR: 'Globalization, Electronic Commerce and Social Impacts: The Influence of National Environments on Diffusion and Impacts of the Internet'.","awardID":"0085852","effectiveDate":"2000-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["527619","426259"],"PO":["564456"]},"55766":{"abstract":"Institution: William Marsh Rice University<br\/>Proposal Number: EIA 0086264<br\/>PI: Moshe Y. Vardi<br\/>Title: Collaborative Research: Integrating Logic in the Computer Science Curriculum<br\/><br\/>This CISE Educational Innovation (EI) proposal requests funds to develop a series of modules that seamlessly integrate logic and logic-based software tools into existing, widely taught computer science (CS) courses. Few undergraduate computer science curricula prepare students adequately in logic. The typical student sees a few weeks of truth tables and propositional logic in discrete practical work. These modules would allow CS departments to easily modify their curricula to rectify this situation. By supplying modules, complete with lecture notes, presentations, problem sets, and tools, the investigators hope to facilitate curricular treatment of applied logic at all levels of college education, particularly in CS departments with scarce resources. This project has the potential to have a major impact on the way that CS is taught.","title":"Educational Innovation: Collaborative Proposal: Integrating Logic into the Computer Science Curriculum","awardID":"0086241","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["518005"],"PO":["551712"]},"54677":{"abstract":"This is the first year funding of a three-year continuing award. This multi-disciplinary study will explore a novel approach based on 3D magnifying \"lenses\" to building improved highly interactive 3D interfaces to scientific and engineering data that allow users to easily interact at multiple scales and with multiple coordinate systems. To be effective it is necessary that interfaces to large data bases be highly interactive allowing users to \"drill down\" on demand to see detail as necessary, or to \"zoom out\" to get contextual information. The P1 will extend human spatial cognition theory to deal with common problems in interactive 3D visualization systems, and in particular to cover perceptual issues relating to eye-hand coordination in multi-scale environments using stereo and head tracking VR technologies to improve visualization and interaction. The PI will develop techniques to link views so that users do not become disoriented while interacting with data at different scales. A proof-of-concept prototype that enables scientists and engineers to monitor and control remotely operated vehicles or autonomous undersea vehicles will be used to conduct experimental user evaluations to provide feedback and measure success.","title":"ITR: Multi-Scale Interaction with 3D Data Environments","awardID":"0081292","effectiveDate":"2000-09-01","expirationDate":"2004-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["490628","450848",139678],"PO":["565227"]},"54798":{"abstract":"The focus of this project is on the development of conceptual<br\/>foundations along with a middleware infrastructure for rapid<br\/>construction of dynamic and secure distributed collaborations. This<br\/>project is investigating techniques for constructing dynamic<br\/>collaboration environments from their high-level specifications. These<br\/>specifications are interfaced with a middleware to build the desired<br\/>environment. This project is developing techniques for specifying a<br\/>collaboration plan using XML and mechanisms for a mobile agent based<br\/>middleware for implementing such a plan. A collaboration specification<br\/>identifies the participants in a collaboration by their roles, and also<br\/>specifies the associated role-based security policies. It specifies the<br\/>shared objects together with the coordination and workflow requirements<br\/>for information flow among the participants. Mechanisms are being<br\/>investigated for participants to dynamically join or leave an environment.<br\/>These include mechanisms for authentication of a participant's<br\/>credentials, assignment of roles, and discovery of resources by a<br\/>participant. These mechanisms and services are integrated in an<br\/>agent based middleware, using the Ajanta agent programming system,<br\/>for constructing distributed collaborations. This middleware investigates<br\/>use of mobile agents for building transportable user interfaces,<br\/>for executing remote coordination actions, and as mobile workflow<br\/>objects. It also provides support for resource discovery, naming, event<br\/>management, and security.","title":"ITR: Dynamic and Secure Distributed Collaborations","awardID":"0082215","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["74434"],"PO":["309350"]},"56866":{"abstract":"Institution: University of Colorado at Boulder<br\/>Proposal Number: EIA 0090026<br\/>PI: Robert B. Schnabel<br\/>Title: Attracting and Retaining Women in Information Technology Programs: A Comparative Study of Three Programmatic Approaches<br\/><br\/>This CISE Information Technology Workforce (ITW) proposal requests funds to examine the factors that cause women to select and remain in IT educational programs, in the context of three programs at the University of Colorado at Boulder. One is the recently developed multidisciplinary Technology, Arts and Media (TAM) undergraduate certificate program that is attracting a very high percentage of women. Another is the traditional undergraduate computer science major that is sparsely populated by women but taking steps to amend this situation. The third is a Virtual Development Center supported by the Institute for Women and Technology that is specifically intended to involve women in formulating and conducting IT projects. The overarching goal of this research is to gain knowledge that will lead to greater participation in and retention of women in higher education IT programs by identifying program features that appeal to women. This project has the potential to provide valuable insights about the recruitment and retention of women in IT majors.","title":"ITW: Attracting and Retaining Women in Information Technology Programs: A Comparative Study of Three Programmatic Approaches","awardID":"0090026","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1359","name":"RES EXP FOR TEACHERS(RET)-SITE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["425934","494943","519850",146337,"510094"],"PO":["289456"]},"55656":{"abstract":"The emergence of new applications has fostered a number of attempts to add functionalities to the minimalist Internet core. However, the adoption of enhancements to the Internet has either been slow, failed entirely, or limited to special-purpose private networks. The key reasons for this failure are extensibility and scalability: First, IP networks were not designed to be extensible at the internetworking level. Second, proposals for new network layer services often require that vast amounts of state information be managed in the core network infrastructure, thus, introducing scalability bottlenecks which exacerbate the existing scalability problem of the growing Internet.<br\/> Today, the development and deployment of advanced services on the Internet has reached a crossroads: efforts to add new services have quickly encountered scalability problems, yet new services are in critical demand and must be rapidly and widely deployed.<br\/> The research goal is to develop truly scalable services for each of the three fundamental components of the Internet's infrastructure: information communication, replication, and storage. Taking a new and unified approach to the seemingly conflicting requirements for scalability and sophisticated network services, the researchers propose to develop:<br\/> 1. Scalable Performance-Predictable Communication: a new foundation for quality-of-service communication via a scalable edge-based architecture.<br\/> 2. Scalable Multicast for Efficient Data Dissemination: a self-organizing multicast infrastructure scalable to many spontaneously-formed groups.<br\/> 3. Scalable Storage for Next Generation Information Services: an infrastructure which brings information<br\/>closer to users and enables scalable third-party information storage services.<br\/> 4. Design Principles of Scalable Services: a multi-faceted approach for the development and deployment<br\/>of scalable services in the global Internet, under consideration of economic models, industrial structure,<br\/>theories and algorithms, engineering, and deployment.<br\/> Thus, this project proposes to develop architectures and methodologies for deploying scalable services in the global Internet. The impact of this project will be to provide the theoretical underpinnings, basic architecture, and a prototype implementation for the information communication of the global Internet of the 21st century. An integral part of this project is the dissemination of results and the infiltration of standard organizations with the concepts developed within this project, and innovative approaches to educate the next generation of engineers for the future Internet.","title":"ITR: Collaborative Research: Scalable Services for the Global Network","awardID":"0085879","effectiveDate":"2000-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["229260"],"PO":["292741"]},"54688":{"abstract":"Sources of on-line information are becoming increasingly decentralized, heterogeneous, and complex even as they become correspondingly richer and more valuable. Determining the structure of these information sources is becoming key to extracting and managing the knowledge they contain. Some of these sources exhibit an explicit network structure --- the hyperlinks of the World Wide Web form an excellent example. In other domains, ranging from electronic communication to informal human social networks, subtle hidden linkage relations play a large role in determining the information flow within and between communities. The link structures of both types of environments can yield a surprising wealth of latent information about their content, making their complexity manageable.<br\/><br\/>The proposed research seeks effective mechanisms for eliciting a global understanding of link structures in information networks. A key component of this effort is the design of techniques and tools enabling a richer level of interaction with on-line information. The research focuses on the development and integration of new techniques in three areas: natural language understanding methods to uncover implicit relationships in on-line content, efficient algorithms to analyze complex networks of inter-connections, and mathematical models of the dynamics and social processes by which networked information evolves.","title":"ITR: The Construction and Analysis of Information Networks","awardID":"0081334","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["384275","548297","450550","560669","406425"],"PO":["563751"]},"51058":{"abstract":"This proposal funds a set of interactions, in particular a workshop next<br\/>month, between humanists and computer researchers to expand on the<br\/>possible uses of new technology in humanities research and teaching.<br\/>The proposal comes from the National Initiative for a Networked Cultural<br\/>Heritage. It supplements Rockefeller Foundation funding.<br\/><br\/>The major purpose of the workshop and the related activities is to<br\/>prepare a research agenda for the area of computational humanities and<br\/>define problems and needs for new technology, both to help the humanists<br\/>in their scholarship and educational activities, and to help explore the<br\/>new challenges and opportunities for information technology presented<br\/>by these areas.","title":"Workshop: Building Blocks - Part One","awardID":"0004154","effectiveDate":"2000-09-01","expirationDate":"2001-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6857","name":"DIGITAL LIBRARIES AND ARCHIVES"}}],"PIcoPI":["415200"],"PO":["565136"]},"55667":{"abstract":"The proposed research studies the design of agile wireless networks that accommodate time<br\/>variations in the communication channels, the information sources, and the network topology. The research will lead to design principles that, in addition to enabling more efficient use of the current cellular and PCS bands, will allow exploitation of frequency bands in the 10-100 GHz range to provide high-speed multimedia services for both indoor and outdoor applications. While the basic cellular paradigm of wireless access to a high-speed communication and computing backbone will be adhered to, nearly every other assumption in existing second-generation and projected third-generation cellular and PCS networks will be reexamined. Some of the significant differences from current designs are as follows. A dense network of base stations will provide connectivity despite the high path losses and sharp shadowing at higher frequency bands. Cells with well-defined boundaries may no longer exist, and mobile terminals will see a rapidly varying network topology. A variety of traffic classes, such as voice, data, and video, with diverse requirements regarding delay, loss, quality of reproduction, and number of potential receivers will be considered. Packetized transmission will be considered as a flexible means of supporting such multimedia applications so that current circuit-based cellular trunking is not applicable.<br\/>A key element of the approach is to envision new applications and new overall system architec-<br\/>tures. Modeling based on propagation studies and analysis of requirements for carried datastreams will be used both to continually revise the concept systems and to provide models for the design of algorithms for such things as joint implementation of source coding, channel estimation, interference suppression, routing and congestion control. The performance of the algorithms will be evaluated broadly, including aspects of implementation in VLSI as appropriate, and the results will lead to further revision and refinement of the overall system architecture. Many tradeoffs will be explored, such as the tradeoff_ between the performance of distributed soft detection and the network capacity needed to assemble the required information. The integrated research effort will be conducted by five overlapping research teams of University of Illinois faculty investigators and their students, organized around the following interdisciplinary<br\/>projects:<br\/><br\/>Concept Systems, Modeling, and Performance Limits<br\/><br\/>Design Principles for Wireless Packet Networks<br\/><br\/>Design for Time-Varying Channels<br\/><br\/>Jointly Optimized Source Coding, Channel Coding, and Estimation<br\/><br\/>VLSI Algorithms, Architectures, and Bounds<br\/>The bulk of the requested funding will be used to support the students. Most of the faculty and<br\/>students have adjacent offices within the Coordinated Science Laboratory, an environment carefully cultivated to promote intense interaction and collaboration. Regularly scheduled weekly meetings of the investigators are used to coordinate the research and identify opportunities for better integration of the design approach. An External Advisory Committee of key technical people from industry will help ensure that the research is focused on problems and issues likely to be important in the future. This proposal is to supplement NSF grant NSF CCR 79381 \\An Integrated Exploration of Wireless Network Communication.\" That grant is funded at a level of $700K for three years beginning October 1, 1999, whereas the original funding request was for $2.5M over five years. Although the proposal was rated as highly competitive, the funding received covers only six students and no faculty time. Additional funding will greatly enhance our ability to achieve our research and educational goals. <br\/><br\/>Keywords: Wireless networks, fading channels, multimedia communications","title":"ITR: High-Speed Distributed Wireless Communication Networks","awardID":"0085929","effectiveDate":"2000-09-15","expirationDate":"2005-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["456909","470450","381437","509442","348133"],"PO":["564898"]},"54699":{"abstract":"To overcome the limitations of current development methods for embedded software, which include limited use of secure and type-safe languages and the lack of support for formal validation techniques, this work explores the use of the modern secure language Java coupled with light-weight formal methods to establish correctness. It tailors the Java technology to fit the domain of embedded systems by placing restrictions on the Java subset, supporting provably correct-by-construction synthesis techniques for reactive control skeletons, and analysis techniques based on algorithmic as well as deductive formal verification techniques. A key goal is also to support advanced features such as dynamic software upgrades and process migration through safe implementation methods that are formally verified. It develops a new set of model-checking and program analysis tools that are demonstrated on prototype hardware\/software co-designs of embedded Java processors.","title":"ITR: Formal Methods for Robust Embedded Software","awardID":"0081406","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["161876","561775"],"PO":["562984"]},"43336":{"abstract":"The objective of this research is to develop new paradigms for coordination and control of unmanned aerial vehicles (UAVs), which are anticipated to have wide-range of applications, including fighting forest fires, human rescue during natural disasters, protection of crops, surveillance of a city, monitoring of enemy, and mitigation of threats. The basic and unique contribution of this work is to develop strategies and algorithms for feasible and optimal planning of groups of autonomous systems to satisfy their governing equations and applicable constraints. The goal is to reduce on-line computations close to real-time by exploiting the inherent \"feedback linearizable\" or \"differentially flat\" structure of dynamic systems. The PI plans to simultaneously undertake two complementary directions: (i) develop algorithms for coordinated planning of a fleet of UAVs, and (ii) test these algorithms on a laboratory test-bed with free-floating vehicles.","title":"Cooperative UAVs: A Higher-Order Approach to Real-Time Trajectory Planningc Coordination, and Control","awardID":"9912447","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["558467"],"PO":["335186"]},"56888":{"abstract":"The PIs are exploring issues relating to the development of viable systems that would allow programmers to create Java programs via spoken English input. They have to this end designed and implemented a proof-of-concept prototype called NaturalJava which supports user input of simple Java programs via written English sentences. Their ability to improve the prototype is limited at present both by software architecture shortcomings and by a lack of understanding of how real users would prefer to interact with a spoken programming interface. What kinds of written and spoken English sentences would they use? What type of navigation\/editing model would be effective in such an environment? To answer questions such as these, the PIs plan to conduct a Wizard-of-Oz user study in which they will invite Java programmers to write programs under controlled conditions. Subjects will write programs using a system that behaves like an improved version of NaturalJava; half of them will use a written English interface, and the other half will use a spoken English interface. A hidden expert Java programmer will play the role of NaturalJava, reading (or listening to) the commands and creating the source code. The PIs expect to learn a great deal by recording and transcribing the sessions, interviewing the programmers, and examining the resulting Java programs. At the end of the year the PIs expect to have acquired a solid understanding of the issues, so that they will then be in a position to detail and pursue their long-term agenda which, if successful, would prove especially valuable to people with certain kinds of disabilities. The research team will include a graduate student who is blind, and for whom most of the NSF funds are allocated; the PIs are not charging for their time.","title":"SGER: Initial User Experiments Towards a Spoken Language Interface for Programming","awardID":"0090100","effectiveDate":"2000-09-01","expirationDate":"2003-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6846","name":"UNIVERSAL ACCESS"}}],"PIcoPI":["351449","451671"],"PO":["565227"]},"55678":{"abstract":"Our society increasingly relies on prompt, accurate delivery of information over the Internet. Users need assurance that the information they get in this way is authentic, and they need to get this assurance in a cheap and reliable way.<br\/><br\/>The research centers around a new approach for engendering this confidence. The starting point is to separate the roles of the \"owner\" of a database and its \"publisher\" (or publishers). With this approach the user need not trust the publisher. Instead, the owner of the database provides the user with a small amount of \"summary information\". After that, the publisher not only answers the user's questions, but also provides, along with each answer, a short \"digital certificate\" of accuracy. Using the summary information, the certificate lets the user check that the information received is correct and complete. Developing and evaluating good schemes to construct these certificates is the key technical challenge.<br\/><br\/>The publisher need not maintain a trusted system, lowering his cost of doing business. The publisher can also more easily provide information from multiple owners. Overall, the approach should make it cheaper to obtain reliable data over the Internet, and will expand the settings where the data is used.","title":"ITR: Scalable and Secure Information Republication","awardID":"0085961","effectiveDate":"2000-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["518062","548342","562714","388358"],"PO":["469867"]},"48803":{"abstract":"Proposal Summary<br\/>In this research, we propose to use group representation theory to generate automatically fast<br\/>algorithms for digital signal processing (DSP) transforms. Group representation theory provides a<br\/>deeper understanding of the structure of signal transforms and a context to address fundamental<br\/>questions in modeling and processing of signals. We propose to use representation theory to design<br\/>new transforms with desirable characteristics.<br\/>Our work is at the meta-level of DSP algorithm libraries (DSP-AL), like SPIRAL, [23]. SPI-<br\/>RAL is a library of DSP algorithms that concatenates a formula generator block with a code<br\/>generator block to produce optimized software implementations for a given computer. SPIRAL<br\/>applies iteratively fast algorithms, the algorithmic rules, to generate a rich collection of alternative<br\/>equivalent formulas (the formula space) for the same DSP algorithm. For each formula, SPIRAL<br\/>then produces automatically optimized code that runs efficiently on the given computer. By<br\/>searching over the formula space, SPIRAL generates automatically the formula and correspond-<br\/>ing code implementation that matches in an optimized sense the algorithm to the hardware.<br\/>What SPIRAL, or any other existing DSP-AL for that matter, does NOT do is the automatic<br\/>generation of the fast algorithm, or algorithmic rules. This meta-level is the focus of our proposed<br\/>research. We exploit group representation theory to develop the theoretical framework and the<br\/>tools that produce automatically these fast algorithms for a number of DSP transforms. We will<br\/>implement and interface these tools to a DSP-AL (SPIRAL) which will enable us to translate<br\/>directly a fast DSP algorithm as generated by our tools to an efficient low-level language program.<br\/>Generating a fast discrete signal transform, given as a matrix, consists of two steps: determin-<br\/>ing the \"symmetry\" of the transform, which is a pair of representations under which the transform<br\/>is invariant; decomposing stepwise the representations, giving rise to factorized decomposition ma-<br\/>trices, which determine the factorization of the transform. The symmetry catches redundancy in<br\/>the transform, and the decomposition of the representations turns the redundancy into a factoriza-<br\/>tion of the transform - the fast algorithm. To realize this program, new results on decomposition<br\/>matrices will be derived in the context of a constructive extension of standard representation<br\/>theory, where representations are manipulated up to equality, not only up to equivalence.<br\/>We will implement the algorithm for generating fast discrete signal transforms within a package<br\/>for symbolic computation with group representations and structured matrices and interface it with<br\/>a DSP-AL, namely SPIRAL.<br\/>We consider different types of \"symmetry,\" going beyond regular representations to include<br\/>arbitrary permutation and monomial representations, in order to capture in the representation<br\/>framework a wide class of signal transforms. Besides the DFT, and trigonometric transforms, we<br\/>will consider other transforms including wavelet transforms.<br\/>We use the group representation framework to explore the connection between the \"symmetry\"<br\/>of a signal transform and its properties with respect to signal processing. The use of a transform<br\/>can be justified on the basis of the model underlying the data. We have shown this relation to be<br\/>connected to the boundary conditions (b.c.) assumed in describing a certain class of models widely<br\/>used in applications. These b.c.'s also reflect the type of \"data extension\" that is hypothesized,<br\/>for example, cyclic b.c.'s versus signal periodic extension versus the discrete Fourier transform.<br\/>This proposal will exploit the relations between the \"symmetry\" of the representation, the signal<br\/>transform, and the signal models, enabling us to address some fundamental questions, namely<br\/>how to design a signal transform which is adapted to a given signal model (i.e., reflects a desired<br\/>symmetry) and is computationally the most efficient.","title":"Group Representations and Automatic Generation of Fast Algorithms for Discrete Signal Transforms","awardID":"9988296","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["451785","332185"],"PO":["564898"]},"69516":{"abstract":"","title":"CISE Educational Innovation: Radically Rethinking CSI","awardID":"0196404","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"1536","name":"S-STEM:SCHLR SCI TECH ENG&MATH"}}],"PIcoPI":["434524"],"PO":["551712"]},"69307":{"abstract":"","title":"Compiler Optimizations for Limited Memory Embedded Systems","awardID":"0196126","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["550988"],"PO":["551992"]},"48748":{"abstract":"The focus of this research is on developing techniques and algorithms that<br\/>will allow idle workstations to be opportunistically exploited for parallel<br\/>and distributed shared-memory applications. The target environments range<br\/>from local-area networks (LAN's) to wide-area networks (WAN's). The central<br\/>challenges are competition from other applications for workstation and<br\/>network resources, load imbalance arising from differing system speeds, and<br\/>heterogeneity.<br\/><br\/>The intent is to design and build as transparent a system as possible. Such<br\/>a system will need new methods of deriving dynamic sharing and processor<br\/>capacity information online, new load-balancing and thread-migration<br\/>heuristics that minimize both communication and load imbalance in dynamic<br\/>environments, and easy-to-use API's that will provide the type information<br\/>needed to address heterogeneity. The end result of this work will be a set<br\/>of techniques, policies, and code that will allow shared-memory<br\/>applications to be transparently migrated across a set of non-dedicated<br\/>workstations. In allowing otherwise-unused resources to be exploited by<br\/>this new application domain, this research will significantly expand the<br\/>value of incrementally-deployed sets of workstations.","title":"Shared-memory Metacomputing","awardID":"9988129","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["409678"],"PO":["241298"]},"54920":{"abstract":"The goal of this research is the production of an improved computer code for molecular electronic structure computation that permits the practical computation of the energy of a molecule with an accuracy at least ten times better than that currently possible. The project will apply this code to the computation of energy barriers and potential energy surfaces for elementary gas phase chemical reactions. Once it becomes aailable to the general scientific community, the code will find application to a wide range of other problems in chemistry and materials science. The computed potential energy surfaces will have immediate application for reactive scattering computations. In this way the project contributes significantly to the infrastructure that will eventually enable the computation of chemical rate constants from first principles. These constants are widely applicable. For example, they are essential input for computer models of atmospheric chemistry and combustion.<br\/><br\/>The new feature of this method is the use of Rayleigh-Schroedinger perturbation theory to treat the electron correlation cusp problem. Existing highly-developed orbital-based methods are well suited to description of the global behavior of the wave function. However, they are not well suited to the description of the cusp, a secondary feature that eventually limits the accuracy of large scale electronic structure computations. The new method solves the first-order wave function by use of explicitly correlated geminal basis functions.","title":"ITR: Perturbation Theoretic Approach to the Electron Correlation Cusp Problem","awardID":"0082899","effectiveDate":"2000-09-01","expirationDate":"2004-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[140350,"510422","384253"],"PO":["551992"]},"54931":{"abstract":"This is the first year funding of a three-year continuing award. This project addresses the need to assist humans in heavy materials handling, since such tasks expose the worker to known risk factors for work-related musculoskeletal disorders, such as lifting, bending, twisting, and maintenance of awkward postures. This project will study the use of cobots to implement ergonomic guiding surfaces to assist a human in the manipulation of a heavy load. With such a mechanism, the load can be constrained to move along a frictionless guide, and the human is allowed to apply forces in directions which are comfortable while the guide directs the motion to the goal. Cobots use rolling contacts to directly implement passive guiding constraints, and as a result they are safer to interact with and use less power than a conventional robot. To design assistive guide constraints, the project will study how humans naturally interact with constraints assuming that the essential nature of this interaction can be modeled by the human's desire to minimize some notion of effort. With this model, The PIs will design guides that minimize the necessary human effort and will experimentally verify the correctness of the model. The PIs will develop software for automatically planning near-optimal guides in cluttered workspaces and will test the guides using cobot hardware on realistic materials handling tasks. The resulted ergonomic virtual surfaces in materials handling will reduce the occurrence of work-related musculoskeletal disorders. It will also increase productivity, providing an intuitive and safe interface between human and computer. Finally, this work will expose new principles in human motor control, as the design of assistive guiding surfaces requires a better understanding of how humans interact with constraints.","title":"ITR:- Virtual surfaces for human\/robot mutual labor","awardID":"0082957","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["522422",140387,"541975",140389],"PO":["234178"]},"54700":{"abstract":"The project will construct a Virtual Variorum Edition (VVE) of Cervantes' (1547-1616) influential \"Don Quixote de la Mancha\". The VVE, based on available-quality microfilmed images of the original editions published during Cervantes' life, will contain the important editions of the work in image and text; annotation of the variances present among the editions to enable comparison; derivative editions, generated as the result of scholarly analysis of the variances and bearing supporting reasoning; and commentary by experts that illuminates elements of texts and of the comparisons among editions. The project's focus is on the digital representation, interlinking, and dissemination of the many computer-based manifestations of the documents and commentary. It will prototype an end-to-end effort; from front-end acquisition of materials through flexible back-end presentation to readers. The VVE, even in prototype form, will be an important artifact, with potential to become the standard research tool used by Cervantes scholars. It will, for the first time, make the resource of multiple rare editions of the \"Quixote\" easily available in primary-source form. The project will have implications for Digital Library projects involving the humanities, both as an demonstration of what can be achieved today but also through development and validation of techniques.","title":"ITR: The Cervantes Project--Advances from Computer Science Research to Update and Enhance Traditional Scholarship Practices","awardID":"0081420","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["465209",139747],"PO":["564456"]},"54821":{"abstract":"A fundamental problem in a wide variety of wideband communications applications is that of adapting a unitary matrix. For example, consider an array-to-array AWGN wireless communications link in which the transmitter has knowledge of the channel. To achieve the Shannon capacity of such a link, the optimal transmitter prefilters the vector of transmitted symbols by the right unitary factor in the channel singularvalue decomposition. This prefilter, coupled with a matrix-valued matched filter at the receiver, converts the matrix channel into an equivalent bank of independent scalar channels, greatly simplifying the modulation, coding, and other signal processing tasks needed to maximize throughput. Despite the optimality of the unitary prefilter, however, the high complexity of the SVD (especially for rapidly varying channels) makes it difficult to realize in practice. A low-complexity algorithm for adapting a unitary matrix could be the catalyst that brings such optimal space-time processing closer to reality. Other applications requiring an adaptive unitary matrix include blind fractionally spaced equalization; blind multiuser detection for CDMA; blind combining for narrowband arrays; and signal-noise subspace separation and subspace tracking. <br\/><br\/>The objective of this proposal is to develop low complexity and robust strategies for adapting unitary matrices, to assess their performance, convergence properties, and complexity, and to compare them to existing alternatives. The proposal is built around three core algorithms for adapting a unitary matrix U k T he MPLL algorithm, the subspace separator, and the adaptive SVD algorithm. All three take the form:<br\/><br\/>U k + 1 = U kR l {g(z k ) z k },<br\/><br\/>where z k = U k * y k and y k is the receiver observation vector, and where R l {x z} denotes a particular unitary matrix that rotates x \/ || x || a fraction l of the way to z \/ || z ||. The memoryless function g(z) is anonlinear decision device for the MPLL, while it is a linear matrix for the subspace separator and the adaptive SVD algorithm.<br\/><br\/>This recursion has a number of nice properties; it is conceptually simple, and simple algorithms are often the most robust; it ensures that U k is always unitary, since R l is unitary; there exists a lower complexity implementation that does not require full-rank matrix multiplication; and the recursion has a useful geometric interpretation that facilitates its application to new areas. Furthermore, as discussed in this proposal, preliminary results indicate that the recursion has excellent convergence properties. <br\/><br\/>The inspiration for the proposed algorithms came from the scalar phase-locked loop (PLL). The PLL is clearly the workhorse for adapting unitary scalars, primarily because of its robustness, low complexity,good performance. It stands to reason, therefore, that some of these properties might carry over into the higher-dimensional problem of adapting unitary matrices. <br\/><br\/>The proposed research constitutes a significant advancement in the theory of signal processing and its application to communication theory, and is applicable to a wide variety of signal processing applications beyond communications. The project will provide two Ph.D. students with extensive physical-layer training for next-generation wideband communications systems.","title":"ITR: Adaptive Unitary Matrices For High-Speed Communications","awardID":"0082329","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["507792"],"PO":["564898"]},"54942":{"abstract":"This project explores techniques for efficient computation on large, disk-based data sets. The research focuses on theoretical and practical aspects of ``active'' storage systems, in which each storage unit (a disk or group of disks) has some limited capability for local computation. A key goal of the project is to develop a theoretical model for active storage systems. The model is a basis for designing and evaluating algorithms for active storage systems, identifying useful computation kernels for active storage units, and deriving lower bounds for fundamental problems. The applied aspects of the project include design and implementation of a programming environment (PEARL) for active storage algorithms, and experimental evaluation of new algorithms for active storage. This project is a collaboration with a separately funded project team at Carleton University in Ottawa, Canada.","title":"ITR: Algorithms for Active Storage","awardID":"0082986","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["313394","553906"],"PO":["180163"]},"54832":{"abstract":"EIA-0082393<br\/>Hickey, Timothy<br\/>Brandeis University<br\/><br\/>ITR: Groupware-Mediated Cooperative Programming: Teaching Web<br\/>Technology to Non-Scientists<br\/><br\/>One consequence of the rapid growth of the Internet is the corresponding<br\/>rapid increase in the demand for teams of software and Web site developers<br\/>to support the creation of Web content and services. Complicating matters<br\/>is the need to train large numbers of workers with non-technical<br\/>backgrounds for the growing electronic workplace. This research explores<br\/>groupware-mediated cooperative tools to teach IT skills to novices. A same<br\/>time\/different place groupware system will be built, deployed, and<br\/>experimentally tested that supports collaborative learning of Web<br\/>development and applet programming for a computer science general service<br\/>course serving social science, humanities, and fine arts students.","title":"ITR: \/Groupware-Mediated Cooperative Programming: Teaching Web Technology to Non-Scientists","awardID":"0082393","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[140100,140101],"PO":["564318"]},"51323":{"abstract":"","title":"Design and Implementation of Algorithms in Semi-Algebraic Geometry","awardID":"0049070","effectiveDate":"2000-09-01","expirationDate":"2003-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["550244"],"PO":["201974"]},"54722":{"abstract":"Project Summary<br\/>Objectives - This project aims to develop new applied mathematical technologies that add res a<br\/>widespread need in computational and simulation science: the quantitative optimization and verifi-<br\/>cation of dynamical models, incorporating both chaotic and stochastic behaviors, against observed<br\/>data. In the last couple of decades, great effort has been devoted to constructing simulation-based<br\/>models for complex phenomena, with profound advances in both analytic techniques for numerical<br\/>approximation and implementation technology on digital computers. Progress along one of the<br\/>final steps to gaining scientific insight, the verification of models against Nature, has been more<br\/>haphazard. When model and natural physical system produce temporally unpredictable variables<br\/>one cannot match any specific time-dependent behavior but only compare statistical quantities<br\/>extracted from both. Here, common practice is frequently quite crude, and is where we direct our<br\/>investigation.<br\/>Methods to be employed - We exploit recent developments in coding theory, specifically, context-<br\/>tree methods developed for universal data compression by the information theory community.<br\/>These techniques are computationally rapid, have excellent empirical performance and theoretical<br\/>properties. Our goal is not literally to compress data, of course, but to use the data structures<br\/>and models of the coding methods as high-quality statistical intermediaries between computational<br\/>models and observed data sets, providing a common mathematical \"meeting ground\" where fair,<br\/>and theoretically justifiable comparisons may be made.<br\/>Potential impact of the project - Large scale simulations play an increasingly important role in<br\/>the study of complex phenomena of national and global importance, from the efficiency, capability<br\/>and byproducts of complex industrial combustion and reaction systems, to environmental moni-<br\/>toring, culminating with global climate models. Predictions derived from these models inevitably<br\/>enter into the public discourse about policies, with significant legal and economic impact upon<br\/>many. The scientific community thus bears a burden to ensure that the models have been tested<br\/>against actual experiment and cross validated with intellectually sound approaches, and herein lies<br\/>the principal scientific value of the proposed investigation.<br\/>The Institute for Nonlinear Science at UCSD has an excellent international reputation and has<br\/>been able to attract high-quality post and pre-doctoral students with diverse backgrounds and<br\/>educational emphasis. This particular project offers will offer an opportunity for the students to<br\/>simultaneously learn about intriguing statistical and theoretical developments from the engineering<br\/>and applied mathematics community applied, in an novel cross-disciplinary approach, to models<br\/>of realistic, and important engineering problems, all set in the Institute's milieu and language of<br\/>\"applied theoretical\" physics. The skills that a successful student will take from this project com-<br\/>prise as are some mathematical fluency, physical intuition, engineering practicality and integrated<br\/>numerical and symbolic computational skills.<br\/>Finally, to the computational community, we anticipate developing and universally offering<br\/>free-standing software to perform the analyses described in the project proposal. We hope to<br\/>lower the barrier to entry for on-the-front-line computational and experimental scientists to employ<br\/>these algorithms, raising the quality of common scientific practice in dynamical model verification<br\/>without being so impractical or esoteric that few are able to successfully adopt our viewpoint.","title":"ITR: Validating simulation to observed data with source coding methods","awardID":"0081636","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[139814],"PO":["564898"]},"42864":{"abstract":"EIA-9911078<br\/>Margaret Martonosi<br\/>Princeton University<br\/><br\/>CISE Research Instrumentation: Instrumentation Support for System-On-A-Chip and Embedded System Research<br\/><br\/>The Department of Electrical Engineering at Princeton University will purchase a high-end server, workstations, networking hardware, and CAD tools, which will be dedicated to support research in computer engineering. The equipment will be used for several research projects, all generally in the areas of Computer Architecture, Computer-Aided Design, and particularly focused on advancing design and architecture techniques for embedded systems and systems-on-a chip.<br\/><br\/>In a fundamental paradigm shift system design in the semiconductor industry, entire systems are being built on a single chip, using multiple embedded functional blocks called cores. This has been made possible by the ever-increasing density of chips. The current 0.25-micron technology has made it possible to integrate tens of millions of transistors on one chip, and considerable interest is focused on discussing what the contents of billion-transistor systems-on- a-chip (SOCs) ought to be.<br\/><br\/>We propose to develop algorithms and tools to provide key technologies with breakthrough potential to semiconductor companies,and to develop efficient software environments and tools to deal with all aspects of the SOC design problem.","title":"CISE Research Instrumentation: Support for System-on-a-Chip and Embedded System Research","awardID":"9911078","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["431683","550002","213414","495323"],"PO":["557609"]},"55701":{"abstract":"The applications of microfluidic devices (which involve liquids moving in spaces measured in micrometers, i.e. millionths of a meter) are growing explosively. As a specific example, consider the development of microsystems for blood testing and screening. For consumers, one could envision devices available in drugstores that could perform genetic screening for conditions of concern to individuals. At a larger scale, use of such devices in blood banks could significantly reduce the time and blood lost in screening the 14 million pints of blood donated per year. Sample preparation is a critical bottleneck in the development of integrated miniature analytical systems, and it remains largely unaddressed. It is currently done outside the microsystem by mixing, shaking, and pipetting, because there are no effective integrated design method. Improved computational methods promise to allow integration and interconnection of microfluidics. This will have an effect analogous to automated methods for VLSI design on microelectronics; it will revolutionize the field.<br\/><br\/>This project will develop a computational infrastructure for simulation and design of microfluidic systems involving non-Newtonian, micrometer\/nanometer-scale flows dominated by surface-related phenomena. Computational tools and analytical tools will be developed and used to compare with theoretical and experimental results. The project emphasizes methods to deliver complex molecules to flow surfaces, to create surface reaction sites and to provide the components for molecular-scale mixing and dispensing. It will design, fabricate, and characterize both stationary and oscillating MEMS fluidic channels and surfaces to evaluate molecular-scale mixing, flow, delivery, and dispensing of complex biological fluids. The focus will be on surface dominated flow and reaction phenomena that can be scaled for delivery of single molecules to programmed reaction sites. Such surface-related phenomena should find broad application in making MEMS-based, \"chip-scale\" analytical instruments and \"biochips\". The computational tools required to analyze and design such devices are currently nonexistent. This project brings together a team of computer scientists, numerical analysts, fluid dynamicists, experimentalists, and microscale process theoreticians who will collaborate closely on creating those tools and using them.","title":"ITR: Computational Infrastructure for Microfluidic Systems with Applications to Biotechnology","awardID":"0086061","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["449907","244163","524314","486626","275409"],"PO":["565272"]},"51103":{"abstract":"The Potomac Institute for Policy Studies will convene a conference in June 2000 to address two broad questions of importance to US Armed Forces: what opportunities do advances in science offer to US forces and how do scientific advances change the type of threats to US forces. The workshop will bring together representatives of the military, Congress, and scientific communities to present their views of changes pertinent to these questions. Specific areas addressed at the workshop include military perspectives on maneuver and power projection and protection, firepower and precision targeting, air warfare, space warfare, information and networking, and intelligence and threat assessment. Science perspectives on topics such as energy, human factors and neuroscience, nanoscale technologies, information and knowledge, biomedical advances, and advanced materials will also be provided. The workshop organizers will prepare a report that summarizes the presentations and conclusions.","title":"Out of the Box and into the Future: A Dialogue Between Warfighters and Scientists on Far-Future Warfare Conference","awardID":"0004254","effectiveDate":"2000-09-15","expirationDate":"2001-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}}],"PIcoPI":["394020"],"PO":["198445"]},"55712":{"abstract":"This is the first year funding of a five-year continuing award. The goal of this project is to improve reading achievement of children with reading problems by designing computer-based interactive reading tutors that incorporate new speech and language technologies. The reading tutors will help English- and Spanish-speaking children learn to read by providing classroom teachers and reading specialists with tools to instruct and exercise the set of auditory, visual and linguistic skills needed to read, speech discrimination, speech production, phonological awareness, sound-to-letter mappings, vocabulary, fluency and comprehension. The tutors will be designed, tested and refined in collaboration with reading specialists and instructional designers, and tested with children in special education programs in elementary schools in Boulder Colorado. <br\/><br\/>The tutors will incorporate new and improved auditory and visual speech recognition and facial animation technologies. Five partner sites - Oregon Graduate Institute (OGI), Universidad de las Americas, Puebla (UDLA), University of California, Santa Cruz (UCSC), University of California, San Diego (UCSD) and the University of Colorado (CU), will develop speech and language technologies. Research and development of children's speech recognizers will be conducted at UDLA for Spanish and at OGI for English. In addition, these sites will design and develop speech corpora to enable recognition research. UCSD will conduct research leading to development of head tracking and speech reading systems, and design and develop video corpora to enable this research. UCSC will conduct research leading to development of new animated faces with improved animation capabilities. System integration will be conducted at OGI, which will integrate auditory and visual recognition systems and facial animation systems into the CSLU Toolkit. CU will develop English reading tutors in collaboration with teachers, instructional designers and students, and conduct evaluations of project outcomes. UDLA will also develop and test Spanish versions of the tutors.<br\/><br\/>The project is expected to produce significant advances in auditory and visual recognition technologies, including accurate recognition of children's speech, accurate recognition of visual features of speech, and the first real-time integration of auditory and visual speech recognition in language training applications. In addition, the PI and his team will achieve a new level of understanding of the structure of children's speech, and the processing of auditory and visual information in reading. Facial animation is expected to play a major role in engaging children, enabling them to enjoy the learning experience more and therefore spend more time on task. The PI expects to demonstrate that facial animation using visible articulators will improve speech discrimination and speech production skills, improved phonological awareness and improved reading. By integrating auditory and visual speech recognition and speech generation technologies into animated agents, and designing reading tutors that incorporate these agents in a well designed reading program, the PI hopes to improve reading achievement in schools. To optimize this outcome, the PI is working closely with reading specialists to incorporate their experience and best practices; and by developing formative and summative evaluation plans that assure fair and accurate assessment of the outcomes of the planned interventions.","title":"ITR: Creating the Next Generation of Intelligent Animated Conversational Agents","awardID":"0086107","effectiveDate":"2000-09-01","expirationDate":"2007-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7496","name":"COLLABORATIVE SYSTEMS"}}],"PIcoPI":[142849,"551122","463668","483791"],"PO":["565227"]},"54623":{"abstract":"EIA-0080940<br\/>Novick, David G.<br\/>University of Texas at El Paso<br\/><br\/>CISE Minority Institutions Infrastructure: Graduate Education for Minority Students in Computer Science and Engineering: Extending the Pipeline<br\/><br\/>The proposed project concentrates on: (i) building community among relatively isolated majority-Hispanic institutions, so that students early in the pipeline have access to role models, (ii) building a strong graduate program in a majority-Hispanic community, so that students and the program can take advantage of existing community and university support structures, and (iii) building communities of interest among the four-year colleges, an M.S. and Ph.D. granting university with the experience and capabilities to support Hispanic students, and Ph.D. granting research universities so that the students late in the pipeline have a high level of engagement with excellent research.","title":"MII: Graduate Education for Minority Students in Computer Science and Engineering: Extending the Pipeline","awardID":"0080940","effectiveDate":"2000-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7399","name":"CISE MINOR INST INFRA (MII) PR"}}],"PIcoPI":[139538,"408502","318770","559621"],"PO":["550859"]},"54865":{"abstract":"Interactive exploration effectively enables scientists to identify and interpret data, embedded in much larger datasets, that represents significant underlying phenomena. There is a critical need for data management support for the process of interactive exploration of very large data sets. However, scientific database research has not yet had a major impact on the way that scientists actually use scientific data. The lack of a comprehensive conceptual model for the scientific data has limited the success of current systems in becoming more general and less ad hoc. <br\/><br\/>The principal goal of this research is to develop, validate, and prototype a formal data model for distributed multi-resolution scientific data that encapsulates its inherent structure to guide efficient database implementation. The model includes comprehensive geometry and topology-based features for describing a wide variety of sampling grids, features for representing sub-domains of a dataset that contain discovered knowledge, and error measures that reflect the accuracy or authenticity of each representation level. From a repository containing a dataset represented as a multi-resolution hierarchy, a scientist accesses successive levels of error-annotated detail to zoom into the meaningful areas, downloading data from these regions to a LAN and his\/her workstation for further","title":"ITR: A Data Model for Multiresolution Scientific Data","awardID":"0082577","effectiveDate":"2000-09-01","expirationDate":"2005-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["358445",140191],"PO":["563751"]},"55723":{"abstract":"With the advances in embedded processors, low cost sensor technologies, and wireless communication, unprecedented amounts of diverse types of information about the real world and its activities are being generated. Much of the information is spatio-temporal in nature; concerning objects dispersed in space and time, and interacting and communicating with each other and their surroundings. An infrastructure that facilitates real-time capture, storage, processing, display, and analysis of the information generated will truly revolutionize a wide variety of application domains. Examples of domains that will benefit from this technology include avionics, ground traffic, commercial applications such as ship-ping and transportation, emergency response and disaster relief operations, physical phenomenon such as weather and storm tracking, forest fire tracking, migration patterns of animals\/birds, command and control, smart environments, etc. Applications in the above domains require real-time monitoring, tracking and analysis of objects\/events\/phenomena in space and time. <br\/><br\/>An integral component of such sensor enriched communication and information infrastructure is a database management technology that allows seamless access to information dispersed across a hierarchy of storage, communication and processing units - from sensor devices, where data originates, to large data banks where the information generated is stored for analysis and mining. This research will explore next generation database management system technology that provides effective support for information processing in highly distributed and dynamic sensor-enriched environments. The approach taken will be end-to-end - that is, research will be conducted on all aspects of the system ranging from representation, data modeling, query languages, data structures, query optimization, query processing, distribution, and concurrent accesses. A prototype database management infrastructure that supports highly dynamic geographically dispersed spatio-temporal data, multi-resolution representation of data, and provides effective support for visualization and analysis will be developed.","title":"ITR: Collaborative Research: Real-time Capture, Management and Reconstruction of Spatio-Temporal Events","awardID":"0086144","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["557651","523591"],"PO":["563751"]},"54755":{"abstract":"High velocity work environments such as medical trauma centers depend on robust and efficient coordination by team members to bring together appropriate knowledge and skills, or expertise. This project investigates the existing and potential role of information technology (IT) in expertise coordination in a type of high velocity, high outcome work environment: level-I trauma centers in this country. A combination of qualitative and quantitative methods are used to collect observational and survey data in a range of trauma centers regarding the expertise needs of trauma medical teams, the points of expertise needs, the modes of acquiring needed expertise, the sources of information related to work and expertise coordination, and uses of IT for the coordination of needed expertise, as well as broader organizational variables. The project will contribute to the development of guiding principles in the design of next generation IT for high velocity work environments in the areas of user interfaces, coordination modes, and the evaluation of IT on coordination. It will contribute to the understanding of expertise coordination and how IT affects these processes. Finally, the project will enhance an existing multi-disciplinary research program on information and coordination, particularly as it relates to issues in emergency trauma care.","title":"ITR: Expertise Coordination and Information Technology in High Velocity Work Environments","awardID":"0081868","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["472085","225702","317910",139905,139906],"PO":["495796"]},"54876":{"abstract":"The DHARMA domain-specific middleware system being developed in this project is intended to allow hydrologic field engineers to address water-management problems, on a scale previously impossible, with sophisticated domain-specific computational management systems. DHARMA is used to provide automatic data acquisition via the Internet; data fusion from online, local, and cached resources; smart caching of intermediate results to allow for reuse in future simulation cycles; and smart scheduling to optimize execution times on metacomputing systems. Our target watershed model, WEPP, is a continuous simulation processed-based model which represents new soil erosion prediction capabilities. However, it is limited to very small watersheds with current computer technology. A revolutionary change in hydrologic modeling on the watershed scale will be brought about by applying the WEPP model to the 925 square miles Lake Decatur watershed. Currently, all watershed scale hydrologic models are based on empirical relationships. WEPP is the only model which scientifically accounts for soils, sediment transport, runoff, channel flow, plant growth, decomposition, snow melt, freeze-thaw effects, and climatic conditions. Through DHARMA, WEPP is the only model which will provide accurate predictions and evaluate the effects of alternative watershed management practices on watershed water quality.","title":"ITR: DHARMA: Domain-Specific Metaware for Hydrologic Applications","awardID":"0082667","effectiveDate":"2000-09-01","expirationDate":"2005-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[140221,"528451","495163",140224,"559268"],"PO":["563751"]},"55624":{"abstract":"This is the first year funding of a four-year continuing award. The proportion of elderly in the United States is growing at a phenomenal rate, yet little of today's information technology addresses the critical problems that arise as a result of this demographic shift. This project will develop advances in IT to address one such challenge, that of enabling the elderly to remain living in their homes for as long as possible. More specifically, the PI and her team will design and build a personal mobile robotic assistant for the monitoring and guidance of the daily activities of an elderly person. To achieve that vision research will be conducted to advance the state-of-the-art in several areas of IT, including: the development of advanced techniques for flexibly reasoning about plans and monitoring their execution; the development of statistical algorithms for learning models of people's daily activities; the design and evaluation of self-tailoring multi-modal interfaces that enable elderly people to interact easily with the robotic assistant; and the development of new sensor modalities to meet the needs of a mobile robot in an elder's home. The work will be evaluated along three dimensions: through theoretical and simulation-based evaluations of components, through targeted user studies, and through a series of field tests conducted at regular intervals throughout the project in the homes of elderly people. The research team is multi-university and interdisciplinary, comprising experts in the fields of computer science, robotics, human-computer interaction, and health care. The project also includes a strong education focus in that it seeks to provide a unique forum for training undergraduate and graduate students in issues related to IT for the elderly.","title":"ITR: Personal Robotic Assistants for the Elderly","awardID":"0085796","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["549458",142503,142504],"PO":["565227"]},"54535":{"abstract":"This project will identify materials and devices for the construction of Sensitive Skin. Sensitive Skins will enable machines to sense over their entire surface, operate in unstructured environments, and become \"cautious.\" The availability of Sensitive Skin would trigger a revolution in service automation, raise the efficiency of machine use, thereby greatly benefiting the environment, and provide powerful prosthetic devices to humans. The project will begin by exploring the incorporation of integrated circuit type metalization in bendable and stretchable passive circuits. Their physical components will be first meanders then helices of interconnect wires made by thin film techniques. These will be embedded near the neutral plane of the circuit structure. Active devices, primarily thin film transistors, at first will be confined to rigid platforms. Depending on advances made in the experimental and theoretical understanding of stretchable metalization, further experiments will address flexible active devices and circuits. The result of this project will be basic design rules for constructing Sensitive Skin.","title":"Electrical and Mechanical Design Rules for Skin-Like Transistor Circuits","awardID":"0080693","effectiveDate":"2000-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["518190"],"PO":["234178"]},"54777":{"abstract":"The problem of numerical robustness and geometric consistency is well known<br\/>in many areas of computational science. The issue is that inexact computer arith-<br\/>metic leads to incorrect and inconsistent geometric conclusions (for example, is a<br\/>point inside or outside a triangle). While computers are getting faster, software<br\/>is not getting more robust. Indeed, the trend is towards more nonrobustness. We<br\/>propose a new computational paradigm to reverse this trend.<br\/><br\/>Robustness is often seen as an all-or-nothing proposition. Our new paradigm<br\/>consists in viewing robustness as a computational resource, to be traded off against<br\/>other resources such as speed. Each program defines a certain robustness-speed<br\/>trade-off curve; we want to be able to run the program at any point along this<br\/>curve. This proposal will develop the technology to make this capability effcient<br\/>and easily accessible to all programmers. As a result, any programmer can produce<br\/>nearly ordinary C\/C++ code which can be run robustly. The implications of this<br\/>paradigm are wide ranging, and will bring the fruits of robustness research into<br\/>mainstream computing.<br\/>We propose to (1) conduct basic research to support this new computing<br\/>paradigm, (2) to create the technology and software tools to achieve this paradigm,<br\/>and (3) to explore the applications of fast and usually robust algorithms in algo-<br\/>rithm design. For (1), we will focus on effciency issues such as novel root bounds,<br\/>incremental computation, guaranteed absolute precision for elementary functions.<br\/>For (2), we expect to significantly extend the power, efficiency and usability of our<br\/>Core Library and include capabilities such as symbolic perturbation. Finally an<br\/>example of (3) concerns the general problem of checking of geometric structures and<br\/>their applications in new efficient geometric algorithms.<br\/>We propose to apply our robustness techniques and software to two significant<br\/>applications in which nonrobustness problems are well-known:<br\/><br\/>* Mesh Generation: we will construct the first fully robust mesh generator which<br\/>will be deployed in a major ow solver system, Cart3d.<br\/><br\/>* Geometric Modeling: we will build a robust geometric modeler which will be<br\/>the first such system that is precision-sensitive.<br\/><br\/>This proposal involves international collaboration with Professor Mehlhorn's<br\/>Algorithms and Complexity Group at the Max-Planck Institute of Computer Sci-<br\/>ence in Germany. Our domestic collaborator are Michael Aftosmis from NASA<br\/>Ames Research Center (on mesh generation) and Shankar Krishnan from AT&T<br\/>Research Laboratories (on geometric modeling).","title":"ITR: A New Computational Paradigm: Robustness as a Resource","awardID":"0082056","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["409933",139962],"PO":["562362"]},"54788":{"abstract":"This is the first year funding of a three-year continuing award. Inspired by the fact that even the simplest of animals, such as insects, have remarkable perception capabilities which are difficult for present-day engineered systems to duplicate, this project seeks to understand how the brain accurately organizes and processes on the macro-scale level the temporal flow of visual information at a lower stage of the visual pathway that is the primary visual cortex (also called area V1) and to develop machine vision systems based on the findings to mimic brain visual function. The novel aspects of this project include the innovative use of scalp electrodes to probe macro-scale processes of the visual cortex, investigation of encoding of sequences of patterns rather than single presentations, use of innovative mathematical models, and recognition of the existence of several different, task modulated, low-level perceptual mechanisms. The experimental part of the project focuses on the storage of temporal patterns, presented continuously over the time scale of tens of minutes, and how the stored information is integrated in the primary visual cortex with the newly acquired visual input. Scalp recordings will be used to investigate collective responses of neurons in area V1 to sequences of patterns in which the similarity among patterns will be modulated in different ways. Mathematical models of dynamic aggregation, encoding, and reduction of information will be developed. The models will be augmented later to explore different possible roles that memory and attention can play in this aggregation of visual information. Finally, the models based on adaptive versus fixed cell responses will be compared. Of major interest throughout will be the investigation of perceptual capabilities that can emerge at the level of processing of the primary visual cortex and the innovative machine vision algorithms that can be developed that capture these capabilities. In addition to the potential of producing machine vision systems with capabilities of real vision, the work will contribute to the advancement of basic scientific understanding in the field of neurosciences, in particular of processes in the visual cortex. Neuromorphic system design is a developing new discipline that meshes neuroscience and mathematical modeling. Furthermore, the project will be a three way international collaboration between laboratories at the University of California at San Diego, the Algerian Ecole Nationale Polytechnique, and the Brain Science Institute in Japan. This will provide a rare opportunity for the students to work in an international research setting and to establish collaborative ties they may benefit from in the future in their independent research careers.","title":"ITR:Algorithms for Machine Perception based on Visual Cortex Models","awardID":"0082119","effectiveDate":"2000-09-01","expirationDate":"2004-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[139990],"PO":["234178"]},"43315":{"abstract":"Parallel architectures based on the optical interconnect technology are becoming more and more popular as reflected by the numerous optical computers that have been proposed in recent years. Optical computers have been shown to possess superior interconnect properties compared to their electrical counterparts. These architectures offer the potential of building affordable machines operating at extremely high speeds.<br\/><br\/>The development of algorithms for the proposed optical architectures is complicated by the fact that some models support pipelined data transfer, other models have a heterogeneous interconnect topology, and yet other models use an asymmetric topology. Although algorithms have been designed for some of these models, this development is in its infancy. The developed algorithms are mainly for a limited set of fundamental problems, and even this level of development has been done for only a few of the proposed architectures. Further, the developed algorithms assume that the size of the architecture is a function of the problem size. This assumption is clearly invalid in practice. Typically, the problem size will be much larger than the size of the architecture. An important question is if the optical architecture algorithms that have been developed so far are scalable. That is, can they be efficiently extended to solve problems whose size is considerably larger than the machine size. In this project the base of known efficient algorithms for optical architectures will be significantly expanded. Special attention will be paid to scalable algorithms. A cross-architecture performance study from the algorithms point of view will be performed. This study will be conducted in the domains of fundamental data operations and image processing. Scalability study has been conducted in the past by various researchers on models such as the PRAM, meshes with buses, and so on. But little has been done for the optical models. Also, many of the past works (for example, on meshes with buses) have studied the scalability issue by simulating a machine of one size on a machine of different size. Such studies are restricted in their applicability. In this project the general scalability issue will be investigated and hence the scalability of algorithms will be explored directly. In particular, the following question will be addressed: As the size of the input increases arbitrarily, how do the speedup and efficiency of the algorithm under concern change?<br\/><br\/>The problem domains of interest are fundamental data operations such as sorting, routing, selection, etc. and image processing operations such as clustering, template matching, histogram, FFT, etc. These operations have been chosen since they span a number of application domains. At least three optical architectures, namely, Arrays with Reconfigurable Optical Buses (AROBs), Optical Transpose Interconnection Systems (OTISs), and Partitionable Optical Passive Star (POPS) computers, will be considered. The algorithms and algorithmic techniques to be developed in this project can be expected to be applicable to other architectures as well.","title":"An Algorithmic Evaluation of Optical Interconnection Networks","awardID":"9912395","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["485106","559638"],"PO":["543507"]},"54689":{"abstract":"As design-for-test (DFT) research becomes mature, a deep understanding of the relationship among structural features and their mutual effects on testability is needed. Sequential loops are widely accepted as a significant testability problem that must be addressed by the DFT process. Reconvergent fanout is also known to be a problematic structure for testability, however its impact on test has not been thoroughly studied. This project will investigate the relationship between reconvergent fanout, sequential loop length, and aspects of testability including fault coverage, test application time, and test generation time. This understanding will enable the creation of new DFT approaches, which improve testability in a unified way, considering all structural features and their interactions.","title":"ITR: Data Correlation and its Effects on VLSI Testability","awardID":"0081343","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["251935"],"PO":["562984"]},"55668":{"abstract":"Today's Internet owes its great success to the simple, \"hour-glass\" IP network protocol architecture laid out twenty-five years ago. With rapid advances in networking technologies and explosive growth of rich multimedia content in recent years, the networking community finds itself at an important crossroads: what should be the next generation Internet architecture for controlling network resources and provide the quality of service (QoS) needed by emerging multimedia applications? There is a multidimensional spectrum of possible approaches to providing QoS guarantees. The choice of a QoS solution for the next generation Internet will have a substantial impact on both the evolution of the Internet itself, and on what it enables. Making the \"right\" choices requires the development of a fundamental understanding of the scalability of QoS controls and the impact of these controls on the efficacy of QoS provisioning.<br\/> The goal of the proposed research is to develop a comprehensive, quantitative understanding of the fundamental trade-offs involved in various approaches toward providing scalable QoS guarantees. To this end, the researchers will develop coherent theories to systematically address the issue of scalability in QoS controls. Our research program divides broadly into four areas:<br\/> Aggregate network calculus for guaranteed flows: To gain a thorough understanding of the fine time-scale(e.g., packet-level) behavior of a network system in providing QoS performance guarantees, we will develop an aggregate network calculus to study the impact of aggregate QoS control mechanisms on the performance and complexity of data plane operations. This theory is developed for guaranteed flows - flows which require the network to commit, either at a per-flow or an aggregate level, a certain amount of resources (e.g., bandwidth and buffer) throughout their life time, regardless of the network congestion status. The aggregate network calculus will provide a mathematical framework to quantify the impact of aggregate QoS controls on the fundamental trade-offs in QoS provisioning. It will also yield insights into the design of scalable data plane QoS control mechanisms.<br\/> End-to-end QoS controls for responsive flows: The researchers will develop fluid models to study the impact of ag-gregate QoS control mechanisms on the end-to-end performance of responsive flows. A responsive flow responds to signs of network congestion, such as loss, by adapting its transmission rate. These models will enable us to develop a better understanding of the behavior of responsive flows such as<br\/>TCP coupled with different aggregate QoS mechanisms and to design end-to-end QoS services for responsive flows.<br\/> QoS control laws and control plane aggregation rules. The researchers will develop QoS control laws for capturing the slow time-scale, system-wide behavior of a network and aggregation rules that address the perfor-mance and complexity of control plane operations under aggregate QoS controls. These QoS control laws and aggregation rules will lead us to the design of distributed and centralized algorithms for scalable control plane operations.<br\/> Scalable QoS mechanisms and service architectures As an integral part in developing these theories, the researchers will also design effective and scalable QoS mechanisms, and tools and techniques for quantifying and evaluating the trade-offs of various QoS solutions. Based on the results from these efforts, the researchers will study how various QoS solutions can be combined to construct meaningful end-to-end services.<br\/> The research will blend formal modeling\/analysis, experimentation\/implementation, and evaluation. The<br\/>understanding and insights gained as a result of our research will lead to the establishment of the theory,<br\/>design principles, and guidelines for building scalable QoS controls for the future Internet. This, in turn,<br\/>will allow reasoned and informed choices to be made as the next generation Internet takes shape.","title":"ITR: Collaborative Research: Scalable QoS Control for the next Generation Internet","awardID":"0085930","effectiveDate":"2000-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["564485"],"PO":["7594"]},"55679":{"abstract":"Successful life forms in nature adapt to changes in the environment in ways that improve the efficiency of their activities or enhance their chances for survival. In the context of computer software, opportunities for adaptation arise from changes in the computational needs of an application as it executes, changes in availability of resources, failure of hardware, etc. However, most software today does not adapt to such changes, so its efficiency and survivability may be far from optimal. This project will develop general principles for building software systems that can adapt to such changes, and will demonstrate the validity of those principles by building prototype applications.<br\/><br\/>Progress in this area can only by made by focusing on a particular application domain that requires adaptive software, and assembling a team of applications researchers and computer scientists to tackle the problems in that domain at all levels. This project brings together a strong interdisciplinary team to focus on Computational Field Simulation (CFS). In particular, it will focus on computational fracture mechanics and reactive, multiphase fluid flows, both of which have an enormous number of opportunities for adaptive methods. These adaptations can be classified into three distinct categories.<br\/>Application-level adaptivity. A variety of mathematical models may be available to describe the science of a problem, and it may be advantageous to switch adaptively between them to trade accuracy for time or other resources.<br\/>Algorithm-level adaptivity. There are often multiple algorithms for solving a given model (e.g. direct or iterative methods for solving linear equations), and it may be advantageous to switch adaptively between them to manage resource availability or properties of the desired output.<br\/>System-level adaptivity. The computational environment may change (e.g. more processors may become available or some communications links may fail), and the computation must adapt to these changes or risk crashing or taking significantly more time than necessary.<br\/>This project argues that a general architecture designed to exploit these opportunities must have a set of interoperable components on a software bus, hardware\/software sensors for monitoring stimuli, and control modules for orchestrating the components in response to the stimuli. It will undertake algorithmic research in each of the component areas, and will synthesize complete adaptive codes from the components using ideas similar to those in hardware synthesis. Adaptivity will be exploited at all levels in the resulting software. The project finally hopes to abstract a general theory of adaptive software systems from its experience in building such systems for field-driven simulations.","title":"ITR: Adaptive Software for Field-driven Simulations","awardID":"0085969","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"5979","name":"CENTRAL & EASTERN EUROPE PROGR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["439586","556730","260339","211338","362246"],"PO":["564388"]},"48815":{"abstract":"As real-time computer application systems become larger and more complex, it is becoming imperative that such applications be implemented on multi-processor platforms rather than on uniprocessor ones. Furthermore it is often the case that the implementation platforms are not completely homogeneous, but are comprised of several different kinds of processors and other resources. This project will different kinds of processors and other resources. This project will study both the fundamental scheduling-theoretic questions, and the pragmatic implementation issues, that arise when periodic task systems are to be implemented on such heterogeneous multi-resource platforms. This research will build upon previous research, performed by both investigators, on fair scheduling in real-time system. The theoretical findings resulting from this research will be validated by applying them to some implementation projects currently under development at the University of North Carolina.","title":"Real-time Scheduling on Heterogeneous Multiprocessors","awardID":"9988327","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["31436","518412"],"PO":["309350"]},"48936":{"abstract":"The goal of this research project is to make it possible to process approximate queries on combinatorial structures such as trees and graphs in a fast (i.e., sublinear with respect to the number of objects being searched) and efficient manner. The ultimate goal is to be as fast as approximate keyword search in text documents. The approach consists of: (1) discovering the best heuristics for answering these NP-complete problems in polynomial time with high quality, and (2) discovering data structures to make queries on thousands or millions of such objects fast. The results of this project will provide techniques and software to search for patterns among graph and tree structured data. Possible applications of such a search engine include searches among proteins, chemical compounds, neuroanatomical structures, Web\/text filters and XML documents. The techniques developed in this research are in particular suitable for bioinformatics and biocomputing applications. Professors Shasha and Wang plan to collaborate with five additional researchers in these areas: Jack Collins, National Cancer Institute working in small molecule-protein docking for drug design; Michael Donohue, Professor of Biology and Director of the Harvard University Herbaria planning to apply this research to phylogenic trees; Bruce Shapiro, National Cancer Institute developing algorithms and computational systems for determining structure\/function of nucleic acids; Cathy Wu, National Biomedical Research Foundation doing research in analysis and classification of protein sequences; and Daniel Zaharevitz, National Cancer Institute whose goal is to make biological and structural data more available to the research community via better search capabilities. These collaborators help to motivate and validate the tree and graph matching tools and algorithms development for biological applications.<br\/>http:\/\/www.cis.njit.edu\/~jason\/sigmod.html","title":"Collaborative Research: ASES: An Approximate Search Engine for Structure","awardID":"9988636","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["335170"],"PO":["563751"]},"48859":{"abstract":"The next generation of computing will be dominated by applications which fall between the existing categories \"real-time\" and \"general purpose\". These \"real-rate\" applications have performance contraints, such as throughput, smoothness, and bounded latency that are looser than real-time but stricter than general purpose applications. This project will further the state-of-the-art in resource management for real-rate applications, aiming to provide more predictable, accurate, and dynamic resource allocation. In particular, it will develop mechanisms and policies that can manage resources accurately for variable rate, high performance applications such as video streaming, sensor networks, or routers. It will also develop modeling and analysis techniques based on control theory that support reasoning about the dynamic behavior of applications and computer systems. Activities included in the project include: evaluating control algorithms for suitability for different application classes, inventing implementation techniques for building low overhead highly accurate controllers, developing techniques to analyze complex systems composed of multiple adaptive applications and resource managers, and defining notions such as quality-of-service or correctness that incorporate dynamics.","title":"Collaborative Research: Progress-Based Resource Management Using Control","awardID":"9988440","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["341681","246370",125068],"PO":["241298"]},"50301":{"abstract":"This proposal is for research into hard open questions concerning the power of various complexity classes. The work will focus on two types of questions. The first deals with showing that certain famous problems are not \"too easy\". For example, while it is widely believed that SAT requires exponential time, we cannot even prove that there is no linear time Turing Machine for SAT. Our first work will focus on trying to prove modest lower bounds on problems such as SAT.<br\/><br\/> Second we will also investigate harder questions and attempt to find ways to separate complexity classes. These are, of course, very difficult problems but we have a \"new\" approach that seems promising. In any event we should be able to get some conditional results that will at least add additional evidence to our belief that certain classes are distinct.<br\/><br\/> A word in general about this research. We feel that it is in some sense \"high\" risk in that the problems are quite hard. However, we feel that unless people work seriously on them they will never be solved. Also we believe that our approaches have enough of a new slant that they may at least partially succeed.","title":"Research Into Foundations of Computational Complexity","awardID":"0002299","effectiveDate":"2000-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["400310"],"PO":["543507"]},"52611":{"abstract":"Non-Technical Abstract<br\/><br\/>This research focuses on new mathematical algorithms for improved synchronization and detection of direct-sequence code-division multiple access (DS-CDMA) signals. In DS-CDMA applications such as cellular telephony, multiple signals from user handsets are received simultaneously at a base <br\/>station. In order to accommodate the maximum number of users, the times-of-arrival (delays) and channel distortions of all received signals must be simultaneously tracked. In this project, the channel\/delay parameters are tracked using a modified extended Kalman filtering (EKF) algorithm.<br\/>More sophisticated EKF algorithms are also evaluated that perform forward error correction decoding (Turbo-CDMA) jointly with channel\/delay estimation. The resulting algorithms provide <br\/>reduced symbol error rates and hence increased system capacity. The results of the research are applicable to a broad range of DS-CDMA systems, including third-generation mobile telephony, wireless local-area networks, and ad-hoc networks.","title":"Tracking Mode Receivers for Asynchronous DS-CDMA","awardID":"0073214","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["355335"],"PO":["223414"]},"52501":{"abstract":"Abstract<br\/><br\/>This project involves interdisciplinary research in which algorithmic<br\/>approaches are developed to design and analyze adaptive experiments. An<br\/>adaptive (sequential) design is one whose characteristics change in<br\/>accordance with information arising from the ongoing experiment, as <br\/>opposed to classical statistical designs where such characteristics are<br\/>set in advance and remain fixed throughout. Adaptive designs have a wide<br\/>range of application in clinical trials, destructive testing, behavioral<br\/>ecology, computer performance prediction, adaptive control, etc., where<br\/>they have the potential to reduce the expenditure of experimental <br\/>``resources'' such as time, money, or quality of life. Unfortunately,<br\/>adaptive designs are difficult to analyze and optimize. Exact analytic<br\/>solutions are rarely available, and thus, historically, such designs have<br\/>been predominantly approached via asymptotic methods and ad hoc<br\/>approximations. Computationally, adaptive designs require significant<br\/>time and space that has often made exact calculations infeasible.<br\/><br\/>This project will expand the size and scope of solvable problems by<br\/>developing new computational approaches for creating and evaluating<br\/>designs and utilizing state of the art computational facilities.<br\/>Attention is directed to problems that are important in applications,<br\/>with a major emphasis on supplying researchers greater flexibility in<br\/>modeling their statistical and cost objectives. For many of these<br\/>problems, exact optimality will be unattainable, and thus techniques for<br\/>producing near-optimal designs will also be pursued. Several of these<br\/>techniques are based on optimizing smaller or simpler problems and<br\/>extrapolating their solution structure to larger or more complex<br\/>problems. This compliments analytical, asymptotic work and provides new<br\/>insights into the structure of solutions. In other cases, a shift from<br\/>serial algorithms to parallel ones will be used to address the<br\/>additional complexity.","title":"Computationally Aggressive Approaches to Adaptive Design","awardID":"0072910","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1269","name":"STATISTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}}],"PIcoPI":["456329",133899],"PO":["544672"]},"53953":{"abstract":"EIA-0078826<br\/>Koplik, Joel<br\/>CUNY City College<br\/><br\/>MRI: Parallel Computer Equipment for the Levich Institute of CCNY<br\/><br\/>The faculty of the Levich Institute of the City College of New York requests funding for the purchase of a medium-scale parallel computer system for research in fluid mechanics. The equipment will support research activities in (1) shear-induced diffusion in suspensions, (2) polymer blends and instabilities, (3) complex multiphase flows, (4) molecular fluid mechanics and (5) interfacial and surfactant dynamics. In addition, the proposed system will be invaluable for broad educational purposes: developing the conceptual familiarity, hands-on experience, and hardware infrastructure required thinking and working computationally in parallel terms","title":"MRI: Parallel Computer Equipment for the Levich Institute of CCNY","awardID":"0078826","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["380326","539762","315673","308372","199459"],"PO":["557609"]},"54811":{"abstract":"Abstract<br\/><br\/>The objective is to improve the reliability of software produced by<br\/>end-user programming languages in general, and by spreadsheet<br\/>languages in particular. The approach is to address software<br\/>engineering issues as an integrated whole in ways that incrementally<br\/>interact with each other and with the user. For example, the system<br\/>will notice the user's reactions to sample values she tests, and will<br\/>then suggest general principles about the spreadsheet, encouraging the<br\/>user to refine or modify the suggestions. This collaboration between<br\/>the system and user will incrementally generate formal specifications<br\/>as the spreadsheet evolves. These specifications can in turn be fed<br\/>back to enhance reliability -- by automatically suggesting appropriate<br\/>test values, by helping locate faults, and by ensuring continuing<br\/>consistency with the specifications. The research involves three<br\/>facets: developing an interactive mechanism for user-system<br\/>collaboration, developing algorithms for the system's part of the<br\/>collaboration, and conducting experiments to evaluate effectiveness.<br\/>This is the first research attempting to bring fundamental software<br\/>engineering principles to bear on end-user programming. Since the use<br\/>of end-user-written programs and spreadsheets is very widespread and<br\/>their lack of reliability is pervasive, improved reliability will<br\/>impact a potentially huge number of business and personal computer<br\/>users.","title":"ITR: End-User Software Engineering","awardID":"0082265","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[140046,"548135","548132"],"PO":["564388"]},"54932":{"abstract":"This is the first year funding of a three-year continuing award. Hybrid user interfaces combine together multiple displays and interaction devices to benefit from the advantages of each. For example, a hybrid user interface could be constructed in which multiple users view one or more common displays, such as a wall-mounted data visualization and a desk-top virtual workbench 3D model. At the same time, each user might see complementary private material, customized to her own information needs, and overlaid on and registered with the common displays---an augmented reality that is presented on personal, tracked, hand-held or head-worn see-through displays.This project addresses environment management, the task of managing large numbers of virtual objects on large numbers of displays in hybrid user interfaces. More complex than the tasks involved in current window management, environment management will be especially challenging if it is to address the needs of future mobile, collaborating users, whose proximity to other users, displays, and interaction devices may change rapidly and unpredictably as users move about. This work explores an alternative to direct manipulation approaches, in which knowledge-based environment management tools take over many low-level tasks to avoid overwhelming the user. The goal is to increase a user's effectiveness by making it possible for her to exert higher-level control over the layout and contents of her personal and shared work environment. This project will develop the underlying concepts for hybrid user interfaces and effective environment management facilities, and will design, demonstrate, and test research prototypes that embody these concepts. Special emphasis is placed on issues raised by collaborative, 3D augmented environments that exploit a wide range of displays (held, worn, and stationary), including head-tracked see-through displays that create augmented realities, in which virtual objects coexist in the same surrounding space as users and other physical objects. User interface design approaches that can promote shorter task performance time, lower error rate, or greater user satisfaction, will be vital for improving our ability to interact with information and with each other in the nontraditional world of collaborative mobile computing.","title":"ITR: Environment Management for Hybrid User Interfaces","awardID":"0082961","effectiveDate":"2000-09-01","expirationDate":"2003-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["530199"],"PO":["565227"]},"54701":{"abstract":"Particular protocols and mechanisms (e.g., \"cookies,\" \"finger\" commands, the design of message headers), as embedded in commonly used information technologies such as the Internet, have the ability to affect experiences in online environments and to regulate behavior. A series of historical case studies will be conducted to understand how the use of these mechanisms can have social consequences. These case studies will encompass the historical development of the Internet as well as the ways in which social values such as free speech, privacy, and intellectual property rights have intersected these developments. Documentary methods and qualitative interviews will be used. The results of these case studies will allow a better understanding of the processes that build norms, customs, and consensus in online environments. Further, this research will aid in the development of theoretical models to assist policy makers in understanding how sensitivity to the design of IT (and its various mechanisms, protocols, etc.) may be an alternative to formulating new laws and regulations to achieve positive social outcomes from new information technologies. Finally, this research addresses the relationship between the commercialization and privatization of the Internet and our established constitutional and social values.","title":"ITR: Understanding \"Code\": How Information Technologies Regulate Behavior","awardID":"0081426","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["542485"],"PO":["495796"]},"54943":{"abstract":"PROJECT SUMMARY<br\/>The channel fading and co-channel interference present in a wireless radio propagation channel presents a harsh challenge to the radio design engineer. Diversity techniques commonly used to combat the channel include the use of interleaved coded modulation and multiple antennas at the receiver end. Lately there has been a great deal of interest in the use of multiple antennas at the transmitter end, i.e., in using transmit diversity. Researchers have shown that the capacity of multi-antenna systems significantly exceeds that of conventional single-antenna systems. Space-time codes attempt to realize the potential increase in capacity by distributing code symbols intelligently in space (across the different transmit antennas) and time. This topic has received a great deal of attention since the BLAST space-time system was proposed and demonstrated at Bell Labs. This is because, owing to the additional dimensionality obtain by exploiting space, a spectral efficiency of 40 bits per sec per Hz at realistic signal to noise ratios was demonstrated (i.e., 20 times the spectral efficiency achieved in current cellular systems). The importance of space-time methods in communication and information theory was recently recognized by the selection of the work by Tarokh, Seshadri and Calderbank for the 1999 IEEE Information Theory Paper Prize. The great majority of space-time coding research has been based on the following assumptions:<br\/><br\/>Single-user link or time-division multiplexed<br\/><br\/>Complex Gaussian channel gains (frequency at fading) from each transmit (Tx) antenna to each receive (Rx) antenna.<br\/><br\/>Independent channels for each Tx-Rx antenna pair.<br\/><br\/>Equal average energy in each Tx-Rx antenna channel.<br\/><br\/>Time non-selective channels (quasi-static assumption)<br\/><br\/>Based on these assumptions, effective design rules have been established by considering the probability of pairwise codeword error. These design rules aim to maximize the diversity and coding gains. The assumptions described above best represent a system with a dense, rich scattering environment sur-rounding the Tx and Rx antenna arrays and stationary or slowly moving receivers. This model is applicable, for example, to an indoor office environment. It may also be accurate for a pedestrian cellular user in a dense urban environment, depending on the base-station antenna location. However, space-time channel measurements and models suggest that in many cases of practical interest, the above assumption of independence of channel gains is not accurate. The lack of like-signal interference may also not be applicable to code-division multiple access (CDMA)<br\/>systems since a well-utilized CDMA system is limited by such interference. Virtually all third-generation mobile radio standards are based on CDMA systems as are the most effective wireless LAN systems. In a CDMA system, the effects of signature sequence design must also be considered together with coding and<br\/>modulation.<br\/>In this project, we have developed an expression for the pairwise error probability for a system model that is broadly applicable. Our model includes arbitrary correlation between Tx-Rx antenna channels, multiple CDMA users, and the potential for time variations in the channel gains. Based on this model we propose to develop design rules for space-time spreading and coding for CDMA systems. Our goal is to develop rules that are applicable to a variety of applications (i.e., mobile users and dense scattering, or fixed-point systems<br\/>out of the scatter) and\/or which are robust to uncertainties in the channel model.<br\/>We propose to generalize the methods of space-time coding so that the approach may be used in CDMA systems and\/or systems without rich scattering environments. Research directions include rules for spacetime spreading and code design, investigation of receiver structures and channel estimation\/tracking, code design for simplified decoding and modified design rules for non-Euclidean distance receivers. This study will be conducted under different channel model assumptions and presumed knowledge at the receiver and transmitter of channel knowledge.","title":"ITR: Space-Time Spreading and Coding","awardID":"0082987","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["562301","257944"],"PO":["223414"]},"51797":{"abstract":"With the advent of third and fourth generation wireless infrastructure, and the simultaneous emergency of pervasive connectivity for all devices based on bluetooth like systems and ad-hoc networks, a new vista is open for research in the area. We propose ideas for a research program aimed at realizing ubiquitous computing systems based on the cooperation of autonomous, dynamic and adaptive components (hardware as well as software) which are located in vicinity of one another. These systems will be composed of a collection of independently designed components that automatically become aware of each other, establish basic (wireless) communication, exchange information about their capabilities and requirements, discover and exchange APIs, and learn to cooperate effectively to accomplish their individual and collective goals. The proposed work will enable a new class of applications that effectively use mobility and pervasive computing. We address several research problems that span the fields of distributed computing, data management, and dynamic collaboration between components. The team of researchers is located at UMBC and UI-Chicago, and plans to interact closely with collaborators at industrial labs (IBM, Hughes, Sun).","title":"Dynamic Negotiation Agents in Mobile Computing","awardID":"0070802","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["563576","558176","533183"],"PO":["309350"]},"54712":{"abstract":"The need to improve congestion control techniques for the Internet has grown recently. Non real-time data traffic, which is currently transported on a \"best effort\" basis, will increasingly have more stringent delay and throughput requirements to meet critical scientific, corporate and e-commerce applications. In order to meet this enhanced quality of service requirement, the existing feedback congestion control scheme incorporated in the Transmission Control Protocol (TCP) needs to be understood. For this purpose, the PIs intend to:<br\/><br\/>1) Build an analytical model that can incorporate key features of TCP Reno and TCP enhancements under consideration by the IETF. The model the PIs present here is interesting in that it can accommodate multiple TCP flows and possibly multiple network nodes.<br\/><br\/>2) Place TCP in a control-theoretic framework so that its stability and transient behavior is well understood. The use of non-linear control techniques proposed here is novel, and should make available a new set of mathematical tools to study this problem.<br\/><br\/>3) The synthesis of these two activities will in turn suggest methods that ensure that any proposed TCP successor is stable, as well as improving throughput and fairness. A more limited goal but with perhaps more immediate impact is a better understanding of the stability and performance of TCP Reno.<br\/><br\/>All of this work will be performed within the complementary congestion control efforts underway such as traffic engineering using the Multiprotocol Label Switching (MPLS) protocol, traffic shaping and policing, service scheduling and buffer management.<br\/><br\/>In addition to a survey of the state of the art, the PIs present some preliminary results and ideas for future research. The PIs demonstrate an analytical model of TCP Reno for the single node case, and some of the insights that even such a simple model provides. The PIs also present a way of extending recent control theoretic work in flow control to a more realistic and general context, where boundary effects and unknown, time-varying propagation delays appear in networks. Lyapunov theory, the theory of functional (retarded) differential equations and constructive design methods in modern nonlinear control will play a key role in the synthesis of new feedback congestion control schemes for the Internet.<br\/><br\/>The broader impacts of this research include the development of closer interaction between the control theory and networks research communities, curriculum enhancement at the graduate and undergraduate levels, applying some of the practical implications of this work through ongoing industry interactions, and inputs to IETF groups.","title":"ITR: Design and Analysis of End-to-End Feedback Congestion Control Schemes","awardID":"0081527","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["525973","522718"],"PO":["250082"]},"54833":{"abstract":"Storage systems have evolved from small disk systems under control of a file server to large, independent disk and disk-array systems that can be directly accessed by applications. It is becoming increasingly difficult for system administrators to manage these complex storage systems manually. This work addresses this problem by proposing to develop smart storage systems that perform complex tasks like configuration, capacity planning, fault management, and load balancing in addition to routine tasks like data storage and retrieval and data backups. The automated storage system adapts to changes in the workload and system configuration without human intervention. The storage management software uses device and workload models to compute the optimum data-to-device mapping. These models are embedded inside the storage management software that is developed using constraint satisfaction programming techniques. The main contribution of the proposed work is the development of workload-aware and system-aware storage techniques that significantly improve system performance and ease storage data management.","title":"ITR: Data Management Using Smart Storage Systems","awardID":"0082399","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["148166"],"PO":["469867"]},"54954":{"abstract":"This project will develop a multiresolution numerical methodology for solving the partial differential equations of fluid dynamics on the sphere, and apply it to practical atmospheric-flow simulations. Its starting point is the spectral-element method (SEM), which retains the spectral accuracy of spherical-harmonic transform methods, without the latter's problems near the poles. Observing that the spatial discretization via SEM and via multiwavelets (on the finest scale) are the same, the researchers will develop an adaptive multiresolution multiwavelet solver, and test it using standard atmospheric simulation benchmarks.<br\/><br\/>Although it is well understood that atmospheric phenomena involve strong multiscale interactions, today there are no adaptive multiresolution solvers. The necessary mathematical tools that take the multiscale nature of the problem into account have appeared only recently, and form the foundation for this research. The success of this project will have a significant impact on both the speed and the accuracy of atmospheric simulations and weather prediction.","title":"ITR: Collaborative Research on Multiresolution Adaptive Spectral Element Solvers for Atmospheric Fluid Dynamics","awardID":"0083048","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["193664"],"PO":["551992"]},"54965":{"abstract":"The objective of this project is to develop the design methodology, software tools and programming environment for the automated synthesis of Mission-specific Processors (MSPs) based on the Morphosys architecture developed at UC, Irvine. Because their hardware design is not tailored to the application(s), generic embedded processor architectures make inefficient use of area and power. ASICs on the other hand cannot be updated to accommodate different algorithm improvements. By allowing a set of target applications to dictate the architecture, MSP designs incorporate the necessary components and interconnections to optimize the performance of a specific suite of programs. The synthesized architecture is dynamically reconfigurable and supports a retargetable compiler to incorporate algorithm enhancements or changing task specifications. The proposed approach relies on the compilation of a program expressed in a high-level algorithmic language into a data-flow graph (DFG) format and from that format into VHDL. This technology has been developed as part of the Cameron Project at Colorado State University. A new MSP design framework will be developed to incorporate constraint-based MSP synthesis and estimation as well as compilation support for the synthesized architecture.","title":"ITR: Synthesis of Adaptive Mission-Specific Processors","awardID":"0083080","effectiveDate":"2000-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["518640","444397","472357"],"PO":["562984"]},"55702":{"abstract":"Visualization of Multi-valued Scientific Data: Applying Ideas from Art and Perceptual Psychology<br\/><br\/>This is a multi-disciplinary research project to discover new visualization tools for interacting with and understanding multi-valued volumes of scientific data and the physical phenomena they measure. The tools will be developed and evaluated in close collaboration with scientists in three disciplines: neurobiologists studying neural development and disease via biological imaging, computational flow researchers studying blood flow through arteries, and geographers using remote sensing for environmental monitoring and resource management. We will factor out common patterns from the problems in these multiple disciplines to develop interaction metaphors and visualization techniques that are generalizable and widely applicable.<br\/><br\/>This project develops new visualization evaluation methodologies, an area that has only begun to be addressed. And it compares the effectiveness of visualization applications in several interactive and static computing and display environments including a 4-wall Cave, a 40'x40' virtual environment with a head mounted display, stereo head-tracked workbenches, desktop workstations, paper, and 3D rapid-prototyping output. Immersive environments will be studied<br\/>because the value of these non-traditional working environments has not been established and because they present an opportunity to explore fundamentally different interaction metaphors. Comparisons will be performed for both interactive and static cases with appropriate technology determined for each application.<br\/><br\/>This project brings together experience from art and perceptual psychology for inspiration. Through several centuries, artists have evolved a tradition of techniques to create visual representations for particular communication goals. Art history provides a language for understanding that knowledge. We will draw inspiration from painting, sculpture, drawing, and graphic design and apply these techniques to the scientific problems.<br\/><br\/>Beyond inspiration, perceptual psychology also brings a second set of knowledge to bear on scientific visualization problems. Evaluating the effectiveness of visualization methods is difficult because, not only are the goals difficult to define and codify, tests that evaluate them meaningfully are difficult to design and execute. These evaluations are akin to evaluating how the human perceptual system works. Perceptual psychologists have been developing experiments for understanding perception for decades, and they will help develop methodology and expertise for evaluating visualization methods in close collaboration with biologists, fluids researchers, geographers, artists, and computer scientists.<br\/><br\/>While many of the individual components of this project are important alone, the collaborative aspects are the most notable. Mining ideas from art and perception will suggest unusually innovative visualization ideas. The application of new visualization techniques and collaboration with researchers in other fields will provide us with a unique opportunity to validate the techniques and ensure that they are responsive to the needs of the scientific problems. Because the techniques will be developed with application to multiple disciplines, they are likely to find further application within these and other disciplines. The assembled team brings strengths in all of the disciplines and has already demonstrated a track record of collaborative work.<br\/><br\/>The broader impact of the proposed research lies not only in the information technology arena, where new methods will help scientists in many disciplines to more effectively interact with and understand their data and gain insight about the physical phenomena they represent, but also in the specific scientific domains we will study. The study of blood flow could lead to improved understanding of and treatment for cardiovascular pathologies. An understanding of early neural development could enable new therapies for birth defects, genetic disorders, and other diseases. Remote sensing advances could provide more effective resource monitoring and permit widespread improvements in global quality of life.","title":"ITR: Visualization of Multi-valued Scientific Data: Applying Ideas from Art and Perceptual Psychology","awardID":"0086065","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["517149","517413","550484"],"PO":["532791"]},"54976":{"abstract":"PROPOSAL NUMBER: CCR-0083099<br\/>INSTITUTION: Univ of Ca - Irvine<br\/>PI: Debra Richardson and David Redmiles<br\/>TITLE: ITR: Quality Software by Design<br\/><br\/>ABSTRACT<br\/>Quality has always been a concern with respect to software. Yet now, with such great reliance on software in every aspect of our lives, there is even greater need to address quality in software development. High quality software means software whose specifications meet customers' requirements and whose implementations meet specifications. The focus of this proposal is helping software developers design quality into their systems, which is far more cost-effective than relying solely on post-implementation quality evaluation and corrective maintenance. In particular, the proposed research encompasses a plan for combining for the first time (1) formal architecture and component design models, (2) analysis and testing techniques based on these formalisms, together with (3) cognitive-based, design environments for critiquing software design. The proposed research explores innovative user interface approaches to delivering critical design-related quality assessment information to software developers as they interactively develop designs. The information to be delivered is based on design heuristics, formal analysis and testing, and usage data and feedback. Information is to be delivered in a manner consistent with research in human cognition. Finally, to ensure that this research has the potential to impact real work, the formal architecture and component design models leverage and extend industry standards.","title":"ITR: Quality Software by Design","awardID":"0083099","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["483634","272419"],"PO":["564388"]},"51346":{"abstract":"","title":"Geometric Problems in Graphics, Databases and Networking","awardID":"0049093","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["536698"],"PO":["321058"]},"54866":{"abstract":"During remote collaboration, partners have access to much less information than during face-to-face collaboration. This project uses psychological experiments to examine how knowing where a partner is looking affects performance and strategies on collaborative tasks. Phase 1 asks: When partners are physically co-present, how aware are they of where the other is attending, and how do they achieve shared attention? Phase II applies these basic results to remote collaborations; partners wear eye-trackers that transmit gaze information to each other's computer displays. A space of tasks and representations is explored: Tasks are varied in systematic ways (e.g., some lend themselves to parallel activity, while others require consensus for each step), and different representations of the same gaze information are compared. The goal is to understand which representations work best for which tasks. With technological advances making eyetracking easier, less cumbersome, and more affordable, a gaze-based computer interface may someday join the ranks of ubiquitous input devices like the mouse. If this technology is to be integrated into the \"every citizen interface,\" it is necessary to understand how people use the information in gaze to achieve a joint focus of attention. This could provide the foundations for new technology for computer-mediated collaboration.","title":"ITR: Contributions of Eye Movements and Shared Attention to Collaborative Tasks","awardID":"0082602","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["483394","362801","508252"],"PO":["495796"]},"55724":{"abstract":"Two major goals are:<br\/>(1) To establish a new-generation integrated methodology for real- time (RT) distributed programming and software engineering on the basis of the recent developments in object-oriented (OO) RT<br\/> distributed programming; and <br\/>(2) To develop an integrated tool-set named the Real-time Object Network Engineering Environment (RONEE), which will bring about a quantum jump in the system engineers' productivity in<br\/> constructing distributed RT application systems.<br\/><br\/>The research base of this multi-nation researcher team includes (1) a new high-level style of RT OO distributed programming called the TMO (Time-triggered Message-triggered Object) programming, (2)<br\/>middleware supporting RT objects such as TAO object request broker and TMOSM, (3) OS and middleware support for fault-tolerant RT distributed computing such as ROAFTS and TTP OS, (4) frameworks<br\/>such as RT UML and ACSR for formal specification, etc.<br\/><br\/>Specific research tasks include integrations of cornerstone<br\/>techniques and development of RONEE for:<br\/>(1) High-level distributed RT programming based on C++ and JAVA;<br\/>(2) Formal multi-level specification of requirements and designs;<br\/>(3) Efficient execution of RT objects, stationary and mobile;<br\/>(4) Fault-tolerant computing with distributed RT objects;<br\/>(5) Verification of timing designs;<br\/>(6) Distributed RT simulation and 3D visualization of application<br\/>environments to support software validation.","title":"ITR: RONEE - An Integrated Engineering Method and Tool Environment for Reliable Object-oriented Real-time Distributed Systems","awardID":"0086147","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["217949","296371","534923",142891],"PO":["223414"]},"54877":{"abstract":"The goal of this research is to reduce the cost and improve the<br\/>performance of observation-based branch characterization mechanisms in<br\/>the compiler and hardware. Often, correlation discovered at great cost<br\/>or missed entirely through execution can be determined in a simple<br\/>algebraic fashion at compile time. Relationships between program<br\/>structures can be inferred from these algebraic expressions and<br\/>subsequently conveyed to compiler optimizations and to the hardware<br\/>through appropriate mechanisms to be developed by this research. Once<br\/>employed, these relationships can refocus the efforts expended by<br\/>observation-based mechanisms, or can eliminate the need for them<br\/>altogether.","title":"ITR: Collaborative Research--Ascertaining Runtime Branch Characteristics through Algebraic Analysis of Programs","awardID":"0082671","effectiveDate":"2000-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["489873"],"PO":["551992"]},"55614":{"abstract":"A necessary step towards the goal of building more reliable software systems, on time and within budget, is to establish an institutionalized empirical discipline for understanding causal relationships among the processes, components, and technologies that affect the building of systems. As in the physical and natural sciences, experimentation in software engineering requires a community with support for collaboration, experimental replication and refinement, and sharing of experimental data and results.<br\/>For these reasons the Center for Empirical Software Engineering Research (CESER) undertakes original empirical research and is developing a prototype system for sharing and evolving the results of such research with a community of affiliated researchers and practitioners. CESER develops and refines techniques to increase the descriptive and predictive power of empirical models, and studies specific software development technologies to enable industrial organizations to understand the benefits and drawbacks of those technologies in their specific context. The Center provides courses and symposia on empirical methodologies and results, and assists the use of empirical knowledge in software engineering education. The Center's initial focus is on empirical studies of software COTS integration and software quality improvement phenomenology.<br\/>The center is initially organized as a collaborative effort among the University of Maryland, the Fraunhofer Center - Maryland, the University of Southern California, the University of Nebraska at Lincoln, and Mississippi State University.","title":"ITR: Collaborative Research Proposal for a National Center for Empirical Software Engineering Research","awardID":"0085749","effectiveDate":"2000-09-15","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["528453"],"PO":["564388"]},"54767":{"abstract":"At present, access to the information in large-scale text collections is largely limited to keyword-based searches which retrieve entire documents or passages. While such tools are often satisfactory in retrieving information on general topics, they provide little support for accessing information involving specific relationships, events, or facts.<br\/><br\/>Information extraction technology offers the possibility of creating structured, tabular representations of selected relations from large text collections --- representations which can support more detailed document querying. Until now, however, developing extraction systems for a broad range of relations has been too expensive and time-consuming to consider its use in this way. Recent developments in extraction system customization offer the promise of substantially easing this task, and so making this approach to document indexing feasible.<br\/><br\/>This research project will: 1) use corpus-based techniques to automatically identify the most common relationships within a sublanguage (the set of texts concerning a particular subject matter), and the different ways in which these relations are expressed in the text; 2)construct systems to extract information about these relationships from new text, building tabular summaries; and 3) provide a user interface for querying these relationships and accessing the underlying documents. Taken together, these tools should offer significant new capabilities for accessing the information in large text collections.","title":"ITR: Automated Structuring of Text Information","awardID":"0081962","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["226113","226114"],"PO":["563751"]},"54888":{"abstract":"Project Summary<br\/>Environmental observation and forecasting systems (EOFS) are emerging new technologies with unparalleled<br\/>potential to impact sustainable development. EOFS are expected to foster and support new paradigms for<br\/>generation, transfer and social application of knowledge in domains that range from the global earth to its<br\/>regional and local sub-systems.<br\/>At the core of EOFS is the timely and customized acquisition, generation, processing and delivery of reliable,<br\/>relevant information to many and very diverse audiences. Multiple challenges need to be met to implement<br\/>this concept.<br\/>A critical challenge is the development of automated procedures to verify the quality of the huge amounts<br\/>of observational and simulation data that are generated by EOFS both in real-time and off-line. Process-<br\/>based strategies for quality control of scientific data, while effective for moderate-size archival data are too<br\/>labor-intensive to map well into EOFS-scale data sets. Strategies based on pattern recognition and machine<br\/>learning hold significant promise as an alternative or complement.<br\/>Under the proposed project, we will develop approaches based in statistical pattern recognition and signal<br\/>processing, on-line adaptive systems, datamining, and advanced search to address critical quality control<br\/>issues including: 1) Detecting sensor corruption in non-stationary, spatial-temporal systems, 2) Estimating<br\/>true signals from corrupted sensor data, and 3) Detecting and characterizing regimes where model anomalies<br\/>are likely.<br\/>These quality control techniques will be developed and exercised on CORIE, a pilot EOFS for the COlumbia<br\/>RIver Estuary and adjacent coastal waters (http:\/\/www.ccalmr.ogi.edu\/CORIE)<br\/>The project will have strong social impact, through the role of EOFS (and, specifically, CORIE) on regional<br\/>and national sustainable development issues. The project will also include cross-disciplinary educational<br\/>opportunities at multiple levels.","title":"ITR: Statistical Pattern Recognition in Environmental Observation and Forecasting Systems","awardID":"0082736","effectiveDate":"2000-09-01","expirationDate":"2003-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["459571","562760"],"PO":["564898"]},"54899":{"abstract":"EIA-0082791<br\/>Gottschalk, Thomas<br\/>California Institute of Technology<br\/><br\/>ITR: A Distributed Simulation Infrastructure for a K-12 Inquiry Environment<br\/><br\/>This research involves planning the construction of a scaleable,<br\/>persistent, interactive event simulation framework for supporting<br\/>knowledge-building curricula within K-12 education. The proposed system<br\/>uses advanced simulation and information technology methods to create an<br\/>inquiry environment, fostering cooperative interactions and knowledge<br\/>co-creation while students work together to solve curriculum-based problems<br\/>and challenges. The technical basis of such an inquiry environment is a<br\/>metacomputing system combining distributed discrete event simulations,<br\/>information and operational databases, graphical control interfaces, and<br\/>visualization. While much of the system can be built from familiar pieces,<br\/>the focus on education provides a number of interesting opportunities for<br\/>new research in computing and metacomputing strategies.<br\/><br\/>The general area of user-directed simulations is viewed as a particular<br\/>area in which High Performance Computing (HPC) can become a true enabling<br\/>technology for substantive educational reform. The proposed work will plan<br\/>the exploration, development, and extension of HPC technologies for K-12<br\/>education. This work relies on strong partnerships in cognitive science<br\/>and education to ensure that the technology features and capabilities are<br\/>matched to objectives within progressive models of knowledge and learning.<br\/>The K-12 simulation framework that could result from this work may be<br\/>regarded as a first step in the larger task of matching HPC capabilities to<br\/>contemporary cognitive science and educational research, enabling<br\/>substantive advances in learning.","title":"ITR: A Distributed Simulation Infrastructure for a K-12 Inquiry Environment","awardID":"0082791","effectiveDate":"2000-09-01","expirationDate":"2001-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["499269",140288,140289],"PO":["564318"]},"55636":{"abstract":"Modern statistical learning approaches are expected to play a key role in providing more powerful tools to harvest information from bits, a crucial and growing problem for the Internet. The goal of this project is thus to develop a new technology for the management, organization, and search of multimedia digital information by exploiting and extending new statistical learning theories and algorithms. In the process we expect to prototype key system components and to develop scientific insights. Anticipated outcomes of the research are (1) new learning algorithms and associated representations that can be applied to categorize text, images, and video, (2) new theoretical analyses of these learning algorithms and query-answering methods and (3) demonstrations and evaluations of prototype systems for classifying and routing email messages and searching, categorizing, and extracting information on the Web.<br\/><br\/>Smarter classification software for multimedia data is a prerequisite to enable a second, more intelligent wave of Internet technologies. Automatic techniques to route, organize and search information are needed to help individuals and organizations exploit the sea of data that the computer networks are creating. The success of projects like this will make such a step possible and accelerate the evolution of the Internet.","title":"ITR: From Bits to Information: Statistical Learning Technologies for Digital Information Management and Search","awardID":"0085836","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[142535,"523294"],"PO":["565227"]},"56857":{"abstract":"Institution: Washington State University<br\/>Proposal Number: EIA 0089986<br\/>PI: Kristine M. Kuhn<br\/>Title: Women and Information Systems: Modeling the Impact of Work Values, Attitudes, and Attributes on Career Choices<br\/><br\/>This CISE Information Technology Workforce (ITW) proposal requests funds to assess whether women are more attracted to careers in Information Systems (IS) because of the perception that it is more people-oriented than other computer-related fields. Both men and women undergraduate students will be surveyed as to their work values, beliefs, and attitudes related to IS, and job preferences in order to test a model of the underlying factors driving gender differences with respect to career choices. This project has the potential to provide significant insights about factors affecting the recruitment and retention of women in IT majors","title":"ITW: Women and Information Systems: Modeling the Impact of Work Values, Attitudes, and Attributes on Career Choices","awardID":"0089986","effectiveDate":"2000-09-01","expirationDate":"2002-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["183507","530243"],"PO":[146304]},"43327":{"abstract":"PI: Zuckerman, David I.<br\/>Institution: U of Texas Austin<br\/>Proposal Number: 9912428<br\/><br\/>Abstract<br\/><br\/>There have been interesting recent results on the connection between pseudo-randomness and fault-tolerance. This project investigates these connections further.<br\/>In psudo-randomness, the project investigates extractors, derandomizing space-bounded computations, pseudorandom generators for combinatorial rectangles and pseudorandom permutations. Each item on the list has an application to the following item. In fault-tolerance, the project investigates randomized computation in the perfect infomation and cryptographic models, and aspects of error-correcting codes related to extractors.","title":"Pseudorandomness and Fault Tolerance","awardID":"9912428","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["518438"],"PO":["543507"]},"55669":{"abstract":"Many of today's performance-critical applications involve manipulating data<br\/>sets that are either too large or too rarely used to be reliably found in<br\/>local memory caches or local cache servers. Due to the enormous disparity<br\/>between processor cycle times and disk and network access latencies, these<br\/>applications waste a large fraction of their time waiting for data; as we<br\/>look to the future, this problem is expected to become even worse. To<br\/>overcome this problem, this research will combine aggressive storage<br\/>prefetching with intelligent cache management to fully hide the data access<br\/>latency while using memory resources intelligently. Program transformation<br\/>tools and runtime support systems will be developed that collaborate to<br\/>customize memory hierarchy and distributed cache resource management for<br\/>data-intensive applications. With application-specific guidance of memory,<br\/>network and disk resources, it is possible to decrease execution times by<br\/>orders of magnitude. The ultimate goal of the research is for programs to<br\/>never waste time waiting for data, and for programmers to never waste their<br\/>valuable programming time thinking about this performance problem.","title":"ITR: Static and Dynamic Techniques for Latency Hiding in Data-Intensive Applications","awardID":"0085938","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["485986","465808"],"PO":["223414"]},"47815":{"abstract":"ABSTRACT<br\/>Proposal: 9985109<br\/>Title: CAREER: The Long-Term Effects of Technology on Microprocessors<br\/>PI: Doug Burger, University of Texas at Austin<br\/><br\/>The research funded by this CAREER grant is addressing three of the microprocessor design challenges posed by deep submicron technologies: slowing performance growth, decreasing reliability, and increasing power dissipation. This research is attacking these challenges by proposing new technology-sensitive designs across three design categories: individual microarchitectural cores, large on-chip memory systems, and chip multiprocessors.<br\/><br\/>The microarchitecture research is organized into two parts: a technology-based scalability analysis of current microarchitectures, to determine and quantify future microarchitectural bottlenecks, and an evaluation of the grid instruction processor--a new microarchitecture, containing two-dimensional arrays of functional units, which eliminates many of the microarchitecture bottlenecks that will arise from advancing technologies.<br\/><br\/>The research is also evaluating how multi-megabyte on-chip memory systems should be designed in future wire-dominated environments. Both the physical design (which will have sub-banks numbering in the thousands) and the logical organization (how to map data into caches with non-uniform, position-dependent latencies) are being explored.<br\/><br\/>Finally, the funded research is exploring ways of accelerating single-thread performance by adding new mechanisms to chips with multiple processor\/memory tiles each. These mechanisms include fine-grained computation migration, dynamic thread parallelization, redundant computation, and working set size-based dynamic allocation and adjustment of on-chip memory.","title":"CAREER: The Long-Term Effects of Technology on Microprocessors","awardID":"9985109","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["217452"],"PO":["325495"]},"54349":{"abstract":"0080016 Hull The Materials Research Science and Egineering Center (MRSEC) at the University of Virginia supports an interdisciplinary research program on nanoscopic materials design. The group research explores the guided growth of epitaxial semiconductor sufaces, combining short-range self-assembly phenomena with long-range pattern definition techniques. Techniques utilized include focused ion beam surface modification, nano-scaled electrochemical etching and strain field engineering. This will lead to the capability for definition of nanoscale semiconductor surface structures of arbitrary length scales and complexity, with applications to quantum device structures, biological templating and nanoscale electrochemical processes. The Center's research is aided by extensive collaborations with other universities, government and industrial laboratories. The Center also provides seed support for emerging research opportunities in related areas.<br\/><br\/>The Center supports well maintained shared experimental facilities and also supports interactive efforts with industry and other sectors. Education outreach efforts focus on developing collaborations with two- and four-year colleges in the Commonwealth of Virginia, and include a joint curriculum development effort with Longwood College, Northern Virginia Community College and Hampton University.<br\/><br\/>Participants in the Center currently include 21 senior investigators, 2 postdoctoral associates, 11 graduate students, 6 undergraduate students and 2 technicians and other support personnel. Professor Robert Hull directs the MRSEC.","title":"MRSEC: The Center for Nanoscopic Materials Design","awardID":"0080016","effectiveDate":"2000-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0307","name":"Division of MATERIALS RESEARCH","abbr":"DMR"},"pgm":{"id":"1675","name":"NANOSCALE: SCIENCE & ENGIN CTR"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0307","name":"Division of MATERIALS RESEARCH","abbr":"DMR"},"pgm":{"id":"1735","name":"MATERIALS RSCH SCI & ENG CENT"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0307","name":"Division of MATERIALS RESEARCH","abbr":"DMR"},"pgm":{"id":"1736","name":"MATERIALS CENTERS & EDUCATION"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7299","name":"Catalyzing New Intl Collab"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0709","name":"Division of BIOENGINEERING & ENVIRON SYSTE","abbr":"BES"},"pgm":{"id":"7457","name":"NANOSCALE SCIENCE & ENG EDUCAT"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"5345","name":"BIOMEDICAL ENGINEERING"}}],"PIcoPI":["555556"],"PO":["557159"]},"48937":{"abstract":"This project addresses two important high-level issues -- reliability and performance -- in the development of quality software components that store and manipulate persistent data, where that data may be shared and accessed concurrently on behalf of principals that may be acting either cooperatively or competitively. The objective of the research is to design, implement and evaluate techniques that allow application developers to compose the competitive concurrency model of traditional database systems, namely transactions, with the cooperative concurrency model of traditional programming languages - namely, threads -- without sacrificing performance. The resulting fusion, so-called transactional threads, encourages development of more reliable applications that manipulate large amounts of shared, structured data. This project is developing specifications and implementations of integrated compiler\/run-time and data storage techniques that enable transactional threads to perform efficiently. These techniques are being evaluated experimentally through execution and measurement of benchmark transactional persistent programs. Concrete research products include the development of prototypes of transactional threads for persistent extensions of the Modula-3 and Java programming languages. The experimental approach to this research offers a rich environment for training of experimental computer science students, for further experimental research applications, and for development of reliable persistent application systems. <br\/>http:\/\/www.cs.purdue.edu\/~hosking","title":"Transactional Threads for Reliable Persistent Application Systems","awardID":"9988637","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["562118"],"PO":["563751"]},"56318":{"abstract":"0088063<br\/>Boston, Nigel<br\/>University of Illinois at Urbana<br\/><br\/>CRCD: A Cryptography Center for Research and Education<br\/><br\/>This project is concerned with the field of cryptography. This university is establishing the Illinois Center for Cryptography and Information Protection (ICCIP), a multidisciplinary center focused on research and education in fields that influence information protection and are influenced by information protection techniques. This CRCD project lays the groundwork for the educational and curricular aspects of the center. Multidisciplinary groups of upper-level undergraduate students and graduate students (from engineering, computer science and mathematics) are organized into teams attacking problems in modern cryptography. This project also addresses the development of cryptography related courses that are cross-listed in mathematics, engineering, and computer science. The project involves industrial partners who contribute practical problems and interact with teams. Industry, government, and academe need employees with a broad range of skills who can work in this field in inter\/multidisciplinary teams. For example, attacks on current crypto-systems can be sophisticated mathematical ones or direct physical ones. To counter such attacks takes concerted efforts from team members having different expertise in mathematics, engineering, and computing. The same holds true for the creation of new information protection schemes. Computing and engineering practitioners are faced with physical limitations of circuits, software, and devices in implementing mathematical solutions to information protection. This curriculum produces individuals with broad backgrounds and experience in working in teams on realistic problems in cryptography and the creation of novel collaborations that will advance technological developments much quicker than has historically been the case.","title":"CRCD: A Cryptography Center for Research and Education","awardID":"0088063","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4725","name":"EXPERIMENTAL SYSTEMS\/CADRE"}}],"PIcoPI":["333038","381437","483541"],"PO":["551712"]},"47639":{"abstract":"ABSTRACT<br\/>PROPOSAL NUMBER: 9984336<br\/>TITLE: Incorporating Technology Scaling into the Design, Evaluation, and Implementation of Computer Architectures<br\/>PI: Stephen W. Keckler, University of Texas at Austin<br\/><br\/>The objectives for the research funded by this CAREER proposal are to investigate computer architectures that simultaneously address the challenges of deep-submicron technologies and meet the needs of modern dynamic applications. The most significant technology challenges are the diverging speeds of transistors and wires, increased power consumption and heat generation in integrated circuits, and higher susceptibility to transient logic faults due to decreasing feature sizes.<br\/><br\/>This research includes three components. First, accurate technology models for future silicon fabrication technologies are developed. The focus is on communication delay, both along wires and within microarchitecture structures such as register files and ALUs and on the reliability of microprocessor components when subjected to external energy sources. Second, these models are incorporated into the SimpleScalar toolset to evaluate existing architectures under these new technological constraints and provide a platform for evaluating future architectures. Third, multiple processor cores on a chip are investigated as a means to construct a \"server-on-a-chip\" and to build a system that tolerates transient faults. The necessary features of this multicore architecture are hardware and system software that dynamically schedule jobs to meet latency, throughput, and redundancy (for reliability) requirements of the workloads.","title":"CAREER: Incorporating Technology Scaling into the Design, Evaluation, and Implementation of Computer Architectures","awardID":"9984336","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["424003"],"PO":["325495"]},"48739":{"abstract":"This project will study the impact that advanced combinatorial algorithm<br\/>techniques and data structures can have on the performance of<br\/>heuristic search, both in theory and in the context of<br\/>building a general-purpose combinatorial optimization engine.<br\/>This engine will be applied to yield quality implementations of<br\/>heuristics for twenty NP-complete problems which arise commonly in practice.<br\/>This approach focuses attention on identifying versatile high-performance<br\/>approaches to local optimization. Further, it suggests a variety of<br\/>new lines of theoretical research which will lead to improved optimization<br\/>algorithms.<br\/><br\/>The impact of this research revolves around (1) the development of new<br\/>combinatorial algorithms and data structures supporting powerful<br\/>crossover, mutation, and cycle-avoidance operations, and mapping energy<br\/>landscapes, as well as provably good approximations, (2) a systematic<br\/>study of the performance of local search variants including simulated<br\/>annealing, genetic algorithms, and tabu search, (3) the development of<br\/>useful software for research, industrial, and educational applications,<br\/>and (4) the creation of a new competitive forum for assessing the state<br\/>of the art in algorithm engineering.","title":"Algorithm Engineering for NP-Complete Problems","awardID":"9988112","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["472850"],"PO":["543507"]},"48629":{"abstract":"The objective of this research is to investigate the integration of background knowledge into a machine learning approach for automatically indexing text documents. Case-Based Reasoning models for utilizing past experiences have been developed for domains where the cases are text. The prohibitive cost of manually indexing cases has hindered the development and maintenance of large systems for applications in the law, ethics, or help-desk settings. New methods that learn a text classifier from a small collection of annotated case summaries, which will classify large numbers of cases automatically, can help overcome this knowledge-acquisition bottleneck. Text learning algorithms used elsewhere are not applicable because they require large training sets. Here, background knowledge about the domain and a linguistic analysis of the examples is employed to develop a better representation of the examples, which will allow learning algorithms to better generalize from small collections of text cases. The project will also yield a better understanding of what makes a good text representation for learning and classification, and the effects of adding background knowledge and natural language processing tools. The experiments are based on a relatively small collection in a well-defined domain, in which the PI and his group have accumulated significant expertise. This unique background allows a more thorough analysis of the experimental results than generally performed. The classifier is evaluated both on a set of marked-up summaries and the corresponding full-length documents. Further experiments explore the use of unseen and unlabeled cases, and explain the observed behavior. The results and the analysis of the experiments will enable researchers in other domains to improve the representation of text cases. Thus, the research results will not only be relevant for case-based reasoning and machine learning, but also for information retrieval and other text-based applications.","title":"Adding Domain Knowledge to Inductive Learning Methods for Classifying Texts","awardID":"9987869","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["488662"],"PO":["563751"]},"52700":{"abstract":"As the twenty-first century unfolds, new wireless services are being deployed and several more are envisioned. In order to provide these services, future wireless systems should be capable of handling much higher data rates than today's systems. The limited spectrum available for these services implies that the spectral efficiency of future systems will have to be significantly higher. In addition to being spectrally efficient, next-generation wireless systems will have to be power efficient. Lower transmit powers means lesser interference to other users, better reuse of the spectrum and, hence, higher efficiency for the overall network. Wireless channels offer several impairments to the transmitted signals, deteriorating the quality of the communication link. Increasing the power and spectral efficiency in the presence of such an unreliable<br\/>link is a challenging task which can be greatly facilitated by the use of efficient coding and signal processing techniques. This research investigates the design of powerful coding techniques such as turbo codes and low density parity check codes for increasing the power and spectral efficiency of wireless systems.<br\/><br\/>This research involves a detailed study of the design and performance analysis of turbo-like codes with low decoding complexity, and low density parity check codes (LDPC) for use in a wireless environment. Specific areas covered in detail are the design of coding schemes for use with multipath channels and turbo equalization, the design of LDPC codes for spectrally efficient modulation, and the design of incremental redundancy schemes using LDPC codes for use in a non-stationary environment. This work differs from the existing work in that it studies several novel coding techniques and concentrates on the design of codes matched to the iterative decoding algorithm being used, rather than the design of codes based on hypothetical<br\/>maximum-likelihood decoding.","title":"Low Density Parity Check Codes and Turbo Codes for Wireless Communication","awardID":"0073506","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["551055"],"PO":["564898"]},"54911":{"abstract":"EIA-0082849<br\/>Page, Rex<br\/>University of Oklahoma<br\/><br\/>ITR: Formal Methods Education and Programming Effectiveness: Are They<br\/>Related?<br\/><br\/>Software is often laced with coding errors which result in loss of life and<br\/>productivity. These problems have been addressed by improved tools,<br\/>disciplined processes, more effective design and analysis, and software<br\/>product inspections. This research addresses the problem through better<br\/>education. This work seeks evidence for the integration of mathematical<br\/>reasoning in computing education as leading to improved programming skills.<br\/> The project will measure and compare the programming effectiveness of two<br\/>cohorts: one that studies core concepts of mathematical reasoning within<br\/>the context of programming and another studying these core concepts in a<br\/>pure mathematical context. The comparison measure of programming skills<br\/>will be software development projects in a subsequent course. Learning<br\/>more about any relationships between programming ability and mathematical<br\/>reasoning can be an important step in improving curricula that educate<br\/>students for the critical information technology positions of the future","title":"ITR: Formal Methods Education and Programming Effectiveness: Are They Related?","awardID":"0082849","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1359","name":"RES EXP FOR TEACHERS(RET)-SITE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["450799",140323],"PO":["564318"]},"50687":{"abstract":"Computationally Efficient <br\/>Joint Demodulation for Sensor Arrays<br\/><br\/><br\/><br\/>Abstract<br\/><br\/>The objective of the proposed research is to realize order-of-magnitude improvements in the interference mitigation capability of an antenna array with its associated multi-channel digital signal processing algorithms, compared with performance presently attainable using conventional linear processing. The motivating commercial applications include high-capacity cellular telephony, personal communications systems, and wireless local area networks. Such huge increases in interference mitigation capability translate to similar magnitude increases in system capacity. With no end in sight to the accelerating demands on communications capacity, the commercial value of a breakthrough of this type would be tremendous. <br\/><br\/>The signal processing method being investigated is joint demodulation of multiple signals using a multichannel Viterbi algorithm modified to trade signal quality for computational cost. The goals are to 1) characterize the number of interfering signals that can be separated and 2) characterize the degree of reduction in complexity of the Virterbi algorithm that can be realized while maintaining acceptable bit-error-rate, both as functions of the number of antenna elements in the array, and parameterized by signal-to-noise ratio. The interference environments simulated model cellular telephone channels with GSM and\/or IS-136 signaling.","title":"Computationally Efficient Joint Demodulation For Sensor Arrays","awardID":"0003284","effectiveDate":"2000-09-01","expirationDate":"2002-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":[129466],"PO":["564898"]},"54922":{"abstract":"EIA-0082907<br\/>Wagner, Kelvin<br\/>University of Colorado<br\/><br\/>ITR: Revolutionary Computing Using Ultrafast Optical Soliton Switching<br\/><br\/>The objective of this project is to develop a new technology for ultra high speed (terabit per second) information processing, communication, and computing. The technology is based on optical spatio-temporal solitons, which are localized packets of electromagnetic energy. Logic devices and computing architectures based on the interactions of spatio-temporal solitons in two and three dimensions will be investigated theoretically and experimentally. These devices and systems will employ materials with high order optical nonlinearities as well as artificially structured media designed to support soliton propagation and interactions. This research is expected to provide a foundation for a robust, practical, compact, cascadable, and logically complete switching technology with processing speed and density orders of magnitude beyond those of existing information-processing electronics.","title":"ITR: Revolutionary Computing Using Ultrafast Optical Soliton Switching","awardID":"0082907","effectiveDate":"2000-09-01","expirationDate":"2006-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["494668"],"PO":["521045"]},"54933":{"abstract":"The goal of the Sutter graph database architecture is to help biologists make sense of the human genome, by enabling them to search genome sequence alignments for patterns of functional and structural relationships between genes. Sequence alignments are the key for discovering meaningful connections between diverse biological data, to make sense of the completed Human Genome. Yet no current database is designed to query detailed sequence alignment relationships as is needed. The Sutter architecture is designed to provide a fast, flexible, and intuitive query system for genomic alignment data, based on storing the entire graph database in a set of indexes, enabling direct lookup for any item to find its relationships. By focusing on indexing, Sutter can move away from the fixed, inflexible schema (table structure) of relational systems, while retaining some of the basis of their speed. A major design goal of Sutter is to implement genomic data objects efficiently, enabling it to store a full genome database in RAM, and achieve dramatically faster query performance. Sutter's first application is to serve the genome research community as an online resource for mining single-nucleotide polymorphisms, their effects on protein function, and mapping disease genes.","title":"ITR: A Novel Graph Database Architecture for Mining Discoveries from the Human Genome","awardID":"0082964","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[140393,"335186"],"PO":["563751"]},"54702":{"abstract":"This research focuses on the analysis of spatial interactions in distributed GIS environments. Data related to systems of spatial interactions includes spatial flows and locational and attribute data pertaining to origins and destinations. Given that these datasets are distributed across multiple nodes of a computer network, this research aims to: 1) study mechanisms of data partitioning and develop a metadata structure that describes the partition; 2) develop decomposable algorithms for gravity modeling that minimize communication cost; and 3) develop efficient algorithms for learning and classifying flow patterns using distributed data sources. The approach is to let the databases reside at their native sites. The algorithms dynamically decompose themselves into partial computations that are executed at individual database sites, and local results are composed to obtain the same global results that would have been obtained if the databases had been moved to a common site. The algorithms can find the decompositions to match the distribution of data across the network. This research will have significant impact on many problems that need to process distributed data. For example, it can enable GIS systems to analyze spatial-temporal datasets distributed over the Internet without having to move the databases to a common site.","title":"ITR: Advanced Algorithms for Spatial-Temporal Interactions in Distributed GIS","awardID":"0081434","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["283133","521101"],"PO":["563751"]},"54944":{"abstract":"This is the first year funding of a three-year continuing award. The goal of the \"Virtual Trainer\" is to create a computer-based animation that can interactively teach how to move. The hardware requirements for the Virtual Trainer in its final stage would be an inexpensive state-of-the-art personal computer equipped with a camera system. The Virtual Trainer will be able to demonstrate movements to its user, monitor the execution of these movements by the user, and suggest corrections in case of inadequate performance. The Virtual Trainer will be useful in a large number of applications, including rehabilitation of movement-impaired patients (e.g., stroke-patients), sport and exercise education, dance instruction, and interactive entertainment industry. Additionally, the technology developed for the Virtual Trainer has the potential to pioneer new algorithms for robot control using \"teaching from demonstration\", to contribute to the development of automated monitoring systems for human environments, to the generation of humanoid computer simulations, and also to gaining new insights into biological motor control and the functioning of the nervous system. The research team of this project will primarily focus on issues of movement recognition and movement generation with the Virtual Trainer for rehabilitating stroke-impaired patients with upper and lower limb disabilities.","title":"ITR: The Virtual Trainer","awardID":"0082995","effectiveDate":"2000-09-01","expirationDate":"2004-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["492859","338154"],"PO":["565227"]},"52777":{"abstract":"Jagannathan Ramanujam, Louisiana State University<br\/><br\/><br\/>The performance of programs on modern processors depends critically on<br\/>how their memory access characteristics can be matched to the<br\/>multi-level memory hierarchy commonly used in these processor<br\/>architectures. The goal of this project is derive compiler<br\/>transformations to improve the memory performance of scientific<br\/>computations. In particular, a combination of program restructuring<br\/>and memory layout transformations of data will be derived to handle a<br\/>larger class of programming constructs than perfect nests and regular<br\/>memory accesses. This project will study several important problems,<br\/>including: (a) strategies to integrate tiling and data shackling in<br\/>order to effectively orchestrate the movement of data through memory<br\/>hierarchies; (b) issues in the design of a sophisticated<br\/>locality-enhancing compiler for regular and irregular codes; (c)<br\/>extensive experimental evaluation of locality-enhancing<br\/>transformations; (d) insights on the interaction between techniques<br\/>for exploiting instruction-level parallelism and register-level reuse;<br\/>and (e) possible insights on improvements in the design of memory<br\/>systems for applications, including the design of application-specific<br\/>cache architectures. Most importantly, these compiler techniques will<br\/>allow users to easily exploit the enormous computation power in modern<br\/>processor architectures.","title":"Program and storage transformations for improving memory performance","awardID":"0073800","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["557461"],"PO":["551992"]},"52667":{"abstract":"Craig Chambers<br\/><br\/>Higher-level programming languages, such as Smalltalk, ML, and Java, can make<br\/>programming easier, more reliable, and more flexible than lower-level<br\/>programming languages, such as C and C++. Unfortunately, these software<br\/>engineering benefits often come at significant cost to run-time efficiency.<br\/> One<br\/>important obstacle to achieving good performance for higher-level languages is<br\/>the relatively inefficient approach to the representation and layout of data<br\/>structures, where data structures are represented uniformly as heap-allocated<br\/>structures referenced indirectly via pointers.<br\/><br\/>This research aims to reduce the performance costs of this high-level data<br\/>model<br\/>while retaining its software engineering benefits for programmers.<br\/>Declarative<br\/>techniques will be developed for specifying the layout of data structures and<br\/>for specifying optimizations to data structure layouts. Techniques will be<br\/>developed for deciding which layout optimizations to apply, based on a mix of<br\/>programmer suggestions, automatic static analyses, and dynamic profile<br\/>feedback. A flexible, language-independent compiler intermediate<br\/>representation<br\/>will be designed that explicitly maintains, checks, and optimizes<br\/>representations. The techniques will be implemented in an optimizing<br\/>compiler,<br\/>and their effectiveness measured on a range of large benchmark programs in a<br\/>variety of object-oriented programming languages.","title":"Representation Specification and Optimization of Object-Oriented Languages","awardID":"0073379","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["332082"],"PO":["551992"]},"55703":{"abstract":"This is the first 4 years funding of a five-year continuing award. Humans are very good at discerning the spatial origin of sound using a mixture of frequency-dependent interaural time difference (ITD), interaural level difference (ILD), and pinna spectral cues in disparate environments ranging from open spaces to small crowded rooms. This ability helps us to interact with others and the environment by sorting out individual sounds from a mixture, and helps us to survive by warning us of danger over a wider region of space compared to vision. These advantages of spatial sound are important for human-computer interaction. <br\/><br\/>While the frequency-independent ITD cues (delays) associated with the two ears are relatively easy to render over headphones, the ILD (level difference) and pinna elevation cues are not. For a given source location and frequency content, the sound scattered by the person's torso, head and pinnae, and is received differently at the two ears, leading to differences in the intensity and spectral features of the received sound. These effects are encoded in an extremely individual \"Head Related Transfer Function\" (HRTF) that depends on the person's anatomical features (structure of the torso, head and pinnae). This individuality has made it difficult to use the HRTF in the proposed applications. Recent research, including that of members of this team, has focused on measuring the HRTFs for individuals in specific environments, on constructing models of the HRTF, on understanding how the geometry of the body is related to the characteristics of HRTF, and how the brain processes the cues to derive spatial information. However, this research has also indicated that the brain is extraordinarily perceptive to errors in cues that result when sound is rendered with an incorrect HRTF.<br\/><br\/>In this project the PI and his team will use numerical methods to compute individualized HRTFs from accurate 3-D surface models of the body. They will use multiview, multiframe computational vision techniques to extract the surface models from imagery. They will then use boundary element methods employing fast multipole\/ transform techniques and parallel processing to compute the HRTFs from the surface models. The resulting HRTFs will be evaluated both by objective comparisons with acoustically measured HRTFs and by psychoacoustic testing, and will be used in demonstrations of virtual reality, augmented reality, and teleconferencing. A major advantage of this vision-based approach is that it will allow the PI and his team to investigate and model the way that HRTFs change with body posture, providing the potential of tracking dynamic environments. Thus, the project will include fundamental research to extend the static HRTF measurements to dynamic situations in different environments, using a combination of visual tracking to locate the person in real space, and construction of in-room HRTFs from free-field HRTFs using fast iterative techniques. This will provide a scientific foundation for HCI applications of audio rendering. The research will in addition yield algorithms and understanding that will have an impact on varied fields, including computer vision based model creation; scientific computing; computational acoustics for noise control and land mine detection; neurophysiological understanding of human audition; etc.","title":"ITR: Personalized Spatial Audio via Scientific Computing and Computer Vision","awardID":"0086075","effectiveDate":"2000-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["564721","151489","151490","532931","478385"],"PO":["565227"]},"54856":{"abstract":"EIA-0082520<br\/>Snyder, Lawrence<br\/>University of Washington<br\/><br\/>ITR: Fluency 1 and Teaching Teachers to Teach IT<br\/><br\/>Fluency with information technology (FIT) is the ability to effectively use<br\/>computers, networks, software and information resources now and in the<br\/>future. Fluency is a new standard of IT knowledge formulated by the<br\/>National Research Council's Committee on Information Technology Literacy in<br\/>their report, Being Fluent With Information Technology. To enable students<br\/>to continually learn IT, Fluency provides the foundations (concepts) on<br\/>which to build further understanding, and the mechanisms (capabilities) to<br\/>understand when more must be learned. The goal of this project is to pave<br\/>the way for the widespread offering of information technology fluency<br\/>courses in K-12 schools, community colleges and adult education. The<br\/>project will allow the creation of a Fluency 1 curriculum whose<br\/>presentation stretches over one year, allowing for a paced introduction of<br\/>IT topics and time to prepare for and work on IT projects. Fluency 1<br\/>contains components of algorithmic thinking and programming and should help<br\/>provide teaching guidance that is suitable to assist a present \"computer<br\/>literacy\" teacher in teaching Fluency.","title":"ITR: Fluency 1 and Teaching Teachers to Teach IT","awardID":"0082520","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["346688"],"PO":["564318"]},"55714":{"abstract":"With the advances in embedded processors, low cost sensor technologies, and wireless communication, unprecedented amounts of diverse types of information about the real world and its activities are being generated. Much of the information is spatio-temporal in nature; concerning objects dispersed in space and time, and interacting and communicating with each other and their surroundings. An infrastructure that facilitates real-time capture, storage, processing, display, and analysis of the information generated will truly revolutionize a wide variety of application domains. Examples of domains that will benefit from this technology include avionics, ground traffic, commercial applications such as ship-ping and transportation, emergency response and disaster relief operations, physical phenomenon such as weather and storm tracking, forest fire tracking, migration patterns of animals\/birds, command and control, smart environments, etc. Applications in the above domains require real-time monitoring, tracking and analysis of objects\/events\/phenomena in space and time. <br\/><br\/>An integral component of such sensor enriched communication and information infrastructure is a database management technology that allows seamless access to information dispersed across a hierarchy of storage, communication and processing units - from sensor devices, where data originates, to large data banks where the information generated is stored for analysis and mining. This research will explore next generation database management system technology that provides effective support for information processing in highly distributed and dynamic sensor-enriched environments. The approach taken will be end-to-end - that is, research will be conducted on all aspects of the system ranging from representation, data modeling, query languages, data structures, query optimization, query processing, distribution, and concurrent accesses. A prototype database management infrastructure that supports highly dynamic geographically dispersed spatio-temporal data, multi-resolution representation of data, and provides effective support for visualization and analysis will be developed.","title":"ITR: Collaborative Research: Real-time Capture, Management and Reconstruction of Spatio-Temporal Events","awardID":"0086116","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[142856,"296399"],"PO":["563751"]},"52447":{"abstract":"EIA-0072743<br\/>Kavraki, Lydia<br\/>Rice University<br\/><br\/>CISE Postdoctoral Associates in Experimental Computer Science: Manipulation<br\/>of Rigid and Deformable Objects with Applications in Manufacturing and<br\/>Computer-Aided Surgery<br\/><br\/>Object manipulation has been a central theme in robotics over the last<br\/>decade. Efficient techniques have been proposed for positioning,<br\/>orienting, sorting, etc., rigid objects under a variety of constraints and<br\/>sensory input. Although several problems concerning rigid parts deserve<br\/>further attention, recent advances in manufacturing also require the<br\/>manipulation of deformable objects such as cables, pipes, paper, etc.,<br\/>needed for producing compact assemblies. Building on the theory of<br\/>manipulation of rigid objects, the postdoctoral associate will investigate<br\/>the manipulation of deformable objects and selected problems involving<br\/>rigid object manipulation. The goal is for the associate to assist in (a)<br\/>developing appropriate computational models for deformable objects, (b)<br\/>studying fundamental notions such as stable grasping and fixturing of<br\/>deformable objects, and (c) providing efficient procedures to compute the<br\/>expected deformations of objects under manipulation constraints. One<br\/>important and challenging application of the proposed work is the<br\/>simulation of deformable human tissues. Such a simulation can lead to the<br\/>development of virtual training environments for surgical procedures.","title":"CISE Postdoc Research Associates in Experimental Computer Science: Manipulation of Rigid and Deformable Objects with Applications in Manufacturing and Computer-Assisted Surgery","awardID":"0072743","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["557516"],"PO":["564318"]},"55725":{"abstract":"The proposed research will investigate new software engineering<br\/>techniques and tools for infrastructural software that will improve<br\/>its reliability, safety, and predictability. The key idea is to use<br\/>abstract design models to drive new static analyses that check that<br\/>the software correctly implements its design (and if not, identify the<br\/>source of the problem). To ensure that our research addresses the<br\/>important issues that developers face in the field, we will conduct<br\/>our research in the context of the development of an air traffic<br\/>control system component. Specifically, the research will investigate<br\/>the use of object models to express important design properties and<br\/>new pointer analysis algorithms to verify that the code correctly<br\/>implements the object models. Object models describe essential object<br\/>in the heap and the relationships between them; pointer analysis<br\/>automatically analyzes code to extract information about how objects<br\/>refer to each other. The research will investigate techniques that<br\/>improve the precision of the pointer analysis by using the object<br\/>model to focus the analysis on the properties of interest.","title":"ITR: Design Conformant Software","awardID":"0086154","effectiveDate":"2000-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["326919","335202","497068"],"PO":["325495"]},"54878":{"abstract":"Contemporary distributed systems are increasingly extensible, heterogenous and dynamically evolving. Further, the execution environment (including the hosts and the network) is dynamic in its underlying structure and capacity. This research project aims to develop and analyze an adaptable distributed programming environment (including a programming model and a runtime system) for effectively utilizing such complex systems. <br\/> The research project will develop a programming environment in which programs and its components can freely migrate across different hosts. The distribution of program components across different hosts can be controlled by binding specific mobility paradigms with the components. Further, the mobility paradigms can be changed dynamically, both by an application and\/or by the runtime system. Such a programming model entails an execution environment in which distribution of program components can be controlled dynamically in order to adapt to changes in load, resource availability, resource distribution, component distribution and computational capabilities of hosts. <br\/> The research will also develop runtime system techniques for creation and management of mobile components, resource allocation and security. It will develop adaptive scheduling schemes that allow hosts to precisely control allocation of local and distributed resources to non real-time and real-time distributed components.","title":"ITR: Supporting Dynamic and Scalable Distributed System Infrastructures","awardID":"0082677","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["284993"],"PO":["325495"]},"54768":{"abstract":"The purpose of Computational Geometry is to provide provably efficient algorithms and data structures for applications of a geometric nature. Unfortunately, the commonly adopted attitude of studying worst-case behavior has disserved the field by building a gap between the theoretical research and the growing community that implements and uses geometric algorithms. This project will develop frameworks that model more closely the behavior of algorithms of practical importance on actual data. To do this, it will concentrate on ray shooting, which is the bottleneck operation in the fundamental ray tracing technique for producing photo-realistic images in graphics. Ray shooting also has numerous other applications.<br\/><br\/>Technically, the project will develop a new framework for predicting the \"average\" (rather than worst-case) performance of ray shooting on any decomposition- or hierarchy-based data structure on a given input. This would allow one to compare the expected performance of different approaches on a given data, with the eventual aim of being able to predict the cost of an operation, such as rendering a scene at a certain resolution, or optimizing the choice of a data structure to store a scene, prior to actual ray-shooting computation. It will also devise novel ray shooting\/ray tracing algorithms that reduce the I\/O-complexity for datasets too large to fit in main. In addition, It will attempt to extend the proposed performance-predicting framework to incorporate I\/O-complexity as well, to cover the entire spectrum of the input sizes. Finally, the project will implement its algorithms, address the corresponding robustness issues, and investigate the accuracy of the predictive framework on practical data.","title":"ITR: Geometric Algorithms and Analytical Models: the Case of Ray Shooting","awardID":"0081964","effectiveDate":"2000-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["518464","292992","280545"],"PO":["321058"]},"54889":{"abstract":"The Computer Science and Engineering, and Telecommunication Departments at Michigan State University (MSU) requested support to conduct research involving the categories: Human-Computer Interface, Information Management, and Scalable Information Infrastructure. Three existing research laboratories will be connected and used as a testbed to facilitate this collaborative interdisciplinary research: High-Speed Networking & Performance Lab (HSNP), Media and Entertainment Technologies Lab (MET), and Media Interface and Network Design Lab (MIND). A primary objective of the proposed research is to further advance the client-server technologies for a ubiquitous multimedia computing environment. Since ubiquitous computing capability may take the form of advanced personal digitized assistants (PDAs), wearable computer systems featuring heads up displays, or argumented reality systems, this proposal addresses key issues which include: (1) personal environment data capture, (2) environmental data salience, (3) transport of multimedia data over wireless and heterogeneous network systems in a client-server environment, (4) media access and retrieval, and (5) human-computer-interface (HCI) design and analysis. Some of the significant questions that are addressed in the project are: (a) given continuous audio and video capture, what is the best choice of content to archive in a personal multimedia database? (b) how can audio and video capture of unconstrained content be used as an effective query mechanism for a multimedia database? (c) how can perceived latency and communications performance be optimized in a wireless environment where bandwidth, error rates, and latency are continuously variable and dependent upon many environmental conditions?, (d) how can the quality-of-service for the transport of real-time multimedia traffic be guaranteed using heterogeneous networks and wireless network systems?, and (e) what should be the design principles to support a fully mobile user engaged in hand-free high-bandwidth, collaborative work and communication? New algorithms and techniques will be developed and tested to address these questions either via simulation, emulation, or experimentation. It is anticipated that the existing facilities will be significantly enhanced via a pending NSF research equipment proposal. This proposed equipment (e.g., VoD servers, multimedia lap tops, WaveLan products, wearable argumented reality interfaces) will be the defining infrastructure to support a sophisticated testbed, connecting three research laboratories (HSNP, MET, MIND) via wireless links. The multi-lab testbed will be used for the experimental phase of the project. As an effort to broaden the participation in our research, the PIs will invite interested faculty (via two-week summer workshops) and students (via ten-week summer research experience) from HBCUs (Historically Black Colleges and Universities) to work with them during the three summers. Additionally, the PIs will invite a few interested professionals from industry to participate in the research initiatives.","title":"ITR: Wireless Client-server Technologies for Ubiquitous Multimedia Computing","awardID":"0082743","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["196076",140260,"345982"],"PO":["250082"]},"55626":{"abstract":"This award provides support for a collaborative project involving two computer scientists and a plant geneticist who will develop new methods, efficient algorithms, and software tools for several important problems in the field of bioinformatics. This supported work includes research into computational paradigms such as quartet methods, interactive systems, and approximation algorithms as applied to the evolutionary analysis of gene sequences, gene duplication, and horizontal transfer events in the genomes of chloroplasts, a DNA-containing organelle found in all plants. Additional studies will examine the information content of genomes by improving and testing a recently developed sequence entropy estimator and a distance metric for genomic sequences. Work in this area will include the application of the improved methods to sequence data from the genomes of mitochondria, viruses, chloroplasts and bacteria. Other efforts will address the important problem of simultaneous multiple sequence alignment and evolutionary tree reconstruction. The multiple sequence alignment approaches to be developed are based on the use of conserved blocks that have few or no gaps, and multiple alignments within a constant band. Work in a fourth area will develop efficient algorithms for computing short and long interspersed nuclear elements (SINES and LINES) in genomic sequences of lengths up to billions of nucleotides. Because of the large amounts of data that must be analyzed, this will require the development or adaptation of appropriate external memory algorithms. <br\/><br\/>Biological, biomedical and pharmaceutical research is undergoing a major revolution as new analytical technologies produce unprecedented amounts of genetic data. The exploration of this information is critically dependent upon the development of advanced computational and software techniques for data analysis, storage and retrieval. From this dependency, a new interdisciplinary research field, bioinformatics (or computational molecular biology) has emerged in recent years. The work supported through this award is expected to make both fundamental and applied contributions to the field. The fundamental research will explore and explicate new ideas and methods for solving algorithmic problems in bioinformatics and the applied research will involve the development and evaluation of software tools in the practice of plant genomics. Although the efforts are aimed at improving the understanding of the evolution of chloroplast genomes, the approaches should be readily extensible to analysis of all other genomes.","title":"ITR: Collaborative Research: ITR\/ACS: Computational Techniques for Applied Bioinformatics","awardID":"0085801","effectiveDate":"2000-09-01","expirationDate":"2004-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["196924"],"PO":["565272"]},"54779":{"abstract":"Recent years have seen an explosive growth in the number of multimedia devices and communication tech-nologies. While these multimedia technologies still depend on wireline links, the future of multimedia com-munication is in wireless. Mobile multimedia networks will provide seamless communication between roam-ing users. Applications such as video conferencing or internet access will become available from any where in the world. Widely varying classes of network traffic (traffic heterogeneity) that change over time will be generated by multimedia applications. The network itself will consist of both wireline and wireless links (network heterogeneity). We are already beginning to feel this change.<br\/>A major constraint in multimedia wireless technology is the limited power budget. Mobile devices such as laptops and personal digital assistants have limited battery life. The re-chargeable battery technology has resulted only in a small increase in battery efficiency. So, it is important to optimize network protocols for minimum power to ensure the continued growth of wireless based multimedia communication. Many attempts have been made towards this goal at individual layers of the network protocol stack. Most of these efforts have concentrated only at the physical and link layers. In this proposal, we deal with the wireless network protocol stack as a whole and provide a unified framework to optimize both computation and transmission power at various layers of the protocol stack. A power manager serves as the central core of our framework. The<br\/>different layers of the protocol stack communicate with each other through the power manager that makes adaptive policy decisions based on the network, traffic, and power limitations. This is a uniqueness of the proposal. In the conventional model, the network layers have minimal or no communication at all leading to poor performance compared to the proposed framework. The proposed methods strive to optimize the quality of service (QoS) with minimum power consumption at the mobile wireless nodes. Towards achieving our objectives we consider the following research issues :<br\/><br\/>Adaptive source coding and modulation strategies at the physical layer that minimize power for a desired reliability. The adaptation is done based on channel state estimates produced by the link layer.<br\/><br\/>New error-resilient coding methods that do not have the drawbacks of the conventional forward error correcting codes. Little overhead, graceful degradation, and simple encoding and decoding that reduce the power requirements for computations are the main strengths of the coder. The coders are especially well-suited for state-of-the-art compression standards like JPEG, MPEG, and H.263. Radically different on-line channel state estimators are also proposed.<br\/><br\/>Power-aware transport control protocols that distinguish between various channel and battery state.<br\/><br\/><br\/>Application layer adaptation mechanisms to conserve power. The mechanisms use techniques from networking and signal processing areas to improve the performance.<br\/><br\/>Adaptive power manager (integrated controller) policies that control the entire wireless network from a global point of view. Reliability, bandwidth, robustness and power considerations are taken into account for policy decisions.<br\/><br\/><br\/><br\/>A simulation framework to experiment with different hardware configurations and network topologies and constraints. The developed framework will be help to validate and update our theories. This tool that will be made available through the web will be invaluable for other researchers in designing future energy-efficient wireless multimedia systems.","title":"ITR: Collaborative Research: Optimization and Integrated Control of Low Power Wireless Multimedia Networks","awardID":"0082064","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["515465","507752","549542"],"PO":["564898"]},"56847":{"abstract":"Institution: University of Wisconsin - Parkside<br\/>Proposal Number: EIA 0089957<br\/>PI: Sylvia Beyer<br\/>Title: Predictors of Women's Interest and Retention in Undergraduate IT Majors<br\/><br\/>This CISE Information Technology Workforce (ITW) proposal requests funds to study the barriers that discourage women from taking courses in IT and the causes of their low retention in IT. The project will consist of three studies. Study 1 uses a test-retest experiment to assess the impact of female IT role models on stereotypes and level of knowledge about IT. Study 2 is longitudinal; undeclared students' course taking patterns in IT will be followed from their first semester to the end of their third year. Study 3 is also longitudinal and examines predictors of undergraduate women's retention in IT. This research will look at interest in IT along a continuum ranging from complete lack of interest, to lukewarm interest (taking a general level course which does not carry credit toward the major), to more serious interest (taking an introductory course designed for potential majors), to committed interest (declaring the major). Likewise, the study of attrition will look not only at female IT majors who drop out of IT but also at women who leave the IT pipeline after taking only one or two courses. This project has the potential to provide significant insights about the recruitment and retention of women in IT majors.","title":"ITW: Predictors of Women's Interest and Retention in Undergraduate IT Majors","awardID":"0089957","effectiveDate":"2000-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["439630",146271],"PO":["289456"]},"55659":{"abstract":"The project is driven by the vision of a Global InfoBase (GIB): a ubiquitous and universal information resource, simple to use, up to date, and comprehensive. Towards this vision, the project is developing technologies needed to transform today's World-Wide Web into the GIB. The project consists of four interrelated thrusts:<br\/><br\/>* Integration of existing technologies into a ``universal'' information model and query language.<br\/><br\/>* Personalized information management, so users obtain more relevant and timely information.<br\/><br\/>* Sophisticated semantic-analysis tools.<br\/><br\/>* Algorithms for mining information to synthesize new knowledge.<br\/><br\/>The Web has created a resource comprising much of the world's knowledge. Yet today our ability to use the Web as an information resource is in a primitive state. The GIB project is developing technology that will allow society far more effective and efficient use of the dramatically growing amount of information available online.","title":"ITR: From the Web to the Global InfoBase","awardID":"0085896","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"V145","name":"CIA-KNOWLEDGE DISCOVERY & DISS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"W295","name":"CIA-KNOWLEDGE DISC & DISSEMIN"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"W525","name":"CIA-GRANT EXTENSIONS FOR KNOWL"}}],"PIcoPI":[142610,"447448","401830","384241"],"PO":["563751"]},"48905":{"abstract":"Energy Efficient Operating Systems for Pocket Computers<br\/>Dirk Grunwald, Dept. of Computer Science, Univ. of Colorado, Boulder<br\/><br\/>Many techniques have been proposed to combat processor and system<br\/>power demands. We propose to conduct a systematic investigation of<br\/>power conservation mechanisms and policies. The research will<br\/>construct an open-source, power-efficient operating system suitable<br\/>for next-generation, powerful palm-top computers. Moreover, we will<br\/>examine the possible energy reduction from application level energy<br\/>management using a a variety of runtime environments that collaborates<br\/>with the operating system to limit or control application-level<br\/>resource usage, including threads memory management. The research will<br\/>use existing high performance processors designed for mobile computing<br\/>as well as simulator processor power models to assess how power<br\/>demands can be reduced with minimal user intervention. This research<br\/>is significant because it addresses one of the paramount issues<br\/>hampering the widespread use of ubiquitous computing, the high power<br\/>demand of such computers.","title":"Energy Efficient Operating Systems for Pocket Computers","awardID":"9988548","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["543625"],"PO":["309350"]},"55208":{"abstract":"The goal of this research is to investigate and develop computational methods for supporting automated negotiation of contracts in business-to-business E-commerce applications. Such processes require the ability to negotiate over contracts that have scheduling constraints, interact with a highly distributed web of suppliers with different capabilities through the completion of the contracted work, and deal with failures in contract execution. These problems are modeled using a community of self-interested agents with limited rationality, each representing a business entity or a decision-maker. Algorithms and decision strategies will be developed for effective bid construction, bid evaluation, supplier selection, execution monitoring, and renegotiation of contracts among multiple agents. A distributed computational testbed will be developed and used for simulation, and analysis. The results of this research will contribute to the development of general computational models for multi-agent contracting. The research efforts will also produce a highly distributed market infrastructure with an agent population that can be used by industry and researchers for further investigations, as well as by educators as a tool for training the next generation of e-commerce specialists. The potential payoff of the research is high, given the projected size of the business-to-business and make-to-order e-commerce.","title":"Collaborative Research: A Computational Framework for Agent-based Contracting","awardID":"0084234","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["525682"],"PO":["495796"]},"48806":{"abstract":"A \"software component\" is any code that a programmer can use as part of a larger piece of code. Components may be classified along three dimensions: (1) Source-level components are delivered as source code, while binary-level components are delivered as executables. (2) Lightweight components extract little run-time cost, while heavyweight components extract a large run-time cost. (3) Generative components create new code fragments at the time that the component is used, while non-generative components simply copy code from the component. Subroutine and class libraries are binary-level, medium-weight, and non-generative; macros and C++ templates are source-level, lightweight, and generative. Broadly speaking, binary-level components are more convenient, while generative components are more powerful. The goal of this project is to produce a technology for lightweight, generative, binary-level components. It is based on two principles: Higher-order macros, used as a powerful component language, and compositional semantics, to permit macros to be rendered as executables. The goal of the research is to raise the level of programming by allowing programs to be built from more powerful and general components than current component technologies admit.","title":"Technologies for Lightweight, Generative, Binary Software Components","awardID":"9988307","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["451105"],"PO":["564388"]},"48608":{"abstract":"Large-Scale Nonlinear Programming<br\/> <br\/>Large nonlinear optimization problems arise in many important<br\/>areas of application such as climate modeling, weather forecasting,<br\/>network design, and finance. An important open problem is how to<br\/>solve these problems reliably and quickly. The proposal describes a <br\/>variety of new algorithms, based on barrier techniques, that promise<br\/>to be effective on problems of unprecedented size and complexity.<br\/>To ensure that the new methods are robust even in the case of high<br\/>ill-conditioning, novel regularization techniques are proposed. An<br\/>Internet-based solver implementing the new algorithms will be<br\/>developed as part of this project. It will allow the engineering<br\/>and scientific communities to solve large optimization problems<br\/>automatically using a web-based interface.","title":"Large-Scale Nonlinear Programming","awardID":"9987818","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["517236"],"PO":["321058"]},"52701":{"abstract":"The storage density of rotating magnetic recording is approaching its<br\/>theoretical maximum. Magnetic probe-based technology avoids these limitations by using techniques such as orthogonal recording which promise very high density storage within the next five to ten years. Probe-based storage devices promise improved access times, enormous potential parallelism gains, and remarkable storage densities. However, because of the unique characteristics of these devices there is a high<br\/>probability that existing file system architectures and algorithms will be suboptimal. By reexamining these basic structures in the context of probe-based storage, it is likely that significant performance gains can be achieved.<br\/><br\/>The proposed work comprises fundamental research in four areas: simulation of probe-based storage devices, architectural issues such as parallelism and caching, storage allocation and file layout, and request scheduling. In reexamining these basic issues for this new technology, this research creates a body of work that will lead the way in the development of secondary storage systems for such devices. This research is likely to result in a better understanding of the implementation details associated with probe-based storage devices to provide a set of algorithms and structures that can be used in systems implementations employing them.","title":"Architectures and Algorithms to Exploit Probe-Based Storage","awardID":"0073509","effectiveDate":"2000-09-01","expirationDate":"2005-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["540846","555419","557751"],"PO":["180163"]},"54912":{"abstract":"Users increasingly want to use Internet applications for information access and processing from a variety of fixed and mobile networked computing devices, such as desktops, cell phones, and PDAs. These devices have different capabilities, are not equally secure, and operate under different network conditions. Mobile users may also want to transfer an on-going communication activity from one device (e.g., a desktop) to a different device (e.g., a PDA). The proposed research aims to design a software framework for building distributed<br\/>applications to meet these emerging needs. A key concept is to use mobile, context-aware communicating components to compose distributed applications. Using component mobility across devices, system designers can build robust and responsive applications that adapt to varying network connectivity and to various device capabilities. The framework will also allow applications to adapt to changes by dynamically adding and removing components, or by replacing a set of components with another set. To allow users to move active work across devices, communication among components will handle component mobility and tolerate transient disconnections. This research will address performance issues, develop software methodology to accommodate device heterogeneity, and explore solutions to handling security concerns in using the framework to build distributed applications.","title":"ITR: A Mobile Component Framework for Building Adaptive Distributed Applications","awardID":"0082851","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["550044"],"PO":["564388"]},"54923":{"abstract":"This project explores two complementary techniques for addressing<br\/>fundamental limitations in replicating network services. The first aspect<br\/>of this proposal seeks to automatically replicate service programs and<br\/>state information to allow transparent caching or replication of dynamic<br\/>services. The goal of the research is to allow transparent caching or<br\/>replication of dynamic services, a key step toward automatically converting<br\/>unscalable service implementations into scalable ones. The second thrust of<br\/>this work is to allow network services to dynamically trade replica<br\/>consistency for increased system availability and performance. The TACT<br\/>(Tunable Availability and Consistency Tradeoffs) toolkit allows Internet<br\/>services to flexibly and dynamically choose their own<br\/>availability\/consistency tradeoffs. We use three consistency metrics,<br\/>Numerical Error, Order Error and Staleness to capture application-specific<br\/>consistency requirements of Internet services. Applications use these<br\/>metrics in addition to application-specific parameters to assign a numeric<br\/>value to system consistency, e.g., the percentage of user requests that<br\/>must eventually be rolled back because of underlying replica<br\/>inconsistency. Finally, TACT allows consistency to be specified on a<br\/>per-user, client, and replica basis, enabling differentiated quality of<br\/>service.","title":"ITR: System Support for Automatic and Consistent Replication of Internet Services","awardID":"0082912","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["553906","485593"],"PO":["223414"]},"54813":{"abstract":"The exponential growth of the number of Internet hosts has been well documented in the trade press. The research community, however, has not seen many systematic empirical studies of how the Internet topology evolves over time and in space. Most recently, the authors of [FFF99] report on several power-law relationships observed on Autonomous Systems' (AS) connectivity degree, degree frequencies, and the neighborhood size within any given hop count from an AS. This pioneering work represents a first important step toward a better understanding of the dynamic nature of the actual Internet topology.<br\/> The need for realistic random topologies in simulations has long been recognized by researchers working on routing and multicast protocols, e.g. [BE90, ZGLA91, WE94]; more recently, the need for realistic random topologies has also been voiced by researchers studying traffic dynamics and protocol behavior [MS94, FGHW99, F+00]. In recognition of this, several topology generators have been proposed in the literature. The most recent one, proposed in [J+00] and called Inet, takes advantage of the power-law relationships reported in [FFF99] in its construction of random topologies.<br\/> The preliminary work conducted as part of this research and reported in this proposal shows exponential growth over time in frequency of every outdegree, the outdegree of every rank, and the neighborhood size within any given hop count from an AS. The preliminary results also show that only the random topologies generated by the Inet model have the power-law relationships similar to those of the Internet. Unfortunately, these random topologies do not exhibit the exponential growth observed of the Internet. A new Inet topology generator, called New Inet,was constructed to generate topologies exhibiting both the power law relationships and exponential growth rates over time.<br\/><br\/>The research proposed here consists of three parts:<br\/>1. To investigate whether or not proposed topology models are in fact capturing the essence of certain underlying network design mechanisms or engineering constraints that result in random topologies that perforce exhibit many of the empirically observed phenomena. To this end the PIs focus on two particular approaches concerning the emergence of scaling phenomena associated with Internet-like graph structures in the context of the models of Barabasi and Albert [BAJ99, BA99] and of Carlson and Doyle [CD99a, CD99b].<br\/>2. An in-depth analysis of the properties of connectivity graphs at the intra-AS level. In particular, the Pis are interested in large ASs spanning wide geographic area.<br\/>3. To determine if trees constructed from a given graph can serve as a \"fingerprint\" of the graph from which various properties of the graph can be derived; and to model policy routing on the Internet as such trees. In particular, the PIs want to check whether these tree structures exhibit scaling laws that have been found ubiquitous in the context of river networks such as the Horton-Strahler laws [Hor45, Str57].<br\/> The PIs propose to continue studying AS-level connectivity data made available by the National Laboratory for Applied Network Research (NLANR) for better understanding of how ASs connect to each other, how this connectivity changes over time, and how each individual AS can be modeled in long-running simulations. Additionally, the PIs also propose to model router-level connectivity within ASs. For this, the PIs have access to intra-AS connectivity information from the AT&T WorldNet backbone.<br\/> Funding for two graduate student research assistants was requested in this proposal. Both students will spend their academic year at the University of Michigan under the supervision of the PI, Sugih Jamin. They will help the PIs carry out research on studying AS-level connectivity, intra-AS connectivity, source-rooted trees constructed from traceroute data, and improve the New Inet random topology generator. During summers, one or both of the students will visit AT&T Labs-Research in Florham Park under the supervision of the co-PI, Walter Willinger, to collect and study data on AT&T WorldNet backbone. To improve the collaboration, the PI and co-PI may also visit each other'ssite during the project.","title":"How to Generate Random Topologies with Internet-like Characteristics","awardID":"0082287","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["551079","201028"],"PO":["250082"]},"54945":{"abstract":"The researchers propose an integrated approach to energy efficient collaborative communication in ad-hoc wireless networks. The interdisciplinary approach will address simultaneously all key levels of system design: data link layer power management, network layer energy, location, and quality of service-based routing, and application layer interfaces.<br\/> The objective is to reduce communication power consumption while simultaneously increasing the communication quality between the collaborators. The model problem assumes that people are interacting via ad-hoc networking integrated into pocket computers for some common task. For the communication to be successfull, all participants must be reachable via the network and have sufficient energy to perform any necessary computation. At the heart of the problem is the distributed scheduling of communication between entities to reduce communication and computation energy. Participants must have an estimate of the remaining energy available by other participants as well as models of the communication topology. Decisions must be made whether to route traffic through adjacent nodes (reducing direct power expenditure while possibly increasing latency or global energy consumption) or increasing transmitter power (potentially reaching a broader set of participants). This objective will be reached by developing design methodologies in the following research areas:<br\/> Link-layer controllers that adaptively learn low-power strategies for error correction <br\/>codes, transmission power levels, and radio activity times for reduced overall power consumption, within the constraints of delay and error bounds.<br\/> Network-layer controllers that use inter-node attenuation, available node energy, and current traffic flows to optimize routing so as to maximize the availability of all nodes.<br\/> Network interfaces that allow the programmer to describe delivery constraints on messages such that communication schedules can reduce energy in a changing routing topology.<br\/> System level power modeling that allows the application layer to trade additional processor power to reduce networking power.<br\/> The project is targeted to the emerging spectrum of highly capable pocket or wearable computers and the ad-hoc networks formed by those computers. The researchers will both deploy an experimental infrastructure and use in-depth simulation models to evaluate our system. The prototype system will use a combination of laptop computers using 802.11 wireless networking and the advanced \"Itsy\" palm-top computer with lower bandwidth (and significantly lower power) interfaces. The simulation models will use realistic whole-system power models for advanced pocket computers coupled with a standard network simulator that we have enhanced with more realistic RF propagation models.<br\/> This project is significant because it address a communication model that will be common with future generation computation and communication devices. It is realistic because it will use an experimental network. It is general because we will be able to use the simulation framework to model future compute and communication networks. Finally, it is achievable because it leverages the on-going work in optimizing channel assignment in wireless networks and energy efficient computing.","title":"ITR: Energy and Quality of Service Aware Ad-Hoc Networking","awardID":"0082998","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["543625","529582"],"PO":["7594"]},"54725":{"abstract":"This project proposes runtime and compiler support that will enable programs to harvest idle SMPs and\/or single processor workstations to perform parallel computations. The unique feature of this system is the ability to adapt parallel programs to the dynamic availability of processors while exploiting the locality within an SMP. The project integrates several goals, namely:<br\/><br\/>1) Extend the Distributed Shared Memory, Strings, to support thread migration, incorporate adaptation to the changing number of available processors at runtime and propose techniques to balance data locality and the parallelism used when the number of processors changes at runtime. <br\/> <br\/>2) Study the impact of eviction time on remapping strategies and constraints. <br\/><br\/>3) Develop compile-time support for parallel programs which can be executed in an environment where the number and the availability of the processors can change.<br\/><br\/>4) Develop analytic models and extensively evaluate the above compiler and runtime techniques using several \"real programs\".<br\/><br\/>5) Integrate the utilization of idle cycles for parallel computing on cluster of SMP workstations into the existing parallelization environment.","title":"ITR: Opportunistic Parallel Computation","awardID":"0081696","effectiveDate":"2000-09-01","expirationDate":"2003-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["402054","558152",139823],"PO":["241298"]},"54846":{"abstract":"Research on Information Technology Transfer (ITT) to developing countries has suffered due to a lack of knowledge about how the process works. Studies have generally been done from a distance and have assumed an acultural environment in which national IT policy plays an unspecified role. Implementation factors have also been missing from the explanatory models. The goals of this project are to test a theoretical model that explains the ITT process and examine the effectiveness of national IT policy in one developing country -- Egypt. Egyptian users of urban\/rural information centers, cybercafes, and ISPs, private and public sector knowledge workers, and national IT policy makers will be sampled. Research methods will include ethnography, interviews, systematic observation, and questionnaires. Drawing from anthropological, economic, and technology innovation and diffusion theories, this research integrates technical and socio-cultural factors within a national setting. Policy makers in developing countries can learn why some policies encourage the process of ITT while others hinder it. Managers in transnational firms charged with introducing IT in foreign subsidiaries, offices, and plants can learn how to better implement IT. This research will result in new knowledge, theories and methods for assessing Information Technology Transfer in other developing countries.","title":"IT Transfer to Egypt: Process Model for Developing Countries","awardID":"0082473","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":[140136,"224018","224019",140139],"PO":["495796"]},"54736":{"abstract":"EIA-0081761<br\/>Zhao, Wei<br\/>Texas Engineering Experiment Station<br\/><br\/>ITR: On a Virtual Laboratory for Network Engineering Educational Programs<br\/><br\/>The primary objective of this proposed research is to investigate issues<br\/>involved in building a virtual laboratory for network engineering<br\/>educational programs. Different from a conventional teaching laboratory,<br\/>the proposed virtual laboratory will not require students to physically<br\/>present in the laboratory rooms, rather they conduct their experiments via<br\/>remote network connections, such as the World Wide Web. The intent is to<br\/>demonstrate that this kind of virtual laboratory facilitates the training<br\/>of IT workers in a significant way: it will reduce the cost, increase the<br\/>facility utilization, and improve the quality of IT courses that are<br\/>experiment-oriented. This project will focus on addressing technical<br\/>challenges that are critical for successful implementation and operation of<br\/>such a virtual laboratory. Configuration and scheduling techniques will be<br\/>studied that provide students with remote but real time access to the<br\/>equipment during their experiments. These kinds of configurations must be<br\/>carried out in an efficient and flexible manner so that a large number of<br\/>students can do their experiments simultaneously. Access control methods<br\/>will also be investigated that deal with the degree of control over network<br\/>components given to the user. The efficacy of diverse access control<br\/>methods will be examined over a range of implemented exercises. The aim is<br\/>to build a virtual laboratory that allows an instructor to choose the<br\/>interplay of operating system support, experiment semantics, and network<br\/>support to best suit the learning environment.","title":"ITR: On a Virtual Laboratory for Network Engineering Educational Programs","awardID":"0081761","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["453727","530863","368857","368857"],"PO":["564318"]},"55715":{"abstract":"With the advances in embedded processors, low cost sensor technologies, and wireless communication, unprecedented amounts of diverse types of information about the real world and its activities are being generated. Much of the information is spatio-temporal in nature; concerning objects dispersed in space and time, and interacting and communicating with each other and their surroundings. An infrastructure that facilitates real-time capture, storage, processing, display, and analysis of the information generated will truly revolutionize a wide variety of application domains. Examples of domains that will benefit from this technology include avionics, ground traffic, commercial applications such as ship-ping and transportation, emergency response and disaster relief operations, physical phenomenon such as weather and storm tracking, forest fire tracking, migration patterns of animals\/birds, command and control, smart environments, etc. Applications in the above domains require real-time monitoring, tracking and analysis of objects\/events\/phenomena in space and time. <br\/><br\/>An integral component of such sensor enriched communication and information infrastructure is a database management technology that allows seamless access to information dispersed across a hierarchy of storage, communication and processing units - from sensor devices, where data originates, to large data banks where the information generated is stored for analysis and mining. This research will explore next generation database management system technology that provides effective support for information processing in highly distributed and dynamic sensor-enriched environments. The approach taken will be end-to-end - that is, research will be conducted on all aspects of the system ranging from representation, data modeling, query languages, data structures, query optimization, query processing, distribution, and concurrent accesses. A prototype database management infrastructure that supports highly dynamic geographically dispersed spatio-temporal data, multi-resolution representation of data, and provides effective support for visualization and analysis will be developed.","title":"ITR: Collaborative Research: Real-time Capture, Management and Reconstruction of Spatio-Temporal Events","awardID":"0086124","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["515756"],"PO":["563751"]},"54868":{"abstract":"Petar M. Djuric<br\/>Project Summary<br\/>Signal processing is an area that already plays a significant role in the current GSM and IS-95 systems.<br\/>This role will only increase in the projected third generation wireless communications, and in fact, the<br\/>success in implementing these systems will strongly depend on the ability of the signal processing methods<br\/>to resolve the new technical problems that will emerge with it. The underlying technology of the third<br\/>generation systems will be based on the wideband CDMA (WCDMA) modulation scheme. In the core<br\/>of this technology will be sequential signal processing algorithms with abilities to capture fast-changing<br\/>characteristics of transmission channels very quickly and to exploit known system information optimally.<br\/>The significant advances of latest CDMA signal processing methods notwithstanding, it is clear that the<br\/>requirements for much lower bit error rates than in current systems will markedly increase the demands on<br\/>signal processing capabilities of sequential algorithms for WCDMA signals. Additional challenge arises due<br\/>to complexities that are a result from the need to handle high data rates and users with high mobility. Since<br\/>the communication channels will be rapidly time varying, the signals will undergo quick attenuations and the<br\/>new algorithms on channel estimation and tracking, channel equalization, interference rejection, and RAKE<br\/>receiver adaptations must have extremely fast convergence rates. The objective of the proposed research is<br\/>to develop algorithms that will meet the challenges of this new technology.<br\/>The basic methodology for the proposed processing of WCDMA signals will be based on particle filters, which recently have gained much attention for their potential in handling nonlinear and non-Gaussian<br\/>models. The underlying principle used in the design of such filters is the representation of the posterior<br\/>distribution of state variables (the unknowns of the system) by a set of particles (samples). Each particle<br\/>is given an importance weight so that the set of particles and their weights represent a random measure<br\/>that approximates the desired posterior distribution. The particles may also represent means of density<br\/>functions, usually Gaussians, in which case the particles have additional variables, the covariances of the<br\/>Gaussians. As new information becomes available, these particles propagate recursively through the state<br\/>space and their weights are modified using the principles of Bayesian theory. There are several ways of<br\/>applying particle filters including sampling-importance-resampling, mixture Kalman filtering, and Monte<br\/>Carlo and Metropolis-Hastings importance resampling. These approaches have their advantages and disad-<br\/>vantages in performance, and impose different demands for real-time implementation. In the proposal, new<br\/>schemes will be studied that naturally combine the best features of the existing schemes, and tailor them<br\/>for processing of WCDMA signals. Not only will the new schemes be able to replicate or surpass the best<br\/>possible performance of the known methods, but they will also be general enough to provide foundations for<br\/>development of new task specific schemes.<br\/>Four important topics will be investigated. The first is the examination of fundamental schemes for<br\/>propagation of state particles. This issue is critical for two important reasons: (a) it aspects the performance<br\/>of the algorithm and (b) it subsumes the implementation, which although parallelizible, is in some cases too<br\/>computationally demanding and therefore not too practical. The second topic is task specific and is related<br\/>to multiuser detection and channel estimation as well as exploitation of the physical characteristics of the<br\/>channel and the base station\/mobile asymmetry for development of improved algorithms. The third one<br\/>is examination of the flexibility of the proposed methodology and the interaction of the various algorithms<br\/>and tasks in order to improve their performances and robustness. Finally, the fourth topic will be related to<br\/>investigation of computational requirements, and structures that would allow for real-time use.","title":"ITR: Sequential Signal Processing Methods for Third Generation CDMA Signals","awardID":"0082607","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["563567"],"PO":["564898"]},"52448":{"abstract":"EIA-0072744<br\/>Bohringer, Karl<br\/>University of Washington<br\/><br\/>CISE Postdoctoral Associates in Experimental Computer Science: Probing<br\/>Neural Substrates of Behavior<br\/><br\/>The focus of our multi-disciplinary research program is the development of<br\/>tools and techniques for multisite intracellular recording in freely<br\/>behaving animals. More specifically, we are involved in a<br\/>multi-investigator effort to implant a microcomputer into the brain of a<br\/>marine mollusk, for the purpose of recording neuronal signals. This effort<br\/>comprises three main thrusts: (1) to develop silicon microcomputers that<br\/>can record from, and communicate with, multiple neurons in an intact<br\/>animal; (2) to develop multi-site intracellular probe arrays, and the<br\/>techniques for attaching these arrays to nervous tissue without damaging<br\/>either probes or tissue; and (3) to develop neurophysiological preparations<br\/>and techniques for surgically implanting both microchips and probe arrays<br\/>in live, freely behaving animals, and for recording from these animals in<br\/>their natural environment for several hours.","title":"CISE Postdoctoral Research Associates in Experimental Computer Science - Probing Neural Substrates of Behavior","awardID":"0072744","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["557263"],"PO":["289456"]},"54758":{"abstract":"The Internet is used by a rapidly expanding and changing set of applications. The need for the network to evolve and even to provide application specific processing is significant. However the current network infrastructure is hard to evolve and does not readily support customizability. The goal of Active Networking [21, 3, 2] is to facilitate this evolution and customization by making the network infrastructure programmable. One way of adding programability is to allow code to be down-loaded into the routers, thus enabling the addition or modification of services. A more radical approach is to allow the packets themselves to carry programs to be executed selectively on the network's routers. Among other issues, these two approaches increase the possibility of denial of service attacks whereby a user places excessive demands on network resources in order to deny access to another user. However, they also enable new approaches to handling such attacks and to addressing the general problem of allocating resources within the network.<br\/><br\/>The proposed research focuses on issues involving programmable, or active, packets. Active packets facilitate denial of service attacks in several ways. First, unlike conventional data transport packets, an active packet may require processor cycles and memory at the routers beyond those needed to simply forward the packet. Second, in general, the execution of an active packet at a router may cause more than one active packet to be transmitted from the router. Such behavior is useful, since it allows a packet to fan out across the network, but it is potentially dangerous since it can lead to an exponential growth in the resources used by a single initial packet. Experience with active packet-based systems [9, 8, 23, 22, 24] suggests that denial of service is the single biggest obstacle which must be overcome before such systems are feasible.<br\/><br\/>The proposed research tackles this problem along various fronts. First, the researchers propose to design packet programming languages that make some types of behavior intrinsically impossible. For example, in PLAN [9], packet programs are guaranteed to terminate and thus can never use an un-bounded number of router cycles. The researchers will explore tradeoffs between restricting behavior in terms of resource requirements and limiting the expressibility and thus the flexibility of active packets. However, not all potentially harmful behaviors can be eliminated in this manner. Thus, on a second front, the researchers will consider mechanisms that explicitly account for a packet's resource usage in the network. For example, each packet may carry a resource bound, which is decremented as resources are used, and which triggers termination when the bound is used up. The proposed research combines both implicit and explicit mechanisms for controlling resource usage, with algorithms to control the flow of traffic into the network to decrease the likelihood of denial of service. More generally, one can envisage assessing costs to active packets that execute on congested resources. Thus, on a third front, the researchers propose to investigate mechanisms based on congestion costs to achieve more efficient resource allocations and how they can be facilitated via active packets.<br\/><br\/>Three methodologies will be used to validate proposed solutions. First, the researchers will draw on mathematical modeling to motivate the benefits and investigate the characteristics of the proposed solutions. Second, the researchers will leverage expertise and past work on implementing active networks to demonstrate what is feasible to build, and explore the constraints each solution will place on eventual applications. Finally, the researchers will use network simulation to investigate systems on a scale not achievable on the experimental testbeds.","title":"ITR: Collaborative Research: Resource Allocation and Denial of Service Prevention in Active Networks","awardID":"0081901","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["527253"],"PO":["250082"]},"54648":{"abstract":"EIA-0081102<br\/>Rosson, Mary<br\/>Virginia Polytechnic Institute and State University<br\/><br\/>ITR: Universal Access to Programming-- A Cross-Generational Learning<br\/>Community<br\/><br\/>Issues of lifelong learning can be addressed by informal education--<br\/>voluntary and self-directed learning activities taking place in diverse<br\/>settings (often outside traditional classrooms) that incorporate a variety<br\/>of learning methods and are motivated by intrinsic interests such as<br\/>curiosity, completion of a task itself, or social interaction. The<br\/>voluntary and self-directed nature of these informal activities make them<br\/>ideal for reaching populations outside traditional education settings.<br\/>With respect to informal education on programming, modern visual simulation<br\/>environments have many features that make them appealing. This research<br\/>will investigate the effectiveness of a state-of-the-art simulation<br\/>programming environment as support for informal education of a diverse<br\/>population of end-user programmers within the context of an ongoing<br\/>research project on community network infrastructure. Key research<br\/>objectives include:<br\/><br\/>* Characterization of the programming literacy gained through visual<br\/>simulation programming and a determination of how this knowledge and its<br\/>accusation is mediated by the maturity and background of end users.<br\/><br\/>* Analysis of the role of the existing local community as a learning<br\/>community in building and maintaining the programming skills of end users<br\/>of varying ages and roles.<br\/><br\/>* Prototyping and evaluating a framework for cumulating and sharing the<br\/>artifacts and practices of end-user programming within the learning<br\/>community.","title":"ITR: Universal Access to Programming--A Cross-Generation Learning Community","awardID":"0081102","effectiveDate":"2000-09-15","expirationDate":"2003-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1359","name":"RES EXP FOR TEACHERS(RET)-SITE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["549541","549540"],"PO":["564181"]},"54769":{"abstract":"EIA-0082001<br\/>Shim, Jung<br\/>Mississippi State University<br\/><br\/>ITR: E-business and Business Telecommunications Center<br\/><br\/>This proposed research is for planning the development and expansion of<br\/>research, training, and education in electronic business (e-business) and<br\/>telecommunications of an information systems program. Collaborative<br\/>research, enhanced course offerings, equipment, and industry partnerships<br\/>would result in new methods for educating citizens in information<br\/>technology (IT), expand the supply of entrants into IT professional jobs,<br\/>and increase the breadth and depth of existing computer science,<br\/>information systems, and marketing programs. Research in<br\/>telecommunications would be expanded to involve experimentation with remote<br\/>teleconferencing systems to conduct IT work. Other foci include anywhere,<br\/>anytime training over the Internet and experimentation with the<br\/>effectiveness of video distance training methodologies. The overall goal<br\/>would be to expand education and training efforts to form a regional center<br\/>for the production of bachelor degree students with concentrations in<br\/>e-commerce and telecommunications along with technical Internet-oriented<br\/>coursework. In addition, faculty and graduate students would have<br\/>opportunities to extend their training through telecommunications and<br\/>e-business oriented training workshops.","title":"ITR: E-business and Business Telecommunications Center","awardID":"0082001","effectiveDate":"2000-09-01","expirationDate":"2001-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["175521","187305",139944],"PO":["564318"]},"56848":{"abstract":"Institution: University of Virginia<br\/>Proposal Number: EIA 0089959<br\/>PI: Joanne Cohoon<br\/>Title: Departmental Factors in Gendered Attrition from Undergraduate IT Majors<br\/> <br\/>This CISE Information Technology Workforce (ITW) proposal requests funds to address the disproportionate loss of women from undergraduate programs in computer science. The objectives are to profile the top-producing U.S. computer science departments, to identify the departmental characteristics and practices that affect equal retention of male and female computer science majors, and to disseminate this information and make recommendations for action based on the study results. One component of the project will be a survey of chairpersons and faculty from 227 computer science departments. Fifteen of these departments will be randomly selected for on-site interviews of chairpersons, faculty, and students. This project has the potential to provide significant insights about what kind of educational environment is likely to retain female students in computer science at rates comparable to male students.","title":"ITW: Departmental Factors in Gendered Attrition from Undergraduate IT Majors","awardID":"0089959","effectiveDate":"2000-09-15","expirationDate":"2005-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["464116","424949","513746"],"PO":["289456"]},"56859":{"abstract":"Institution: Georgia State University Research Foundation, Inc.<br\/>Proposal Number: EIA 0089995<br\/>PI: Paula E. Stephan<br\/>Title: Retention of Women and Minorities in the IT Workforce<br\/><br\/>This CISE Information Technology Workforce (ITW) proposal requests funds to study whether women and underrepresented minorities either trained in IT or employed in IT careers have different rates of retention and advancement. The study also examines whether the rate by which individuals not trained in IT are absorbed into IT jobs differs by gender and minority status. The study will use the NSF's SESTAT database, which is a comprehensive, integrated database containing information over time on the employment, educational, and demographic characteristics of scientists and engineers who possess at least a bachelor's degree. This project has the potential to provide valuable insights about the retention and advancement of women and underrepresented minorities in IT careers.","title":"ITW: Retention of Women and Minorities in the IT Workforce","awardID":"0089995","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["436633",146310],"PO":["564181"]},"48807":{"abstract":"PI: Steven Homer<br\/>Proposal Number: 9988310<br\/>Institution: Boston University<br\/><br\/>Abstract<br\/><br\/>Two complementary areas of computational complexity theory will be studied. The first is the complexity of quantum computing, a project that my colleagues and I have begun work on during the past two years. To this point two projects have been completed, both concern finding lower bounds for classes of quantum computations. I propose to continue to explore the power of quantum computation and try to obtain both lower and upper bounds by relating quantum classes to classical complexity theory. The second area concerns the study of the complexity theory of natural combinatorial functions in PSPACE. Here the goal is to make use of the extensions of the polynomial hierarchy, which were defined and explicated in an earlier paper on the hyperpolynomial hierarchy. Tools such as the NP-jump and the methods of Toda's theorem will be studied and extended in order to classify counting problems and other natural complex problems in PSPACE. We intend to explore this new framework for the classification of optimization problems and to study the relationship between older notion such as alternation and the extended polynomial hierarchies which we have defined.","title":"Quantum Computation and Complexity Theory","awardID":"9988310","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["449081"],"PO":["543507"]},"48829":{"abstract":"CCR-9988357<br\/>J Strother Moore & Chandrajit Bajaj<br\/>U Texas Austin<br\/><br\/>The proposed work will enable real-time interrogative visualization and steering of<br\/>the data-intensive computations of applied symbolic logic, in support of hardware<br\/>and software verification. <br\/><br\/>The microprocessor industry is finding increasing use for mechanized formal methods:<br\/>the mathematical specification and mechanized symbolic analysis of hardware and<br\/>software systems. For example, the ACL2 theorem prover has been used by Advanced<br\/>Micro Devices, Inc., to find bugs in the AMD-K7 TM floating-point hardware, bugs<br\/>that had escaped over 80 million test vectors. Theorem provers also enable symbolic<br\/>simulation of new designs from formal specifications and security analysis of<br\/>devices for use in e-commerce (see below). Such applications represent the practical<br\/>emergence of applied symbolic logic.<br\/><br\/>Formal logic is the mathematical tool of choice for modeling computing<br\/>systems, in exactly the same sense that differential equations are the tool of<br\/>choice for modeling physical systems. While study of logic is well established, the<br\/>application of logic is new, because until the invention of the digital computer,<br\/>engineered artifacts were essentially mechanical. The semiconductor industry is now<br\/>turning to logic-based mechanized tools because models of modern processors are too<br\/>complex to analyze any other way; and that complexity cannot be eliminated because<br\/>it is used to buy speed and speed provides the competitive edge. <br\/><br\/>The semi-automatic theorem provers that make such analysis possible are industrial-<br\/>strength symbol manipulation engines. These engines process symbolic data<br\/>representing logical formulas. Intermediate formulas may consume megabytes of<br\/>storage. The engines explore vast search spaces determined by thousands of<br\/>definitions and theorems in data bases created by various design team members.<br\/>Proofs may contain millions of primitive inference steps. The engines use decision<br\/>procedures where feasible and are otherwise guided both by heuristics and the human<br\/>user.<br\/><br\/>Due to the computational intensity of the problem, today's semi-automatic deduction<br\/>engines are designed for use in an iterated guess style, where the guess<br\/>determines the search space. When a proof attempt fails, the rea-son is often<br\/>mathematical rather than search-strategic. The user's role is creative: diagnose the<br\/>problem and invent the mathematical abstractions necessary to facilitate proof. This<br\/>may require defining new formal concepts to state generalizations or decompositions.<br\/>Such input from the user fundamentally alters the search space.<br\/><br\/>The research proposed here will produce a new paradigm for semi-automatic theorem<br\/>provers in which the user steers the system in real time. Visualization paradigms<br\/>for symbolic data and symbolic manipulation will be developed, including what we<br\/>call symbolic spreadsheets which allow inter-related symbolic data to be displayed<br\/>coherently. The search space will be explicit, visible and dynamically computed.<br\/>Structure will be imposed via the definitions and lemmas in the data base. Four<br\/>fundamental research topics will be addressed: (i) selection of the abstract<br\/>entities to be visualized, the visual reification of these abstractions, and the<br\/>requirements for effective steering; (ii) visualization algorithms for efficient<br\/>display and interrogation of symbolic logical data and processes; (iii) theorem<br\/>proving algorithms producing human surveyable proofs while allowing real-time<br\/>interaction; and (iv) a client\/server model of semi-automatic theorem proving<br\/>allowing the visualization and deduction engines to be decoupled but interoperable.<br\/><br\/><br\/>This is an ideal setting in which to study the visualization of symbolic data<br\/>processing, with a clear path to immediate and critical applications in the<br\/>semiconductor industry and, due to the pervasiveness of formal systems in computing<br\/>(e.g., programming languages) promising connections to much wider applications. The<br\/>research will deeply affect both applied logic and visualization.","title":"Formal Methods Visualization","awardID":"9988357","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["517319","428590"],"PO":["532791"]},"52702":{"abstract":"Current microprocessors, which have much wider data-paths than 8 or 16 bit data-words required by multimedia workloads, are attempting to take advantage of this by offering special multimedia instructions. These extensions are a set of short SIMD or superword operations. It has been shown that short SIMD operations are well suited to exploit a fundamentally different type of parallelism than the vector parallelism associated with traditional vector supercomputers. This parallelism is denoted as Superword Level Parallelism (SLP) since parallelism comes in the form of superwords containing packed data.<br\/><br\/>In this project, compiler algorithms for detection and exploitation of superword level parallelism are investigated. The compiler is extended in many directions, from dataword prediction to SLP aware register allocation, to take advantage of superword level parallelism and an extensive evaluation of these techniques is performed. Architectures that can take full advantage of SLP are also investigated in this research. Scaling the data-paths is a simple and straightforward use of the available silicon area. However, there are novel architectural features that can take full advantage of superword level parallelism.","title":"Exploiting Superword Level Parallelism","awardID":"0073510","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["382922"],"PO":["180163"]},"54902":{"abstract":"Application Service Providers (ASPs) - which distribute the use of software, rather than the software itself, via the Internet - are increasingly coming to be seen as one of the next major elements in the development of network services. This project will study and test the application of the ASP concept in an area where it is likely to have a particularly great influence: software for large-scale optimization. The complexity and variety of optimization software present challenging obstacles to the development of network services, but the exceptional variety and modularity of this software insure that successful efforts will have a broad impact in science, education, and business.<br\/><br\/>Technically, the project will build on previous work by the Optimization Technology Center of Northwestern University and Argonne National Laboratory. One subproject will investigate resource allocation for optimization requests whose needs cannot be easily forecast. Others will involve the design and testing of both client-side and server-side object class libraries that have no models in current mathematical computation. The project will also include the automation of algorithm choice and solver scheduling, through the construction and use of a database to learn from results of previous optimization requests and from human experts. The project thus brings together methods, software, and systems for computational large-scale optimization, with the aim of making the impressive technology in this area more accessible for applications, algorithm development, and education.","title":"ITR: Advanced Application Service Provider Technologies for Large-Scale Optimization","awardID":"0082807","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["224072","428505"],"PO":["565272"]},"52724":{"abstract":"The primary objective of the project is to investigate techniques to utilize control independence and compiler-directed multi-threading to exploit instruction-level and thread-level parallelism from ordinary programs. <br\/><br\/>The first step involves investigating the science of ILP that is present when utilizing control independence and multi-threading. Some of the questions that are addressed are: what is required to exploit parallelism, how much of the parallelism can be exploited by simple techniques such as predicated execution or data value prediction, how far should instructions be moved (statically or dynamically) to exploit it how is it impacted by practical considerations, how can it be enhanced by software transformations, on which portions of the code should software transformations be carried out and what should the nature of these transformations be, and what are the characteristics of the storage needed to exploit the available parallelism?<br\/><br\/>The second step involves investigating hardware and software techniques to exploit the benefits of control independence and data speculation in a multi-threading environment. In particular, the use of novel methods to represent\/specify control independence (and data independence) is investigated. Issues relevant to multi-threading, such as tradeoffs between the number of speculative paths and performance are also studied using detailed simulation models.","title":"Utilizing Control Independence and Multi-Threading to Exploit P","awardID":"0073582","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["225924"],"PO":["551992"]},"51767":{"abstract":"With the advent of third and fourth generation wireless infrastructure, and the simultaneous emergence of pervasive connectivity for all devices based on bluetooth like systems and ad-hoc networks, a new vista is open for research in the area. We propose ideas for a research program aimed at realizing ubiquitous computing systems) which are located in vicinity of one another. These systems will be composed of a collection of independently designed components that automatically become aware of each other, establish basic (wireless) communication, exchange information about their capabilities and requirements, discover and exchange APIs, and learn to cooperate effectively to accomplish their individual and collective goals. The proposed work will enable a new class of applications that effectively use mobility and pervasive computing. We address several research problems that span the fields of distributed computing, data management, and dynamic collaboration between components. The team of researchers is located at UMBC and UI-Chicago, and plans to interact closely with collaborators at industrial labs (IBM, Hughs, Sun).","title":"Dynamic Negotiating Agents in Mobile Computing","awardID":"0070738","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["557651"],"PO":["309350"]},"54814":{"abstract":"Multicast is a network service for delivering the same data to multiple destinations. A wide range of emerging network applications - such as multi-participant video conferencing, multi-party interactive games, distance learning, group collaboration, and resource location - can greatly benefit from this service.<br\/> In this project, the researchers will develop congestion control protocols for IP multicast to support scalable and efficient dissemination of layered data to a large number of receivers in heterogeneous, dynamic networks. The researchers will investigate the use of an integrated set of three distinct mechanisms - per-group feedback-based transmission adjustment, selective participation, and menu adaptation - to solve the general multicast congestion control problem. These mechanisms will operate at different time-scales and distribute the responsibility of adaptation to different entities in the network. The researchers will experimentally evaluate the scalability and performance of protocols in a large-scale network environment where the multicast session shares network with other unicast and multicast sessions, receivers join and leave the network, and the bottleneck links and bandwidths fluctuate over time. The researchers will implement multicast congestion control protocol in the network testbed of programmable routers, based on the Internet eXchange Architecture (IXA). The outcome of the research will be a family of algorithms, protocols, and prototype implementations that will significantly advance the state of art in designing multicast congestion control protocols.","title":"Multicast Congestion Control Protocols","awardID":"0082294","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["261975"],"PO":["250082"]},"54946":{"abstract":"This project will build a new generation of numerical simulation systems by creating a feedback path between physical experiments and numerical solvers. There are a number of exciting implications of this data-adaptive simulation idea. Engineering fluid flows are inherently complex. This complexity limits measurement and precision, so engineers are forced to work with fluid flows based on very sparse information. Numerical solvers, on the other hand, can resolve tiny flow structures, but they generally run in an open-loop mode and are thus unverified. Coupling the two forms of technology offers powerful advantages to each. Comparisons against live experimental data will allow simulation algorithms to be verified quantitatively, in detail, and in-line. Once it is verified in this fashion, one can use the simulation with confidence on related problems. Once can also use the sensor information to correct the solver's data, or even to adjust the solver parameters on the fly. Moreover, once the solver is properly synchronized with the real system, one could use the former to explore the physics of the latter in more detail than sensors would allow - and still trust the results.<br\/><br\/>A particularly compelling application area for data-adaptive simulation techniques is microelectromechanical systems (MEMS). This emerging technology is driving a revolution in engineering design that is placing new demands on numerical simulation. Accurate modeling of the interaction of tiny, flexible, moving structures with high-speed chaotic fluids is challenging. To resolve the fine details in this kind of simulation, computational fluid dynamics technology requires extremely fine meshes and the solution of very large systems of nonlinear equations. This makes it difficult to build production-quality computer-aided design (CAD) tools for MEMS, which in turn forces engineers to fabricate devices without testing them. Functional CAD tools would allow MEMS designers to achieve one-pass design, much as VLSI does now.","title":"ITR: An Interactive Experimental\/Numerical Simulation System with Applications in MEMS Design","awardID":"0083004","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["531245","517075","530767"],"PO":["551992"]},"54715":{"abstract":"The objective of this research is to determine how best to design computer systems for collecting <br\/>data from (rather than providing data to) users. Government agencies might use such systems to gather the factual data used to calculate the unemployment rate or the Consumer Price Index. Three sets of laboratory experiments focus on actual and simulated desktop (i.e., keyboard and mouse entry) and speech survey interviewing systems. The first set of studies examines response accuracy and user satisfaction with systems that monitor users' speed of responding and speech patterns in order to diagnose when users misinterpret concepts in the survey questions and could use additional clarification. The second set of studies examines user response accuracy and satisfaction with interfaces that do (or do not) tailor this clarification through dialogue. The third set of studies contrasts interfaces that require users to educate themselves about how the questions should be interpreted with interfaces that engage users in dialogue to figure out the correct answer. The project uses the methods of experimental psychology to provide guidelines for future development of interfaces that collect information from users. This research could significantly improve the accuracy of data collected online by government agencies and others.","title":"ITR: Adaptive Interfaces for Collecting Survey Data from Users","awardID":"0081550","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["455453","552787"],"PO":["495796"]},"52779":{"abstract":"Internet traffic has increased at an exponential rate over the past decade. Much of recent explosion in Internet data can be attributed to the phenomenal growth in the number of new users, the migration of corporate data to the Internet, and a surge in usage of multimedia as a content delivery medium. As a result, Internet traffic has doubled every few months and shows no signs of slowing down. Another development is the ever increasing demand for multimedia applications such as ReadAudio, Windows Media and others. These applications would benefit greatly if the underlying network infrastructure provided some form of Quality of Service (QoS) guarantee.<br\/> Attempting to keep pace with the bandwidth and other QoS requirements for multimedia applications, network equipment vendors and Internet service providers have continuously developed and deployed faster routers and higher speed links at the edges of backbone networks. Yet current demand for QoS guarantees within the routers still far exceed the supply. Recent development of Internet differentiated services (DiffServ) aims to provide services such as premium and assured services in addition to the existing best-effort service within routers in order to satisfy the demand for bandwidth and other QoS requirements. However several routing problems with respect to QoS guarantees are still open.<br\/> The researchers will investigate the limitations of the current IP routers and their routing algorithms leading to the development of a high-performance QoS routing framework. The researchers will apply two major ideas: differentiated routing, deploying different types of routing protocols for different service classes in an integrated fashion, and parallel algorithms and structures within the routers to decrease the routing overhead. Hence, primary objectives of the proposed framework are to implement and theoretically support two innovative elements: (1) differentiated routing services and protocols to provide differentiation in routing decisions depending on QoS requirements, and (2) a QoS-aware router architecture with parallel computation on multiple general purpose processors to achieve cost effective, scalable and high-throughput routing.<br\/> The first objective, exploration of differentiated routing, will allow the researchers to provide QoS-aware routing decision solutions within DiffServ networks. The second objective, investigation of parallel algorithms and structures within a QoS-aware router architecture, will allow the researchers to provide fast solutions, hence low per-packet routing overhead, to three major problems within DiffServ routers: routing table computation, packet forwarding and packet scheduling.<br\/> To achieve these two objectives, the researchers will investigate concepts and theoretical framework for high-performance QoS routing, and verify concepts and theoretical framework via simulations and prototype implementation.<br\/> What makes this research feasible and promising are recent developments in QoS-aware systems, parallel algorithms and end-to-end QoS routing algorithms. These components make it possible to support flexible and generic high-performance QoS routing framework, accessible to any distributed multimedia applications.","title":"High Performance QoS Routing","awardID":"0073802","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["561784"],"PO":["565090"]},"55705":{"abstract":"A necessary step towards the goal of building more reliable software systems, on time and within budget, is to establish an institutionalized empirical discipline for understanding causal relationships among the processes, components, and technologies that affect the building of systems. As in the physical and natural sciences, experimentation in software engineering requires a community with support for collaboration, experimental replication and refinement, and sharing of experimental data and results.<br\/>For these reasons the Center for Empirical Software Engineering Research (CESER) undertakes original empirical research and is developing a prototype system for sharing and evolving the results of such research with a community of affiliated researchers and practitioners. CESER develops and refines techniques to increase the descriptive and predictive power of empirical models, and studies specific software development technologies to enable industrial organizations to understand the benefits and drawbacks of those technologies in their specific context. The Center provides courses and symposia on empirical methodologies and results, and assists the use of empirical knowledge in software engineering education. The Center's initial focus is on empirical studies of software COTS integration and software quality improvement phenomenology.<br\/>The center is initially organized as a collaborative effort among the University of Maryland, the Fraunhofer Center - Maryland, the University of Southern California, the University of Nebraska at Lincoln, and Mississippi State University.","title":"ITR: Collaborative Research for a National Center for Empirical Software Engineering Research","awardID":"0086078","effectiveDate":"2000-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["262266",142819],"PO":["564388"]},"54616":{"abstract":"EIA-0080926<br\/>Moreno, Oscar<br\/>University of Puerto Rico-Rio Piedras<br\/><br\/>MII: Infrastructure for a New Program in Computer Science at the University of Puerto Rico - Rio Piedras Campus<br\/><br\/>This project focuses on establishing a Division of Computer Science at the University of Puerto Rico-Rio Piedras (UPR-RP). Specifically, the project will involve: (i) cooperation with University of Puerto Rico-Mayaguez to offer a joint Ph.D. program in computing and information sciences and engineering, (ii) enhancement of cutting-edge computer science research at UPR-RP, (iii) increase in the number of underrepresented students completing a Ph.D. in computer science and (iv) increase in the production of cutting edge research projects in computer science. The new equipment will be used to enhance existing research activities at UPR-PR and to attract four new faculty who have a proven ability to engage in cutting edge research. The grant will support directly nine graduate students.<br\/><br\/>.","title":"CISE MII: Infrastructure for a New Program in Computer Science at the University of Puerto Rico - R\u00edo Piedras Campus","awardID":"0080926","effectiveDate":"2000-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7399","name":"CISE MINOR INST INFRA (MII) PR"}}],"PIcoPI":[139519,"255932",139521],"PO":["297837"]},"54737":{"abstract":"With the high levels of system-level integration for electrical systems available today, tools for simulation and test of complex mixed-technology systems are urgently needed. Circuit simulators such as Spice are not adequate for simulating large circuits due to large run times. Even behavioral level simulation is too slow for the large numbers of simulation runs needed to do simple things such as design centering and fault simulation. The key thrust of this research is to develop new simulation algorithms that significantly speed up the process of design and test of complex mixed-signal\/mixed-technology systems. The algorithms will quickly assess the merits of mixed-technology system design perturbations. The key observation is that the impact of design perturbations on the relative performance of the designs can be assessed accurately by approximate simulation methods, rather than by expensive exact simulation. These techniques are expected to speed up evaluation of design transformations for optimization of complex systems and test optimization by three orders of magnitude.<br\/><br\/>The project has three specific goals. First, it will develop techniques for fast time and frequency domain approximate numerical simulation of mixed-technology systems. Second, it will develop algorithms for fast time and frequency domain approximate spatial simulation of mixed-technology systems by partitioning the system into blocks that can be simulated under \"open-loop\" conditions. Third, it will develop techniques for fast time and frequency domain approximate numerical and spatial simulation. The project will accomplish this by combining the first two techniques.","title":"ITR: Fast Approximate Simulation Methods for Rapid Design and Test of Complex Electrical Systems","awardID":"0081769","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["550643"],"PO":["562984"]},"54748":{"abstract":"The goal of this project is to develop new tools based on the notion of \"discreet proof\" for ensuring security of electronic-commerce transactions. This type of proof is \"discreet\" in the sense that it reveals no more than is strictly necessary for the purposes of a given transaction. Discreet proofs are useful in providing authenticity, confidentiality, anonymity, accountability, and other properties often needed to ensure security of a transaction. For example, discreet proofs can be used to decouple the information in a medical database<br\/>regarding a patient's medical condition and treatment from the patient's identity, thereby protecting the patient's privacy while simultaneously providing accountability in the dispensing of drugs and facilitating the collection of aggregate data for socially desirable goals. Constructing discreet proofs for a given application can be technically challenging. Expected research results include i) software tools to automate the construction of discreet proofs; ii) specific proofs for frequently used cryptographic primitives in<br\/>E-commerce; iii) practical protocols based on discreet proofs for E-commerce applications. Through its educational component, the project is expected to increase the pool of adequately trained personnel in the growing area of E-commerce.","title":"ITR: Discreet Proofs for Electronic Commerce Applications","awardID":"0081823","effectiveDate":"2000-09-01","expirationDate":"2003-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[139885,"381930"],"PO":["561889"]},"54649":{"abstract":"EIA-0081112<br\/>Twidale, Michael<br\/>University of Illinois at Urbana-Champaign<br\/><br\/>ITR: Interfaces for Supporting Over-The-Shoulder Learning<br\/><br\/>For many people, a key form of learning how to use software, for example,<br\/>is not by taking a training course, nor reading a manual or online help, or<br\/>experimenting with the software. Instead they may lean over the shoulder<br\/>of a colleague at work and ask for help. This over-the-shoulder-learning<br\/>(OTSL) is important to study to understand more about its relative<br\/>importance and the circumstances in which it is and is not successful.<br\/>Building on prior work studying informal collaborative help in libraries<br\/>and offices, the research will address how often OTSL occurs and its<br\/>significance as a way of learning, possible genres of OTSL, the evolution<br\/>of learning a software application over time, the resources people use to<br\/>support OTSL, barriers to OTSL as currently practiced, and the skills of<br\/>efficient help-giving and determining how these skills may best be taught.<br\/>This work will help determine the functionalities that have the greatest<br\/>potential for improving the effectiveness of OTSL and contribute to<br\/>fundamental research in user interface design and computer-supported<br\/>cooperative work and learning.","title":"ITR: Interfaces for Supporting Over-The-Shoulder Learning","awardID":"0081112","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[139604,"447954"],"PO":["564318"]},"51933":{"abstract":"EIA-0071126<br\/>Nass, Clifford<br\/>Stanford University<br\/><br\/>Digital Government: Information Technology Accommodation Research: Open a Door to Universal Access<br\/><br\/>This proposal describes a collaborative research project involving: Stanford University, Social Security Administration, Census Bureau, and General Services Administration (GSA). The goal of this research is to enable the partner agencies to better accommodate blind and visually impaired computer users, and to permit development of newer, smaller accessor systems for use with the Total Access System, a technology under development at Stanford. The long-term goal of this project is to create enabling technology that supports disabled members of the workforce at the Census Bureau and other Federal agencies and to transfer these technologies to the private sector.<br\/><br\/>The research will be conducted over a three-year period. Year one will focus on the research to select and evaluate appropriate technologies and develop a prototype access system for the blind and to document its usability. During year two, the prototype will be improved based on usability test results and the Total Access System technology will be upgraded. Key technologies necessary for development (multi-modal input and miniaturization) will be developed and prototyped. The third year will bring these technologies together in a kiosk prototype.","title":"Digital Government: Information Technology Accomodation Research: Open a Door to Universal Access","awardID":"0071126","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6846","name":"UNIVERSAL ACCESS"}}],"PIcoPI":["513294",132553],"PO":["371077"]},"54914":{"abstract":"The Internet is governed by a compendium of protocols spanning a number of functionalities including congestion control, routing, multicast, label switching, resource reservation and admission control, error control, and network management. These protocols engage in control actions at multiple time scales, from microseconds for routing and label switching, to milliseconds for congestion control, and the several second range for multicast, routing table updates, and network management. The behavior and performance of a network system is influenced by the workload that drive the protocols - reliable transport of heavy-tailed files, QoS-sensitive streaming of VBR video and audio, burstiness of connection arrivals, skewed make-up of short- and long-lived flows, and self-similar burstiness of multiplexed traffic - with Internet workload exhibiting variability and correlation at multiple time scales, from multiplicative scaling observed for IP flows in the millisecond range, to long-range correlations present in the second range.<br\/> With QoS emerging as a unifying umbrella under which the various network subsystems can<br\/>be organized and viewed as provisioning user-specified services, the need arises to coordinate and<br\/>integrate the control activities - many of whom have direct impact on end-to-end QoS - such that<br\/>both effective and efficient services can be rendered. In tandem with the QoS integration challenge, the PIs are presented with the opportunity to explicitly exploit the multiple time scale nature of network protocols and Internet workload to affect seemless and predictable services. In the proposed project, the PIs plan to address the following two-pronged problem: (1) exploit multiple time scale property of network protocols to facilitate effective coordination and integration of disjoint network controls for end-to-end QoS, and (2) exploit multiple time scale nature of Internet workload to achieve workload-sensitive traffic controls.<br\/> Problem (1), in turn, is comprised of two key issues: sufficiency or separation conditions under which two network controls - e.g., routing and congestion control-acting at different time scales can be integrated without causing harmful effects with respect to stability and efficiency, and the effective coupling of protocols when time scale separation is not available - e.g., label control and congestion control. Problem (2) consists of three key issues: short-lived connection management using lightweight optimistic control, long-lived connection management using connection duration prediction and multi-layered feedback control, and QoS amplification through workload-sensitive, end-to-end and per-hop control. The two-fold challenge that the PIs plan to attack is grounded in well-defined technical problems, and at the same time, represents an innovative traffic control dimension with broader implications to the next generation Internet.<br\/> The PIs bring expertise in core traffic control areas spanning congestion control (Park), QoS<br\/>routing (Hou), multicast (Hou), label switching (Park), and traffic modeling (Park). Both PIs<br\/>have significant experience in performance analysis and protocol design, and they complement each other's strengths with respect to simulation (Hou) and implementation (Park) based performance evaluation. The PIs will leverage existing benchmarking platforms - the Purdue Infobahn QoS testbed comprised of Cisco 7206 routers (Park) and the NetSim performance evaluation environment (Hou) - to implement, test, and benchmark the protocols. The research results, technology demonstration, and software prototypes will be made available through the Web to academic institutions, industrial affiliates, and the networking community at large.","title":"ITR: Multiple Time Scale Traffic Control for Next Generation Internets","awardID":"0082861","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["342042","409715"],"PO":["250082"]},"54925":{"abstract":"The goal of this project is to develop an integrated<br\/>hardware\/software infrastructure to support power management for<br\/>battery-powered mobile and wireless applications. These future<br\/>environments will support applications with demanding requirements<br\/>such as disaster recovery. Energy conservation, especially for<br\/>mobile and embedded devices, promises to have significant economic,<br\/>environmental, and societal impacts.<br\/><br\/>The activities focus on three key directions: i) the development of<br\/>power measurement tools, workloads, and experimental methods to<br\/>evaluate energy consumption, ii) the energy-aware APIs to allow<br\/>application-directed power management, and iii) the development of<br\/>system support for high-level solutions.<br\/><br\/>These research projects all rely on experimental techniques for<br\/>evaluating ideas. Making empirical measurements and observations on<br\/>device and workload characteristics pinpoints the problem areas of<br\/>greatest potential. Initially formulating simulation models narrows<br\/>the solution space and allows consideration of new architectures.<br\/>Finally, constructing working prototypes allows observation of all<br\/>activity associated with real operating environments and offers<br\/>deeper insights into their behavior. The popularity and<br\/>accessibility of the palmtop and handheld platforms gives this<br\/>research significant potential for immediate technology transfer.","title":"ITR: System Support for Energy Management in Mobile and Embedded Workloads","awardID":"0082914","effectiveDate":"2000-09-01","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["353750","555929","485593"],"PO":["209879"]},"54705":{"abstract":"It is very well known that there is sometimes a striking divergence between the continuous and the discrete. The theory of time scales has been initiated by Stefan Hilger ten years ago in order to unify study for differential and difference equations. Not only is it able to treat these two cases simultaneously, but it also can handle numerous other cases \\in between\" the continuous and the discrete, and those cases might be important for applications. For this reason it also could be worth to think about the consequences of a better developed time scales theory for graduate and in particular for undergraduate education. As the theory is very new and virtually important to every area in analysis, work on this subject done now will be fundamental. If NSF funds this proposal we would expand the theory of dynamic equations on time scales in various ways. We would like to conduct study of linear dynamic systems on time scales which would result in a better understanding of higher order dynamic equations. For those the task of characterizing disconjugacy is an interesting one, and this question we also want to address for higher order Sturm-Liouville dynamic equations or, more general, linear Hamiltonian dynamic systems on time scales. Such systems also would be<br\/>interesting if an eigenvalue parameter was involved, and we would like to derive an existence theorem, an expansion theorem, Rayleigh's Principle, and more general oscillation results for these eigenvalue problems. Another interesting task, which is intimately connected to the above problems, would be to establish a theory of variational analysis on time scales. To give necessary and sufficient conditions for strong and weak local minima would be the main concern of such a project, and it would also be of use to establish a Weierstrab Theory for variational problems on time scales.","title":"ITR: Analysis of the Capacity Improvement for Wireless Networks with Multiple Transmit and Receive Antennas","awardID":"0081476","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["486561","545777","364780","557396"],"PO":["564898"]},"54826":{"abstract":"This is the first year funding of a three-year continuing award. The project investigates on-chip analog and mixed mode computation for an intermediate sensory signal representation before the information is read out from the sensor chip. By appropriate information encoding, such representation will be robust to limitations of the sensing and readout process, thus enabling efficient extraction of useful environmental information. On-chip computation enables a sensor to make partial decisions on-chip and to use those decisions to create an optimal signal representation and robust extraction of sensory information. This project will focus on image sensors. From a theoretical point of view, image sensors are interesting because they are scalable parallel systems that require fine-grain, distributed computation and global data communication among a large number of sites. The necessity to bring together data from a large number of processors\/sites quickly saturates communication connectivity and adversely affects computing efficiency in large parallel systems. The aim of this project is not to miniaturize conventional image<br\/>processing on-chip, but rather to obtain information about the environment that is not obtainable if computation is not performed on the sensory level. From a practical point of view, this project focuses on the ability of image sensors to adapt to high and low dynamic range scenes. Such scenes routinely cause conventional sensors to fail; yet<br\/>such scenes are omnipresent in everyday imaging applications. The PI's group will<br\/>build several high resolution CMOS line and area computational image sensors to test our signal encoding techniques. Ultimately chips will be tested in an ongoing robotic application at the CMU Robotics Institute. One candidate application is a visual guidance of fully autonomous or robot-assisted wheelchair for severely disabled users who are able to provide only high-level control to the system. The primary significance of this research is toward alleviating the problem of global data aggregation and communication from large and scalable parallel systems. The secondary significance of this research is in its practical application to visual perception systems and its superior information extraction ability.","title":"ITR: Sensory Level Computation and Information Encoding for Robust Imaging","awardID":"0082364","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["267325"],"PO":["234178"]},"54716":{"abstract":"Network simulation is an indispensable tool for researchers seeking to understand the principles of network architecture and protocol design. A key parameter in any moderate to large-scale simulation is the topology, i.e., the way the nodes of the network are organized and connected to each other. \"Good\" models for topology are essential for good simulations.<br\/> The PIs have developed graph modeling software that currently is widely used as a tool for generating topologies, particularly models of large internetworks. The Georgia Tech Internet Topology Models (GT-ITM) package allows researchers to construct model topologies whose structure arguably resembles the node-level structure of the Internet: routers or switches, connected by (bidirectional) links, and grouped into domains. The GT-ITM software is included with \"ns2\" [2], the defacto open-source standard for network simulation.<br\/> Despite the wide-spread use of GT-ITM, in general, and its transit-stub model, in particular, a number of critical and fundamental questions remain unanswered about network topology modeling. For example,<br\/> 1)Topology models. Recent data indicates that the current Internet topology has some properties that are not well reflected in the transit-stub model of GT-ITM [17]. For example, features such as the exchanges where many transit domains come together are lacking. Are there \"better\" techniques to generate topologies intended to model the Internet? More fundamentally, how should a topology generation technique be evaluated (i.e., how is \"better\" measured)?<br\/> 2)Topology scaling. Although strides are being made in supporting large-scale simulations [33], most researchers will continue to simulate their protocols on topologies that are smaller than the target operational large-scale networks. How should smaller topologies be configured so that they reasonable reflect their larger counterparts? Is there a theory of topology scaling that can provide the fundamental grounding for configuring topologies of various sizes?<br\/> 3)Topology use. The PIs primary interest in topology modeling is to provide a foundation for large-scale simulations. Facilitating the use of topologies in simulations must go beyond providing theoretically sound models, however, and include a set of complementary tools for graph visualization, routing table construction, etc. What visualization tools are useful to researchers and assist in accurate intuitive understanding of underlying topology? How can different routing policies be effectively reflected in routing table construction?<br\/> The researchers propose (1) to address these and other fundamental questions in the area of topology modeling and (2) to reflect their understanding in a set of topology tools and benchmarks made available to the research community at large. This work will build on the PIs prior experience in modeling internetworks. <br\/> The proposed work will contribute to fundamental understanding in the area of topology modeling. The work will include a set of evaluation criteria to assess the quality of a topology generation method and improvements in topology models. The work will also produce an evolutionary theory of topology scaling, with implications for efficient simulation using topologies that are smaller than the target. In addition to contributions to fundamental understanding, a central component of the proposed work is a set of tools and benchmarks to be made available to the research community at large, following in the tradition of the GT-ITM<br\/>suite. These tools will allow other researchers to generate topologies, assess the quality of candidate topology modeling methods, utilize benchmarks based on current and future technologies, and interact with a visualization of topology.","title":"ITR: Collaborative Research in Internet Topology Models - A Foundation for Large-Scale Simulations","awardID":"0081557","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["550876","550429"],"PO":["250082"]},"52659":{"abstract":"Bandwidth management and pricing of elastic services is key to the efficient and profitable running of emerging high-speed networks. Elastic traffic or traffic which can alter its rate characteristics to adapt to the congestion state of the network, such as TCP\/IP traffic, already forms a major part of the traffic carried by today's networks, the Internet being the current paradigm. In networks where the basic bandwidth availability and user characteristics are not efficiently priced as well as managed, profitability or efficiency is reduced since pricing and consequent user satisfaction are going to determine demand and useful throughput (\\goodput\"). While the ideas of dynamic optimal resource allocation and pricing based on user resource requests and budgets are very attractive they cannot be implemented in a large network for scalability reasons. This is due to both communication as well as computational overheads. Hence, there is a need for creating a hierarchical structure and to perform aggregation in order to make the concept implementable and useful. However, the researchers believe that there is a need for a well-defined framework so that they can understand and quantify the trade-offs that have been made in terms of efficiency, overhead, fairness, complexity, responsiveness (especially if the propagation delays are large) and robustness. Other issues very much related to implementation are linked to measurement of congestion and to convergence and stability of efficient and computationally feasible distributed algorithms.<br\/> The proposed research will:<br\/> (1) Further develop and refine a game theoretic framework proposed by the PIs for bandwidth allocation for elastic traffic. The allocation maximizes the efficiency (in terms of network revenue) of network utilization and incorporates the crucial notion of fairness. The main thrust will be the development of appropriate solution concepts in non-static environments.<br\/> (2) Use the above framework to develop pricing structures which will lead to network efficiency while providing user level satisfaction.<br\/> (3) Develop distributed algorithms which enable the proper allocation of bandwidth as defined through game theory above based on users' willingness to pay and bandwidth demands. In particular, the issues of<br\/>network measurements and local information will be addressed. This can be seen as either a solution for a<br\/>small network or as a benchmark to which the researchers proposed solutions incorporating hierarchy and aggregation will be compared.<br\/> (4) Design of scalable solutions incorporating aggregation and an appropriate hierarchical structure of the network, i.e., user level, groups of users, etc. Particular attention will be paid to trade-offs in terms of<br\/>performance and complexity. Both the pure bandwidth allocation based on performance as well as pricing<br\/>based cases will be considered.<br\/> (5) Study in the implementation of these solutions in the context of network protocols such as TCP\/IP. This will involve issues related to stability, convergence, and adaptivity to changing conditions.<br\/> (6) Develop notions of network bandwidth derivatives or option pricing for booking or provisioning of bandwidth resources based on a Black-Scholes paradigm. This is another example of the techniques that the researchers plan to use. This one will be used at an intermediate level of the researchers' network hierarchy, namely between a service provider and a network operator.<br\/> The researchers expect that the proposed work will involve: advances in applications of game theory; contributions to the notions of aggregation and fairness; development of an approach to bandwidth options; optimal pricing structures; development of feasible real-time algorithms for bandwidth allocation; and contributions to implementation issues based on available information. The techniques will be drawn from game theory, Lyapunov theory, convergence of stochastic algorithms, nonlinear constrained optimization, mathematics of finance, and stochastic analysis.","title":"Distributed Bandwidth Management and Pricing in High-Speed Networks","awardID":"0073359","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["231101","153088"],"PO":["565090"]},"54606":{"abstract":"AI is approaching the point where it will be possible to build autonomous robotic agents capable of performing human-like tasks without direct human control. Such autonomous agents must be able to plan their activities in the face of incomplete knowledge of their environment. This project aims at understanding how such planning works and building implemented systems that accomplish it. Specifically, this investigation is aimed at the construction of an artificial rational agent capable of engaging in decision-theoretic planning in environments of realistic complexity and unpredictability. The design of a system to do automated planning is one of the traditional goals of artificial intelligence research, and some highly successful planning systems have been constructed for use in narrowly constrained environment; however, these systems presuppose that the planner knows everything it needs to know when it is first presented with the planning problem, and most of them further require complete knowledge of all relevant aspects of the agent's environment and knowledge of precisely what will result from performing any relevant act in any circumstance the planner will encounter. While such assumptions might be satisfied by an industrial robot operating in a constrained environment, human beings plan without satisfying any of these conditions. In particular, planning problems often drives the search for new knowledge rather than presupposing that the planning agent knows everything it needs to know from the beginning. And human beings do not assume that they can predict with certainty what will happen when they perform any available action under any conceivable circumstances. In constructing and evaluating plans, people take account of the varying probabilities of different consequences of actions, and they assign values and costs to those consequences before deciding whether to adopt a proposed plan. In other words, they plan decision-theoretically. The objective of this project is to understand how decision-theoretic planning is possible in an agent operating in an uncooperative and only partially predictable environment, and then to build an artificial agent whose planning capabilities more closely approximate those of human beings. This should illuminate some of the structure of rational cognition in both artificial agents and human agents.","title":"Practical Reasoning in Autonomous Agents","awardID":"0080888","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["248906"],"PO":["491702"]},"54727":{"abstract":"As the complexity of the Internet, the nature of its applications, and its socioeconomic framework evolve, new algorithmic and architectural ideas will be proposed, tested, and adopted. While the original Internet design principles will likely remain valid, the researchers believe that it is important to have in place a mathematical framework within which these design principles can be expressed and applied to the next generation of Internet algorithms and architectures. Building such a framework is the ultimate goal. The mathematical tools will come from optimization, game theory and competitive analysis. The researchers shall work on the following topics.<br\/><br\/>Multicast. The researchers shall seek to determine the relative efficiency, in terms of link usage, of multicast versus unicast, devise and analyze efficient methods of multicast error recovery, and determine how efficiently multicast can be simulated in the application layer by a coordinated set of unicasts.<br\/><br\/>Congestion Probing. The TCP congestion control protocol controls its window size with an additive-increase and multiplicative-decrease (AIMD) algorithm. One can think of this as a probing algorithm in which the flow attempts to discover the maximum rate of traffic that<br\/>can be send under current conditions; if a packet drop is recorded it is assumed the bandwidth rate was too high and so the window size is reduced. The researchers shall develop efficient probing algorithms and theoretical limits on the efficiency of probing under different models of Internet congestion.<br\/><br\/>Cost Sharing. How are the recipients of a multicast transmission to share the network costs? The researchers assume that the information to be multicast is of a certain value to each possible recipient, but this value is private to that individual. The researchers shall investigate strategyproof cost sharing methods where each user is assured that their outcome is maximized if they truthfully reveal their value to the network. The researchers' goal is to characterize the set of protocols that are acceptable on both game-theoretic and complexity grounds.<br\/><br\/>Information Dissemination. While traditional databases require transactional consistency, many repositories of information require only the much weaker notion of eventual consistency. That is, in such cases we care only whether, and how quickly, the information is disseminated, but do not require global consistency during the dissemination. The researchers shall identify message-efficient strategies for selectively propagating information so that the network will eventually converge to a fully updated state.","title":"ITR: Analysis of Internet Algorithms: Optimization, Game Theory and Competitive Analysis","awardID":"0081698","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["561682","558880","560562"],"PO":["250082"]},"56927":{"abstract":"Automation of a given design process requires an algorithmic analysis of it. The availability of fast and easily implementable algorithms is essential to the discipline. This proposal focuses on the physical design problems and their interaction with higher and lower-levels of the design hierarchy. Two classes of problems are being studied. First, the interaction between various cost functions in the placement problem is being investigated. In particular, relationship among net-cut, wirelength, congestion, and timing is being researched. Next, the class of algorithmic predictors and statistical predictors are being studied. One goal of this project is to show that it is possible to obtain accurate prediction very fast using floorplan and placement predictors. CAD tools associated with the above projects are under development.","title":"Algorithmic Aspects of Physical Design Problems","awardID":"0090203","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["547185"],"PO":["562984"]},"55717":{"abstract":"This is the first year funding of a three-year continuing award. Robust domain-independent language understanding is essential for multilingual information extraction, summarization, question answering, and automatic translation. With pervasive computing environments soon to come, language understanding will become even more indispensable for interacting with artifacts of widely different functionalities. The field of natural language understanding has made significant progress in the last fifteen years. A large part of this gain is due to the sophisticated combination of statistical algorithms with template-based algorithms tailored to specific domains like air-traffic information, travel scheduling, and business news. But any real solution to the problem of domain-independent understanding will require moving beyond template-based monolingual systems to more flexible, general purpose HCI systems via three key innovations: (1) a domain-independent semantic language as the back end for these understanding systems, replacing the current domain-restricted templates and slots; (2) rich semantic lexical databases which are broad enough to cover the necessary words for language engineering tasks, and deep enough in usable semantic information to support true domain-independent understanding; and (3) sophisticated techniques for performing this mapping.<br\/><br\/>This project will develop these three components: a very large lexical database FrameNet++, a semantic language designed for domain-independent understanding tasks, and the tools for applying it to and evaluating it on key NLU applications. The semantic language and lexical database are based on formalizing the semantic frames and the semantic and syntactic combinatory properties - the valences - of a significant portion of the English lexicon. FrameNet++ will offer significantly richer semantic information than is available in current databases like COMLEX and WordNet, by characterizing the conceptual frames within which words are defined and identifying the semantic roles which the arguments of these words can take. These roles and frames are key to building domain-independent language understanding applications. The project will focus from the start on specific NLU applications: word sense disambiguation, information extraction, multilingual information extraction, and an eventual extension to text data mining. For each application, the PI and his team will apply the FrameNet++ system to improve the domain independence of the semantic components, using statistical algorithms for semantic annotation that we have already begun to implement. These applications will in turn provide a rich and realistic evaluation framework to guide FrameNet++ development, and will encourage potential users to apply it to a wide variety of tasks.<br\/><br\/>The FrameNet++ database will be capable of serving many purposes. Provided with statistical information about frequencies of words, word\/sense mappings, and combinatorial patterns linked to word senses, it will be usable in various automatic language understanding processes, including word sense disambiguation and information extraction. Since the formal semantic annotations are keyed to conceptual structures which are independent of any individual language, they are available for the creation of parallel lexicon databases of other languages. The semantic structures in the databases will facilitate matches from one language to another, in machine translation and machine-assisted translation, while the syntactic structures allow the production of appropriate grammatical sentences in the target language.","title":"ITR: Framenet++: An On-Line Lexical Semantic Resource and its Application to Speech and Language Understanding","awardID":"0086132","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["353897","456792","517444",142866],"PO":["246649"]},"51119":{"abstract":"EIA-0004280<br\/>van Dam, Andries<br\/>Brown University<br\/><br\/>Special Projects: Workshop to Establish a Research Agenda in Learning Science and Technology<br\/><br\/>This award supports a workshop to define major research areas in learning science and technology, in particular at large scale, identifying the most pressing research needs and suggest ways of combining these topics into themes. This is a timely and very important project, as universities and other deliveries of training and education struggle to re-define their teaching methods given the extraordinary changes just beginning due to ubiquitous high-performance computing and networking.<br\/><br\/>This workshop is related to an overall effort by NSF and others to foster the development of the Learning Federation (LF), a fledgling research organization designed to undertake research in this area. As envisioned by the organizers, the Learning Federation will model itself after consortia such as Sematech in the semiconductor industry; it will support pre-competitive, not-for-profit research among a consortium of industry, government, foundations and universities and will be managed and governed by the consortium members. The LF goal is to achieve a critical mass of projects by providing long-term, stable, \"large-grain\" funding for interdisciplinary research teams. The LF will fund basis learning science and technology as well as appropriate uses of technology and experimental content such as libraries of learning objects and courses. The focus will initially be on undergraduate, graduate, and life-long learning. The result will be a next generation of learning environments suited to a network context<br\/>.","title":"Special Projects: Workshop to Establish a Research Agenda in Learning Science and Technology","awardID":"0004280","effectiveDate":"2000-09-15","expirationDate":"2002-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"1666","name":"RESEARCH ON LEARNING & EDUCATI"}}],"PIcoPI":["448703"],"PO":["371077"]},"55629":{"abstract":"Today's Internet owes its great success to the simple, \"hour-glass\" IP network protocol architecture laid out twenty-five years ago. With rapid advances in networking technologies and explosive growth of rich multimedia content in recent years, the networking community finds itself at an important crossroads: what should be the next generation Internet architecture for controlling network resources and provide the quality of service (QoS) needed by emerging multimedia applications? There is a multidimensional spectrum of possible approaches to providing QoS guarantees. The choice of a QoS solution for the next generation Internet will have a substantial impact on both the evolution of the Internet itself, and on what it enables. Making the \"right\" choices requires the development of a fundamental understanding of the scalability of QoS controls and the impact of these controls on the efficacy of QoS provisioning.<br\/> The goal of the proposed research is to develop a comprehensive, quantitative understanding of the fundamental trade-offs involved in various approaches toward providing scalable QoS guarantees. To this end, we will develop coherent theories to systematically address the issue of scalability in QoS controls. The research program divides broadly into four areas:<br\/> Aggregate network calculus for guaranteed flows: To gain a thorough understanding of the fine time-scale(e.g., packet-level) behavior of a network system in providing QoS performance guarantees, the researchers will develop an aggregate network calculus to study the impact of aggregate QoS control mechanisms on the performance and complexity of data plane operations. This theory is developed for guaranteed flows - flows which require the network to commit, either at a per-flow or an aggregate level, a certain amount of resources (e.g., bandwidth and buffer) throughout their life time, regardless of the network congestion status. The aggregate network calculus will provide a mathematical framework to quantify the impact of aggregate QoS controls on the fundamental trade-offs in QoS provisioning. It will also yield insights into the design of scalable data plane QoS control mechanisms.<br\/> End-to-end QoS controls for responsive flows: The researchers will develop fluid models to study the impact of aggregate QoS control mechanisms on the end-to-end performance of responsive flows. A responsive flow responds to signs of network congestion, such as loss, by adapting its transmission rate. These models will enable us to develop a better understanding of the behavior of responsive flows such as<br\/>TCP coupled with different aggregate QoS mechanisms and to design end-to-end QoS services for responsive flows.<br\/> QoS control laws and control plane aggregation rules. We will develop QoS control laws for capturing the slow time-scale, system-wide behavior of a network and aggregation rules that address the perfor-mance and complexity of control plane operations under aggregate QoS controls. These QoS control laws and aggregation rules will lead us to the design of distributed and centralized algorithms for scalable control plane operations.<br\/> Scalable QoS mechanisms and service architectures As an integral part in developing these theories, the researchers will also design effective and scalable QoS mechanisms, and tools and techniques for quantifying and evaluating the trade-offs of various QoS solutions. Based on the results from these efforts, the researchers will study how various QoS solutions can be combined to construct meaningful end-to-end services.<br\/> The research will blend formal modeling\/analysis, experimentation\/implementation, and evaluation. The<br\/>understanding and insights gained as a result of our research will lead to the establishment of the theory,<br\/>design principles, and guidelines for building scalable QoS controls for the future Internet. This, in turn,<br\/>will allow reasoned and informed choices to be made as the next generation Internet takes shape.","title":"ITR: Collaborative Rsearch: Scalable Quality-of-Service Control for the Next Generation Internet","awardID":"0085824","effectiveDate":"2000-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["543509"],"PO":["7594"]},"53209":{"abstract":"ABSTRACT<br\/><br\/>This research involves the general area of error control coding for digital communication and storage systems. In particular, it describes a number of fundamental research topics related to a powerful new method of error control coding called turbo coding. The research has two major goals: (1) to propose new turbo coding schemes with performance and\/or complexity advantages compared to the current state-of-the-art, and (2) to advance the fundamental state of knowledge regarding this exciting new approach to error control coding. Although still very new, turbo coding is beginning to be applied in numerous areas that require error control techniques, including deep space communication, satellite communication, and digital cellular telephony, to name just a few. Because of its ability to perform close to theoretical limits with reasonable implementation complexity, it is anticipated that turbo coding and related techniques will have an enormous impact on virtually all applications of error control coding over the next 10 years or so.<br\/><br\/>Turbo coding can achieve moderate bit error rates (in the range of 10-4 to 10-6) at signal-to-noise ratios very close to channel capacity. However, there is still room for improvement in turbo coding performance, particularly in applications that require bit error rates below 10-6. Further, there is considerable theoretical interest in achieving a more complete fundamental understanding of the key properties of turbo codes that result in such excellent performance. The investigators study several new basic research problems in turbo coding. Among the topics to be investigated are (1) several new turbo code designs capable of achieving even better performance than existing schemes, (2) the introduction of a more general class of turbo codes that has the potential to yield better codes and\/or reduced decoding complexity compared to standard turbo coding methods, and (3) the development of a new sub-optimum soft-in, soft-out decoding approach that can be used with more codes, thus offering the promise of near capacity performance at very low bit error rates, say below 10-10.","title":"Collaborative Research - New Directions in Turbo Coding","awardID":"0075221","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["283483"],"PO":["223414"]},"48809":{"abstract":"Learning from Multiple-Instance and Unlabeled Data<br\/><br\/>Sally A. Goldman<br\/>Department of Computer Science<br\/>Washington University<br\/>St. Louis, MO 63130 <br\/><br\/><br\/>PROJECT SUMMARY<br\/>In standard supervised learning each example is given a label with the correct (or possibly noisy) classification. In unsupervised learning, all the individual examples are unlabeled with just a single overall label. This project is studying two learning models that fall between these two extremes. In the multiple-instance model the learner only receives labeled collections (or bags) of examples. A bag is classified as positive if and only if at least one of the examples in the bag is classified as positive by the target concept. Supervised and unsupervised learning can be thought of as two special cases of this model. In supervised learning, each example is in its own bag, and in unsupervised learning, all examples are together in one bag. The multiple-instance model was motivated by the drug activity prediction problem where each example is a possible shape for a molecule of interest and each bag contains all likely shapes for the molecule. By accurately predicting which molecules will bind to an unknown protein, one can accelerate the discovery process for new drugs, hence reducing cost. Existing multiple-instance learning algorithms use boolean labels for the bags. However, in the drug activity prediction problem, the true label is a real-valued affinity value measurement which gives the strength of the binding. This project is performing an in-depth study of learning in the multiple-instance model with real-valued labels including empirical studies using real drug binding data. Other applications areas will also be explored.<br\/>This project is also studying learning when much of the available data is unlabeled. In many application areas (e.g. the classification of web pages as appropriate or inappropriate for minors, or medical applications) there is a small amount of labeled data along with a large pool of unlabeled data. This project is studying techniques to use the unlabeled data to improve the performance of standard supervised learning algorithms. In particular, a method of co-training is being studied in which there are two independent learning algorithms which are originally trained on the labeled data. Then using statistical techniques, each learner will repeatedly select some of the unlabeled data to labeled for the other learner. This project will perform empirical studies and also theoretical studies to understand the limitations of various approaches to develop better learning algorithms.","title":"Learning from Multiple-Instance and Unlabeled Data","awardID":"9988314","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["228082"],"PO":["543507"]},"52704":{"abstract":"This research investigates compiler techniques for improving the<br\/>performance and scalability of Internet server programs. Servers have<br\/>a different set of characteristics from the computations that compiler<br\/>writers have focused on in the past. Instead of executing a<br\/>compute-bound computation with a modest number of long-lived threads,<br\/>servers typically use many short-lived threads to manage I\/O bound<br\/>connections from multiple clients. These new characteristics place a<br\/>premium on previously less relevant aspects of the system such as the<br\/>thread creation overhead and thread stack overhead. They also provide<br\/>opportunities that the compiler can exploit to improve the memory<br\/>management. The research will attack thread overhead by automatically<br\/>transforming multithreaded code to event-driven form. Code in<br\/>event-driven form contains an event loop that repeatedly blocks<br\/>waiting for the next event from any of the current connections. It<br\/>then invokes a handler that executes the appropriate action, then<br\/>returns to the event loop. This transformation will eliminate thread<br\/>creation and management overhead. The compiler will attack memory<br\/>management overhead by analyzing the program to identify objects whose<br\/>lifetimes are tied to individual threads, then using specialized<br\/>memory management algorithms for these objects.","title":"Compiler Technology for Scalable Servers","awardID":"0073513","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["497068"],"PO":["551992"]},"52715":{"abstract":"Predicated execution is a feature used in the Explicitly Parallel<br\/>Instruction Computing (EPIC) architecture for achieving the<br\/>instruction level parallelism (ILP) needed to keep increasing future<br\/>processor performance. The IA-64 processor being developed at Intel<br\/>with Hewlett Packard is an example of an EPIC architecture. An<br\/>advantage of predicated execution is the elimination of<br\/>hard-to-predict branches by combining both paths of a branch into a<br\/>single path, thereby obtaining additional opportunities for ILP.<br\/>However, this merging of several paths into one has disadvantages, as<br\/>it complicates optimizations and scheduling in both software and<br\/>hardware.<br\/><br\/>This research develops a comprehensive framework for new compiler and<br\/>hardware analysis whose projected impact is to realize the performance<br\/>of predicated execution. Underlying our framework is the efficient<br\/>maintenance and use of predicate relationships and precise information<br\/>about predicated regions. This proposal builds on our prior work by<br\/>(1) incorporating critical path and resource constraints into a<br\/>compiler intermediate form for predicated compilation, (2) developing<br\/>hardware structures to allow predicate speculation and out-of-order<br\/>execution, (3) developing software and hardware dynamic predication<br\/>and (4) developing predicate-sensitive compiler optimizations,<br\/>especially those based on value prediction or profiling.","title":"Predicate-Sensitive Software and Hardware Analysis to Enable Optimization and Speculation","awardID":"0073551","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["481145","293079"],"PO":["551992"]},"54904":{"abstract":"Several large-scale IT applications are enabled by the design, implementation and evaluation of a scalable real-time streaming media architecture. Large volumes of real-time data are stored, maintained, and retrieved online. Popular examples of real-time media include video and audio, while less familiar examples are haptic and avatar data. The real-time end-to-end delivery of very high quality (megabits per second) media cannot be supported with the current Internet-based infrastructure due to the lack of a scalable server architecture as well as a missing global resource management protocol.<br\/><br\/>The evaluation of our architecture in a realistic setup is the objective of integrating three of our previous successful research projects: 1) a distributed real-time file server (RTFS), 2) a redundant hierarchical interconnect architecture (RedHi), and 3) the Super-streaming paradigm to improve individual RTFS utilization by using client side resources.<br\/><br\/>The impact of this architecture is on both the server design as well as the online multimedia content. Furthermore, the realization of such an infrastructure is enabling large scale applications such as video-on-demand, news-on-demand, distance learning and scientific exploration and visualization. These applications, in turn, will be promoting teaching, training, and learning as well as enhancing scientific and technological understanding.","title":"ITR: An Infrastructure for the Real-Time Delivery of High Quality Continuous Media from Distributed Scalable Servers to Multiple Clients","awardID":"0082826","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["550740"],"PO":["563751"]},"54915":{"abstract":"Highly interactive graphics applications have stringent latency requirements to ensure a compelling experience. These requirements are usually met by overprovisioning hardware resources and are validated through ad-hoc testing. Recent advances in real-time scheduling technology could serve as the<br\/>basis for a more analytical approach. Unfortunately, conventional real-time scheduling disciplines are quite rigid and are usually implemented only within special-purpose real-time operating systems. For these reasons, real-time scheduling techniques have been largely ignored within the graphics community.<br\/><br\/>In this project, a real-time scheduling and analysis framework will be developed for latency-sensitive graphics applications. This framework will extend recent work on rate-based processor scheduling. The proposed framework will allow timing requirements to be specified as average rates and will be highly tolerant of any deviance from specified rates. <br\/><br\/>The proposed rate-based framework will be evaluated through research involving the nanoManipulator system (www.cs.unc.edu\/Research\/nano). The nanoManipulator couples a scanning tunneling microscope or atomic force microscope to a virtual-reality graphics display and a haptic interface to provide a telepresence system. The existing nanoManipulator is not multi-threaded, and thus the system is difficult to modify and analyze. In this project, a fully multi-threaded version of the nanoManipulator will be developed using the<br\/>proposed framework.","title":"ITR: Rate-based Scheduling Technology for Latency-Sensitive Graphics Applications","awardID":"0082866","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["554765","31436","518412","553223"],"PO":["321058"]},"54926":{"abstract":"EIA-0082915<br\/>Schnabel, Robert<br\/>University of Colorado<br\/><br\/>ITR: Research, Curriculum and Partnerships for Broadening the<br\/>Information Technology Pipeline<br\/><br\/>This project supports a collaboration to explore a new multimedia paradigm<br\/>for educating students for careers and lives in the networked information<br\/>age. Through research and course delivery, this collaboration will explore<br\/>new curricula that allow students from a wide variety of disciplines to<br\/>obtain the understanding and skills that prepare them to be a part of the<br\/>modern information technology workforce. The project will broaden the<br\/>information technology pipeline in two critical ways: by increasing the<br\/>diversity of academic disciplines and aptitudes from which students can<br\/>enter the information technology workforce, and by applying this approach<br\/>to a racially diverse population.<br\/><br\/>The project will develop a multidisciplinary curriculum and research in<br\/>technology, arts, and media (TAM). The research associated with the<br\/>development and evaluation of the TAM curriculum has four components: 1)<br\/>computer and cognitive science research addressing approaches to using<br\/>information technology in education that will help determine both the<br\/>content and the delivery of the curriculum. 2) social science research<br\/>about the impacts of the networked information age upon our society that is<br\/>linked to a key portion of the curriculum, 3) education research about the<br\/>use of information technology in K-12 education that will impact the<br\/>education course offerings of the TAM curriculum, and 4) formative and<br\/>summative evaluations of the TAM curriculum in achieving its goals.","title":"ITR: Research, Curriculum and Partnerships for Broadening the Information Technology Pipeline","awardID":"0082915","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["425934"],"PO":["564318"]},"50328":{"abstract":"This project investigates the cognitive learning styles of heterogeneous, distributed software agents to uncover how they best learn, discover how other agents learn and take advantage of the various learning capabilities. The objectives of this research project are to 1) identify the various styles of multi-agent learning, 2) develop a multi-agent learning framework, and 3) conduct experiments on multi-agent learning. This research project will advance our understanding of agent information and knowledge sharing.","title":"A Preliminary Investigation of Diverse Learning Styles in a Multi-agent System","awardID":"0002364","effectiveDate":"2000-09-01","expirationDate":"2001-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["464121"],"PO":["495796"]},"54948":{"abstract":"This is the first year funding of a three-year continuing award. Multimodal technologies and machine learning have the potential to open doors for individuals with disabilities, by enabling systems to provide interfaces which allow people to express themselves through a variety of modalities which suit their capabilities. But individual differences among potential users make it difficult to design a single interface that works for everyone. Adaptive systems which tune to a user's idiosyncratic abilities and preferences can eliminate the need for users to conform to fixed interface protocols. Previously, the P1 has achieved promising results both in developing models of learning from multimodal input, and in discovering acoustic features that carry information in severely impaired speech. In this project the PI will develop a framework for adaptive interfaces by integrating these threads of research. Multimodal learning will provide interfaces with a core adaptive engine that can detect and statistically model salient inter-modal patterns. Acoustic analysis of impaired speech will provide one of many modes of input which an individual with disabilities might use to express him or herself. By combining multiple modes of sensing with learning, an interface can be trained to respond to an individual's unique expressive behaviors (speech., gestures) and translate them into appropriate machine actions. The P1 will implement two assistive communication aids to test our. these ideas. The first prototype will learn to translate unintelligible spoken phrases into clear synthetic speech. To do so, it will learn consistent acoustic features of the user's voice that can reliably be mapped onto machine actions. The second system will dynamically adjust the display of a communication aid by predicting words and symbols that the user would most likely select. Predictions are based on observations of patterns of behavior exhibited by the user in past communication interactions. Unlike currently available word prediction systems, this interface will take into account the topic of conversation by analyzing the speech of the user's communication partner using speech recognition and topic identification technologies. Both interfaces will undergo usability testing in hospitals and clinics in Boston and Toronto. Based on these efforts, the P1 will derive a set of design principles for using adaptive elements in assistive communication aids and man-computer interfaces.","title":"ITR: Multimodal Learning for Assistive Aids","awardID":"0083032","effectiveDate":"2000-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"T010","name":"NSA-HTL CENTER FOR EXCEL PROJE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V723","name":"NSA-HLT CENTER OF EXCEL PROJEC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V798","name":"NSA-ITR MULTIMODAL LEARNING FO"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V839","name":"NSA-HUMAN LANGUAGE & COM PROG"}}],"PIcoPI":["299749"],"PO":["565215"]},"54717":{"abstract":"This project studies the process of visualizing information at every point in space through volume rendering. Traditionally, volume rendering has employed one of two approaches. The first attempts a physically accurate simulation of a process such as X-rays passing through tissue or light passing through a fog, producing the most realistic views of volume data (at least for data with an appropriate physical meaning). The second approach is only loosely based on the physical behavior of light, using instead an arbitrary appearance of each value in space and an accumulation process through space to create a wider range of appearances for the volume in the visualization. This project proposes a new approach to volume rendering: the augmentation of a physics-based rendering process with non-photorealistic rendering (NPR) techniques to enhance the expressiveness of the visualization. NPR draws inspiration from such fields as art and technical illustration to develop automatic methods to synthesize images with an illustrated look from geometric surface models. The new approach, called volume illustration, combines the familiarity of a physics-based illumination model with the ability to enhance important features using non-photorealistic rendering techniques.<br\/><br\/>Technically, the project faces several challenges. In surface-based NPR, the surfaces (features) are well defined, whereas with volumes, volumetric feature areas are often amorphous regions that must be determined through analysis of local volumetric properties. Once these volumetric feature volumes are identified, user selected parametric properties can be used to enhance and illustrate them. Volume illustration provides a flexible unified framework for enhancing structural perception of volume models through the amplification of features, the addition of illumination effects, and the application of procedural textures. Volume illustration will work on both presampled and procedurally defined volume models, enabling a range of image styles from practical technical illustrations to more abstract painterly effects. The project will develop a collection of volume illustration techniques, including novel volume illustration techniques and techniques that adapt and extend NPR techniques to volume objects.","title":"ITR: Volume Illustration: Non-Photorealistic Rendering of Volume Models","awardID":"0081581","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"V847","name":"NSA-RES IN INF VISUAL CLUSTER"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"V110","name":"NSA-ANALYSIS OF LGL AMT OF HET"}}],"PIcoPI":["499748","507476"],"PO":["565272"]},"55707":{"abstract":"Ensembles of distributed communication, computation, and storage resources, also known as \"Computational Grids\", are emerging as a critical platform for high-performance computing. Grids are used effectively to support runs of distributed applications at a large enough scale to provide new disciplinary results to their developers. Researchers in almost every field of science and engineering are particularly interested in a class of applications particularly well suited to the Grid, scientific simulations where many parameterized instances of a give computation are performed. The development of accessible, efficient, fault-tolerant Grid-enabled versions of simulation software will enable disciplinary scientists to investigate wide-ranging scenarios and to obtain new results orders of magnitude faster than is currently possible.<br\/><br\/>Many scientists would like to view large-scale simulations as software instruments that support some level of user interaction. This would be effective only if simulations can be deployed easily and controlled dynamically, i.e. if the computation can be steered. A traditional scenario is for the user to steer the simulation based on partial results that evolve continuously during execution. The partial results provide an increasingly refined indicator of the final results of the simulation and can be used to identify mid-execution which parameter sets are most promising. Given the potential of wide-area, federated Grid environments to deliver the aggregate computational power, data storage and dissemination facilities for large-scale simulations, and the need for scientists to steer such computations, it is increasingly important to develop performance-efficient and steerable software instruments that target the Grid. This project will address the significant computer science problems that arise from the need to support steerable scientific simulations in large-scale Grid environments.<br\/><br\/>The project will design, develop, and prototype a virtual software instrument as a vehicle for designing and prototyping scalable, steerable scientific simulations for the Grid. It will use a Monte Carlo simulation program, MCell, as a prototype application for development and testing of the virtual instrument. The virtual instrument itself will consist of a set of software modules, libraries, interfaces, and steering-sensitive scheduling algorithms. The project will have impact on both the computer science and disciplinary science communities. It will foster new research in computer science through the development of event models, performance models, data management strategies, and adaptive scheduling and steering algorithms. It will also enable domain scientists to obtain new results in neuroscience.","title":"ITR: Virtual Instruments: Scalable Software Instruments for the Grid","awardID":"0086092","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["562621","532981","397101"],"PO":["551992"]},"56807":{"abstract":"EIA-0089869<br\/>Buy, Ugo<br\/>University of Illinois Chicago<br\/><br\/>Workshop on Digital Government: An Urban Research Agenda<br\/><br\/>This grant will support a workshop to define the information and computer science research agenda related to urban government issues. It will involve a consortium of 17 urban universities (listed on page 4 of the proposal) called the Great Cities Universities, of which the University of Illinois Chicago is one.<br\/><br\/>Information and networking technologies now have the potential to affect a variety of domains of interest in an urban environment including land use, criminal justice, digital governance and democracy, GIS-supported issues such as housing and business locations, social welfare services, education, and many more. This is a rich area of applications which should be of great interest to the computer and information science community.<br\/><br\/>This will be a joint effort of UIC's Department of Electrical Engineering and Computer Science and UIC's College of Urban Planning and Public Affairs; both disciplines will be essential to the an effective workshop.<br\/>.","title":"Workshop on Digital Government: An Urban Research Agenda","awardID":"0089869","effectiveDate":"2000-09-01","expirationDate":"2002-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":[146163,"441174"],"PO":["371077"]},"56818":{"abstract":"EIA-0089892<br\/>Shulman, Stuart W.<br\/>Drake University<br\/><br\/>Digital Government: SGER: Citizen Agenda-Setting in the Regulatory Process: Electronic Collection and Synthesis of Public Commentary<br\/><br\/>This planning grant will support initial examination of the impact of new communications technologies, such as the Internet, on public involvement in the regulatory rule-making process, leading to more sophisticated and manageable information systems for citizen\/government interaction. A related topic of interest is to explore the degree to which electronic avenues make public comment more difficult or less effective for the citizen. The partner agency is the National Organic Program (NOP) of the U.S. Department of Agriculture. As the project progresses, it will promote further collaboration between social scientists, federal agencies, and information scientists. Recently, the NOP received over 275,000 comments via email, fax and postal mail in response to a proposed regulation. It is difficult to draw conclusions from such a large and heterogeneous set of responses without the assistance of information technologies. NOP has provided the PI a sample data set of 20,000 responses to begin this project.","title":"Digital Government: SGER: Citizen Agenda-Setting in the Regulatory Process: Electronic Collection and Synthesis of Public Commentary","awardID":"0089892","effectiveDate":"2000-09-01","expirationDate":"2001-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["491832"],"PO":["371077"]},"55619":{"abstract":"Despite enormous progress in networking and computing technologies, their application has remained restricted to conventional person-to-person and person-to-computer communication. However, the Moore's Law driven continual reduction in cost and form factor is now making it possible to imbed networking - even wireless networking - and computing capabilities not just in our PCs and laptops but also other objects. Further, a marriage of these ever tinier and cheaper processors and wireless network interfaces with emerging micro-sensors based on MEMS technology is allowing cheap sensing, processing, and communication capabilities to be unobtrusively embedded in familiar physical objects. The result is an emerging paradigm shift where the primary role of information technology would be to enhance or assist in \"person to physical world\" communication via familiar physical objects with embedded (a) micro-sensors to react to external stimuli, and (b) wireless networking and computing engines for tetherless communication with compute servers and other networked embedded objects. <br\/><br\/>The proposed research seeks to explore wireless networking, middleware, and data management technologies for realizing the above vision. The problems of ad hoc structure, distributed nature, unreliable sensing, large scale\/density, and novel sensor data types are characteristic of such deeply instrumented physical environments with inter-networked physical objects. This requires one to rethink current architectures, protocols, algorithms, and formalisms that were developed for different needs. Further, to provide a concrete problem domain, we propose to use and evaluate our technologies in a \"smart kindergarten\" driver application targeted at developmental problem-solving environments for early childhood education. This is a natural application as young children learn by exploring and interacting with objects such as toys in their environment. Our envisioned system would enhance the education process by providing a childhood learning environment that is individualized to each child, adapts to the context, coordinates activities of multiple children, and allows unobtrusive evaluation of the learning process by the teacher. This would be done by wirelessly-networked, sensor-enhanced toys with back-end middleware services and database techniques. <br\/><br\/>The main information technology contributions of this research would be:<br\/> Wireless protocols for networks using short-range radios, with focus on highly unstructured, dynamic, and dense networks of embedded devices, and problems of energy efficiency and quality of service needs of sensor data.<br\/> Network architectures designed for naming, addressing, and routing by object capabilities and attributes, as opposed to id based approaches in conventional networks.<br\/> Efficient techniques and algorithms for identifying, locating, and tracking users and objects in instrumented environments, particularly indoors.<br\/> Middleware architecture providing services such as special communication patterns, context-aware network resource allocation and scheduling under attribute and capacity constraints, power-aware operation, media processing using shared background servers, and context discovery, tracking, and change notification.<br\/> Data management methods to handle data from multiple heterogeneous, unreliable, noisy sensors in a highly dynamic environment, with support for real-time sensor data interpretation and fusion, and off-line mining.<br\/> Automated mining of user profiles from sensor data, and their use in task planning and execution of actions in the instrumented environment <br\/> Techniques for sensor-assisted automatic speech recognition of children's speech.<br\/><br\/>Complementing the above will be the driver application where a Smart Kindergarten for developmental problem solving will be prototyped based on the above ideas, and evaluated in a real classroom setting. Various objects, particularly toys, will be wirelessly networked and have sensing and perhaps actuator capabilities. A wireless network, with radios and protocols suitable for handling a high density of proximate objects, will interconnect the toys to each other and to database and compute servers using a toy network middleware API. Sensors embedded in toys and worn by children will allow the database servers to discover and track context and configuration information about the children and the toys, and also orchestrate aural, visual, motion, tactile and other feedback. The system will enhance the developmental process by providing a problem-solving environment that is individualized, context adaptive, and coordinated among multiple children. It will also allow monitoring and logging for unobtrusive paper-free assessment by teacher or parent.<br\/><br\/>The project team is interdisciplinary, with researchers from UCLA's CS and EE Departments for the technology component of the project, and from UCLA's Graduate ","title":"ITR: Technologies for Sensor-based Wireless Networks of Toys for Smart Developmental Problem-solving Environments","awardID":"0085773","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["142856","384752","558131","472184","515835"],"PO":["292741"]},"54409":{"abstract":"EIA-0080206<br\/>Keleher, Peter<br\/>University of Maryland<br\/><br\/>CISE Research Infrastructure: System Support for Enterprise Application Servers<br\/><br\/>This proposal is for the acquisition and maintenance of a single large-scale shared-memory multiprocessor (SMP), and an active disk array. The equipment will be used to support a broad program of research into system support for enterprise applications. These applications include database servers, file servers, multimedia servers, and \"enterprise application\" servers. Though the group's projects include a broad range of specific activities, the overriding vision for the group will be a unified investigation of how to structure and support large-scale server applications. The researchers will take a vertical approach to this problem, investigating issues at every level from the application down to the network protocol level.","title":"CISE Research Infrastructure: System Support for Enterprise Application Servers","awardID":"0080206","effectiveDate":"2000-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":[138955,"152351","410444","245234","409678"],"PO":["297837"]},"52716":{"abstract":"The purpose of this research is to extend the present performance limits of pipelined analog-to-digital converters (ADCs) through the development of a digital signal processing technique that corrects for analog circuit mismatches. With recent trends toward software reconfigurability and digital signal processing, pipelined ADCs have become widely used in applications such as cellular telephone base-stations and wideband wireline modems. However, analog component mismatches have limited the accuracy achieved by present fabricated pipelined ADCs to levels below those desirable in many communications applications. For example, the accuracy ceiling imposed by analog component mismatches in present pipelined ADCs with conversion rates at or above 10MHz is approximately 75dB peak signal-to-noise-and-distortion (SINAD). Several distinct mismatch calibration techniques have been proposed in recent years to address the mismatch problem, but so far they have not made it possible to break through the above-mentioned 75dB SINAD ceiling. The problem is that the calibration techniques proposed to date are ultimately limited by the precision of their analog components, which tends to decrease as the conversion rate is increased. This research involves the development of a new pipelined ADC mismatch calibration technique that avoids this problem. The new technique differs from other mismatch calibration schemes in that it continuously measures and cancels noise in the ADC output arising from component mismatches during normal operation of the ADC; no special calibration signals or auto-calibration phase are required prior to A\/D conversion. Both the measurement and cancellation of mismatch noise are performed entirely using digital logic, but unlike previously proposed digital calibration techniques the technique does not require additional pipeline stages or bits per stage. The objectives of the research are to 1) refine the technique, 2) quantify its performance limits through simulation and theoretical analyses, and 3) develop a CMOS pipelined ADC prototype that achieves record-setting performance enabled by the technique as a proof-of-principle.","title":"Digital Cancellation of Analog Mismatch Noise in Pipelined ADCs","awardID":"0073552","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["560228"],"PO":["564898"]},"54905":{"abstract":"Humans can recognize objects and scenes using their senses. The ability of learning the appearance of a great number of objects, organizing them into categories, and quickly recognizing them later is an important skill for survival. Replicating such ability in machines would be extremely useful in a great number of scientific and industrial applications such as automatic exploration of databases of medical images, diagnostics and quality control in industrial plants, automatic classification of images and sounds on the web.<br\/><br\/>The aim of this study is to develop a theory of recognition that is applicable any type of sensory data and where no supervision is required for learning and categorization.<br\/><br\/>The approach is probabilistic: object categories are modeled by probability density functions on part appearance and object shape. Detection and recognition are formulated as statistical inference problems. Unsupervised learning of object categories is approached using maximum likelihood. In order to motivate and test the theory the investigators will engage in three applications: automatic classification and retrieval of objects from image databases, of human actions from movies, and of neuronal signals associated with perceptual tasks.","title":"ITR: Learning and recognition of objects in sensory data.","awardID":"0082830","effectiveDate":"2000-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["173279","517415"],"PO":["234178"]},"54916":{"abstract":"Two of the largest issues facing the Internet today are the problems of (1) providing quality-of-service to applications that require some form of \"guarantee\" of bandwidth availability and\/or end-to-end delay, and (2) the problem of avoiding congestion between traditional best-effort flows. Packet scheduling has been the mechanism traditionally used for quality-of-service guarantees while end-system adaptations in the transport layer have been the dominant form of congestion control. Typically, the problems of congestion control and quality-of-service have been addressed as largely independent concerns and separate mechanisms have been developed for each .<br\/> The essence of this project is to study the interplay between congestion control and quality-of-service and the mechanisms that have been employed for realizing each. The starting point is an investigation of using active queue management(AQM) techniques in network routers to provide both congestion control and quality-of-service for IP flows. Active queue management refers to the practice of manipulating the queue of packets at an outbound network interface on a router to bias the performance of network flows. For example, discarding packets from the queue is an active queue management mechanism that is used in the RED (random early detection) congestion avoidance mechanism.<br\/> There does not yet exist any fundamental theoretical understanding of how individual AQM mechanisms effect the performance of network flows. From the perspective of Internet service providers this problem is compounded by the fact that there is little, if any, understanding of how AQM mechanisms can be tuned to realize specific performance goals. The impact of AQM mechanisms on broader measures of network performance is unknown because a framework for analyzing AQM performance does not yet exist. This is in contrast to other approaches for quality-of-service such as packet scheduling. Packet schedulers have been carefully analyzed and frameworks exist for computing bounds on performance metrics such as delay, delay-jitter, packet loss, etc. <br\/> The main goal of this project is to develop the theoretical underpinnings and engineering principles to guide the construction and deployment of AQM for the Internet. This requires an analytic and empirical study of AQM mechanisms for the purpose of understanding the costs, benefits, and scalability limitations of using AQM for congestion control and quality-of-service. The project also contributes to the overall understanding of principles of resource management in routers. In addition, novel AQM schemes that provide new, scalable solutions for quality of service and congestion control are developed.<br\/>Specific objectives include the following:<br\/> 1. Develop an analysis framework for understanding the performance of AQM mechanisms. A novel aspect is consideration of both network-centric performance metrics such as link utilization, and end-system<br\/>or user-centric measures such as response time.<br\/> 2. Develop and analyze novel AQM and hybrid AQM-packet scheduling schemes that realize a spectrum of quality-of-service and congestion control services. A key contribution here is a demonstration of the costs<br\/>and benefits of using packet scheduling v. AQM for scalable implementations of services.<br\/> 3. Demonstrate the effectiveness of the AQM schemes through a case study in managing a research network and supporting an advanced, real-time, distributed-virtual-environment application.<br\/> The results of this project can have a significant impact on the evolution of the Internet to support new levels of service quality and control congestion while ensuring scalability for very large numbers of users and devices.","title":"ITR: Active Queue Management for Scalable Network Services: Theory and Internet Practice","awardID":"0082870","effectiveDate":"2000-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["554765","491562"],"PO":["250082"]},"54927":{"abstract":"With the advent of Internet, it is now anticipated that wireless data services will within a few years surpass the demand for voice services. The explosive demand for wireless data services is forcing the telecom and networking research communities to rethink some of the well-known solutions to the limited capacity problem which is fundamental in such networks.<br\/> In this proposal, a new concept for solving the limited capacity problem in current wireless systems is formulated, and a cost-effective approach to implement the concept is described. The researchers main concept is to circumvent congestions in cellular networks by \"hopping\" to frequencies in the unlicensed band, such as the Industrial, Scientific, and Medical Band (ISM) band (2.4 - 2.5 GHZ) and by diverting traffic to noncongested areas. The researchers propose to integrate cellular and mobile relaying technologies by deploying new devices called mobile relaying stations (MRS's). With MRS's, a mobile host can communicate with the base transceiver stations (BTS's) located in a different cell by switching (or \"hopping\") to the unlicensed frequency band. In this way, a mobile host moving into a congested cell can continue its call that would otherwise be dropped; likewise, a new call that would normally be blocked in a congested cell could be served by borrowing channels from a nearby cell via relaying. As a result, handoff-dropping probability and new call blocking probability of existing cellular systems can be substantially improved. This, in turn, leads to an unprecedented increase in the number of users (i.e., capacity) of these systems if one utilizes the proposed new concept in conjunction with cell splitting. While the hardware complexity of the proposed next-generation wireless systems will be slightly higher than that of the conventional systems, the anticipated benefits in terms of improved network performance, capacity, and connectivity at all times will far outweigh this slight increase in hardware complexity.<br\/> The success of this project could lead to a major paradigm shift in the next-generation wireless network standards. It is also anticipated that this project will enhance the telecommunications and networking education and research programs at the State University of New York at Buffalo, and could pave the way for a Center for Advanced Telecommunications and Networking that houses faculty and graduate students from the Department of Electrical Engineering, Department of Computer Science and Engineering, as well as other departments.","title":"ITR: A New Generation Wireless System with Integrated Cellular and Mobile Relaying Technologies","awardID":"0082916","effectiveDate":"2000-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["511691","193642"],"PO":["7594"]},"54718":{"abstract":"Compilers are an essential component in the software engineering process. They bridge the abstraction gap between high-level programming languages, where the design and reasoning about software takes place, and intermediate or machine level, at which distribution or execution takes place. This project explores strategies for increasing the reliability of compilers by constructing a compiler companion, called a translation validator, that watches the compilation as it unfolds and checks that each transformation preserves the operational meaning of the program being compiled. This promises to be a feasible alternative to compiler verification since it is, in general, easier to verify that a transformation has been performed correctly than to verify the program that performs it. Two major benefits are expected from translation validation. One is a significant increase in the effectiveness of testing during development and maintenance of compilers. The other is a methodology for translating along with the source code the formal arguments obtained by source-level static analyses into corresponding formal arguments at the level of the executable that is being distributed and executed. This would allow a code receiver to check quickly that the code has certain properties of interest, such as secure behavior, without having access to source code.","title":"ITR: Translation Validation for Advanced Compiler Optimizations","awardID":"0081588","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["451874"],"PO":["325495"]},"54729":{"abstract":"One of the goals of third and fourth generation cellular systems is to provide broadband data access to highly mobile users. Space-time transmission strategies, which exploit the presence of multiple antennas at the transmitter or receiver, have been cited recently as one of the key technologies needed to achieve this goal. While there has been great progress on space-time coding and modulation in recent years, most of this work has assumed that perfect channel estimates are available at the receiver. In certain situations, however, it may be difficult or costly to obtain accurate channel estimates. The goal of this project is to design new space-time modulation strategies that do not require channel estimates at the transmitter or receiver. The core idea is a new and general architecture for differential modulation using multiple antennas, which can be applied to any number of antennas and any signal constellation. Modulation techniques adhering to this architecture can be demodulated coherently or noncoherently. These techniques permit the receiver to exploit accurate channel estimates when they are available, but performance degrades only slightly when estimates are not available. The tools developed here also over a fresh perspective on pilot-assisted space-time modulation and provide a systematic way to jointly design the training symbols, receivers, and modulation schemes. This project addresses a broad spectrum of issues, including fundamental performance limits, new modulation and coding techniques, and low-complexity receivers. The ultimate goal of this work is to more fully exploit the potential of multi-antenna radio channels, and in the process reduce the power and bandwidth requirements of wireless communication.","title":"ITR: Differential Modulation in Space and Time","awardID":"0081706","effectiveDate":"2000-09-01","expirationDate":"2004-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["560179"],"PO":["223414"]},"55708":{"abstract":"This Project will develop advanced parallel algorithms and software for simulating complex flows with dynamic interfaces. The development of scalable, parallel high-accuracy algorithms for simulating such flows poses enormous challenges in computational science. The project will use these algorithms for microstructural simulation of blood flow. This application provides an excellent testbed for the methods: it is extremely computationally challenging and of critical medical importance.<br\/><br\/>Blood flow belongs to a class of flow problems with dynamic interfaces. Blood is a mixture of interacting gel-filled solid sells and fluid plasma. Current blood flow models are macroscopic, treating the mixture as a homogeneous continuum. Microstructural models resolve individual cells deformations and their interaction with the surrounding plasma. Because of the computational difficulties of resolving tens of thousands of dynamically deforming cells, no one to date has simulated realistic blood flows at this level. Yet such simulations are necessary in order to gain a better understanding of blood damage - which is central to improved artificial organ design - and for the development of more rational macroscopic blood models.<br\/><br\/>Simulating flows with dynamic interfaces is much more difficult than flows in well-understood fixed domains. The central challenges are to develop numerical algorithms that stably and accurately couple the moving fluid and solids, and geometric algorithms for computing the resulting dynamic meshes. This project takes the approach of treating both fluid and solid domains as collections of grid points, with associated meshes, that evolve over time and devising numerical algorithms that couple the domains seamlessly. It will attack the difficulty of creating and managing the evolving mesh by developing scalable parallel algorithms for the convex hull, Delaunay triangulation, and mesh partitioning components. With careful attention to fundamental algorithmic issues, these cheap geometric computations will enable these dynamic flow simulations to scale to thousands of processors as on mult-teraflop systems.<br\/><br\/>This research will benefit a wide community of scientists and engineers. The computational algorithms will be widely applicable to a variety of fluid-solid and fluid-fluid interaction problems. More generally, the core parallel computational geometry kernels will provide generic support for the geometric computations underlying many dynamic irregular problems. The project will distribute a portable library of efficient implementations of these algorithms. Also, the project will undertake a broad-based, interdisciplinary program integrating research and education. It will be part of a new program in Computational Science and Engineering, serving as the archetype of how applications, computational, computer, and mathematical scientists can work together to tackle societal problems that cannot be solved solely by any one discipline.","title":"ITR: Simulation of Flows with Dynamic Interfaces on Multi-Teraflop Computers","awardID":"0086093","effectiveDate":"2000-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["475261","485154","548200","527004"],"PO":["565272"]},"41309":{"abstract":"The goal of this research project is to develop, implement, and test a methodology for building inductive databases (IDBs), which extend conventional databases by integrating in them inductive inference capabilities. Such capabilities allow a database to answer questions that require synthesizing plausible knowledge on the basis of the facts in the databases. The methodology integrates a database with a host of inductive inference operators that can be evoked automatically through scripts, called Knowledge Scouts, and expressed in a Knowledge Generation Language. Proposed ideas are tested experimentally on two datasets, one characterizing life changes in post-communist countries, and the second relating lifestyles with diseases. <br\/>http:\/\/www.mli.gmu.edu","title":"Inductive Databases and Knowledge Scouts","awardID":"9906858","effectiveDate":"2000-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["355581"],"PO":["563751"]},"55609":{"abstract":"This is the first year funding of a five-year continuing award. The world of business and organizations is entering a period of dramatic and rapid technology-based transformations that many people believe will be as significant as those that characterized the Industrial Revolution. This project will investigate the profound socioeconomic changes likely to be associated with such transformations through conducting empirical research that is broad-based, in-depth, and longitudinal. Using multiple theoretical and methodological approaches, a panel of strategically-selected firms in established as well as entrepreneurial and emergent businesses will be tracked over time. A comprehensive set of systematic and grounded empirical data in these organizations will be collected and analyzed over five years, and will generate deep insights and general theories about what is really happening as organizations use information technology to transform how they work and interact with the market over time.","title":"ITR: Social and Economic Implications of Information Technology: What Is Really Happening?","awardID":"0085725","effectiveDate":"2000-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[142450,"551789","439054",142453,142454],"PO":["565227"]}}