{"187671":{"abstract":"Sequential decision making in the presence of uncertainty arises in problems that span transportation and logistics, energy, health and military operations. Real-world instances of these problems are fundamentally intractable, beyond the reach of our most powerful computers. Parallel research among communities such as operations research and computer science has produced a diversity of algorithmic strategies that offer unique features, but significant language and notational barriers have limited the sharing of ideas. This workshop will consist of a series of conversations so that leading professionals, post-docs and students from both communities will better learn the languages of both communities. A major activity will be the design of challenge problems that benefit from the combined skills of both communities. For example, the problem of optimizing fleets of UAVs is a problem class that would be solved in very different ways by each community. Computer scientists tend to solve these as swarms of loosely coordinated, independent agents. Operations researchers have the tools to optimize these fleets using large-scale optimization, reflecting the perspective of a single controller. <br\/><br\/>If successful, the workshop will lead to avenues for improved collaboration between the operations research and computer science communities, including a roadmap for future collaboration between the two research communities. Ultimately this should lead to increased capabilities for solving problems that have been intractable up to now by exploiting the unique skills that each community brings, most prominently the computational power of machine learning and mathematical programming.","title":"Workshop: A Conversation Between AI and OR on Sequential Decision Making,held at Rutgers University, Spring 2012.","awardID":"1152008","effectiveDate":"2011-10-01","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"5514","name":"OPERATIONS RESEARCH"}}],"PIcoPI":[503132],"PO":["565139"]},"187012":{"abstract":"The focus of this project is on cloud computing.<br\/><br\/>The Cloud4Home project strives to enhance services and service delivery by moving from the current \"in the cloud\" vs. \"at the edge\" model of cloud computing to a hybrid model in which services can easily leverage both types of resources. <br\/><br\/>Concurrent with the rapid gains in popularity of cloud computing facilities and infrastructure is an even more impressive continued increase in the capabilities of the end devices used in the Internet's periphery. In fact, major hardware manufacturers are releasing new end devices as frequently as every six months, whereas server systems typically experience a multi-year replacement cycle. This raise the interesting challenge of how to best combine cloud-provided services, like those offered commercially, with services that can efficiently run on consumer devices like smartphones, iPads or netbooks, laptops and desktops nodes, and game consoles. In particular, purely end-point based solutions cannot take advantage of the large storage and computational capacities present in large scale datacenters. Conversely, current \"thin client\" models in which end devices \"simply access the Internet\" can suffer from high and variable delays in accessing and using remote resources. Preferable to either extreme would be a solution that (1) can leverage the lower costs of using local resources and exploiting locally available state and avoid potential issues with data privacy or security for cloud-based operation, while at the same time (2) utilize Internet resources when those are not encumbered by undue costs like high latency or undue communication overheads.<br\/><br\/>The specific technical requirements for such enhanced services include:<br\/> -jointly using remote cloud platforms with local, nearby resources available in the home, office or other \"private\" environment; <br\/> -decoupling the physical location of state and service execution from the applications that interface with such services\/state, and <br\/> -exposing higher-level \"properties\" of the diverse capabilities of the aggregate resources and then use this heterogeneity to better meeting application requirements and satisfy service policies.<br\/><br\/>To achieve these goals, this project introduces the system-level abstraction of resource containers, which represent pools of resources in the Cloud4Home environment tagged with specific properties or features. Resource containers will be realized for and evaluated with representative @home and server systems and with services that combine computational with storage needs. If successful, the Cloud4Home prototype can be a valuable vehicle to explore the myriad of other challenges in these environments - from dynamic resource discovery to security and privacy.","title":"EAGER: Resource Containers: Addressing Resource Heterogeneity for Cloud4Home Applications","awardID":"1148600","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["517873"],"PO":["551712"]},"186044":{"abstract":"This award provides funding for a collaborative project between Ohio State University, Cornell University, The Indian Institute of Science - Bangalore, the Wildlife Institute of India, and the Indian Institute of Information Technology - Allahabad. The dramatic dwindling of forests and concomitant escalation in human-wildlife conflicts are resulting in broad environmental impact, including large economic and social costs, increasing human deaths in areas used by large mammals, and animal population decline. This project enables a baseline operational wireless sensor network system for protection of animals, humans, and the forest. <br\/><br\/>The forest setting involves complex scenes demanding the discrimination of several targets of interest in a highly cluttered setting as well as discrimination of their intent and behaviors. Activity patterns evolve in a naturally adversarial environment. The system architecture being developed integrates in a transformative way a suitably rich set of sensing modalities with intent inferencing, learning, optimization, and deployment techniques, to monitor a diverse set of targets. Mature system components are to be deployed in Panna, a tiger reserve in central India, in close cooperation with domain experts and forestry management. The project is a collaboration between researchers in the US and India who are substantially involved in complementary aspects of wildlife related research. A subsequent protection-centric effort in the US is envisioned that builds upon the lessons learned by this effort. <br\/><br\/>Successful realization of system components and a baseline system would lead to an assessment of the potential benefits of using wireless sensor networks for protection related to forests and potential transition into production use. Over time, this will help establish credible early-warning systems, and monitoring protocols for animal use of human areas and human use of forest areas that can support recovery efforts. This project is part of the Pervasive Communications and Computing Collaboration (PC3) initiative.","title":"PC3: Collaborative Research: Wireless Sensor Networks for Protecting Wildlife and Humans","awardID":"1143651","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["560670"],"PO":["564181"]},"188486":{"abstract":"This project provides student travel support for the IEEE International Conference on Network Protocols (ICNP)held in Vancouver, Canada on Oct 17-19, 2011. The project allows a selected set of US students interested in network protocols to travel to this conference and benefit from the talks and other events. ICNP is a premier conference in this area and exposure to students of cutting edge research is essential.","title":"Student Travel Support for IEEE ICNP 2011","awardID":"1156463","effectiveDate":"2011-10-15","expirationDate":"2012-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["518380"],"PO":["535244"]},"187981":{"abstract":"Despite their increasingly ubiquitous deployment, RFID systems are plagued with a wide variety of security and privacy threats. A large number of these threats arise due to the tag?s promiscuous response to any reader requests. This renders sensitive tag information easily subject to unauthorized reading. It also incites different forms of relay attacks whereby a colluding pair, by relaying information between a legitimate tag and reader, can successfully impersonate the legitimate tag without actually possessing it.<br\/><br\/>This research explores novel context-aware security and privacy mechanisms by leveraging the newly-equipped sensing capabilities on the next generation (passive) RFID tags. The goal is to provide improved protection against unauthorized reading and relay attacks without undermining the usability and efficiency offered by the RFID systems. The project also includes a feasibility study of the proposed mechanisms in terms of both economical and power constraints, and a systematic analysis of possible (new) sensor-centric attacks. The overall proposed activities range from system design and analysis to implementation and performance measurements. <br\/><br\/>More broadly, this exploratory work intends to arrive at a better understanding of the feasibility of utilizing parameters derived from the physical world to solve security and privacy issues of the cyber systems. In terms of educational activities, new security courses focusing on resource-constrained devices and lightweight cryptographic tools will be developed.","title":"EAGER: Collaborative Research: Towards Context-Aware Security and Privacy for RFID Systems","awardID":"1153573","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["520254"],"PO":["562974"]},"186441":{"abstract":"This travel grant supports two US participants to attend the International Workshop on Stochastic Image Grammars (SIG-11). The notion of stochastic image grammars encompasses hierarchical representations of objects and events occurring in images and video, and their associated learning and inference algorithms. The virtue of image grammars lies in their expressive power to represent an exponentially large number of object and event configurations by using a relatively much smaller vocabulary, and a few compositional rules. <br\/><br\/>Statistics, machine learning, natural language processing, and cognitive psychology experience a resurgence of stochastic grammars. In computer vision, however, this momentum seems to be present only in the area of 2D object recognition. The main objective of the workshop is to promote interdisciplinary research among these traditionally separate scientific disciplines toward grammar-based formulations of a wider range of vision problems, beyond object recognition, such as, e.g., 3D structure from motion, and activity recognition. The workshop is also aimed at reducing the apparent disconnect between research groups working on image grammars, by addressing the need for a unified theoretical framework. To this end, SIG-11 provides a forum for sharing research experiences in grammars between the vision community and the keynote speakers who are experts in cognitive psychology, neuroscience, and natural language processing. Solicited peer-reviewed papers are expected to be published in the proceedings of the 13th International Conference on Computer Vision.","title":"SIG-011: International Workshop on Stochastic Image Grammars","awardID":"1145358","effectiveDate":"2011-10-01","expirationDate":"2012-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["542093"],"PO":["564316"]},"197155":{"abstract":"Expressing parallel computations over complex shared-memory data structures has always been a vexing issue in parallel programming. On one hand, popular task-based programming models do not provide first-class abstractions for isolation and locality. On the other, Actor-based programming naturally captures locality but is unsuitable for computations on large shared data structures. The present project partially bridges the gap between these two styles of parallelism through Chorus, a new programming model for parallel computations over unstructured, continually changing shared-memory data structures. <br\/><br\/>The key abstraction of Chorus is an object assembly: a local, isolated region in the heap equipped with a thread of control. Assemblies can imperatively modify themselves, merge with other assemblies, and split into smaller assemblies?through these operations over assemblies, Chorus captures unpredictable, dynamic changes to parallelism. This makes Chorus an ideal programming model for many irregular data-parallel applications (e.g., meshing, clustering), which exhibit fine-grained data-parallelism in typical executions but no parallelism in the worst case, and whose parallelization remains an open and difficult challenge.<br\/><br\/>The predicted outcomes of the project include new insights into the semantic foundations of Chorus and new language constructs integrating Chorus with existing abstractions for asynchronous task creation, directed synchronization, and locality. On the system-building end, the project will integrate Chorus with the Habanero Java parallel programming language, and implement a compiler and runtime for the resultant language. The performance and programmability of this language will be thoroughly evaluated using benchmarks largely consisting of emerging irregular workloads.","title":"SHF: Medium: Collaborative Research: Chorus: Dynamic Isolation in Shared-Memory Parallelism","awardID":"1242507","effectiveDate":"2011-10-01","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}}],"PIcoPI":["551025"],"PO":["565272"]},"186056":{"abstract":"This award provides funding for a collaborative project between Ohio State University, Cornell University, The Indian Institute of Science - Bangalore, the Wildlife Institute of India, and the Indian Institute of Information Technology - Allahabad. The dramatic dwindling of forests and concomitant escalation in human-wildlife conflicts are resulting in broad environmental impact, including large economic and social costs, increasing human deaths in areas used by large mammals, and animal population decline. This project enables a baseline operational wireless sensor network system for protection of animals, humans, and the forest.<br\/><br\/>The forest setting involves complex scenes demanding the discrimination of several targets of interest in a highly cluttered setting as well as discrimination of their intent and behaviors. Activity patterns evolve in a naturally adversarial environment. The system architecture being developed integrates in a transformative way a suitably rich set of sensing modalities with intent inferencing, learning, optimization, and deployment techniques, to monitor a diverse set of targets. Mature system components are to be deployed in Panna, a tiger reserve in central India, in close cooperation with domain experts and forestry management. The project is a collaboration between researchers in the US and India who are substantially involved in complementary aspects of wildlife related research. A subsequent protection-centric effort in the US is envisioned that builds upon the lessons learned by this effort. <br\/><br\/>Successful realization of system components and a baseline system would lead to an assessment of the potential benefits of using wireless sensor networks for protection related to forests and potential transition into production use. Over time, this will help establish credible early-warning systems, and monitoring protocols for animal use of human areas and human use of forest areas that can support recovery efforts. This project is part of the Pervasive Communications and Computing Collaboration (PC3) initiative.","title":"PC3: Collaborative Research: Wireless Sensor Networks for Protecting Wildlife and Humans","awardID":"1143685","effectiveDate":"2011-10-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[499286],"PO":["564181"]},"181282":{"abstract":"","title":"III: Small: RUI: Practical Inference on Real-World Networks of Data","awardID":"1116439","effectiveDate":"2011-10-01","expirationDate":"2014-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[485755],"PO":["565136"]},"186233":{"abstract":"This award will support Quantum Information Processing Workshop to be held in Montreal, Quebec, Canada, on December 12-16, 2011, at the Mathematics Research Center at the University of Montreal. More detailed conference information for QIP 2012 may be found at http:\/\/www.crm.umontreal.ca\/Quantum2011\/. This workshop is the central event in the area of Quantum Computing and, more generally, Quantum Information Science. It is expected that QIP will bring together about 300 leading researchers in theoretical aspects of quantum information and computation, and play a role as one of the most important venues for the groundbreaking research in theoretical computer science. NSF support will help broaden participation at the QIP Workshop by subsidizing the travel for participants who might not otherwise attend QIP, and assist with the venue costs. Organizers aim at increasing the number of student and postdoctoral participants from the under-represented groups.","title":"Travel Support for the 15th Quantum Information Processing Workshop (QIP 2012)","awardID":"1144366","effectiveDate":"2011-10-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[499728],"PO":["565157"]},"186596":{"abstract":"The PIs and Co-PIs of grants supported through the NSF-NIH-BMBF Collaborative Research in Computational Neuroscience (CRCNS) program meet annually. This will be the seventh meeting of CRCNS investigators, and the first involving US-German projects supported by NSF\/NIH and BMBF. The meeting brings together a broad spectrum of computational neuroscience researchers supported by the program, and includes poster presentations, talks and plenary lectures. The meeting is scheduled for October 9-11, 2011 and will be held at Princeton University.","title":"CRCNS 2011 PI meeting at Princeton University","awardID":"1146294","effectiveDate":"2011-10-01","expirationDate":"2012-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}}],"PIcoPI":["556728"],"PO":["564318"]},"181591":{"abstract":"Lattice cryptography is a cutting-edge area of cryptology which has the potential to deliver new and better solutions to many security problems. Lattice algorithms are routinely used to attack and analyze the security of lattice cryptography. However, our current understanding of state-of-the-art lattice algorithms is weak. As a result, the usability of lattice cryptography is severely limited by the lack of high confidence security estimates. Lattice algorithms are investigated, with the goal of providing better understanding of known algorithms, and develop new algorithms as well. Specific goals of the project include: (1) the development of practical variants of the asymptotically fastest known lattice algorithms, (2) the study of analytic models that can be used to predict and explain the behavior of heuristic approaches to lattice problems, and (3) the use of the new models and algorithms to provide concrete security estimates for lattice cryptographic functions. Lattice algorithms are studied using rigorous mathematical methods that provide provable guarantees on the behavior of the algorithms, coupled with extensive practical experimentation to gauge the practical significance of the theoretical results. Computational problems on lattices arise naturally in many areas mathematics and science, from algebraic number theory and communication theory to crystallography and combinatorial optimization. The applicability of the improved lattice algorithms resulting from this project extends beyond cryptography, to reach those other areas as well. Algorithms, experimental data, and instructional material developed in the course of this investigation will be made widely available on the Internet.","title":"TC: Small: Algorithmics and Security of Lattice Cryptography","awardID":"1117936","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[486529],"PO":["565239"]},"181360":{"abstract":"A crucial problem in dependability of concurrent and distributed software systems, which have become prevalent with the advances in service-oriented architecture, cloud computing, multi-core hardware, is the coordination of different components that form the whole system. In order to complete a task, components of a software system have to coordinate their executions by interacting with each other.<br\/>Message-based communication is an increasingly common interaction mechanism used in concurrent and distributed systems where components interact with each other by sending and receiving messages. The objective of the proposed research is to develop novel techniques for specification, analysis, and verification of message-based interactions.<br\/><br\/>The proposed research will develop a hierarchy of communication contract specification models and investigate analysis and verification problems for each class. Within the proposed framework the interactions among components of a software system (called peers) will be modeled as conversations describing the global sequence of messages exchanged among the peers. The proposed research will result in a toolset for analyzing communication contracts and verifying properties of conversations generated by a set of peers that follow a<br\/>given communication contract. The research will have broader impact<br\/>in at least three areas. By developing techniques for analysis and verification of message-based interactions in concurrent and distributed systems, the research will improve the dependability of software systems in a wide variety of application domains, including e-commerce, consumer applications, and telecommunications. Secondly, the research activity will help to expose graduate and undergraduate students to analysis and verification problems in concurrent and distributed systems, and message-based communication, through a variety of educational activities including courses, seminars and individual research mentoring. Finally, the research activity will help to disseminate the knowledge, techniques and tools developed for analysis and verification of communicating systems through publishing in the open literature, and making the software tools available in public domain.","title":"SHF: Small: Collaborative Research: Formal Analysis of Distributed Interactions","awardID":"1116836","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["499317"],"PO":["565264"]},"181030":{"abstract":"A broad range of problems in computer graphics rendering, appearance acquisition, and imaging, involve sampling, reconstruction, and integration of high-dimensional (4D-8D) signals. Real-time rendering of glossy materials and intricate lighting effects like caustics, for example, can require pre-computing the response of the scene to different light and viewing directions, which is often a 6D dataset. Similarly, image-based appearance acquisition of facial details, car paint, or glazed wood requires us to take images from different light and view directions. Even offline rendering of visual effects like motion blur from a fast-moving car, or depth of field, involves high-dimensional sampling across time and lens aperture. The same problems are also common in computational imaging applications such as light field cameras. While the PIs and others have made significant progress in subsequent analysis and compact representation for some of these problems, the initial full dataset must almost always still be acquired or computed by brute force which is prohibitively expensive, taking hours to days of computation and acquisition time, as well as being a challenge for memory usage and storage.<br\/><br\/>The PIs' goal in this project is to make fundamental contributions that enable dramatically sparser sampling and reconstruction of these signals, before the full dataset is acquired or simulated. The key idea is to exploit the structure of the data that often lies in lower-frequency, sparse, or low-dimensional spaces. Their recent collaboration on a Fourier analysis of motion blur has shown that the frequency spectrum of dynamic scenes is sheared into a narrow wedge in the space-time domain. This enables novel sheared (not axis-aligned) filters and a sparse sampling. The PIs will build upon these preliminary results to develop a unified framework for frequency analysis and sparse data reconstruction of visual appearance in computer graphics. To these ends, they will first lay the theoretical foundations, including a novel frequency analysis of Monte Carlo integration and 5D space-time analysis of light fields. They will then develop efficient practical algorithms for a variety of problem domains, including sparse reconstruction of light transport matrices for relighting, sheared sampling and denoising for offline shadow rendering, time-coherent compressive sampling for appearance acquisition, and new approaches to computational photography and imaging.<br\/><br\/>Broader Impacts: From a theoretical perspective, this project will develop a fundamental signal-processing analysis of light transport and appearance and imaging datasets, which will provide the foundation for further work not just in computer graphics but in signal-processing, computer vision, and image analysis as well. Project outcomes will apply to diverse sets of problems and will lead to transformative advances across the spectrum of rendering and imaging applications. The PIs will leverage existing collaborations with industry to transition the new technologies to practical production use. Outreach to K-12 students and the public will be enabled by a new science popularization blog that will leverage the public's excitement for advances in digital photography to introduce novel technical concepts, as well as by events such as the Computer Science Education Day for high school students at UC-Berkeley. The new algorithms and datasets resulting from this work will be made available to the research community; moreover, imaging algorithms will be released in open-source format to work with consumer digital and cell-phone cameras.","title":"CGV: Small: Collaborative Research: Sparse Reconstruction and Frequency Analysis for Computer Graphics Rendering and Imaging","awardID":"1115242","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[485160],"PO":["565227"]},"180062":{"abstract":"Balan<br\/>DMS-1109498<br\/><br\/> The investigator and his colleagues study new methods to recover a signal from a nonlinear processing scheme. Recently two far-reaching discoveries have been made that connected the nonlinear information (magnitudes of frame coefficients) to certain scalar products in larger embedding spaces. Thus the initial problem, which is fundamentally nonlinear, is recast into a linear reconstruction problem coupled with a rank-one approximation problem. When the linear redundant representation is associated with a group representation (such as Weyl-Heisenberg, or windowed Fourier transform), then the relevant tensor operators inherit this invariance property. Thus a fast (nonlinear) reconstruction algorithm is possible. This approach suggests a new signal representation model, where signals are not represented simply by vectors in a Hilbert space, but rather by operators in a larger dimensional Hilbert-Schmidt like-space, similar to the quantum state theory. These methods use results from a wide range of mathematical areas such as harmonic analysis, operator theory, and polynomial algebras.<br\/><br\/> Results of this project have a practical application to areas such as signal processing, optical communication, quantum computing, and X-ray crystallography. Besides advancing the scientific understanding in applied harmonic analysis, this project broadens the two-way communication between mathematics and electrical engineering while promoting teaching, training and learning. The investigator is training graduate students for a globally competitive STEM force through his contacts with industry and international research labs. The project is supported by the Division of Mathematical Sciences and the Division of Computing and Communication Foundations.","title":"Nonlinear Signal Processing and Distributed Optimal Control using Frames and Operators Algebras","awardID":"1109498","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1266","name":"APPLIED MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["538129"],"PO":["562372"]},"181393":{"abstract":"Web applications are an increasingly important part of many aspects of the society, from social interactions to business transactions. Hence, security of web applications is an extremely important and urgent problem. Since web applications are easily accessible, and often store a large amount of sensitive user information, they are a typical target for attackers. In particular, attacks that target input validation vulnerabilities are extremely common and effective. Some of these attacks exploit well-known vulnerabilities, such as cross-site scripting and SQL injection, whereas some others exploit application-specific vulnerabilities that are hard to identify because they depend on the particular input validation logic of the target application. In general, these attacks exploit erroneous or insufficient input validation and sanitization to inject malicious data that can result in execution of harmful commands and access to sensitive information.<br\/><br\/>This research aims to identify and mitigate these vulnerabilities in web applications by performing automatic checking of input validation and sanitization operations. The key insight for this work comes from the observation that developers often introduce redundant checks in both the front-end (client) and the back-end (server) component of a web application. Client-side checks are fast and can improve performance and responsiveness of the application, but can be easily circumvented; server-side checks are hard to circumvent, but require network round-trips and additional server-side processing. Our intuition is that the checks performed at the client and server sides should enforce the same set of constraints on the inputs: if client-side checks are more restrictive, the server may accept inputs that legitimate clients can never produce, as malicious users can easily bypass client-side checks. Conversely, if server-side checks are more restrictive, the client may produce requests that are subsequently rejected by the server, which is not ideal from a performance point of view. This research will develop new techniques based on program analysis, string analysis, and code synthesis that can identify, map, model, and compare the set of checks performed on the client and server sides. These techniques will be able to identify and report inconsistencies between the two sets of checks and (semi)automatically extend the checks to eliminate such inconsistencies. By making web applications more secure and efficient, this research has the potential to benefit the increasingly large part of the society that relies on the use of web applications for its daily activities.","title":"TC: Small: Collaborative Research: Viewpoints: Discovering Client- and Server-side Input Validation Inconsistencies to Improve Web Application Security","awardID":"1116967","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["486421","535036"],"PO":["564388"]},"184166":{"abstract":"Virginia Polytechnic Institute and State University (VT) is partnering with the Henrico County Public School District (HCPS) on a planning grant to develop a CE21 project that will build Computational Thinking (CT) activities into current instructional practices across core middle school curriculum. The project will locate nascent CT activities in the existing curriculum, reinforce and develop the overlap between the curricular area and the target CT area, and subsequently reinforce the CT content in a short, reinforcing instructional unit. This planning grant will be used to prepare for the research by creating, piloting, testing and assembling instructional interventions and materials, approaches to learning progressions in CT, management arrangements and practices across and within VT and HCPS, and advisors across the areas that will need development and oversight in full proposal. The overarching research questions for the full proposal are (1) whether the approach of integrating CT is viable across diverse educational environments, teachers and students, (2) whether the approach has significant negative entailments (\"show stoppers\"), and (3) whether the approach will prove to be scalable across different school systems. <br\/><br\/>The CS department at VT has a long history of innovative engagement with K-12 as well as university pedagogy in computational thinking, mathematics, and science instruction. HCPS is a mixed SES, multi-racial district of 50,000 students, with a ten-year history of integrating laptop use into instruction in grades 6-12. The HCPS administration has identified CT as a needed area for growth and has the backing of the District School Board. They have a vision of 3-4 CT activities in every class in every grade across core curricular areas. HCPS?s vision plus VT's CT expertise and the PI's prior experience with the development and scaling up of educational research position this project to produce transformative knowledge and practices.","title":"Planning Grant: Integrating Computational Thinking Into Middle School Curriculum","awardID":"1132227","effectiveDate":"2011-10-01","expirationDate":"2015-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}}],"PIcoPI":["563439",493880,"563440","531150",493883],"PO":["561855"]},"179887":{"abstract":"Aldroubi<br\/>DMS-1108631<br\/><br\/> There is a growing interest in computer science, engineering, and mathematics for modeling signals in terms of union of subspaces and manifolds. Subspace segmentation and clustering of high-dimensional data drawn from a union of subspaces are especially important with many practical applications in computer vision, image and signal processing, communications, and information theory. For example, recent paradigms for reconstructing signals assume models that consist of union of subspaces, e.g., the reconstruction of signals with finite rates of innovation. Another example is in compressed sampling where signals are assumed to be sparse in some basis or in some dictionary. This assumption implies that the signals live in a union of subspaces. The subspace clustering problem in computer vision is yet another important example in which data are drawn from a union of low-dimensional subspaces. Thus, a mathematical framework for finding such models from observed data is fundamental. In this project the investigator develops a mathematical framework together with algorithms for data modeling in terms of union of subspaces and manifolds. The mathematical theory is connected to the geometry of Hilbert and Banach spaces, topology, nonlinear approximation, optimization, and probability.<br\/><br\/> The investigator develops a mathematical framework and algorithms for describing data by representing them as composed of components that live in restricted sets of the data space, for instance, in subspaces or manifolds. The theory and methods developed by the investigator unify, extend, and complement some of the techniques used in sampling theory, subspace clustering, and the dictionary design problem. The applications are fundamental to many problems in engineering and biomedicine, including motion tracking in videos, data classification and segmentation such as face recognition, and brain morphology. The project is supported by the Division of Mathematical Sciences and the Division of Computing and Communication Foundations.","title":"Union of Subspaces and Manifold Data Modeling: Theory, Algorithms, Testing, and Applications","awardID":"1108631","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1266","name":"APPLIED MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["551713"],"PO":["562372"]},"180371":{"abstract":"Energy sustainability is a theme of national and worldwide importance. Smart-Grid environments are focused on creating and using information and communication technologies to support new and potentially more sustainable ways of producing, transmitting, distributing, and consuming electricity. This project focuses on creating a socio-computational system that enables citizens to make informed choices about their energy consumption, share their decisions with others and visualize the consequences of their own actions. <br\/><br\/>New social-computational systems are needed to facilitate this sort of citizen engagement with the energy economy because (1) most citizens are unaware of these new technological developments; (2) information presentation is poorly designed; and (3) the social context of individual energy use is ignored resulting in few social interactions and collaborations. All of these challenges lie at the intersection of human behavior (both individual and social levels) and technology.<br\/><br\/>Intellectual Merit: The two overarching goals of this project are (a) the creation of transformative theoretical frameworks for understanding social-computational foundations for these settings, making our methodologies, components, architectures, requirements, and guidelines applicable to a large number of other social-computational systems (for example, smart cities and health-care) and (b) the development of human-centered systems for fostering smart communities in Smart-Grid environments that will turn passive consumers of energy into informed, active decision makers. <br\/><br\/>Broader Impacts: The project will lead to new tools and strategies to increase the use of Smart-Grid technologies, thereby reducing overall national energy usage and dependence on foreign energy sources. In addition, the project will make strides in including and supporting the ability of marginal and underrepresented populations to use these technologies, thereby avoiding a digital-energy divide. The Principle Investigators are working with the El Pueblo M\u00e1gico after-school effort at Sanchez Elementary School in Lafayette, Colorado, to engage students and their families in fostering energy awareness and responsibility, providing broader views on end-user energy concerns.","title":"Theoretical Frameworks and Socio-Technical Systems for Fostering Smart Communities in Smart Grid Environments","awardID":"1111025","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":[483372,483373],"PO":["563324"]},"181571":{"abstract":"Computers were invented to automate tedious and error-prone<br\/>tasks, especially in the context of numerical calculations for<br\/>scientific simulation. Given the importance and difficulty of <br\/>developing these simulations, it makes sense to study whether <br\/>computers can assist in their production as well. This project <br\/>focuses on the open-source project Sundance, which provides<br\/>high-level syntax to describe finite element methods (FEM) for the<br\/>numerical solution of partial differential equations, freeing users <br\/>from the burdens of low-level programming. This approach can reduce <br\/>development time from months to days or even hours, allowing <br\/>scientists and engineers to get correct answers more quickly. <br\/>Sundance is useful software starting from a solid theoretical basis,<br\/>where the structure of finite element operators are derived and<br\/>analyzed from software-based Frechet differentiation of variational<br\/>forms.<br\/><br\/>Via this domain-specific embedded language, Sundance users (domain<br\/>scientistis and engineers) can express and simulate nonlinear processes <br\/>with little more difficulty than linear ones; Jacobians are calculated <br\/>internally and automatically. This robust system automates not only <br\/>standard simulations, but also sensitivity calculations, eigenvalue<br\/>problems, and PDE-constrained optimization, all through the language of<br\/>differentiation, providing a simple gateway to efficient ``embedded''<br\/>algorithms for optimization and control. Furthermore, in this project, <br\/>Sundance will be extended to run on emerging architectures such as <br\/>multicore CPU and GPU machines. New low-complexity finite element <br\/>algorithms based on Bernstein polynomials will be developed and included <br\/>within Sundance to further exploit this new hardware. Thus, this project <br\/>represents concrete transformational contributions not only automating<br\/>mathematical software but in core numerical algorithms, broadening the<br\/>circle of domain specialists with access to leading-edge simulation<br\/>technology.","title":"AF: Small: Metanumerical Computing for Emerging Architectures: Automated Embedded Algorithms for Partial Differential Equations on Multicore Platforms","awardID":"1117794","effectiveDate":"2011-10-01","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[486475,"552996",486477],"PO":["565251"]},"182440":{"abstract":"This project explores the diffusion of Web 2.0 technologies among science educators and the ways these technologies are used to build teacher professional communities of practice (CoP). Such technologies are claimed to offer new ways to foster interaction and community building, content creation, and knowledge building and management. However, there is very little research examining the extent to which use of these technologies foster professional CoPs among educators. The project uses a replicated case study design, with replications corresponding to two online communities from the National Science Teachers Association (NSTA) Learning Center. NSTA is a member-driven organization that promotes excellence in science teaching and learning; the Learning Center has approximately 70,000 users including science teachers, science supervisors, administrators, scientists, and others involved in science education. The study uses a longitudinal approach and multiple methods including surveys, web metrics, interviews, and content analysis of discussion forums to characterize these CoPs, understand what motivates educators to participate, assess how participation leads to the development of sociotechnical capital, and evaluate how sociotechnical capital influences professional outcomes including self-efficacy, instructional practices, and job satisfaction.<br\/><br\/><br\/>This work stands to have significant broader impacts by establishing the role that virtual CoPs can play in continuous learning for educators in general and for science educators in particular. A focus on science is especially important in light of the national emphasis on science, technology, engineering, and mathematics (STEM) education, the lack of research on science teaching relative to other academic subjects, and the mismatch in the demand for and supply of professional development opportunities for K-12 science teachers. In addition, because of the relatively low and declining cost of access to web-based applications of the sort studied in this project, such avenues for continuous learning and access to high-quality resources could be widely available to science teachers in both low-income school districts and in rural areas where access to physical resources or collocated colleagues is extremely limited. Whereas collocated peers and in-person opportunities to participate in professional community activities may be scarce, virtual CoPs could go far to address the needs of K-12 science educators.","title":"VOSS - Use of Web 2.0 Technologies to Build Distributed Communities of Practice among K-12 Science Educators","awardID":"1122692","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7642","name":"VIRTUAL ORGANIZATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":[488767,488768,488769,488770,488771],"PO":["565342"]},"181351":{"abstract":"In recent decades synthetic speech has become a ubiquitous and increasingly seamless aspect of human-machine interfaces. Although cars, microwaves, phones, and kiosks all \"talk\" in human-like ways, the naturalness and personality of these voices fall short of human expression. While this may not matter for many text-to-speech (TTS) applications, over two million Americans with severe speech-motor impairments require assistive communication aids with TTS output. Concatenative TTS synthesizers yield highly intelligible voices, yet many assistive devices rely on small footprint, formant synthesis that sounds robotic and has poor intelligibility. Moreover, the choice of voices on conventional devices is limited and does not reflect the user; it is not uncommon for a child to use the same voice her whole life and for her peers to share that same voice even when using different devices. This lack of attention to the individuality of synthetic voices has consequences on adoption of assistive technology as an extension of the user, and may adversely impact societal attitudes toward the user group.<br\/><br\/>In her prior work the PI began to address these issues by adapting a concatenative synthesizer constructed from acoustic recordings of a healthy talker using vocal source characteristics obtained from a target talker with speech impairment. The adapted voice was highly intelligible and conveyed the target user's identity, yet it also retained substantial elements of the healthy talker's identity due to the influence of vocal tract filter characteristics. This suggests that personalized speech synthesis may be more successful utilizing an alternative approach, in which acoustic and articulatory data from healthy talkers are combined with both source and filter characteristics from target talkers to generate an individualized voice. In this project, the PI will develop hybrid statistical parametric synthesis techniques to model vocal tract and source characteristics of impaired talkers, with the goal of generating highly intelligible and personalized synthetic speech. The PI envisages a future where source and filter parameters of a Hidden Markov Model (HMM) based synthesizer can be adapted to model a child user's vocal tract and modified over time to \"grow\" with his maturing vocal system, fostering a stronger personal connection between the user and the communication device.<br\/><br\/>Broader Impacts: This project strives to make communication accessible and socially fulfilling by designing an enabling technology that blurs the line between system and user. The human voice is not merely a signal; it has an individualized and personal quality that impacts how others perceive us and how we interact with those around us. The ultimate goal of this work is to afford users of TTS the same ownership and individuality as the natural voice. Project outcomes will have broad impact both on users of assistive aids and able-bodied users of TTS technologies. The research may also lead to a novel and innovative means of assessing the nature and articulatory locus of speech impairment, by comparing model parameters to impaired productions. The interdisciplinary nature of this research will promote teaching, training and learning in computer science and in speech and hearing sciences.","title":"HCC: Small: Modeling Acoustic and Articulatory Features for Hybrid Synthesis","awardID":"1116799","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[485923],"PO":["565227"]},"181021":{"abstract":"Algorithms for genetics: epistatic interactions, haplotype assembly, and selection signatures<br\/><br\/>Variation in our DNA (often inherited) can have important functional consequences, including susceptibility to diseases. However, much of variation is due to random drift and may have no functional consequence. Identifying the small subset of variations that are functionally important is key to a deeper understanding of the genetic basis of diseases and other phenotypes, and is the mainstay of statistical genetics and other fields. However, rapidly falling costs of genome sequencing implies that genomes of entire populations will be completely sequenced. The availability of tremendous amounts of genetic data, and the complexity of relations between genotypes and phenotypes changes the nature of inference problems from statistical to computational, and demands the use of algorithmic (combinatorial and machine learning) techniques. In this proposal, the PIs propose specific goals in three broad areas, which involve the use of algorithmic techniques in solving problems in genetics. <br\/><br\/>1. Epistatic interactions and geometric embedding: Epistatic interactions where two distant loci interact to jointly mediate the phenotype often confound analyses. However, with millions of loci, testing all pairs for interactions is computationally intractable. The PIs propose to develop fast algorithms for this problem. The approach depends upon the development of a metric embedding that maps the genotypes at a locus to a point in a high dimensional Euclidean metric, such that interacting pairs have small Euclidean distances. This metric embedding is novel, and allows the use of geometric algorithms for fast detection of epistasis.<br\/>2. Haplotype assembly: Haplotyping refers to the separation of the maternal and paternal chromosomes. Successful resolution has great impact in improving the efficacy of genetic association, and in understanding the genetic history of the population. The PIs propose the use of modern strobe-sequencing technologies and single genome amplification to dramatically expand the length of achievable haplotypes. One of the formulated problems maps naturally to connectivity in a new class of random graphs.<br\/>3. Pooled selection: The PIs propose the identification of regions under genetic selection, using next generation sequencing data. Specifically, the proposed tests work on pooled DNA, and partially sampled DNA, and employ a combination of techniques from population genetics and combinatorial optimization.<br\/><br\/>Broader Impact and Intellectual Merit<br\/>The great promise of genomics is that our complete sequence will be an integral part of our medical record, and the major health prognostics will be informed by variation. However, the early research in correlating genotypes and phenotypes is stymied by lack of analysis tools. The problems addressed here are central to the domain and will clearly add to the toolkit of geneticists and biologists. The research also contributes directly to the CISE-CCF mission of developing novel algorithms for Computational Biology, as the proposed problems are uniquely at the intersection of algorithmic and genetics, and open new avenues of research in Computer Science. <br\/><br\/>Dissemination and outreach will continue through the length of the project contributing to the broader impact of this research. It will include invited and contributed presentations, publications, classroom projects, and collaborations. Software will be freely available as source-code, or web-tools, for academic, research and non-commercial purposes adding to the infrastructure of genetic analyses tools.","title":"AF: Small: Algorithms for Genetics: Epistatic Interactions, Haplotype Assembly, and Selection Signatures","awardID":"1115206","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[485132,"549885"],"PO":["565223"]},"186049":{"abstract":"The objective of this research is to develop key components of community-based pervasive systems which will allow citizens to respond to disasters. The systems will make use of inexpensive networked sensors and communication devices distributed among families and communities. The sensors\/devices will enable the collection of situational information and the dissemination of alerts, by use of fault and delay-tolerant networks, and through the use of Cloud computing and crowd sourcing techniques. The Indo-US partnership in this effort will study these issues in the context of the Indian subcontinent where urban and rural landscapes are unique.<br\/><br\/>Sensor-based detection technologies will be studied to help identify events, e.g. abnormal ground motion, and fault-tolerant networks will be designed to connect the sensor systems together and to a resource-rich cloud infrastructure. Methods for performing sensing analysis and data fusion in the cloud will be incorporated so as to address tradeoffs among rates of false positive alarms, false negative alarms, and time to detection. The existing infrastructure will also be used to design systems for delivering actionable alerts\/information to responders and communities using multiple networks. The community-based sensing and alerting techniques developed will be evaluated in campus testbeds at UCI\/Caltech, culminating in a pilot study\/drill at one of the Indian institutions with regional experience in disaster management. <br\/><br\/>Dealing with disasters effectively is a global concern and techniques to leverage communities for data collection and alerting is an effective strategy, especially in nations with diverse populations with varying degrees of technological sophistication. The research will enable a new generation of community-based cyber-physical systems in emerging markets, in which the community helps to detect, communicate and respond to rapidly evolving events such as earthquakes, tsunamis, fires, floods and epidemics. Students at different levels (graduate, undergraduate, K-12) will gain experience with developing real-world applications in a global context via courses and independent study projects. Students will benefit tremendously from exposure to the next generation of community-based cyber-physical systems technologies that will help design safer living environments for the future,","title":"PC3: Collaborative Research: Pervasive Computing for Disaster Response","awardID":"1143666","effectiveDate":"2011-10-01","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[499268,499269],"PO":["564181"]},"181352":{"abstract":"This project provides communication security in a new way, based on channel noise rather than standard cryptographic constructs and algorithms. The idea is old, from work in the 1970s in the information-theory and coding field, but this classical work used weak security metrics and even then was not able to provide any explicit and practical designs. This research bridges the gap between this classical work and modern cryptography. First, it provides a sound theoretical basis in the form of security metrics that are adapted from modern cryptography and demand much stronger security than the classical metrics. Second, it provides explicit, efficient and optimal methods to achieve security under these metrics based only on the assumption that the channel from sender to adversary is noisier than the channel from sender to receiver. Unlike standard cryptography, this approach is not vulnerable to advances in algorithms and adversary computing power and thus provides a new option to secure highly sensitive information.","title":"TC: Small: A Cryptographic Treatment of the Wiretap Channel","awardID":"1116800","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["521666"],"PO":["565239"]},"185400":{"abstract":"The Scintillation Materials Research Center at the University of Tennessee will carry out research that addresses a critical need in national security. Currently the ability to detect radioactive materials at border crossings and ports of entry is limited by the availability and cost of the materials that are used as radiation sensors. This research will address fundamental aspects of manufacturing technology that directly impact the affordability of the high performance detection materials that are needed for effective high speed scanning of cargo. Innovative synthesis techniques will be developed with the goal of improving the sensitivity and lowering the cost of materials that have the capability of uniquely identifying specific nuclear threats. If successful, this technology will yield improvements in both efficiency and sensitivity of nuclear threat detection as well as significant increases in availability and affordability. The same nuclear detection technology is likely to also find applications to other areas serving the public interest including nuclear medicine and sensors used in the exploration for energy reserves.<br\/><br\/>Specifically, the Scintillation Materials Research Center will address a grand challenge in radiation detection by developing crystal growth technology aimed at enabling the production of large size (> 1 cubic inch) gamma-ray scintillators with less than 1% energy resolution at 662 keV. The properties of currently available detection materials limit the performance of radiation detection systems. For most gamma and neutron detection applications, these materials must be available in large size at a reasonable cost while maintaining the required energy resolution to unambiguously identify various nuclear signatures. For gamma-ray and neutron detection applications, scintillators currently offer more options for room temperature operation and large-scale production while semiconductors tend to have better energy resolution. New fundamental understanding of the materials properties of recently discovered scintillators will be coupled with numerical simulations of fluid flow and heat\/mass transport to drive the design of new crystal growth furnaces and new growth protocols aimed at demonstrating the potential of large scale production. The effort will focus on recently discovered scintillators that appear to have inherent advantages for large-scale production. A key strategy of the program is the tight integration of research and education that will provide opportunities for students to develop a deeper knowledge, expertise, and appreciation of this important field.","title":"ARI-MA Scale-up to Success: Pioneering Crystal Growth of Large High Resolution Scintillators","awardID":"1139918","effectiveDate":"2011-10-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"K564","name":"U.S. Department of Homeland Se"}}],"PIcoPI":[497484,497485],"PO":["565136"]},"187689":{"abstract":"This project, holding a two-day workshop which will bring together experts from a wide range of disciplines to articulate the challenges involved in Vertical Farming, will invigorate the research community. Vertical Farming is an indoor, urban farming concept that solves many energy problems associated with outdoor farming. Recent implementations have shown very high yields in the production vegetables, including green peppers and tomatoes, spinach and lettuce. In many cases, water usage has been significantly reduced compared to traditional outdoor farming, and the conditions in which the crops are grown naturally shields them from unseasonal climate, and, from pests and diseases. In addition, Vertical Farming has the potential to generate fresher and healthier produce at reasonable cost.<br\/><br\/>The proposed research has direct impact on the way the majority of the world's population lives. Agriculture impacts each and every one of us. Transformational technology is needed to meet the needs of simply feeding people in the coming decades. We need food to be safe such that it doesn't harm people because of the methods of cultivation used. Finally, agriculture has the potential to negatively impact the environment if not managed carefully and intentionally. This workshop will impact the way that crops are grown in the future, producing safe food, with a low environmental footprint.","title":"Workshop on the challenges in Vertical Farming","awardID":"1152110","effectiveDate":"2011-10-01","expirationDate":"2012-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["561623"],"PO":["543539"]},"185148":{"abstract":"The Georgia Research Corporation proposes to create a new distance-learning medium for computing education especially for in-service high school teachers based on ideas from instructional design and educational psychology. In-service high school teachers are particularly time-constrained (and thus need efficiency) and they are more metacognitively aware than other students (and thus able to better inform the project design). The new medium will combine multiple modalities, worked examples, and structure based on cognitive models of designers' knowledge. The research questions are (1) Will the teachers learn CS knowledge in this on-line setting? (2) Will the teachers will be more efficient at programming activities? and (3) Will the teachers will find the materials useful and satisfying? Because of its focus on teachers, the project can potentially have broad impact, in particular on the strategies for training the 10,000 teachers envisioned in the CS 10K Project. The project will establish models and design guidelines that can be used for the creation of other learning materials, including materials for students, for example, in the proposed new CS Principles AP course.","title":"Type 1: Using Instructional Design Techniques to Create Distance CS Education to Support In-Service Teachers","awardID":"1138378","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}}],"PIcoPI":["521278","521279"],"PO":["561855"]},"186028":{"abstract":"","title":"HealthWave: Secure, Federated Protocols for Electronic Medical Records","awardID":"1143573","effectiveDate":"2011-10-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["528234"],"PO":["564223"]},"181551":{"abstract":"A crucial problem in dependability of concurrent and distributed software systems, which have become prevalent with the advances in service-oriented architecture, cloud computing, multi-core hardware, is the coordination of different components that form the whole system. In order to complete a task, components of a software system have to coordinate their executions by interacting with each other.<br\/>Message-based communication is an increasingly common interaction mechanism used in concurrent and distributed systems where components interact with each other by sending and receiving messages. The objective of the proposed research is to develop novel techniques for specification, analysis, and verification of message-based interactions.<br\/><br\/>The proposed research will develop a hierarchy of communication contract specification models and investigate analysis and verification problems for each class. Within the proposed framework the interactions among components of a software system (called peers) will be modeled as conversations describing the global sequence of messages exchanged among the peers. The proposed research will result in a toolset for analyzing communication contracts and verifying properties of conversations generated by a set of peers that follow a<br\/>given communication contract. The research will have broader impact in at least three areas. By developing techniques for analysis and verification of message-based interactions in concurrent and distributed systems, the research will improve the dependability of software systems in a wide variety of application domains, including e-commerce, consumer applications, and telecommunications. Secondly, the research activity will help to expose graduate and undergraduate students to analysis and verification problems in concurrent and distributed systems, and message-based communication, through a variety of educational activities including courses, seminars and individual research mentoring. Finally, the research activity will help to disseminate the knowledge, techniques and tools developed for analysis and verification of communicating systems through publishing in the open literature, and making the software tools available in public domain.","title":"SHF: Small: Collaborative Research: Formal Analysis of Distributed Interactions","awardID":"1117708","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["499391",486421],"PO":["565264"]},"186402":{"abstract":"Computer vision has made tremendous progress in the past decades, partially enabled by the advanced machine learning techniques. But compared with human perception, computer vision remains primitive. One contributing factor for this is the data-driven nature of the current learning algorithms and their inability to incorporate any related knowledge. The data-driven methods tend to be database-specific and cannot generalize well to unseen data. This project addresses this issue through the introduction of a knowledge-augmented statistical learning framework. Within this framework, knowledge and data can be systematically exploited, captured, and are principally integrated to jointly train a vision algorithm. Developing such a framework, however, is challenging since the domain knowledge often exists in different and diverse formats, typically inaccessible to the data-driven statistical machine learning methods. To overcome this challenge, the research team systematically converts domain knowledge into either the constraints on the model or into pseudo-data, whereby they can be incorporated into the statistical learning methods. The project includes systematic identification of knowledge from different sources and concrete mechanisms to capture the knowledge and to convert them into formats easily accessible to the automatic machine learning methods. The project also involves demonstrating the effectiveness of the proposed framework for certain computer vision problems.<br\/><br\/>The project provides the training for graduate and undergraduate students, and the research results are disseminated through publications and organization of the related workshops.","title":"EAGER: Combining Knowledge with Data for Generalizable and Robust Visual Learning","awardID":"1145152","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[500200],"PO":["564316"]},"182850":{"abstract":"The significant advances realized in recent years in the study of complex networks are severely limited by an almost exclusive focus on the behavior of single networks. However, most networks in the real world are not isolated but are coupled and hence depend upon other networks, which in turn depend upon other networks. Real networks communicate with each other and may exchange information, or, more importantly, may rely upon one another for their proper functioning. A simple but real example is a power station network that depends on a computer network, and the computer network depends on the power network. Our social networks depend on technical networks, which, in turn, are supported by organizational networks. Surprisingly, analyzing complex systems as coupled interdependent networks alters the most basic assumptions that network theory has relied on for single networks. A multidisciplinary, data driven research project will: 1) Study the microscopic processes that rule the dynamics of interdependent networks, with a particular focus on the social component; 2) Define new mathematical models\/foundational theories for the analysis of the robustness\/resilience and contagion\/diffusive dynamics of interdependent networks. This project will afford the opportunity of greatly expanding the understanding of realistic complex networks by joining theoretical analysis of coupled networks with extensive analysis of appropriately chosen large-scale databases. These databases will be made publicly available, except for special cases where it is illegal to do so.<br\/><br\/>This research has important implications for the understanding the social and technical systems that make up a modern society. A recent US Scientific Congressional Report concludes ?No currently available modeling and simulation tools exist that can adequately address the consequences of disruptions and failures occurring simultaneously in different critical infrastructures that are dynamically inter-dependent.? Understanding the interdependence of networks and its effect on the system robustness and on the structural and functional behavior is crucial for properly modeling many real world systems and applications, from disaster preparedness, to building effective organizations, to comprehending the complexity of the macro economy. In addition to these intellectual objectives, the research project includes the development of an extensive outreach program to the public, especially K-12 students.","title":"CDI-Type II: Collaborative Research: Dynamical processes in interdependent techno-social networks","awardID":"1125095","effectiveDate":"2011-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"7231","name":"CYBERINFRASTRUCTURE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"7751","name":"CDI TYPE II"}}],"PIcoPI":["529970",489924],"PO":["565069"]},"181442":{"abstract":"High-assurance systems are used in areas critical to human life and welfare, such as avionic, military, financial, and medical systems. Because of the high cost of failure, e.g., financial disaster or loss of life, these systems have stringent requirements about both secrecy (guarantees that private information cannot be made public) and integrity (guarantees that un trusted information cannot corrupt trusted systems). In order to meet these requirements, the underlying computer hardware on which these systems are run must itself be verifiably secure using the same criteria. In addition, the hardware must also be efficient, able to run the systems with sufficiently high performance to be practical.<br\/><br\/>The goal of this research is to create computer hardware for high-assurance systems that is verifiably secure (that is, provably meets the requirements for secrecy and integrity) while remaining highly efficient. The unique approach taken is to leverage techniques from the programming languages community (e.g., advanced type systems) to create a new hardware description language called Caisson that enables hardware designers to quickly and easily create hardware systems that are provably secure by construction. If a system is designed using Caisson, then it is necessarily secure. Caisson will be used to explore the space of secure hardware designs in order to develop systems that are efficient as well as secure. On a broad scale, the fruits of this research will be a large step towards a safer digital domain, safeguarding the integrity of our financial system, the privacy of our medical records, and the safety of our transportation infrastructure.","title":"SHF: Small: Creating Efficient, Verifiably-Secure Computing Architectures Using Programming Language Techniques","awardID":"1117165","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[486140,"550234"],"PO":["366560"]},"195423":{"abstract":"Abstract <br\/>Abstract (NSF 1035906): <br\/><br\/><br\/>The objective of this research is to establish a foundational framework for smart grids that enables significant penetration of renewable DERs and facilitates flexible deployments of plug-and-play applications, similar to the way users connect to the Internet. The approach is to view the overall grid management as an adaptive optimizer to iteratively solve a system-wide optimization problem, where networked sensing, control and verification carry out distributed computation tasks to achieve reliability at all levels, particularly component-level, system-level, and application level. <br\/><br\/>Intellectual merit. Under the common theme of reliability guarantees, distributed monitoring and inference algorithms will be developed to perform fault diagnosis and operate resiliently against all hazards. To attain high reliability, a trustworthy middleware will be used to shield the grid system design from the complexities of the underlying software world while providing services to grid applications through message passing and transactions. Further, selective load\/generation control using Automatic Generation Control, based on multi-scale state estimation for energy supply and demand, will be carried out to guarantee that the load and generation in the system remain balanced. <br\/><br\/><br\/>Broader impact. The envisioned architecture of the smart grid is an outstanding example of the CPS technology. Built on this critical application study, this collaborative effort will pursue a CPS architecture that enables embedding intelligent computation, communication and control mechanisms into physical systems with active and reconfigurable components. Close collaborations between this team and major EMS and SCADA vendors will pave the path for technology transfer via proof-of-concept demonstrations.","title":"CPS: Medium: Collaborative Research: Architecture and Distributed Management for Reliable Mega-scale Smart Grids","awardID":"1232601","effectiveDate":"2011-10-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["541861"],"PO":["564728"]},"185787":{"abstract":"Bioinformatics and systems biology are complementary disciplines that hold great promise for the advancement of research and development in complex biomedical systems, agricultural, environmental, pharmaceutical and medical sciences as well as public health, drug design, genomics and other similar areas. Research and development in these two disciplines impact the science and technology of fields such as medicine, food production, forensics, agriculture, pharmacology, engineering and bio-mathematical and biophysical sciences, among others. This impact is accomplished by advancing fundamental concepts in molecular biology, genomics and medicine, helping us understand living organisms at multiple levels, developing innovative implants and prosthetics, creating new medical image technologies, and improving tools and techniques for the detection, prevention and treatment of diseases. The International Joint Conference on Bioinformatics, Systems Biology and Intelligent Computing (IJCBS) 2011 provides a common platform for the cross fertilization of ideas and will help shape knowledge and scientific achievements by bridging these two very important and complementary disciplines into an interactive and attractive forum. Keeping this objective in mind, IJCBS 2011 is aimed at promoting interdisciplinary and multidisciplinary education and research, especially for underrepresented groups such as women, minorities, and students with disabilities, as well as faculty, engineers and scientists in these broad but very important scientific fields. The IJCBS 2011 will provide travel support to those under-represented groups and support distinguished workshops and keynote and tutorial lectures delivered by the world's top scientists in their fields. The IJCBS 2011 will host these special sessions focusing on interdisciplinary and multidisciplinary education and research in order to foster collaboration between the bioinformatics and systems biology domains. The IJCBS 2011 is markedly a large flagship international conference in these fields, seeking long term collaborations at the emerging interface.","title":"2K11 and Beyond: The Emerging Fields of Inter\/Multidisciplinary Computer Science in Biomedical Education and Research","awardID":"1141979","effectiveDate":"2011-10-01","expirationDate":"2012-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["553423"],"PO":["565136"]},"181443":{"abstract":"Web applications are an increasingly important part of many aspects of the society, from social interactions to business transactions. Hence, security of web applications is an extremely important and urgent problem. Since web applications are easily accessible, and often store a large amount of sensitive user information, they are a typical target for attackers. In particular, attacks that target input validation vulnerabilities are extremely common and effective. Some of these attacks exploit well-known vulnerabilities, such as cross-site scripting and SQL injection, whereas some others exploit application-specific vulnerabilities that are hard to identify because they depend on the particular input validation logic of the target application. In general, these attacks exploit erroneous or insufficient input validation and sanitization to inject malicious data that can result in execution of harmful commands and access to sensitive information.<br\/><br\/>This research aims to identify and mitigate these vulnerabilities in web applications by performing automatic checking of input validation and sanitization operations. The key insight for this work comes from the observation that developers often introduce redundant checks in both the front-end (client) and the back-end (server) component of a web application. Client-side checks are fast and can improve performance and responsiveness of the application, but can be easily circumvented; server-side checks are hard to circumvent, but require network round-trips and additional server-side processing. Our intuition is that the checks performed at the client and server sides should enforce the same set of constraints on the inputs: if client-side checks are more restrictive, the server may accept inputs that legitimate clients can never produce, as malicious users can easily bypass client-side checks. Conversely, if server-side checks are more restrictive, the client may produce requests that are subsequently rejected by the server, which is not ideal from a performance point of view. This research will develop new techniques based on program analysis, string analysis, and code synthesis that can identify, map, model, and compare the set of checks performed on the client and server sides. These techniques will be able to identify and report inconsistencies between the two sets of checks and (semi)automatically extend the checks to eliminate such inconsistencies. By making web applications more secure and efficient, this research has the potential to benefit the increasingly large part of the society that relies on the use of web applications for its daily activities.","title":"TC: Small: Collaborative Research: Viewpoints: Discovering Client- and Server-side Input Validation Inconsistencies to Improve Web Application Security","awardID":"1117167","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550999"],"PO":["564388"]},"186108":{"abstract":"Through the US Ignite initiative, the National Science Foundation (NSF) seeks to demonstrate the potential and capacity of ultra-high speed broadband networks, seeding demand for and investment into their development. In coordination with other project components, including the communities that comprise the Ignite test network, the NSF plans to conduct a two-phase open innovation challenge, wherein individuals and project teams compete for prizes and funding to develop applications that make use of ultra-high speed networks. These applications will deliver innovative and valuable services in areas of national priority, including smart health, clean energy, cyber-learning, smart transportation, public safety, and advanced manufacturing. <br\/><br\/>Mozilla has a long history of designing and managing Open Innovation Challenges. The organization uses the challenge model to drive participation in shaping product development and innovation. Challenges pair the agility of open innovation, the generativity that comes from the freedom to propose new ideas, diverse perspectives, crowd sourced insight, and accidental encounter with resources and support for projects able to demonstrate measurable impact. Through US Ignite, Mozilla will leverage its experiences to drive ultra-high speed broadband application development.<br\/><br\/>A successful U.S. Ignite prize competition will provide an accessible vision of what is possible with next-generation networks, demonstrate that potential with deployments addressing national priorities, and galvanize a network of gigabit application developers.","title":"US Ignite Application Challenge","awardID":"1143962","effectiveDate":"2011-10-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"L589","name":"Department of Energy"}}],"PIcoPI":["560884"],"PO":["564993"]},"187703":{"abstract":"Computer science is enabling new businesses, new educational approaches, and new forms of cultural expression through enabling new forms of media. But computer science itself, as a discipline, has not traditionally focused on media. In order to continue and expand the remarkable progress of the last two decades of computational media development, computer science must build interdisciplinary bridges with other areas that have greater media expertise, from which new research methods, guiding theories, and evaluation approaches can emerge.<br\/><br\/>The potential impacts of such connections are great. Combining computer science's model of technical innovation with media knowledge could offer cultural and economic benefits far beyond those that can be attained by the simple borrowing of surface elements more common today. It could enable interactive educational software that builds on structural insights gained from thousands of years of drama. Presentation and discovery software for understanding everything from scientific data to family history could embody composition lessons from the work of great artists and designers. Meaningful new forms of interactive storytelling could build on the experience gained from interpreting literature and cinema. In short, the scientific process of breaking new ground in media technology could have powerful new methods for evaluating research directions and progress that are grounded in our shared cultural heritage.<br\/><br\/>For enabling such a future, one important interdisciplinary connection is that with arts and design communities, who have developed knowledge in these areas and communities of practitioners already collaborating with computer scientists. Another important connection, which is unfortunately less well established, is that with the humanities. Despite the fact that the humanities have some of the best-developed approaches for understanding media, and despite the emerging digital humanities community with expertise in work with computational systems, the connection between media-focused computer science and the humanities has not yet fully catalyzed. This workshop will be an important step toward building a robust connection, defining the first research questions and collaboration models to be pursued. The potential long-term impacts of these new connections are high, especially in areas where the U.S. has a leadership position and important investments in research and development.","title":"Workshop: Media Systems -- Connecting Computer Science and the Digital Humanities","awardID":"1152217","effectiveDate":"2011-10-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["536597","536598"],"PO":["564456"]},"186208":{"abstract":"This research project examines the theoretical, algorithmic, and computational issues that arise in compressed sensing (CS) and signal processing problems where there is a need to compute solutions to problems in which the solution vector has many zeros. In addition to the exciting compressed sensing area, this research will benefit numerous signal processing applications where the sparsity constraint on the solution vector naturally arises. Brain imaging techniques such as Magnetoencephalography (MEG) and Electroencephalography (EEG) are currently important examples. Sparse communication channels with large delay spread, high resolution spectral analysis, and direction of arrival estimation, are other important examples. An effective solution to this problem will have significant impact, by providing new and valuable tools to the practicing signal processing engineer. In addition, the tools will be of interest to researchers in cognitive science, neuroscience, and machine learning where sparsity issues naturally arise, such as sparse coding of signals in the brain or learning from data which is often assumed to lie on a low dimensional manifold. <br\/><br\/>This project provides a comprehensive and tighter integration of the compressed sensing field and multi-user information theory. This makes it possible to utilize the rich results available in network information theory which have been successfully applied to the implementation of communication systems. The theoretical tools necessary to enable this integration are being developed by the investigators. This research enables significant advances in both theory and practice in the CS field. The information theoretic insights are leveraged to provide insights on performance limits and guidance on practical CS-based system design. The implementation experience gained from communication systems will be translated to practical algorithm development and efficient CS-based system design.","title":"EAGER: A Multi-User Communication and Information Theoretic Approach to the Sparse Signal Recovery Problem","awardID":"1144258","effectiveDate":"2011-10-01","expirationDate":"2014-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[499664,"551039"],"PO":["564898"]},"180400":{"abstract":"This research seeks to develop socio-computational approaches to improve citizen participation in rulemaking, using a pilot online participation platform, RegulationRoom. Rulemaking, the process through which federal regulatory agencies make new regulations, is an unusual method of federal decision-making because it formally incorporates a period of peer knowledge creation, the \"notice-and-comment\" process. Agencies proposing new rules must seek input from stakeholders, experts, and the general public, and consider all criticisms, questions, new data, and alternative ideas received. Yet only a limited segment of individuals and groups participate, and these participants engage in adversarial position-taking rather than collaborative deliberation. Neither of these shortcomings has been remedied by putting the process online. It is reasonable to hypothesize that broader, better public engagement requires purposefully designing e-rulemaking systems to provide norm enculturation and deliberation priming. This project will explore strategies for each, drawing on expertise in law, conflict resolution, natural language processing (NLP), machine learning, and recommender systems. <br\/><br\/>This research provides unique contributions in at least four areas: (a) advancing the state-of-the art in NLP by developing discourse analysis techniques to facilitate deliberative dialogue and collaborative knowledge production; (b) advancing recommender system and online community research to support mentoring activities and engagement with alternate points of view; (c) advancing the field of conflict resolution by adapting face-to-face moderation techniques to the online environment; and (d) extending legal understanding of how to increase transparency and participation by supporting broader, better public participation in rulemaking and other complex policymaking domains. It will also generate annotated datasets of comment and deliberation quality that will be released to other researchers. The results will extend the techniques and assessment measures available to moderators of online group discussion and provide new computational tools for improving the quality of individual contributions and for interpreting and synthesizing information during the knowledge production process. <br\/><br\/>Learning how to design effective Rulemaking 2.0 systems will strengthen the democratic process by expanding the range of individuals and groups who understand, engage with, and meaningfully contribute to federal policymaking. In addition, better policy outcomes should result from socio-computational techniques that enable meaningful participation by important but traditionally absent stakeholder groups, such as small business owners. State and local governments that use public comment processes will benefit similarly from this work as will non-governmental groups trying to increase effective participation in complex collaborative content creation online.","title":"Computational Facilitation of Online Deliberation in Complex Policymaking.","awardID":"1111176","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["548297","548296","565070"],"PO":["564456"]},"191687":{"abstract":"Textual passwords and personal identification numbers (PINs) are the most dominant means of authentication used currently; and this trend is very likely to continue in the future. However, passwords are either difficult to use (if they are long and randomly generated), or insecure (if users are given the choice of their own passwords). Password Managers are one promising approach aimed to improve the usability and security of passwords, by having a computing device, rather than the user herself, store (and optionally, generate) passwords, and then later deliver or recall them to the user whenever access is needed. A number of password management schemes have been proposed and are employed currently by many affected users. <br\/><br\/>This project concentrates on password management using mobile devices (e.g., cell phones), whose ubiquity makes them an appealing authentication aid. It embarks upon two research directions vis-a-vis such phone managers. First, the project aims at a systematic and formal evaluation, via usability studies and surveys, of currently deployed phone managers. Second, it proposes a redesign that exploits the many different capabilities and characteristics of modern phones (such as on-board sensors and computational resources), in order to address several of the drawbacks with current phone managers. Specifically, a general-purpose password management approach -- called proxy-based authentication -- is introduced. As the name suggests, this approach uses the phone as an authentication proxy between the user and the device to be authenticated to. The project explores how proxy-based authentication can be used to strongly authenticate to: (1) critical online services -- that continue using passwords or PINs -- without incorporating any service-specific modifications, (2) local devices (such as desktops, laptops, ATMs), and (3) ubiquitous but constrained devices (such as personal RFID tags) for user-controlled privacy and enhanced security.<br\/><br\/>The technical merit of this project lies in two aspects. First, it will arrive at a better understanding of current phone managers in terms of usability, efficiency, and security. The goal is to gain insights into users' mental models when using these password managers. Second, the project will pursue the realization of usable proxy-based authentication primitives. To this end, this work is able to simply reuse wealth of existing research on usable user-phone authentication. Instead, the main thrust is on exploring the design and evaluation of usable authentication methods between the phone and the service that ultimately requires authentication. In particular, for phone-service authentication, the project investigates novel short-range human-perceptible (HP) communication that is commonly and cheaply available, fast, robust, least intrusive, and low-power. Notably, the research investigates how to use HP communication to create authenticated channels, and authenticated and eavesdropping resilient channels. Based on the principle of extrinsically motivated design, the project also explores playful HP channels. These channels make the task of manual transmission a fun and entertaining activity for the users.<br\/><br\/>The anticipated impacts of the project include: (1) enhanced interaction among several disciplines including security and cryptography, computer and electrical engineering, networking, and usability and HCI; (2) increased awareness among students and users regarding security practices vis-a-vis one of the most important security problems (authentication); (3) integration of PI's research with educational activities, enabling students taking part in the project to acquire currently uncommon skills at the cusp of Human-Computer Interaction and Trustworthy Computing; (4) emphasis on technology transfer by working with manufacturers and industrial consortia. Another long-term impact of this work is the development of security technologies that can eventually be put to use by general population, i.e., are usable in the true sense. Furthermore, the work is expected to be instrumental in stimulating research on usable security technologies for the blind or visually impaired users who are usually at a high risk for various security vulnerabilities and attacks, perhaps more so in the context of authentication.","title":"TC: Small: Mobile Phone Password Managers: An Evaluation and a Re-Design based on Human-Perceptible Communication","awardID":"1209280","effectiveDate":"2011-10-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["535221"],"PO":["565136"]},"182623":{"abstract":"The PIs, one expert in intelligent tutoring systems, and the other an expert on ecosystems, are investigating the ways model construction can aid in the understanding of complex dynamic systems, specifically ecosystems and systems involved in sustaining life on our planet. The PIs are particularly interested in understanding the affordances of model construction in promoting such learning and the challenges in doing so, and they are doing that by having undergraduates construct and explore models related to issues in sustainability during an introductory sustainability course. Model construction and exploration are done in the context of an intelligent tutoring system (called Lait). Learners switch between constructing models themselves and using the models of others as learning aids. Model constructors know they are constructing their models for others to learn from, and as others are using those models to learn, they may interact (online) with the model constructors to discuss the reasoning behind designing the models. The tutoring system provides scaffolding for model building and for model exploration, supports collaboration around modeling issues and issues related to particular models, and runs the models that are created. The goal is to promote understanding of the systems being modeled, skill at model construction, and understanding of the epistemology of modeling. The first year of research is taking place in the lab; research in later years is taking place in classrooms, specifically in the introductory interdisciplinary sustainability course, which enrolls 300 students per semester.<br\/><br\/>Systems thinking is notoriously difficult and notoriously difficult to learn. Thinking about sustainability is equally complex, and the target domain here is sustainability. There is potential for this work to shed light on how to better help people understand and think about systems and about interactions between and interconnectedness of the systems that sustain our lives on earth. In addition, the literature on learning suggests that learners should learn more from constructing models and making them work than from simply running the models of others as simulations. But up to now, technology has not been up to making modeling by learners accessible. Most research in the area of simulation and modeling to promote learning has therefore focused on the roles of simulation in promoting learning. This project is exploring ways of making systems modeling more accessible to those who are not already competent programmers and will uncover some of the affordances of modeling for promoting learning and the circumstances under which modeling can promote learning about particular systems and learning to be a systems thinker.","title":"EXP: Students Authoring Intelligent Tutoring Systems for Constructing Models of Ill-Defined Dynamic Systems","awardID":"1123823","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":["528613","498182"],"PO":["562669"]},"182876":{"abstract":"The significant advances realized in recent years in the study of complex networks are severely limited by an almost exclusive focus on the behavior of single networks. However, most networks in the real world are not isolated but are coupled and hence depend upon other networks, which in turn depend upon other networks. Real networks communicate with each other and may exchange information, or, more importantly, may rely upon one another for their proper functioning. A simple but real example is a power station network that depends on a computer network, and the computer network depends on the power network. Our social networks depend on technical networks, which, in turn, are supported by organizational networks. Surprisingly, analyzing complex systems as coupled interdependent networks alters the most basic assumptions that network theory has relied on for single networks. A multidisciplinary, data driven research project will: 1) Study the microscopic processes that rule the dynamics of interdependent networks, with a particular focus on the social component; 2) Define new mathematical models\/foundational theories for the analysis of the robustness\/resilience and contagion\/diffusive dynamics of interdependent networks. This project will afford the opportunity of greatly expanding the understanding of realistic complex networks by joining theoretical analysis of coupled networks with extensive analysis of appropriately chosen large-scale databases. These databases will be made publicly available, except for special cases where it is illegal to do so.<br\/><br\/>This research has important implications for the understanding the social and technical systems that make up a modern society. A recent US Scientific Congressional Report concludes ?No currently available modeling and simulation tools exist that can adequately address the consequences of disruptions and failures occurring simultaneously in different critical infrastructures that are dynamically inter-dependent.? Understanding the interdependence of networks and its effect on the system robustness and on the structural and functional behavior is crucial for properly modeling many real world systems and applications, from disaster preparedness, to building effective organizations, to comprehending the complexity of the macro economy. In addition to these intellectual objectives, the research project includes the development of an extensive outreach program to the public, especially K-12 students.","title":"CDI-Type II: Collaborative Research: Dynamical processes in interdependent techno-social networks","awardID":"1125290","effectiveDate":"2011-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"7231","name":"CYBERINFRASTRUCTURE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"7751","name":"CDI TYPE II"}}],"PIcoPI":["545796"],"PO":["565069"]},"182887":{"abstract":"Tissue engineering has shown promise for providing alternatives to traditional surgical methods for reconstruction of damaged or resected tissues, but a number of fundamental issues remain before tissue engineering achieves routine clinical application. The study and design of engineered tissue necessitates the investigation of integrated tissue growth and neovascularization within a biopolymer scaffold. This system illustrates the complexity of natural and engineered systems critical to the survival of living species. The tissue engineering system must be studied in its entirety in order to assess its resiliency and fragility to external environmental changes and internal variations in the decision functions of its elements, to analyze and predict its growth, self-organization and sustainability, and to forecast the emergence of new behavior in its upper levels of hierarchical organization based on the decisions\/behavior of its elements. While several individual aspects of tissue engineering have been studied rigorously and detailed models have been developed for these individual components, agent-based modeling provides an integrated framework for studying the interactions among these individual parts that typically invoke a response more complicated than the sum of the individual parts. <br\/><br\/>The goal of the proposed multidisciplinary research is to integrate experimental and computational studies in an evolutionary active learning framework to optimize engineered tissue growth. Simulations will be run in parallel with experiments to enable adjustments of experimental conditions for improving the growth process based on model predictions of final tissue properties. Three synergistic research activities are integrated. The first is to develop an active learning framework to coordinate the collection and interpretation of experimental and simulation results, refine simulation studies, develop a feedback loop between simulations and experiments, and enable modification of the conditions of ongoing experiments to optimize functional tissue growth. The second is to develop an open-source stochastic multiscale heterogeneous agent-based modeling framework in Java and Repast for modeling tissue growth and develop tissue engineering strategies based on agent-based model predictions. The third is to conduct experimental studies guided by active learning for engineering vascularized bone. The outcome will be a learning-decision-execution environment for integrated computational and experimental research to develop tissue engineering systems studied in their entirety by considering the interdependencies of vascular and tissue growth while tracking variations in individual cells.<br\/><br\/>The transformational research in this project is the development of an iterative \"modeling-simulation-experiment\" cycle guided by active learning (AL) to optimize engineered tissue properties by making adjustments both prior to and during tissue growth. One goal of this project is to develop an open-source agent-based modeling (ABM) environment to use agent-based models and experimental data for the development of tissue engineering strategies that can be rapidly screened by simulations to guide experimental work, with a particular emphasis on tissue engineered bone. The second goal is to develop an evolutionary AL framework and batch process supervision and control strategies for conducting realistic simulations and prediction of complex adaptive systems for engineering vascularized tissue. In vitro and in vivo (animal studies) engineered tissue formation will be modeled, with a particular emphasis on tissue engineering vascularized bone. Research results will contribute to the knowledge base in simulation-based engineering science and computational thinking, and in modeling, simulation and control of complex biomedical systems.<br\/><br\/>This iterative comprehensive \"modeling-simulation-analysis-experimental validation\" approach will provide ultimately a powerful method for healthcare providers to design better strategies for tissue regeneration and engineering. The proposed activity also contributes to promoting education and training in modeling of complex dynamic stochastic systems, hierarchical agent-based models, and tissue engineering for students at multiple levels, including K-12, undergraduate, and graduate students. The techniques for model development and assessment of the effects of stochastic variations can be used in complex adaptive systems in many fields central to national and global concerns - energy distribution systems, ecosystems, epidemics, and supply chains. Vascularized tissue growth presents an ideal testbed for computer science research in active learning of complex living systems. It also provides valuable material for STEM education at secondary and college levels. Modeling activities appropriate for middle, secondary, and collegiate students will not only introduce students to simulations that can b","title":"CDI-Type II: Optimization of Engineered Tissue Growth by Active Learning","awardID":"1125412","effectiveDate":"2011-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7751","name":"CDI TYPE II"}}],"PIcoPI":[490035,"539533",490037,490038,490039],"PO":["565136"]},"190048":{"abstract":"Research supported by this award is developing community-based methods for sensing, recognizing, and interpreting human activities from body-worn sensors. Specifically, this research is<br\/><br\/>1) developing systems that learn new classes of activity with minimal human supervision, where the system queries a human user for additional information on an activity being learned, but only when such queries are informationally necessary and behaviorally unobtrusive,<br\/><br\/>2) developing the paradigm of community-guided learning, which leverages people's social ties and behavioral similarities, in order to define an efficient scheme for sharing various aspects of the underlying activity classes across many individuals, and<br\/><br\/>3) evaluating the new community-guided learning methods by using them to learn about (a) social isolation and functional independence among elderly persons, and (b) social interaction among high-functioning autistic children.<br\/><br\/>Speaking generally, the research is advancing machine learning and artificial intelligence, especially in the areas of semi-supervised, active, and relational learning. Beyond these basic scientific contributions, the resulting research has the potential to transform community health assessment by collecting fine-grained clinically-relevant information continuously, cheaply, and unobtrusively, over long periods of time. This research also opens up many opportunities for education and outreach, in part because it is pushing machine learning and artificial intelligence into social and societally-important realms, promising to attract groups, notably women, who are under-represented in computer science.","title":"CAREER: Enabling Community-Scale Modeling of Human Behavior and its Application to Healthcare","awardID":"1202141","effectiveDate":"2011-10-01","expirationDate":"2015-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["560929"],"PO":["565035"]},"172877":{"abstract":"NSF and Gallaudet University?s Science of Learning Center for Visual Language and Visual Learning (VL2) entails multidisciplinary projects sharing in scientific purpose the discovery of how aspects of higher cognition are realized through one of human?s most central senses, vision. Through the enhancing lens of natural signed languages, projects investigate how deafness and visual languages provide a window into the flexibility and structure of the human mind. Projects identify the effects of visual processes, visual language, and social experience on visual learners? development of cognition, language, and reading and literacy. Visual learning is unraveled in monolinguals and bilinguals spanning development, to promote optimal practices across educational settings. Center projects are divided into seven Strategic Focus Areas. Four involve state-of-the-art scientific research, neuroimaging, and\/or computational modeling, each rendering emerging findings to educational intervention design, including, Visual & Cognitive Plasticity, Language Development & Bilingualism, Reading & Literacy, and Translational Research to Educational Practice. Three involve, Translational outreach, Center Management, and Diversity. Uniqueness: Deaf and hearing scientists and educators; two-way dialog among researchers and teachers\/public; Student Leadership Teams; infrastructure promoting national and international resource sharing across vast partnership institutions; capacity to serve as the nation?s ?first-response? regarding educational priorities. Broader Significance: Center products ensure advances in education for students at risk for low achievement. Comparative analyses of auditory and visual bases for language, reading, and print-literacy lead to new paradigms for understanding learning essential for enhancing educational, social, and vocational outcomes for all humans, deaf and hearing, consequently transforming the Science of Learning.","title":"Collaborative Research: Science of Learning Center: Visual Language and Visual Learning (VL2)","awardID":"1041725","effectiveDate":"2011-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0401","name":"Division of SBE Off of Multidisciplinary A","abbr":"SMA"},"pgm":{"id":"7278","name":"SCIENCE OF LEARN CTRS- CENTERS"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0401","name":"Division of SBE Off of Multidisciplinary A","abbr":"SMA"},"pgm":{"id":"7704","name":"Science of Learning Activities"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"1698","name":"DEVELOP& LEARNING SCIENCES\/CRI"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["560565","483340"],"PO":["564308"]},"181589":{"abstract":"Most of the work on the Semantic Web and more broadly Information Integration assumes that accurate semantic models of sources exist. In practice, although there is a tremendous amount of data available on the Web, there is rarely any semantic description of the sources and the information provided by them. This project will develop a new approach that addresses the problem of automatically discovering and modeling sources by building on the recent development of Linked Open Data within the Semantic Web. The resulting system will be able to learn about any source where there is background knowledge in the Linked Open Data. This work will be a significant advance over what was done previously since it will allow an intelligent system to expand its knowledge to learn models of sources that cover information for which the system has no known sources. The system will start with all of the data and knowledge in the Linked Open Data as well as semantic descriptions of some related services (through the work on Linked Open Services). The system will then learn how a new source relates to the known sources by exploiting the knowledge already available the the Linked Open Data. The result will be a rich semantic description of the individual sources that can be used in Semantic Web applications and information integration systems.<br\/><br\/>The ability to automatically discover and learn detailed semantic descriptions across a range of sources that go beyond the current source descriptions will greatly expand the utility of Semantic Web and information integration systems. This capability will allow people and systems to better exploit the massive amount of data available today on the Internet and provide a tool to keep up with its growth. Within the bioinformatics world, for example, the amount of data continues to grow rapidly, and the ability to find and structure this data will have a significant impact on ability of researchers to fully exploit all of this information to solve biomedical research questions, such as finding more effective treatments for cancer. More information about the project can be found at http:\/\/www.isi.edu\/integration\/people\/knoblock\/projects\/prj_source_modeling.html","title":"III: Small: Building Linked Open Services from Online Sources","awardID":"1117913","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["561230",486525],"PO":["563727"]},"181259":{"abstract":"A broad range of problems in computer graphics rendering, appearance acquisition, and imaging, involve sampling, reconstruction, and integration of high-dimensional (4D-8D) signals. Real-time rendering of glossy materials and intricate lighting effects like caustics, for example, can require pre-computing the response of the scene to different light and viewing directions, which is often a 6D dataset. Similarly, image-based appearance acquisition of facial details, car paint, or glazed wood requires us to take images from different light and view directions. Even offline rendering of visual effects like motion blur from a fast-moving car, or depth of field, involves high-dimensional sampling across time and lens aperture. The same problems are also common in computational imaging applications such as light field cameras. While the PIs and others have made significant progress in subsequent analysis and compact representation for some of these problems, the initial full dataset must almost always still be acquired or computed by brute force which is prohibitively expensive, taking hours to days of computation and acquisition time, as well as being a challenge for memory usage and storage.<br\/><br\/>The PIs' goal in this project is to make fundamental contributions that enable dramatically sparser sampling and reconstruction of these signals, before the full dataset is acquired or simulated. The key idea is to exploit the structure of the data that often lies in lower-frequency, sparse, or low-dimensional spaces. Their recent collaboration on a Fourier analysis of motion blur has shown that the frequency spectrum of dynamic scenes is sheared into a narrow wedge in the space-time domain. This enables novel sheared (not axis-aligned) filters and a sparse sampling. The PIs will build upon these preliminary results to develop a unified framework for frequency analysis and sparse data reconstruction of visual appearance in computer graphics. To these ends, they will first lay the theoretical foundations, including a novel frequency analysis of Monte Carlo integration and 5D space-time analysis of light fields. They will then develop efficient practical algorithms for a variety of problem domains, including sparse reconstruction of light transport matrices for relighting, sheared sampling and denoising for offline shadow rendering, time-coherent compressive sampling for appearance acquisition, and new approaches to computational photography and imaging.<br\/><br\/>Broader Impacts: From a theoretical perspective, this project will develop a fundamental signal-processing analysis of light transport and appearance and imaging datasets, which will provide the foundation for further work not just in computer graphics but in signal-processing, computer vision, and image analysis as well. Project outcomes will apply to diverse sets of problems and will lead to transformative advances across the spectrum of rendering and imaging applications. The PIs will leverage existing collaborations with industry to transition the new technologies to practical production use. Outreach to K-12 students and the public will be enabled by a new science popularization blog that will leverage the public's excitement for advances in digital photography to introduce novel technical concepts, as well as by events such as the Computer Science Education Day for high school students at UC-Berkeley. The new algorithms and datasets resulting from this work will be made available to the research community; moreover, imaging algorithms will be released in open-source format to work with consumer digital and cell-phone cameras.","title":"CGV: Small: Collaborative Research: Sparse Reconstruction and Frequency Analysis for Computer Graphics Rendering and Imaging","awardID":"1116303","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[485699],"PO":["565227"]},"183349":{"abstract":"The term Smart Grid represents a complex set of technologies with potential to enhance the efficiency and reduce costs of electricity production, storage, transmission, distribution and use. Advances in nanotechnologies and new nanomaterials will play crucial roles throughout Smart Grid systems, changing electricity transmission, reliability, resilience, and energy storage, and shaping electricity use and demand management in novel ways. Although Smart Grid systems are critical to developing a sustainable U.S. energy system, significant variation is apparent in visions of what these systems are and how they are developing. By exploring the values and contexts that shape Smart Grid development and implementation, this project contributes to ongoing efforts to accelerate the transition of our aging electricity system to increase future energy security, reduce the threats of climate change, and contribute to sustainable development. <br\/><br\/>This research, funded by the CISE directorate, the SBE Nano Initiative, and the STS program, is guided by four questions: (1) What are the parameters of the political and policy debates surrounding Smart Grid? (2) How do stakeholders in different regions articulate their visions of Smart Grid development and deployment? (3) What are the major deployment challenges for Smart Grid technologies? (4) How can theory on science, technology and society, socio-technical transitions, and energy technology deployment be refined and expanded to more effectively integrate empirical components of emerging energy technology systems? To answer these research questions, the investigators will analyze Smart Grids in three electricity transmission systems of North America: the Midwest Independent System Operator (MISO), the New England Independent System Operator (ISO-New England) and the Electricity Reliability Council of Texas (ERCOT); both MISO and ISO-New England include Canadian interconnections. The principal investigators will conduct policy review and analysis, focus groups, interviews, and media analysis to examine the values that inform Smart Grid development and use as well as barriers to implementation. <br\/><br\/>The project contributes to a growing body of social scientific research on nanomaterials and scientific innovation. In addition to increasing understanding of national, regional and state-level influences on Smart Grid technology deployment, the researchers' results will enable energy professionals, state and regional planners, policy analysts, non-profits, and businesses to develop more effective strategies for involving the public in Smart Grid technology design, technology implementation, and policy formation.","title":"Collaborative Research: Smart Grid: An Analysis of How Socio-Political Contexts Shape Energy Technology Development and Policy","awardID":"1127600","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"7603","name":"SCIENCE, TECH & SOCIETY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["553640"],"PO":["563704"]},"184637":{"abstract":"GoingEasy\u00ae with Crowdsourcing: Building Cyber-Physical Systems for People with Visual Impairment <br\/><br\/> Many practical barriers continue to exist for a blind individual who strives to lead an independent and active life, despite decades of development of assistive technologies. This project addresses the following two most prominent challenges: (1) disparity in information-sharing among people with visual impairment and its limited understanding by the research community; and (2) lack of methods and tools for effectively addressing the disparity. The central idea is to engage visually-impaired people and their families and friends to directly contribute to a joint endeavor of enhancing information flow, increasing awareness, and improving efficiency of assistive practices, through employing social media and participatory Web. The research is focused on designing computational methodologies and developing tools that are necessary for building cyber-physical systems for a domain where the tight intertwining of physical and cyber systems plus active participation of the human users are the key to attaining the otherwise unlikely capabilities for improving the quality of living for people with special needs. The key approach is to develop a blind-specific cyber-physical system that supports social-media-based crowdsourcing. This enables visually-impaired people to form loosely-connected groups, actively contribute their information and knowledge, and ask\/answer unique questions of special needs. Such a system has specific features required: i) blind-friendly (both the cyber components and the physical components); ii) able to provide constantly-updated information, as opposed to just static websites); iii) able to support the users? real-time query for information when mobile iv) able to provide information that is important to the users? daily living, and v) supports expandability and scalability of the CPS, e.g., being able to bridge to other existing social network sites or to expand the virtual community. Specific approaches include automatic direction inquiry, instant call-in\/text-in system, community-specific data mining, information retrieval and behavior modeling, all aiming at providing the most useful information for the target user. <br\/><br\/> Aiming at bridging a significant knowledge gap in addressing the challenge of disparity in information-sharing for people with special needs in the age of social media, the project contributes to the development of a deeper understanding of the principles and methodologies in building new cyber-physical systems that promote and support active participation of users of the system, which is especially important for special-need groups such as the visually impaired, the elderly, etc. The significant impact of the work on the society lies in its potential in empowering special-need groups to pursue active and independent living in the information era. The work?s immediate impact on education is two-fold: supporting the visually-impaired students in independent learning and study as well as training students to work on emerging domains of tightly-intertwined cyber and physical systems.","title":"CPS:Medium: GoingEasy with Crowdsourcing - Building Cyber-Physical Systems for People with Visual Impairment","awardID":"1135616","effectiveDate":"2011-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["517806",495194,"527025"],"PO":["565136"]},"188949":{"abstract":"The grant will provide travel support for students to attend a conference on partitioned global address space programming (PGAS). The broader impacts are to provide research experiences to the students.","title":"Increasing Student Participation in Fifth PGAS Conference (PGAS11)","awardID":"1158635","effectiveDate":"2011-10-01","expirationDate":"2012-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[506602],"PO":["564388"]},"181635":{"abstract":"Probabilistic reasoning is now routinely used in many fields of science and engineering, where it underlies systems that perform tasks such as text classification, social network analysis, medical diagnosis, information extraction, probabilistic planning, vision and robotics. This project aims to develop an anytime and generalized probabilistic inference engine that targets a wide range of probabilistic representations, including classical, propositional representations --- such as Bayesian and Markov networks --- in addition to more expressive representations based on first order logic. The project will also investigate probabilistic queries in complexity classes that have not received much attention in the literature, yet can be used to study the robustness of inferences and decisions based on probabilistic reasoning systems. The targeted inference engine is planned to put the state of the art in exact inference at the service of approximate inference, allowing it to resign to approximations only when exact inference yields. Moreover, the engine is planned to smoothly and incrementally improve its approximations over time. A key emphasis of the project is to accomplish these objectives while using the most general probabilistic representation as an input, to allow for the widest possible adoption of the developed inference engine. Our anticipated results will impact many fields by allowing users to perform more accurate probabilistic inference, on larger models and in different contexts. Through scientific articles, research seminars, conference presentations, and graduate teaching, we expect the obtained results to be widely disseminated so as to maximize the attained benefits by various communities. Moreover, we plan to publicly release software systems that embed our results, continuing with a long tradition of publicly releasing award-winning software systems for probabilistic reasoning.","title":"RI: Small: Generalized Anytime Probabilistic Inference","awardID":"1118122","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[486633],"PO":["562760"]},"182889":{"abstract":"CDI-Type II. Acoustic Sensor Arrays for Understanding Bird Communication<br\/><br\/><br\/>The intent of this project is to permit humans to understand the grammar and meaning of bird songs. Recent advances in sensor arrays, computation, and computational linguistics finally make this long-sought goal achievable. The approach taken in this proposal is to: (1) collect very large amounts of bird song recordings from acoustic sensor arrays in a variety of natural settings; (2) process the data by software, some of which is recent and some of which will be developed using new advances in localizing source with beamforming, then filtering out noise, identifying events of interest, and then classifying them according to species and individual, and combining that with behavioral observations; (3) this information\/knowledge will then be stored in a large database that can be shared among the collaborating research groups; and (4) it will be analyzed by computational-linguistic tools to identify the syntax of the songs, and combined with information about the context in which it occurred, then analyzed by new software methods to identify the meaning of those songs. The project begins testing inferences from those inferences and explore consequences for individual and community ecology. <br\/><br\/>The research will be transformational in several ways. First, it will contribute to a profound transformation that is already underway: the recognition of very sophisticated signaling strategies and syntactic structures in non-human species. The new tools and methods for collecting and analyzing bird song now allow a level of observation that previously would not have been possible. Scientists are now collecting truly vast amounts of data from previously inaccessible settings and subjecting data to previously undiscovered sophisticated structural analyses. It will be transformational to computational linguistics if the natural world beyond humans were shown to have languages that are radically different from our own (as seems quite likely). In addition, the project will radically expand the range of engineering with voice recognition and classification, which so far has been restricted almost exclusively to humans. <br\/><br\/> Other contributions will come from the database that will comprise huge amounts of data pertaining to bird songs and the environmental\/behavioral context in which it occurs. Offering both thematic and outreach contributions, the project will bring together people from engineering, ecology, linguistics and art -- and from the US, Mexico and Japan. The educational part will bring together underserved K6-12 students with the research community and will involve them with well-established educational programs in engineering, biology and art | science. While the science portion of this project is high-payoff --- high-risk, the outreach portion will certainly be effective at furthering appreciation and learning of science.","title":"CDI-Type II: Acoustic Sensor Arrays for Understanding Bird Communication","awardID":"1125423","effectiveDate":"2011-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7751","name":"CDI TYPE II"}}],"PIcoPI":[490046,490047,"526053",490049,"558131"],"PO":["565136"]},"182669":{"abstract":"This project is aiming to learn how to promote geospatial thinking skills and ability to use data gathered geospatially to solve complex problems. The technology being developed leverages on-line maps to situate scenarios in GeoGames so that learners have access to real GIS, remote sensing, socioeconomic, agricultural and other data and models as they engage with others to solve real-world problems in the GeoGame. The focus is on helping learners gain and use a spatial perspective in their thinking and problem solving. Geogames present real-world challenges that require large-scale data collected across geographical areas in game-like ways to draw in the learners; the learners solve problems using the data found through navigating the maps and in conjunction with each other. Research questions being investigated are about how to use such games, visualizations, and data to engage learners in learning in the context of real-world problem solving, learning to solve problems of real-world complexity, and learning to use geospatial representations. The innovation integrates the strengths of geospatial technologies, gaming, and social networking to promote learning about real-world facts and also complex, interlinked human, environmental, and technological systems in an experiential, collaborative, and engaging way. The focus is at the college level but ultimately could be appropriate for high-schoolers, middle-schoolers, and the general population.<br\/><br\/>Policy people tell us that a geospatial perspective is essential in addressing many of society's pressing issues (e.g., economics, agriculture, climate change, transportation, relief, urban planning, emergency services). This approach of GeoGames may provide an engaging and broadly-applicable way to educate future policy makers in taking a global perspective on both the global and local problems they address. The approach may also provide a way to help the public appreciate the connectedness of the world, the broad implications of local policy decisions, and the issues that must be considered in policy making.","title":"EXP: GeoGames - A Virtual Simulation Workbench for Teaching and Learning through a Real-World Spatial Perspective","awardID":"1124037","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"7444","name":"NATIONAL SMETE DIGITAL LIBRARY"}}],"PIcoPI":["550772","550773","561968"],"PO":["562669"]},"182912":{"abstract":"The Institute for Quantum Information and Matter (IQIM) is a center-level activity that spans Quantum Information Science (QIS), Condensed Matter Physics (CMP), Atomic, Molecular, and Optical Physics (AMOP), and the emerging field of Mechanical Quantum Systems (MQS). The unifying theme for the IQIM is the exploration of collective quantum phenomena that endow physical systems of many interacting constituents with astonishing properties that in effect transform the weirdness of the microscopic quantum realm to macroscopic scales. The principal motivations for the creation of the IQIM are the extraordinary set of scientific opportunities associated with the study of exotic quantum states of matter and the potential for discovery brought by newly developed tools from Quantum Information Science. The IQIM ties together the diverse Caltech community of researchers, from physics to applied physics, to computer science, who focus on emergent quantum phenomena and provides a sustaining base for the scientific development of a new field of research that will actively involve national and international communities of researchers in QIS, CMP, AMOP, and MQS. By way of extensive programs in education and outreach, the IQIM will impact high school and college education and will engage the general public with the \"mind boggling\" nature of the quantum realm.<br\/><br\/>It has long been known that individual atoms and electrons, as well as electromagnetic and mechanical oscillators (i.e., photons and phonons), obey laws of quantum physics that in many respects defy common sense. Under the right conditions, interactions among many such quantum objects can lead to remarkable quantum phenomena that have heretofore not existed in nature. Advances to create, characterize, and utilize such exotic quantum phenomena have been made in condensed matter physics (CMP), atomic-molecular-optical physics (AMOP), and at the interface between these areas. In conjunction with parallel developments in quantum information science (QIS), a revolution is underway in the study of exotic quantum systems that is the unifying theme and driving motivation for the IQIM. Progress in the experimental realization and theoretical understanding in this area will surely have profound implications for basic physics. The IQIM will merge insights and analytic tools from QIS with advancing laboratory capabilities in CMP, AMOP, and MQS for the discovery and characterization of exotic quantum states of matter, and will thereby shed light on issues at the core of physics. Eventually, the ability to manipulate exotic quantum systems may lead to new technological capabilities, including methods for designing and exploiting quantum materials.<br\/><br\/>The Institute for Quantum Information and Matter will have the following scientific thrusts:<br\/><br\/>Quantum Information: Investigators at the current NSF-sponsored Institute for Quantum Information (IQI) have made Caltech a recognized world leader in theoretical QIS. IQI faculty are integral members of the IQIM and conduct research that is closely allied to the IQIM, e.g., the application of topological principles to quantum phase transitions and the discovery of universal features of entanglement that that distinguish quantum phases of matter. Research at the IQIM includes investigations of the connections between quantum information science and other aspects of basic physics. IQI scientists will lead the quest to apply insights into the properties of quantum entanglement for the study of quantum many-body systems and quantum phase transitions, as well as to apply quantum information theory to illuminate how information is encoded in spacetimes subject to strong quantum fluctuations. The IQI will also continue its world leading programs on quantum computation and communication.<br\/><br\/>Quantum Many-Body Physics: Caltech has world leading programs in the quantum physics of strongly interacting many-body systems (e.g., superconductors, exotic magnets, strongly correlated electron systems, etc.). Research thrusts in this area will emphasize emergent quantum phenomena, including quantum Hall physics, topological states of matter, exotic magnetic systems, and ultra-cold atomic gases, and with strong connections to powerful theoretical techniques from QIS. These studies will involve some of the most fascinating and puzzling manifestations of many-body quantum mechanics.<br\/><br\/>Quantum Optics: Another area of great strength at Caltech is the study of optical interactions at the level of one atom and photon, where seminal advances in the realization of new paradigms for light-matter interactions by way of micro- and nano-scopic optical cavities have been made. Within IQIM, existing capabilities for quantum control of strong interactions of single atoms and photons will be extended to explore quantum many-body systems composed of 1- and 2-D arrays of atoms whose interactions are mediated by photons in microscopic quantum opt","title":"Institute for Quantum Information and Matter (IQIM)","awardID":"1125565","effectiveDate":"2011-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"1646","name":"PHYSICS FRONTIER CENTER"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"7282","name":"ACC PHYSICS & PHYSICS INSTRUM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[490112,490113,"511760",490115],"PO":["564422"]},"190007":{"abstract":"Despite their increasingly ubiquitous deployment, RFID systems are plagued with a wide variety of security and privacy threats. A large number of these threats arise due to the tag?s promiscuous response to any reader requests. This renders sensitive tag information easily subject to unauthorized reading. It also incites different forms of relay attacks whereby a colluding pair, by relaying information between a legitimate tag and reader, can successfully impersonate the legitimate tag without actually possessing it.<br\/><br\/>This research explores novel context-aware security and privacy mechanisms by leveraging the newly-equipped sensing capabilities on the next generation (passive) RFID tags. The goal is to provide improved protection against unauthorized reading and relay attacks without undermining the usability and efficiency offered by the RFID systems. The project also includes a feasibility study of the proposed mechanisms in terms of both economical and power constraints, and a systematic analysis of possible (new) sensor-centric attacks. The overall proposed activities range from system design and analysis to implementation and performance measurements. <br\/><br\/>More broadly, this exploratory work intends to arrive at a better understanding of the feasibility of utilizing parameters derived from the physical world to solve security and privacy issues of the cyber systems. In terms of educational activities, new security courses focusing on resource-constrained devices and lightweight cryptographic tools will be developed.","title":"EAGER: Collaborative Research: Towards Context-Aware Security and Privacy for RFID Systems","awardID":"1201927","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["535221"],"PO":["562974"]},"181604":{"abstract":"Interference is a key impediment to achieving high data rates in wireless communications systems. Intentional interference or \"jamming\" has primarily been studied in military communication networks. Most prior work has used non-descriptive models for the jammers, without ascribing any strategies or special capabilities to them beyond their ability to broadcast noise. This research project focuses on the design of the jamming strategies themselves, rather than on their mitigation (although the latter issue is inherently addressed as well). Questions considered include: What information can jammers exploit? How does the jammer deal with situations where this information is imprecise? How can distributed jammers coordinate their interference to maximize its effect? How should the jamming be designed to mask communications that must be kept secure from eavesdroppers?<br\/><br\/>The project is focuses on jamming techniques that exploit multiple antennas at the physical layer. Specific research thrusts include:<br\/>-- Cooperative jamming in wireless networks: Cooperative policies are being developed that optimally allocate resources to the desired link and friendly jammers.<br\/>-- Malicious feedback: Scenarios where the \"jamming\" is not noise but rather malicious physical layer feedback. These are studied to determine the extent of potential damage and possible remedies.<br\/>-- Robustness to inaccurate channel estimates: Maximizing the impact of jamming depends critically on the quality of the available channel information. This research is investigating the effect of inaccuries in this information and on techniques that are robust to such.<br\/>-- Experimental studies: Using MIMO radios in their lab, the researchers are implementing cooperative jamming approaches in a real network and studying the gap between theoretical and actual performance.","title":"CIF: Small: Jamming in Wireless Networks: Offensive Strategies and Cooperation","awardID":"1117983","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[486561],"PO":["564924"]},"181626":{"abstract":"Severe delay and resource (energy, bandwidth) constraints are typical in emerging communications and networking applications within a variety of scientific and engineering disciplines. This is particularly the case in highly constrained sensor networks. Such applications strongly motivate foregoing the convenience of digital communication and revisiting the potential benefits, and even necessity of analog communication, albeit in the modern context of distributed source-channel coding and routing. Major challenges emerge, including the derivation of a theoretical foundation for analog networking from estimation and information theoretic principles, specializing to a variety of subproblems and networking scenarios involving distributed source-channel coding, and developing effective practical algorithmic approaches, as well as a formidable optimization challenge due to the high complexity of the overall objective function which is literally riddled with poor local optima.<br\/><br\/>The general analog networking problem is formulated in terms of analog mappings, between source and channel variables at source nodes (encoders), between received and transmitted variables at intermediate network nodes, and between received and reconstruction variables at sink nodes (decoders). Research is pursued along several specific lines of investigation, including derivation of delay-constrained performance bounds and optimality conditions, optimal and low complexity algorithm design, global optimization techniques, analog mappings for distributed source-channel coding, analog multiple descriptions coding, extensions to sources and channels with memory, and optimal routing in an analog network. The effort builds on a body of preliminary work and results, including the necessary conditions for optimality of such mappings in simple settings, iterative algorithms to find locally optimal mappings, as well as a powerful non- convex optimization tool (deterministic annealing), which has been successfully employed in related optimization problems.","title":"CIF: Small: Analog Networking: Distributed Source-Channel Approaches to Delay and Resource Constrained Communications","awardID":"1118075","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["550914"],"PO":["564924"]},"192968":{"abstract":"An increasing amount of data is stored in an interconnected manner. Such data range from the Web; hyperlinked pages; to bibliographical data; graph of citations; to biological data; associations between proteins, genes, and publications; to clinical data; associations between patients, hospitalizations, exams and diagnoses. A critical need in order to leverage the available data is the enablement of information discovery, i.e., given a question (query) find pieces of data or associations between them in the data graph that are \"good\" (relevant, authoritative and specific) for the query, and rank them according to their \"goodness\". Submitting such queries should not require knowledge of a complex query language (e.g., SQL) or of the details of the data (e.g., schema). Unfortunately, little has been done to provide high-quality information discovery on data graphs in domains other than the Web, where search engines have been successful. This project is expected to have the following broader impacts: (a) Promote participation of FIU (one of the largest Hispanic institutes in the country) minority students in the research process, in the form of independent or senior class projects. (b) Facilitate effective information discovery on biological and clinical data, which can lead to cost savings, and increased research productivity in these domains. The results will be disseminated through publications, public Web demo systems, and the project Web site (http:\/\/dblab.cs.ucr.edu\/projects\/DGID\/).","title":"III-CXT-Small: Information Discovery on Domain Data Graphs","awardID":"1216032","effectiveDate":"2011-10-31","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[516939],"PO":["563751"]},"182716":{"abstract":"This collaborative project is investigating the characteristics of a mixed-reality learning environment that combines the rich context and multi-sensory experiences of a physical lab with the interactive simulations of a virtual lab. The hybrid environment integrates sensors and simulations to bring out the advantages of each setting in a complementary way. The research team is developing four such mixed-reality laboratory experiences for secondary school level chemistry and physics courses and studying student learning in these contexts. Two of the activities use an integration strategy in which data acquired in real time from a physical experiment are used to control a virtual experiment. The advantage of this coupling is that abstract concepts or invisible processes can be visualized on the computer screen while the physical experiment is underway. Whenever the learner's hands-on interaction with the physical experiments changes the sensor measurement, the visualization in the virtual experiment responds accordingly, creating an intimate link between the two worlds. The other integration strategy uses physical and virtual experiments in parallel, challenging the student to match the results measured by the sensors and the results computed by the simulations. The learning potential in this configuration stems from the ability to go back and forth between both worlds, adjusting the virtual experiment to match the physical experiment and then adjusting the physical experiment to test the fidelity of the virtual experiment. Implementations of the four activities in eight classrooms are being compared to classes covering similar content. The intellectual merit of this project lies in its investigation of the potential of cyberlearning technologies to transform inquiry in the lab. In addition, the project brings to bear the expertise of a recognized team of researchers. The project is exercising its broader impacts through its identification of a new instructional approach to STEM education. The combination of physical and virtual labs carries the potential for broad utility, with the insights and examples developed by this project potentially applicable throughout STEM education. In fact, because all of the project software is open source and the materials made available freely from the project's website, the only expenses to schools are for the sensors. A key design criterion is that all project software is compatible with sensors from multiple vendors so that schools are not limited in their choices.","title":"DIP: Collaborative Research: Mixed-Reality Labs: Integrating Sensors and Simulations to Improve Learning","awardID":"1124281","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":["562505",489538],"PO":["560894"]},"182629":{"abstract":"This collaborative project is investigating the characteristics of a mixed-reality learning environment that combines the rich context and multi-sensory experiences of a physical lab with the interactive simulations of a virtual lab. The hybrid environment integrates sensors and simulations to bring out the advantages of each setting in a complementary way. The research team is developing four such mixed-reality laboratory experiences for secondary school level chemistry and physics courses and studying student learning in these contexts. Two of the activities use an integration strategy in which data acquired in real time from a physical experiment are used to control a virtual experiment. The advantage of this coupling is that abstract concepts or invisible processes can be visualized on the computer screen while the physical experiment is underway. Whenever the learner's hands-on interaction with the physical experiments changes the sensor measurement, the visualization in the virtual experiment responds accordingly, creating an intimate link between the two worlds. The other integration strategy uses physical and virtual experiments in parallel, challenging the student to match the results measured by the sensors and the results computed by the simulations. The learning potential in this configuration stems from the ability to go back and forth between both worlds, adjusting the virtual experiment to match the physical experiment and then adjusting the physical experiment to test the fidelity of the virtual experiment. Implementations of the four activities in eight classrooms are being compared to classes covering similar content. The intellectual merit of this project lies in its investigation of the potential of cyberlearning technologies to transform inquiry in the lab. In addition, the project brings to bear the expertise of a recognized team of researchers. The project is exercising its broader impacts through its identification of a new instructional approach to STEM education. The combination of physical and virtual labs carries the potential for broad utility, with the insights and examples developed by this project potentially applicable throughout STEM education. In fact, because all of the project software is open source and the materials made available freely from the project's website, the only expenses to schools are for the sensors. A key design criterion is that all project software is compatible with sensors from multiple vendors so that schools are not limited in their choices.","title":"DIP: Collaborative Research: Mixed-Reality Labs: Integrating Sensors and Simulations to Improve Learning","awardID":"1123868","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":["563454"],"PO":["560894"]},"182409":{"abstract":"This project is focused on modeling and validating the macromolecular assembly of viral capsids. <br\/>Rigorous, mechanistic explanations and predictions are lacking for many milestone processes that occur during self-assembly of symmetric macromolecular structures. This is despite the fact that numerous representative structures of self-assembled viral capsids are available. In this project, we are specifically interested in: a) nucleations, b) autostery, conformational switches and c) scaffolding removal, all of which are processes driven by configurational and combinatorial entropy, a stumbling block for commonly used computational molecular simulation paradigms including molecular dynamics and Monte Carlo methods. Multiscale Geometry and Symmetry Constraints (MGSC) is a versatile and computationally highly efficient new modeling paradigm developed by this PI team during a prior NSF project: it complements and integrates with former paradigms while addressing key shortcomings. The project will use the MGSC paradigm to translate key questions about biological processes driven by configurational and combinatorial entropy into diverse mathematical and algorithmic questions that elucidate the influence of geometry and symmetry upon these processes. These questions are independently interesting and are related to longstanding open problems in combinatorial rigidity, algebraic geometry of configuration spaces, algebraic combinatorics, and complexity. Moreover, using MGSC, we will obtain a systematic modeling procedure not only for extracting the minimal, relevant data (model input) for answering focused questions about these processes (Occam?s razor), but also for interpreting the answers (model output) biologically. Finally, the project will use existing experimental results (in vitro and in vivo, performed at a co-PI?s lab) on representative families of viruses (such as the Murine Parvovirus (MVM), Maize Streak Virus (MSV), Adeno associated viruses (AAV4) to validate its predictions, for instance, on crucial inter-molecular interactions whose removal disrupts assembly.<br\/><br\/>Viral capsid self-assembly from its constituent protein molecules is a phase of the viral lifecycle that is relatively independent of the structure and processes of the host cell. Yet, the self-assembly phase has not been targeted in the design of drugs or vaccines for treating viral infections, nor has it been leveraged in the design and use of viral vectors in gene therapy. This is because the rapidity, efficacy, robustness, spontaneity and mathematically complex orchestration of viral capsid self-assembly, occurring at the nano-scale, is extremely difficult to understand. This project aims at bringing new insights into the viral capsid self-assembly process by combining the expertise of two mathematicians, a computer scientist and an experimental structural biologist. <br\/>The project will build upon these results to continue the development of an open source software suite EASAL (Efficient Atlasing and Search of Assembly Landscapes). This has the potential to be used by a wide variety of disciplines that are interested in isolating the crucial inter-atomic interactions that drive macromolecular self-assembly. Hence the project will provide outstanding interdisciplinary research experience not only to the graduate students and postdocs involved, but to the PIs as well. The project will provide research experience for STEM teachers at local schools and will additionally involve Tertl Studos - a game-based learning software company that is interested in working in the public domain - to creatively incorporate geometric constraint solving algorithms into a wide variety of math and science benchmarks in grades 4-12.<br\/><br\/>This proposal was submitted to the DMS programs in Mathematical Biology and Computational Mathematics, to CCF\/CISE and to MCB\/BIO in response to the Dear Colleague Letter: Unsolicited Proposals at the Interface of the Biological, Mathematical and Physical Sciences. <br\/>It is co-funded by sevral NSF programs: Mathematical Biology\/DMS\/MPS, Molecular and Cellular Biology\/BIO, Algorithmic Foundations CCF\/CISE as well as by the DMS Cyberinfrastructure for the 21st Century (CIF21) fund.","title":"MPS: BIO: Theory, Algorithms, Software, for Predicting Geometric Entropy-driven Virus Assembly, using Multiscale Configuration Space Atlasing and Combinatorial Enumeration","awardID":"1122541","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7334","name":"MATHEMATICAL BIOLOGY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"7275","name":"CROSS-EF ACTIVITIES"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0807","name":"Division of MOLECULAR AND CELLULAR BIOSCIE","abbr":"MCB"},"pgm":{"id":"8011","name":"Networks and Regulation"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1106","name":"Division of HUMAN RESOURCE DEVELOPMENT","abbr":"HRD"},"pgm":{"id":"1114","name":"Cellular Processes"}}],"PIcoPI":[488680,488681,"564569",488683],"PO":["230845"]},"192959":{"abstract":"CAREER: A Collaborative Adaptive Data Sharing Platform<br\/><br\/>The increased popularity of domain social networking and blogs is creating a huge amount of shared data. Properly annotating this data would allow its effective searching and analysis. Consider as a specific motivating application a disaster mitigation collaboration network for businesses. Using keyword search to find open child care locations after a hurricane would require sifting through hundreds of shared documents. Current data sharing platforms provide little help to the users to effectively and effortlessly annotate their data in a way that will benefit the information demand of other users. The long term goal of this project is to leverage the collective knowledge of communities to increase the utility of shared information. The objective of this project is to create the knowledge and techniques to allow the users of an application domain to effectively and effortlessly annotate, share and query data, by exploiting the past user interactions -- i.e., data annotations, query workload and user query relevance feedback. A key novelty of the proposed Collaborative Adaptive Data Sharing Platform (CADS) is that the past user interactions are leveraged to effectively annotate the data at insertion-time. <br\/><br\/>The intellectual merit of this project is the facilitation of effective annotation, matching and querying of shared data by leveraging the user interactions at insertion and query time. The algorithms for the transformative concept of adaptive insertion form, which will suggest the best attributes, values and matchings to annotate the to-be-inserted data, will estimate the information value and confidence of a candidate annotation and dependencies analysis on the query workload. The adaptive query form algorithms which will guide the user in formulating effective queries, will exploit past user interactions to estimate the user?s affinity to a condition. All algorithms will be evaluated with real users and datasets.<br\/><br\/>This project is expected to have the following broader impacts: (a) Promote participation of FIU (one of the largest Hispanic institutes in the country) minority students in the research process. This is expected to attract more minority students to pursue MS or Ph.D. in computer science, which is hindered by the lack of exposure to academic opportunities. (b) Facilitate effective collaboration and information sharing among the members of communities -- e.g. disaster management, scientific, news.","title":"CAREER: A Collaborative Adaptive Data Sharing Platform","awardID":"1216007","effectiveDate":"2011-10-31","expirationDate":"2015-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["516939"],"PO":["565136"]},"181629":{"abstract":"There is a rich research literature on information integration (e.g., on data fusion, data integration, and data exchange, including schema matching, mapping, and composition), knowledge-representation, ontologies, and semantic web technologies. However, there has been little prior work on the related problem of merging annotated datasets that already have largely compatible schemas, but where data values of some fields can come from (or link to) different concept hierarchies (taxonomies). Combining datasets into a single, consistent representation is a prerequisite for addressing many important scientific questions (e.g. those that rely on data to be expressed at broad spatial, temporal, and taxonomic scales). In practice, scientists combine multiple datasets manually, a time-intensive and error-prone process. In many application domains (e.g., biodiversity, ecology, systematics) data are often annotated with concepts from different but interrelated taxonomies. For instance, scientists who wish to combine datasets that record the presence or absence of species at given locations are often faced with datasets that draw species names from different taxonomies. In such cases, merging datasets requires aligning the different taxonomies. However, even for aligned taxonomies (i.e., where formal articulation constraints are given), many different dataset merges are possible, including inconsistent or incomplete ones. These in turn can yield different or even contradictory outcomes in subsequent interpretations and downstream data analysis. The primary goals of this project are to develop new techniques at the interface of data integration, knowledge-representation, and reasoning, to empower scientists by giving them new tools for merging and 'logically debugging' taxonomies and annotated datasets. The proposed Euler toolkit will include a formal framework with a broad range of constraints and data types; novel provenance-based techniques to detect, explain, and repair inconsistencies in taxonomy alignments; and new techniques to reduce uncertainty in alignments. <br\/><br\/>For further information see the project web site at the URL: http:\/\/www.daks.ucdavis.edu\/projects\/euler","title":"III:Small: A Logic-Based, Provenance-Aware System for Merging Scientific Data under Context and Classification Constraints","awardID":"1118088","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["538708",486619,486620],"PO":["563727"]},"187072":{"abstract":"This project aims to uncover the existence of a qualitatively better class of analog error-correcting codes than previously known in the brain, show how such codes can be used and decoded, and develop the theory for quantifying the performance of such codes. <br\/><br\/>Information theory was introduced into neuroscience relatively early, and the theory of efficient (source) coding has been widely embraced in the sensory neurosciences. However, the second branch of information theory, which deals with the maximally parsimonious addition of redundancy to recover signal from noise, has curiously not made inroads in neuroscience. Shannon's channel coding theorem revealed the existence of codes that make possible error correction at efficiencies previously thought impossible.<br\/><br\/>The investigator's central hypothesis is that the brain routinely employs such error correcting codes and the machinery required to decode and work with them. The hypothesis is motivated by a recent analysis of the grid cell code for animal location by the investigator and colleagues, showing it has unprecedented error-correction properties compared to known population codes in the brain (Sreenivasan & Fiete, 2011). The investigator proposes to: 1) Develop definitions and constraints for analog neural codes, to apply the channel coding framework to neural codes and thus characterize their \"goodness\" on error-correction. 2) Identify high-level coding properties that enable strong error-correction, and search for these properties in observed but poorly understood neural codes. At the same time, explore strong theoretical error-correcting codes that the brain may plausibly implement. 3) Model plausible neural mechanisms for decoding such codes. Decoding is inference, so this question can be more generally thought of as exploring neural mechanisms for hierarchical inference. <br\/><br\/>This project is computational and theoretical, and also involves close collaboration with neurophysiologists, to apply quantification techniques to neural data and work with experiments to inform the theories and test predictions.","title":"EAGER: Noise and strong analog error-correcting codes in neural computation","awardID":"1148973","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["546555"],"PO":["564318"]},"186061":{"abstract":"The objective of this research is to develop key components of community-based pervasive systems which will allow citizens to respond to disasters. The systems will make use of inexpensive networked sensors and communication devices distributed among families and communities. The sensors\/devices will enable the collection of situational information and the dissemination of alerts, by use of fault and delay-tolerant networks, and through the use of Cloud computing and crowd sourcing techniques. The Indo-US partnership in this effort will study these issues in the context of the Indian subcontinent where urban and rural landscapes are unique.<br\/><br\/>Sensor-based detection technologies will be studied to help identify events, e.g. abnormal ground motion, and fault-tolerant networks will be designed to connect the sensor systems together and to a resource-rich cloud infrastructure. Methods for performing sensing analysis and data fusion in the cloud will be incorporated so as to address tradeoffs among rates of false positive alarms, false negative alarms, and time to detection. The existing infrastructure will also be used to design systems for delivering actionable alerts\/information to responders and communities using multiple networks. The community-based sensing and alerting techniques developed will be evaluated in campus testbeds at UCI\/Caltech, culminating in a pilot study\/drill at one of the Indian institutions with regional experience in disaster management. <br\/><br\/>Dealing with disasters effectively is a global concern and techniques to leverage communities for data collection and alerting is an effective strategy, especially in nations with diverse populations with varying degrees of technological sophistication. The research will enable a new generation of community-based cyber-physical systems in emerging markets, in which the community helps to detect, communicate and respond to rapidly evolving events such as earthquakes, tsunamis, fires, floods and epidemics. Students at different levels (graduate, undergraduate, K-12) will gain experience with developing real-world applications in a global context via courses and independent study projects. Students will benefit tremendously from exposure to the next generation of community-based cyber-physical systems technologies that will help design safer living environments for the future,","title":"PC3: Collaborative Research: Pervasive Computing for Disaster Response","awardID":"1143705","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[499298],"PO":["564181"]},"178174":{"abstract":"Every aspect of modern society, ranging from health care to national defense, depends on the availability of affordable, reliable software. The availability of this software, in turns, depends on helping software engineers to find high-quality components that they can assemble into finished software. Web sites currently provide access to millions of components that perform vital operations related to networking, graphics, data processing, and thousands of other functions. However, software engineers lack a validated, reliable method for selecting high-quality components that they can reuse in new software applications. Lacking such a method, software engineers sometimes use components that turn out, in retrospect, to be extremely difficult to reuse. This difficulty, in turn, increases the time required to create software, the cost of that software, and the potential for subtle bugs.<br\/><br\/>This research project is expected to provide a validated, reliable model for quickly assessing the reusability of components. This method will make use of \"low-ceremony evidence\" (LCE): information that characterizes different aspects of component quality yet is incremental, often informal, potentially context-dependent, and frequently contradictory. Examples of LCE include reviews, bug reports, and download counts of components. While each piece of LCE provides only an incomplete perspective into a component's quality, preliminary work suggests that the synthesis of LCE can be highly informative about component quality. This new research project (1) will use factor analysis to determine which pieces of LCE are mutually consistent, yielding scales for assessing one or more aspects of quality such as reusability, and (2) will statistically test how well these scales are correlated with the actual empirical difficulty that software engineers report with reusing those components. The resulting validated scales are expected to be useful for automatically assessing the quality of components in online websites. This would make it possible in future work to develop enhanced search engines enabling software engineers to quickly find high-quality components that they can use to create the software that society needs.","title":"SHF: EAGER: A first empirical test of low ceremony evidence for assessing quality attributes","awardID":"1101107","effectiveDate":"2011-10-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["541827"],"PO":["564388"]},"159364":{"abstract":"Abstract:<br\/>Award Number ? 0940824<br\/>Title: DataNet Full Proposal: Sustainable Environment through Actionable Data (SEAD)<br\/><br\/>The universities of Michigan, Indiana, and Illinois propose a DataNet partnership called Sustainable Environment through Actionable Data (SEAD). SEAD will enable new modalities of sustainability science - the study of dynamic interactions between nature and society. Advancing the science of sustainability requires integration of social science, natural science, and environmental data at multiple spatial and temporal scales that is rich in local and location-specific observations; referenced for regional, national, and global comparability and scale; and integrated to enable end users to detect interactions among multiple phenomena. SEAD will respond to the expressed needs of sustainability science researchers for long-term management of heterogeneous data by developing new capabilities for data integration, dissemination, and long-term preservation. SEAD will provide researchers with tools for active curation and use social networking to engage data producers and users in community curation, gradually shifting curatorial and collection development responsibilities from professional curators to the producer and user communities. Our focus is on the \"long tail\" of social and environmental data: derived data products, data collections from individual PI's and small group investigations, and data sets of local, regional or topical significance that are critical to sustainability science but are of limited value until they can be referenced geo-spatially and temporally, combined with related data and observations, and modeled consistently. SEAD will make data accessible to diverse users, including domain scientists, local, national and international policy makers, manufacturers of sustainable technologies, citizen scientists, and informed consumers. SEAD will take advantage of existing robust digital library and institutional repository (IR) infrastructures at the three universities for access, storage, and preservation to ensure wide accessibility of data, linkages between data and scientific publications, and persistence.<br\/><br\/>SEAD will serve researchers efficiently and in a financially sustainable way via active curation, make innovative use of social networking, integrate data with existing digital library infrastructures, and provide synthesis services that significantly increase the research and societal value of data. Our work will establish a new active curation paradigm that can be readily integrated into the scientific workflow and that leverages social networking technologies to engage the science community in data curation. Our research program will produce novel solutions to the synthesis of heterogeneous data across different levels of spatio-temporal granularity and scope; management of logical contexts and data models; appropriate sharing of data with privacy and proprietary restrictions; and preservation through emulation and migration-based-technologies and policies for distributed stewardship. Our cyberinfrastructure development work will support a network of repositories that functions on several levels: locally through integration of SEAD data into campus digital library\/repository infrastructures, inter-institutionally through a model for distributed data curation and storage, and nationally and internationally by extending our approach to other IRs, other DataNet Partners, sensor and observational networks, and topical data archives. Our financial sustainability plan will identify appropriate incentive mechanisms and business models based on a tight coupling of preservation and access services with research library managed IR infrastructure and ongoing involvement of scientists and users.<br\/><br\/>SEAD will build national and global capabilities for science-informed sustainability policy and planning in land use, natural resource management, agriculture, energy, economic development, \"green\" manufacturing, and related areas where critical decisions will be made in the next decade. The project will engage the community that preserves and shares scientific data, thus enhancing the public investment in scientific research and making taxpayer funded data widely available and easier to use which will provide high-value cost-effective curation and preservation capabilities through partnerships with other \"small science\" domains.","title":"DataNet Full Proposal: Sustainable Environment through Actionable Data (SEAD)","awardID":"0940824","effectiveDate":"2011-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}}],"PIcoPI":["554538","529937","471467","565242","537127"],"PO":["565292"]},"181191":{"abstract":"The goal of this project is to develop new techniques for visualizing static and dynamic data. Visualization allows us to perceive relationships in large interconnected datasets. While statistics may determine correlations among the data, intuitive visualizations of these correlations helps us frame what questions to ask about the data. Moreover, algorithms for visualizing processes that evolve over time will have applications beyond the traditional uses of information visualization in exploratory data analysis and searching for patterns and trends.<br\/><br\/>Graphs are often used to capture relationships between objects and visualized as node-link diagrams. Contact graphs provide an alternative and often more intuitive way to visualize planar graphs. In contact graphs, nodes are represented by regions and edges are represented by two regions sharing a common border. Such representation suggests the familiar metaphor of a geographical map. In this research project the PIs will study characterizations of the classes of graphs that admit contact graph representations where nodes have \"nice\" shapes (e.g., convex, with small complexity, with predetermined areas) and techniques for creating such representations. While contact graphs are restricted to planar graphs, the PIs will extend the notion to general graphs using clustering and embedding methods.<br\/><br\/>As an integral part of this project, graduate and undergraduate students will be involved in all aspects of the described research activities. This continues a tradition of integrating undergraduates into research projects that are easily accessible and visually appealing. As with past projects, all new software developed will be made available to the broader community.","title":"AF:Small:Algorithms for visualizing data with contact graphs and data maps","awardID":"1115971","effectiveDate":"2011-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7929","name":"COMPUTATIONAL GEOMETRY"}}],"PIcoPI":[485534,485535],"PO":["565157"]}}