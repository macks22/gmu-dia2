{"62705":{"abstract":"The Workshop on Software Engineering and Mobility will be held on May 13-14, 2001, in Toronto, Canada, in conjunction with the 23 rd International Conference on Software Engineering. The two-day meeting is designed to bring together leading software engineering researchers whose work is concerned with mobility in all its forms, i.e., both logical movement of code fragments and physical movement of hosts. This proposal seeks to stimulate the participation of graduate students in the workshop proceedings by providing travel grants in the amount of $500 to $1,000. The goal is to enable between 8 and 16 graduate students involved in doctoral research on topics related to the themes of the workshop to<br\/>participate in its workings. Special attention will be paid to ensure diverse geographic, racial, and gender representation among the invited students. Specialized workshops, such as this, have a tendency to attract established researches and a very small contingent of students whose dissertations are near completion.<br\/><br\/>Since discussions taking place in the workshop often reshape the research agenda of the field, students who are in the earlier stages of research could benefit the most from being involved in the workshop. Yet, they are least likely to attend. The funding we are requesting from NSF to support travel grants to the workshop will significantly affect the level of student participation. Even though the size of the travel grants is relatively small, the prestige of receiving one will make both advisors and students give serious consideration to applying for the grants. Finally, if successful, we hope to create a culture in which conference travel by students happens earlier than customary for the long-term benefit of the entire<br\/>research community, e.g., improved retention in the doctoral program.","title":"Student Travel Support for the Software Engineering and Mobility Workshop","awardID":"0111878","effectiveDate":"2001-08-01","expirationDate":"2002-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["384032"],"PO":["209879"]},"62947":{"abstract":"This project aims to extend an existing simple saliency-based visual attention system to animated color video sequences so as to enable it to cue the object recognition module towards interesting locations in live video streams, and simultaneously to extend an existing model for object recognition to on-line adaptability through top-down signals and task- and object-dependent learning of features. The PIs will then integrate these attention and recognition models, by developing feedforward and feedback interactions between localization of regions of interest and object recognition in those regions. This will require substantial elaboration of both models, as well as specific work on their integration. The result will be a complete model of object localization and recognition in primates, with direct applicability to computer vision challenges. The PIs will next implement and deploy the combined model on a cluster of CPUs linked by very fast interconnect (just installed at USC) to allow for real-time processing, and will demonstrate its utility in a prototype video-conferencing application in which the on-line adaptive attentional component of the integrated system will quickly locate regions in the monitored environment where something interesting is happening (e.g., a user raising her hand in a conference room). The recognition part of the system will then be trained and refined on-line to recognize relatively simple hand signs (e.g., a finger pointing up, meaning that the user wishes to become the center of interest in a video-conference). This work will demonstrate two points: that a biologically-inspired approach to traditionally hard computer vision problems can yield unusually robust and versatile vision systems (which work with color video streams and quickly adapt to various environmental conditions, users, and tasks); and that computational neuroscience models of vision can be extended to yield real, useful and widely applicable computer vision systems, and are not restricted to testing neuroscience hypotheses under simple laboratory stimuli.","title":"ITR\/SY: A Neuromorphic Vision System for Every-Citizen Interfaces","awardID":"0112991","effectiveDate":"2001-08-15","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["523294","435190","549488"],"PO":["335186"]},"60659":{"abstract":"Abstract<br\/>CTS-0103002<br\/>N. Seeman, et al., New York University<br\/><br\/>This proposal was received in response to Nanoscale Science and Engineering (NSE) solicitation, NSF-00119, in the category Nanoscale Interdisciplinary Research Teams (NIRT). This is a collaborative activity between New York University, California Institute of Technology and Dow Chemical Co. using GOALI model. The goal is to synthesize and demonstrate operational nanoscale machines or devices. The level of control offered by DNA systems can be exploited to make intricate DNA nanostructures, including self-assembling DNA that forms two-dimensional and three-dimensional arrays. Modeling and simulation is a critical part of this project, in order construct and test the DNA nanostructures. <br\/><br\/>It is proposed to combine the activities of New York University, California Institute of Technology and Dow Chemical laboratories to achieve a demonstration of DNA based nanomechanical devices useful for performing fast calculations, for sensors that detect specific molecules in the environment, or to improve the properties or performance of a material. Practical design and manufacture of nanoscale machines and devices requires overcoming numerous challenges in synthesis, processing, characterization, design, optimization, and fabrication. The approach will be first to prototype the designs computationally, optimizing the particular base-pair sequences, making sure that the particular lengths and spacings will lead to proper clearances, and testing the operation of the device, including the dynamics. The project will focus on nanomechanical devices of three types. <br\/>o The B-Z based nanomotor. A DNA based nanomotor predicated on the B to Z DNA<br\/>transitions under different salt conditions. <br\/>o A DNA sequence-specific mechanical device <br\/>o A DNA based switch based on principles similar to the DNA sequence-<br\/>specific mechanical device.","title":"NIRT\/GOALI: DNA-Based Nanomechanical Devices","awardID":"0103002","effectiveDate":"2001-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1415","name":"PARTICULATE &MULTIPHASE PROCES"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1480","name":"ENGINEERING RESEARCH CENTERS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1674","name":"NANOSCALE: INTRDISCPL RESRCH T"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"1504","name":"GRANT OPP FOR ACAD LIA W\/INDUS"}}],"PIcoPI":["554823",155980,"554822","296135","558957"],"PO":["278176"]},"80415":{"abstract":"","title":"Design of Machines Organized as Processor-and-Memory Hierarchies","awardID":"0296005","effectiveDate":"2001-08-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["540130"],"PO":["248088"]},"60804":{"abstract":"0103748<br\/>Aluru, Srinivas.<br\/>Iowa State University<br\/><br\/>CISE Postdoctoral Associates in Experimental Computer Science: Parallel Hierarchical Methods for Computational Electromagnetics<br\/><br\/>The goal of this research is to develop parallel algorithms and build parallel software for the solution of a wide variety of problems involving the computational analysis of electromagnetic scattering. Specific problems of interest are: 1) electromagnetic scattering from quasi-planar surfaces, 2) dielectric random rough surfaces, 3) multiregion surfaces, 4) three-dimensional problems where the fields are characterized by frequency and 5) three-dimensional problems where the field behavior is dependent on time history. The unifying theme in addressing these problems will be the use of the hierarchical Fast Multipole Method and its variants. A major goal of the research is to develop the capability to solve highly non-uniform problems efficiently. Emphasis will be placed on the development of distribution-independent algorithms, i.e., provably efficient algorithms for which the run-time is independent of the distribution without making any assumptions on either the range of distributions or the limited precision of computer arithmetic. The postdoctoral research associate will develop and validate software employing these algorithms in close cooperation with experts in electromagnetics at Iowa State University. Validation of the results will be carried out via comparisons against experimental data as well as numerical results obtained from slower, established solvers. The associate will perform experimental evaluation of the performance of the software using conventional parallel computers and high-performance clusters.<br\/><br\/><br\/><br\/>0103748<br\/>Aluru, Srinivas.<br\/>Iowa State University<br\/><br\/>CISE Postdoctoral Associates in Experimental Computer Science: Parallel Hierarchical Methods for Computational Electromagnetics<br\/><br\/>The goal of this research is to develop parallel algorithms and build parallel software for the solution of a wide variety of problems involving the computational analysis of electromagnetic scattering. Specific problems of interest are: 1) electromagnetic scattering from quasi-planar surfaces, 2) dielectric random rough surfaces, 3) multiregion surfaces, 4) three-dimensional problems where the fields are characterized by frequency and 5) three-dimensional problems where the field behavior is dependent on time history. The unifying theme in addressing these problems will be the use of the hierarchical Fast Multipole Method and its variants. A major goal of the research is to develop the capability to solve highly non-uniform problems efficiently. Emphasis will be placed on the development of distribution-independent algorithms, i.e., provably efficient algorithms for which the run-time is independent of the distribution without making any assumptions on either the range of distributions or the limited precision of computer arithmetic. The postdoctoral research associate will develop and validate software employing these algorithms in close cooperation with experts in electromagnetics at Iowa State University. Validation of the results will be carried out via comparisons against experimental data as well as numerical results obtained from slower, established solvers. The associate will perform experimental evaluation of the performance of the software using conventional parallel computers and high-performance clusters.","title":"CISE Postdoctoral Research Associates in Experimental Computer Science: Parallel Hierarchical Methods for Computational Electromagnetics (CCR-NSG; ACIR)","awardID":"0103748","effectiveDate":"2001-08-15","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":["565135"],"PO":["564318"]},"60937":{"abstract":"One focus of the research is perfect simulation. Markov chain Monte Carlo (MCMC) approximate sampling methods have become extremely popular for Bayesian inference problems and for problems in other areas, such as spatial statistics, statistical physics, and computer science as a way of sampling approximately from a complicated probability distribution. For some problems, it is now possible to use more sophisticated MCMC techniques to sample perfectly (that is, without error) from the distribution of interest. The investigator and his colleagues work on creating, improving, analyzing, and applying efficient perfect simulation algorithms; these algorithms include the Fill-Machida-Murdoch-Rosenthal algorithm and the new Randomness Recycler technique pioneered by the investigator and his colleague Mark Huber. The second focus concerns probability and combinatorial structures, especially trees. The investigator and his colleagues study such problems as characterizing the \"shape\" of random multiway search trees (via fundamental research in the area of analytic combinatorics known as singularity analysis); generalizing the analyses of the height of a random incomplete digital search tree, of the move-to-front rule for self- organizing lists, and of recursive trees; and extending the so-called generalized smoothing transformation to distributions on the entire real line.<br\/><br\/>One focus of the investigator's research is perfect simulation from probability distributions. Standard \"Markov chain Monte Carlo\" (MCMC) methods for approximate simulation from complicated probability distributions have proved extremely useful for problems in statistics (including image analysis), physics (including models for magnetism and for phase changes), and computer science as a way of sampling approximately from a complicated probability distribution. But there are problems with the MCMC approach -- most notably that for many problems it is unknown for how long the simulations must be run in order to come close to the distribution of interest. For some problems, it is now possible to use more sophisticated MCMC techniques to sample perfectly (that is, without error) from the distribution of interest. The investigator and his colleagues work on creating, improving, analyzing, and applying efficient perfect simulation algorithms, including two different algorithms pioneered by the investigator. The second focus concerns interplays between probability and combinatorial structures, especially trees, which are fundamental structures for the storage of computer data. This second focus of research has applications to the modeling of epidemics, family trees of ancient manuscripts, and pyramid schemes and to the election of multiple leaders in a multiprocessor computer network.","title":"Studies in Perfect Simulation and Combinatorial Probability","awardID":"0104167","effectiveDate":"2001-08-01","expirationDate":"2004-12-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1263","name":"PROBABILITY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["319269"],"PO":["278032"]},"60618":{"abstract":"This proposal was submitted in response to the solicitation \"Nanoscale Science and Engineering\" (NSF-00-119). The resulting grant is co-funded by the Divisions of Materials Research and Mathematical Sciences. <br\/><br\/>Nanostructures such as quantum dots and quantum wires can be employed to yield devices with novel electronic properties. One particularly promising route to quantum dot formation is via the spontaneous self-assembly process that occurs during heteroepitaxy. To control the quantum dot formation and self-assembly process to the extent that these novel electronic devices become a reality, this team of researchers will investigate the mechanisms of dot formation, and develop predictive models of the dot formation and self-organization process.<br\/><br\/>Achieving this goal requires an integrated interdisciplinary effort that can address the quantum dot formation and self-assembly process from the atomistic to the continuum or nanometer length scales. The work of this group will thus involve, for example, first-principle calculations of surface energies and surface diffusion coefficients, calculations of the evolution of quantum dot shape and composition during deposition, and the nonlinear dynamics of pattern formation or self-assembly of quantum dots. Each effort will feed into the other, as the information at the smaller length scales will be employed in the larger scale calculations, enabling us to bridge length scales that range from the fraction of a nanometer to thousands of nanometers. The ultimate goal of the project is to develop an understanding of the important materials issues governing formation and self-assembly of quantum dots, and to develop predictive models that enable the first-principles design of quantum dot nanostructures. The models can then be used to design and create specific quantum dot structures, providing for possible breakthroughs in the fabrication of new quantum dot electronic devices.<br\/>%%%<br\/>***","title":"NIRT: The Evolution and Self-Assembly of Quantum Dots","awardID":"0102794","effectiveDate":"2001-08-01","expirationDate":"2006-11-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0307","name":"Division of MATERIALS RESEARCH","abbr":"DMR"},"pgm":{"id":"1765","name":"CONDENSED MATTER & MAT THEORY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1266","name":"APPLIED MATHEMATICS"}}],"PIcoPI":["484710","379286","547420","484709","389021"],"PO":["141355"]},"59370":{"abstract":"Proposal 0098331 <br\/>Charles K Chui, Wenjie He, and Joachim Stoeckler<br\/>U of Missouri, Saint Louis<br\/><br\/>Abstract: Tight frames with scaling factor 2, generated by the standard affine operations of dilation and translation of two compactly supported cardinal splines, called frame generators, can be easily constructed for any spline order m (or degree m-1), by applying matrix extension techniques. However, regardless of the number of (spline) frame generators being used, at least one of them has only one vanishing moment, when the matrix extension approach is followed.<br\/><br\/>In our recent work, we introduced the notion of \"vanishing-moment recovery\" Laurent polynomial factors S(z) is introduced to show that the maximum number m of vanishing moments can be achieved by both compactly supported tight frame generators, for any order m. Furthermore, the Laurent polynomials S(z) can be formulated explicitly when tight frames are relaxed to be sibling frames; that is, both frame generators, together with their corresponding duals, are compactly supported cardinal splines of the same order m. These additional vanishing moments are essential for effective use of the wavelet coefficients for feature extraction, noise removal, etc.<br\/><br\/>Cardinal splines are spline functions with an equally spaced knot sequence extending from. However, in most practical applications, the intervals of interest are bounded and data samples may not be uniformly distributed. Hence, mth order splines with arbitrary knots, or at least with m stacked knots at one or both end-points of the interval of interest, are needed. This new research project is concerned with formulation of the matrix equivalent Sk of the Laurent polynomials S(z), construction of Sk and the corresponding tight (and more generally sibling) frame generators of mth order compactly supported splines with arbitrary knots and with m vanishing moments, achievement of such important features as inter-orthogonality for sibling frames, development and integration of the associated frame algorithms with the existing spline tools, investigation of spline-wavelet frame tools for adding sparsification and editing fearures for applications in computer graphics, and development of a portable software library.","title":"Spline-Wavelet Frames in Computer Graphics and other Applications","awardID":"0098331","effectiveDate":"2001-08-15","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":[152485,152486,152487],"PO":["321058"]},"59293":{"abstract":"Proposal #0098114<br\/>Kupar, Deepak<br\/>University of Mexico<br\/><br\/>Semantic unification has been effectively employed in many subfields of logic, computer science, artificial intelligence and cognitive science, with its most popular use being in resolution, logic programming languages such as Prolog, and the type inference mechanism in the programming language ML. Semantic unification (associative-commutative unification) played a pivotal role in settling open questions in mathematics (e.g. Robbins' conjecture about boolean algebra in 1996 by McCune using the theorem prover EQP). Recently, semantic unification has been found useful also in cryptographic analysis, knowledge representation and distributed computing.<br\/><br\/>This project will be a continuation of research on the theory of semantic unification as well as the design, development and implementation of semantic unification algorithms. This research will be motivated by new applications of semantic unification in cryptographic protocol analysis in conjunction with Catherine Meadows' work on the NRL (Naval Research Laboratory) Protocol Analyzer, in knowledge representation and description logics, induction theorem proving, and process algebra.<br\/><br\/>The new unification algorithms will be first developed and experimented using the Unification Workbench, a tool under development at SUNY, Albany, with the eventual goal of integrating them into application software, the NRL Protocol Analyzer and a rewrite-based induction theorem prover RRL (Rewrite Rule Laboratory) for use in the applications discussed above.<br\/><br\/>This award is one of three in a collaborative research team. The three awards are CCR-0098114 (Deepak Kapur, U New Mexico), CCR-0098270 (Christopher Lynch, Clarkson U), and CCR-0098095 (Paliath Narendran, SUNY Albany).","title":"Collaborative Research on Semantic Unification and its Applications","awardID":"0098114","effectiveDate":"2001-08-15","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["531861"],"PO":["321058"]},"59284":{"abstract":"Proposal #0098095<br\/>Narendran, Paliath<br\/>SUNY Albany<br\/><br\/>Semantic unification has been effectively employed in many subfields of logic, computer science, artificial intelligence and cognitive science, with its most popular use being in resolution, logic programming languages such as Prolog, and the type inference mechanism in the programming language ML. Semantic unification (associative-commutative unification) played a pivotal role in settling open questions in mathematics (e.g. Robbins' conjecture about boolean algebra in 1996 by McCune using the theorem prover EQP). Recently, semantic unification has been found useful also in cryptographic analysis, knowledge representation and distributed computing.<br\/><br\/>This project will be a continuation of research on the theory of semantic unification as well as the design, development and implementation of semantic unification algorithms. This research will be motivated by new applications of semantic unification in cryptographic protocol analysis in conjunction with Catherine Meadows' work on the NRL (Naval Research Laboratory) Protocol Analyzer, in knowledge representation and description logics, induction theorem proving, and process algebra.<br\/><br\/>The new unification algorithms will be first developed and experimented using the Unification Workbench, a tool under development at SUNY, Albany, with the eventual goal of integrating them into application software, the NRL Protocol Analyzer and a rewrite-based induction theorem prover RRL (Rewrite Rule Laboratory) for use in the applications discussed above.<br\/><br\/>This award is one of three in a collaborative research team. The three awards are CCR-0098114 (Deepak Kapur, U New Mexico), CCR-0098270 (Christopher Lynch, Clarkson U), and CCR-0098095 (Paliath Narendran, SUNY Albany).","title":"Collaborative Research on Semantic Unification and its Applications","awardID":"0098095","effectiveDate":"2001-08-15","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["402395"],"PO":["562984"]},"59384":{"abstract":"The proposed work addresses a variety of issues related to motion planning of complex systems: development and application of statistical methods to reduce the effect of the \"course of dimensionality\" in configuration-based motion planning; constructing stochastic models of mechanical systems to account for noise in low-level sensing and actuation and its effect on high-level planning; coordination of multi-robot swarms and their biological analogues. The obtained results will be tested on holonomic as well as non-holonomic systems, and also applied to studying other complex systems, such as protein molecules.","title":"Diffusion Processes in Motion Planning and Control","awardID":"0098382","effectiveDate":"2001-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["508352"],"PO":["335186"]},"63091":{"abstract":"NSF PROPOSAL #0113792<br\/><br\/><br\/>ITR: Aligning Societal Values, Privacy Policy, and IT Requirements<br\/><br\/>Colin Potts, Georgia Institute of Technology<br\/>Annie I. Anton, North Carolina State University<br\/><br\/>The guarantee and assurance of privacy must be included in the design of information technologies from the onset. This research focuses on how society uses, values, and protects citizens' personal information. From the perspective of system design, software engineers need methods and tools to enable them to design systems that reflect those values and protect personal information, accordingly. This research examines how privacy considerations and value systems influence the design, deployment and consequences of IT. Investigations will include study of the motivations and barriers to the use of IT when use of these technologies requires the user to provide Personally Identifiable Information (PII). In essence, this work focuses on: societal values, web site policies, and the operational functioning of web-based e-commerce systems, which are often misaligned. The goal is to develop concepts, tools and techniques that help IT professionals and policy makers bring policies and system requirements into better alignment. An action-oriented set of conceptual tools, including guidelines and privacy-relevant policy templates will be constructed and validated. The tools will be fully documented and illustrated on a web site developed for the purpose of conducting the proposed project and disseminating results and recommendations.","title":"ITR\/PE: Aligning Societal Values, Privacy Policy, and IT Requirements","awardID":"0113792","effectiveDate":"2001-08-01","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["235460","517936"],"PO":["564388"]},"69582":{"abstract":"","title":"CAREER: Spectral Techniques for Functional Testing of Sequential Circuits and System-On-A-Chip","awardID":"0196470","effectiveDate":"2001-08-15","expirationDate":"2007-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["494757"],"PO":["562984"]},"59231":{"abstract":"Proposal #0097976<br\/>Hong, Hoon<br\/>North Carolina State U<br\/><br\/>The long term objective of this research is to develop mathematical theories, algorithms, and software libraries\/packages for efficiently solving quantified algebraic constraints (quantified boolean expressions of polynomial equations\/inequalities over real numbers), which can handle large real life problems. This particular project will focus on moderate size inputs (up to about 10 variables). There are still many interesting real life problems of moderate sizes.<br\/><br\/>The potential impact is as follows. Many important and difficult problems in mathematics, scientific, engineering and industry can be reduced to that of solving quantified algebraic constraints. Thus the availability of efficient algorithms\/softwares for solving quantified algebraic constraint will have a broad impact on science and industry.<br\/><br\/>The specific approaches are as follows.<br\/><br\/>- Allow approximate solutions.<br\/><br\/>The subject of quantifier constraint solving arose originally as a problem in logic. Naturally, obtaining \"exact\" solution has been the goal of the previous research efforts. In order to obtain exact solutions, most calculations have been carried out symbolically, suffering from enormous intermediate computation swelling. Further, they had to deal with all the singular\/degenerate cases, which are often very expensive computationally to analyze. However, in most real-life problems, approximate solutions are acceptable. In fact, often, there are many uncertain coefficients in constraints, and thus it is even meaningless to try to find exact solutions. Hence, we will allow approximate solutions. During this project period, we will pursue two particular ideas in this direction: \"approximate quantification\" and \"box approximation\" of solution sets. Our preliminary investigations suggest that these are very promising ideas\/directions.<br\/><br\/>- Utilize the structure of constraints.<br\/><br\/>So far, the constraints have been treated as \"flat\" objects. For example, the polynomials arising in the constraints have been viewed as \"atomic\" objects. However, constraints in real life problems usually have intrinsic structures that arise naturally from the structures in the underlying laws\/components or from the way how the those laws\/components are combined. Thus, we will utilize the structures of given constraints. During this project period, we will study ways to utilize two particular structures: \"convexity\" of bounded quantifiers and \"composition\" structure of polynomials. Again, our preliminary investigations suggest that these are very promising ideas\/directions.<br\/><br\/>The results will be implemented in a software library and freely distributed on the web, in order to facilitate their application to moderate size real life problems by the scientific and engineering communities.","title":"Solving Quantified Algebraic Constraints","awardID":"0097976","effectiveDate":"2001-08-15","expirationDate":"2005-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["550491"],"PO":["321058"]},"59242":{"abstract":"Proposal #0098005<br\/>Popovic, Zoran<br\/>U of Washington<br\/><br\/>We propose a multi-layered approach to capturing and synthesizing realistic human shapes and motions. To capture the static shape of real humans, we will employ 3D scanning techniques including hierarchical light striping, simultaneous multi-striping, and photometric stereo. A feature-tracked motion capture system as well as 3D scanning techniques will generate motion data. The investigators will acquire this motion data at varying resolutions in order to drive the analysis of skeletal motion, body part deformation such as bulging due to flexing a muscle, and secondary motion such as leg vibrations that occur when stomping on the ground.<br\/><br\/>This wealth of human data will then drive an analysis, modeling, and synthesis stage. The static scan data will be analyzed to construct the space of possible human shapes. This human shape model together with the body part motion capture and full-body motion capture will be used to construct a detailed kinematic<br\/>model of the human body. Modeling human shape movement at such different levels of detail will allow control of the human motion on the coarse skeletal level while preserving the fine details such as muscle bulging. Furthermore, this multi-layered approach will enable selective replacement of different layers in the human model structure. For example, it will be possible to map the animated movement onto a different body scan and observe a different surface shape movement and creasing. The detailed kinematic human model will be further extended with a model of human dynamics by taking into account a number of physical properties of the human body such as muscle usage and mass distribution. This additional dynamic information provides a way to preserve the realism of motion even when the structure of motion is significantly modified. In addition, the investigators will extend the skeletal dynamic model with secondary motion simulations constructed to replicate the loose skin and tissue vibrations that occur in high-energy movements.<br\/><br\/>The investigators will incorporate their work into new curriculum both at their university and in courses being offered to the professional community. This work will be folded into CDROM's that reach a wide audience, including the general public and a broad spectrum of high school students who may be considering careers in information technology. The results of the research will include complex databases of human shape and motion to be distributed to the general research community in order to encourage further research in this area.","title":"Surface and Motion Capture for High Fidelity Synthesis of Digital Humans","awardID":"0098005","effectiveDate":"2001-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["549589","438138"],"PO":["532791"]},"59363":{"abstract":"Group communication services form important building blocks for applications in dynamic<br\/>distributed systems, where processors and communication links can repeatedly fail and recover.<br\/>Such dynamic behavior is especially descriptive of mobile environments, in which processors can<br\/>change their physical location continually. The key features of a group communication facility are<br\/>(1) indicating to each processor with which other processors it can currently communicate, and (2)<br\/>letting processors within a group communicate with each other in an ordered and reliable manner.<br\/>A typical approach to developing fault-tolerant software is to assume certain limitations on the<br\/>behavior of faulty components. However, in reality there is a non-zero probability that any such<br\/>assumptions will be temporarily violated; in fact, this probability grows with time. In particular,<br\/>mobile communication networks are exposed to environmental noise whose level is hard to predict<br\/>in advance. Thus, it may be too optimistic to approach correctness by assuming that the system<br\/>is consistent initially and each subsequent step maintains consistency. Self-stabilizing algorithms<br\/>cope with temporary faults in an elegant way. A self-stabilizing algorithm can be started in any<br\/>global state, which could be reached due to an arbitrary combination of failures, and always en-sures<br\/>that the task of the algorithm is achieved, assuming that the designer's assumptions hold for<br\/>sufficiently long intervals.<br\/>The goal of this research is to design self-stabilizing group communication services and apply<br\/>these services to mobile networks.<br\/>One part of the research will focus on the specification and design of initialized group services,<br\/>in which the establishment of a new group ensures that messages related to previous incarnations<br\/>are discarded. Various synchrony assumptions will be considered in order to identify the necessary<br\/>and sufficient conditions for the specified initialized group services. One approach to be investi-gated<br\/>is using transient fault detectors that will trigger the establishment of a new group whenever<br\/>inconsistency is detected. Impossibility results will be developed to indicate which system assump-tions<br\/>are necessary; lower bound results will be proved to shed light on the degree of optimality of<br\/>the solutions obtained. A second part of the research will study how different mobile applications<br\/>can take advantage of the self-stabilizing group communication services developed. A third part<br\/>of the research will explore the interactions between the group communication services and other,<br\/>lower level, mobile services.<br\/>Group communication services have been incorporated in several existing academic and indus-trial<br\/>distributed systems. However, none of them is self-stabilizing and none of them is specifi-cally<br\/>tailored for mobile environments. Self-stabilization and group communication are important<br\/>paradigms for the design of dynamic communication networks, and in particular wireless net-works.<br\/>There is no doubt that the new methods developed in this project will contribute to future<br\/>implementations of robust group communication systems.","title":"Self-Stabilizing Group Communication for Mobile Environments","awardID":"0098305","effectiveDate":"2001-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["438784"],"PO":["309350"]},"59264":{"abstract":"Our research goal is to improve quality level of CMOS ICs without performing the high-cost burn-in process. High-voltage screening schemes have been successfully developed and implemented to eliminate early-life failures due to oxide defects in digital CMOS circuits. However, the success is not extended to its analog counterparts due to their working conditions and circuit topological structures. This project proposes to develop efficient yet effective high-voltage stress test process for analog circuits. The research objective is to develop the framework of an automatic stress test system for analog\/mixed-signal circuits, where the system integrate three major components: stressability analysis, stressability design methodologies, and stress test process. The component of stressability design methodologies include a stress vector generation<br\/>process and a stressability enhancement process. The stress test process generates the test programs with the defined stress conditions for the circuits under test.<br\/> <br\/> The success of this development will enable the analog circuit to be stressed properly using high-voltage screening to eliminate early-life failures due to oxide defects and to enhance reliability and quality of CMOS<br\/>ICs without performing high-cost burn-in screening.","title":"Research on Reliability Enhancement of Mixed-Signal\/Analog CMOS Integrated Circuits","awardID":"0098053","effectiveDate":"2001-08-15","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":[152236,152237],"PO":["562984"]},"65380":{"abstract":"WORKSHOP: 2001 SIGART \/ AAAI Doctoral Consortium<br\/><br\/><br\/><br\/>This is a standard award to support the 6th SIGART \/ AAAI Doctoral Consortium, to be held as a workshop during the 17th International Joint Conference on Artificial Intelligence (IJCAI'01), August 4-10 in Seattle. The Doctoral Consortium will provide a unique opportunity for a group of PhD students to discuss and explore their research interests and career objectives together with a panel of established researchers. The event is similar in spirit to that funded by NSF last year, and has once again attracted a diverse group of student participants who reflect a wide range of topic areas and methodologies within artificial intelligence, and who have settled on their thesis directions but who still have significant research left to do. Selection was based on clarity and completeness of the submission packet, stage of research, advisor's letter, and other evidence of promise such as published papers or technical reports; a complete list of the 14 participants' names and affiliations may be found at http:\/\/www.acm.org\/sigart\/DCparticipants.html. Abstracts of the participants' presentations will be published in the issue of SIGART \"Intelligence\" that follows the consortium. The request for NSF support is higher this year than last, because Microsoft corporation chose not to cosponsor the event this time. Doctoral Consortium co-chairs are the PI and Marie desJardins, University of Maryland at Baltimore County; the organizing committee also included Janyce M. Wiebe, University of Pittsburgh; Mary P. Harper, Purdue University; Vibhu O. Mittal, Just Research and CMU; and Evangelos Milios, Dalhousie University. Panelists for the 2-day event will include: Robert St. Amant, North Carolina State University; Maria Gini, University of Minnesota; Craig Knoblock, ISI & USC; Gerhard Lakemeyer, Aachen University of Technology; Evangelos Milios, Dalhousie University; Shlomo Zilberstein, University of Massachusetts at Amherst; Stuart Shapiro, SUNY Buffalo; Foster Provost, NYU; and Rebecca Bruce, University of North Carolina at Asheville.","title":"2001 SIGART\/AAAI Doctoral Consortium to be held August 4-10, 2001,in Settle,Washington.","awardID":"0124241","effectiveDate":"2001-08-15","expirationDate":"2002-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["527853"],"PO":["564456"]},"67394":{"abstract":"Computer security is an especially pressing and national need because of the increasing dependence on information systems in most aspects of our lives including business, finance, transportation, medicine, education and national security to name a few. These information technology systems are vulnerable to a variety of events which can compromise the functioning and integrity of the system such as design problems, physical failures, malicious attacks, and scaling problems that can occur within individual components and systems and in the complex interaction among these systems. While there is ongoing research in security such as in computer systems, networks, storage, cryptography, and distributed systems, more needs to be done, especially to ensure availability, fault-tolerance, confidentiality, and the integrity of the information system from applications to underlying infrastructure. <br\/><br\/>A workshop on security, privacy, and trust was held in the fall of 2001 in Berkeley, CA. The purpose of the workshop was to bring together academic, industrial, and government experts in these areas to develop a research agenda and identify research areas that can make a major impact in the future. The workshop provided a report outlining a research agenda for trustworthiness and information security on the national scale.","title":"Research-Agenda-Setting Workshop on Security, Privacy, and Trust","awardID":"0133248","effectiveDate":"2001-08-01","expirationDate":"2002-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["229259"],"PO":["187585"]},"67086":{"abstract":"Proposal #131855<br\/>Altunbasak, Yucel<br\/>GA Tech Res. Corp - GIT<br\/><br\/>An effective way of providing error resilience for multimedia transmission in a communication system with a relatively small reduction in efficiency is multiple description coding (MDC), which assumes the existence of multiple independent channels between the transmitter and receiver, each of which can be temporarily down or can experience burst errors. With MDC several coded streams, called descriptions, are generated and transmitted over different channels. At the destination, if all of the streams are received error free, then the signal can be reconstructed at its highest level of fidelity. However, if only one or a few descriptions are received in a usable form, the receiver can still reconstruct an acceptable signal. All multiple description coding methods to date assume an on-off channel mode between the transmitter and the receiver; each link is either broken, in which case the transmitted symbols, or packets, are lost completely, or it functions properly, in which case the packets are received free of errors. This model is appropriate for Internet transmission, but it is not appropriate for wireless channels.<br\/><br\/>This study replaces the parallel in independent on-off channel model with a wireless channel model, such a Rayleigh fading model. Communication is performed using multiple transmit and received antennas over the channel. With these models the signal at any of the receive antennas is the superposition of the transmitted signals from each transmit antenna independently faded. Therefore, even if the descriptions at the receiver side are completely independent, the received signal at each antenna will include some information from each description. This research involves finding the best multiple description coding strategy for these channels, the theoretical limits of such a scheme, and the efficiency","title":"SPS: Multiple Description Coding with Correlating Transforms for Multiple Antenna Wireless Systems","awardID":"0131855","effectiveDate":"2001-08-15","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":[173930,"347935"],"PO":["564898"]},"57692":{"abstract":"People who are quadriplegic and nonverbal, for example from cerebral palsy or traumatic brain injury, often have great difficulties communicating their desires, thoughts, and needs. A video-based human-computer interface system will be developed to provide such people access to computers. The interface system will detect and track their limited voluntary motions to help them communicate with family, friends, and care providers. A set of cameras with pan, tilt, and zoom mechanisms will be pointed at the computer user. Computer vision algorithms will recognize the movements of a finger, foot, or facial feature in real time and interpret them as a communication of the computer user. Augmentative communication software will be developed that uses these interpretations to provide access to commercially available or custom-built application software. The system will be trained and tested by several non-speaking children with cerebral palsy and other serious disabilities. This research is expected to advance the state-of-the-art in the fields of computer vision and assistive technology with new video interpretation algorithms and innovative real-time system design. It will help people with severe disabilities gain access to a computer and thereby obtain a tool for communication, which in turn will enable them to actively acquire knowledge, to partake in increased recreational activities, to surf the internet, and to use computer-controlled technologies such as automated wheelchairs.","title":"CAREER: Video-Based Computer Interfaces for People with Severe Disabilities","awardID":"0093367","effectiveDate":"2001-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6846","name":"UNIVERSAL ACCESS"}}],"PIcoPI":["557296"],"PO":["565227"]},"61290":{"abstract":"The proposed research will investigate architectural approaches to optimize memory-hierarchy performance, focusing on the gap between the lowest level of on-chip cache and the off-chip DRAM. Prior work has shown that the combination of careful scheduling of prefetch requests on dedicated high-band width DRAM channels and careful placement of prefetch data in the cache can make very aggressive prefetching schemes practical. The proposed work builds on this framework in three directions: integration of multiple prefetch-generation sources, development of prefetching based on run-ahead threads, and integration of prefetching and replacement such that predictions of future access patterns can be applied in both domains. In each of the proposed areas, detailed designs will be developed, tested, and iteratively refined via simulation. As solutions in each area firm up, the results will be integrated into a unified model to work out interactions among the mechanisms. The overall objective of the research is to develop and analyze an integrated memory system that delivers maximum efficiency across a range of DRAM-constrained system workloads. The impact of these design techniques will be to increase the efficiency and performance of the high-performance systems used as database, web, and technical computing servers, increasing their responsiveness and capacity.","title":"Optimizing Integrated Memory-Hierarchy Designs","awardID":"0105503","effectiveDate":"2001-08-01","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["383899"],"PO":["180163"]},"63061":{"abstract":"ABSTRACT<br\/>Proposal #0113633<br\/>U of Arizona<br\/>Andrews, Gregory<br\/><br\/>A binary rewriting system is a software system that transforms a binary (executable) program into a different but functionally equivalent binary program. This project is developing binary rewriting techniques for flexible link-time and run-time code optimizations. The aim is to develop a unified binary rewriting infrastructure that is able to handle a wide variety of applications---sequential, parallel, distributed,<br\/>and mobile---hardware architectures---from RISC to CISC---and optimization criteria---including execution time, power consumption, and communication bandwidth.<br\/><br\/>Existing techniques for compile-time code optimization suffer from several limitations: they are unable to cross the dividing line between application code and libraries; they cannot take advantage of commonly encountered values along the critical path if such values cannot be guaranteed to be compile-time constants;<br\/>and they typically focus only on improving execution time. To overcome these limitations, this project is investigating the following topics: (1) low-level cost models that can be used for cost-benefit analyses of different optimization metrics; (2) efficient computation of value profiles and their use for<br\/>low-level code specialization; and (3) techniques that reduce the overheads associated with communication libraries used by parallel and mobile applications.","title":"ITR\/SY (CISE): Software Improvement Through Binary Rewriting","awardID":"0113633","effectiveDate":"2001-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["241298","550173"],"PO":["561889"]},"59322":{"abstract":"Approximation of NP-hard problems: Algorithms and Complexity<br\/>Sanjeev Arora<br\/>Princeton University<br\/><br\/>The broad goal of the project is a study of the approximation properties of<br\/>NP-hard problems. NP-hard problems are those that do not have any efficient<br\/>algorithms if the classes P and NP are different, as is widely-believed. They arise in a variety<br\/>of application areas in science and technology, including scheduling, VLSI<br\/>design, artificial intelligence, design of optimum networks, etc. <br\/>Since we do not expect to solve these problems optimally, there is a need to <br\/>design efficient approximation algorithms for them: algorithms that compute a <br\/>solution whose cost is within a small factor of the optimum. The PI has been<br\/>involved in designing approximation algorithms during the past decade. He has<br\/>also been part of an ongoing research program that shows that for many of these problems,<br\/>computing approximate solutions is no easier than computing optimum<br\/>solutions. (In other words, approximation is also NP-hard.) These<br\/>inapproximability results shed important light on the problems as well.<br\/><br\/>The project takes a two-pronged approach, combining a search for good<br\/>approximation algorithms with a search ---using the theory of probabilistically <br\/>checkable proofs (PCPs)--- for inapproximability results. The project focusses<br\/>on a collection of important algorithmic problems, including: learning mixtures<br\/>of distributions (a problem important in AI and data mining\/analysis),<br\/>learning bayes nets and markov random fields (useful in speech recognition,<br\/>machine vision, medical diagnoses systems etc.), lattice problems (useful in<br\/>cryptography and cryptanalysis), and graph coloring (a central problem in complexity theory).<br\/>Progress, especially algorithmic progress, on any of these problems has<br\/>important consequences.","title":"Approximation of NP-Hard Problems: Algorithms and Complexity","awardID":"0098180","effectiveDate":"2001-08-01","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["549429"],"PO":["543507"]},"61291":{"abstract":"Collaborative: Electro\/Magnetoencephalography Signal Processing Methods and Performance<br\/><br\/>Arye Nehorai<br\/>EECS Department<br\/>University of Illinois at Chicago<br\/><br\/>Detecting electric sources in the brain is important for both understanding its function and for clinical applications. Examples include mapping the brain activities and finding foci of epilepsy activities before surgical treatment. We are developing detection methods that find the sources through computer processing of measurements from arrays of sensors around the head. More specifically, we employ eletro\/Magnetoencephalography (E\/MEG) sensors that measure electric potentials on the scalp and induced magnetic field outside the head. We are developing several new methods of processing the E\/MEG signals, analyzing their performance and validating with real data their applicability, thus contributing to improvements in the use and performance of E\/MEG equipment and to increase the capabilities of neurological data processing tools.<br\/><br\/>We hope to solve some of the most currently relevant E\/MEG problems: (i) estimating and tracking paths of functional and neuronal connectivity, following the trajectories of cerebral sources, (ii) estimating concentrated and extended sources, in the presence of noise with unknown spatio-temporal covariance, (iii) simultaneously estimating source parameters and tissue conductivities, (iv) developing computationally efficient methods for realistically-shaped head models, which reduce the demands on segmentation algorithms, (v) estimating source parameters for evoked responses with inhomogeneous epochs. <br\/><br\/>We are also deriving performance measures for evaluating the newly proposed methods allowing comparison with existing systems and techniques; identifying those that are effective and helping in the optimum design of future systems. <br\/><br\/>Finally, we are using empirical data sets evaluate and validate methods. These data sets are being derived by the Dr. Jeffrey Lewine's group from Clinical and Cognitive Neurosciences studies where whole-head MEG and high-density EEG are recorded simultaneously. The Nehorai group is developing the processing methods and the two groups will collaborate on their evaluation and validation.","title":"Collaborative: Electro\/Magnetoencephalography Signal Processing Methods and Performance","awardID":"0105504","effectiveDate":"2001-08-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":[157608],"PO":["564898"]},"75283":{"abstract":"EIA- 0107686<br\/>Purdue University<br\/>Jose Fortes<br\/><br\/>Title: SGER: Exploratory Research on Transnational Digital Government<br\/><br\/>This grant will support a preliminary study of the uses of information technologies to support multilateral collaborations between two South American countries in the topic area of drug abuse and trafficking. Important topics to be surmounted include the many differences in infrastructure and processes related to data gathering, and the differing legal and security regimes in place. There will be an element of multi-lingualism to be explored also. The collaboration will begin with the support and approval of the Inter-American Drug Abuse Control Commission of the Organization of American States (OAS). The Commission has developed a process and procedures for multilateral government evaluation of various drug abuse parameters, which will serve as the context in which to evaluate collaboration technologies research. Researchers from several US universities and the OAS will participate.","title":"Digital Government SGER: Exploratory Research on Transnational Digital Government","awardID":"0222275","effectiveDate":"2001-08-01","expirationDate":"2003-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["540130"],"PO":["371077"]},"63073":{"abstract":"ABSTRACT<br\/>Proposal 0113681<br\/>Altunbasak, Yucel<br\/>GA Tech Res Corp - GIT<br\/><br\/>ITR\/SI(SPS)+AP+SY: High-Resolution High-Precision Video Reconstruction<br\/>with Applications to Visual Communications and Image Enhancement<br\/><br\/>The problem of resolution and bit-depth enhancement from compressed data will become increasingly important for applications in the emerging, error-prone, restricted bandwidth, wireless and heterogeneous computing environments. This research involves enhancing the spatial, temporal and bit-depth resolution of video signals by means of multi-frame and multi-channel processing. The system that is developed as part of this work is applicable to various areas of video communications and multi-media processing.<br\/><br\/>The number of bits assigned to represent the intensity or color information at points in an image is usually referred as the bit depth. When the bit depth is not sufficient, images suffer from ridge-like structures known as false contours. Bit-depth limitations become important when low-contrast details are required, as in medical imaging, aerial\/satellite photography, and high-quality scanning applications. Noting the similarity between the bit-depth and spatial resolution enhancement, this research examines a method for increasing the bit depth. Specifically, when a sequence of video frames is available, it is possible to achieve a higher bit depth and higher spatial resolution through a projections-onto-convex-sets (POCS) based data fusion method.<br\/><br\/>The multiple-frame video processing algorithms and their multimedia and communication applications form an integral part of the signal processing education agenda at Georgia Tech. Motivated and encouraged by the level of interest in multi-frame processing (by the students), the project constructs a web-centric demo of image resolution and precision enhancement for the benefit of the undergraduates as well as the research community.","title":"ITR\/SI(SPS)+AP+SY: High Resolution Video and Still Reconstruction with Applications to Visual Communications and Image Enhancement","awardID":"0113681","effectiveDate":"2001-08-15","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["347935"],"PO":["564898"]},"69662":{"abstract":"","title":"NER: Molecular Diode and Molecular Nonvolatile Memory","awardID":"0196553","effectiveDate":"2001-08-01","expirationDate":"2003-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":[180277],"PO":["187585"]},"59411":{"abstract":"The proposed work focuses on human-robot interaction, namely on the robot physically sensing the human hand. Specifically, the PIs will study the microstructure (texture) of the contact surfaces between a robot and a human hand, to infer the perceptual dimensionality of haptic texture sensing (perceptual model), and establish the mapping of relevant spaces. Methods for producing intuitive and efficient synthetic textures will be investigated. Rendering algorithms will be developed for synthesizing textures with desired perceptual qualities. The work is expected to contribute to various areas of haptic perception, texture studies, and multimodal rendering of information.","title":"Haptic Texture Perception and Rendering for Personal Robotics","awardID":"0098443","effectiveDate":"2001-08-01","expirationDate":"2005-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}}],"PIcoPI":["439280","542088","416761","499748","464438"],"PO":["335186"]},"59796":{"abstract":"The proposed work addresses development of novel methods for enhancing the ability of humans to perform complex and delicate manipulation tasks at a microscopic level. The proposed approach is based on a combination of off-line programming and on-line adaptation of task-specific human-computer manipulation idioms. The work builds upon this group's experience in the development of steady-hand robotic augmentation. Specific tasks from microsurgery and micro-assembly will be used for testing the ideas and evaluating the results obtained.","title":"Scale-Invariant Skill Augmentation for Cooperative Human-Machine Micromanipulation Systems","awardID":"0099770","effectiveDate":"2001-08-01","expirationDate":"2005-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["531055","553223","520895"],"PO":["335186"]},"69597":{"abstract":"","title":"ITR: Collaborative Research: Innovative Software for Large-Scale Nonlinear Optimization","awardID":"0196485","effectiveDate":"2001-08-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["517079"],"PO":["551992"]},"55088":{"abstract":"Cluster computing exploits the exponential growth in processing power, memory\/disk capacity, and network link speed of commodity hardware developed in the PC industry to achieve excellent price-performance, and is becoming a major platform for scientific computation, Web page and file servicing, as well as large-scale information analysis applications such as data mining and knowledge discovery. A distinct characteristic<br\/>shared by many emerging workloads on PC clusters is the requirement for intensive disk data accesses during program computation. The fundamental technique to address the performance problems associated with disk I\/O is to overlap disk access with program computation so that the I\/O delays are completely masked. Disk prefetching is one incarnation of this technique. In this project, we propose an automatic application-<br\/>specific file prefetching scheme that exploits specific applications' access patterns to the fullest extent and achieves close to perfect prefetching. The key idea is to apply the concept of decoupled architecture, which was originally proposed to bridge the gap between CPU and memory, to overlap computation with disk I\/O. Given an application program, the compiler automatically translates it into two threads, one corresponding<br\/>to the original program (computation thread) and the other including all statements in the original program that are related to disk I\/O (prefetch thread). At run time, the prefetch thread is scheduled to be suficiently ahead of the computation thread so that all the file access requests of the computation thread are satisfied in the file system cache, which is populated by the prefetch thread anticipatively. To validate the decoupled I\/O architecture, we will design, implement, and evaluate an active parallel disk I\/O subsystem called Platypus that embodies the application-specific file prefetching scheme and that is designed to be a modular building block for scalable PC cluster systems that aim at data-intensive computing. Platypus consists of a source-to-source translator to generate computation and prefetch threads from a SPMD parallel program<br\/>automatically, a run-time thread scheduler that coordinates the execution of prefetch threads on the I\/O nodes, and a cache manager that maximizes main memory utilization efficiency by optimally balancing the benefits of file caching and prefetching.","title":"A Decoupled I\/O Architecture for Data-Intensive Cluster Computing","awardID":"0083497","effectiveDate":"2001-08-15","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}}],"PIcoPI":["202714"],"PO":["551992"]},"59246":{"abstract":"This research involves media-on-demand systems. A media-on-demand system is a distributed network system where servers respond to demands by clients to receive various types of media such as video, audio, or large files. Such systems may be implemented within an organization like a hotel or a university, or over the Internet. Currently, Internet media-on-demand systems use unicast, meaning that each client receives its own transmission. This method does not scale up well for popular media where hundreds of thousands of requests might be received in a short time. Thus today, for example, hotels providing movies-on-demand typically make customers wait up to an hour for starting times. <br\/><br\/> In this research, the principal investigator studies algorithms for systems where multicast or broadcast is available and buffer storage is adequate. Tradeoffs among server bandwidth, startup delay, client receive bandwidth and client buffer size are studied. In particular, new algorithms and mathematical analyses are developed to explore these tradeoffs. The main goal of the research is to understand how to achieve the highest Quality of Service with as few resources as possible.","title":"Algorithms for Media-on-Demand Systems","awardID":"0098012","effectiveDate":"2001-08-01","expirationDate":"2005-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["485574"],"PO":["543507"]},"59026":{"abstract":"Proposal #0097348<br\/>Traub, Joseph F.<br\/>Columbia University<br\/><br\/>There is huge interest in solving high dimensional problems. Many applications involve functions of hundreds, thousands or even an infinite number of variables. Examples occur in physics, chemistry,<br\/>mathematical finance, and economics. <br\/><br\/>It is the rare high dimensional problem that can be solved analytically. Generally one must settle for an approximate numerical solution to within an error e. The computational complexity is the minimal computational resource need to solve a problem to within e. Time is the resource considered<br\/>and is measured by the number of information operations, arithmetic operations and comparisons. An example of an information operation is the computation of a function value.<br\/><br\/>If a worst case deterministic assurance of an e-approximation is desired, then often the computational complexity depends exponentially on the number of variables d; the problem suffers the \"curse of<br\/>dimensionality\". Examples include integration, approximation, globaloptimization, integral and partial differential equations over typical isotropic classical spaces of r-times continuously differentiable<br\/>functions. If the computational complexity is exponential in either 1\/e or d the problem is said to be intractable. If the complexity is polynomial in 1\/e and d, it is tractable. If, in addition, the minimal number of information operations, arithmetic operations and comparisons is independent of d the problem is strongly tractable. <br\/><br\/>Intractability may sometimes be broken by settling for a stochastic assurance of error; examples are randomization (for instance, Monte Carlo) or the average case. A second way in which intractability might<br\/>be broken is additional domain knowledge about the problem. An example of the domain knowledge is that the integrands in certain mathematical finance problems are non-isotropic. Additional domain knowledge can sometimes be used to make the problem strongly tractable even in the worst case deterministic setting!<br\/><br\/>Continuation of research on achieving tractability and strong tractability is proposed. In particular, one proposed area of research is under what conditions is a double-win achievable for high dimensional integration:<br\/> * convergence faster than Monte Carlo,<br\/> * with a worst case deterministic assurance.<br\/>The theoretical results will be used to improve the FinDer software system.<br\/><br\/> More generally, research is proposed on the following topics:<br\/> * Theory and Computer Experiments for Mathematical Finance,<br\/> * Tractability of Quasi-Monte Carlo and Monte Carlo Algorithms,<br\/> * Variable Smoothness, <br\/> * Generalized Tractability.","title":"Theory and Applications of Information-Based Complexity","awardID":"0097348","effectiveDate":"2001-08-15","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["516897","516898"],"PO":["321058"]},"59158":{"abstract":"The objective of the proposed work is to investigate and build a system for measuring finger postures and forces. The system will become an important milestone on the way to producing more effective haptic devices. In the existing systems the natural haptic sense of the human finger is lost or obstructed - this problem will be overcome in the current work. Fundamental properties of finger hemodynamics and tissue mechanics will be investigated, as well as design and signal properties issues. Nail sensor design will be optimized with respect to the distribution of photo diodes and the location and wavelength of LEDs across the nail surface. A nonlinear filter for motion artifact rejection will be designed.","title":"Multi-Functional Fingernail Sensors Using Photoplethysmograph","awardID":"0097700","effectiveDate":"2001-08-15","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["351676"],"PO":["234178"]},"61292":{"abstract":"RUI: Oriented Matroids and Rigidity Theory Techniques for Pseudo<br\/>Triangulations, Visibility Graphs and Other Structures in Computational<br\/>Geometry<br\/><br\/>PI: Ileana Streinu<br\/><br\/>Abstract:<br\/><br\/>This research is motivated by fundamental questions in Robotics and<br\/>Computer Graphics, such as planning the motion of a robot arm, detecting<br\/>collisions and computing visibilities. It seeks efficient algorithmic<br\/>solutions by investigating the underlying computational structures with<br\/>novel mathematical tools and it has a substantial potential to lead to<br\/>applications in understanding the nature of the protein folding process in<br\/>biology.<br\/><br\/>The investigator is undertaking a systematic plan of research aimed at<br\/>furthering the understanding of how the underlying oriented matroid<br\/>structure of points and lines affects properties of a variety of partially<br\/>embedded combinatorial structures such as pseudo triangulations and<br\/>visibility graphs. The focus is on combinatorial (enumeration, generation,<br\/>characterization) and algorithmic questions, the underlying framework is<br\/>geometric (dimensions 2 and 3), and the techniques involved come from<br\/>matroid and oriented matroid theory, rigidity theory, combinatorial<br\/>topology, computational algebraic geometry and graph embeddings.","title":"RUI: Oriented Matroids and Rigidity Theory Techniques for Pseudo Triangulations, Visibility Graphs and Other Structures in Computational Geometry","awardID":"0105507","effectiveDate":"2001-08-01","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["550373"],"PO":["543507"]},"65472":{"abstract":"The goal of this project is to investigate the retrieval and reuse of information in organizations. Research has shown that many organizations waste valuable information because these processes are complicated and difficult. Detailed systematic insights are necessary to understand how organizations can more effectively reuse information and engage in productive \"knowledge management\" practices. Based on their previous work, the PIs will examine key theoretical issues through micro-level distributed cognition analyses in two technical support organizations to better understand these processes and organizational practices. Such a project is necessary to move beyond the hype often associated with the discourse about knowledge management in the scholarly and management literatures.","title":"Collaborative Research: Field Studies of Organizational Memory and Information Reuse","awardID":"0124878","effectiveDate":"2001-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["430298",169453],"PO":["564456"]},"63096":{"abstract":"This project envisions an environment where a scientist can easily combine existing software components to create an efficient, highly parallel scientific simulation. To accomplish this, it will develop new software component technologies for high performance computing environments, including a high performance component framework and a new parallel Interface Definition Language (IDL). It will use those tools to investigate mechanisms for integrating high performance (often data parallel) computing with distributed software components. Success of this project will be measured by providing acceptable performance on at least two scientific applications using the new component framework. The applications chosen for the first test of this work (whose development has already started under separate funding) are bioelectric source localization and a combustion simulation of a high-energy material placed in a pool fire. Both applications will stress the capabilities and efficiencies of the proposed work.<br\/><br\/>As software systems, including high performance parallel programs, become more complex, the use of component architectures can help manage many aspects of this complexity. However, such mechanisms are not prevalent in parallel scientific computing applications due to limitations of existing component systems. These include inefficient handling of large amounts of data, inability to express parallelism in the data or within a component, and difficulty matching parallelism in one component with parallelism in another. The new component architecture research will help overcome many of these limitations. It will, among other features, provide efficient mapping of components to processors, provide efficient communication between parallel components, facilitate migration of components (including checkpoint\/restart capabilities), and facilitate redistribution of components for dynamic load balancing.","title":"ITR\/SY: Data Parallel Component Software Components","awardID":"0113829","effectiveDate":"2001-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["342952"],"PO":["565272"]},"57574":{"abstract":"This project has two main objectives: 1) to understand the current communication and coordination activities in the Hospital Operating Room (OR), focusing on the surgical team as the center of activity, and 2) to develop and test a theory of situated learning of decision skills. The first objective will be met through observations of surgeries and interviewing key personnel. We will collect video data, audio data, and code the communication activities between personnel in the room using verbal protocol analysis. We will also conduct a series of structured interviews with surgeons, nurses, anesthesiologists and OR staff to specifically ask these personnel about communication and coordination practices. The second objective will be met by developing a part-task simulation of the surgical environment using computer-based training, and measuring the ability to teach key situation assessment skills for various surgical cases with this simulation. This research will impact our understanding of surgical decision making, and provide a tangible means to train surgical decision making in a safe, simulated environment. The impact of this research will be to reduce medical error, improve training practices, and improve team communication and coordination in the OR.","title":"CAREER: Cognitive Engineering of Surgical Work Processes","awardID":"0092985","effectiveDate":"2001-08-01","expirationDate":"2007-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["461728"],"PO":["564456"]},"57476":{"abstract":"In this project, trading agents---software programs that participate in markets---will be designed to ascertain the rules of auctions of interest and dynamically construct a decision representation. A strategy generation engine is the component of a flexible trading agent that converts the inputs (user preferences, auction rules, and models of other agents) into a decisionable format. Game theory and Markov Decision Processes are techniques that will be applied to making decisions in these markets. Previous research in the area of trading agents assumes that the market configuration is predetermined. However, the Internet marketplace is far more fragmented; a particular product will often be offered for sale in a variety of auction formats. Thus, flexible trading agents are necessary. The software programs will be made publicly available as Web-based learning materials for e-commerce courses. These materials will enable instructors in e-commerce and artificial intelligence courses to use trading agent games for class projects.","title":"CAREER: Automatic Synthesis of Bidding Strategies for Trading Agents","awardID":"0092591","effectiveDate":"2001-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":[147875],"PO":["564456"]},"59544":{"abstract":"The objective of the proposed work is to investigate the vision task of coherent surface identification in a single image, and to use acquired knowledge for improvement of existing algorithms. The work is a natural extension of the PI's recent work on coherent surface detection, while also adding new aspects related to the field of object recognition. The envisioned system will be able to autonomously learn object recognition models from a set of images, and then identify those objects in a complex environment. The work has strong connection to vision-based robotics as applied to unknown environments.","title":"RUI: Coherent Surface Identification and Object Recognition","awardID":"0098802","effectiveDate":"2001-08-15","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["439956"],"PO":["317663"]},"59357":{"abstract":"ABSTRACT<br\/>Proposal #0098284<br\/>Saunders, B. David<br\/>University of Delaware<br\/><br\/>This is a program of research in the area of exact solution of systems of linear equations and related problems. There will be an emphasis on Diophantine problems, wherein the input data (coefficients) are integers and the solutions sought must also have integer coefficients. There will also be an emphasis on parametric linear systems, wherein the input data contain symbolic parameters and the solutions must be expressed in terms of these parameters, including all special cases (ranges of values of the parameters for which the solutions have form different from the general case). New efficient algorithms are sought and high performance software is to be developed based on both new and previously described methods.<br\/><br\/>The work will be largely carried out in the context of the LINBOX collaboration. LINBOX is a group of twelve researchers in three countries (USA, France, Canada) who are conducting research in the design of efficient algorithms for linear algebra, in their implementation in a software library, and in how to interface the library to widely-used scientific computing software. such as Maple and Mathematica.<br\/><br\/>There are two basic approaches to sparse matrix problems, iterative and direct. Both approaches have been significantly developed by the numeric linear algebra community. Iterative methods involve finding recurrence relations in a series of vectors resulting from matrix-vector products. In LINBOX these have been called \"black box\" methods, and the adaptation of such methods to symbolic problems has been the emphasis to date. There has been substantial theoretical work in the past two decades in this area. The emphasis of LINBOX is to find and to demonstrate in software the variants and extensions and improvements to these methods which will work in practice. The here proposed research will continue in this direction but will also work to develop the direct methods for solution of sparse symbolic linear systems, again basing on prior work in numerical linear algebra.","title":"Exact Computation in Sparse Linear Algebra","awardID":"0098284","effectiveDate":"2001-08-15","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["451563"],"PO":["321058"]},"59599":{"abstract":"This is the first workshop of a planned workshop series. Its objective is to stimulate and focus interest in the emerging area of data management for context-aware, mobile computing environments. As wireless bandwidth becomes more widely available, the communication infrastructure will be heavily wireless oriented. It will provide adaptive connectivity among immobile systems and portable devices such as cell phones, laptops, and other such future devices. Under this platform the computing will begin to migrate away from the desktop toward these devices consequently it will become necessary to managed data more carefully. Industry and academia recognized wireless devices as an important area for development, however, the problems of data management have not been addressed in a coordinated manner. This workshop aims to fill this gap by providing a forum for leading researchers from both industry and academia in the areas of infomation management, wireless networking, communications and signal processing systems to set the research agenda for the future. This workshop will lead to a more cohesive research community and will result in a quicker development and adoption of technologies for this new area. It will facilitate the development of new standards and will provide the synergy necessary for the US technical community to become a dominant player in this field. The results of the workshop will be made available online through web site (http:\/\/www.cstp.umkc.edu\/nsfmobile\/wshop.html\/ or http:\/\/www.cs.brown.edu\/nsfmobile\/wshop.html\/) and will be reported in periodicals (e.g., ACM and IEEE) and relevant conferences, workshops or meetings.","title":"Workshop Series on Mobile Computing","awardID":"0099128","effectiveDate":"2001-08-15","expirationDate":"2002-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0504","name":"Division of MICROELECTRONIC INFOR PROCESS","abbr":"MIP"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["562301","483625"],"PO":["563751"]},"59269":{"abstract":"This research addresses several problems in three areas of computational <br\/>complexity. The overall objective in each case is to understand the limits <br\/>of the capabilities of computers and the algorithms that run on them. <br\/>The first area of research concerns tradeoffs between the processing time and <br\/>storage requirements of computations: <br\/>When can one solve problems using algorithms that are both fast and <br\/>use small amounts of storage and when is one limited to trading off these<br\/>two resources, reducing storage requirements only at the cost of <br\/>additional running time?<br\/>The second area of research concerns the increased efficiencies in data <br\/>structures that are possible by taking advantage of the wide range of <br\/>instructions in modern processors that operate on entire computer words at <br\/>once.<br\/>The third area of research involves the analysis of algorithms to solve <br\/>NP-hard search problems.<br\/>When many such algorithms search but do not find a solution to a problem,<br\/>they implicitly provide proofs that no such solution exists.<br\/>In this portion of the research, the investigators analyze the form of these <br\/>implicit proofs to show the limits of the efficiencies of these search <br\/>algorithms.<br\/><br\/>More specifically, the research in time-space tradeoffs builds on the <br\/>investigators' previous work on time-space tradeoff lower bounds and is aimed <br\/>at extending these results to other natural problems such as graph <br\/>connectivity and improving the complexity limits shown by current lower bound <br\/>techniques.<br\/>The research in data structures works in the model of random-access machines <br\/>with arbitrary unit-cost operations on word-size quantities.<br\/>The goal of this data structure research is to understand the limits of the<br\/>algorithmic improvements possible in this model, particularly for <br\/>nearest-neighbor queries, priority queues, sorting, and garbage collection.<br\/>The research on the complexity of NP-search algorithms focuses on<br\/>the proof complexity of co-NP properties of random structures.<br\/>The goal is to show that for randomly-chosen inputs, natural proof systems <br\/>such as resolution almost always require exponential-size proofs of membership <br\/>in the co-NP sets corresponding to the duals of natural NP problems.<br\/>A consequence of this would be proofs that large classes of algorithms for <br\/>solving the NP problems require exponential time on large numbers of inputs.","title":"Lower Bounds for Time-space Tradeoffs, Data Structures, and Proof Complexity","awardID":"0098066","effectiveDate":"2001-08-01","expirationDate":"2005-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["517581"],"PO":["543507"]},"63020":{"abstract":"ABSTRACT<br\/>Proposal #0113418<br\/>U of Cal Davis<br\/>Farrens, Matthew<br\/><br\/>Microprocessors now rival supercomputers in raw processing power, thanks to increases in transistor densities and architectural advances such as the exploitation of parallelism. However, the bandwidth and latency of memory systems is so limited that increasing performance in the microprocessor often leads to little overall system improvement.<br\/><br\/>At the same time that this is occurring, software costs are burgeoning. This research explores using some of the increasing silicon real estate to provide extra functionality. The approach is to dedicate a portion of these new transistors to provide programmable monitoring hardware to enhance software development, make debugging more efficient, increase reliability and provide run-time security. Additional applications may be found in monitoring run-time guarantees and invariants for embedded systems.<br\/><br\/>Taking a specific example, this approach can address pointer-related defects occurring in software which render systems unreliable and vulnerable to hackers. A simple, auxiliary co-processor monitors address references from a compute processor via a loose coupling (e.g. via the L1 cache coherence bus). This loose coupling reduces design complexity and avoids the need for any core CPU redesign and allows this approach to be readily added to existing designs. Furthermore, the approach is complementary to static compiler analysis techniques and the research extends conventional analysis to exploit efficient run-time monitoring capabilities.","title":"Improving System Functionality using Monitoring Processors","awardID":"0113418","effectiveDate":"2001-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["486140","485983","562714"],"PO":["561889"]},"64142":{"abstract":"0118022<br\/>Das <br\/><br\/>Description: This award supports US-Nepal cooperative research entitled \"Theoretical and Experimental Investigations on Some Current Electronic Structure Related Topics in Condensed Matter Systems and Ozone-UV Interaction.\" This is an initiating activity among the Theoretical Electronic Structure and Properties Research Group, University at Albany, State University of New York, the Condensed Matter and Atmospheric Physics Research Group, Tribhuvan University (TU), and the Condensed Matter and Materials Physics Experimental Research Group, University of Central Florida (UCF). This project covers five diverse areas of research that include glasses, quantum computation dealing with solar radiation and upper atmosphere chemistry, studies of hyperfine interactions of electron distributions in materials, ozone depletion and environmental impacts in Nepal, and a solar cell fabrication capability at TU. <br\/><br\/>Scope: This award launches joint activities between two US universities and the Tribhuvan University, Nepal. Topics were selected according to common interests at these institutions between theory and experimental groups in a way that complement their expertise and enhance the potential for future interactions among the three groups. Faculty and students at TU will gain expertise in experimental aspects of Moessbauer spectroscopy and characterization of electronic structures of materials. In the long-term, research on solar cell thin films and nanocrystalline particles corresponds to Nepalese national development interests. This is the first cooperative research project in physics supported under the US-Nepal Cooperative Science Program. It is jointly supported by the Division of International Programs and the Division of Materials Research, Condensed Matter Physics Program.","title":"US-Nepal Cooperative Research: Theoretical and Experimental Investigations on Some Current Electronic Structure Related Topics in Condensed Matter Systems and Ozone-UV Interaction","awardID":"0118022","effectiveDate":"2001-08-15","expirationDate":"2006-01-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"5976","name":"AFRICA, NEAR EAST, & SO ASIA"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1710","name":"CONDENSED MATTER PHYSICS"}}],"PIcoPI":[165339],"PO":["558017"]},"69664":{"abstract":"","title":"ITW:Mediating Careers: The Role of Labor Market Intermediaries in Facilitating the Entry, Retention, and Advancement of Women and Minorities in the Information Technology Workforce","awardID":"0196555","effectiveDate":"2001-08-27","expirationDate":"2004-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["392589",180282],"PO":["289456"]},"59336":{"abstract":"Complex ULSI designs will be plagued by a myriad of interconnects problems that could require many design iterations to meet timing, power, area, and noise specifications. To cope with this interconnect dilemma, the current transistor-centric VLSI design flow must evolve into an interconnect-centric design flow; however, for this design flow to develop it must accurately predict the impact of interconnects on the performance of logic megacells at the earliest stages of design. This research effort is focused on developing an accurate prediction of the length of each net in a given netlist during logic design. The novel aspect of this work is that a stochastic wire length distribution model, which has been developed in part by the principal investigator, is being used to aid in this prediction. In addition, prediction methodologies that give the designer the ability to choose from a set of possible wiring configurations is emphasized. An integral part of this prediction methodology is the incorporation of the wire length predictions into length prediction driven placement algorithms. The significance of this proposed research is that highly accurate wire length predictions could substantially enhance the accuracy of early timing analysis and give the designer greater flexibility in finding solutions to overcome impending interconnect limits.","title":"Interconnect Length Prediction and Length Prediction Driven Placement","awardID":"0098227","effectiveDate":"2001-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["539892"],"PO":["562984"]},"59259":{"abstract":"Proposal #0098040<br\/>Princeton University<br\/>Vanderbei, Robert J.<br\/><br\/>Optimization is the process of determining values of certain controllable parameters so as to achieve the best, i.e. smallest or largest, value of an objective function within a specified domain of feasible parameter settings. The demand for high-performance optimization algorithms and software is increasing rapidly as the power of the current technology to solve difficult real-world problems is becoming more widely recognized.<br\/>Much of the success of modern optimization techiques stems from the recent development of so-called interior-point methods. These methods were first developed for linear optimization problems but are now actively being extended to nonlinear optimization problems.<br\/><br\/>This research involves the development of new interior-point algorithms and software for large-scale nonlinear constrained optimization. Specific goals include: (1) fundamental enhancements to the current state-of-the-art, such as the replacement of the merit-function for step-length control with a<br\/>filter-based method and the development of better techniques to detect unbounded and infeasible problems; (2) extension of the basic algorithm to new problem classes, such as second-order cone programming and semidefinite programming, that don't quite fit the basic paradigm of nonlinear constrained optimization; (3) further extension beyond the realm of optimization to nonlinear complementarity problems, which arise in many engineering problems; and finally (4) development of a large repository of optimization models, which serves both to illustrate the power of modern optimization technology and also to provide a test bed for future algorithm development.","title":"Interior-Point Methods for Nonlinear Optimization and Complementarity","awardID":"0098040","effectiveDate":"2001-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":[152226],"PO":["321058"]},"61294":{"abstract":"Synchronization insures correctness of parallel execution by enforcing true data dependencies and timing constraints. In a parallel programming environment based on the shared-memory programming model, synchronization is provided either through explicit user-level coarse-grain synchronization primitives (such as locks and barriers) or implicitly synchronized data structures such as lock-able L-structures and write-once I-structures.<br\/><br\/>In this project we propose a new efficient way to support fine grained synchronization mechanisms<br\/>on multiprocessors. We propose to design a full\/empty tagged memory hierarchy with aggressive hardware support for fine grained synchronization that is embedded in the cache coherency mechanism of an SMP or a NUMA multiprocessor, or a single-chip multiprocessor. We propose to handle synchronization faults in a similar way as cache misses in a lockup-free cache. We believe that handling synchronization and coherence together can provide a more efficient execution, reducing the occupancy in the memory controllers and the network bandwidth consumed by protocol messages. The performance benefits are primarily the result of allowing a dataflow style of computation in programming models, and maximizing the exposed parallelism by minimizing the possibility of false dependencies caused by coarse grained synchronization.","title":"Efficient Fine Grained Synchronization Support Using Full\/Empty Tagged Shared Memory and Cache Coherency","awardID":"0105516","effectiveDate":"2001-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["408968"],"PO":["325495"]},"76100":{"abstract":"EIA-9975275<br\/>Fortes, Jose A.<br\/>Eigenmann, Rudolf <br\/>Purdue Research Foundation<br\/><br\/>CADRE: NETwork-computer for Computer Architecture Research and Education (NETCARE)<br\/><br\/>This award provides support for NETCARE (NETwork-computer for Computer Architecture Research and Education), an infrastructure supporting a repository of computer architecture tools, to be managed by a consortium of three universities: Purdue University, University of Wisconsin and Northwestern University. NETCARE will use the PUNCH network computing software developed at Purdue University, to provide the user interface, manage the repository of architecture tools, and perform high-level scheduling and dedicated resource access control. Condor, a resource management system that uses idle CPU cycles of networked workstations, developed at the University of Wisconsin, will be used to perform low-level scheduling and management of resources. NETCARE will be universally accessible through conventional World Wide Web browsers and will provide software tools and computing resources for the computer architecture research and education community.","title":"CADRE: NETwork-Computer for Computer Architecture Research and Education (NETCARE)","awardID":"0226851","effectiveDate":"2001-08-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4725","name":"EXPERIMENTAL SYSTEMS\/CADRE"}}],"PIcoPI":["540130"],"PO":["297837"]},"64385":{"abstract":"EIA- 0119469<br\/>Ophir Frieder<br\/>Illinois Institute of Technology<br\/><br\/>Educational Innovation: Enhancing the CS Undergraduate Curriculum to Include Data Mining and Information Retrieval<br\/><br\/>This project involves the development (and introduction into the undergraduate computer science curriculum) of two new courses: Data Mining and Information Retrieval. In this sequence, students build systems that implement key data mining and information retrieval algorithms and learn how to apply these algorithms to solve real-world problems. At the end of this sequence, students understand and use the fundamental algorithms and existing state-of-the-art in web search engines, intranets, data mining, and customer relationship management. Two significant group projects provide students with experience as participants of a software development team. These projects enable larger implementation achievements that further the understanding of algorithms, implementation trade-offs and software project management. In addition, such a group project is a critical experience that future employers and graduate schools look for.","title":"EI: Enhancing the CS Undergraduate Curriculum to include data mining and information retrieval","awardID":"0119469","effectiveDate":"2001-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T471","name":"CIA-KDD WORKING GROUP"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1359","name":"RES EXP FOR TEACHERS(RET)-SITE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}}],"PIcoPI":["259346","517717","251275","510840"],"PO":["551712"]},"58973":{"abstract":"IIS-0097218<br\/>Paul E. Utgoff<br\/>University of Massachusetts at Amherst<br\/>$119,407 - 12 mos<br\/><br\/><br\/><br\/>Feature Construction for Large Discrete Domains<br\/><br\/><br\/><br\/><br\/>This is the first year funding of a three year continuing award. This project focuses on the problem of learning the representations on which more widely studied data fitting programs depend. Thus, instead of providing a representation and watching the fitting algorithm run its course, the goal is to attack the more fundamental problem of learning the representation itself. The objective is to produce an agent that can identify all of the useful features of a large discrete domain. Artificial neural networks of the typical one or two layers of hidden units cannot scale to large problems of the kind that the PI wants to solve (learning in large discrete domains), because this kind of `few-layered learning' suffers not only from local minima and shallow gradients, but more fundamentally from inappropriate bases and the inherent need for exponentially many features (hidden units) imposed by the constraint of so few layers of features. The PI will pursue scalable methods that he characterizes as `many-layered learning', which will move the state-of-the-art past the current nonscalable practices of feature construction, which in turn will affect much of the work in function approximation, including the current nonscalable use of few-layered artificial neural networks. The project will produce a variety of algorithms for many-layered learning. Among them will be one for building a nested feature representation based on problem-solving experience. A second will demonstrate that knowledge layering and decomposition follow naturally from using only simple learning mechanisms to learn the next most easily learned features based on the representation learned thus far. The larger implications for many-layered learning on intelligence will be investigated.","title":"Feature Construction for Large Discrete Domains","awardID":"0097218","effectiveDate":"2001-08-01","expirationDate":"2005-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["225743"],"PO":["355797"]},"57653":{"abstract":"Finite-Field Wavelets for Cryptography and Error-Control Coding<br\/>Faramarz Fekri<br\/> <br\/>Today's success is increasingly dependent on being able to access, share and use information whenever and wherever needed. The widespread availability and transmission of such information demands new approaches to cryptography and error-control coding. Notions of complexity, scalability, and adaptability are becoming critical challenges for error-control coding and data security. This research explores wavelet transform over finite fields and their applications to convolutional coding and data security. It investigates a rich set of signal processing techniques that can be exploited for the construction of new coding and security schemes. The research is not evolutionary. It defines a new research area on the boundary of three very large research fields; namely digital signal processing, communications, and computer science. It impacts 1. basic science, 2. technology and products, and 3. education and learning. <br\/>This research explores the intersection of finite-field wavelet transforms, error-control coding and data encryption. The primary focus of this research is to advance the study of wavelets and filter banks over finite fields and their applications to error -control coding and data security. It develops the theory of wavelet transforms over finite fields which provides a general wavelet decomposition of sequences defined over finite fields. This is an approach that has a rich history in signal processing for the representation of real-valued signals, but it has been lacking in the finite-field case. In particular, the research explores multiresolution wavelets and overcomplete filter banks over finite fields. Along with wavelet theory on finite fields, this work investigates the first application of the finite-field wavelet theory to new types of time varying convolutional codes that have unusual trellis structures with reduced complexity. Using multiresolution decomposition of wavelets, the researchers intend to construct rate-compatible wavelet convolutional codes for handheld devices to support flexible data rates (voice, fax, video,...). To address security issues with handheld devices, this research exploits the finite-field wavelet as a unifying framework for effective joint design of data encryption and error control coding. In this framework, the public and secret keys of the user determine the wavelet system and the security is tied to the length of the wavelet basis function. The goal of the research is centered around the development of innovative coding\/security protocols for handheld devices.","title":"CAREER: Finite-Field Wavelets for Cryptography and Error Control Coding","awardID":"0093229","effectiveDate":"2001-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["485126"],"PO":["564898"]},"69522":{"abstract":"","title":"Collaborative Research: Protocols for Mobile Ad Hoc Networks","awardID":"0196410","effectiveDate":"2001-08-01","expirationDate":"2003-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["553537"],"PO":["234222"]},"64650":{"abstract":"The Semantic Web is a vision: the idea of having data on the Web defined and linked in a way that it can be used by computers not just for display purposes, but for automation, integration and reuse of data across various applications. The goal of the International Semantic Web Working Symposium (SWWS) (July 30-August 1, Stanford, California) is to bring together researchers and practitioners (1) to present the state-of-the-art in the development of the Semantic Web; (2) to examine the research issues that relate to the different components of what constitutes the Semantic Web technology; (3) to cross-fertilize ideas on the development of Semantic Web information systems among different domains. SWWS is both the first workshop on this topic in North America and the first one sponsored or in corporation with three major funding agencies from the U.S. and from Europe, namely NSF, DARPA, and the European Commission. It also has strong ties with the W3C Semantic Web Activity. The expected outcome of the workshop is a better common knowledge and synergy for those wishing to develop new exciting basic technology and applications for the Semantic Web. It should guide the future cooperation for enabling future standards to be adopted worldwide. A written report will be produced following the workshop, summarizing the main conclusions and research directions to follow, which will be published at http:\/\/www.semanticweb.org\/SWWS\/. We expect that this workshop and the follow-up report can serve as guidance for future international collaboration in research projects on the Semantic Web topic.","title":"International Semantic Web Working Symposium","awardID":"0120811","effectiveDate":"2001-08-15","expirationDate":"2002-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["554456"],"PO":["563751"]},"64551":{"abstract":"Future mobile communications technologies are expected to provide a wide variety of services, high-quality audio, high-definition video and quick response control data, through wide-band access channels. Future systems will acquire multimedia capability and will facilitate the use of high-speed wireless local area networks (W-LAN) and Home Broadcasting networks in place of traditional architectures. These systems will be designed to address user demands for broadband wireless communications and will drive the development of new microwave and mm-wave devices and circuits. Possible in-home application scenarios for both analog and digital transmission will require very compact, low-cost and high efficiency receive\/transmit devices that can provide asymmetric data transmission from a home server to various appliances for quality<br\/>operation and control. In response to the above technology needs, this program proposes to develop a novel RF front-end receiver architecture that consumes very little power, is highly compact, very low-cost and high-performance.<br\/><br\/>The proposed architecture is based on a CMOS on SOI implementation for both the RF and digital parts of the circuit and allows for an intimate integration of the circuit with the RF filters and antenna structure. The new receiver architecture will be based on the use of metamaterial substrates for the development of highly integrated filter banks, will rely on vertical integration for the development of highly compact three-dimensional wireless front ends, will have a novel antenna structure intimately integrated with the highly selective multi-frequency substrate and have a novel mixed signal digital IF circuitry. The design of the receiver will be accomplished through a holistic mixed circuit approach that accurately takes into account high frequency effects including dispersion, radiation and electromagnetic coupling. The modeling and simulation problem encountered in the implementation of the above vision is typical to mixed-signal RFICs. The proposed technical approach represents a solution to the broader problem and has the potential to alleviate the design bottleneck at the analog\/RF\/ package interface.<br\/><br\/>The University of Michigan will use its own fabrication facilities together with the IBM Blue Logic Cu-11 CMOS on SOI 0.11m facilities to develop the proposed receiver. North Carolina State University will provide modeling and simulations necessary for the design of the receiver. A prototype 4-channel 5-10GHz receiver will be simulated, designed, fabricated, packaged and tested during the course of this work. In addition, 16-channel very high-Q electromagnetic bandgap filter bank will be designed, fabricated and tested. Moreover, topics such as manufacturing tolerance, temperature effects, filter tuning and frequency scaling will be studied.<br\/><br\/>The proposed work will be performed in close collaboration with IBM High performance logic development and RF Technology development. Graduate and undergraduate student research investigators in both Universities will execute the research tasks. A number of these students may spend part of their summer at IBM on internships to facilitate the collaboration and take the opportunity to interact with IBM scientists. Furthermore, the research outcomes of this effort, in terms of the design of the mixed-signal circuit architectures, will become the basis of a new senior\/graduate-level course in high frequency circuits. Special effort will be placed in attracting<br\/>underrepresented students through the University of Michigan UROP (Undergraduate Research Opportunities) and Maria Sara Parker Programs specifically designed to provide research experiences to undergraduate and graduate female and minority students. The results of these efforts will be disseminated broadly via publications in scientific journal and\/or presentations in technical conferences and the development of an interactive web site.","title":"Research for Mixed Signal Electronic Technologies: A Joint Initiative Between NSF and SRC: Novel RF Front-Ends For Future Mobile Communication Systems","awardID":"0120319","effectiveDate":"2001-08-01","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["513776","531740"],"PO":["562984"]},"61284":{"abstract":"The proposed research has as final objective advancing knowledge on disk arrays performance, as well as developing new disk array organizations and algorithms for improved performance and reliability. The following specific areas will be investigated. Mirored disks (RAID1) double the disk access bandwidth for reads, but even higher performance is possible through scheduling. A combination of single disk scheduling methods adapted to mirrored disks and methods utilizing non-volatile storage to defer writes will be investigated. RAID6 disk arrays tolerating two disk failures utilize two parity disks or one parity disk and one utilizing the Reed-Solomon code. Two data layouts for the former case have been proposed. The performance of these configurations will be compared with each other, as well as RAID5, while the system is operating in normal, degraded, and rebuild modes. Active disks process data locally to disk, responding with final or filtrated data rather than raw data. Techniques to process more sophisticated queries than those considered so far will be investigated. Prioritized processing of disk requests allows background applications to make progress without significant impact on the performance of higher priority applications. We plan to investigate nonpreemptive as well as preemptive priorities in processing disk requests.","title":"Performance Evaluation of Disk Arrays","awardID":"0105485","effectiveDate":"2001-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":[157594],"PO":["325495"]},"64562":{"abstract":"This project aims at developing fast algorithms for rapid simulation of giga-scale systems-on-chip, where coupled circuit, logic, and electromagnetic (EM) effects (including RLC parasitics, coupling, cross talk, skin and thermal effects---both quasi-static and full-wave), are becoming increasingly important. For coupled EM and circuit simulation, we propose to investigate a novel partial-element equivalent electric circuit (PEEC) approach. For coupled EM and digital simulation, we propose to investigate variant time stepping in EM analysis and to use conservative synchronization with digital events. More specifically, our approach consists of the following key elements:<br\/><br\/>Developing fast integral-equation-based solution methods that will make feasible EM simulation in these settings, and will permit hierarchical or multilevel EM analyses at varying degrees of model complexity.<br\/><br\/>Implementation of fast and hierarchical schemes through a variation of the partial equivalent electric circuit method for triangular mesh tessellations.<br\/><br\/>Coupling of EM simulation schemes directly to digital logic simulation in order to analyze switching and ground bounce in power-ground plane situations.<br\/><br\/>Exploitation of structure and redundancies present in EM, circuit-level as well as coupled-system matrices in order to drastically reduce memory and computation time to a degree such that rigorous and complete coupled simulation will be feasible for complex-systems-on-chip. Sensitivity analysis, reduced-order modeling, and multi-physics simulations are targeted in addition.<br\/><br\/>Development of optimized compilation techniques for generating ordinary differential equation (ODE) code for circuit simulation, and for exploiting the circuit structural regularity for fast hierarchical circuit\/EM simulation. The application drivers for testing proposed coupled EM\/circuit and EM\/digital simulation will include (1) Giga-hertz CMOS transceivers on chip, and (2) Power\/ground network of giga-hertz digital circuits including gate switching activity modeling.<br\/><br\/>It is intended that the development of fast and rigorous EM\/circuit and EM\/logic simulation will enable accurate yet efficient sign-off simulation of next generation mixed-signal circuits and systems, enable simulation in the loop design optimization and architecture tradeoff, and finally enable design for testability where EM effects are becoming hard to characterize, predict, and measure.","title":"Research for Mixed Signal Electronic Technologies: A Joint Initiative Between NSF and SRC: Fast Methods of Coupled EM. Circuit and Logic Simulation for Giga-Scale","awardID":"0120371","effectiveDate":"2001-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["377870","182786"],"PO":["562984"]},"66630":{"abstract":"This workshop uses recognized experts in information technologies to improve our understanding of the appropriate use of information technology in sustainable development. We intend to look particularly closely at remote environments recently affected by conflict and natural disasters. Attention will be directed toward methods of collecting and relaying information between a remote local population and their environment, and we intend to evaluate both the methods and metrics of collection and the capability for remote, high-dimensional visualization of those complex local systems. The hypothesis is that collecting health information locally with the capability of remote visualization can offer a quantitative and predictive method for community analysis. With careful attention to design, and iterative feedback for the community, we expect to offer earlier recognition of a spectrum of possible threats. Information collected, analyzed, and iterated may improve health while guiding local development sustainability, thereby improving regional stability. Better understanding the ecology and epidemiology of locations distant in geography and in culture broadens our global insight and benefits national security.","title":"Workshop: Information Technology in Sustainable Development: Implications for the Enhancing of National Security","awardID":"0129559","effectiveDate":"2001-08-01","expirationDate":"2002-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[172721],"PO":["241298"]},"59920":{"abstract":"Theory revision is the correcting of a given, roughly correct rule,<br\/>also known as a concept or theory. This problem arises frequently in<br\/>machine learning, for instance, when the initial output of an <br\/>expert system is not correct, and when the machine learning<br\/>problem is too large or too complex to solve from scratch, and an<br\/>approximately correct rule is needed to jump-start the learning<br\/>process. There has been considerable ad hoc building of theory <br\/>revision systems, but the theory is poorly understood. This research<br\/>investigates fundamental mathematical possibilities and limitations<br\/>of efficient theory revision. It is hoped that as a result of<br\/>this research, theory revision in computational learning theory will<br\/>emerge as a general framework for the study of learning situations<br\/>where a large amount of initial information is available or<br\/>necessary. <br\/><br\/>In particular, the PIs investigate the following areas: extensions<br\/>of their previous work on propositional logic theory revision<br\/>with queries, relations to certificate complexity and<br\/>attribute-efficient learning, revision problems for predicate logic<br\/>representations, and both the learning and revising of categorial <br\/>grammars.","title":"Theory Revision and Related Problems in Learning Theory","awardID":"0100336","effectiveDate":"2001-08-15","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["528421","409637"],"PO":["543507"]},"57533":{"abstract":"With the rapid emergence of Internet related applications, providing integrated services such as data, voice, and video in mobile computing systems has become increasingly important. However, mobile communication<br\/>systems such as cellular networks are primarily designed for supporting voice. Due to the different workload characteristics and quality of service (QoS) requirements of integrated services, prior resource<br\/>management techniques may not be efficient for handling the increasing demand of emerging applications. To address this issue, the research focuses on the design and evaluation of (1) bandwidth management schemes<br\/>to provide QoS guarantees and efficiently utilize the frequency spectrum; (2) cache management mechanisms to reduce the bandwidth and power consumption; and (3) efficient protocols to allow mobile devices to power<br\/>off most of the time. The research proposes to integrate these three components to provide a resource management infrastructure that can efficiently support integrated services in mobile computing systems. The<br\/>research results will be used and emphasized in the wireless networks and mobile computing courses developed in this project.","title":"CAREER: Designing Efficient Resource Management Schemes to Support Integrated Services in Mobile Computing Systems","awardID":"0092770","effectiveDate":"2001-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["550785"],"PO":["561889"]},"69666":{"abstract":"","title":"Middleware Components to Support Mobile Users in Heterogeneous Environments","awardID":"0196557","effectiveDate":"2001-08-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["539039","394642",180288],"PO":["309350"]},"59349":{"abstract":"Propoal #0098270<br\/>Clarkson University<br\/>Lynch, Christopher<br\/><br\/>Semantic unification has been effectively employed in many subfields of logic, computer science, artificial intelligence and cognitive science, with its most popular use being in resolution, logic programming languages such as Prolog, and the type inference mechanism in the programming language ML. Semantic unification (associative-commutative unification) played a pivotal role in settling open questions in mathematics (e.g. Robbins' conjecture about boolean algebra in 1996 by McCune using the theorem prover EQP). Recently, semantic unification has been found useful also in cryptographic analysis, knowledge representation and distributed computing.<br\/><br\/>This project will be a continuation of research on the theory of semantic unification as well as the design, development and implementation of semantic unification algorithms. This research will be motivated by new applications of semantic unification in cryptographic protocol analysis in conjunction with Catherine Meadows' work on the NRL (Naval Research Laboratory) Protocol Analyzer, in knowledge representation and description logics, induction theorem proving, and process algebra.<br\/><br\/>The new unification algorithms will be first developed and experimented using the Unification Workbench, a tool under development at SUNY, Albany, with the eventual goal of integrating them into application software, the NRL Protocol Analyzer and a rewrite-based induction theorem prover RRL (Rewrite Rule Laboratory) for use in the applications discussed above.<br\/><br\/>This award is one of three in a collaborative research team. The three awards are CCR-0098114 (Deepak Kapur, U New Mexico), CCR-0098270 (Christopher Lynch, Clarkson U), and CCR-0098095 (Paliath Narendran, SUNY Albany).","title":"Collaborative Research on Semantic Unification and its Applications","awardID":"0098270","effectiveDate":"2001-08-15","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["402469"],"PO":["321058"]},"59239":{"abstract":"Conventional solutions for I\/O have attempted to provide hardware<br\/>and software parallelism via RAIDs or parallel machines\/supercomputers.<br\/>However, the problems associated with cost, scalability, <br\/>and\/or accessibility of these environments make them unattractive <br\/>for widespread usage. This research addresses this important<br\/>deficiency in high-performance I\/O support, by proposing a shared storage<br\/>system using an off-the-shelf cluster of workstations, disks, and<br\/>networks. The proposed research goes beyond current state-of-the-art in I\/O <br\/>support for clusters and examines a broad spectrum of<br\/>issues related to I\/O software on clusters, that include<br\/>application-directed, compiler-directed, and runtime system-directed <br\/>optimizations. These optimizations are crucial to reduce\/hide the <br\/>latencies to different levels of the I\/O hierarchy which will help <br\/>accelerate the deployment of clusters for I\/O-intensive applications.","title":"Systems Support for High Performance I\/O on Shared Storage Clusters","awardID":"0097998","effectiveDate":"2001-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["542015","542016"],"PO":["309350"]},"62891":{"abstract":"This project involves research to enable musical tele-presence employing high performance communication networks and audio-video immersive environments. The goal is to create the impression of \"being in the same room\" for geographically separated users offering complete and immediate two-way visual and auditory contact to enable two or more musicians at different locations to freely interact musically. Three linked \"tele-presence\" studios being developed at the University of Rochester will be employed to understand the sources and effects of latency in musical interactions arising from acoustic, electronic and network factors under two-way real-time links. The controlled links between the studios will allow for gradated stages between the controlled situation of a dedicated local network to the more congested state of the Internet2 and the wider Internet. Building upon existing research, the limits of tolerance for latency in musical situations will be explored for various available network protocols, important Quality of Service issues and tradeoffs found in each will be investigated, and fault tolerant data transmission applications that employ data interleaving will be developed. Resources of the University of Rochester's Eastman School of Music will help guide this development from the end-user perspective. Ultimately the development of musical tele-presence will create an infrastructure through which music lessons and master classes by the best instructors can be simulcast in an interactive way. Performers could rehearse, perform and record together over the Internet, and chamber music groups could form unencumbered by geographical distances.","title":"ITR\/SI: Musical Tele-presence","awardID":"0112689","effectiveDate":"2001-08-15","expirationDate":"2006-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["360639","360640",161478],"PO":["564456"]},"59844":{"abstract":"Theory revision is the correcting of a given, roughly correct rule,<br\/>also known as a concept or theory. This problem arises frequently in<br\/>machine learning, for instance, when the initial output of an <br\/>expert system is not correct, and when the machine learning<br\/>problem is too large or too complex to solve from scratch, and an<br\/>approximately correct rule is needed to jump-start the learning<br\/>process. There has been considerable ad hoc building of theory <br\/>revision systems, but the theory is poorly understood. This research<br\/>investigates fundamental mathematical possibilities and limitations<br\/>of efficient theory revision. It is hoped that as a result of<br\/>this research, theory revision in computational learning theory will<br\/>emerge as a general framework for the study of learning situations<br\/>where a large amount of initial information is available or<br\/>necessary. <br\/><br\/>In particular, the PIs investigate the following areas: extensions<br\/>of their previous work on propositional logic theory revision<br\/>with queries, relations to certificate complexity and<br\/>attribute-efficient learning, revision problems for predicate logic<br\/>representations, and both the learning and revising of categorial <br\/>grammars.","title":"Theory Revision and Related Problems in Learning Theory","awardID":"0100040","effectiveDate":"2001-08-15","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["516895"],"PO":["279077"]},"57238":{"abstract":"EIA-0091530<br\/>Stephen E. Reichenbach<br\/>University of Nebraska-Lincoln<br\/><br\/>Digital Government: A Geospatial Decision Support System for Drought Risk Management<br\/><br\/>This project will develop and integrate new information technologies for improved government services in the U.S. Department of Agriculture (USDA) Risk Management Agency (RMA). The mission of the RMA is to strengthen the safety net for agricultural procedures (farmers) through sound risk management programs and education. Rick management in agriculture is critically important to producers, their communities, and the nation's economy, but it involves many complex problems.<br\/><br\/>Our objective is to improve, through research and advanced development, the RMA's risk assessment services in three important ways:<br\/><br\/>To speed risk assessment with automation<br\/>To enhance risk assessment with increased spatial and temporal resolution and additional input variables To extend risk assessment to forecasts and economic analyses","title":"DIGITAL GOVERNMENT: A Geospatial Decision Support System for Drought","awardID":"0091530","effectiveDate":"2001-08-01","expirationDate":"2005-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["451312","491467",147262,"486378","194011"],"PO":["371077"]},"60780":{"abstract":"EIA-0103676<br\/>Bhargava, Bharat.<br\/>Purdue University<br\/><br\/>CISE Postdoctoral Associates in Experimental Computer Science: Experiments in Security and Quality of Service in Mobile Systems<br\/><br\/>Disaster recovery after an emergency such as an earthquake, terrorist attack, or war may depend on mobile systems for communications. Security and Quality of Service (QoS) are of utmost importance. Providing security and QoS is a difficult problem in mobile systems because the availability of network and other resources may change as the mobile host fails, moves, or comes under intentional or unintentional attack. Research on a technique to achieve fault-tolerant mobile node authentication in an efficient way is proposed for a postdoctoral research associate. Such a technique would eliminate single points of failure, distribute loading, and enhance scalability and survivability, and make failures transparent to users. A series of experiments are planned that will evaluate this technique under a variety of variables and lead to the development of new authentication and key management techniques. The associate will 1) identify guidelines for authentication between an upstream domain and an ingress router in a QoS enabled network, 2) evaluate various secure group communication and access control techniques for suitability in wireless communications, and 3) explore adaptability requirements when considering security as a QoS parameter.","title":"Postdoctoral: Experiments in Security and Quality of Service in Mobile Systems","awardID":"0103676","effectiveDate":"2001-08-01","expirationDate":"2003-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":["540775"],"PO":["564181"]},"60076":{"abstract":"This is the first year funding of a three year continuing award. The PI's contention is that the field of computer vision has matured to the point where a completely portable system capable of finding signs and other textual events in the environment in close to real time, and then reading their contents aloud, is feasible. His goal in this project is to provide the visually impaired with a way to obtain crucial information from the environment that is now totally inaccessible (except through intervention of a sighted person). Running on a wearable computer connected to a gyroscopically referenced head mounted camera, the envisaged system will detect text and signs within a compact representation of continuous video of the user's surroundings in the form of a mosaic. The sign detection and recognition system will use a set of multi-scale features that have been shown to be invariant to changes in viewing angle and illumination. Recognition will be accomplished by building multi-resolution spatial networks of distributions of these features and matching them against a database of known (customized to locale) signs (e.g. international highway signs) using a coarse to fine matching technique that is both robust and efficient. Text will be detected using the same techniques, with the aid of a commercial OCR system. The PI will also examine the OCR's intermediate representations, and a word dictionary for tolerance to character recognition errors. He will leverage existing work on image retrieval from large databases using image content, face recognition, image indexing using color properties, and text detection and recognition in complex images. The work will be performed in three phases roughly corresponding to a year each. System design and evaluation will both be conducted in conjunction with Lighthouse International, which specializes in rehabilitation training for the visually impaired. In the first phase of the work, individual components, which include camera stabilization, mosaics, text and sign recognition, will be developed. In the second phase, a head mounted unit, attitude inference, a wearable computer, a camera, speech synthesizer and user interface model will be developed. Additionally, the use of log-polar cameras will be examined for fast computation of multi-scale features and for its effectiveness in simultaneously addressing the field of view and resolution issues. The third and last phase will consist of a series of user and system evaluations and refinements. There is no doubt that, if successful, this research will have a tremendous impact on and dramatically improve the lives of visually impaired individuals.","title":"VIDI: Visual Information Dissemination for Visually Impaired Individuals","awardID":"0100851","effectiveDate":"2001-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6846","name":"UNIVERSAL ACCESS"}}],"PIcoPI":["290022"],"PO":["565227"]},"64432":{"abstract":"The process for designing an integrated circuit (IC) system-on-a-chip (SoC) shares many similarities with the hardware design of a system on a board or on several boards. The hardware system designer knows the characteristics of the set of system input signals that are to be processed, and the characteristics of the set of system output signals. There are usually several signal processing architectures that can accomplish the goal and the designer must evaluate the tradeoffs that are inherent in the various designs. Board-level hardware system designers have to use available standard commercial components for the most part to create the system of desired functionality. Sometimes requirements allow for the creation of custom ICs, and occasionally a few transistors and discrete components are used to provide proper interfaces among chips. Designers evaluate the potential that various components have for meeting overall system performance requirements based upon the components' terminal characteristics. From the designers' skill and insight, an architecture is selected, the hardware realization breadboarded, and evaluated. In the process of designing an SoC IC, the terminal characteristics of the SoC inputs and outputs must be known. Often, proven board-level hardware realizations of the function are referred to as possible architectures for the SoC. These proven board-level architectures are defined in terms of the interconnection of the group of commercial products that provide various signal processing sub-functions. The SoC architecture can also be defined in terms of these sub-function modules. Partitioning the SoC into blocks that correspond to the sub-functions successfully used in board-level designs is usually convenient because the characteristics of the sub-functions' interconnecting signals are well understood. The performance required of each of the SoC sub-functions must be inferred from the performance specifications of the overall SoC. However, the SoC IC designers do not have available these sub-functions as performance-characterized cells laid out in the target fabrication technology. The SoC IC design team usually has to create each of the sub-function blocks as a custom IC cell. The transistor-level topologies of analog and digital functional blocks are then identified and evaluated.<br\/><br\/>Existing CAD tools are capable of sizing MOS transistors of circuits with modest complexity to customize the circuit to meet design specifications through performance function minimization. One SoC IC design problem is to select the sub-function performance requirements in such a way as to optimize the overall SoC performance. It is possible to find these optimized sub-functions' performance requirements using the overall SoC performance specifications and performance function optimization techniques. A new CAD tool that can optimize the SoC sub-function performances based upon the overall SoC performance requirements will be created. The resultant optimized sub-function performance requirements can then become the inputs to other existing design optimization CAD tools that perform subsequent more-detailed design automation steps to create the transistor-level circuit realizations.<br\/><br\/>Integrated micro-systems, systems-on-a-chip, will be very complex combinations of analog, digital, mixed-signal, photonic, and MEMS signal processing functions. The analysis, design, and design verification of such a system is incredibly complicated, and will require the use of many very sophisticated CAD tools. At the present time and in the near future, it is unrealistic to expect a single integrated suite of CAD design tools to be able to provide all of the capabilities needed to design, layout, and verify the functionality of an SoC that includes extensive digital functionality, and analog, mixed-signal, photonic, and MEMS signal processing sub-systems. Research will be undertaken on an integrated micro-system design automation tool that will optimize the performance of a complex mixed-signal signal-processing SoC entirely at the conceptual level. Research in behavioral modeling, high-level system performance specification, and performance optimization by objective function minimization will be undertaken to support this effort. To facilitate this overall goal, flexible, accurate, computationally efficient, technology-independent, implementation-independent, high-conceptual-level behavioral models that reflect all important limiting effects of the function that could influence SoC performance are required that represent the many diverse possible actions that can be taken by the various subsystems of an SoC. Analog, digital, mixed-signal, photonic, and MEMS devices that may be included on an SoC will considered in this research.<br\/><br\/>One deliverable is a fully documented design environment that supports the capture of an SoC functional description as an interconnection of sub-functions defined in a library of","title":"Research for Mixed Signal Electronic Technologies: A Joint Initiative Between NSF and SRC: CAD Tool for High-Level Design Automation of Integrated Mixed-Signal Microsystems","awardID":"0119778","effectiveDate":"2001-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":[166110],"PO":["562984"]},"64465":{"abstract":"Stephen L. Bloom<br\/>\"Axiomatizing Fixed Points<br\/>Stevens Inst. of Technology<br\/><br\/>The purpose of the proposed work is to obtain complete, but simple, descriptions of the properties of the \"fixed point\" or \"iteration\" operation in computation. Simpler axioms may lead to concrete discreptions of free structures and we intend to use the axioms and\/or these concrete descriptions to find and improve decision algorithms. Previous work by Bloom, Esik and others has resulted in a complete description of the equational laws satisfied by the iteration operation. This description takes the form of the axioms for Iteration Theories, which capture important features of many classes of structures of interest in the theory of computation. The original axiomatization of iteration theories contained a complicated equational scheme. Recently, this scheme has been replaced by the \"group identities\". Nevertheless, further simplifications seem to be possible. Another goal is to find relative finite axiomatizations of iteration theories enriched by additional operations and\/or relations. If successful, there are major beneficial corollaries. For example, a relatively simple set of axioms for the concurrent behavior of finite state processes (both for bisimilarity equivalence and for trace equivalence), for Kleene relation algebras with and without conversion, for the behavioral equivalence of recursive program schemes or recursive data type definitions and others.<br\/><br\/>Lastly, some previous work of the investigators and others has indicated that the laws of iteration theories hold in the extremely general setting of 2-categories, and we intend to investigate this phenomenon in detail.","title":"SGER: Axiomatizing Fixed Points","awardID":"0119916","effectiveDate":"2001-08-01","expirationDate":"2002-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":[166259],"PO":["543507"]},"59603":{"abstract":"The explosive growth of computer networks, combined with rapid and unpredictable developments in ap-plications and workloads, has rendered network service inference and performance prediction increasingly de-manding and intractable tasks. Nonetheless, end-systems must have knowledge of internal network traffic con-ditions and servicing in order to validate, predict, or enhance performance capabilities required by demanding applications. Network service providers also have a great need for gauging the performance of their own sub-systems without recourse to global strategies. Without special-purpose network support, the only alternative is to indirectly infer dynamic network characteristics using edge-based network traffic processing.<br\/> The INCITE (InterNet Control and Inference Tools at the Edge) Project focuses experts from the fields of<br\/>networking, digital signal processing, and applied mathematics towards the goal of characterizing network ser-vice based solely on edge-based measurement at hosts and\/or edge routers. This project blends recent work in multifractal traffic modeling, quality of service (QoS) measurement, and network tomography to develop a unique and innovative framework for network service inference. The INCITE Project will develop new al-gorithms and implementations using the latest in DSP-driven network processor technology, providing a vital step towards better managing and understanding of Internet performance. Our effort consists of three closely inter-related research thrusts:<br\/>1. Multifractal Traffic and Path Modeling: We will develop new, highly accurate tools for analyzing,<br\/>modeling, and measuring the dynamics of network connections and end-to-end paths from the edge. Our<br\/>approach to inferring the competing cross-traffic load on a path utilizes an innovative exponentially spaced<br\/>probing sequence that is inspired by the theory of multifractal random processes. These probing packet<br\/>chirps balance the trade-off between overwhelming the network with probes and obtaining statistics rich<br\/>enough for accurate estimates.<br\/>2. Multiclass Service Inference: We will develop a framework for clients to assess a network's core QoS<br\/>functionalities based on external and passive observations. Using the theory of traffic envelopes, maximum<br\/>likelihood estimation, and hypothesis testing, clients will be able to assess a broad set of the network's<br\/>multi-class control mechanisms such as the service disciplines, link sharing rules and parameters, and<br\/>policing parameters.<br\/>3. Unicast Network Tomography: We will develop a novel methodology for network tomography that pro-vides<br\/>link-level performance characterization of networks of arbitrary topologies based on unicast traffic<br\/>measurements at a the network edge. A new network modeling framework based on factor graphs will<br\/>enable the statistical inference of link-level service parameters (e.g., losses, delays, and service strate-gies). A key strength of our envisioned methodology is that it will enable scalable, real-time tomography algorithms deployable on hosts and\/or edge routers.<br\/> The INCITE Project will develop the theoretical underpinnings of network multifractal traffic processing,<br\/>service inference, and link-level characterization for complex, large-scale networks, and lead to computation-ally efficient and scalable service inference algorithms based only on traffic measurement at the network edge. Moreover, in collaboration with a leading provider of broadband Internet bandwidth (Enron) and an innovator in networked signal processing hardware (Texas Instruments), we will build a complete prototype implementation of the proposed algorithms, including modules for multifractal traffic and path modeling, service inference, and network tomography. This reference implementation will provide a first-of-its-kind platform for obtaining a deep understanding of large networks and enable principled designs of future network architectures, algorithms, and models.","title":"INCITE: A Framework and Methodology for Edge-Based Traffic Processing and Service Inference","awardID":"0099148","effectiveDate":"2001-08-15","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["497441","518179","548310","233003"],"PO":["292741"]},"69525":{"abstract":"","title":"TCP-Unaware Approaches to Improve Performance of TCP Over Wireless Links","awardID":"0196413","effectiveDate":"2001-08-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["553537"],"PO":["234222"]},"59307":{"abstract":"Design of high performance clusters with Quality-of-Service (QoS)guarantees is becoming increasingly important to support a variety of scientific and commercial applications. Performance of a cluster can be improved by an efficient scheduling mechanism. Although a few communication-guided scheduling algorithms<br\/>have been proposed recently for clusters, these schemes have not been tested on large platforms to<br\/>examine the potential benefits.<br\/><br\/>Therefore, the main motivation of this research is to design scalable and efficient scheduling algorithms for clusters. The proposed research addresses three related issues. First, an in-depth evaluation of the existing<br\/>scheduling schemes will be done on a large cluster platform using real workloads before developing<br\/>new algorithms. Second, various design issues in implementing these algorithms on the generic virtual interface architecture (VIA) will be explored. Finally, the research will examine QoS provisioning<br\/>mechanisms to facilitate predictable performance in clusters.<br\/><br\/>The success of this research is expected to have many important contributions in the area of cluster computing. Primarily, the practical scheduling algorithms developed in this research can be used on large platforms. The results from the VIA and QoS research should provide novel solutions to satisfy different performance and QoS requirements, and should foster further research in this area.","title":"Scalable and Efficient Scheduling Techniques for Clusters","awardID":"0098149","effectiveDate":"2001-08-01","expirationDate":"2005-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["550859"],"PO":["309350"]},"63025":{"abstract":"EIA-0113440<br\/>Vwani Roychowdhury<br\/>University of California at Los Angele<br\/><br\/>Title: Quantum Communication and Cryptography: Protocols and Systems<br\/><br\/>A functional quantum computer would render all public-key cryptographic protocols (e.g., RSA, Diffie-Hellman), used for secure communication over the Internet, insecure; conversely, QKD could save the Internet and enable secure public communication. Similarly, super-dense coding can potentially double the classical capacity of a channel, if the parties could share EPR pairs in advance.<br\/><br\/> This project is aimed at a theoretical study of issues in quantum informatin processing, including (1) algorithms for entanglement purification and distillation, (2) Capacity results for various quantum channels, (3) efficient entanglement manipulation and pure state management via local quantum operations and classical communication (LOCC), (4) quantum key distribution using practical systems, and (5) novel informationally-secure quantum cryptographic protocols that only quantum systems might enable, but are not known to exist using classical cryptographic protocols.","title":"ITR\/SI: Quantum Communication and Cryptography: Protocols and Systems","awardID":"0113440","effectiveDate":"2001-08-15","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["455118"],"PO":["565223"]},"67678":{"abstract":"Abstract<br\/>F.S. Roberts, Rutgers University<br\/>EIA Special Projects Program<br\/><br\/>NSF CISE and EU IST have in place a Memorandum of Understanding to conduct a series of joint program planning workshops in order to develop plans for a series of joint programs in CISE-related areas between the US and the European Union. The EU IST has designated ERCIM as the coordinator of nine planning workshops to be held in Europe over the three year period starting in 2001. NSF will support a travel grant program through DIMACS as requested in this proposal to cover costs of the US delegation to these international program planning workshops, beginning with the Bionics workshop in Brussels on June 18, 2001.","title":"Three Special Focus Programs at DIMACS","awardID":"0134668","effectiveDate":"2001-08-15","expirationDate":"2008-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"V068","name":"CIA-KDD & TARGET CHARACHTERIZA"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["264120"],"PO":["371077"]},"69669":{"abstract":"","title":"Digital Government: Internet Voting Study","awardID":"0196560","effectiveDate":"2001-08-31","expirationDate":"2001-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}}],"PIcoPI":[180294],"PO":["371077"]},"59308":{"abstract":"The investigator will study numerical algorithms for solving moderate to large scale eigenvalue and generalized eigenvalue problems. There are two lines of research. One is to investigate a new kind of parallelizable Hessenberg eigen-value algorithm termed \"subdivision-by-deflation\". The subdivision-by-deflation algorithm reduces the computational complexity and increases the parallelism of Hessenberg eigenvalue problems. This has the potential of reducing the computational cost of the Hessenberg eigenvalue problem significantly below current levels.<br\/><br\/>The other line of research involves continued development of TTQRE, a variant QR algorithm for solving the moderate scale algebraic eigenvalue problem. Although TTQRE has already proved itself to be a significant advance over traditional QR algorithms, it has not yet reached its full potential. Strategies will be designed that adjust its fundamental parameters dynamically during execution. This project supports a graduate student who will participate in the project. The student's training will benefit from practical computational experience on real parallel computers as from the work with theoretical problems.","title":"Numerical Linear Algebra and Eigenvalue Computations","awardID":"0098150","effectiveDate":"2001-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["161277"],"PO":["321058"]},"61321":{"abstract":"Title: Algorithms for approximation and graph problems<br\/>PI: Richard Cole<br\/>CCR-0105678<br\/><br\/><br\/>This research concerns the finding of approximate solutions.<br\/>It is often the case that finding exact solutions is vastly too<br\/>expensive in terms of the time required, to the point of<br\/>being infeasible. Yet fairly accurate solutions which are<br\/>\"good enough\" may be obtainable in a much shorter time, and<br\/>consequently be more practical. The specific problem domains<br\/>on which this research focuses range from pattern matching<br\/>(for example, devising algorithms to find similar and\/or<br\/>repeating patterns in DNA sequences) to intrinsically<br\/>intractable problems such as the travelling salesman problem<br\/>(which amounts to finding a shortest route connecting a<br\/>collection of cities).<br\/><br\/> The research on string matching is considering new notions<br\/>of approximation so as to devise efficient algorithms for a<br\/>broader class of approximate matches than is feasible presently;<br\/>both searches between pairs of strings and against a database<br\/>of strings are being studied. The second part of our research<br\/>focuses on NP-hard problems. We are looking at multicost<br\/>shortest path problems (e.g. with a cost comprising both<br\/>time and price) in which one seeks all non-dominated solutions,<br\/>at improving the quality of approximations for the Travelling<br\/>Salesman Problem in the plane, and also at improving the<br\/>approximations obtainable for generalized Steiner Tree problems.","title":"Algorithms for Approximation and Graph Problems","awardID":"0105678","effectiveDate":"2001-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["518072"],"PO":["279077"]},"60056":{"abstract":"The focus of this proposal is the design and implementation of<br\/>cluster-based electronic commerce servers (or simply distributed<br\/>e-commerce servers) that are efficient, scalable, and capable of<br\/>service differentiation. To achieve these properties, our servers<br\/>will efficiently adapt their quality of service, will efficiently<br\/>handle any type of incoming request according to the client's profile,<br\/>will not involve any centralized resources, and will cache both static<br\/>and certain dynamic content. The key challenges are in determining<br\/>the set of policies and mechanisms that should be used to<br\/>differentiate the services provided and to implement truly efficient<br\/>and scalable policies and mechanisms for request processing. At the<br\/>end of the project, we will demonstrate two distributed e-commerce<br\/>servers (an on-line store and an auction server) running on a cluster<br\/>with 64 processors.<br\/><br\/>The contributions of this project will be the following: (1) A<br\/>complete and general characterization of e-commerce workloads; (2) An<br\/>understanding of the issues involved in service differentiation for<br\/>distributed e-commerce servers, including the use of optimizations<br\/>based on the past history of actions taken by high-priority clients;<br\/>(3) The design, implementation, and evaluation of mechanisms for<br\/>shared state maintenance and transaction support in distributed<br\/>e-commerce servers; and (4) The study of techniques and mechanisms for<br\/>improving the efficiency and scalability of distributed e-commerce<br\/>servers.<br\/><br\/>We believe that the potential implications of our research and<br\/>contributions are far reaching. In fact, we think that the impact of<br\/>our research can be substantial, given how significantly various<br\/>companies have come to rely on their on-line networking operations.<br\/>Furthermore, our research can be useful for operating systems and<br\/>distributed systems teaching purposes, as our software infrastructure<br\/>will provide a tool for the study of distributed e-commerce servers.","title":"CNPq: Service Differentiation, Efficiency, and Scalability in Distributed E-Commerce Servers","awardID":"0100798","effectiveDate":"2001-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["556616"],"PO":["309350"]},"64555":{"abstract":"Analog to Digital Converters (ADCs) are one of the key components that are needed in many integrated circuits today and the application and demand for the converters will only accelerate throughout the next decade as applications expand and the ability to put large systems on a chip becomes reality. Paralleling and enabling this growing demand is an evolution in semiconductor technology with processes that have a continued shrinking of feature sizes and supply voltages. Although these evolutions are providing dramatic speed and transistor density improvements in most digital circuits, they are presenting increasing challenges for realizing analog and mixed-signal functions and the two decade-old strategy of using the same basic circuit structures to implement key functional blocks such as the analog to digital converter will no longer be successful in the sub-100nm processes that are now under development.<br\/><br\/>This research is focused on developing design methodologies that can be used to design high-performance analog to digital converters in sub-100nm semiconductor processes in which not only the supply voltages are decreasing but also the gain characteristics of the basic transistor are deteriorating. The three major initiatives in the project are a) developing techniques for building fast high-gain operational amplifiers that can operate with very low supply voltages, b) developing built-in self-calibration and built-in self-test algorithms for pipelined data converters, and c) incorporating these results into a prototype converter than will be fabricated in a fine resolution process so that the theoretical performance characteristics can be experimentally validated.<br\/><br\/>The low voltage operational amplifiers should find applications in sub-100nm<br\/>processes well beyond their use in pipelined data converters. The self-calibration strategy is based upon treating the pipelined data converter as a system, which is identified through the use of a dedicated digital signal processing block. This approach will provide for yield enhancement and will inherently provide capability for built-in self-test which will be of increasing importance as increasingly complex analog and mixed-signal functions become deeply embedded in large single-chip systems.","title":"Research for Mixed Signal Electronic Technologies: A Joint Initiative Between NSF and SRC: Pipelined Data Converter Design Strategies for Sub-100nm Processes","awardID":"0120345","effectiveDate":"2001-08-01","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["401071"],"PO":["562984"]},"57603":{"abstract":"Until recently, performance has been the single most important issue in the design of hardware and software. However, with the proliferation of battery-powered embedded and portable devices and the ever-increasing clock frequencies of general-purpose processors, the problem of effective energy optimization has become very important for a wide variety of architectures. The goal of this project is to design and implement an energy-aware optimizing compiler framework that take as input a source code written in a high-level language, energy and performance constraints, architectural description and technology related parameters, and generates as output an energy\/performance optimized executable and an estimation of energy consumption. Some key contributions include (i) high-level energy models that can be used by a compiler, (ii) a simulator infrastructure to validate compiler output, (iii) new, energy-oriented compiler optimizations, and (iv) investigating the necessary os and architectural support for effective cooperation between the compiler, os, and architecture so as to address the growing energy problem in a unified manner. The proposed energy\/performance-aware approach represents a radical shift from pure performance-oriented strategies used so far in optimizing compilers, and will open new avenues of research in computing in a world that is increasingly becoming more energy-conscious.","title":"CAREER: EOC: An Energy-Aware Optimizing Compiler Framework","awardID":"0093082","effectiveDate":"2001-08-15","expirationDate":"2007-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}}],"PIcoPI":["542016"],"PO":["565272"]},"64038":{"abstract":"IIS-0117493<br\/>Carl H. Smith, University of Maryland<br\/>$8,500 - 12 mos (joint funding with IDM program, total awad $17,000)<br\/><br\/> <br\/><br\/>Discovery Science 2001<br\/><br\/><br\/><br\/>This is a standard award to provide funding for 2 plenary speakers and up to 10 graduate students attending the fourth conference on Discovery Science to be held in Washington DC in November 2001. The goal of the new field of Discovery Science is to automate (as much as possible) the process by which scientific insights are distilled from large data sets. The intellectual scope of the field is very broad, covering topics from philosophy, logic, automated reasoning and computational learning theory, as well as empirical investigations of various implemented discovery algorithms. An important contribution of the conferences is that they assemble a wide range of perspectives on the process of discovery in the hopes of generating synergy. This year's conference will be the first to be held in this country, and the PI is the local organizer of the meeting. Student participants will be selected by the Steering Committee from among the student authors, based primarily on the rankings of the papers by the Program Committee but moderated slightly by a desire to achieve diversity. The two invited speakers will be senior researchers from related fields, chosen by the Steering Committee with a view to building bridges to related research communities.","title":"Discovery Science 2001","awardID":"0117493","effectiveDate":"2001-08-15","expirationDate":"2002-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["69811"],"PO":["564456"]},"62983":{"abstract":"Abstract<br\/>Proposal #0113181<br\/>Sitaraman<br\/>Clemson University<br\/><br\/>A fundamental goal of software engineering is to enable predictable and modular construction of software systems by assembling components. Any component-based approach works on the basic premise that participating components respect each other's contracts. If this premise is violated, the consequences can be both dangerous and expensive, because the problems may not surface until integration time. Even worse, a system may behave properly on test cases, though internal interface contracts are violated. Undetected failures from internal violations may be revealed ultimately only as accidents to component-based and embedded systems after deployment.<br\/><br\/>This project offers a modular approach for detecting and isolating internal contractual violations. The approach allows checking at suitable levels of abstraction using formal specifications. It permits checking to be turned \"on\" or \"off\" selectively to facilitate effective regression testing, and it addresses violations of performance contracts in addition to functionality for parameterized and object-oriented components. To minimize errors in the violation checking process, the project will use and experimentally evaluate alternative combinations of automation, formal verification, model checking, and testing techniques.","title":"ITR\/SY: Modular Interface Violation Checking Using Formally-Specified Contracts","awardID":"0113181","effectiveDate":"2001-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["521544","508269","530445"],"PO":["561889"]},"76964":{"abstract":"EIA-0083083<br\/>Fortes, Jose A.<br\/>Purdue University<br\/><br\/>CISE CNPq: US-Argentina and US-Chile Collaborative Research on Computer Science and Engineering<br\/><br\/>This is an award to support two workshops, each of two days duration in May 2000, in Chile and Argentina. It is anticipated that these workshops will build on the success of the CISE\/NSF programs with Mexico and Brazil (CONACyT and CNPq, respectively) to begin creating the collaborations and personal connections necessary to support the possibilities for similar government to government bilateral arrangements with Chile and Argentina.","title":"CISE CNPq: US-Argentina and US-Chile Collaborative Research on Computer Science and Engineering","awardID":"0230772","effectiveDate":"2001-08-01","expirationDate":"2003-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"X508","name":"DARPA-US ARGENTIA CHILI COLLAB"}}],"PIcoPI":["540130"],"PO":["371077"]},"63104":{"abstract":"The Million Book project is a multinational initiative to create a digital online archive of at least a<br\/>million books and manuscripts freely available to anyone at any time. It will enhance research,<br\/>learning and teaching by making a critical mass of scholarly information freely available to<br\/>read online. It will support the needs of citizens for practical information and recreational reading<br\/>as well as supporting scholarship and education. India, and possibly China, will supply the manpower<br\/>for scanning centers while the U. S. provides equipment and software. This pilot project supplies<br\/>the startup money for the first few scanning centers.","title":"ITR\/IM: The Million Book Project","awardID":"0113878","effectiveDate":"2001-08-15","expirationDate":"2002-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["355022","461693"],"PO":["564456"]},"63005":{"abstract":"The primary goal of this project is to design, implement and test a new display system for digital libraries.<br\/>It is motivated by the lack of display capabilities in most systems today; we need more screen resolution and screen size. This project will combine commodity video projectors and computing equipment with software to provide automatic calibration and to provide better interfaces to visualization techniques. This will be of value in virtual reality environments and scientific data analysis environments as well as in digital library implementations. The project will be done in partnership with a library at the University of Kentucky and a computing facility at the University of Puerto Rico.","title":"ITR\/SY+IM(CISE): Self-Calibrating, Scalable Displays for Digital Library Collections","awardID":"0113325","effectiveDate":"2001-08-15","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}}],"PIcoPI":["494196","359059"],"PO":["564456"]},"63016":{"abstract":"ITR Small Proposal <br\/>Collaborative: 0113385\/0112591<br\/>Sayeed\/Popovic<br\/><br\/>Abstract<br\/><br\/>Reliable and seamless wireless connectivity in varied environments is a necessary requirement for the rich and diverse communications of the future. Space-time processing has emerged as a key enabling technology for future wireless communications: signal space dimensions are fundamental to reliable communication and antenna arrays augment the traditional dimensions of time and frequency with the spatial dimension. While recent theoretical and technological advances provide a tremendous boon for modern communications, the state-of-the-art is far from realizing the full potential of space-time processing due to significant gaps in our current understanding on two fronts:<br\/><br\/>Fundamental mechanisms underlying the interaction of the space-time channel with the signal space in spatial, temporal, and spectral dimensions.<br\/><br\/>Jointly optimized design of front-end hardware, antenna arrays, and signal processing algo-rithms. <br\/><br\/>The overall goal of the work proposed here is an integrated approach to the design of antenna array hardware and space-time processing algorithms for significantly improved wireless link performance<br\/>at reduced cost and complexity.","title":"ITR\/SI: Collaborative Research: Integrated Signal Processing and Antenna Array Design for Wireless Diversity Links","awardID":"0113385","effectiveDate":"2001-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["531613"],"PO":["564898"]},"76458":{"abstract":"This research program investigates the theory and pragmatics of naming and sharing data and computation threads, using principles of optimal evaluation and linear logic. These tools explicitly highlight the operations of copying and discarding that are essential in procedure calling protocols.<br\/><br\/>The project analyzes the algorithmics of optimal evaluation, the complexity of box management, and the evaluation pragmatics for languages with explicit control. Also included in the research agenda are intensional full abstraction theorems, where the meaning of a term includes operational information about how computations are shared, and the use of context semantics as a flow analysis tool, where the so-called \"geometry of interaction\" can give information about how procedures access their arguments. A further investigation of ``superposition'' phenomena that occur in high-level sharing is planned. The final component seeks a refined explanation of the bus system of graph reduction in terms of linear logic, in the hope of giving a new categorical rendition of the incremental computation that characterizes optimal evaluation.","title":"Theory and Pragmatics of Optimal Reduction: Logic, Linear Naming, and Programming Language Design","awardID":"0228951","effectiveDate":"2001-08-01","expirationDate":"2007-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["370683"],"PO":["564388"]},"60751":{"abstract":"This multi-disciplinary proposal will unite researchers from physics, chemistry, and biology to work synergistically on a coherent project that involves one basic concept, the development and synthesis of novel materials from self-assembled magnetic nanostructures whose configuration and\/or functions can be tuned and controlled by external fields. We will demonstrate that, by understanding physical mechanism of self-assembly and field-controlled phenomena and by bringing together two frontiers of the new century---the nanoscale science and the field of soft matter, we will be able to develop functional materials that enable new technologies ranging from memory devices, drug delivery agents, field-controllable nanomachines, magnetically actuatable polymers, and many other liquid, gel, or solid devices.<br\/>We propose to perform experimental and theoretical research to study the conditions for self-assembly phenomena in surfactant-stabilized magnetic fluids. Experimental observations using scattering techniques such as neutron and light scattering, imaging (Atomic Force Microscopy (AFM)\/Magnetic Force Microscopy (MFM)), and thermodynamic measurements (e.g. heat capacity) will be supported and evaluated by using computer simulations. We propose to use realistic quaternion molecular dynamics simulations in viscous media to study the dynamics of isomer transitions under varying conditions and to present a correct interpretation of the experimental results. Based on the configuration of self-assembled structures in zero field and its response to external fields, novel structures can be synthesized that have important applications.<br\/>The proposed research will provide the basis for the design of new, smart materials and externally controlled systems that can respond to an external environment through the unique combination of theory, computer simulations, and experimental investigations. This work will have an important impact in applied physics, chemistry, material sciences, biology and medicine, and device industries. Our approach aims to facilitate the education of tomorrow's scientists in nanoscience and technology through the involvement of students in every aspect of proposed research.","title":"Self-Assembly of Magnetic Nanostructures and Related Enabling Technologies","awardID":"0103587","effectiveDate":"2001-08-01","expirationDate":"2006-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1708","name":"QuBIC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"1517","name":"ELECT, PHOTONICS, & MAG DEVICE"}}],"PIcoPI":[156315,"462606","369802"],"PO":["395818"]},"62830":{"abstract":"This research concerns the unsupervised learning of structural information about English that is not present in current tree-banks (specifically the various Penn tree-banks). That is, one wants a machine to learn this information without having to create a corpus in which the information is annotated. The structural information to be learned often falls at the boundary between syntax and semantics; for example, does the fact that the \"New York Stock Exchange\" has as part of the name the location \"New York\" fall under syntax or semantics? What about the similarity between the expressions \"[to] market useless items\" and \"the market for useless items\"? The intention is to learn this kind of information in a form that current statistical parsers can use so that they can output more finely structured parses. But this is not meant to suggest that parsing is the sole use for this sort of information. More and more systems for automatically extracting information from free text use coreference detection and \"named-entity recognition\" (e.g., recognizing that \"New York\" is a location, but \"New York Stock Exchange\" is an organization). There is evidence to suggest that both coreference and named-entity recognition can be improved with the finer level of analysis to be made possible by this research. Or again, \"language models\" (programs that assign a probability to strings in a language) are standard parts of all current speech-recognition systems; there is evidence that suggests that finer grained syntactic analysis can improve current language models. Thus, this research will enable a wide variety of systems to make better use of language input and so make these systems more accessible to a diverse user pool.","title":"ITR\/SY(CISE) Learning Syntactic\/Semantic Information for Parsing","awardID":"0112435","effectiveDate":"2001-08-15","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["527631"],"PO":["565215"]},"60663":{"abstract":"This proposal was received in response to NSE, NSF-0019. The goal of the research is to explore the potential application of carbon nanotubes for greatly enhancing the efficiency of existing microarray devices in biological\/biomedical research. The proposed work will synthesize arrays of well-aligned carbon nanotubes that can be used to transfer biomolecules from the tips of the nanotubes for creating microarrays at a level of packing density not achievable by current techniques. Carbon nanotubes are uniquely suited for this application owing to their extremely high elastic modulus and strength as well as exceptional capability in sustaining large nonlinear elastic deformation.<br\/><br\/>This is a preliminary feasibility study of a novel idea in nanoscience and engineering with focuses on nanoscale devices and systems architecture, and modeling and simulation at the nanoscale. The effort is likely to catalyze rapid advances in biological\/biomedical research.<br\/><br\/>The objectives of this exploratory research are to (a) better understand the growth of aligned carbon nanotubes for achieving optimal control of their length, diameter, and packing density <br\/>in microarrays, (b) better understand the structures and performance of individual nanotubes <br\/>as well as microarrays through microscopic and mechanical characterizations, (c) initiate computational mechanics effort at both the continuum and atomistic levels for modeling the <br\/>nano-structure, chirality, and mechanical behavior of nanotubes, (d) develop the tools and criteria for assessing the performance of this novel microarray device for biological\/biomedical research, and (e) evaluate the feasibility of the nanotube-based microarray devices.<br\/><br\/>It is expected that this project will advance microarray technology to enable more rapid study by biological and biomedical investigators in areas of genetic research. Ultimately,this technology may result in advancements in the study and treatment of human disease. Fundamentalinvestigations on synthesis, characterization, and property modeling of carbon nanotubes will benefit the technology of nanotube synthesis and engineering. Better understanding of nanotube growth mechanisms will enable improved synthesis and control of the nanotube structure. Development of structure\/property models for mechanical behavior of carbon nanotubes, along with synthesis\/structure relationships, will ultimately provide a tool for engineering their mechanical properties.","title":"NER: Microarray Devices of Aligned Carbon Nanotubes for Biological\/Biomedical Research","awardID":"0103012","effectiveDate":"2001-08-01","expirationDate":"2003-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"1517","name":"ELECT, PHOTONICS, & MAG DEVICE"}}],"PIcoPI":["496669","382994",156002],"PO":["219912"]},"60586":{"abstract":"The principal investigator will study theoretical properties of boosting algorithms. Topics include the assumption of weak hypotheses, the behavior of generalization error in the large time limit and during the process of boosting, a comparison to the optimal Bayes error, the performance in noiseless and noisy situations, overfitting and regularization, and the analogy between regression and classification boosting algorithms. The following goals will be addressed: <br\/><br\/>(I). Provide conditions and examples for the assumption of weak hypotheses to be valid, as well as some implications of the assumption on the generalization error.<br\/>(II). Further understanding of the overfitting behavior and regularization methods in boosting.<br\/>(III). Bring together the important recent developments in the areas of regression (e.g., thresholding) and classification (e.g., boosting), where increasingly different sets of tools have been developed. <br\/><br\/>Boosting algorithms are very useful tools for combining simple prediction rules sequentially and adaptively into more powerful prediction rules, and are of mutual interest to the fields of computer science, machine learning and statistics. A popular version of the algorithms, called AdaBoost, is shown to improve the fit on the existing data very quickly when more and more relatively simple \"rules of thumb\" are incorporated. In addition, the algorithm also improves the prediction of new outcomes very effectively. On the other hand, recent empirical evidence has shown that combining too many simple rules can `overfit' the existing data and deteriorate the performance in predicting new, unseen outcomes, when data are `noisy'. This project studies important theoretical properties of boosting algorithms, based on an analogy between the regression situation (when the outcomes are continuous numbers) and the classification situation (when the outcomes are discrete classes). This will be helpful in understanding how boosting works, in what situations, to what degree, and how to prevent `overfitting' and improve the performance when treating noisy data.","title":"Boosting for Regression and Classification: Some Views from Analogy","awardID":"0102636","effectiveDate":"2001-08-01","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1269","name":"STATISTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["334660"],"PO":["336837"]},"63875":{"abstract":"EIA-0116759<br\/>Angkul Kongmunvattana<br\/>University of Nevada Reno<br\/><br\/>MRI: Acquisition of SMP Clusters for Supporting Shared-Memory Metacomputing<br\/><br\/>This is a proposal for equipment acquisition under the Major Research Instrumentation (MRI) program to support research and student training in the development of high-performance distributed computing systems. The goal is to develop efficient system software for supporting a seamless programming environment on symmetric multiprocessor (SMP) clusters.","title":"MRI: Acquisition of SMP Clusters for Supporting Shared-Memory Metacomputing Research","awardID":"0116759","effectiveDate":"2001-08-01","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[164669],"PO":["557609"]},"77713":{"abstract":"This project focuses on instrumentation of parallel and distributed systems, integrated tool environments, and performance modeling of application-specific systems from high-level specification. The objects of the research include: Develop an integrated environment based on an instrumentation system (IS), so that a user may navigate among multiple performance tools to support analysis and diagnosis strategies; apply a structured approach for IS design and evaluation (P'RISM: PaRallel Instrumentation System Management) to develop new ISs according to system requirements and to provide feedback to other IS developers; select metrics for evaluating IS performance; develop a software architecture for scalable ISs and identify requisite technologies. Three primary activities support these objectives: (1) apply service request outcome analysis to derive a set of metrics for evaluating IS performance and further qualify those metrics that may be used for comparing performance of different ISs: (2) in coordination with the Paradyn project and the Parallel Tools Team at the Cornell Theory Center, complete a full IS performance evaluation study using analytical modeling, simulation, and measurement techniques; and (3) using P'RISM, develop the software architecture of an IS and develop a prototype based on this specification.","title":"Career: Integration of Systems Performance: Tools & Technologies in Research and Education","awardID":"0234252","effectiveDate":"2001-08-15","expirationDate":"2003-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}}],"PIcoPI":["438098"],"PO":["551992"]},"64524":{"abstract":"This proposal deals with new design techniques and chipsets for the coming generations of wireless systems, which provide a wider domain of services and work with different standards. The emphasis will be on the design of low power RF, analog and mixed-signal transceiver front-ends in standard MOS technology. Interdisciplinary research work is proposed at the architecture, block, circuit, and device levels leading to CMOS chipsets and single chip front-end design for both cellular and indoor wireless applications. Transceiver architectures for the implementation of multi-standard TDMA and CDMA wireless systems are proposed. Research is then proposed in three main thrusts encompassing RF, baseband and frequency synthesis CMOS design techniques. In the RF part, MOS modeling of GHz Nonlinearities will be studied and optimization techniques using device widths and bias currents as design parameters to achieve low power and high linearity will be developed. The proposed modeling and optimization techniques will then be used in the design of low noise amplifiers, linear power-efficient power amplifiers and mixers with controllable gain settings.<br\/><br\/>In the baseband part, a multi-standard Sigma-Delta data converter architecture is proposed for TDMA (GSM family and DECT) systems while a pipeline architecture is proposed for CDMA systems. Digitally programmable variable gain amplifiers and filters are proposed as part of a CMOS cell library for baseband signal processing. In the frequency synthesis part, techniques for multi-standard frequency synthesizers together with tuning schemes for multi-standard voltage controlled oscillators are proposed.<br\/>Based on the proposed ideas, several chipsets at the sub-system level will be demonstrated togther with two multi-standard single chip CMOS receivers at the system level, one for TDMA systems and one for CDMA systems (WCDMA, CDMA 2000).<br\/><br\/>A management plan for the proposed activities is provided and a discussion on the education component of this work is included. The proposed work should contribute to the preparation of the nation's critical mass of well trained engineers and scientists that is desperately needed in integrated circuits and systems for future wireless systems. This will enable us to compete effectively on the global scale.","title":"Mixed Signal Electronic Technologies: A Joint Initiative Between NSF and SRC: Radio Frequency CMOS Design Techniques for Multi-Standard Wireless Communications Applications","awardID":"0120225","effectiveDate":"2001-08-01","expirationDate":"2004-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["283481"],"PO":["562984"]},"57605":{"abstract":"The goal of this career development plan is two-fold. Research in<br\/>developing fast and accurate high-level energy-estimation tools and their use in designing new software and architectural techniques for energy efficient Java execution. The PI will also concentrate on formulating and developing an educational plan to provide a strong foundation in interaction of hardware and software systems and hardware system design for undergraduate and <br\/>graduate students.<br\/><br\/>The proposed research will provide an understanding of how to design energy-efficient systems from a holistic viewpoint considering both hardware and software components. In particular, it will provide new insights into exploiting the interaction of <br\/>hardware and software optimizations in reducing energy consumption. The first part of this research will focus on developing high-level energy estimation tools that are essential for designing the energy-efficient architectures and energy-conscious software components to support Java execution. The second part of this research will focus on providing a set of architectural techniques to reduce the energy consumption. The final part of this research will provide techniques for designing the software components of the Java runtime system to better exploit any energy-saving features present in the underlying hardware.","title":"CAREER: Energy-Efficient Architectures and Their Interaction with Software: A Java Perspective","awardID":"0093085","effectiveDate":"2001-08-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["549542"],"PO":["550859"]},"57616":{"abstract":"Storage systems have evolved from simple disks under the control of file servers to large, indepen-<br\/>dent disk-array systems connected to the network using Network-Attached Storage (NAS) and Storage<br\/>Area Network (SAN) technology. A unique feature of these storage systems is that they are directly<br\/>accessible by applications running on independent computers without the intervention of file servers.<br\/>A downside, however, is that these systems are very difficult to manage because of the increased de-<br\/>mands placed on them by data intensive applications and the number of storage devices connected to<br\/>the network. We propose to improve the management of such storage systems by automating the<br\/>storage management tasks and incorporating performance techniques to provide the system with the<br\/>\\intelligence\" to adapt to varying storage and workload conditions. In essence, this storage manage-<br\/>ment software system will control and manage all access to storage devices on the network, much as<br\/>an operating system manages and controls all access to a computer system. The storage manager will<br\/>allow applications to express their response time, availability, and bandwidth requirements, and then<br\/>use this information along with its knowledge of device behaviors and application access patterns to<br\/>decide how best to map data to devices such that application constraints and storage system goals<br\/>are met. Based on this work, we anticipate the development of user-friendly, self-managed storage<br\/>systems that are more cost-effective, efficient, and available than current systems that are configured<br\/>and managed manually.<br\/>Our education goal is to integrate performance evaluation tools and techniques into the Computer<br\/>Science curriculum at the University of New Hampshire. Students who will work on the storage<br\/>management system will require performance evaluation skills and our education plan addresses this<br\/>issue. Our long-term goal is to coordinate with industry and other institutions to implement a<br\/>self-managing storage system and make itavailable for research and educational purposes.","title":"CAREER: Automated Storage Manager - An Operating System for Input\/Output Devices on Storage Area Networks","awardID":"0093111","effectiveDate":"2001-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":[148166],"PO":["543507"]},"80452":{"abstract":"","title":"CAREER: RUI: Temporal\/Multi-dimensional Reasoning with Imprecision and Uncertainty","awardID":"0296042","effectiveDate":"2001-08-15","expirationDate":"2003-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["349921"],"PO":["491702"]},"61720":{"abstract":"This proposal concerns the exploration of new approaches to computational problems that arise in robotics, geographic information systems, and in biological applications. These approaches involve techniques that lie at the intersection of mathematics and computer science and the application of mathematical perspectives in the development on new algorithms to solve a variety of problems. The primary goal is to use techniques from Morse theory, homology theory, geometric group theory and combinatorics to study problems of shape, configuration, motion planning, and structure in computer science. Applications include computer graphics, visualization of scientific data, computational analysis of molecular docking problems and robotics. A key element is that this work will be done within an interdisciplinary team that includes researchers in computer science, biochemistry and chemistry at Duke, UNC and Stanford.<br\/><br\/>The research in this project will be important to advance our understanding in a number of important areas. Techniques developed will give new approaches to analyzing noise in data sets such as those from x-ray Crystallography, brain scans, satellite images, and ocean temperature. The robotics work will enhance our ability to create automated devices that perform tasks in dangerous or remote environments. And the biology work has as its long term goal the development of better computational tools to help biomedical researchers find appropriate molecules that can interact with","title":"Persistence, Combinatorial Morse Functions and Shape Spaces and their Applications","awardID":"0107621","effectiveDate":"2001-08-15","expirationDate":"2003-07-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1267","name":"TOPOLOGY"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["519404"],"PO":["562372"]},"62974":{"abstract":"This project will design and implement a distributed rendering platform that consists of off-the-shelf commodity components, yet delivers real-time photorealism on a large scale. This parallel rendering system was inspired by a similar system recently built at Princeton University. Proposed extensions to that work include a significant expansion in scale, new task-scheduling algorithms, a new integrated network design that links graphics card drivers to network interface card drivers in distributed Linux systems, and an extension of the Keller technique, called instant radiosity, to deliver real-time, global illumination. Design and implementation of the platform should provide graduate students in computer science with valuable hands-on experience in designing large-scale systems for distributed processing. The resulting platform should serve as a valuable research tool for several groups including the NSF ERC group, which will use visualization to explore product and process design for new fibers and films. The enabling code extensions, to widely-available open software systems that this project builds, will be freely available over the Internet.","title":"ITR\/SI: Design and Implementation of a Graphics Supercomputer from Commodity Components","awardID":"0113139","effectiveDate":"2001-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["490673","343491"],"PO":["565272"]},"62985":{"abstract":"The central focus of this proposal is the development of efficient algorithms for the storage and movement of data. Specifically, we are interested in algorithms that impact the performance of large multimedia data storage systems. In algorithmic terms, some of the principal challenges that arise in the context of multimedia data storage are: (a) deciding how many copies of each data item need to be stored, (b) determining the exact layout of data on a set of servers, (c) dealing with changing workloads and dynamic data access patterns. These related challenges require the development of efficient algorithms for optimizing data layout to maximize client satisfaction, monitoring the performance of data storage systems and scheduling the movement of large amounts of data.<br\/><br\/>Futhermore, what makes the issues that we consider even more significant is the fact that data storage and movement issues also arise within publicly share networks such as the Internet where the bandwidth can be dynamic and highly variable, and can result in a poor choice of paths chosen to transfer data in the network. One way to address this issue is to route data through specific holding points. By doing this we are able to increase throughput and decrease completion times by an order of magnitude to transfer data from several sources to a single destination. Algorithms related to this problem have been developed by us and are being tested with the Bistro framework, which is a framework for providing a data upload service such as one required by IRS for tax submission purposes. Our data movement algorithms are being used to schedule the transfer of data from many different locations to a final destination server.<br\/><br\/>While some specific instances of the individual problems have been considered earlier, there is no work dealing comprehensively with the range of issues that we focus on.","title":"ITR\/SY: Algorithms for Data Storage and Movement","awardID":"0113192","effectiveDate":"2001-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["538796","410098"],"PO":["279077"]},"60565":{"abstract":"Robust Limited Memory Hybrid Sparse Solvers<br\/><br\/>Sparse linear solvers can be broadly classified as being either 'direct' or 'iterative.' Direct solvers are based<br\/>on a factorization of the associated sparse matrix and are extremely robust. However, their memory requirements grow as a non-linear function of the matrix dimension because original zeroes fill-in during factorization.<br\/>The Krylov subspace (KSP) family of iterative methods are memory scalable, but their convergence<br\/>can be slow or fail altogether. This project concerns developing scalable hybrids than can be parameterized<br\/>to model the range from pure iterative to pure direct methods. We propose to develop parallel algorithms<br\/>and software engineering methods aimed at providing robust, limited memory hybrid solvers that satisfy the<br\/>computational demands of a variety of applications.<br\/>On the algorithmic front, our focus is on hybrids obtained by preconditioning KSP solvers using suitable<br\/>incomplete matrix factors. Such preconditioners are robust and widely applicable, but until recently they<br\/>were considered unsuitable for parallel computing. The main reason is that the sparse triangular solves for<br\/>applying the preconditioner become a bottleneck due to the relatively high latency of communication. We<br\/>have recently developed a latency tolerant 'selective-inversion' scheme that overcomes this problem to yield<br\/>an efficient and scalable implementation. In this project, we propose developing parallel sparse factorization<br\/>techniques that are efficient for the entire spectrum of fill-in. We will develop a new 'supernodal diagonal<br\/>row block' formulation for scalable incomplete factorization. We will also consider innovative ways of<br\/>combining symbolic (level of fill) and numeric (threshold) strategies to specify fill-in to be either retained<br\/>or discarded. Additionally, our algorithmic framework enables us to provide a single, unified, extensible<br\/>implementation of hybrids for symmetric positive definite, symmetric indefinite, and nonsymmetric systems.<br\/>On the software front, we define a new 'usage model' based 'reverse engineering' process to develop a high-performance domain specific solver as a smart composite of several methods. Our premise is that the right composite solver is domain specific; substantial performance gains can be realized by selecting the right combination of underlying methods to match linear system attributes. We will obtain a uniform interface to a variety of parallel sparse solver software by developing an object-oriented sparse template library that utilizes parameterized polymorphism. Composites will be instantiated by using this template library and a scripting language that supports parallel computing using MPI.<br\/>Our design goals and performance targets will be keyed to three large-scale computational science applications. The first concerns computational methods for advanced optimization; this application requires robust indefinite solvers. The second is a structural mechanics application for modeling cracks and fractures. The third application involves large sparse eigenvalue problems that arise in quantum molecular dynamics.<br\/>Our project represents a concerted effort to resolve critical research issues in the area of parallel sparse<br\/>matrix computations. Our goal is to develop the next generation of sparse solvers by combining research in<br\/>parallel algorithms and software engineering.","title":"Robust Limited Memory Hybrid Sparse Solvers","awardID":"0102537","effectiveDate":"2001-08-15","expirationDate":"2006-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}}],"PIcoPI":["550407"],"PO":["565272"]},"60697":{"abstract":"0103175<br\/>Lindsay<br\/><br\/>This proposal was submitted in response to the solicitation \"Nanoscale Science and Engineering\" (NSF 00-119). It brings together experts in organic photochemistry, experimental and theoretical physicists and engineers in a University (Arizona State)-Industry (Motorola)collaboration aimed at developing nanoscale molecular optoelectronic devices based on paradigms from photosynthetic electron transfer.<br\/><br\/>The first phase of the project builds on the PIs' current work on the basic building blocks of molecular electronic devices. They will use bifunctionalized molecules covalently bonded at one end to a gold-coated conducting AFM tip and at the other end to a gold substrate. In this way they will measure the electrical properties of simple molecular insulators (n-alkanes) and molecular wires (carotenoids) at the single molecule level. These measurements will be compared to first-principles simulations, with the goal of developing both theory and experiment until they have a reasonably accurate description of transport in both the molecules and their contacts to the metal electrodes. Armed with this information, they will insert the molecules into nano-scale gaps in gold electrodes on oxidized silicon wafers.These devices will be made at Motorola. Final gap fabrication uses active-feedback control of electrochemical deposition, a technique developed by a consultant to the group.The goals of this step are to (1)make two electrode devices on wafers that can be characterized in terms of the single-molecule AFM data and (2) explore the current-voltage characteristics of these devices with greater flexibility than possible in the AFM (for example, making temperature-dependent measurements).<br\/><br\/>The second phase will focus on the electronic properties of optically excited molecules, and molecules in high-energy charge-separated states. The use of light to provide additional inputs to molecular-scale electronic devices offers several advantages, and may lead the way to the design and fabrication of technologically useful constructs. They will use much the same approach as outlined above, but with the addition of controlled optical excitation of chromophores. They will start with the carotenoids, as the simplest system, but will go on to study molecules containing porphyrins and fullerenes that are built to make transitions into long-lived triplet states, or into long-live charge-separated states. These systems present theoretical as well as experimental challenges, and they propose computational approaches for dealing with nuclear-relaxation on excitation or charging and for dealing with highly correlated molecular electronic states.<br\/><br\/>They propose a single-molecule opto-electronic switch as a candidate device on which to focus the long-range efforts of the group. The device might prove useful as an optoelectronic molecular-scale building block. But developing the science and technology that would go into building the device and understanding it are the main motivation for this project.<br\/><br\/>This group provides an extraordinary opportunity for training minority students in multidisciplinary approaches to nanoscience in both academic and industrial research environments.","title":"NIRT: Nanoscale Molecular Opto-Electronics","awardID":"0103175","effectiveDate":"2001-08-15","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"1504","name":"GRANT OPP FOR ACAD LIA W\/INDUS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"1517","name":"ELECT, PHOTONICS, & MAG DEVICE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"1674","name":"NANOSCALE: INTRDISCPL RESRCH T"}}],"PIcoPI":["391314","162520","446323","529311",156122],"PO":["508629"]},"61313":{"abstract":"This research aims to expand and redefine the role of prediction-based techniques for parallel and distributed systems. First, we reduce barrier synchronization overhead by predicting the final producer of a<br\/>value before the barrier. This producer identification allows the consumer to speculatively proceed past the barrier, only waiting on the actual production as needed. Second, we introduce the slipstream<br\/>paradigm to multiprocessor systems. A redundant version of each parallel thread runs concurrently, its execution reduced by speculatively removing long-latency events, such as shared memory writes. The reduced thread dynamically detects sharing patterns, which are used by the original thread to optimize its coherence and synchronization actions, improving overall performance. Finally, we investigate the use of producer-validated message prediction to reduce traffic in a message-passing environment. Both the producer and the consumer of a message predict its contents, using redundant prediction histories. Since the producer knows the results of the consumer's prediction, it need only send those data that were not correctly<br\/>predicted. This traffic reduction is significant in environments in which communication is much more costly than computation, such as networked embedded systems. These three avenues of research represent an excursion into new frontiers of prediction-based technology, resulting in parallel systems that scale to new levels of availability and performance.","title":"New Prediction Paradigms for Parallel and Distributed Systems","awardID":"0105628","effectiveDate":"2001-08-01","expirationDate":"2003-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["332138","518384"],"PO":["180163"]},"51215":{"abstract":"The proposed work addresses the problem of reliable robotic assembly. The project seeks to develop powerful computer techniques to ensure proper assembly of 3D polyhedral parts undergoing 6d spatial motions. The work will culminate in custom-aided-design software capable of 1) assessment of whether two parts can be reliably assembled using only contact forces as environmental input, and 2) producing a description of the \"best admittance\" behavior for the specified task.","title":"Admittance Selection for Spatial Force-Guided Assembly","awardID":"0010017","effectiveDate":"2001-08-15","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":[130705],"PO":["335186"]},"65636":{"abstract":"Carnegie-Mellon University is hosting the ROBOCUP-2001: The Fifth International Symposium, Competitions, and Demonstrations, in Seattle, Washington in the Summer 2001. The event is sponsored by the American Association for Artificial Intelligence (AAAI). The award will pay for the travel of 40 students, $500\/person, to the ROBOCUP.","title":"Student Travel for Robocup 2001 Conference ( Seattle, Washington)","awardID":"0125538","effectiveDate":"2001-08-15","expirationDate":"2002-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["518535"],"PO":["234178"]},"80597":{"abstract":"","title":"Workshop: Developing a Common Wireless Networking Infrastructure","awardID":"0296188","effectiveDate":"2001-08-01","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["539039","394642"],"PO":[209879]},"62843":{"abstract":"Computer Scientists have been challenged by the existence of<br\/>remarkable algorithms that work well in practice, but whose<br\/>theoretical analyses suggest that these algorithms should perform<br\/>poorly or are inconclusive. The root of this problem is that<br\/>traditional theoretical analyses measure the performance of<br\/>algorithms on their worst inputs. This research analyzes the<br\/>performance of algorithms using smoothed analysis, a new measure of<br\/>the performance of algorithms that can better predict practical<br\/>performance. Using smoothed analysis, this research aims to explain<br\/>the good practical performance of some algorithms that are famous<br\/>for outperforming pessimistic worst-case analyses.<br\/><br\/><br\/> In particular, algorithms that take real or complex inputs, such as<br\/>those that usually occur in scientific and engineering applications,<br\/>are examined under random perturbations of their worst-case inputs.<br\/>The most famous of these, the simplex method for linear programming,<br\/>was the subject of the paper introducing smoothed analysis. Yet, this<br\/>work only investigated one rarely-used pivot rule. This research<br\/>attempts smoothed analyses of the simplex method under more commonly<br\/>used pivot rules. It also considers smoothed analyses of interior<br\/>point methods and algorithms for convex programming. An attempt is<br\/>being made to extend this analysis to algorithms that take discrete<br\/>inputs.","title":"ITR\/SY(CISE): Why algorithms work well in practice: pertubation-based average-case analysis of the simplex algorithm and beyond","awardID":"0112487","effectiveDate":"2001-08-01","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["483530"],"PO":["543507"]},"62943":{"abstract":"Open source software relies on the expertise of developers around the world, who volunteer to produce software collaboratively. Their mode of collaboration requires participants to share the results of their work freely with others. By revealing the source code of the programs on which they work, developers participating in these collaborations are able to design new features, fix bugs in programs, and tailor the software to suit their own needs. The attractiveness of engaging in this method of producing software in the Internet environment has led to the emergence and growth of specialized, online virtual communities whose members follow rather clearly established procedures in performing their professional tasks, but are otherwise bound together by loose rules of association. This project inquires into the sustainability of such organizations, and the likely extent of their domain of viability-in terms of the kinds of goods and services that might reliably be supplied in this way. The investigation has three more proximate empirical objectives. The first is to identify typical patterns in the evolution of these communities' informal organizational structures and their norms of conduct. The development of procedural authority, and other means of resolving conflicts among individuals in regard to the substance of their work, and of verifying and validating their contributions, are subjects for special study. The second objective is to characterize the distribution of effort input within these communities and its relationship to the structure and distribution of internal \"rewards,\" and derived external benefits for different levels of participation. These tasks will be approached through analysis of passively collected data, participant responses to email survey questionnaires, and in-depth case histories of particular communities. A third and larger goal is to understand the dynamics of these \"virtual communities\" and the similarities and differences they exhibit in comparisons with collaborative organizations involving spatially distributed academic (\"open science\") researchers whose work is enabled by computer-mediated telecommunications","title":"Economic Organization and Viability of Open Source Software","awardID":"0112962","effectiveDate":"2001-08-15","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["228091"],"PO":["495796"]},"64901":{"abstract":"EIA -0121824<br\/>Roberts, Fred S<br\/>Rutgers University<br\/><br\/>Special Projects: DIMACS Workshop: Complexity in Biosystems: Innovative Approaches at the Interface of Experimental Modeling and Computational Simulation<br\/><br\/>This workshop focuses on the new research area of complex biosystems modeling and simulation, bringing together scientists who are developing this field along with interested newcomers. It will serve to build a community of researchers across disciplinary boundaries in computer and mathematical sciences and biology, leading to a continuing collaborative working group in this area. The workshop proposal requests participant support for 3 nonlocal organizers and 18 invited speakers, with additional participant support set aside for nonlocal graduate student participation.","title":"Special Projects: DIMACS Workshop: Complexity in Biosystems: Innovative Approaches at the Interface of Experimental Modeling and Computational Simulation","awardID":"0121824","effectiveDate":"2001-08-01","expirationDate":"2002-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["264120"],"PO":["329035"]},"75736":{"abstract":"Memory management consumes a great deal of time on today's computer systems, and will take even longer in the future. Software techniques have successfully hidden most of this overhead on personal workstations by shifting the work to times when the system is waiting for user<br\/>interaction. Such techniques are less effective on SMP servers, where the overall computational overhead is what matters. The Dynamic Memory Management Unit (DMMU), a special-purpose hardware mechanism based on bitmaps and combinational logic can greatly diminish this overhead. Preliminary results for three languages show that this approach is much<br\/>faster than software memory allocation, and consumes only slightly more memory than software-allocation techniques. This proposal calls for the integration of this hardware unit into SMP systems, which would allow concurrent garbage collection in multithreaded-multiprocessors<br\/>environments. This can speed up the performance of server applications written in Object-Oriented languages such as C++ and Java.","title":"Concurrent Garbage Collection for Multithreaded-Multiprocessor Environments","awardID":"0224862","effectiveDate":"2001-08-01","expirationDate":"2005-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["209728"],"PO":["565272"]},"65407":{"abstract":"Computer Science (31)<br\/>This project is developing a curriculum framework for undergraduate and graduate programs in Information Assurance. The framework includes: identification of broad areas of knowledge considered important for practicing professionals in information assurance, identification of key learning objectives for each of these areas, identification of a body of core knowledge and skills that all programs should contain, and a model curriculum including scope and sequence.<br\/><br\/>The framework's development is undertaken via a workshop of leading information assurance educators leading to a draft document which will then be widely distributed for comment and dissemination.","title":"Information Assurance Curriculum Development","awardID":"0124409","effectiveDate":"2001-08-15","expirationDate":"2003-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"7427","name":"CCLI-EDUCATIONAL MATERIALS DEV"}}],"PIcoPI":["551341"],"PO":["300027"]},"63108":{"abstract":"Current interfaces employ textual representations, and restrict people from exploiting their spatial abilities to assist in dealing with the increasingly expanding information sphere they confront. This project is motivated by the view that spatial and temporal organization of images can serve as effective interface components and may offer multiple advantages over textual lists of titles and URLs. It explores several image-based applications: (1) Visual bookmarks and visual site indexes, that replace textual URLs with images from the pages; (2) Visual browsing summaries and activity histories, that use images as a way of accessing previous web-based activities; (3) Image augmented query results, that add images to the results of web searches to help disambiguate them.","title":"ITR\/SY Proposal: Image-Based Information Access and Organization","awardID":"0113892","effectiveDate":"2001-08-15","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["550599"],"PO":["563751"]},"69609":{"abstract":"","title":"CAREER: Effective Grid Programming with EveryWare and G-commerce","awardID":"0196500","effectiveDate":"2001-08-01","expirationDate":"2007-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}}],"PIcoPI":["402357"],"PO":["565272"]},"62845":{"abstract":"Proposal #0122495<br\/>Florida State University<br\/>Van Hoeij, Mark<br\/><br\/>A one day meeting, an East Coast Computer Algebra Day (ECCAD), will be held at Florida State University, Tallahassee, Florida, on Saturday, May 5, 2001. The meeting is the eighth of the series, which has been held at a variety of US East Coast locations since 1994. We expect 60-80 participants will be from the computer algebra research community or interested in scientific\/engineering applications of computer algebra, drawn from the eastern half of North America, but especially from the East Coast of the United States. The meeting includes invited talks and contributed poster\/software demo sessions, covering the breadth of computer algebra: algorithms, software, and applications. We are requesting funding to cover travel expenses of US-based participants. The organizing committee intends to give preference to funding students and recent Ph.Ds who plan to make a presentation at the meeting.","title":"East Coast Computer Algebra Day 2001","awardID":"0112495","effectiveDate":"2001-08-15","expirationDate":"2002-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["550445"],"PO":["179846"]},"61305":{"abstract":"Kleene algebra with tests (KAT) is a system for describing and<br\/>manipulating computations and assertions. KAT allows propositional logic<br\/>and the algebra of programs to be integrated seamlessly into a single<br\/>system that is remarkably powerful in expressive and deductive<br\/>power, yet computationally and conceptually simple.<br\/><br\/>KAT has many applications in computer science. In particular<br\/>it has recently been used to specify and verify various communication<br\/>protocols and common compiler optimizations. It does so more simply<br\/>and with less effort than more traditional systems such as Hoare<br\/>Logic.<br\/><br\/>In this proposal, we propose (i) to further develop the theory of KAT;<br\/>(ii) to produce a research monograph of significant scope giving a<br\/>comprehensive introduction to KAT; and (ii) to continue to investigate<br\/>the use of KAT in practical program verification.","title":"Kleene Algebra","awardID":"0105586","effectiveDate":"2001-08-01","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["320931"],"PO":["543507"]},"64517":{"abstract":"This is funding to subsidize travel and housing expenses of students selected to participate in the Student Research Workshop to be held in conjunction with the 2nd Annual Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL-2001), which will take place June 3-7, 2001 in Pittsburgh. The intimate workshop format will encourage student participants to begin building a rapport with established researchers. Students will have sufficient time to present their research (25 minutes) and then receive feedback from a panel of established researchers in the field (15 minutes). The workshop will provide students with invaluable exposure to outside perspectives on their work at a critical time in their research, and will also allow them to put their work into perspective based on feedback from the panel and from fellow participants.","title":"Workshop Proposal for NAACL-2001 Student Research Workshop, Pittsburgh, PA.","awardID":"0120182","effectiveDate":"2001-08-01","expirationDate":"2002-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}}],"PIcoPI":[166424],"PO":["564456"]},"80423":{"abstract":"","title":"ITR: Bugscope: An IT Test Bed for Sustaining Educational Outreach","awardID":"0296013","effectiveDate":"2001-08-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["239244","239245"],"PO":["564318"]},"60601":{"abstract":"0102710<br\/>Donald, Bruce<br\/>Dartmouth College<br\/><br\/>CISE Postdoctoral Associates in Experimental Computer Science: Physical Geometric Algorithms and Systems for High-Throughput NMR<br\/><br\/>While automation is revolutionizing many aspects of biology, the determination of three-dimensional protein structure remains an expensive task. Traditional automated and semiautomated approaches to protein structure determination through nuclear magnetic resonance (NMR) spectroscopy require dozens of experiments and months of spectrometer time, making them unsuitable for high-throughput automation. The research proposed is to develop algorithms and systems for determining protein structure from only a few key NMR spectra. The system will use algorithms similar to and adapted from physical geometric algorithms, pattern recognition and machine vision, signal processing, and robotics, in order to analyze spectra, assign spectral peaks to atom interactions, compute secondary structure, and estimate the global fold. Previously developed software, JIGSAW, represents NMR data with graphs encoding potential interactions between amino acid residues. JIGSAW applies graph algorithms to find subgraphs encoding the secondary protein structure. The postdoctoral research associate will build on the insights of JIGSAW by assisting to 1) integrate automated analysis of geometry and correlations in three-dimensional input spectra, 2) prove correctness, completeness, and complexity results within a random graph formalism, 3) extend JIGSAW to larger proteins, and 4) utilize long-range interactions in order to estimate three-dimensional protein structure.","title":"Postdoctoral: Physical Geometric Algorithms and Systems for High-Throughput NMR Structural Biology","awardID":"0102710","effectiveDate":"2001-08-01","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":["213293"],"PO":["564318"]},"80445":{"abstract":"","title":"Planning and Workflow Management for a Virtual Laboratory for Structural Biology","awardID":"0296035","effectiveDate":"2001-08-17","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}}],"PIcoPI":["379546"],"PO":["565272"]},"62868":{"abstract":"ITR Small Proposal <br\/>0113385\/0112591<br\/>Sayeed\/Popovic<br\/><br\/>Abstract<br\/><br\/>Reliable and seamless wireless connectivity in varied environments is a necessary requirement for the rich and diverse communications of the future. Space-time processing has emerged as a key enabling technology for future wireless communications: signal space dimensions are fundamental to reliable communication and antenna arrays augment the traditional dimensions of time and frequency with the spatial dimension. While recent theoretical and technological advances provide a tremendous boon for modern communications, the state-of-the-art is far from realizing the full potential of space-time processing due to significant gaps in our current understanding on two fronts:<br\/><br\/>Fundamental mechanisms underlying the interaction of the space-time channel with the signal space in spatial, temporal, and spectral dimensions.<br\/><br\/>Jointly optimized design of front-end hardware, antenna arrays, and signal processing algo-rithms. <br\/><br\/>The overall goal of the work proposed here is an integrated approach to the design of antenna array hardware and space-time processing algorithms for significantly improved wireless link performance<br\/>at reduced cost and complexity.","title":"ITR\/SI: Collaborative Research: Integrated Signal Processing and Antenna Array Design for Diversity Wireless Links","awardID":"0112591","effectiveDate":"2001-08-01","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["544688"],"PO":["564898"]},"60779":{"abstract":"0103675<br\/>Katsinis, Constantine<br\/>Drexel University<br\/><br\/>CISE Postdoctoral Associates in Experimental Computer Science: An Interconnection Network Architecture for Petaflops Computing<br\/><br\/>Research in high-performance computer systems is proposed that will expand the one-dimensional prototype Simultaneous Optical Multiprocessor Exchange Bus (SOME-Bus) interconnection network into a two-dimensional architecture. Recent work on the SOME-Bus over the past few years has raised several important issues (e.g., network interface design, network management, programming, applications and performance) that remain open and challenging as they relate to the potential two-dimensional bus. The experimental and theoretical work of the postdoctoral research associate will contribute to multidisciplinary research in computer architecture, performance analysis, optoelectronic devices, and VLSI design. The associate's research training will be enhanced by interactions with other nearby academic and industry groups working on similar high-performance architectures, and limited contributions to graduate student projects and courses in computer architecture.","title":"Postdoc: An Interconnection Network Architecture for Petaflops Computing","awardID":"0103675","effectiveDate":"2001-08-15","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":["528361"],"PO":["564318"]},"64717":{"abstract":"EIA-0121167<br\/>David R. Foster<br\/>Harvard University<br\/><br\/>SGER: Digital Government: Harvard Forest Carbon Exchange Modeling Work in Connection with Digital Aerial Image Analysis by UMass, Amherst.<br\/><br\/>This grant will support preliminary explorations for applying digital video aerial image analysis to long-term issues of global warming, in particular carbon cycle modeling, in the government arena. Many government agencies are already using GIS heavily, but in a less dynamic way, relying on single images in time, without fine-grain time references. This project will explore government uses of real-time imaging, at resolutions beyond what can be achieved with commercial satellite images, allowing the digital film to be geo-referenced, integrated with data streams from other sensors, and viewed in 3D through polarized glasses.","title":"Digital Government: Harvard Forest Carbon Exchange Modeling Work in Connection with Digital Aerial Image Analysis by UMass, Amherst","awardID":"0121167","effectiveDate":"2001-08-01","expirationDate":"2003-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}}],"PIcoPI":["558020"],"PO":["371077"]},"63507":{"abstract":"Proposal #0115611<br\/>Wang, Paul S.<br\/>Kent State University<br\/><br\/>Following the NSF sponsored IAMC'99 Workshop and reinforcing an emerging research trend in making mathematical computation and data accessible on the Internet, the workshop provides a timely forum for researchers to further exchange ideas and discuss standards. The workshop will have invited talks, contributed papers, panel discussions, and system demonstrations. The results will be made available on the Web. An article overviewing the state of the art and future developments will be prepared for wide dissemination (e.g. publication in the magazine Science or Scientific American). An IAMC working group will be organized to foster research collaboration after the workshop.<br\/><br\/>The IAMC workshop is being organized by Angel Diaz of IBM, Norbert Kajler of Ecole des Mines de Paris, and Paul S. Wang (the PI) of Kent State University as a pre-conference activity of ISSAC'01. The requested budget of $4,200 covers travel reimbursements and honoraria for invited speakers. With this support, the workshop will charge no registration fee for attendees. The workshop and this proposal have strong support from ISSAC'2001 organizers.","title":"Conference Support: Workshop on Internet Accessible Mathematical Computations, 7\/22\/2001","awardID":"0115611","effectiveDate":"2001-08-15","expirationDate":"2002-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["277844"],"PO":["179846"]},"80524":{"abstract":"","title":"REU: Performance Measurement and Evaluation of Multithreaded Systems","awardID":"0296115","effectiveDate":"2001-08-23","expirationDate":"2003-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["13545","533936"],"PO":["289456"]}}