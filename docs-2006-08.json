{"109406":{"abstract":"The LETRAS project investigates novel approaches to development of Machine<br\/>Translation (MT) technology, with the goal of establishing a general framework<br\/>that supports building MT prototype systems for languages for which only<br\/>limited amounts of data and resources in electronic form are available. The<br\/>research focus of the project is on automatic learning of translation<br\/>transfer-rules from limited amounts of elicited bilingual data. A new run-time<br\/>translation \"engine\" maps source language sentences to their target language<br\/>equivalents, by building a large structure of possible partial translations<br\/>and then applying effective search techniques for recovering the best<br\/>translation. In the last stage, an automatic rule refinement module helps the<br\/>system learn how to correct and improve its imperfect translation rules, based<br\/>on feedback on translation errors provided by users. MT prototype systems for<br\/>several language pairs are being constructed as an integral part of the<br\/>project and in collaboration with external research groups. The prototypes<br\/>guide our research and test out our new ideas. At the same time, our<br\/>collaborations with local researchers and native communities promote the<br\/>development of information technology for native languages and educate local<br\/>researchers with our state-of-the-art MT research. The prototypes include a<br\/>Hebrew-to-English MT system (with University of Haifa, Israel); an<br\/>Inupiaq-to-English MT system (with University of Alaska, Fairbanks, and the<br\/>Inupiat Heritage Center in Barrow, Alaska); and a Karitiana-to-Portuguese MT<br\/>system (with University of Sao Paulo, Brazil). Support for the Alaska<br\/>collaboration is being provided by NSF's Office of Polar Programs (OPP), and<br\/>support for the collaborations with Israel and Brazil is being provided by<br\/>NSF's Office for International Science and Engineering (OISE). OISE is also<br\/>providing funding for a planning trip to Bolivia to explore a possible <br\/>Aymara-to-Spanish project. The potential long-term impact of the project<br\/>is profound - enabling the development of Machine Translation for many<br\/>languages of the world, which in turn opens the door for active participation<br\/>of native and minority communities in the information-rich activities of the<br\/>21st century.","title":"LETRAS: A Learning-based Framework for Machine Translation of Low Resource Languages","awardID":"0534217","effectiveDate":"2006-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7299","name":"Catalyzing New Intl Collab"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7316","name":"EAPSI"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7274","name":"HUMAN LANGUAGE & COMMUNICATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}},{"dir":{"id":"14","name":"Office of OFFICE OF POLAR PROGRAMS                ","abbr":"OPP"},"div":{"id":"1403","name":"Division of ANTARCTIC SCIENCES DIVISION","abbr":"ANT"},"pgm":{"id":"5221","name":"ARCTIC SOCIAL SCIENCES"}}],"PIcoPI":["502549","562859"],"PO":["565215"]},"122331":{"abstract":"This award enables a planning workshop to initiate a series of meetings and actions on Cyber Physical Systems (CPS). The meeting is being held in Arlington, VA, July 26-27, 2006. The goal is to forge a multi-domain community of researchers who will focus on CPS as a unified research area. The planning meeting draws together an inclusive group of experts who are research and thought leaders from key relevant domains: real-time systems, embedded systems, systems software and middleware, control systems, wired and wireless networks, and mobile systems. The planning workshop will develop a strategy and plan for community-scale workshops to assess research needs and develop research roadmaps in this emerging area.","title":"NSF Planning Meeting for Cyber-Physical Systems","awardID":"0643274","effectiveDate":"2006-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}}],"PIcoPI":["461012"],"PO":["561889"]},"116930":{"abstract":"The persistent drive for increased performance and the contradictory need to reduce power consumption pose serious challenges to the advancement of embedded computing. Reconfigurable computing answers these by providing a flexible medium for hardware-based execution. Compute-intensive sections of application code are implemented in reconfigurable hardware, such as field-programmable gate arrays (FPGAs), to accelerate the application, reduce its power requirements, or both. A traditional microprocessor executes application parts not implemented in hardware, providing a mixed software\/hardware execution model. However, unlike traditional custom hardware, the actual functionality of reconfigurable hardware is changeable during execution to implement different hardware functions within and across applications. The performance and power benefits of hardware implementation are therefore complemented by the flexibility to address computing needs that change over time, where that time-span may be measured in days, seconds, or even microseconds. Reconfigurable computing is therefore a powerful and compelling computing paradigm for future embedded computing.<br\/><br\/> This project addresses one of the key barriers to the use of reconfigurable computing in mainstream embedded devices: the lack of systems software support appropriate to modern multi-tasking multi-threaded embedded systems. In this research, the project is developing OS-level techniques to schedule and allocate reconfigurable hardware between multiple executing threads and processes in order to achieve the best overall system-level performance and power-savings. Scheduling topics under investigation include: dynamic binding of compute-intensive functions to hardware or software, choosing between different hardware implementations targeting different area\/performance\/power tradeoffs, adaptive scheduling based on changing system loads, and predictive pre-fetching of hardware functions. With powerful run-time scheduling algorithms, embedded devices of the future will reap the full potential of reconfigurable computing.","title":"CSR---EHS: Scheduling Techniques for Reconfigurable Embedded Computing","awardID":"0615358","effectiveDate":"2006-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["377736"],"PO":["561889"]},"116842":{"abstract":"Abstract:<br\/><br\/>This collaborative project studies dynamical systems characterized by a combination of hybrid and probabilistic behavior. Hybrid behavior is characterized by discrete switching between system modes and continuous evolution within a mode. Such systems frequently arise in a wide range of applications, from power electronics and communication networks to economics and biology. In this research, a new modeling framework for such systems is developed, which supports external variables, compositional reasoning, and nondeterministic as well as probabilistic transitions. New stability criteria for such probabilistic hybrid systems are obtained. In contrast with existing results, they are formulated in terms of two independent components: a family of Lyapunov functions (one for each continuous mode) and a slow-switching condition of an average-dwell-time type. This modularity has the benefit of decoupling the search for Lyapunov functions from the verification of the desired properties of the discrete dynamics. The latter task is the focus of the project, and is treated using two complementary methods: one based on proving an invariant property, and another based on solving an optimization problem. These theoretical results are supported by development of new software tools.","title":"CSR--EHS: Collaborative Research: Verification of Probabilistic Hybrid Systems: Stability and Beyond","awardID":"0614993","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["523280"],"PO":["561889"]},"116732":{"abstract":"Abstract:<br\/><br\/>This collaborative project studies dynamical systems characterized by a combination of hybrid and probabilistic behavior. Hybrid behavior is characterized by discrete switching between system modes and continuous evolution within a mode. Such systems frequently arise in a wide range of applications, from power electronics and communication networks to economics and biology. In this research, a new modeling framework for such systems is developed, which supports external variables, compositional reasoning, and nondeterministic as well as probabilistic transitions. New stability criteria for such probabilistic hybrid systems are obtained. In contrast with existing results, they are formulated in terms of two independent components: a family of Lyapunov functions (one for each continuous mode) and a slow-switching condition of an average-dwell-time type. This modularity has the benefit of decoupling the search for Lyapunov functions from the verification of the desired properties of the discrete dynamics. The latter task is the focus of the project, and is treated using two complementary methods: one based on proving an invariant property, and another based on solving an optimization problem. These theoretical results are supported by development of new software tools.","title":"CSR--EHS: Collaborative Research: Verification of Probabilistic Hybrid Systems: Stability and Beyond","awardID":"0614414","effectiveDate":"2006-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["517826"],"PO":["561889"]},"116644":{"abstract":"ABSTRACT<br\/>0613889<br\/>Moshe Y. Vardi<br\/>William Marsh Rice University<br\/><br\/>SoD-HCER: A Theory of Automated Design<br\/><br\/><br\/>As computerized systems are becoming larger, more complex, and increasingly distributed, an increasing portion of the design effort goes into the validation and verification effort. There is a growing need for formal methods that guarantee systems reliability, correctness, and efficiency by design. This project will address this challenge by contributing to the the establishment of a theory of automated design of computing systems. The focus of this project is on moving algorithmic techniques for assertion-based automated verification into assertion-based automated design, building on emerging standard temporal assertion languages such as OVL, PSL, and SVA. The new techniques will enable the development of systems of higher quality within shorter design cycles and with lower costs. The vision for Science of Design underlying this proposal is that of design automation, in which the process of converting formal specification to implementation is, to a major extent, automated. <br\/>The implication is that a major portion of the manual design effort should go into the development of high-level specification, since much of the implementation effort can then be automated. The ultimate goal of this project is a demonstrable improvement in design productivity and quality.","title":"SOD:HCER: A Theory of Automated Design","awardID":"0613889","effectiveDate":"2006-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7372","name":"ITR-SCIENCE OF DESIGN"}}],"PIcoPI":["565263"],"PO":["564388"]},"116897":{"abstract":"This research project investigates how to extend the scalable model of<br\/>dynamic multithreading to encompass three key functionalities ---<br\/>multiprogramming, interprocess communication, and support for I\/O ---<br\/>without requiring painstaking manual planning, tuning, or configuring. <br\/>The research focuses particularly on using provably good<br\/>``feedback-driven'' strategies to accomplish this end. The<br\/>researchers are developing a multiprogrammed multithreaded system to<br\/>embody these strategies and provide a research vehicle for discovering <br\/>additional properties of interacting adaptive jobs. Among the<br\/>techniques under study is ``history-based feedback,'' which offers a<br\/>promising foundation for provably effective scheduling and resource<br\/>allocation strategies. <br\/>This research hopes to make multiprocessors more efficient and easier<br\/>to use by the vast majority of computer users, not just by expert<br\/>computer scientists. Open-source software developed in the course of<br\/>the research is freely available to anyone on the World Wide Web. <br\/>Course materials on multiprocessor scheduling are distributed via the<br\/>MIT OpenCourseWare project.","title":"CSR-AES: Feedback-Driven Adaptive Multithreading","awardID":"0615215","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["548187","471720"],"PO":["493916"]},"117755":{"abstract":"Project Proposed:<br\/><br\/>This project, acquiring virtual reality infrastructure, aims at supporting research in computer graphics, visualization, and virtual reality. Spanning the areas of artificial intelligence, computer game development for computer science education, anatomy visualization, surgical simulation, and statistical data visualization, the infrastructure would service Computer Games for Learning (Edutainment), Virtual Surgery Simulation, and Scientific Data Visualization. The facility might enable experiments in the use of immersive networked virtual environments for distance education. On surgery simulation the current projects expand into an immersive environment with direct user manipulation of virtual objects through haptic devices, supplying a better sense of reality for both patients and surgeons. Providing a different perspective of data visualization, manipulation, and mining, the infrastructure would contribute to a new initiative on virtual environment construction through video images.","title":"MRI: Acquisition of a Virtual Reality Testbed for Research and Teaching in Visualization, Simulation, and Edutainment","awardID":"0619340","effectiveDate":"2006-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}}],"PIcoPI":[311710,"564109",311712,"352325","511368"],"PO":["557609"]},"116579":{"abstract":"Directorate for Computer and Information Science and Engineering (CISE)<br\/>Division Computer and Network Systems (CNS)<br\/>Science of Design (SoD) Program<br\/><br\/>Proposal Number: 0613550 <br\/>P\/I: Steven Tanimoto <br\/>PI's Department: Computer Science and Engineering <br\/>Institution: University of Washington<br\/>Award: $ 449,642<br\/><br\/>Title: \"SoD-TEAM: Problem-Solving Methodology in Collaborative Design\"<br\/><br\/>This project focuses on software tools that facilitate collaboration among members of a design team. The project permits a design team to manage the explored portions of a space of alternative designs. In addition, it supports evaluation and communication among team members about design alternatives. One goal of the project is to develop a methodology and a framework for software-designers that is based on studies that will lead to understanding how to support end-user exploration of solution-spaces. In addition the project facilitates collaboration among designers with different interests, expertise and the need to have both private as well as share common group-based designs. The theory of problem solving that forms the basis of the project involves \"state-space search.\" The state-space search methodology applies to both formal problem solving (where automation without human intervention is possible) and to complex design problems in which some aspects can be \"fuzzy\". However, the approach proposed with this project is to merge the two genres of software and create a new one: software that allows a collaboration among automatic design processes and human designers, and one that makes visible not only the details of particular designs but also a substantial piece of the space of possible designs. In support of this project, the proposers developed the core of an initial research prototype software system to support design with transparent display of design spaces. This system, T-Star, implements a human interface that supports problem-solving using an approach from artificial intelligence that includes a view of the portion of the solution space that has been explored so far. Having a visual rendition of the spatial context of exploration helps ground design team collaboration.<br\/><br\/>Program Manager: Anita J. La Salle<br\/>Date: June 26, 2006","title":"SoD-TEAM: Problem-Solving Methodology in Collaborative Design","awardID":"0613550","effectiveDate":"2006-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7372","name":"ITR-SCIENCE OF DESIGN"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[308498,308499],"PO":["564388"]},"119307":{"abstract":"NeTS-NBD: Measurement-Based Mobility Modeling for MANETs<br\/><br\/>Award 0626850<br\/><br\/>Mihail Sichitiu<br\/><br\/>Mobile ad hoc networks (MANETs) are inherently cooperative. Because possibly all communicating devices may undergo varying degrees of mobility in MANETs, they rely heavily on nearby nodes to maintain network connectivity. Therefore, the underlying mobility patterns of mobile nodes strongly influence the performance of MANET protocols. Modeling and reproducing the mobility patterns arising from real scenarios are very important for simulation-based performance studies of MANET protocols.<br\/><br\/>The primary goal of the study is mobility modeling and generation. In contrast to existing work, this research focuses on modeling the mobility patterns from real scenarios and emulating such patterns in synthetic mobility traces that can be used for creating realistic simulation environments. The proposed model has the desirable characteristics that it is customizable to match any real scenario (e.g., busses in a city, students in a campus, or zebras in a herd), while allowing for convenient diversification (i.e., allows changing the number of nodes, density, etc.).<br\/><br\/>The main deliverables of this project are a suite of mobility models and the tool that uses them to generate the traces. Since for the foreseeable future MANET performance evaluation will be based on network simulations, it is expected that the results of this project will be widely used in the MANET community. It is envisioned that the proposed model will effectively replace the random way point as the standard mobility model used in any MANET performance evaluation.","title":"NeTS-NBD: Measurement-Based Mobility Modeling for MANETs","awardID":"0626850","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["450636","526944"],"PO":["565090"]},"119219":{"abstract":"This proposal focuses on developing theoretical foundations of discrete curvature flows on surfaces, studying different geometric structures on surfaces using the flows, and applying them to geometric modeling, computer graphics and visualization. Shape classification and comparison are fundamental problems in computer vision and graphics. The PIs propose to classify surfaces according to their conformal structure using Teichmueller theory. The PIs will develop practical algorithms to compute Teichmueller space coordinates using discrete Ricci flow and use the coordinates to index large scale geometric database. In contrast to smooth surfaces, discrete surfaces have an extra structure: combinatorial structure. Combinatorial structure plays crucial roles in discrete geometries. It is a fundamental problem to get better understanding of the roles played by combinatorial structures. Discrete curvature flow is a powerful tool to study this problem. The PIs plan to develop the corresponding mathematics based on discrete variational principle to support these computational algorithms. The mathematical study is based on the cosine law which the PI consider as the basic metric-curvature relation in the discrete setting. The PI have discovered that derivatives of the cosine law produce striking identities valid in all constant curvature spaces. These identities produce energy functionals which include almost all known action functionals in the discrete setting. The potential applications of these newly discovered variational principles in graphs and visualization seem to be abundant.<br\/><br\/>Conventional computational geometry algorithms are mainly defined in flat spaces. These algorithms can be systematically generalized to curved spaces via geometric structures. This opens a new territory for geometric algorithmic design on manifolds by solving the easiest special case in the plane then directly generalizing the solution to arbitrary surfaces. Splines play the most fundamental role in geometric modeling. In aircraft, automobile and many other industries, almost all designs are aided by computer using splines. The shapes of mechanical parts have highly complicated topological and geometric features. Unfortunately, current splines can only be defined on the plane. It has been a long lasting open problem to find rigorous ways to define splines on general surfaces. The PIs plan to solve the problem by introducing novel algorithms to construct spines and calculate geometric structures via discrete curvature flow. Surface parameterization is a powerful technique to map surfaces in 3D onto the plane and convert 3D geometric problems to 2D. In texture mapping, in order to enhance the visual effects, images with subtle details are pasted onto the coarse polygonal surfaces. The central issue for parameterization is to control the distortion, the PIs propose to build the relation between distortion and the curvature and to seek a practical way to find the optimal parameterization. In today's Internet, there are huge amounts of geometric information. Building a geometry Google is the most urgent and fundamental problem for geometers and computer scientists. The PIs plan to build such geometric search engine using the methods developed in the proposal.","title":"MSPA-MCS: Discrete Curvature Flows on Graphics and Visualization","awardID":"0626223","effectiveDate":"2006-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["519258"],"PO":["565286"]},"130164":{"abstract":"The end-to-end argument is a fundamental principle of the Internet architecture. The commercialization<br\/>of the Internet, however, has brought new requirements like trust, QoS, ISP differentiation, third party<br\/>involvement and less sophisticated users. These requirements have prompted the rethinking of the end-to-end<br\/>principle in a quest for a new Internet architecture. Past experience indicates that the development of a<br\/>new architecture will likely be a long process, rich with debate and will draw from a vast and often uncharted<br\/>solution space.<br\/> This research will investigate part of the solution space, namely the viability and suitability of Network<br\/>Assisted Services as a possible component of the future Internet architecture. A network-assistance archi-tecture called Network Samaritans (NetSam) is defined to map the framework for such services. NetSam is motivated by the observation that many new requirements seemingly require new mechanisms in the net-work. Unlike Active Networks, NetSam is a moderate, yet careful step towards an enhanced network that provides a set of services beyond basic forwarding, but spiritually very distant from the malleable network of AN. NetSam preserves the architectural spirit of the Internet by seeking to determine the minimum func-tionality that is both necessary and appropriate in the network. NetSam is not an Internet architecture, but merely a framework for new services pivoting on network assistance, which may become part of the future architecture.<br\/>Approach<br\/> The study will be carried out in the context of three important applications: Reliable Multicast, Distributed Denial of Service, and Network Management. The investigation will follow a disciplined, minimalist approach, assuming that a service is not needed unless proven otherwise. Selected services will be decom-posed and their components distributed between the network and the application. Network components willbe simple and general so they can be easily implemented in the routers with minimal security risks.<br\/> The NetSam architecture defines a new architectural division of services, namely filter and surrogate<br\/>services. Filter services are very simple and typically implemented in the routers, while surrogate services<br\/>are more complex and typically implemented at the edges (but use some help from forwarding filters).<br\/>Together, filters and surrogates provide flexibility and support a large spectrum of services.<br\/> The study will follow a top-down approach by isolating the applications of network assistance. Simple<br\/>and general services will be defined, with candidates including packet marking, steering and sampling and<br\/>then appropriate filters will be designed. The resulting system will be evaluated through implementation and<br\/>simulation.<br\/>Impact on Advancing Knowledge<br\/> This research proposes a new paradigm for application\/network interaction. Unlike current paradigms<br\/>that follow either complete separation or union of the two, this research proposes informed interaction<br\/>between the network and application. The major contribution of this research to science will be the architecturethat governs this interaction.<br\/>Impact on Education<br\/> This research will expose students to both theoretical and practical issues on application\/network interaction. Students will be challenged to think deeper about the distinction between the application and the network, with emphasis on understanding concepts like the end-to-end argument and active networking.<br\/>Students will learn to analyze application requirements and consider the merits and demerits of router-assisted services. Students will learn how to define a new architecture. Project work will task students with the definition of new services and the decomposition and implementation of their constituent primitives.","title":"CAREER: Network Samaritans (NETSAM): Network-Assisted Service for the Internet","awardID":"0724741","effectiveDate":"2006-08-16","expirationDate":"2008-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["559198"],"PO":["565090"]},"110584":{"abstract":"Practical Cache-Oblivious B-Trees <br\/><br\/>For over three decades, the B-tree has been the data structure of choice for maintaining searchable, ordered data on disk. Such B-trees are sometimes referred to as \"cache-aware\" B-trees because they are aware of, and optimize for, one particular block size (such as the disk block size) in the memory hierarchy. In contrast, recent theoretical results show how, in principle, to build a \"cache-oblivious\" B-tree, which simultaneously optimizes for all block sizes with no explicit measurement or tuning. Although recent experiments show that cache-oblivious B-trees can outperform cache-aware B-trees for any given block size, sometimes by two orders of magnitude, cache-oblivious B-trees are not yet practical. This project aims to understand how the theoretical promise of cache-oblivious B-trees can be realized in practice. <br\/><br\/>Building a practical library for cache-oblivious search trees is a difficult systems engineering problem. Existing designs are complex and lack concurrency. They provide amortized performance guarantees rather than worst-case performance guarantees. They do not support the transactional semantics required by databases and file systems. By combining theoretical insights with modern software technology, such as memory mapping, this research project hopes to provide a practical library for cache-oblivious search trees that offers provable guarantees of performance.","title":"CPA: Practical Cache-Oblivious B-Trees","awardID":"0541209","effectiveDate":"2006-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["548187","471720"],"PO":["550859"]},"132254":{"abstract":"The biological sciences are advancing by posing increasingly complex and quantitative questions which require experiments that are increasingly complex procedures, and analysis of increasingly complex and large data sets. Information technology is pervasive throughout this process. Before beginning the laboratory work, computation is necessary for planning the experiment, and for later analysis of the results. In gene chip experiments for determining gene activity levels, planning issues include which biological hypotheses should be considered and what chemical conditions will yield the most informative results, followed by computation to reduce the collected data, which can be gigabytes of information, to forms that can be understood and exploited by biological scientists. In electron microscope experiments for determining the 3-D structure of viruses, planning issues include electron energy, defocus level, beam current, number of tilts, and tilt angles, followed by computation to reduce the measured data, which can be one hundred thousand or more images, to a biologically-plausible 3-D structure. Historically, insufficient attention has been devoted to the use of highly sophisticated information technology for quantitative planning and analysis of experiments, which jointly takes into account the behavior of the measurement apparatus, the goals of the experiment, the unavoidable uncertainty in the system, and the algorithmic complexity that a particular experimental design implies for the subsequent computational analysis of the experimental data. The research objective of this ITR project is to bring together a team of investigators from MIT, Purdue and NYU-Courant along with their industrial collaborators to apply principles from information, coding and systems theory, along with advanced computational methods for statistical inference and numerical optimization, to create a unified approach to planning and analysis of complex quantitative experiments in the biological sciences, such as the determination of gene expression using gene chips and the determination of 3-D viral structure from scattering and electron microscopy experiments. These biological problems will challenge the state of the art in information technology and an important characteristic of the project is the parallel development of new information technology and new biological applications. The human-resources objectives of this ITR project are to provide the opportunity for undergraduate students, graduate students, and postdoctoral associates to learn about and contribute to this exciting area at the interface between information technology and biological sciences. Because of the biological focus of the research it is anticipated that the proposed project will be an outstanding opportunity to recruit women and other underrepresented minorities into the Systems, Information and Computer Science endeavor.","title":"ITR: Collaborative Research: New Approaches to Experimental Design and Statistical Analysis of Genomic and Structural Biologic Data from Multiple Sources","awardID":"0735297","effectiveDate":"2006-08-17","expirationDate":"2010-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["518003"],"PO":["562984"]},"121056":{"abstract":"This SGER project focuses on a challenging, novel and important research topic. The project builds upon, extends and combines technologies from two disparate disciplines (study of cell kinetics and genetic programming) to formalize and implement the algorithmic constructs of geometric self-organization.<br\/>Focusing effort on a project at the intersection of biology, engineering and computer science will advance the<br\/>emerging field of bio-computing. The importance of achieving this technical goal is highlighted by the number<br\/>of applications that can benefit from harnessing the power of self-organization (Chemotaxis Simulation, Tissue Engineering, Computer-Aided Geometric Design and Swarm Robotics). The PI is an accomplished researcher who has training in both the physical and computing sciences with specific expertise in simulations based on locally-interacting microstructures, as well as experience in managing large long-term collaborative projects.<br\/>The project has access to the substantial computing and human resources needed for its successful execution This proposal describes a multi-disciplinary project that brings together activities in computational biology, geometric modeling and evolutionary computing. SGER support will allow the PI to assess the feasibility of combining chemotaxis simulation with genetic programming in order to produce biology-inspired geometric modeling technologies. It will create a diverse team of students and faculty to conduct research at a unique technical junction. It will foster new avenues of research that incorporate concepts from cellular biological systems into computational solutions and algorithms. The project's outreach program builds upon established partnerships with Philadelphia inner-city schools and will expose under-represented minorities to the latest trends in computing and biology. The goal of the program is to inspire young students to become involved in the newly developing field of bio-computing. The PI has a strong track record of involving women and minorities in his research. This commitment will be sustained within this project. The project will reach out to build strong collaborations between groups within Drexel University's College of Engineering, School of Biomedical Engineering and College of Medicine, creating new scholarly synergies. The results will be disseminated widely through publications and conference presentations, web material, and outreach activities to the community. Given the application of Morphogenic Primitives to tissue engineering, robotics, sensor networks and computational biology, they promise to provide substantial societal benefits in the areas of engineering, medicine, health care and the basic biological sciences, as well as launch a new approach to geometric computeraided design.","title":"SGER: Automated Shape Composition Via Genetic Programming","awardID":"0636323","effectiveDate":"2006-08-01","expirationDate":"2008-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["453840"],"PO":["532791"]},"116832":{"abstract":"Abstract<br\/><br\/>Due to the limits of power dissipation, the trend today in chip microarchitecture is to implement a multiprocessor with simple cores (Chip MultiProcessors or CMP) in which each core may run multiple threads concurrently (Chip MultiThreading or CMT). Future performance improvements will mostly come from supporting more and more threads in every microprocessor generation. In this context, there is renewed interest in designing highly scalable multithreaded algorithms.<br\/>The goal of this project is to develop, evaluate and expand a generic model for parallel algorithms called STAMP (Synchronous, Transactional and Asynchronous MultiProcessing model). The STAMP model includes performance and power and is a compromise between simplicity, generality and good predictive value. The work in this project proceeds in two directions: design and exploration of parallel algorithm models, and application of the model to specific algorithms and applications. A simulation infrastructure for CMPs based on Simics called SimWattchMP is used for measuring performance and power and simulating system activity.<br\/>If the model gains widespread acceptance, it will become a major abstracted platform on which designers and programmers of parallel algorithms can reliably design, program and evaluate their algorithms without the detailed knowledge of the machine and system. This will be critical to the evolution of hardware and software systems in the next 15 years. Research results will be widely disseminated by publications and will also be made available to the community at large through a project web page.","title":"CSR---SMA: Collaborative Research - STAMP: A Universal Algorithmic Model for Next-Generation Multithreaded Machines and Systems","awardID":"0614929","effectiveDate":"2006-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[309150],"PO":["493916"]},"116843":{"abstract":"Our proposed pilot project will explore the possibility of developing a more effective programming model for such distributed and data intensive environments, using an abstract mechanism for data management from the GridRPC community data handles. Analogous to the function handles that are central to the GridRPC paradigm, a data handle is an abstraction that can be dynamically bound to data and storage resources at run-time. A programmer can use a data handle as if it were variable, passing it between multiple GridSolve calls, while at the same time, the internal GridSolve run-time system can perform various operations (e.g. read, write) on them. We believe that if we can provide TGS with a data handle mechanism at the right level of abstraction, one that integrates different existing grid data management approaches while exposing the appropriate amount of structure to the scientific end user, then we can enable SCE-based TeraGrid applications that involve workflow patterns with a wide range complexity.","title":"Collaborative Research: CSR--AES: TeraGridSolve: General Purpose Scientific Computing Environments for the TeraGrid","awardID":"0615004","effectiveDate":"2006-08-01","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["335186"],"PO":["551712"]},"116865":{"abstract":"As distributed systems are deployed across machines free to opt in or out at any time, host availability is a first-order concern. Systems typically deal with availability in a reactive way, making little distinction between machines with different availability behaviors. In short, current systems view fluctuating availability as a problem. This project views availability as an opportunity, by predicting the availability of many individual hosts in a larger collective. By using a competitive tournament of predictors, the project is able to predict the availability of many nodes even in completely unmanaged networks. The research effort applies these predictors in three domains. In the first, epidemic propagation, the project augments current viral infection models to consider availability in addition to topology. The second application is delay-tolerant networking. By using availability prediction as a practical contact oracle, one can improve end-to-end latency and routing efficiency. As a third application, the project applies availability prediction to DHT-based storage and archival networks. By biasing placement of some replicas towards highly available nodes, churn-induced document transfer is reduced and overall system availability improved. By ugmenting the maintenance protocols with availability predictions, network overhead is further reduced.","title":"CSR-PDOS: Availability-Aware Services","awardID":"0615086","effectiveDate":"2006-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["530391"],"PO":["402055"]},"116898":{"abstract":"Storage systems are exploding in size, complexity and popularity, and<br\/>as they grow, they expose themselves to a variety of failures. As<br\/>such, the software that supports these systems must be able to<br\/>tolerate a growing number of failures. Erasure coding is a technique<br\/>that allows storage nodes to be enriched with extra coding<br\/>information so that if one or more nodes fail, the original data may<br\/>be recovered from the survivors. While erasure codes have existed<br\/>for decades, there is a considerable gap in understanding<br\/>constructions, performance and properties of codes that tolerate<br\/>multiple failures. This project's mission is explore, design,<br\/>evaluate and disseminate erasure codes for multiple failures that<br\/>significantly improve the performance and failure coverage of current<br\/>codes. The research component is centered around unifying disparate<br\/>techniques from classical coding theory, disk array technology, and<br\/>asymptotic graph theory.<br\/><br\/>This work will impact all applications where multiple storage nodes<br\/>are used in tandem, and the risk of one or more nodes failing is<br\/>significant. New, efficient codes will be developed and evaluated<br\/>with respect to the best currently known codes. Additionally, the<br\/>implementations of these codes will be disseminated to the community<br\/>of systems programmers that need them, and tutorial material will be<br\/>developed so that the codes may have wide impact. This is a serious<br\/>issue, as most current codes are presented in a theoretcially formal<br\/>way that puts them beyond the reach of the programmers who need to<br\/>implement them. Finally, erasure codes will be used as the basis for<br\/>motivational programs on math and science at K-12 schools in East<br\/>Tennessee.","title":"CSR-PDOS: Exploring and Developing Improved Erasure Codes for Storage Systems","awardID":"0615221","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["450864"],"PO":["535244"]},"116304":{"abstract":"Many visualizations of the output of computer simulations use geometry relationships. These are currently created manually using 3D modeling software or by direct programming. This project uses new methods to model a visualization and specify how large sets of objects can be aggregated when the scale of the visualization changes. This will also allow for real-time visualization of urban simulations on PCs and large immersive virtual reality installation. As world populations and urbanization grow explosively, urban planning has become increasingly important: in Phoenix, the average low temperature in the summer has increased by almost 14 degrees due to the urban development and resulting urban heat island; long and slow freeway commutes in cities like Los Angeles or traffic gridlock in Delhi or Mexico City are examples of the urgency and necessity of urban planning. Large urban areas need sustainable planning to ensure the availability of sufficient resources for future years. Smaller cities growing into large urban areas need effective planning to become habitable and provide reasonable quality of life. This project develops modeling and visualization tools that will contribute to planning a better future for urban environments and make our cities more livable. The team addresses two major problems: developing a systematic effort to develop methodologies to specify a visualization of simulation data of geometric and semantic urban data and developing algorithms to compute visual representations for multiple scales based on ideas from cartographic simplification. In addition to training of students, the work will be the basis of both graduate and undergraduate course being developed.","title":"SEI(GEO): Visual Geo-Analystics","awardID":"0612269","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}}],"PIcoPI":["455816","455160","455161"],"PO":["565136"]},"117877":{"abstract":"This project, acquiring a high-performance PC cluster, will enable computationally aggressive techniques to be applied in a variety of disciplines, with a focus on environmental disciplines that relate to the environment and economy of south Texas. This cluster is designed to support the following projects:<br\/>Integrated windmill and utility system simulation,<br\/> Modeling\/simulation of linked and braided electroactive polymers,<br\/> Monte Carlo and molecular dynamics simulations of gas hydrates,<br\/> Modeling subsurface microbial competition,<br\/>Modeling coupled transport of colloids and contaminants, and their biological effects in river systems,<br\/>Decision support tools to estimate groundwater availability,<br\/>Modeling flow and transport of contaminants,<br\/>GIS-based flood and storm surge simulation and damage assessment,<br\/>Air quality forecasting,<br\/>Instrument and measurement research on estimate precision using ratio indicator, and<br\/>Using simulation-based genetic algorithms for dynamic signal control optimization in networks with stochastic route choice and time-variant demand.<br\/>These applications and the general computational methods to be employed have been planned. The system design includes a gigabit-ethernet-based interconnect and 128 processors with 2 GBytes of local memory, connected to a 1.2 TByte storage-area network. Management will include an Advisory Board and a Management Board. TAMUK is providing power\/environmental support and system administrator personnel.","title":"MRI: Developing a High Performance Computing Center Through Acquisition of a PC Cluster for Cross-Disciplinary Research and Education","awardID":"0619810","effectiveDate":"2006-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["536999","536999","351223","548563","548563","544982",312267],"PO":["557609"]},"117899":{"abstract":"This project, designing, implementing, and simulating architectural components to calculate their power requirements and developing detailed models of fault-tolerance, aims at acquiring appropriate infrastructure for the tasks (high-performance Blades, hard drive, Gigabit Ethernet, software). Proposing a shift in the design of embedded systems and microarchitectures, the work focuses on designing embedded systems that exploit application tolerance to reduced accuracy. Tolerance is often used to accommodate variations in quality of service in communication and network performance. While proposing a set of static and dynamic mechanisms to track computations involving control, the project pushes this tolerance into microarchitecture of embedded processors. The project examines two types of errors that benefit from tracking the data categories by evaluating the potential of mapping computations and data to <br\/><br\/>-Architectural components with differing levels of soft error protection and<br\/>-Reduced precision components, that save power through voltage overscaling and\/or power gating. Proposed are a general compiler and architecture mechanisms that will function on any code, but are designed to exploit applications that can trade some form of output fidelity for relaxed accuracy requirements.","title":"MRI: Acquisition of Computing Resources for Management of Reliability through Data Classification and Voltage Overscaling","awardID":"0619911","effectiveDate":"2006-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["528013"],"PO":["557609"]},"119429":{"abstract":"The proposed research will address an issue of substantial importance: how<br\/>to stop the rapid spread of malicious software that infects host<br\/>computers. The objective of this project is to develop fast methods of<br\/>analysis that accurately identify exploit code in network traffic. These<br\/>methods should succeed even if the exploit is concealed by means of code<br\/>obfuscation and metamorphosis (i.e., varying in form from one instance to<br\/>the next).<br\/><br\/>We statically analyze the control and data flow of code to characterize<br\/>the pattern of system calls executed by the code. Both large and small<br\/>exploit codes typically accomplish much of their function by such calls.<br\/>The use of code obfuscation techniques or metamorphic program<br\/>transformations will not in general change this pattern. We use weighted<br\/>matching to compute the degree of similarity between two code fragments,<br\/>based on their system call patterns. <br\/><br\/>The research project will include<br\/>* extensive evaluation of the initial method<br\/>* faster methods of control flow analysis and disassembly<br\/>* improvements in the accuracy of static data flow analysis<br\/>Other outcomes will include the development of a software implementation<br\/>of our detection method, and standard benchmarks for evaluating and<br\/>comparing such methods.<br\/><br\/>We propose to integrate this research with education of undergraduate and<br\/>graduate students about software vulnerabilities, and how to prevent or<br\/>remove them.","title":"CT-ER: Metamorphic Worm Detection","awardID":"0627505","effectiveDate":"2006-08-15","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["548079"],"PO":["521752"]},"109419":{"abstract":"The BlogoCenter project is a collaborative effort (0534784, Junghoo 'John' Cho, University of California-Los Angeles and 0534323, Dragomir Radev, University of Michigan Ann Arbor) with a goal to develop innovative technologies for building a system that (1) continuously monitors, collects, and stores personal Weblogs (or blogs) at a central location; (2) discovers hidden structures and trends automatically from the blogs; and (3) makes them easily accessible to general users. By making the new information on the blogs easy to discover and access, this project is helping blogs realize their full potential for societal change as the \"grassroots media.\" It is also collecting an important hypertext dataset of human interactions for further analysis by the social and behavioral sciences research communities. <br\/><br\/>In developing such a system, the project investigates new research challenges in three areas: (1) novel monitoring algorithms that discover and download new information from rapidly-changing distributed sources with minimal delay; (2) new text and graph mining techniques appropriate for large-scale hypertext corpora; and (3) novel text ranking and summarization algorithms to help the users access new and high-quality information quickly from the rapidly-evolving blogs. <br\/><br\/>The project will make a significant impact to the scientific community by making the collected datasets and the source code of the prototype available to other research groups via the Web (http:\/\/www.eecs.umich.edu\/~radev\/blogocenter), accelerating progress in the blog-related research. The new research findings will be disseminated via scientific conferences and journals, spurring significant advancements in distributed Web-source monitoring, text summarization and ranking, and large-scale text and graph mining. In addition, this project will support graduate and undergraduate student research and foster cross-institution collaboration.","title":"Collaborative Research: BlogoCenter - Infrastructure for Collecting, Mining and Accessing Blogs","awardID":"0534323","effectiveDate":"2006-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["466946"],"PO":["563751"]},"112532":{"abstract":"Abstract<br\/><br\/>Program: NSF 04-588 CISE Computing Research Infrastructure<br\/>Title: CRI Collaborative Research: Building the Next-Generation Global Routing Monitoring System<br\/><br\/>Lead Proposal: CNS-0551725<br\/>PI: Massey, Daniel F.<br\/>Institution: Colorado State University <br\/><br\/>Proposal: CNS-0551661 <br\/>PI : Meyer, David M.<br\/>Institution: University of Oregon<br\/><br\/>Proposal: CNS-0551541<br\/>PI : Wang, Lan<br\/>Institution: University of Memphis<br\/><br\/>Proposal: CNS-0551736<br\/>PI : Zhang, Lixia<br\/>Institution: University of California-Los Angeles<br\/><br\/><br\/>Researchers at the University of Oregon, Colorado State University, University of Memphis, and University of California at Los Angeles will develop the next generation of the RouteViews system as a community resource to provide the most needed data to networking researchers and educators and network operators. RouteViews provides data on routing in the global Internet and tracks changes at Internet nodes. The project builds upon the existing RouteViews data collection system that was launched in 1998. That system archives routing data from the global Internet and was originally intended as a tool for network operators. Over the last few years, the RouteViews archive has quickly become a major data source for the network research community and numerous recent network routing research projects have benefited from it. These projects range from network topology measurement and routing stability analysis to network diagnosis, anomaly detection, and new routing protocol designs. RouteViews data is also starting to appear in classrooms and has potential for use in both graduate and undergraduate education. This project will address weaknesses in the initial implementation both in the system architecture and the quality of data collected. The investigators will replace the current router software package with an extensible data collector, rebuild the data archive with a new standard format, and provide real-time distribution of the global routing information.","title":"CRI: Collaborative Research: Building the Next-Generation Global Routing Monitoring System","awardID":"0551725","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["559197"],"PO":["565090"]},"116910":{"abstract":"Our proposed pilot project will explore the possibility of developing a more effective programming model for such distributed and data intensive environments, using an abstract mechanism for data management from the GridRPC community data handles. Analogous to the function handles that are central to the GridRPC paradigm, a data handle is an abstraction that can be dynamically bound to data and storage resources at run-time. A programmer can use a data handle as if it were variable, passing it between multiple GridSolve calls, while at the same time, the internal GridSolve run-time system can perform various operations (e.g. read, write) on them. We believe that if we can provide TGS with a data handle mechanism at the right level of abstraction, one that integrates different existing grid data management approaches while exposing the appropriate amount of structure to the scientific end user, then we can enable SCE-based TeraGrid applications that involve workflow patterns with a wide range complexity.","title":"Collaborative Research: CSR--AES: TeraGridSolve: General Purpose Scientific Computing Environments for the TeraGrid","awardID":"0615264","effectiveDate":"2006-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["495745"],"PO":["551712"]},"116921":{"abstract":"The next-generation of embedded computing systems will be increasingly human-centric. Embedded devices will operate in an environment where they monitor and react to human activity as opposed to engineering artifacts. Transparent interfaces and implicit modes of human-computer interaction will be enabled by sensors that are unobtrusively embedded in our immediate environment. These sensors and other embedded devices will accompany their (human) host to ensure uninterrupted service. Applications of such devices will include augmenting human capabilities, logging past activities (e.g., as a memory aid or to provide longitudinal monitoring), ensuring safety, and enhancing social connections (by offering a new form of remote access to an individual). Personal effects (such as attire) are a prime target for instrumentation to enable the human-centric, embedded-computing vision. Smart wardrobes equipped with distributed sensing, computing and memory resources are thus likely to become an increasingly popular platform for embedded computing. The objective of this project is to investigate the software infrastructure required to enable and support future wearable embedded systems such as those that reside in smart wardrobes and other personal effects. The project identifies the challenges encountered in building such a software infrastructure, and develops a new embedded operating system and middleware service architecture to address these challenges.","title":"CSR-EHS: Towards Ubiquitous Wearable Embedded Computing","awardID":"0615318","effectiveDate":"2006-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["553633"],"PO":["561889"]},"116943":{"abstract":"Abstract<br\/><br\/>Due to the limits of power dissipation, the trend today in chip microarchitecture is to implement a multiprocessor with simple cores (Chip MultiProcessors or CMP) in which each core may run multiple threads concurrently (Chip MultiThreading or CMT). Future performance improvements will mostly come from supporting more and more threads in every microprocessor generation. In this context, there is renewed interest in designing highly scalable multithreaded algorithms.<br\/>The goal of this project is to develop, evaluate and expand a generic model for parallel algorithms called STAMP (Synchronous, Transactional and Asynchronous MultiProcessing model). The STAMP model includes performance and power and is a compromise between simplicity, generality and good predictive value. The work in this project proceeds in two directions: design and exploration of parallel algorithm models, and application of the model to specific algorithms and applications. A simulation infrastructure for CMPs based on Simics called SimWattchMP is used for measuring performance and power and simulating system activity.<br\/>If the model gains widespread acceptance, it will become a major abstracted platform on which designers and programmers of parallel algorithms can reliably design, program and evaluate their algorithms without the detailed knowledge of the machine and system. This will be critical to the evolution of hardware and software systems in the next 15 years. Research results will be widely disseminated by publications and will also be made available to the community at large through a project web page.","title":"CSR---SMA: Collaborative Research - STAMP: A Universal Algorithmic Model for Next-Generation Multithreaded Machines and Systems","awardID":"0615428","effectiveDate":"2006-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["518643"],"PO":["493916"]},"111388":{"abstract":"Technology advancements are producing increasingly complex systems, that are often expected or required to meet performance demands and yet be extremely reliable and secure. As a result, engineers are increasingly utilizing computer tools to analyze high-level models of a system during its design. Uncertainties, such as device failures or arrivals of requests, lead to stochastic events within the model. Automated computer tools can numerically analyze the stochastic process described by the model to obtain performance measures of the system model, and can utilize implicit data structures to represent much larger stochastic processes than would be possible otherwise. Alternatively, discrete-event simulation can be used to produce confidence intervals for the performance measures.<br\/><br\/>This NSF CAREER research process project extends the applicability of high-level system models by generalizing the types of models supported by implicit representations to include a unified hierarchy in which a model event may itself be described by another more detailed model. This allows a complex system model to be constructed out of several simple components. The goal is to use implicit methods to control the state space explosion that has plagued analysis of complex systems. Techniques to construct and exploit the model hierarchy are being developed and implemented by this project in software libraries and tools. These techniques include numerical analysis methods that use implicit representations, discrete-event simulations, and hybrid approaches that unify numerical analysis methods with discrete-event simulation. The project is developing tools and technology that will enable the analysis of complex systems and impact important areas of computer systems research, including complex real-time embedded systems, Peer-to-Peer networks, safety-critical systems, agent-based systems, and software verification for high-confidence systems.<br\/><br\/>The CAREER research program is closely integrated with educational efforts through assignments, projects, and lectures that are introduced into courses on discrete-event simulation and analysis of stochastic processes.","title":"CAREER: Composition Approaches for the Analysis of Complex Systems","awardID":"0546041","effectiveDate":"2006-08-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["467171"],"PO":["561889"]},"116855":{"abstract":"Complex distributed systems must be monitored to find problems,<br\/>record\/archive system health, oversee system operation, detect<br\/>malicious activity, and perform a myriad of other tasks. To improve<br\/>the reliability, security, performance, ease-of-construction and<br\/>maintaince of system monitors, this research develops a high-level,<br\/>domain-specific language to specify the data that monitoring systems<br\/>accumulate, archive and present to users. Using high-level<br\/>specifications of distributed data sources, our compiler generates<br\/>reliable, secure, and high-performance monitoring tools that<br\/>concurrently fetch distributed data, archive (self-describing) data<br\/>for later analysis, query data to troubleshoot problems, and display<br\/>statistical data summaries to monitor real-time system health.<br\/><br\/>To make a broad impact, the PIs will develop tools for monitoring<br\/>distributed systems, including clusters and wide-area platforms such<br\/>as PlanetLab, a global network research testbed with 400-450 nodes and<br\/>200-250 network experiments running at any given time. We will make<br\/>the technology open-source, enabling others to use the monitoring<br\/>system for their own projects. Additionally, we will also work with<br\/>industrial partners to transfer our monitoring technology to industry.<br\/><br\/>Finally, the language and compiler system being built will make a<br\/>broad impact outside the networking community as the kind of ad hoc<br\/>data found in monitoring systems also appears across the natural and<br\/>social sciences, including biology, chemistry, physics and economics.<br\/>Hence it will be possible to use the specification language to<br\/>describe the formats of scientific data sets and to generate querying<br\/>and visualization tools that help improve the productivity of a wide<br\/>range of computational scientists.","title":"CSR-SMA: Language Support for Data-Centric Systems Monitoring","awardID":"0615062","effectiveDate":"2006-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["533299","483683"],"PO":["493916"]},"113467":{"abstract":"This award supports the continuing operation and development of Einstein@home, a public distributed computing project built using the Berkeley Open Infrastructure for Network Computing (BOINC) and used by the LIGO Scientific Collaboration (LSC) to search for gravitational waves from spinning neutron stars. Members of the general public can quickly and easily install the software on their Windows, Macintosh, or Linux personal computer. When otherwise idle, their computer downloads data from Einstein@home, searchs it for pulsar signals, then uploads information about any candidates. Einstein@home was chosen as key project of the American Physical Society's (APS) World Year of Physics 2005 activities and has been operating since February 2005. More than 100 000 people have participated and the project is currently delivering more than 20 Tflops of computing power. This is (by an order of magnitude) the largest computing resource available to the LSC. This award supports a collaboration between the LSC and the BOINC team to increase the sensitivity of the neutron star search using a more sensitive hierarchical method based on the Hough transform with the potential to increase the number of detectable sources by an order of magnitude, to provide maintenance and support for the Einstein@home server, to provide support for the public users, and to enhance and extend the capabilities of BOINC as infrastructure both for Einstein@home and for other applications of distributed computing. This award will support the production and maintenance of a stable production branch of the BOINC development code and the use of standard software engineering practices such as unit tests on all supported platforms. This will ensure that Einstein@home and other distributed computing projects can achieve their scientific goals without concern for instability and bugs in the underlying software infrastructure.<br\/><br\/>Gravitational waves were predicted by Einstein in 1916, but have never been directly detected. The Laser Interferometer Gravitational Wave Observatory (LIGO) was built for this purpose. Funded by the NSF in 1994, it is the most sensitive detector of gravitational waves ever built. LIGO has completed four science runs since 2002 and is now in the midst of its first long science run operating at design sensitivity. Hidden in the data from LIGO and its partner British\/German GEO600 detector are weak signals from spinning neutron stars, but searching for them requires far more computing power than is available in conventional computing clusters. Einstein@home not only enables this type of search but also allows anyone in the world with a reasonably up-to-date computer to participate in forefront scientific research. Supporting and enhancing the BOINC infrastructure will enable other projects to use the vast number of compute cycles available from volunteer computing and to engage the public in scientific research.<br\/><br\/>This award is supported by the Physics Division and Office of Multidisciplinary Activities in the Mathematical and Physical Sciences Directorate and by the Office of Cyberinfrastructure.","title":"Development and support of BOINC and Einstein@Home","awardID":"0555655","effectiveDate":"2006-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"7244","name":"COMPUTATIONAL PHYSICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4089","name":"NETWORK CENTRIC MIDDLEWARE SVC"}}],"PIcoPI":["455369","550108","484988","480116","544609"],"PO":["467733"]},"117713":{"abstract":"This project, acquiring an extremely low-latency multiprocessor system with on-board hardware accelerators, develops efficient scalable algorithms and software resource management schemes for individual applications. The cluster will be used in support of the following projects.<br\/><br\/>-Investigation into scalable hardware and software design for Internet web servers and data centers,<br\/>-Symbolic model checking,<br\/>-Pattern discovery for biological applications,<br\/>-Automatic compilation of high-level code, such as C or Fortran, into RTL VHDL code,<br\/>-Warp processing, and<br\/>-Augmenting existing microarchitecture with security protections ensuring integrity & confidentiality of program execution.<br\/><br\/>The proposed cluster can be partitioned into several subclusters that can work independently and simultaneously on different applications, provides ultra low message passing latency within a sub-cluster and between sub-clusters, and provides an SMP environment with processors that can be used for tightly-coupled codes; thus a hybrid programming model suits different applications. The research projects on FPGA compilation, hardware\/software partitioning, and CPU micro architecture design require an FPGA-based system for a test bed.","title":"MRI: Acquisition of an Ultra Low-Latency Multiprocessor System with On-Board Hardware Accelerators","awardID":"0619223","effectiveDate":"2006-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["518640","516924","451554"],"PO":["557609"]},"115777":{"abstract":"This award establishes a NSF-FDA Scholar-in-Residence project at the U.S. Food and Drug Administration. With NSF support, a graduate student member of the University of Pennsylvania's formal methods team will participate in a research project for medical device software evaluation at the FDA's Center for Research in Devices and Radiological Health. This effort seeks progress towards technology-supported, rigorous evaluation of software-intensive medical devices, using an infusion pump as case study. The research focuses on establishing the behavioral equivalence of the device software with the specified requirements for devices in this class. The study also explores potential device interactions with operator controls and with changes in the patient's condition. The longer-term goal of this project is to enable a more comprehensive, evidence-based approach for evaluation of medical devices and other safety-critical, software-centric systems.","title":"Applying Formal Methods to Improve the Quality of Software in Medical Devices","awardID":"0610297","effectiveDate":"2006-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["553656"],"PO":["561889"]},"116635":{"abstract":"Directorate for Computer and Information Science and Engineering (CISE)<br\/>Division Computer and Network Systems (CNS)<br\/>Science of Design (SoD) Program<br\/><br\/>Proposal Number: 0613823 <br\/>P\/I: Mary Shaw<br\/>PI's Department: Computer Science<br\/>Institution: Carnegie-Mellon University<br\/>Award: $132,021<br\/><br\/>Title: \"SoD-HCER: Incorporating Uncertainty in the Evaluation of Software Designs\"<br\/><br\/>This project involves the development of a systematic framework, the software confidence chain, for codifying and managing uncertainty in software design. This research lays the groundwork for confidence chains by designing and validating a representation for evaluation information that also captures confidence information and cost of analysis and that supports dynamic update of the information. In addition, the project will explore two specific techniques for handling uncertainty, characterizing uncertainty about requirements and resources that change over time and reducing uncertainty about end users' needs and expectations by improving ways for them to express their needs and expectations. The proposed research will provide a scientific basis for describing and managing uncertainty in software design, especially early in the design process, while it is still relatively inexpensive to make changes. Connecting assessments of uncertainty and confidence directly to analysis will improve the linkage to costs and benefits seen by clients, enabling more informed business decisions about software development. This project will improve our fundamental understanding of design by providing a unified approach to describing and managing uncertainty that recognizes and preserves the relations among sources of uncertainty and confidence. It will contribute analysis techniques that both provide useful analysis power and explore different facets of uncertainty, especially in the early stages of design. It will contribute both to a scientific understanding of specific types of uncertainty management and to the more general challenge of developing predictive evaluations. In addition, the research will contribute to a longer-term objective of developing a comprehensive model that rigorously relates a wide class of analyses. It will also help to establish an interdisciplinary bridge between software design and well-established business models. Development of a scientific basis for finding design points that are cost effective in light of uncertainty holds promise for improving products used by the community at large, for example by making it easier to select from among similar competing products. Similarly, increased attention to user preferences, especially for dynamic adaptation to preferences, should make computing less inscrutable to everyday users.<br\/><br\/><br\/>Program Manager: Anita J. La Salle<br\/>Date: July 5, 2006","title":"SoD-HCER: Incorporating Uncertainty in the Evaluation of Software Designs","awardID":"0613823","effectiveDate":"2006-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7372","name":"ITR-SCIENCE OF DESIGN"}}],"PIcoPI":["504468"],"PO":["551712"]},"116877":{"abstract":"All major microprocessor vendors are now committed to multi-threaded and<br\/>multi-core processors, which make thread-level parallelism visible to<br\/>the application programmer. A growing consensus holds that traditional<br\/>lock-based programming techniques are inadequate to program these<br\/>machines, and that transactions are the most promising alternative. The<br\/>central goal of the project is to chart a viable transition path to<br\/>future transactional systems. This goal encompasses work on (1)<br\/>semantic extensions, including exceptions, conditions, nesting,<br\/>irreversible operations, and interoperability; (2) characterization and<br\/>minimization of the costs of software transactions; (3) development of<br\/>hardware assists; and (4) fast ad-hoc nonblocking data structures that<br\/>interoperate with transactions. Work on these fronts spans the<br\/>compiler, run-time system, OS kernel, and high-level hardware<br\/>architecture, with an emphasis on the run-time level. Expected impacts<br\/>and outcomes include a high-performance, open-source, library-level<br\/>implementation of transactional memory; high-performance nonblocking<br\/>data structures for standard language libraries (examples have already<br\/>been adopted for the standard release of Java); a deeper understanding<br\/>of transactional semantics, and of the relationships among transactions,<br\/>locks, and nonblocking data structures; new hardware implementation<br\/>techniques; and appropriate compiler support. More broadly, a<br\/>comprehensive roadmap for transactional memory holds the promise of<br\/>extending Moore's Law and the IT revolution through the coming decade,<br\/>with wide-ranging benefits for science, commerce, government, and<br\/>quality of life.","title":"CSR--PDOS: Fulfilling the Promise of Transactions in Multithreaded Systems","awardID":"0615139","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["564815","556692"],"PO":["535244"]},"116888":{"abstract":"In the past five years, a body of research has emerged that explores adaptive behavior in optimizing compilers. This project explores the potential impact that adaptive control of single optimizations may have on the performance of embedded applications. The project focuses on two specific optimizations: inline substitution and register allocation. Inline substitution has the potential to improve running time and shorten critical paths, but can also increase static code size, a negative in a memory-constrained environment. Register allocation is a critical step in all modern compilers, one that can increase both code size and running time. Preliminary experiments with inline substitution suggest that significant improvements are possible with limited impact on resource needs, but only with application-specific adaptive control. This project is extending that work to address constraints that arise in embedded systems and to measure the potential improvements on embedded applications. With register allocation, the project is developing a parameterization of the problem that is amenable to adaptive control. Experiments will measure the impact that adaptive control of these parameters can have on performance characteristics of embedded applications. This one-year study should establish the potential that adaptive techniques have to improve code quality for embedded applications.","title":"CSR-EHS: Parameterizing Optimizations for Adaptive Control","awardID":"0615180","effectiveDate":"2006-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[309293,309294],"PO":["561889"]},"116899":{"abstract":"Soft real-time embedded systems, such as PDAs, portable multimedia devices, sensors, and some control systems, require the processing of data streams in a timely fashion, as determined by the satisfaction of end users who cannot detect occasional execution failures or deadline misses. Additional system resources would provide better performance, but the end users may not notice and will not reward such efforts. This unique feature sheds light on the efficient design and implementation of soft real-time systems. This project is developing a new design framework to systematically transfer such softness of the deadlines into better resource management, such as reduction of energy consumption.<br\/>The strategy pursued in this research is to allocate (off-line) the minimal system resources necessary to meet the given soft real-time performance requirements statistically. That is, the system does not guarantee the completion of each execution, but it will produce sufficiently many completions over a large number of repetitions to meet the user-specific completion ratio. Then during real time execution, on-chip temperature on system speed and power dissipation guide dynamic scaling of frequency and voltage to exploit unused capacity for energy efficiency on the multi-processor system.<br\/>This work focuses on (1) building and validating a theoretical foundation for the proposed probabilistic design framework; (2) developing a set of probabilistic multimedia application benchmarks and prototype synthesis tool software; and (3) conducting proof-of-concept prototyping of consumer-oriented digital signal processing software.<br\/>This research enables the resource-efficient design and implementation of an important family of soft real-time embedded systems and is expected to have direct impact on the embedded systems industry, future surveillance systems, and people's daily life. Both undergraduate and graduate students involved in the project learn embedded system design skills and gain research experience.","title":"CSR---EHS: PITAS: Probabilistic Implementation and Temperature Aware Scheduling of Embedded Software for Energy Efficiency","awardID":"0615222","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[309324],"PO":["561889"]},"116305":{"abstract":"This project is addressing a systemic problem in scientific research: although datasets collected through scientific protocols may be properly stored, the protocol itself is often only recorded on paper or stored electronically as the script developed to implement the protocol. Once the scientist who has implemented the protocol leaves the laboratory, this record may be lost. Collected datasets become meaningless without a description of the process used to produce them; furthermore, the experiment designed to produce the data is not reproducible. <br\/><br\/>This research is developing a database (ProtocolDB) to manage scientific protocols and the collected datasets obtained from their execution. The approach will allow scientists to query, compare and revise protocols, and express queries across protocols and data. The research is also addressing the issue of recording and querying the provenance (the why and where) of data. ProtocolDB will benefit scientists by providing a scientific portfolio for the laboratory which not only enables querying and reasoning about protocols, executions of protocols and collected datasets, but enables data sharing and collaborations between teams.<br\/><br\/>The intellectual merit of the research includes the design of a model for scientific workflows, and a query language to retrieve, transform, compare scientific workflows, integrate datasets, and reason about data provenance. This theoretical contribution will establish advances in the development of systems supporting the expression of scientific protocols. The ProtocolDB implementation will be evaluated by our scientific partners. The broader impact resulting from the project is the development of a general-purpose system for managing scientific protocols and their collected datasets. The established collaborations, involving academic, governmental, and private institutions, will contribute significantly to the breadth of its use.","title":"Collaborative Research: SEI+II ProtocolDB: Archiving and Querying Scientific Protocols, Data and Provenance","awardID":"0612273","effectiveDate":"2006-08-15","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}}],"PIcoPI":["427973","233230"],"PO":["565136"]},"116668":{"abstract":"Abstract<br\/>0614002<br\/>Tevfik Bultan<br\/>U of Cal SB<br\/><br\/>Design for Verification<br\/><br\/>Developing dependable software is one of the most important challenges in computer science. In recent years, there has been significant progress in verification techniques that automatically find errors in software. <br\/>However, these techniques are not capable of analyzing large software systems since they are not scalable. The goal of this project is to develop a design for verification approach that enables software developers to document the design decisions that can be useful during verification in order to improve the scalability and applicability of the automated verification techniques.<br\/><br\/>The proposed research will investigate what type of design information is needed for achieving scalable verification and how this information can be transferred from the design phase to the verification phase. This investigation of the interplay between software design and verification will advance the knowledge both in dependability of software systems and in science of design.<br\/><br\/>A set of design patterns that facilitate building software components that are amenable to automated verification will be developed. These design patterns will provide mechanisms for recording the design information that is necessary to achieve scalable verification. The design patterns developed within this project will also be useful tools in teaching how to construct highly dependable software systems to computer science students.","title":"SoD-HCER: Design for Verification","awardID":"0614002","effectiveDate":"2006-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7372","name":"ITR-SCIENCE OF DESIGN"}}],"PIcoPI":["486421"],"PO":["564388"]},"119309":{"abstract":"NeTS-NBD Simulcast Enhanced Wireless Networks<br\/><br\/>Award 0626863<br\/><br\/>Tan F. Wong and John M. Shea<br\/><br\/>Information theory predicts that it is more efficient to simultaneously transmit (simulcast) signals carrying independent information to multiple users on a wireless channel than it is to time-, frequency- or code-share the channel among the users. In current wireless networks, this simulcasting capability of the wireless medium is not utilized. This research aims to develop practical simulcasting transmission techniques that exploit such hidden resources in both infrastructure and ad hoc networks. The application of simulcasting at the physical layer has many impacts on the higher-layer protocols. Under a cross-layer framework, the use of simulcasting in wireless networks is investigated through analysis, simulation, and experimentation. The expected analytical results will be used to investigate the performance limits of simulcasting. Simulation results will be used to test protocol designs and evaluate performance under more realistic models for channel, traffic, mobility, etc. A heterogeneous ad hoc network (HANET) testbed will be developed to emulate simulcasting in real networks.<br\/><br\/>The increasing demand for wireless services has resulted in significant pressure to develop new approaches to more efficiently utilize bandwidth resources. The simulcasting techniques developed in this project have the potential to significantly improve efficiency in cellular and wireless local area networks. Through this project, engineering students learn to design communication systems by understanding the analytical limitations, evaluating performance through simulations, and deploying and testing new protocols on the HANET testbed. The research results will be disseminated through the Internet and publications in conferences and technical journals.","title":"NeTS-NBD: Simulcast Enhanced Wireless Networks","awardID":"0626863","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["550716","518031"],"PO":["557315"]},"112522":{"abstract":"Abstract<br\/><br\/>Program: NSF 04-588 CISE Computing Research Infrastructure<br\/>Title: CRI: Collaborative Research: SMT-LIB, A Common Library and Infrastructure for Satisfiability Modulo Theories <br\/><br\/>Lead Proposal: CNS-0551646<br\/>PI: Tinelli, Cesare<br\/>Institution: University of Iowa<br\/><br\/>Proposal: CNS-0551697<br\/>PI: Stump, Aaron D.<br\/>Institution: Washington University<br\/><br\/>Proposal: CNS-0551645<br\/>PI: Barrett, Clark<br\/>Institution: New York University<br\/><br\/><br\/>Investigators at the University of Iowa, Washington University and New York University will develop a community resource for users and developers of solvers for satisfiability modulo theories (SMT). The solvers are logical reasoning programs used in software and hardware verification. The project will develop standards and interfaces to enable incorporation of solvers into verification tools and benchmarks and develop services for accurate evaluation and comparison of SMT solvers. These will support use by a broad community of researchers. Broader impacts of this project are the improvement of research capability in verification. Longer-range benefits will include more reliable future hardware and software systems.","title":"CRI: Collaborative Research: SMT-LIB, A Common Library and Infrastructure for Satisfiability Modulo Theories","awardID":"0551697","effectiveDate":"2006-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["532995"],"PO":["550859"]},"121498":{"abstract":"Objective: To explore novel RF circuit topologies designed in the time rather than in the frequency domain for achieving very high impedance transformations (>200:1) over ultra wide bandwidths (DC-9GHz). The proposed approach will result in circuits that will be instrumental in communication and characterization systems focused on high-impedance RF components including nanoscale FETs and nanomechanical resonators.<br\/><br\/>Intellectual Merit: For over half a century the design of nearly all wireless commercial communication systems has been following two major design conventions: 1) the RF system impedance is set to 50 with a realizable impedance transformation ratio of less than 10:1 due to technological limitations; 2) the bandwidth of the transmitted data is limited to a small fraction of the center frequency, typically less than 10%. Although higher bandwidths are possible, they come at the expense of extra loss and real estate on the chip. Until recently, these limitations have not hindered the implementation of high-performance wireless communication systems because conventional RF devices and the developed predominantly frequency-domain design techniques are well suited for 50 narrowband systems.<br\/><br\/>The advent of nanotechnology, however, has enabled microwave engineers to produce RF devices with drastically different properties that often conflict with conventional design rules. As both active (transistors) and passive (nanomechanical resonators) RF devices are reducing in size by three orders of magnitude from micrometers to nanometers in order to satisfy speed and frequency requirements, their impedances are getting increasing higher and they now reach 1-50k. Moreover, ultra-wideband (UWB) architectures have been relatively recently legalized by the FCC allowing designers to develop significantly simpler receiver architectures. However, the practical difficulties of realizing low-loss and compact ultra-wideband matching networks as well as electronic circuits that produce pulses wider than 5GHz, is currently limiting this technology to the lower UWB band (3.1 -4.8 GHz), leaving the more interesting allowable part of the spectrum (5 -10.6 GHz) unexplored The complete lack of solutions in these areas has made the integration of nanoscale devices to RF systems practically impossible. The exploratory proposed effort is focused on developing revolutionary design techniques to alleviate the above described problems. In particular, we propose to explore novel RF circuit topologies designed in the time rather than in the frequency domain. These topologies are based on time-variant circuits that can be reconfigured and matched to the desired bandwidths. Our preliminary results clearly demonstrate that these concepts results in extremely simple and compact circuits with impedance transformation ratios in excess of 200:1 over a 9GHz bandwidth.<br\/><br\/>Broader Impacts: To the best of the investigators' knowledge this is the first attempt to utilize time variant circuits for wideband RF nanoelectronics. This area is particularly interesting because it brings the promise of significantly faster RF communication systems with major cost and battery-life benefits. Due to their very high impedances, though, RF nanoelectronics have not been utilized in any system architectures so far. The impedance mismatch between them and traditional 50 systems (200:1 to 1000:1) is so high that renders these devices unusable. This exploratory research proposes for the first time a viable solution to this serious problem. If successful, system-level researchers will be capable for the first time to bring the promise of RF nanoelectronics to reality because they will be able to implement nano- amplifiers, mixers, filters and eventually RF front-ends.","title":"SGER: Ultra Wideband Time-Variant Matching Networks with Very High Impedance Ratios for Nanoscale Electronics","awardID":"0638531","effectiveDate":"2006-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T489","name":"DIA-MASINT CONSORTIUM PROJECT"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"1517","name":"ELECT, PHOTONICS, & MAG DEVICE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}}],"PIcoPI":["513776","531741"],"PO":["438934"]},"116911":{"abstract":"CSR---AES: Collaborative Research: SoftCheck: Compiler and Run-Time Technology for Efficient Fault Detection and Correction in Low nm-Scale Multicore Chips<br\/><br\/>The goal of this project is to develop flexible and efficient Runtime and Compiler System (RCS) technologies to cost-effectively detect and recover from hardware faults in upcoming multicore chips. Semiconductor variations, temperature hot spots, soft errors and aging will make hardware reliability one of the central concerns in the design of multicore processors. RCS technologies will make it possible to meet this challenge because of their flexibility, low cost and ability to target errors that affect program outcome. <br\/><br\/>Two important objectives of this project are: (1) to avoid full instruction replication within or across threads this is key to acceptance in the energy- and cost-conscious commodity markets and (2) to provide knobs to select the desired performance vs. error-coverage tradeoff. <br\/><br\/>A prototype, SoftCheck, will be implemented for evaluation purposes. A wide range of novel, cost-effective fault detection and correction techniques will be designed and implemented in SoftCheck. The fault-detection techniques will include: (i) exhaustive self-checking, (ii) partial self-checking, (iii) partial cross-thread checking in a multicore environment, and (iv) other cross-cutting, often multiprocessor-related, approaches. The fault-correction techniques include: (i) disabling clusters in a core (ii) disabling complete cores, and (iii) dynamic recompilation to use other hardware.","title":"Collaborative Research: CRS--AES: SoftCheck: Compiler and Run-Time Technology for Efficient Fault Detection and Correction in Low nm-Scale Multicore Chips","awardID":"0615267","effectiveDate":"2006-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["496841"],"PO":["493916"]},"127933":{"abstract":"The goal of this project is to provide automatic word sense disambiguation systems based on a principled English sense inventory geared to information processing needs. Polysemy, the many possible interpretations, or senses, of a word, is one of the major bottlenecks to accurate and focused information processing. Past attempts to use a public domain resource, WordNet, as a sense inventory for creating training data have not been successful due to vague and subtle sense distinctions that lead to poor inter-annotator agreement. We are experimenting with approaches to group fine-grained WordNet senses into more coarse-grained sense distinctions that can be annotated more rapidly and more accurately. Using linguistic evidence, we are refining our methodology for grouping word senses and our annotation process while creating large amounts of sense-tagged text. This new sense inventory has links to WordNet, FrameNet, and VerbNet, with clear criteria associated with the sense distinctions that facilitate accurate human sense tagging. Using the annotated data we are developing accurate supervised and semi-supervised automatic word sense disambiguation systems by experimenting with different machine learning algorithms and feature sets. <br\/><br\/>The sense inventory, the tagged data, and the trained systems will all be in the public domain for both national and international access, providing a stable English sense inventory geared to computational applications. The availability of broad coverage automatic word sense disambiguation systems will provide a major boost in performance to information retrieval, information extraction, question answering and machine translation, improving our ability to stay abreast of the information avalanche.","title":"Advancing the Performance of Word Sense Disambiguation by Finding Consistent Criteria for Sense Distinctions","awardID":"0715078","effectiveDate":"2006-08-31","expirationDate":"2009-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7274","name":"HUMAN LANGUAGE & COMMUNICATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["511542"],"PO":["565215"]},"111389":{"abstract":"The exponential rise of manufacturing variations, environmental uncertainties, and reliability degradations dramatically influences all aspects of a nanoscale integrated system. These emerging physical effects lead to an excessive amount of performance variability and invalidate current integrated circuit design ethodologies. To overcome these challenges and continue along the path predicted by Moore's law, a fundamental shift in the design paradigm is needed to seamlessly integrate nanometer technology properties, integrated circuit design, and advanced electronic design automation (EDA) strategies. This project aims to develop a comprehensive suite of predictive design tools to analyze and mitigate circuit performance variability in the presence of multiple sources of uncertainties. These design tools comprise variability models, statistical analysis, and concurrent optimization methods to improve design predictability and reliability for future nanoscale systems of all types, from computation to consumer electronics. In addition, a hierarchical framework will be developed to statistically predict system performance under various variability and reliability constraints. This framework allows designers to identify key design needs, evaluate important design tradeoffs, and adaptively make design decisions up front. Research efforts in this project facilitate the robust design of nanometer circuits and enhance the fundamental understanding of reliable design with unreliable components, including both nanoscale complementary-metal-oxide-semiconductors (CMOS) and future emerging technologies. The education component of this project transfers the newly developed design knowledge to a diverse population of students, through novel education curricula and web-based dissemination tools. The basic design concepts will be taught in a summer course for K-12 teachers, at a level that can be appreciated by the teachers and, more importantly, by their students to stimulate an initial interest in engineering.","title":"CAREER: Bridging the Technology-EDA Gap through Strategic Tools for Robust Nanometer Design","awardID":"0546054","effectiveDate":"2006-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["543501"],"PO":["562984"]},"117802":{"abstract":"This project, establishing a state-of-the-art 128-CPU cluster computing facility, services research programs in theoretical astrophysics, liquid state chemical physics, nanotechnology, quantum chemistry, molecular biophysics, neuroinformatics, and structural bioinformatics, all of which depend on high-end computing. The cluster also impacts ongoing instruction in the university. The instrument serves as a learning tool and the basis of courses and certification program in computational sciences.","title":"MRI: Acquisition of Cluster Computing Facilities for Research and Education at Wesleyan University","awardID":"0619508","effectiveDate":"2006-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["552175","547136","435733"],"PO":["557609"]},"116834":{"abstract":"This project consists of techniques and tools for developing fast,<br\/>correct distributed applications. Two aspects are novel. First,<br\/>application modules developed with these techniques are statically<br\/>analyzed for potential conflicts when executed in parallel. Modules<br\/>that may conflict are serialized to avoid errors. Second,<br\/>applications are transparently monitored at run-time to show where<br\/>conservative serialization has unduly slowed the application.<br\/><br\/>The traditional approach to building concurrent systems is to write<br\/>the serial version of a module and then consider how concurrent<br\/>executions might cause errors. Each potential problem must be<br\/>synchronized appropriately before the application may be executed<br\/>safely on concurrent requests. This project analyzes code to<br\/>conservatively preclude dangerous interactions and run it safely in a<br\/>concurrent environment. The resulting safe application can be made<br\/>faster using the same techniques that developers use today to ensure<br\/>safety. For example, locks can be employed to make two segments of<br\/>code safe for concurrent execution. Although static analysis allows<br\/>developers to learn where modules may conflict, the second piece of<br\/>this project, transparent monitoring of concurrent applications, helps<br\/>developers focus their attention on areas of contention that occur in<br\/>practice.<br\/><br\/>This project's techniques will allow large, concurrent applications to<br\/>be developed without the bugs normally introduced by parallel<br\/>computation. As more of the software we use runs on central sites,<br\/>multiplexed for thousands of users, these concerns are growing. Our<br\/>techniques will be disseminated as papers at systems and languages<br\/>conferences, and as software artifacts that demonstrate their utility.","title":"CSR-PDOS : Safe at Any Speed: Safe and Fast Distributed Applications","awardID":"0614944","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["343006"],"PO":["565255"]},"112478":{"abstract":"Abstract<br\/><br\/>Program: NSF 04-588 CISE Computing Research Infrastructure<br\/>Title: CRI Collaborative Research: Building the Next-Generation Global Routing Monitoring System<br\/><br\/>Lead Proposal: CNS-0551725<br\/>PI: Massey, Daniel F.<br\/>Institution: Colorado State University <br\/><br\/>Proposal: CNS-0551661 <br\/>PI : Meyer, David M.<br\/>Institution: University of Oregon<br\/><br\/>Proposal: CNS-0551541<br\/>PI : Wang, Lan<br\/>Institution: University of Memphis<br\/><br\/>Proposal: CNS-0551736<br\/>PI : Zhang, Lixia<br\/>Institution: University of California-Los Angeles<br\/><br\/><br\/>Researchers at the University of Oregon, Colorado State University, University of Memphis, and University of California at Los Angeles will develop the next generation of the RouteViews system as a community resource to provide the most needed data to networking researchers and educators and network operators. RouteViews provides data on routing in the global Internet and tracks changes at Internet nodes. The project builds upon the existing RouteViews data collection system that was launched in 1998. That system archives routing data from the global Internet and was originally intended as a tool for network operators. Over the last few years, the RouteViews archive has quickly become a major data source for the network research community and numerous recent network routing research projects have benefited from it. These projects range from network topology measurement and routing stability analysis to network diagnosis, anomaly detection, and new routing protocol designs. RouteViews data is also starting to appear in classrooms and has potential for use in both graduate and undergraduate education. This project will address weaknesses in the initial implementation both in the system architecture and the quality of data collected. The investigators will replace the current router software package with an extensible data collector, rebuild the data archive with a new standard format, and provide real-time distribution of the global routing information.","title":"CRI: Collaborative Research: Building the Next-Generation Global Routing Monitoring System","awardID":"0551541","effectiveDate":"2006-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["545336"],"PO":["565090"]},"116889":{"abstract":"This project provides next generation programming tools that enable<br\/>compositional construction of complex, adaptive, software systems. As the<br\/>name connotes, the adaptive code kitchen is a loose collection of capabilities<br\/>by which an application scientist can specify and realize \"recipes\" of<br\/>adaptivity around native object codes. These capabilities include function<br\/>interception, continuation modification, dynamic process checkpointing and<br\/>rollback, and runtime recommendation. The project develops both the <br\/>compile-time and runtime infrastructure enabling these capabilities and also <br\/>a cookbook of standard adaptivity schemas, which can be instantiated to cover <br\/>a wide range of adaptation possibilities. Using the adaptive code kitchen, the <br\/>application scientist can incorporate libraries of native object codes, <br\/>specify problem\/task boundaries, organize his application into clouds <br\/>of related functions, instantiate one of the supplied adaptivity schemas,<br\/>and track the application's progress through an interactive monitor. <br\/>As a domain case study, the project investigates computational fluid dynamics <br\/>simulations, especially the modeling of turbulence. <br\/><br\/>Besides improved understanding of application composition systems, the impacts <br\/>of the adaptive code kitchen project are in both the domain context and <br\/>in educational outreach. The accurate modeling and prediction of turbulent <br\/>flows, especially in airplanes, ships, and automobiles, as supported by the <br\/>adaptive code kitchen can have a major impact in reducing energy consumption. <br\/>In addition, the investigators will offer short-term courses at Virginia Tech <br\/>showcasing the use of the techniques developed here and, in this manner, give <br\/>domain scientists across campus the training and expertise they need to <br\/>construct their own adaptive applications.","title":"CSR-AES: The Adaptive Code Kitchen: Flexible Approaches to Dynamic Application Composition","awardID":"0615181","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[309296,"529083","498314",309299],"PO":["535244"]},"111500":{"abstract":"Scientific data repositories increasingly involve large amounts of images and streams of empirical measurements generated by a diverse set of data sources. The goal of this project is to develop online structures and algorithms to dynamically maintain and analyze data sequences for scientific discovery and monitoring purposes. The implementation focuses on specific applications from physical and biological sciences that generate vast amounts of multi-dimensional data sequences. For scientific discoveries, an iterative querying framework is developed for modeling of the sequences of observations. The framework optimally utilizes access structures to execute queries ranging from a simple max aggregate to complex scientific queries. Interactive tools are implemented where researchers are able to incorporate domain specific knowledge into the search process. For real-time monitoring, one-pass summaries that can be updated in constant-time are developed. The structures are designed to be self-adaptive with respect to the workload changes and to handle heterogeneous and incomplete information. The project involves collaborations with domain experts in focus areas and is expected to advance the state-of-the-art knowledge in the application domains. For example, the gene expression analysis tools implemented in this project have already enhanced the ability of the collaborative researchers in their studies of Haemophilus Influenzae (first described in 1892 by Dr. Richard Pfeiffer during an influenza pandemic) in order to understand it role in a wide range of clinical diseases, so that effective vaccines can be developed. This research project is integrated with education through significant educational and outreach activities. The developed toolkits, findings, and methods of the project will be communicated in a broader context and to an expanded audience through the project website (http:\/\/www.cse.ohio-state.edu\/~hakan\/Career.html).","title":"CAREER: Exploration of Dynamic Sequences in Scientific Databases","awardID":"0546713","effectiveDate":"2006-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7496","name":"COLLABORATIVE SYSTEMS"}}],"PIcoPI":["359541"],"PO":["563751"]},"122885":{"abstract":"This is funding to support a doctoral research colloquium (workshop) of 25-30 dissertation stage doctoral students in the field of Information for a day of talks and interaction with 9-10 faculty members who are distinguished Information researchers. The event will take place in conjunction with and immediately preceding the 2006 i-Conference, the second conference in what the organizers hope will become an annual event that brings together faculty and students from the new \"Information Schools.\" The first i-Conference was held last year at Pennsylvania State University. About 300 faculty, students, and guests attended that conference, which was successful in building a sense of community around the new Information field and the i-school vision, bringing together people who might not otherwise engage with one another, to share their views associated with interdisciplinary research. Last year's conference included a Doctoral Student Poster Session, which was very well attended. This year's i-Conference will take place in Ann Arbor, Michigan, on October 16-17, and will include an expanded Doctoral Research Colloquium as indicated above on October 15. The goals of the colloquium are: to build a cohort group of new researchers who will then have a network of colleagues spread out across the world; to guide the work of the new researchers by having experts in the research field give advice; to provide encouragement and support for the selection of Information research topics; to illustrate the interrelationship and diversity of the field of Information; and to make it possible for promising new entrants in the field to attend the i-Conference and have an enjoyable and rewarding experience so that they will return and submit papers, panels, posters, etc. in future years. Student participants will be selected by a faculty review committee based on materials submitted by applicants in response to a call for participation; care will be taken to ensure that the colloquium is an equal opportunity event. In three parallel sessions, student participants will present their work and a faculty panel will provide feedback that is geared to helping the students understand and articulate how their work is positioned relative to other research, whether their topics are adequately focused for thesis research projects, whether their methods are correctly chosen and applied, and whether their results are appropriately analyzed and presented. At the end of the day, the group will convene in a plenary session at which various professional issues such as being in the job market and getting grants to support research, will also be discussed. The student papers will be published in a booklet that will be circulated to attendees at the conference.<br\/><br\/>Broader Impacts: The doctoral research colloquium will help expand the participation of young researchers pursuing graduate studies in this field, by providing them an opportunity to gain wider exposure in the community for their innovative work and to obtain feedback and guidance from senior members of the research community. It will further help foster a sense of community among these young researchers, by allowing them to create a social network both among themselves and with senior researchers at a critical stage in their professional development. Since the students and faculty constitute a diverse group on several dimensions (nationality, scientific roots, methods), the students' horizons are broadened at a critical stage in their professional development, to the future benefit of the field.","title":"Workshop: i-Conference Doctoral Research Colloquium October 16-17, 2006 in Ann Arbor, Michigan","awardID":"0646198","effectiveDate":"2006-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}}],"PIcoPI":["551830"],"PO":["565227"]},"120586":{"abstract":"Linguistics is not included in high school curricula. Nevertheless,<br\/>it is a rich area for careers in academia, education, government,<br\/>national security, and information technology. It is also important<br\/>as as cognitive, social, and behavioral science. Computational<br\/>Linguistics combines linguistic analysis with mathemetical and<br\/>algorithmic considerations. As a sub-area of Human Language<br\/>Technologies, it is one of the scientific bases of information<br\/>technologies involving speech, information retrieval, and universal<br\/>access. In this project, more than 30 faculty and graduate students<br\/>in Computational Linguistcs are collaborating to plan a Computational<br\/>Linguistics Olympiad (CLO) contest targeted at high school students.<br\/>The CLO as we envision it will include linguistic analysis as well as<br\/>algorithmic thinking in order to attract students who might pursue<br\/>careers in Human Language Technologies. An ideal contest would<br\/>identify talent independent of training. Therefore, skills like<br\/>computer programming, which are not evenly distributed across gender<br\/>and social class, should not be required. The intended outcome of the<br\/>CLO is to identify talented students so that they can be advised to<br\/>get the higher education they need in order to work in the field of<br\/>Human Language Technologies, with the ultimate goal of increasing the<br\/>size and diversity of the pool of future researchers in Human Language<br\/>Technologies.","title":"Planning Workshop for a Computational Linguistics Olympiad","awardID":"0633871","effectiveDate":"2006-08-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7274","name":"HUMAN LANGUAGE & COMMUNICATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"1311","name":"LINGUISTICS"}}],"PIcoPI":["561898","496511"],"PO":["565215"]},"112512":{"abstract":"Abstract<br\/><br\/>Program: NSF 04-588 CISE Computing Research Infrastructure<br\/>Title: CRI Collaborative Research: Building the Next-Generation Global Routing Monitoring System<br\/><br\/>Lead Proposal: CNS-0551725<br\/>PI: Massey, Daniel F.<br\/>Institution: Colorado State University <br\/><br\/>Proposal: CNS-0551661 <br\/>PI : Meyer, David M.<br\/>Institution: University of Oregon<br\/><br\/>Proposal: CNS-0551541<br\/>PI : Wang, Lan<br\/>Institution: University of Memphis<br\/><br\/>Proposal: CNS-0551736<br\/>PI : Zhang, Lixia<br\/>Institution: University of California-Los Angeles<br\/><br\/><br\/>Researchers at the University of Oregon, Colorado State University, University of Memphis, and University of California at Los Angeles will develop the next generation of the RouteViews system as a community resource to provide the most needed data to networking researchers and educators and network operators. RouteViews provides data on routing in the global Internet and tracks changes at Internet nodes. The project builds upon the existing RouteViews data collection system that was launched in 1998. That system archives routing data from the global Internet and was originally intended as a tool for network operators. Over the last few years, the RouteViews archive has quickly become a major data source for the network research community and numerous recent network routing research projects have benefited from it. These projects range from network topology measurement and routing stability analysis to network diagnosis, anomaly detection, and new routing protocol designs. RouteViews data is also starting to appear in classrooms and has potential for use in both graduate and undergraduate education. This project will address weaknesses in the initial implementation both in the system architecture and the quality of data collected. The investigators will replace the current router software package with an extensible data collector, rebuild the data archive with a new standard format, and provide real-time distribution of the global routing information.","title":"CRI: Collaborative Research: Building the Next-Generation Global Routing Monitoring System","awardID":"0551661","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7369","name":"INTERNATIONAL RES NET CONNECT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["543493"],"PO":["565090"]},"121114":{"abstract":"Information systems play a central role in developing an effective comprehensive approach to prevent, detect, respond to, and manage infectious disease outbreaks of animals and humans. Currently, a large amount of animal and public health infectious disease data is being collected by various laboratories, health care providers, and government agencies at local, state, national, and international levels. Furthermore, many agencies have developed information access, analysis, and reporting systems of varying degrees of sophistication. Researchers from a wide range of backgrounds have also contributed by developing technologies to facilitate real-time data collection and sharing, and algorithms (e.g., those tailored for syndromic surveillance) to analyze collected data. In effect, recent years have witnessed the emergence of infectious disease informatics (IDI), a subfield of biomedical informatics that systematically studies these information management and analysis issues. The purpose of this workshop is to bring together the appropriate academic and practitioner community members to further advance the objectives of IDI research. IDI research can be summarized as the development of the science and technologies needed for collecting, sharing, reporting, analyzing, and visualizing infectious disease data and for providing data and decision-making support for infectious disease prevention, detection, and management. Public health personnel in both federal and local agencies have long recognized the need for IT research to continue to address problems in data sharing, security, privacy, and analysis of disease data. The intent of this workshop is to bring together IDI researchers and practitioners to discuss selected IDI topics directly relevant to data sharing and analysis for real-time animal and public health surveillance.","title":"Arizona Biosurveillance Workshops","awardID":"0636637","effectiveDate":"2006-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}}],"PIcoPI":["548216"],"PO":["565136"]},"110587":{"abstract":"Acquisition and Modeling of Non-Rigid Shape and Deformation<br\/><br\/>The acquisition of three-dimensional digital replicas of real-word objects enables digital archiving, virtual restoration, simulation, medicine, education, reverse engineering, and many other applications. The recent success of the efforts to digitize sculptures by Michelangelo, the Florentine Pieta, and artifacts in Cairo's Egyptian Museum demonstrate that the technical challenges involved in scanning static, rigid objects have been largely solved. However, the same scanning technology is far less effective for numerous applications requiring digitization of non-rigid, deforming objects, including humans, animals, and the environment. For example, the state-of-the-art scanners today require human patients to remain motionless in a single pose for several seconds even though infants, small children, and people with disabilities may find it difficult to remain still for the required time periods. More fundamentally, the key drawback of present-day scanning technology is that a single, static scan of a deformable object is a poor representation of its shape because human and animal shapes can easily change at any time instant.<br\/><br\/>This research tackles the algorithmic challenges in acquiring moving three-dimensional shapes. Using high-speed depth cameras to acquire real-time range images allows the object to change freely throughout the scanning process and in the process reveal its entire shape, including the usually occluded regions. The acquired range images are then automatically processed to compute temporal correspondence between data points in nearby frames; to reverse the motion of these data points; and to reconstruct the moving three-dimensional shape in its entirety by aggregating partial information from each time frame. These algorithms simplify acquisition of non-rigid shapes and enable new applications such as studies of locomotion development in humans and animals and content creation for education and training.","title":"Acquisition and Modeling of Non-Rigid Shape and Deformation","awardID":"0541227","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["370293"],"PO":["532791"]},"116912":{"abstract":"Our proposed pilot project will explore the possibility of developing a more effective programming model for such distributed and data intensive environments, using an abstract mechanism for data management from the GridRPC community data handles. Analogous to the function handles that are central to the GridRPC paradigm, a data handle is an abstraction that can be dynamically bound to data and storage resources at run-time. A programmer can use a data handle as if it were variable, passing it between multiple GridSolve calls, while at the same time, the internal GridSolve run-time system can perform various operations (e.g. read, write) on them. We believe that if we can provide TGS with a data handle mechanism at the right level of abstraction, one that integrates different existing grid data management approaches while exposing the appropriate amount of structure to the scientific end user, then we can enable SCE-based TeraGrid applications that involve workflow patterns with a wide range complexity.","title":"Collaborative Research: CSR--AES: TeraGridSolve: General Purpose Scientific Computing Environments for the TeraGrid","awardID":"0615271","effectiveDate":"2006-08-01","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["558550"],"PO":["551712"]},"111357":{"abstract":"This project proposal focuses on the problem of topical link analysis with a goal to improve the relevance of web search results. A web page (or author) is not equally authoritative on all topics. However, traditional link analysis techniques consider only a single measure of authority, with little or no concern for the topic or community from which that authority is derived. This research finds ways to determine the context of recognized authority, and to incorporate that context as topicality or community recognition into more accurate automated analyses of reputation. This project further improves link analysis by distinguishing between popularity, quality, and authority. By integrating such analysis into fundamental link analysis techniques, search result quality improvements are demonstrated using human relevance and quality judgments. This contextual link analysis provides new opportunities to significantly improve measurements of authority and thus search engine result rankings (as well as topical rankings for other purposes), and to better understand the topical structure of interlinked document networks such as the Web and scholarly publications. <br\/><br\/>The project additionally incorporates educational and outreach activities, including a program to stimulate undergraduate interest and experience in computer science research in area schools, while promoting interaction among nearby faculty. The project web page <br\/>(http:\/\/www.cse.lehigh.edu\/~brian\/nsf\/career-05.html) provides access to research results and additional information on project.","title":"CAREER: Contextual Link Analysis","awardID":"0545875","effectiveDate":"2006-08-15","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7496","name":"COLLABORATIVE SYSTEMS"}}],"PIcoPI":["365997"],"PO":["560586"]},"116923":{"abstract":"The objective of this project is to develop a theoretic framework and a hierarchical methodology for autonomic power and performance management of distributed computing centers through (a) online modeling, monitoring, and analysis of power consumption and performance; (b) adaptive learning and automatically identifying strategies to minimize power consumptions while maintaining the required quality of service requirements for a wide range of workloads and applications; and (c) dynamically reconfigure the computing, storage and network resources according to the selected optimization strategies. The proposed methodology exploits the emerging hardware and software standards to improve power efficiency of processors and devices such as such as Intels quickstart and SpeedStep processors, disk spindown, power aware page allocation and RDRAM that offer a wider range of low-power states and reducing the cost of transitions. <br\/><br\/>The impact of this project is in the significant reduction of power consumptions of Internet services and Web servers that account for 8% of the US electricity consumption. In addition, the project results have a profound impact on the environment because by reducing the demand for energy, the amount of CO2 produced each year by electricity generators is reduced significantly.","title":"Collaborative Research: Autonomic Power and Performance Management in Distributed Computing Systems","awardID":"0615323","effectiveDate":"2006-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["561892"],"PO":["551712"]},"116934":{"abstract":"Many applications require high reliability and availability. Unfortunately, software failures and administrative reconfiguration errors greatly reduce system reliability and availability, each contributing to 26-30% of system failures. To improve software reliability and reduce administrative errors, many reliability assurance techniques have been used at different stages of the software life cycle, including software testing, online software patch validation, partial replication-based fault detection and recovery, and online validation of administrative reconfigurations. <br\/><br\/>Interestingly, all of the above reliability assurance tasks share a common characteristic: multiple almost-redundant executions (MARE). In other words, they all execute multiple versions\/copies of the same software, each execution differing from the others only slightly in code segment, input, or configuration. An existing solution commonly used to perform MARE is to fully execute these almost-redundant runs sequentially (as done for software testing) or simultaneously (as done for online patch and reconfiguration validation) on the same or different machines. The inherent inefficiency of these approaches materializes in one of two ways large overhead or large waste of resources and human effort both negatively impacting the validation time and cost for reliability.<br\/><br\/>To efficiently support the MARE used in performing various reliability assurance tasks, we propose a novel approach called delta execution and a comprehensive infrastructure to support it. To address the research challenges arising in delta execution, the proposed research tightly integrates innovations from multiple layers: operating sytsem, dynamic and static compilation, programming language support and various reliability assurance.","title":"CSR--PDOS: Improving System Reliability via Delta Execution","awardID":"0615372","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["542482","539055","551097","518574"],"PO":["493916"]},"122159":{"abstract":"Longstanding programs in Human-Computer Interaction, Universal Access, and Digital Society and Technologies have been combined into a single \"cluster\" on Human-Centered Computing as part of IIS Division's new solicitation entitled \"Information and Intelligent Systems: Advancing Human-Centered Computing, Information Integration and Informatics, and Robust Intelligence\" (NSF 06-572). This is funding to support one of a pair of 1.5-day workshops to be held at NSF in September, 2006, in response to this reorganization. Each workshop will bring together (a different group of) current NSF PIs whose ongoing research spans the broad spectrum of topics now included in HCC, along with selected additional members of the research community with related interests. The primary goals of the workshop are to educate the research community about the new HCC cluster and the related solicitation, and to help NSF identify emerging trends in the field. Participants will discuss and prioritize the important subfields of HCC that the scientific community believes will have a major impact in the near-to-medium term. Because the workshop will take place in September, there will be sufficient lead-time for the event to affect proposals submitted by the research community for the upcoming solicitation deadlines (October-December, 2006). In addition, workshop feedback to NSF will occur before proposals are reviewed and funding recommendations made.<br\/><br\/>Broader Impacts: This workshop will present a unique opportunity for current PIs and other members of the rapidly growing HCC research community to discuss the state of the art and to engage in strategic planning toward shaping the direction of this new and interdisciplinary research area with major implications for the future of society. The workshop will broaden awareness among PIs of the rich variety of research topics that comprise HCC. It will foster networking across the inherently interdisciplinary focus areas of the field, and will also afford young researchers a chance to receive constructive feedback on their current work and future plans through interaction with more senior investigators with related interests. The workshop organizers will produce a comprehensive workshop report, and the workshop website will become a permanent repository of the workshop discussions, breakout group reports, etc for general access by the research community at large.","title":"Workshop on Human-Centered Computing: Defining the Future of HCI, DST, and UA September 2006-NSF Arlington, VA","awardID":"0642302","effectiveDate":"2006-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6846","name":"UNIVERSAL ACCESS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["431050","472685"],"PO":["565227"]},"116868":{"abstract":"Large scale parallel systems are critical to take on the challenges <br\/>imposed by highly demanding applications of critical importance. Pushing the <br\/>limits of hardware and software technologies to extract the maximum <br\/>performance can increase their susceptibility to failures. This arises as a <br\/>consequence of growing hardware transient errors, hardware device failures, <br\/>and software complexity. These failures can have substantial consequences <br\/>on system performance, and add to the costs of maintenance\/operation, <br\/>thereby putting at risk the very motivation behind deploying these large <br\/>scale systems. Rather than treat failures as an exception and take<br\/>reactive remedies, this project intends to anticipate their occurrence <br\/>and take pro-active runtime measures to hide their impact.<br\/><br\/>This research is expected to make three broad contributions towards<br\/>developing a runtime fault-tolerance infrastructure.<br\/>The first set of contributions is on collecting and analyzing<br\/>system events from an actual BlueGene\/L system over an<br\/>extended period of time. The second set of contributions are models for<br\/>online analysis and prediction of evolving failure data.<br\/>The third set of contributions are on failure-aware parallel job <br\/>scheduling and checkpointing. On the educational front, in addition to <br\/>enhancing graduate curriculum and research, this project intends to involve <br\/>undergraduate students and women. The tools developed in this project and the <br\/>related results will be made available in public domain and published in <br\/>leading journals\/conferences. In addition, the PIs will also push these <br\/>tools to be incorporated on actual systems, to enhance their fault-tolerance<br\/>abilities.","title":"Collaborative Research: CSR---SMA+AES: Pro-Active Runtime Health Enhancement of Large-Scale Parallel Systems Using PROGNOSIS","awardID":"0615097","effectiveDate":"2006-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["542015"],"PO":["535244"]},"117847":{"abstract":"This project, building a testbed for optical\/wireless integration, aims at meeting the need of next generation communication systems, providing high data rates with ubiquitous access anytime anywhere. The integration of existing heterogeneous networks (including optical high-speed SONET, 3G cellular, Wireless LAN (WiFi), the forthcoming WiMAX, etc.), demands new solutions to issues such as architecture design for efficient integration, mobility management, network management, resource management, billing models, etc. This work, involving three kinds of access networks (the WiMAX over Sonet\/WDM to WiFi access network, a 3G emulation network, and WiMAX over optical extension network), develops a prototype test bed, namely an emulation environment to evaluate practicality. The testbed supports research not only in the Optical\/Wireless integration, but also in each stand-alone network. Specifically, the instrumentation aims at supporting the following research.<br\/> System design for next-generation communication networks by integrating WiMAX, 3G and SONET,<br\/> Novel wireless network planning strategy based on optical\/wireless integration,<br\/>Bandwidth management in wireless\/wireline networks,<br\/>Seamless integration of UMTS (WCDMA) and WLAN,<br\/>Design and development cognitive jamming in OFDM communications systems,<br\/>Jamming avoidance in MIMO communications systems,<br\/>Secure traffic engineering for next-generation optical networks,<br\/>Resource allocation for 3G cellular networks with multimedia services, and<br\/>Network management for WiFi networks.","title":"MRI: Acquisition of a Testbed for Optical\/Wireless Integration","awardID":"0619693","effectiveDate":"2006-08-01","expirationDate":"2010-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["312117",312117,"489828",312119,312120],"PO":["557609"]},"116527":{"abstract":"0613162<br\/>Steven P. Reiss<br\/>Brown University<br\/><br\/>Designing the Undesignable<br\/><br\/>Software design involves designing the undesignable. It differs from other forms of design in that software design is expected to meet a set of constraints that changes dynamically and faster than the software can adapt.<br\/>Moreover, future trends in software development will force developers to design systems that are out of their control. This research investigates whether a component model that includes the semantics of a component as part of its interface can address these problems of software design. Semantics is used here in the broad sense to include the functionality of the component, security and privacy constraints imposed on or by the component, a recovery model, and an economic model for choosing components. The research involves exploring ways of defining and checking such semantic specifications against component implementations and the use of such specifications as a new design metaphor. If successful, this approach promises to let developers control software design and get a handle on many of the problems that plague the evolution of modern software.","title":"Sod-HCER: Designing the Undesignable","awardID":"0613162","effectiveDate":"2006-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7372","name":"ITR-SCIENCE OF DESIGN"}}],"PIcoPI":["448702"],"PO":["564388"]},"121720":{"abstract":"Visual analysis is defined to be the science of analytical reasoning facilitated by interactive visualizations. The goal of visual analysis is to enable the understanding of massive datasets. Such datasets arise in science, engineering and commerce, as well as intelligence analysis and emergency response. Analyzing large amounts of information is a major intellectual challenge as well as a key technology for homeland security. The<br\/>emerging field of visual analysis is the synthesis of many ideas from otherwise disparate fields including human-computer interaction, scientific and information visualization, statistical graphics and mathematical visualization, and geographic information systems and cartography.<br\/><br\/>The goal of this workshop is to bring together computer scientists and mathematicians to discuss mathematical and computational problems involved in visual analysis. A secondary goal is to engage the mathematical community and introduce them to this application area.","title":"Workshop on the Mathematics of Visual Analysis","awardID":"0639579","effectiveDate":"2006-08-15","expirationDate":"2009-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["564241","423120","483871"],"PO":["532791"]},"116913":{"abstract":"CSR---AES: Collaborative Research: SoftCheck: Compiler and Run-Time Technology for Efficient Fault Detection and Correction in Low nm-Scale Multicore Chips<br\/><br\/>The goal of this project is to develop flexible and efficient Runtime and Compiler System (RCS) technologies to cost-effectively detect and recover from hardware faults in upcoming multicore chips. Semiconductor variations, temperature hot spots, soft errors and aging will make hardware reliability one of the central concerns in the design of multicore processors. RCS technologies will make it possible to meet this challenge because of their flexibility, low cost and ability to target errors that affect program outcome. <br\/><br\/>Two important objectives of this project are: (1) to avoid full instruction replication within or across threads this is key to acceptance in the energy- and cost-conscious commodity markets and (2) to provide knobs to select the desired performance vs. error-coverage tradeoff. <br\/><br\/>A prototype, SoftCheck, will be implemented for evaluation purposes. A wide range of novel, cost-effective fault detection and correction techniques will be designed and implemented in SoftCheck. The fault-detection techniques will include: (i) exhaustive self-checking, (ii) partial self-checking, (iii) partial cross-thread checking in a multicore environment, and (iv) other cross-cutting, often multiprocessor-related, approaches. The fault-correction techniques include: (i) disabling clusters in a core (ii) disabling complete cores, and (iii) dynamic recompilation to use other hardware.","title":"Collaborative Research: CSR--AES: SoftCheck: Compiler and Run-Time Technology for Efficient Fault Detection and Correction in Low nm-Scale Multicore Chips","awardID":"0615273","effectiveDate":"2006-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550505"],"PO":["493916"]},"116924":{"abstract":"Hybrid systems play an increasingly important role in transportation networks, robotics and in fields such as medicine and biology. Today hybrid systems are found in sophisticated embedded controllers used in the airplane industry, but also in medical devices that monitor serious health conditions. As hybrid systems are often part of devices operating in safety-critical situations, the verification of their safety properties becomes increasingly important. A hybrid system is considered safe if it is not possible for the system during its evolution to enter an unsafe state starting from an initial safe state. This project develops modeling algorithms and analysis techniques for the verification of safety properties of hybrid systems. Its main goal is the design and implementation of a probabilistically complete framework for computing trajectories that take the system from a safe to an unsafe state, or witness trajectories. Existence of a witness trajectory indicates that the hybrid system is not safe. When a witness trajectory is not found, the repeated application of the proposed methodology can increase the user's confidence in the safety of the system. Since hybrid systems have discrete and continuous aspects of control, a witness trajectory consists of one or more continuous parts interleaved with discrete transitions. This project blends in a novel way search methods for continuous spaces inspired by research in robot motion planning, with search techniques for discrete spaces and formal tools. The problem addressed is of central importance for the creation of high-confidence hybrid and embedded systems with reliability guarantees.","title":"CSR\/EHS: A Robotics-Inspired Approach for the Verification of Hybrid Systems","awardID":"0615328","effectiveDate":"2006-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["565263","557516"],"PO":["561889"]},"117903":{"abstract":"This project, acquiring a 96-node\/1536-core Opteron cluster with Infiniband interconnect and 10TB storage, facilitates a rich diversity of research at the interface of computer science and biology. The research to be enabled has many applications with a remarkable range of scale, from the sub-molecular to the organismal. The work is motivated by a common desire to push novel computational approaches to the limit that most significant problems can be tackled with available computational resources (both in terms of algorithmic advances and in terms of solving the largest). The project represents a broad range of methods, from physics-based simulation, to genomics and proteomics, to biostatistics, to joint experimental\/ computational methodology. The enabled research can be grouped in four areas:<br\/><br\/>-Simulation and modeling of macromolecular structures,<br\/>-Analysis of sequence and genomic\/proteomic datasets,<br\/>-Modeling of very large datasets, and <br\/>-Fundamental computer science.<br\/><br\/>Besides enabling research, the instrument is an advance in commodity computing combining the low cost of Linux clusters with the power of shared memory machines. Out comes a supercomputer with a very low total cost of ownership. Highlights include:<br\/><br\/>-Molecular dynamics simulation based on quantum mechanically derived force fields: to understand hydrophobic effect that drives protein folding and to get closer to the goal of accurately modeling protein folding<br\/>-Modeling of structure water in ribosome: to understand protein structure and function in the cellular milieu<br\/>-Integration of genetic networks using genome sequence and experimental data: to appropriately combine disparate information into a single unifying framework based on common gene function and evolutionary descent<br\/>-Whole genomic alignments and inference of evolutionary constraints: to predict impact of population genetic variation on the function of the organism, at the interface of population genetics and evolutionary theory<br\/>-Simulation of human motion based on accurate, yet tractable, models of the neuromusculoskeletal system and simulation of blood flow in aorta: areas known for applied value<br\/>-Development of algorithms for fluid dynamics, solid mechanics, graphics, segmentation, computer vision: areas of computer science with a strong mathematical component, as well as applied aspects such as movie animations","title":"MRI: Acquisition of a Hybrid Shared-Memory \/ Massively-Parallel Commodity Cluster for Cost-Effective Super-Computing at Stanford","awardID":"0619926","effectiveDate":"2006-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[312372,"467067","483870",312375,"419817"],"PO":["557609"]},"116935":{"abstract":"Title: Energy Conservation in Storage Systems Using Coding Techniques <br\/><br\/>The project explores system-level energy management schemes for storage systems. It aims to develop storage organizations, groupings, and data layouts that facilitate energy conservation by exploiting complex redundancy already built into the system for fault tolerance. The approach is motivated by the trend towards using increasingly sophisticated redundancy techniques in storage systems to guard against data loss. The project investigates methods to leverage this redundancy to provide additional functionality, in particular energy conservation. The project involves several components: exploration of the design space using replication as well as erasure-coding techniques for energy conservation, design of control mechanisms and algorithms for dynamic disk provisioning and associated performance and energy models, and development of a test-bed for empirical validation of the techniques.<br\/><br\/>Energy consumption has become an increasingly important issue in the operations of large-scale storage systems. Power and cooling equipment, and electricity together represent a significant portion of the total cost of ownership. The results of this project have potential for economic and environmental impact on the operation of large storage centers.","title":"Collaborative: CSR - PDOS: Energy Conservation in Storage Systems using Coding Techniques","awardID":"0615376","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["410022"],"PO":["535244"]},"117837":{"abstract":"Proposal No. CTS-0619641<br\/>Principal Investigator: Patrick A. Tebbe, Minnesota State University, Mankato<br\/><br\/><br\/>MRI: Acquisition of a Linux Cluster to Fulfill High Performance Computing Needs Within Engineering and Science <br\/><br\/>This Major Research Instrumentation grant will improve the computational infrastructure of the Departments of Mechanical and Civil Engineering (MECE) and Computer and Information Science (CIS), at Minnesota State University Mankato (MSU). A Linux computer cluster will be acquired with the memory and architecture properties required to facilitate ongoing research, course, and training activities. Engineering software that has been optimized for use on a distributed processor system is also requested to allow the system to be fully utilized for engineering research and education. The equipment and software will directly support three research projects with critical computational needs: 1) Study of Transient and Three-dimensional Effects in Physical Vapor Transport, 2) Linguistic Features for Speech Recognition, and 3) Statistical Disclosure Assessment. Each of these topics is currently restricted by a lack of high performance computing (HPC) infrastructure. The overarching broad impact of this project will be to increase high-performance computing in the research and educational experiences of engineering and science students and enhance the research potential of faculty at MSU. Acquisition of the resources described will enable these and future research projects to move forward while aiding the institution in meeting its educational goals. The equipment will be used in numerous undergraduate and graduate courses in both departments. In addition, a new cross-disciplinary Seminar in High Performance Computing course will be created based on these research topics and this equipment. Through this seminar and the numerous affected courses, undergraduate and graduate students will be exposed to high performance computing and trained for its use in research. Outreach and training of other campus faculty will be conducted in order to increase the number of potential research and classroom users of the system. MSU is a non-Ph.D. granting institution and the recent recipient of a $2 million grant from the State of Minnesota to establish a Center of Excellence in Manufacturing and Engineering. The Center partners MSU with 5 technical or community colleges and one state Higher Education District. With the objectives of building partnerships with K-12 and industry, a unique opportunity exists to leverage this proposal with the Center's work. In addition, numerous external entities including several universities, an international university, NASA, and a small company will be involved as research collaborators with these projects.","title":"MRI: Acquisition of a Linux Cluster to Fulfill High Performance Computing Needs Within Engineering and Science","awardID":"0619641","effectiveDate":"2006-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1443","name":"FLUID DYNAMICS"}}],"PIcoPI":[312067,"412396","548330"],"PO":["525323"]},"116869":{"abstract":"Computer systems are becoming victims of their own success. Deployed<br\/>software has orders of magnitude more users, software environments,<br\/>and usage patterns than it has in testing labs, which leads to two<br\/>fundamental problems. First, software complexity accounts for a large<br\/>fraction of system cost---the cost of administering, configuring,<br\/>updating, performance tuning, and supporting systems is surpassing the<br\/>cost of the hardware. Second, software complexity becomes a<br\/>first-order limit on key system properties like reliability,<br\/>performance, and usability. <br\/><br\/>The goals of this work are to build prototype software systems that<br\/>integrate machine learning to simplify operation, avoid performance<br\/>problems, and make efficient use of computer resources. For<br\/>distributed systems like web services the key goals are avoiding<br\/>performance pitfalls and making efficient use of computing resources.<br\/>Software support addresses the problem of configuring software and<br\/>fixing it or the environment when something goes wrong. Autonomic<br\/>network diagnosis requires the system to identify and correlate events<br\/>to reach a diagnosis for the state of the network. The work will address<br\/>the security problems of information leakage that arise when mutually<br\/>distrustful parties share machine learning models, as they might for<br\/>software support (software vendor and user) and network diagnosis<br\/>(competing network providers).","title":"CSR--PDOS: Autonomic Systems: Integrating Machine Learning with Computer Systems","awardID":"0615104","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["450689","553684","519592","555324","266247"],"PO":["561889"]},"126307":{"abstract":"Graph partitioning is a fundamental combinatorial optimization<br\/>problem that has many practical applications such as<br\/>in supporting efficient load balancing for parallel processing,<br\/>in VLSI layout, and in data clustering. This proposed research program <br\/>focuses on the study of spectral methods for graph partitioning.<br\/>Spectral methods make use of the eigenvectors of graph matrices (e.g., <br\/>the Laplacian or the adjacency matrix of a graph) to construct a quality<br\/>partitioning. They have been popularly used in practice<br\/>for partitioning meshes in scientific simulation, for dividing graphs<br\/>derived from circuits, and for clustering data in web-graph analysis<br\/>and information organization. However, the quality of the partition that <br\/>these methods should produce has so far eluded precise analysis.<br\/>Spielman and the PI made some breakthrough progresses.<br\/>In particular, by proving that the second smallest eigenvalue of<br\/>the Laplacian matrices of bounded-degree planar graphs<br\/>is at most O(1\/n), Spielman and the PI<br\/>showed that proper use of spectral techniques can produce<br\/>a bisection of graphs with cut size at most $O(\\sqrt{n})$,<br\/>which is best possible for the family of planar graphs.","title":"ITR: Collaborative Research: Smoothed Analysis of Algorithms","awardID":"0707522","effectiveDate":"2006-08-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["483530"],"PO":["499399"]},"121721":{"abstract":"The goal of this project is to bridge the gap between ecology research and natural resource managers, in particular field foresters who make day-to-day decisions regarding which stands to harvest and which trees to leave in these harvested stands. These managers balance conflicting goals: produce revenue, preserve forests, and provide habitat. The project aims to determine which ecology research results and data are most applicable to the problem of leavetree-selection, and distill relevant work into a form usable by field foresters in the Pacific Northwest. Initially, the team will identify the most applicable ecology research results, and produce prototype decision aids for the selection of leave trees. We will develop a knowledge representation for forest management guidelines and tree crown characterization. The research team is composed of computer scientists and ecologists from The Evergreen State College and Portland State University; and a forest biometrician, programmer, and resource managers from the Washington State Department of Natural Resources. The result of the work lies in databases and tools, as well as papers and software developed that will help move recent research results from data to decisions and paper to process, and in the concomitant computer science research that has implications beyond this problem and its domain. These include appropriate knowledge representations for research results and scientific artifacts, cognitive aspects of models, research results, and scientific visualization, and improving decision making aids. Other impacts include improved natural resource decisions in Washington State and a characterization of needs of a certain class of decision makers. Educational impact includes a natural resource management component in a full time, quarter-long undergraduate interdisciplinary course (computer science, mathematics, ecology). A course in evidence-based natural resource management for the Evergreen Masters' Program will be designed, and a workshop for Oregon State University ecoinformatics Ph.D. students will be conducted.","title":"SGER: From Measurement to Management: Evidence-Based Practice in Natural Resource Management","awardID":"0639588","effectiveDate":"2006-08-15","expirationDate":"2008-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1629","name":"BE: NON-ANNOUNCEMENT RESEARCH"}}],"PIcoPI":["483300","533018","474015","537156"],"PO":["565136"]},"120753":{"abstract":"Modern means of communication, such as web-logs, chatrooms, and e-mail messaging, provide unprecedented opportunities for a vast number of people to express their opinions and communicate with other people, most of whom are not personal acquaintances.<br\/><br\/>On August 26, 2005, TheWall Street Journal published an article by Daniel Henninger, \"A Quite Majority Replaces Vietnam's 'Silent Majority'.\" He writes: \". . . Richard Nixon . . . gave a famous speech in 1969. . . . The idea, of course, was that the daily attention commanded by the anti-war movement was missing a class of Americans who sat home seething at the behavior of protesters. Today, because of the Internet, no one has to seethe in silence, as wired activists in both parties proved in 2004's high-tech elections, and now. But it may be that the current infatuation with anti-Bush, anti-Iraq sentiment is again missing a political current flowing beneath the surface of the news, just as the media missed . . . the value voters in the 2004 election.\"<br\/><br\/>The political and social reality of our time includes a huge communication space, \"the electronic society,\" which allows an ever growing number of people to express themselves and actively participate in the social life of the general society. It is expected that drastically increased ways of self-expression and communication should intensify the processes of forming and evolving social trends. The electronic space is so large that it demands sophisticated computer algorithms in order to address important questions and do meaningful analysis.<br\/><br\/>In any social network, links are formed and broken in a never ending dynamics that represents the evolution of the social network. As the network evolves, social groups form and evolve, and occasionally a social group may grow to a size large enough to represent a new movement or coalition. The goal of this research is to track and discover such coalitions as they form and evolve in the Blogosphere.<br\/><br\/>While technically it is easy to track the evolution of one particular actor of an electronic society, it is much more important and much more difficult to discover groups composed of actors that are holding \"reasonably\" close although not identical opinions, and to differentiate them from those with substantially different opinions. In addition to the immense amount of data to be processed, the researcher must be aware of the volatility of such groups, whose members may agree on some issues, and disagree on others.<br\/><br\/>The straightforward attempt to discover and characterize these groups might involve listing out topics and positions of the actors. This approach is practically impossible not only because of the time necessary to read (by humans) the publications, but also because of the difficulty in characterization: many nuances and subtleties may look contradictory and inconsistent. Using an automated system for reading would not be practical either as it would also require a substantial linguistic analysis of each article.","title":"SGER: Algorithms and Software Tools for Discovering Coalitions and Identifying Leaders in the Blogosphere","awardID":"0634875","effectiveDate":"2006-08-01","expirationDate":"2008-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T471","name":"CIA-KDD WORKING GROUP"}}],"PIcoPI":["548125",320859,"489824"],"PO":["565136"]},"110600":{"abstract":"Prop ID: CCF-0541297 <br\/>PI: Maly, Wojciech <br\/>Institution: Carnegie-Mellon University <br\/>Title: VIrtual TEst STructure (VITEST) <br\/><br\/>Abstract<br\/><br\/>Modern Integrated Circuits (ICs) are built of elements so small that some of them may be too small to be fabricated correctly on everyone fabricated device. Art of modern IC manufacturing is in choosing such scale of miniaturization IC elements (typically transistors) that pushes available technology to its limits, i,e, to the stage in which number of fabricated ICs that work correctly is acceptable and at the same time the number of elements in a single IC as large as possible (by making them as small as possible).<br\/><br\/>To achieve such a balance one must understand specific circumstances causing IC malfunction. Typically such knowledge is acquired by using special purpose test structures, which are fabricated instead of normal IC and therefore are wasting very expensive manufacturing capacity. <br\/><br\/>The key idea of the research covered by this project is in the use of IC products themselves for calibration of manufacturing yield models. These models form a foundation of methodologies used for assessment probability of IC malfunctions.","title":"VIrtual TEst STructure (VITEST)","awardID":"0541297","effectiveDate":"2006-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["401581"],"PO":["562984"]},"120764":{"abstract":"This SGER project is concerned with incorporating uncertainty information into visualization to make the visualization trustworthy. We will study uncertainty information introduced particularly in the process of data analysis and visualization, and develop methods for working with uncertainty at all stages of the data visualization pipeline, including not only the visualization of data in the presence of uncertainty, but also visualization methods that provide insight into the nature of the uncertainty itself to assist in the development of improved experimental designs. The benefits of this research have the potential to provide<br\/>fundamental improvements in the ability to understand and make decisions based on data with uncertainty.<br\/>The main objective of this SGER project is to set a foundation for extensive research. In this one-year project we will first study and model the perception uncertainty and ambiguity of 2D visualizations of 3D or high-dimensional data in order to create refined visualizations that are less ambiguous. The proposed research is unique and ambitious because we attempt to effectively incorporate uncertainty information into visualization and data understanding by considering both the nature and effect of uncertainty in the human cognition context as well as representative application contexts.","title":"Incorporating Uncertainty for Trustworthy Visualization","awardID":"0634913","effectiveDate":"2006-08-01","expirationDate":"2008-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["552243"],"PO":["532791"]},"110556":{"abstract":"ABSTRACT: <br\/>High-Performance Data Access through Memory Abstraction <br\/><br\/>B-trees have been the data structures of choice for external-memory searching for decades because they minimize the number of disk-block accesses performed during a search. It is well known, however, that B-trees are empirically suboptimal because they exploit data locality at only one level of granularity, typically disk blocks, but not at coarser granularities, such as disk tracks, or finer granularities, such as cache lines. <br\/><br\/>Theoretical developments on cache-oblivious data structures and algorithms have shown how to achieve nearly optimal locality of reference simultaneously at every granularity. A striking feature of cache-oblivious data structures is that they free the programmer from the burden of tuning the code for cache and disk effects. The PIs' recent experiments suggest that cache-oblivious B-trees (CO B-trees) can surpass the performance of highly tuned traditional B-trees. CO B-trees achieve superior performance because they approximately optimize for all memory effects. In contrast, cache-aware algorithms ignore important aspects of the memory hierarchy. CO B-trees are not yet ready to be used in file systems and data bases, however, because they lack essential capabilities of industrial-strength B-trees, such as support for variable-size keys, concurrent accesses, and transactions. <br\/><br\/>The researchers propose to investigate how CO B-trees can achieve their potential. The researchers plan to study the wide range of algorithmic problems in data structures, stringology, and distributed systems required to develop a full-featured CO B-tree. In addition, the researchers plan to solve online scheduling problems so that virtual-memory systems can provide efficient support for cache-obliviousness. This algorithmic work is necessary to transfer CO technology to other areas of computer science, engineering, and scientific computing and is intended to transform how scientists and engineers manipulate massive data sets.","title":"Collaborative Research: High-Performance Data Access through Memory Abstraction","awardID":"0541097","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["531670"],"PO":["559883"]},"121578":{"abstract":"Computer Tomography Angiography (CTA) is rapidly emerging as a diagnostic and guiding tool to rule out coronary artery disease in patients. It is predicted that, owing to its non-invasive nature and promising results, CTA will reduce the number of catheterizations by 30%. The increased use of CTA is resulting in a large amount of data, but there are no computational tools to perform analysis on coronary artery plaques. Hence, there is an urgent need to develop computational tools to automatically detect the coronary arteries and then proceed to the assessment of arterial plaque in CTA. To assess such a large amount of CTA data, the process of vessel segmentation needs to be automated. This will require the development of methods to detect tubular structures in the presence of multiple surrounding tissues and uneven distribution of contrast. The objectives of this project are to develop automated, data-driven feature detection for tubular structures, and to develop feature-based learning and prediction algorithms allowing an improved segmentation of tubular data and apply them to the domain of CTA. A successful outcome has the potential of improving health care quality while simultaneously reducing the cost.","title":"Segmentation of 3D Tubular Structures","awardID":"0638875","effectiveDate":"2006-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}}],"PIcoPI":["554348"],"PO":["565136"]},"116903":{"abstract":"NSF Award Abstract<br\/><br\/>There is a fundamental change ongoing in the computer industry. Instead of increasing clock frequency, which increases power dissipation, CPU chip manufacturers are using advances in semiconductor technology to increase the number of cores on a processor chip. This shifts the burden of improving program performance from chip manufacturers to software developers. Many industry experts believe that programming multicore processors is now the most important challenge facing the software industry.<br\/><br\/>Compiler technology for parallel architectures is not effective for irregular applications that use linked data structures such as trees and graphs. These data structures are ubiquitous in important application areas like graphics, mesh generation and linear system solvers.<br\/><br\/>This project develops a new approach for parallelizing and optimizing irregular programs for multicore processors. The key insight is that optimistic parallelization is essential for irregular programs. Transactional memory is an attractive way to implement optimistic parallelization; this project will design, implement and evaluate new transactional models that exploit properties of high-level program abstractions rather than simply tracking low-level reads and writes.<br\/><br\/>Results will be disseminated through publications and by making the software transactional memory system available for downloading. Technology transfer to leading companies is another avenue for disseminating results.","title":"CSR-AES: Parallelizing Irregular Applications for Multicore Processors","awardID":"0615240","effectiveDate":"2006-08-01","expirationDate":"2009-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[309332,"556730","508159"],"PO":["551712"]},"127925":{"abstract":"Nikolopoulos, Dimitrios<br\/>College of William and Mary<br\/>CCF-0346867<br\/><br\/>This research activity involves the design, development and deployment<br\/>of a programming framework for explicit multilevel parallelization using a <br\/>global address space model. The framework targets the upcoming generation of <br\/>Petaflop-class supercomputers, which are based on architectural substrates <br\/>with multiple levels of on-chip and off-chip parallelism and deep memory <br\/>hierarchies. The research addresses the need for increased productivity and <br\/>utilization of the National supercomputing power, by attempting to close the <br\/>gap between computer architecture innovation and parallel programming <br\/>practices. The main goal of this activity is to reduce the <br\/>programming effort required for mapping algorithmic parallelism to <br\/>hierarchical hardware components with heterogeneous means for parallel <br\/>execution and assist programmers in deriving balanced designs of layered parallel applications. The programming framework <br\/>investigated in this research unifies parallel programming models and <br\/>methodologies and enables faster adaptation of parallel code to new hardware <br\/>platforms. Concurrently, it forms a basis for education and training of <br\/>interdisciplinary student audiences in high performance programming. <br\/><br\/>The parallel programming component of this research is designed around <br\/>standard C++ templates with notation for nested threads and iterators. <br\/>The notations for parallelism are coupled with a templated representation of <br\/>data, which allows for arbitrary partitioning, sharing, and coherence control <br\/>at multiple levels of parallel execution constructs. While the programmer <br\/>highlights nested parallelism, the orchestration and management of multigrain <br\/>threads and data are delegated to the compiler and the runtime system. The <br\/>research investigates novel methods for controlling the <br\/>granularity of multilevel parallelism via vertical analysis of the program. <br\/>Periodicity analysis and selective runtime tracing are used as means to <br\/>derive effective data distribution and layout schemes without user<br\/>intervention. Alongside runtime analysis, new resource-driven scheduling <br\/>strategies and novel microprocessor features, including on-chip <br\/>multithreading, on-chip SIMD parallelism and speculative execution, are <br\/>incorporated into the parallelization and program optimization processes.","title":"CAREER: A Unified Framework for Multilevel Parallelization on Deep Computing Systems","awardID":"0715051","effectiveDate":"2006-08-10","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}}],"PIcoPI":["402035"],"PO":["381214"]},"116925":{"abstract":"Abstract: Distributed applications often require the underlying distributed algorithms and middleware to be customized to meet stringent performance requirements. This is typically addressed by manually re-implementing portions of existing algorithms, which is tedious and error-prone. The goal of this project is to develop a comprehensive framework for automated customization of distributed algorithms and middleware. The work aims at developing technologies for various aspects of customization, which include (a) techniques to design distributed algorithms and middleware amenable to customization, (b) domain-specific languages for specifying rules to identify customization opportunities, (c) infrastructure to analyze the specifications to determine when customization rules can be applied, (d) tools to perform the code transformations necessary to perform the optimizations, and (e) extensive evaluation of the developed technologies on a number of applications. The expected project outcomes include tools for automatic customization of algorithms, a study of the extent to which generic distributed algorithms can be customized automatically and a characterization of the types of customizations applicable to different classes of algorithms. This research will ease the development of efficient distributed algorithms to meet the requirements of different applications. Research results from this project will be leveraged in developing new courses on component based design of distributed systems, and in advancing multidisciplinary activities in the area of distributed sensor systems. Technology transition activities will be pursued in collaboration with our industrial partners. Efforts will be made to involve undergraduates and students from underrepresented groups in the research and educational activities.","title":"CSR -- PDOS: Methodologies for Customization of Distributed Algorithms and Middleware","awardID":"0615337","effectiveDate":"2006-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["528451"],"PO":["535244"]},"117805":{"abstract":"This project, developing a shared network measurement analysis and storage infrastructure called the Datapository, aims at providing a common platform of data analysis and management tools. The instrument serves as a research platform for creating a larger-scale, publicly accessible measurement analysis and storage infrastructure. Collection and analysis of data from real deployments critically challenges the network community, as well as experiments driven by such data. This work aims at reducing the substantial administration time and costs associated with management large amounts of data needed by researchers by building a shared infrastructure from off-the-shelf components, and consequently facilitating the following research efforts:<br\/>-Creating Internet-scale forensic analysis architectures,<br\/>-Understanding and improving Internet routing,<br\/>-Designing and evaluating highly available network architectures,<br\/>-Evaluating novel data transfer architectures,<br\/>-Testing worm and intrusion detection algorithms on large network trace collections, and<br\/>-Enabling several educational outreach projects.<br\/><br\/>These efforts face a significant challenge of data management, organization, and analysis, requiring substantial hardware and software infrastructure to store and analyze terabytes of network measurement data. The Datapository includes database configuration and setup, schema optimization, data organization and classification, data distribution, hardware and operating system configuration, and the creation of a code to perform basic filtering and processing of the data. The measurement and analysis infrastructure will serve as the base prototype for the development of a large-scale publicly accessible network data repository.","title":"MRI: Development of a Shared Network Measurement Storage and Analysis Infrastructure","awardID":"0619525","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}}],"PIcoPI":["526903","435983","548263",311936],"PO":["557609"]},"117816":{"abstract":"This project, developing a new generation of mobile robots with wall-climbing and reliable communication capabilities, develops a set of miniature robots to be used as a research instrument suitable for a broad class of research in distributed robotics, mobile sensor networks, and reliable wireless communication. Transforming the present 2-D world of mobile rovers into a 3-D universe, this new generation of mobile robots operates on many types of surfaces, moves on floors, climbs walls, walks on ceilings, and transits between them. The robots contain highly capable, highly adaptive FPGA-based multiprocessors to support sensing, computing, communications, and dynamic reconfigurability or resources, enabling research and development in a wide range of tasks in urban search and rescue, surveillance, environmental monitoring, and planetary exploration. The wall-climbing robots consist of the FPGA-based multiprocessors with vision and wireless communication capabilities. The robots form a comprehensive testbed for measuring various sought-after metrics such as performance, QoS, and reliability in distributed robotics applications.","title":"MRI Instrument Development: A New Generation of Mobile Robots with Climbing and Reliable Communication Capabilities","awardID":"0619577","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}}],"PIcoPI":["540076","554596"],"PO":["557609"]},"115517":{"abstract":"This award provides support for a three year continuing award, a renewal of the BBSI@PITT:Simulation and Computer Visualization of Biological Systems at Multiple Scales, at the University of Pittsburgh, under the direction of Dr. Ivet Bahar. This program offered since 2002 by the University of Pittsburgh (lead institution), the Pittsburgh Supercomputing Center, Duquesne University, and Carnegie Mellon University, will host a ten week summer program for a total of 39 undergraduate and graduate students, 13 per year, for a total of three years. The students will have strong analytical and quantitative skills and high potential for careers in Computational Biology, Bioengineering, or Bioinformatics. BBSI@Pitt will continue to focus on computational and mathematical approaches to understanding the function and dynamics of molecular and cellular systems using known structure, biochemical pathways and other data, much of which is increasingly accumulated in web accessible dateabases. <br\/><br\/>The objectives of BBSI@Pitt are to provide students with a unique training and research experience through a series of cross-disciplinary lectures, computational laboratory sessions, and independent research opportunities not available in traditional undergraduate programs; broaden the student's view of post-genomic computational and mathematical research areas in molecular, cellular, and systems biology; and motivate students to pursue careers in the field.<br\/><br\/>Computational Biology, Bioengineering, and Bioinformatics exist at the interface of many different fields, and individuals with truly cross-disciplinary expertise are quite rare. BBSI@Pitt will continue to have a broad impact on the field by identifying and encouraging promising young students through intensive cross-disciplinary mentoring, providing advice and guidance for career options, and thus contributing to transforming the new generation's approach to biomedical computing problems of far greater complexity than those accessible to earlier generations.<br\/><br\/>This project is being co-funded by the Directorate for Mathematical and Physical Sciences (MPS)\/ Office of Multidisciplinary Activities (OMA) and the Division of Mathematical Science (DMS), the Directorate for Computer and Information Science and Engineering (CISE)\/ Division of Information and Intelligent Systems (IIS) , the Directorate for Engineering\/ Division of Engineering Education and Centers (EEC), and the National Institutes of Health (NIH)\/National Institute of Biomedical Imaging and Bioengineering (NIBIB).","title":"BBSI@PITT: Simulation and Computer Visualization of Biological Systems at Multiple Scales","awardID":"0609139","effectiveDate":"2006-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"1758","name":"BIOENGINEERING & BIOINFORMATIC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"H185","name":"National Institute of Biomedic"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"T343","name":"NIH-BIOENG & BIOINF SUMMER RES"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"T816","name":"NH-BIO SUMMER RESEARCH&TRAININ"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1106","name":"Division of HUMAN RESOURCE DEVELOPMENT","abbr":"HRD"},"pgm":{"id":"1260","name":"INFRASTRUCTURE PROGRAM"}}],"PIcoPI":["392117","518908",305885],"PO":["560483"]},"115759":{"abstract":"A hyperspectral long wavelength infrared (LWIR) imaging sensor may have the ability to utilize polarization phenomena as well. Together, this could enable a new design to be used as a passive detection technique for locating concealed objects and disturbed earth. At shorter wavelengths, a tunable spectral imaging filter has been used, particularly in the Mars orbit satellite. Using such a filter for LWIR has been an materials research challenge. The team has made a significant advance that will permit this technology to be used to demonstrate the basic optical and spectral materials of the mercurous bromide and thallium arsenic selenide materials. The technology should enable the production of very compact and lightweight sensors, capable of being carried or used as an unattended ground sensor. The prototype would be tunable, so that the operator could select the preferred frequency and bandwidth specific to the use of the sensor, thereby enabling a ore generalized collection of hyperspectral data. Rapid data analysis wil provide feedback of rapid detection of ground disturbances, such as in mines, or noxious materials. The research projects will engage students in pushing this engineering and data analysis frontier.","title":"Compact LWIR Hyperspectral Polarimetric System Using AOTF Technology [UoH_FY06_015]","awardID":"0610229","effectiveDate":"2006-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T377","name":"DIA-MASINT CONSORTIUM PROJECT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T768","name":"DIA -MASINT RESEARCH PROJECT"}}],"PIcoPI":[306573],"PO":["565136"]},"112504":{"abstract":"Abstract<br\/><br\/>Program: NSF 04-588 CISE Computing Research Infrastructure<br\/>Title: CRI: Collaborative Research: SMT-LIB, A Common Library and Infrastructure for Satisfiability Modulo Theories <br\/><br\/>Lead Proposal: CNS-0551646<br\/>PI: Tinelli, Cesare<br\/>Institution: University of Iowa<br\/><br\/>Proposal: CNS-0551697<br\/>PI: Stump, Aaron D.<br\/>Institution: Washington University<br\/><br\/>Proposal: CNS-0551645<br\/>PI: Barrett, Clark<br\/>Institution: New York University<br\/><br\/><br\/>Investigators at the University of Iowa, Washington University and New York University will develop a community resource for users and developers of solvers for satisfiability modulo theories (SMT). The solvers are logical reasoning programs used in software and hardware verification. The project will develop standards and interfaces to enable incorporation of solvers into verification tools and benchmarks and develop services for accurate evaluation and comparison of SMT solvers. These will support use by a broad community of researchers. Broader impacts of this project are the improvement of research capability in verification. Longer-range benefits will include more reliable future hardware and software systems.","title":"CRI: Collaborative Research: SMT-LIB, A Common Library and Infrastructure for Satisfiability Modulo Theories","awardID":"0551645","effectiveDate":"2006-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["550906"],"PO":["550859"]},"116937":{"abstract":"Large-scale computational resources are increasingly being delivered through distributed clusters of commodity workstations, which, when taken as a whole, provide the raw horsepower of traditional supercomputers at significantly reduced cost. Unfortunately, economic reality still dictates that large clusters must be shared across multiple, distinct applications, each with their own resource needs. This project focuses on designing and implementing an efficient management framework that enables the creation, allocation, and management of virtual clusters.<br\/><br\/>A logical abstraction layered on top of a set of physical machines, virtual clusters harness virtual machine technology to more efficiently share computational resources between competing<br\/>application demands while ensuring fault isolation. Critically, this proposal leverages the power of virtual machine monitors to provide novel functionality for an emerging class of applications. In<br\/>particular, by exposing the dynamic levels of parallelism, dilating logical time, and supporting apparently infinitely large clusters, this work supports the distinctive needs of grid computing, network modeling, and Internet epidemiology.<br\/><br\/>An output of this work will be a fully operational environment for managing cluster-based computational resources integrated with publicly available virtual machine technology. In addition to dynamically adjusting resources in response to changes in demand and application load, virtual clusters can instantly create clones of existing virtual machines, a functionality critical to the deployment of large-scale high-fidelity honeypots. Finally, the ability to slow down logical time within a virtual cluster---thereby speeding up the relative speed of network communication---enables the emulation of network links orders of magnitude faster than those typically available on commodity clusters.","title":"CSR---PDOS: Harnessing Virtualized Cluster Resources","awardID":"0615392","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["485593","525660","548363","518658"],"PO":["493916"]},"114407":{"abstract":"TECHNICAL SUMMARY:<br\/>This award supports computational and theoretical research and education in the area of polymer simulation. This project will build on the recent development by the PI and co-workers of the \"field-theoretic simulation\" (FTS) method, enabling numerical investigations of field theory models of polymers, complex fluids, and soft materials without resorting to the mean-field approximation. The proposed research encompasses both fundamental and applied components.<br\/>. Foundations and extensions of the FTS method. This research thrust will include development of improved numerical schemes for time integration of the stochastic \"complex Langevin\" equations used to implement potential field updates. We also propose to develop a new \"ground state-FTS\" technique that should dramatically accelerate simulations of strongly overlapping polymer solutions (neutral and charged) in the semi-dilute and concentrated regimes.<br\/>. Numerical renormalization group theory. We propose to implement pseudospectral numerical RG transformations in tandem with complex Langevin simulations of polymer field theories. This will facilitate the isolation of lattice cutoff effects and enable systematic coarse-graining of polymer solution models. The PI envisions applications to block copolymers in selective solvents.<br\/>. Hybrid particle-field simulations. We propose to develop a new class of simulations for treating nanoparticles or colloids embedded in structured polymer fluids. The particles are treated as \"cavities\" in the fluid fields and the particle coordinates are retained along with the fluid field variables.<br\/>. Defects in confined copolymer films. Translational and bond-orientational order will be examined in FTS simulations of block copolymer films with perimeter boundary conditions. The results will be used to assess the efficacy of grapho-epitaxy for creating defect-free copolymer films that can be used in ultra-high density patterning of advanced electronic, optical, and magnetic devices. The proposed research will closely couple with an experimental program underway in the laboratory of Edward J. Kramer at UCSB.<br\/>The PI will continue in his tradition of effective graduate and post-doctoral training in theoretical and computational polymer science. A particular focus will be to expose students and post-docs with classical physics training to broader soft materials\/polymer science disciplines through a close coupling with experimental groups at UCSB in chemical engineering, materials, and chemistry. The fundamental understanding gained under the proposed project will be further leveraged through the Complex Fluids Design Consortium (CFDC) at UCSB, an industry-national lab-academic partnership that is addressing the computational design of commercial polymer and complex fluid formulations.<br\/><br\/>NON-TECHNICAL SUMMARY:<br\/>This award supports computational and theoretical research and education in the area of polymer science using computers to simulate polymer materials and polymer-related phenomena. The PI plans to continue his work on fundamental theoretical advances and new algorithms aimed at extending a simulation method he developed and at developing new simulation methods for inhomogeneous polymer materials, complex fluids, and soft materials. These methods are needed to handle essential physics that arises across diverse length and time scales in these materials and often makes reliable computer simulation difficult. In an effort coupled to experiment, the PI plans to apply these newly developed advanced simulation methods to thin films of block copolymers and to investigate a promising experimental technique for creating nearly perfect copolymer films that can be used as a template to synthesize inorganic nanowires, nanodots, and other nanoscale structures. <br\/>The PI will continue in his tradition of effective graduate and post-doctoral training in theoretical and computational polymer science. A particular focus will be to expose students and post-docs with classical physics training to broader soft materials\/polymer science disciplines through a close coupling with experimental groups at UCSB in chemical engineering, materials, and chemistry. The fundamental understanding gained under the proposed project will be further leveraged through the Complex Fluids Design Consortium (CFDC) at UCSB, an industry-national lab-academic partnership that is addressing the computational design of commercial polymer and complex fluid formulations.","title":"Field-Theoretic Polymer Simulations: Fundamentals and Applications","awardID":"0603710","effectiveDate":"2006-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0307","name":"Division of MATERIALS RESEARCH","abbr":"DMR"},"pgm":{"id":"1765","name":"CONDENSED MATTER & MAT THEORY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1266","name":"APPLIED MATHEMATICS"}}],"PIcoPI":["560826"],"PO":["141355"]},"116618":{"abstract":"Directorate for Computer and Information Science and Engineering (CISE)<br\/>Division Computer and Network Systems (CNS)<br\/>Science of Design (SoD) Program<br\/><br\/>Proposal Number: 0613738 <br\/>P\/I: Mark Guzdial <br\/>PI's Department: College of Computing <br\/>Institution: Georgia Institute of Technology <br\/>Award: $ 137,114 <br\/><br\/>Title: \"SoD-HCER: Contextualized Design Education for Professionals from Non-Computing Disciplines\"<br\/><br\/>The focus of this project is on end-user programmers. End-user software developers are people who are design and implement software but who have not been formally trained to engage in this activity. This is a large population (estimated between 55 and 90 million people) whose activities range from coding in programming or scripting languages in order to extend the capabilities of a tool, to writing macros for widely used office products or developing web materials. Some of the questions addressed in the project are: \"What do local developers know about design? What should local developers learn about design? How can we teach them about design? What do they understand about data structures, structured programming, or structured processes? If there is a documented lack of design knowledge, what is its impact on their artifacts? The goals of the project are: to investigate what design knowledge local developers value and how they seek out this knowledge; to explore the mechanism of a collaborative case-based design aid to support an existing community of local developers; to explore embedding design education into the local developer's application and to measure the amount of design learning that results. The overall research goal is to develop guidelines for software developers whose users may become end-user programmers and even local developers. The projects success will mean the industry will gain increased knowledge about design practices engaged in by end-users. That knowledge may lead to more effective support structures and education for this class of developers. There are a lot of such people, distributed across a wide range of professions, so impacts may affect many organizations. In addition, insights gained about the population being studied may impact computer science theory and education and the science of design on a wide population of computer users. Another outcome of this research is guidance on how to provide support for task-based learning for end-user programmers. The potential impact of research is far reaching--it could pave the way for introducing techniques for supporting end-user programming into commercial products.<br\/><br\/>Program Manager: Anita J. La Salle<br\/>Date: June 27, 2006","title":"SoD-HCER: Contextualized Design Education for Professionals from Non-Computing Disciplines","awardID":"0613738","effectiveDate":"2006-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7372","name":"ITR-SCIENCE OF DESIGN"}}],"PIcoPI":["521278"],"PO":["557609"]},"116629":{"abstract":"Directorate for Computer and Information Science and Engineering (CISE)<br\/>Division Computer and Network Systems (CNS)<br\/>Science of Design (SoD) Program<br\/><br\/>Proposal Number: 0613793 <br\/>P\/I: Michael D. Ernst<br\/>PI's Department: Department: Electrical Engineering and Computer Science <br\/>Institution: Massachusetts Institute of Technology<br\/><br\/>Award: $200,000 <br\/><br\/>Title: \"SoD-HCER: Testing Designs and Designing Tests\"<br\/><br\/>This proposal addresses concepts of software design and testing. The first thrust is on testing designs, exploring techniques for automatically generating tests from designs (models) that are higher-level than the code. The second thrust is on designing tests: on viewing tests as designs that can be decomposed and recomposed to create new tests with improved properties such as faster execution or better coverage. These two are related but distinct techniques, each integrates testing with a view of design in order to improve the testing process. This project's ideas are new and they have important advantages over other approaches that solve similar problems. Preliminary investigations validated their usefulness with promising results. The funding will permit careful experiments to more scientifically validate the ideas. The potential implications of the proposed work on research and practice are profound. Practitioners are eager to improve their software and their test suites, but they have limited resources and limited knowledge of and patience with formal methods. The proposed work can be viewed as one way of bridging the gap between practice and theory by applying research ideas to real-world problems. <br\/><br\/><br\/>Program Manager: Anita J. La Salle<br\/>Date:","title":"SoD-HCER: Testing Designs and Designing Tests","awardID":"0613793","effectiveDate":"2006-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7372","name":"ITR-SCIENCE OF DESIGN"}}],"PIcoPI":["501796"],"PO":["551712"]},"110635":{"abstract":"Prop ID: CCF-0541461 <br\/>PI: Martin, Alain J. <br\/>Institution: California Institute of Technology <br\/>Title: Asynchronous Circuits and Systems for Nanoelectronics <br\/><br\/>It is expected that CMOS, today's technology of choice for semiconductor-based integrated circuits, will soon run into fundamental physical limits mainly due to the lithographic process used to pattern the circuits. Among all possible successors, non-lithographic molecular-electronic technology based on carbon nanotubes and nanowires is one of the most promising. Because of inherent fabrication difficulties, circuits in those technologies will exhibit large variations in physical parameters as well as large percentage of faults and defects. Taking parameter variability and defect- and fault-tolerance into account will be an inherent part of any successful circuit design methodology in the nanoscale era. <br\/><br\/>Because any variation in an electrical parameter has an effect on the timing behavior of the circuit, being able to design a circuit in a manner such that the correct behavior of the circuit is independent of the timing is a great advantage since it would greatly increase the robustness of the circuit to parameter variations. Such a design style is called ``asynchronous''. The purpose of this research is to develop a design method for molecular-electronic integrated circuits based on asynchronous logic, including error- and defect-tolerance circuit techniques. Another reason for using asynchronous logic is that such logic does not need a clock to implement the sequencing of actions in a typical digital system like a microprocessor. Distributing a clock signal across a chip requires long wires with well-balanced timing properties, which is impossible to do in molecular electronic.<br\/><br\/>The research will develop design methods to deal with both hard defects like broken wires, and soft (or transient) errors as caused for instance by an alpha particle hitting the circuit and changing a bit from zero to one. Dealing with hard errors will require redundancy to be able to use ``spares'' and reconfigurability to redesign a circuit on the fly to circumvent an error. For all those unpredictable changes in the circuit, independence of timing offered by asynchrony will be a great advantage.<br\/><br\/>Because of the non-lithographic nature of the fabrication process, molecular electronics restricts the geometry of the chips. Essentially, a wire can run either north-south or east-west, and all active devices (transistors) are built at the intersection between a north-south wire and an east-west one.<br\/>This restricted geometry calls for large regular structures like FPGAs, rather than random logic with arbitrary geometry. Designing within this restricted geometry (with the additional issue of very highly resistive contacts between wires of different direction) is another challenge of this project.<br\/><br\/>The project will propose and test a complete asynchronous logic family for molecular electronic devices based on carbone nanotubes and nanowires and a design method to deal with different aspects of fault- and defect-tolerance. It is hoped that a significant chip, for instance a small microcontroller, will be designed and fabricated.","title":"Asynchronous Circuits and Systems for Nanoelectronics","awardID":"0541461","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1674","name":"NANOSCALE: INTRDISCPL RESRCH T"}}],"PIcoPI":[293096,"460489","497005"],"PO":["562984"]},"121646":{"abstract":"Exploring Universal Acoustic Characterization of Spoken Languages<br\/><br\/>Abstract<br\/><br\/>We explore a novel approach to modeling all human languages by assuming that the sound characteristics of spoken languages can be covered by a universal set of acoustic units with no direct link to conventional phonetic definitions. Their corresponding models, called acoustic segment models (ASMs), can be used to decode spoken utterances into strings of such units. The statistics of these units and their co-occurrences corresponding to utterances in a training set of a particular language can be used to construct feature vectors to build vector-based language classifiers for automatic spoken language identification (LID). For spoken queries, ASM-derived feature vectors are extracted in a similar manner and then used to discriminate individual spoken languages. This collection of ASMs can be established from bottom up in an unsupervised manner, and will serve as models of acoustic alphabets to construct acoustic lexicons for speech recognition and language identification. In the project we study three fundamental issues related to UAC, namely: (1) acoustic coverage and resolution of acoustic units needed to model spoken languages; (2) complexity and discriminative power of UAC-derived features for spoken language identification; and (3) relationship of language cues with UAC units for modeling spoken languages. This research facilitates a better understanding of human identification of spoken languages through acoustic and linguistic cues, and provides mathematical modeling and computing techniques to build LID systems. We also intend to leverage our research results in another NSF grant on automatic speech attribute transcription (ASAT) to model salient speech cues for language characterization and their relevance to auditory perception. The entire collection of available language cues, including phones, syllables, words, prosody, and lexical cues, can also be incorporated into this synergistic approach to spoken language modeling and identification.","title":"SGER: Exploring Universal Acoustic Characterization of Spoken Languages","awardID":"0639204","effectiveDate":"2006-08-15","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}}],"PIcoPI":["335186"],"PO":["565215"]},"120579":{"abstract":"Domain experts who are doing work at the frontiers of knowledge often need to use advanced user interfaces for information visualization. Although principles of design for these new tools are emerging, the PI argues that evaluation of efficacy by controlled experimental studies is inadequate to deal with exploratory usage, rather that new evaluation methods based on longitudinal and ethnographic strategies must be developed. Furthermore, the PI contends that a growing number of software tools do more than increase productivity; they are designed to support creativity. The PI believes that a new advanced visualization tool he is developing to support exploration of social networks falls into this latter category. In this project, he will employ Multi-dimensional In-depth Long-term Case studies (MILCs) to study the tool's efficacy when it is used by a team of 4-6 professional sociologists, working within the newly formed National Consortium for the Study of Terrorism and Responses to Terrorism (START) at the University of Maryland, engaged in the collection of data and analysis of the social networks of terrorist organizations. This represents a unique opportunity to test and refine both the visualization tool and the evaluation methods. Project outcomes will, through development of improved guidelines for conducting MILCs, lay the foundation for scaling up to larger evaluations in more ambitious projects that blend individual and social creativity.<br\/><br\/>Broader Impacts: The new tool the PI is developing will make contributions to information visualization design principles. In addition, the longitudinal and ethnographic studies to be conducted as part of this project will lead to refinement of both the MILC approach and the PI's tool. The improved evaluation methods and new visualization tool will, in turn, be of benefit to numerous research and industry groups.","title":"SGER: Developing Ethnographic Evaluations for Creativity Support Tools","awardID":"0633843","effectiveDate":"2006-08-15","expirationDate":"2008-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7496","name":"COLLABORATIVE SYSTEMS"}}],"PIcoPI":["527292"],"PO":["565227"]},"112505":{"abstract":"Abstract<br\/><br\/>Program: NSF 04-588 CISE Computing Research Infrastructure<br\/>Title: CRI: Collaborative Research: SMT-LIB, A Common Library and Infrastructure for Satisfiability Modulo Theories <br\/><br\/>Lead Proposal: CNS-0551646<br\/>PI: Tinelli, Cesare<br\/>Institution: University of Iowa<br\/><br\/>Proposal: CNS-0551697<br\/>PI: Stump, Aaron D.<br\/>Institution: Washington University<br\/><br\/>Proposal: CNS-0551645<br\/>PI: Barrett, Clark<br\/>Institution: New York University<br\/><br\/> <br\/>Investigators at the University of Iowa, Washington University and New York University will develop a community resource for users and developers of solvers for satisfiability modulo theories (SMT). The solvers are logical reasoning programs used in software and hardware verification. The project will develop standards and interfaces to enable incorporation of solvers into verification tools and benchmarks and develop services for accurate evaluation and comparison of SMT solvers. These will support use by a broad community of researchers. Broader impacts of this project are the improvement of research capability in verification. Longer-range benefits will include more reliable future hardware and software systems.","title":"CRI: Collaborative Research: SMT-LIB, A Common Library and Infrastructure for Satisfiability Modulo Theories","awardID":"0551646","effectiveDate":"2006-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["521573"],"PO":["550859"]},"112538":{"abstract":"Abstract<br\/><br\/>Program: NSF 04-588 CISE Computing Research Infrastructure<br\/>Title: CRI Collaborative Research: Building the Next-Generation Global Routing Monitoring System<br\/><br\/>Lead Proposal: CNS-0551725<br\/>PI: Massey, Daniel F.<br\/>Institution: Colorado State University <br\/><br\/>Proposal: CNS-0551661 <br\/>PI : Meyer, David M.<br\/>Institution: University of Oregon<br\/><br\/>Proposal: CNS-0551541<br\/>PI : Wang, Lan<br\/>Institution: University of Memphis<br\/><br\/>Proposal: CNS-0551736<br\/>PI : Zhang, Lixia<br\/>Institution: University of California-Los Angeles<br\/><br\/><br\/>Researchers at the University of Oregon, Colorado State University, University of Memphis, and University of California at Los Angeles will develop the next generation of the RouteViews system as a community resource to provide the most needed data to networking researchers and educators and network operators. RouteViews provides data on routing in the global Internet and tracks changes at Internet nodes. The project builds upon the existing RouteViews data collection system that was launched in 1998. That system archives routing data from the global Internet and was originally intended as a tool for network operators. Over the last few years, the RouteViews archive has quickly become a major data source for the network research community and numerous recent network routing research projects have benefited from it. These projects range from network topology measurement and routing stability analysis to network diagnosis, anomaly detection, and new routing protocol designs. RouteViews data is also starting to appear in classrooms and has potential for use in both graduate and undergraduate education. This project will address weaknesses in the initial implementation both in the system architecture and the quality of data collected. The investigators will replace the current router software package with an extensible data collector, rebuild the data archive with a new standard format, and provide real-time distribution of the global routing information.","title":"CRI: Collaborative Research: Building the Next-Generation Global Routing Monitoring System","awardID":"0551736","effectiveDate":"2006-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["543560"],"PO":["565090"]},"116839":{"abstract":"Technology is changing our lives in numerous and ever increasing ways. Even a simple modern house contains wired and wireless networks, dedicated devices (such as TV set-top boxes and game consoles), multi-media displays, mobile devices, and traditional computers. Unfortunately, managing this technology is a challenge to all but the most sophisticated users, and as a result, users are increasingly overwhelmed with the administration, integration, and security management of their home infrastructure. <br\/><br\/>This work simplifies the operation and management of home-based technology, through a new architecture that provides users with simple, powerful, and safe mechanisms for executing programs and storing data. The high-level concept is to support the outsourcing of a large portion of home computing and data management to third parties. The project examines mechanisms that allow third party operators to manage, back-up, upgrade, and diagnose\/repair the applications and data resident within the home. As well, the project examines an in-home architecture in which applications and data are hosted off of a powerful server, enabling users are able to access their applications and data from a variety of devices, using a combination of new search mechanisms and thin-client techniques. <br\/><br\/>Overall, the project makes home computing as easy to use as other home infrastructure, such as heating or security systems that just work in an invisible and natural way. In the long run, the existance of PCs as we know them will disappear and be replaced by appliances that are easily operated by children and adults alike.","title":"CSR - PDOS: Simplifying Administration in the Outsourced Home","awardID":"0614975","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["450764","532591"],"PO":["493916"]},"117829":{"abstract":"This project, acquiring a cluster to perform research on terabyte-scale problems in the areas of information retrieval, network traffic analysis, intrusion detection, and image processing for biomedicine, enables long term studies by providing access to users with terabytes of storage for extended periods of time. In this shared facility, investigators will cooperatively exploit a cluster containing 20 terabytes of disk storage. Additionally, a high performance terabyte disk subsystem, connected by fibre channel will serve as a higher speed cache for the large disk storage. To complete the memory storage, data migration will leverage using existing tertiary storage backup systems. In order to attain both the highest efficiency and the highest flexibility in processing such large datasets, the cluster employs quad-processor nodes and 8 GB of RAM per node. Testing on full size data eliminates errors caused by sampling smaller datasets in many areas. Enabling new research, the projects range from analysis of distributed denial of service, through learning for biomedical images, to parallel tomosynthesis. Software tools to be refined on this facility include methodologies for Information Retrieval, Support Vector Machines (SVM), Clustering, Network Simulation, Out-of-Core Search, 3-D Image Reconstruction, and Spatial and Temporal Databases. It is anticipated that the increase in data manipulation capabilities will provide much quicker turn-around and make possible results that are inaccessible with the currently installed technology.","title":"MRI: Enabling Research on Terabyte-Scale Datasets","awardID":"0619616","effectiveDate":"2006-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["521812","557272","535376","521034","516944"],"PO":["557609"]},"121614":{"abstract":"This is funding to support a PI Workshop on the campus of the University of Southern California in Los Angeles, on September 27-28, 2006. HRI is one of the two cross-cutting technical areas defined in IIS Division's new solicitation entitled \"Information and Intelligent Systems: Advancing Human-Centered Computing, Information Integration and Informatics, and Robust Intelligence\" (NSF 06-572). The 1.5-day workshop will bring together current NSF PIs with ongoing HRI research programs, along with selected additional members of the research community with related interests, to help NSF identify emerging trends in this rapidly evolving field. Participants will discuss and prioritize the important subfields of HRI that the scientific community believes will have a major impact in the near-to-medium term. This workshop is one of several similar events, each focusing on a particular aspect of the new solicitation, being sponsored by IIS Division with the goal of encouraging the research community to provide input to NSF in its strategic planning process as we prepare for the challenges and opportunities anticipated during the coming period of explosive technological growth and change.<br\/><br\/>Broader Impacts: This workshop will present a unique opportunity for NSF PIs and other members of the rapidly growing human-robot interaction (HRI) research community to discuss the state of the art and to engage in strategic planning toward shaping the direction of this new and interdisciplinary research area with major implications on the future of robotics in society. The workshop organizers will produce a comprehensive workshop report, and the workshop website will become a permanent repository of the workshop discussions, breakout group reports, etc for general access by the research community at large.","title":"NSF Workshop on Human-Robot Interaction (HRI)","awardID":"0639060","effectiveDate":"2006-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6846","name":"UNIVERSAL ACCESS"}}],"PIcoPI":["558935","492859","560335"],"PO":["565227"]},"116906":{"abstract":"Scientists and engineers increasingly rely upon computational studies<br\/>involving multiple experiments (runs of simulation software) in domains<br\/>ranging from engineering design-space exploration to drug design.<br\/><br\/>This collaborative project develops foundations for a system that<br\/>facilitates interactive computational studies involving large numbers of<br\/>experiments, permitting the user to continuously monitor and steer how<br\/>the study unfolds, based on partial results. The work specifically<br\/>targets engineering design applications involving small-to-medium size<br\/>simulation problems running on tightly-coupled parallel machines, and<br\/>emphasizes (1) higher-level user control of the overall study; (2) reuse<br\/>of data from prior experiments in carrying forward new computations; (3)<br\/>dynamic management of system resources by relying on a tighter coupling<br\/>between application and system software; and (4) software reuse based on<br\/>common component architecture (CCA) compliance and standardization of a<br\/>more permeable system-\/solver-level interface.<br\/><br\/>The system architecture builds upon the SCIRun2 framework and<br\/>incorporates modules for translating high-level user specifications into<br\/>required experiments, for allocating parallel machine resources to<br\/>experiments to optimize study progress, and numerical methods and<br\/>algorithms for estimating simulation time and resource costs.<br\/><br\/>The primary impact of the work is expected in engineering design, with<br\/>broader applicability to additional classes of biomedical and geometric<br\/>modeling applications. The project will also have important educational<br\/>applications, by creating hands-on simulated exploration experiences for<br\/>students, and by training system computer scientists with a deep<br\/>understanding of specific scientific domains, simulation frameworks, and<br\/>numerical solver interfaces.","title":"Collaborative Research: CSR--AES: Interactive Parallel Platforms for Multi-Experiment Computational Studies","awardID":"0615255","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[309341,"550936"],"PO":["535244"]},"116917":{"abstract":"In the past 15 years, viability theory has enabled significant theoretical achievements in the areas of optimal control, differential games and hybrid systems reachability. The current state of the theory now enables significant breakthroughs in embedded computing as well. This project focuses on the development of novel set-valued numerical analysis schemes and their implementation on application-specific (embedded) platforms. The research addresses three key topics: (1) Higher order numerical schemes for the computation of viability sets. These provide faster convergence rates for numerical solutions of optimal control problems. (2) Formal verification algorithms on discrete maps. These enable the creation of optimal control strategies directly applicable to problems described with arrays of measured data rather than algebraic functions. (3) Set-valued optimal control algorithms. These provide globally optimal solutions for problems in which classical control techniques cannot incorporate state constraints.<br\/><br\/>A generic computational core is being developed, customized and embedded in software and hardware platforms used for two key applications in Civil and Environmental Engineering, and in Air Traffic Control. This is integrated to a hardware platform in development: an active Lagrangian sensor network (sensors mounted on active drifters which follow environmental flows). The goal of this network is to track distributed features in water (salt fronts and turbidity plumes). The driving application is the monitoring of mixing in estuarine environments. The network will be deployed in the San-Joaquin - Sacramento Delta in California. At NASA Ames, the network is being interfaced with the software FACET, with the goal of helping Air Traffic Controllers to optimize wind routing decisions in severe weather conditions.","title":"CSR---EHS: Embedded Viability Computing","awardID":"0615299","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["526902"],"PO":["561889"]},"110538":{"abstract":"ABSTRACT<br\/>0541040<br\/>Zdancewic, Stephan A.<br\/>U of Pennsylvania<br\/><br\/>Unifying Events and Threads: Language Support for Network Services<br\/><br\/><br\/>This research investigates language-based techniques that provide better abstractions for reasoning about and implementing massively concurrent network services such as web servers, games, chat rooms, and peer-to-peer applications. The core idea is to unify the multithreaded and event-driven models of concurrency, providing the benefits of both styles of programming. This unified concurrency model internally structures code in continuation-passing style and uses the type theoretic approach of monads to mediate between the thread and event views of the system.<br\/><br\/>The approach will be tested first by building a high-performance web server using the Haskell programming language. Driven by the experience gained in that phase of the work, the remainder of the research will concentrate on scaling up the methodology in two ways. First, a layered approach to designing large network service stacks will be investigated. Second, ways of adapting the abstractions to work for multiprocessor architectures will be explored. Both of these phases of the research will draw on expressive static type<br\/>systems to eliminate overheads introduced by abstraction boundaries and allow programmers to exploit parallelism.<br\/> <br\/>The expected outcome of this research is improved programming language support and design methodologies for building robust, highly concurrent software.","title":"Unifying Events and Threads: Language Support for Network Services","awardID":"0541040","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}}],"PIcoPI":["556654"],"PO":["564388"]},"116929":{"abstract":"The goal of this project is to research a full-system, cycle-accurate computer simulator that runs approximately three orders of magnitude faster than the fastest current simulators of similar accuracy. Such performance is achieved by a careful partitioning of the simulator that permits the most computationally intensive component to be efficiently implemented in reconfigurable hardware. This partitioning also simplifies and abstracts the simulators, making them easier to make more complete and accurate. For example, an early prototype boots unmodified Linux. The goals of this project are to (i) build and evaluate instances of such simulators, (ii) refine tools to build and use such simulators to the point that they could be used in an advanced undergraduate class and (iii) to further optimize the performance of such simulators by improving the partition interface and implementation strategies. Since the resulting simulators are simultaneously accurate, fast and full-system, we anticipate that all users of cycle-accurate computer simulators, ranging from students to architects designing computers to engineers developing the computers to advanced end-users who wish to tune their applications for a particular computer, will eventually use a form of such a simulator.<br\/>Sharing the same infrastructure will likely lead to better communication between these groups, resulting in better computer systems overall. We expect to disseminate versions of the simulators and tools primarily through a web interface that will allow users to specify a simulator and run it over the web at our site.","title":"A Fast, Cycle-Accurate Computer System Technology","awardID":"0615352","effectiveDate":"2006-08-01","expirationDate":"2010-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["535119"],"PO":["561889"]},"120747":{"abstract":"This project seeks a very modest amount of travel funds to support US faculty to participate in the 2006<br\/>and 2008 workshops. This amount is set to approximately offset the extra travel costs associated with European rather than domestic travel.<br\/>Intellectual Merit:<br\/>The development of a computer graphics curriculum and the necessary courses involves understanding the recent and current research and development of computer graphics techniques and technologies, and integrating this research and development work into undergraduate and masters-level education. We will<br\/>involve computer graphics faculty who are actively involved in both research and teaching as we create the curriculum, and they will create courses based on their research and development experience. In this way we will move forward the entire computer graphics field and in particular will help prepare students for research work in the field.<br\/>Broader Impacts:<br\/>The computer graphics curriculum and courses that will be developed through this project will lead to a much broader kind of computer graphics studies in the US. These studies will involve integrating current or recent research work into pre-research computer graphics courses and will result in a group of computer science professionals who are much better educated in computer graphics, improving the<br\/>graphics capability of the computing profession.","title":"Special Project: Travel Support for International Computer Graphics Education Workshops","awardID":"0634837","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":[320844],"PO":["532791"]},"110616":{"abstract":"The architecture and usage modalities of storage systems have been revolutionized by advances in disk drive and networking technologies. Resource management issues occupy a central and increasingly important role in the operation of data centers that must coordinate the operation of large numbers of concurrent devices and serve hundreds of gigabytes of data per second. Such shared storage servers are being proposed as a cost-effective solution for maintaining data repositories. This research effort addresses resource allocation and scheduling issues that arise in multiplexing a shared storage server and seeks to provide isolation and performance guarantees for multiple contending flows that may have different characteristics. The research is developing robust models, algorithms, and mechanisms that enable efficient sharing of server I\/O resources while enforcing performance guarantees, in the presence of dynamically varying resource constraints. The results will also have applicability to systems of heterogeneous servers. <br\/><br\/>The intellectual advance pursued in this research is the systematic investigation of a new set of resource management issues that arise in the shared server environment. It studies, at a fundamental level, the problem of providing fair or differentiated quality of service among diverse concurrent clients (flows) accessing a shared parallel I\/O system. The work is developing robust models that incorporate the unique resource constraints and performance responses arising in parallel I\/O, developing efficient algorithms for adaptive resource allocation, formal characterization of the solutions with respect to performance and stability, and the development of simulation infrastructure for empirical evaluation of the solutions.<br\/><br\/>The impact of the research will be more robust and scalable resource management for data centers such as commercial and supercomputing server environments. The research will produce mechanisms to enforce service agreements between the service provider and concurrent clients, reaping the economies of scale of shared resources and the increasing economic benefits of consolidated management. The research will also result in the training and education of graduate students in a growing sector of the information technology industry.","title":"Resource Scheduling with QoS for Parallel I\/O Systems","awardID":"0541369","effectiveDate":"2006-08-15","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["410022"],"PO":["561889"]},"110506":{"abstract":"ABSTRACT <br\/>High-Performance Data Access through Memory Abstraction <br\/><br\/>B-trees have been the data structures of choice for external-memory searching for decades because they minimize the number of disk-block accesses performed during a search. It is well known, however, that B-trees are empirically suboptimal because they exploit data locality at only one level of granularity, typically disk blocks, but not at coarser granularities, such as disk tracks, or finer granularities, such as cache lines. <br\/><br\/>Theoretical developments on cache-oblivious data structures and algorithms have shown how to achieve nearly optimal locality of reference simultaneously at every granularity. A striking feature of cache-oblivious data structures is that they free the programmer from the burden of tuning the code for cache and disk effects. The PIs' recent experiments suggest that cache-oblivious B-trees (CO B-trees) can surpass the performance of highly tuned traditional B-trees. CO B-trees achieve superior performance because they approximately optimize for all memory effects. In contrast, cache-aware algorithms ignore important aspects of the memory hierarchy. CO B-trees are not yet ready to be used in file systems and data bases, however, because they lack essential capabilities of industrial-strength B-trees, such as support for variable-size keys, concurrent accesses, and transactions. <br\/><br\/>The researchers propose to investigate how CO B-trees can achieve their potential. The researchers plan to study the wide range of algorithmic problems in data structures, stringology, and distributed systems required to develop a full-featured CO B-tree. In addition, the researchers plan to solve online scheduling problems so that virtual-memory systems can provide efficient support for cache-obliviousness. This algorithmic work is necessary to transfer CO technology to other areas of computer science, engineering, and scientific computing and is intended to transform how scientists and engineers manipulate massive data sets.","title":"Collaborative Research: High-Performance Data Access through Memory Abstraction","awardID":"0540897","effectiveDate":"2006-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["533341"],"PO":["559883"]},"110638":{"abstract":"The distributed, wireless, mobile computing revolution moves information gathering and processing into the human environment. This has a profound impact on security. Traditional security applications, such as firewalls and VPN's, focus on protecting the communication channels between computers against attacks. This is done with security protocols and encryption algorithms running on the powerful processors of physically-protected servers. In an environment of small embedded distributed, wireless connected devices, this assumption is incorrect. The embedded device itself is vulnerable to attacks, and a hacker will select the method of attack that breaks the weakest link in an entire system including the embedded device as well as its communication channel. On top, the embedded device has limited computing and energy resources, and security is expensive (in terms of extra processing, memory, energy and development cost). Therefore, the embedded system is typically divided into secure and non-secure operations. The objective of embedded security is to thwart attacks at whatever abstraction level they happen. Security partitioning thus needs to address all design abstraction levels, software and hardware. The objective of this project is to develop design and validation methods that support a systematic security partitioning in a SoC (System-on-chip) integrated circuit design flow. Our design methods will help the embedded systems designer to cope with security constraints next to the existing constraints such as memory footprint, silicon area, performance, and power consumption.","title":"Design Methods for trusted and secure embedded computing in SOC.","awardID":"0541472","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":[293104],"PO":["562984"]},"122639":{"abstract":"A Grant to fund Student Travel to Mobicom 2006 in Los Angeles, Sept 24-29, 2006<br\/><br\/>This Grant supports travel for students attending Mobicom 2006, in particular assisting the students with financial needs. The twelfth ACM International conference on Mobile Communications (Mobicom 2006) takes place in Los Angeles, California, September 24-29, 2006. Mobicom 2006 is a high caliber forum for research on systems issues in the area of mobile, wireless communications and computing . Mobicom topics span multiple disciplines, including wireless communication, vehicular communications, personal area networks, ad hoc networks, operating systems, distributed algorithms, data processing, scheduling, sensors, and signal processing. Mobicom provides a cross-disciplinary venue for researchers addressing the design of mobile computing in the context of an integrated system. <br\/><br\/>The main goal of this NSF Grant is to provide graduate students in the networking and mobile computing area the opportunity to attend Mobicom 2006, meet with leaders in their field and take part in discussions that are likely to shape their future careers. Besides technical paper presentations in the topics mentioned above, the venue offers a wide range of other stimulating activities including panels, tutorials, industry presentations, posters, demos, and keynote talks. Experience shows that the mere exposure to these technical presentations helps students fine tune their research topics and even find new ones, with important long term benefits to the field at large.","title":"Student travel support for Mobicom 2006","awardID":"0644893","effectiveDate":"2006-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["558959"],"PO":["7594"]},"116908":{"abstract":"A wide variety of systems, including web farms, virtual machines,<br\/>multi-tasking OSes, GRID computing systems, and sensor networks<br\/>improve their accessibility, availability, resilience and fairness by<br\/>``sharing'' resources across the consumers they support. However,<br\/>research that explores how to share resources generally derives point<br\/>solutions, where different resource\/consumer configurations require<br\/>separately-designed sharing mechanisms. For instance, a scheduler<br\/>often has implemented separately a single policy<br\/>(e.g., FCFS, PS, Foreground Background, Shortest Remaining Processor<br\/>Time), optimized for a particular load setting<br\/>and cannot easily be switched to another policy when the situation changes.<br\/><br\/>This project is developing and analyzing Adaptive Sharing<br\/>Mechanisms (ASMs) in which the mechanism used to share resources<br\/>adapts dynamically to both the set of available resources and the<br\/>current needs of the consumers, such that the system is truly<br\/>autonomic. The study has been initiated with a modularization of the ASM<br\/>into separate components, defined by the timescale of operation. A<br\/>study of the various components using both cutting edge novel control<br\/>theoretic and scheduling analyses is being performed.<br\/>The design and analysis of ASMs will provide a theoretical<br\/>grounding for fully autonomic systems, and the project will lead to<br\/>efficient utilization of resources in diverse systems like server<br\/>farms, GRID computing and Sensor Networks.","title":"SMA\/PDOS Collaborative Research: Design, Analysis, and Control of Adaptive Sharing Mechanisms","awardID":"0615262","effectiveDate":"2006-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["555524"],"PO":["493916"]},"110606":{"abstract":"ABSTRACT<br\/>CCF-0541324 <br\/>PI: Niemier, Michael T. and Liebermann, Marya<br\/>Institution: University of Notre Dame <br\/><br\/>Title: Design and study of self-assembling QCA circuits <br\/><br\/>Molecular Quantum-dot Cellular Automata (QCA) is an end-of-roadmap alternative to silicon-based computation. Logical operations and data movement are accomplished via Coulomb interactions between QCA cells that have bistable charge configurations. This basic device-device interaction can allow for the computation of any Boolean logic function. Molecular QCA systems are expected to operate at room temperature, could potentially offer densities and speeds that are at least two orders of magnitude beyond what end-of-the-curve CMOS can provide, and are expected to dissipate very little power. Tools exist which allow circuit designs to be directly translated into QCA cell layouts. However, there is currently no manufacturing process that can position QCA molecules to form QCA circuits with the necessary sub-nm precision. <br\/><br\/>This proposal attacks the positioning problem from both an experimental and a design perspective. The work focuses on the design of computationally interesting QCA systems (i.e. logic that would facilitate tasks like image processing) that might actually be built using a process of self-assembly and guided assembly. The work will develop processes for self-assembly in solution of mesoscale (1-100 nm) circuitboards (DNA structures), to which molecular QCA cells or other components would attach, and use a new process for guided self-assembly of DNA circuitboards on lithographic features on silicon. The systems target, data convolution, can be accomplished with systolic architectures that map well to QCAs device architecture, and the resulting molecular circuitry could eventually provide enhanced data processing capabilities for CMOS chips. <br\/><br\/>There will be a unique interplay between physical science and computer science with work in design influencing what experiments are actually conducted. Closing the feedback loop, experimental science will refine work in design. The net result should be accelerated progress toward realizable systems.","title":"Design and study of self-assembling QCA circuits","awardID":"0541324","effectiveDate":"2006-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1674","name":"NANOSCALE: INTRDISCPL RESRCH T"}}],"PIcoPI":["490724","560915"],"PO":["562984"]},"120915":{"abstract":"Commercial data providers have exploited open sources such as published telephone directories, property transactions, and bankruptcy filings for years. However, recent concerns and legislation related to privacy have caused many sources to redact attributes that provide explicit entity identification, e.g., removing street number and name from the address, using only the last four digits of the security number.<br\/><br\/>Adding to the challenge are semi-structured and unstructured sources such as narrative event notices, e.g., obituary, birth, marriage, divorce. These sources typically have complete names, but provide even fewer address clues, in some cases only naming the city of last residence or the city where the event occurred. These kinds of Partially Redacted Open Sources (PROS) are difficult to automate for several reasons:<br\/>- The documents do not explicitly state all of the attributes defining a unique identity<br\/>- The documents are often in semi-structured or unstructured text formats that complicate attribute extraction<br\/>- Knowledge management is difficult because each type of PROS has a different semantic ontology often with many possible terms even though each instance is sparsely populated Despite these challenges, PROS can be data rich, providing important supplementary entity information. For example, an obituary may give a complete set of family relationships to the decedent including parents, children, and siblings.<br\/><br\/>The primary nature of the proposed research is to investigate and develop effective methods and techniques for resolving the identity of entities appearing PROS. The primary objective of the project will be to improve and extend the methods and techniques developed in previous research for the specific case of identification of individuals in online obituary notices [1, 2] and multi-agency entity resolution [3], and demonstrate that these same methods and techniques can be effective when applied to other types of PROS.<br\/><br\/>The anticipated output of the research is a set of technical papers documenting in detail the methods and techniques developed in the project and assessments of their effectiveness in various PROS contexts. Where appropriate, software prototypes developed as part of the project will be included as part of the project deliverables.","title":"Methods and Techniques for Entity Indentification in Open Source Documents with Partially Redacted Attributes","awardID":"0635655","effectiveDate":"2006-08-15","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T471","name":"CIA-KDD WORKING GROUP"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T472","name":"CIA-KNOWLEDGE DISC & DISSEM PR"}}],"PIcoPI":[321257,321258,"557523",321260],"PO":["565136"]},"132709":{"abstract":"The proliferation of embedded video cameras in mobile wireless devices has created a tremendous challenge for the design of underlying wireless communication infrastructure to support high-performance and secure video data delivery. While current mobile devices and networks are still considered resource-scarce components, many video-based wireless applications require not only real-time security features but also stringent network Quality of Service (QoS) guarantees such as minimum bandwidth for the routing path and bounded end-to-end latency for on-time delivery. Hence, allocating limited resource intelligently becomes a critical issue for secure real-time video communication on wireless embedded systems. To achieve the goal, this project seeks to develop the following: (1) a multilevel secure MPEG-4 streaming mechanism that adaptively encrypts and decrypts digital video data at different security levels according to streaming requirements and the surrounding network environment, (2) multi-path secure routing\/streaming technique that balances streaming performance and security goals on mobile ad hoc networks (MANETs), (3) cross-layer design for secure video streaming that exhibits a compact, yet flexible, secure streaming system structure for pervasive wireless embedded video systems. Through experimental, application-oriented research, this project aims to provide methods for secure real-time video communication among mobile devices on MANETs. This work will provide important technology for disaster recovery, vehicle networks, and military applications, and it will provide highly relevant research and educational opportunities for students.","title":"CSR---EHS: Secure Real-Time Communication for Networked Embedded Video Systems","awardID":"0737926","effectiveDate":"2006-08-16","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["335186"],"PO":["493916"]},"118290":{"abstract":"The increasing demand for Exa-byte-scale storage capacity by high end computing applications requires a<br\/>higher level of scalability and dependability than that provided by current file and storage systems.<br\/>The proposal deals with file systems research for metadata management of scalable cluster-based parallel and distributed file storage systems in the HEC environment. It aims to develop a scalable and adaptive metadata management (SAM2) toolkit to extend features of and fully leverage the peak performance promised by state-of-the-art cluster-based parallel and distributed file storage systems used by the high performance computing community. There is a large body of research on data movement and management scaling, however, the need to scale up the attributes of cluster-based file systems and I\/O, that is, metadata, has been underestimated. An understanding of the characteristics of metadata traffic, and an application of proper load-balancing, caching, prefetching and grouping mechanisms to perform metadata management correspondingly, will lead to a high scalability. It is anticipated that by appropriately plugging the scalable and adaptive metadata management components into the state-of-the-art cluster-based parallel and distributed file storage systems one could potentially increase the performance of applications and file systems, and help translate the promise and potential of high peak performance of such systems to real<br\/>application performance improvements.<br\/>The project involves the following components:<br\/>1. Develop multi-variable forecasting models to analyze and predict file metadata access patterns.<br\/>2. Develop scalable and adaptive file name mapping schemes using the duplicative Bloom filter array technique to enforce load balance and increase scalability<br\/>3. Develop decentralized, locality-aware metadata grouping schemes to facilitate the bulk metadata operations such as prefetching.<br\/>4. Develop an adaptive cache coherence protocol using a distributed shared object model for client-side and server-side metadata caching.<br\/>5. Prototype the SAM2 components into the state-of-the-art parallel virtual file system PVFS2 and a distributed storage data caching system, set up an experimental framework for a DOE CMS Tier 2 site at University of Nebraska-Lincoln and conduct benchmark, evaluation and validation studies.","title":"HEC: Collaborative Research: SAM^2 Toolkit: Scalable and Adaptive Metadata Management for High-End Computing","awardID":"0621526","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7583","name":"ITR-HECURA"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["366560","559285","464413"],"PO":["565272"]},"119182":{"abstract":"This proposal focuses on developing theoretical foundations of discrete curvature flows on surfaces, studying different geometric structures on surfaces using the flows, and applying them to geometric modeling, computer graphics and visualization. Shape classification and comparison are fundamental problems in computer vision and graphics. The PIs propose to classify surfaces according to their conformal structure using Teichmueller theory. The PIs will develop practical algorithms to compute Teichmueller space coordinates using discrete Ricci flow and use the coordinates to index large scale geometric database. In contrast to smooth surfaces, discrete surfaces have an extra structure: combinatorial structure. Combinatorial structure plays crucial roles in discrete geometries. It is a fundamental problem to get better understanding of the roles played by combinatorial structures. Discrete curvature flow is a powerful tool to study this problem. The PIs plan to develop the corresponding mathematics based on discrete variational principle to support these computational algorithms. The mathematical study is based on the cosine law which the PI consider as the basic metric-curvature relation in the discrete setting. The PI have discovered that derivatives of the cosine law produce striking identities valid in all constant curvature spaces. These identities produce energy functionals which include almost all known action functionals in the discrete setting. The potential applications of these newly discovered variational principles in graphs and visualization seem to be abundant.<br\/><br\/>Conventional computational geometry algorithms are mainly defined in flat spaces. These algorithms can be systematically generalized to curved spaces via geometric structures. This opens a new territory for geometric algorithmic design on manifolds by solving the easiest special case in the plane then directly generalizing the solution to arbitrary surfaces. Splines play the most fundamental role in geometric modeling. In aircraft, automobile and many other industries, almost all designs are aided by computer using splines. The shapes of mechanical parts have highly complicated topological and geometric features. Unfortunately, current splines can only be defined on the plane. It has been a long lasting open problem to find rigorous ways to define splines on general surfaces. The PIs plan to solve the problem by introducing novel algorithms to construct spines and calculate geometric structures via discrete curvature flow. Surface parameterization is a powerful technique to map surfaces in 3D onto the plane and convert 3D geometric problems to 2D. In texture mapping, in order to enhance the visual effects, images with subtle details are pasted onto the coarse polygonal surfaces. The central issue for parameterization is to control the distortion, the PIs propose to build the relation between distortion and the curvature and to seek a practical way to find the optimal parameterization. In today's Internet, there are huge amounts of geometric information. Building a geometry Google is the most urgent and fundamental problem for geometers and computer scientists. The PIs plan to build such geometric search engine using the methods developed in the proposal.","title":"MSPA-MCS: Discrete Curvature Flows on Graphics and Visualization","awardID":"0625935","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["519438"],"PO":["565286"]},"118281":{"abstract":"In this proposal, the PIs describe theWisconsin ProgramAnalysis of Storage Systems project (PASS), and seek to develop the techniques needed to build the high-end, scalable, robust storage systems of tomorrow by bringing a more formal approach to the problem, utilizing programming language tools to build, analyze, test, and monitor these storage systems. By applying these techniques, the PIs plan to raise the level of trust in the failure-handling capabilities of high-end storage systems by an order of magnitude.<br\/>The PASS project will change the landscape of storage systems in three fundamental ways. First, by developing more formal failure analysis techniques, we will be able to uncover a much broader range of storage system failure handling problems. Second, within PASS we will develop more robust and scalable testing infrastructure; such a framework will be of general use to the development of any future storage system. Finally, through run-time instrumentation of a large Condor cluster, the PIs plan to gather information as to what types of faults occur in practice as well as how they manifest themselves as failures. Such data will be invaluable to future designs and implementations of robust, scalable storage systems.","title":"HEC: Formal Failure Analysis for Storage Systems","awardID":"0621487","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7583","name":"ITR-HECURA"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7952","name":"HECURA"}}],"PIcoPI":["560467","550389","550390","549944","559530"],"PO":["565272"]},"118260":{"abstract":"The growing disparity between processing speeds and I\/O performance continues to be a limiting factor in the scalability of large scientific applications. Applications are becoming more data intensive, requiring large storage capacities and high bandwidth access to this storage. Further, application sciences are more collaborative, with sharing of data sets becoming prevalent not just between users\/applications of a single organization, but across organizations as well placing even higher performance requirements on the storage system. Given the sensitive nature of many of these applications, in addition to the performance demands, there is an impending need to secure such data from adversarial attacks. The consequences of security breaches can have far reaching consequences, over and beyond the costs of detecting and investigating such breaches. At the same time, one cannot fully confine the data physically since these need to be shared by collaborative applications from different administrative domains. Regulations are also mandating the maintenance of audit records and provenance of data.<br\/>The motivation for this research is driven by the need to secure storage systems which cater to the demands of high-end applications, while meeting their stringent performance requirements. These two goals - performance and security - are often contradictory, with the mechanisms for optimizing one usually coming at the expense of the other. In the proposed DataVault framework, it is recognized that different environments: (i) have diverse storage architectures, (ii) need to guard against different kinds of threats, and may (iii) have different tolerances for the associated performance overheads when implementing the security mechanisms. Rather than have a one-solution-fits-all approach, The PIs propose to investigate the rich design space - threats, storage architecture, enforcement mechanism, performance - to offer insightful choices that can be useful when deploying\/customizing storage systems. DataVault will also include a usable objective-driven policy interface to configure the system for a given set of security and performance needs, while offering a convenient visualization dashboard for security management.","title":"HECURA: Exploiting Asymmetry in Performance and Security Requirements for I\/O in High-end Computing","awardID":"0621429","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7583","name":"ITR-HECURA"}}],"PIcoPI":["542015","521556"],"PO":["565272"]},"109570":{"abstract":"There is a critical need to accurately and efficiently assess and manage water quantity. This challenge is made greater because water management must be conducted under conditions of uncertainty about current and future water resources. Adaptive water management has become the policy heuristic adopted for flexible water management that responds to ever changing physical and social demands. The central challenge of the Adaptive Management approach is the need to quantify the uncertainty in observed water measurements. This research will create new knowledge discovery and information fusion algorithms to compute two water<br\/>metrics and embed them in an overall knowledge management system. The long-term goal is to develop intelligent, scalable decision support tools for collaborative systems that explicitly incorporate uncertainty to analyze and integrate hydrological data and information. The specific objectives of the proposal are:<br\/><br\/>1. Knowledge Discovery and Information Fusion: Design scalable algorithms to (a) compute Quality of Data (QoD) Quality of Information (QoI) and Quality of Knowledge (QoK), (b) incorporate proximity in geospatial events into spatio-temporal data mining and (c) integrate heterogeneous, incomplete, and uncertain geospatial data and information.<br\/>2. Water Metrics: Develop an integrated water metric on Water Status - the integrated state of all water resources at a given point in space and time.<br\/>3. Adaptive Management: Identify specific Water Metrics that managers and decision makers use for adaptive water management.<br\/>4. Software Products: Build a suite of web-based knowledge discovery and information fusion tools to analyze, integrate and visualize hydrological data, water metrics and their quality. <br\/><br\/>Intellectual Merit: The proposed research will contribute knowledge discovery and information fusion methods that explicitly model and propagate uncertainty in general and geospatial analysis in particular. An integrated framework of a digital repository of multiple and diverse data sets will be designed, powered by effective and efficient knowledge discovery, information fusion and visualization tools, that: i) assists hydrologists develop comprehensive models and metrics for the analysis of the water cycle; ii) supports decision makers in adaptive management decisions; and iii) helps policy makers study the social and legal impact on water users.<br\/><br\/>Broader Impact: The research will advance the state of the art in three disciplines: (a) computer science, by developing novel knowledge discovery techniques, (b) hydrology, by developing two integrated water metrics using information fusion approach, and (c) water management and other applications, by identifying important parameters for successful adaptive management.","title":"Building Knowledge Discovery and Information Fusion Tools for Collaborative Systems to Adaptively Manage Uncertain Hydrological Resources","awardID":"0535255","effectiveDate":"2006-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1629","name":"BE: NON-ANNOUNCEMENT RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["521702","526198",290077,"521703",290079],"PO":["560586"]},"118282":{"abstract":"The increasing demand for Exa-byte-scale storage capacity by high end computing applications requires a <br\/>higher level of scalability and dependability than that provided by current file and storage systems. The proposal deals with file systems research for metadata management of scalable cluster-based parallel and distributed file storage systems in the HEC environment. It aims to develop a scalable and adaptive metadata management (SAM2) toolkit to extend features of and fully leverage the peak performance promised by state-of-the-art cluster-based parallel and distributed file storage systems used by the high performance computing community. There is a large body of research on data movement and management scaling, however, the need to scale up the attributes of cluster-based file systems and I\/O, that is, metadata, has been underestimated. An understanding of the characteristics of metadata traffic, and an application of proper load-balancing, caching, prefetching and grouping mechanisms to perform metadata management correspondingly, will lead to a high scalability. It is anticipated that by appropriately plugging the scalable and adaptive metadata management components into the state-of-the-art cluster-based parallel and distributed file storage systems one could potentially increase the performance of applications and file systems, and help translate the promise and potential of high peak performance of such systems to real <br\/>application performance improvements. The project involves the following components: <br\/>1. Develop multi-variable forecasting models to analyze and predict file metadata access patterns. <br\/>2. Develop scalable and adaptive file name mapping schemes using the duplicative Bloom filter array technique to enforce load balance and increase scalability <br\/>3. Develop decentralized, locality-aware metadata grouping schemes to facilitate the bulk <br\/>metadata operations such as prefetching. <br\/>4. Develop an adaptive cache coherence protocol using a distributed shared object model for <br\/>client-side and server-side metadata caching. <br\/>5. Prototype the SAM2 components into the state-of-the-art parallel virtual file system PVFS2 and a distributed storage data caching system, set up an experimental framework for a DOE CMS Tier 2 site at University of Nebraska-Lincoln and conduct benchmark, evaluation and validation studies.","title":"HEC: Collaborative Research: SAM^2 Toolkit: Scalable and Adaptive Metadata Management for High-End Computing","awardID":"0621493","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7583","name":"ITR-HECURA"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["486060"],"PO":["565272"]},"118272":{"abstract":"The PIs propose to develop scalable tools and techniques that will work on large clusters to identify I\/O performance bottlenecks, visualize them for cluster users for ease of analysis. Thiese techniques will conduct large scale tracing and replaying, collecting vital information useful to analyze the cluster's performance given a specific application. The PIs will use automated and user driven feedback to raise or lower the level of tracing on individual cluster nodes to (1) zoom in\/ on hotspots and (2) trade off information accuracy vs. overheads. Extensive investigations will go toward ensuring the accuracy of the information.","title":"HEC: File System Tracing, Replaying, Profiling, and Analysis on HEC Systems","awardID":"0621463","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7583","name":"ITR-HECURA"}}],"PIcoPI":["540845","543574","486115"],"PO":["565272"]},"116282":{"abstract":"Satellite and ground-based remote sensing produces large quantities of heterogeneous and multisource spatial-temporal data. This offers promise for highly accurate retrievals of geophysical parameters on a global scale, but it also opens a number of computational challenges related to the construction of efficient and accurate retrieval algorithms. This project is exploring this opportunity through development of data mining methods to: (a) improve existing single-sensor retrieval algorithms; and (b) allow high-quality joint-sensor retrieval. Aerosol-related data from the TERRA and AQUA satellites and the AERONET network of ground-based sensors is being used for development and validation of the proposed algorithms. The intellectual merit of the proposed work is in: addressing this challenge through the use of complex forward-simulation models; exploring spatial-temporal properties of large, heterogeneous and multi-resolution data; conditional probability modeling and uncertainty estimation; sampling design; use of advanced data structures; and integration and handling of multi-TB data. The broader impacts stem from development of accurate aerosol retrieval methods that will allow improved characterization of the effects of aerosols on the Earth's energy and water cycles. Additionally, the project is providing guidelines for developing accurate and fast retrieval algorithms in other geoscience applications, and will lead to advancements in spatial-temporal data mining. The project is assuring a broad participation of students through incorporating the research results into several courses, exposing diverse groups of students to research, and widely disseminating the results through publications and the project web site (www.ist.temple.edu\/IIS-0612149).","title":"Collaborative Research: Data Mining Support for Retrieval and Analysis of Geophysical Parameters","awardID":"0612149","effectiveDate":"2006-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}}],"PIcoPI":["486283","486284"],"PO":["565136"]},"116293":{"abstract":"The need for higher level processing of Life Sciences resources using a database-like system has increased in the post genomic era, as researchers move from sequence-based to whole genome-based analysis. High throughput and low-cost data processing and gathering techniques are helping researchers to publish an abundance of interesting data from across the globe at an exponential rate. Paradoxically, researchers are now faced with the problem of efficiently and effectively locating and using resources of interest from the vast amount of distributed data repositories. So, the need for generic system and tool support for higher level complex query processing, interpretation of data, and workflow management in a declarative fashion has become critical. The overall goal of this project is to develop a platform, which we will name LifeDB, for ad hoc integration of Life Sciences resources based on a declarative workflow query language called BioFlow. To a large extent, the system will support command line as well graphical interfaces for ad hoc application development and workflow query processing involving distributed resources without any need for traditional programming. The team is developing a visual interface, called WebFusion, for the automatic integration and workflow query processing using biological data as a manual and initial solution, a formal syntax and semantics for BioFlow, a declarative language, to support on the fly integration and workflow query and, new methods for low level data integration, wrapper, and schema mapping service requests toward the implementation of LifeDB system. The approach will change the way biologists currently query databases. Successful implementation and future enhancements of the system will obviate the need for biologists to focus on the \"how to\" of their application and more on the \"what to\" of their research. Students are actively engaged throughout the research.","title":"SEIII-II(BIO): Automatic Tools for the Integration and Analysis of Life Sciences Data","awardID":"0612203","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}}],"PIcoPI":["425921",307804,307805,307806],"PO":["565136"]},"109462":{"abstract":"Recent advances in temporal mining techniques and the proliferation of text documents have opened up possibilities as well as the need for mining temporally significant information from text repositories. The goal of this project is to find news ways to extract meaningful temporal relationships from unstructured text. The approach is based on temporal segmentation of document collections to detect time-varying nature of term use in the collection (e.g., apple or window). This technique will allow the system to do topic tracking and topic detection, in addition to time-sensitive queries. A semantically rich temporal query language that uses keywords, temporal literals, propositional temporal operators as well as Boolean is developed and implemented in an experimental system Chronomine. A novel temporal indexing structure is developed to support efficient querying. The results of this project include the formal semantics and a language for temporal mining of text documents and a system that is capable of temporal decision support from text collections. The project provides educational as well as research opportunities for both graduate and undergraduate students. The research results are incorporated into a prototype that will be freely available on the Web (http:\/\/faculty.ist.unomaha.edu\/pchundi) for anyone to analyze document sets by uploading them. The source code of the prototype will be also made available to the community at large by making it an open source.","title":"Temporal Mining of Text Documents","awardID":"0534616","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["352626"],"PO":["563751"]},"109385":{"abstract":"All nations are facing global problems such as border control and immigration, drug trafficking, terrorism, human disease detection and control, rapid detection of diseases and pests threatening agricultural commodities, and others. The solutions to these complex problems require organizations within a country as well as across national boundaries to effectively and efficiently share, not only heterogeneous data, but also knowledge captured in different knowledge representation schemes and application systems to support their problem-solving and decision-making in highly distributed and dynamic environments. This project will develop the infrastructure and technologies for the processing and management of 1) distributed events, 2) dynamic data associated with event occurrences, and 3) knowledge expressed by different types of rules and rule structures (multi-faceted knowledge) and application system operations invoked by rules. The context for this research is the USDA's National Plant Diagnostics Network (NPDN), a network established for rapid detection of crop disease and pest outbreaks. NPDN's goal is to enable many collaborating organizations to receive data associated with each occurrence of an event type as well as data generated by different types of rules and rule structures, and application operations triggered by the event. This will support the local decision-making, problem-solving and activity coordination of collaborating organizations.<br\/><br\/>The expected results include 1) an extended rule markup language and user interface tools for defining events and capturing multi-faceted knowledge, 2) techniques for efficient and effective management and processing of distributed, heterogeneous events, event data, triggers and rules, 3) a domain ontology for plant disease diagnostics and techniques for ontology management, 4) an extended Web Service infrastructure with an ontology-enhanced and constraint-based registry for semantic discovery of triggers, rules and application operations that are uniformly modeled and published as Web Services, and 5) the deployment of the developed tools and system at several regional centers of the NPDN for application and evaluation of the R&D results.<br\/><br\/>Intellectual merits: First, the extended Rule Markup Language will contribute to the effort of the RuleML community in developing a standard language for organizations to specify and share policies, regulations, processes and constraints expressed in terms of high-level declarative rules. Second, the resulting techniques, algorithms, methodologies and infrastructure will significantly advance the state of arts of information and knowledge management. Third, the proposed ontology-enhanced and constraint-based Web Service registry will significantly improve the quality of discovery and invocation of registered rules, rule structures, and application system operations. By converting heterogeneous rules and rule structures into Web Services, all that will be needed is a single rule server that invokes them as Web Services to achieve collaborative problem-solving.<br\/><br\/>Broader Impacts: First, the R&D results will be applied and evaluated by a federation of collaborating organizations in the NPDN environment. The deployment of the resulting collaborative system and tools will have an immediate application to and impact on the NPDN organization because they will be timely informed of any disease or pest outbreak and receive guided assistance on appropriate emergency response resulting from the application of knowledge rules. Second, events, multifaceted knowledge specifications and application operations registered in the Web Service registry will capture collaborating organizations' policies, regulations, processes and constraints for later education and training uses.","title":"Processing Dynamic Event Data and Multifaceted Knowledge in a Collaboration Federation","awardID":"0534065","effectiveDate":"2006-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7496","name":"COLLABORATIVE SYSTEMS"}}],"PIcoPI":["361593",289580],"PO":["543481"]},"127360":{"abstract":"Data integration systems provide a uniform access to a multitude of data sources. They have the potential to revolutionize the way we access data, and provide a basis on which to build even more advanced information processing architectures. However, today such systems are still extremely hard to build and costly to maintain. They must be told in tedious detail how to interact with data sources, and must be constantly modified to deal with changes at the sources. To address this problem, the project envisions building data integration systems that learn to evolve and self-manage over time, with minimal human intervention. To make fundamental contributions toward realizing this vision, the project employs database and artificial intelligence (especially machine learning) techniques to attack the following central challenges: (a) effectively automating key labor-intensive tasks, including schema matching, global schema creation, and duplicate detection, (b) detecting system failures due to changes at the sources, with minimal human intervention, and (c) further reducing the tremendous data integration burden of the system administrators by spreading the burden thinly over the mass of users. <br\/><br\/>The education plan leverages the research to prepare students and the broader community for the novel data management challenges raised by the Internet world. In terms of intellectual merit, the project takes a next logical step in data integration research. It brings conceptually novel solutions to fundamental issues underlying virtually any data integration or sharing efforts. The project results have the potential for autonomic-computing applications. In terms of broader impacts, the project will facilitate the widespread deployment of data integration systems, thus resulting in more effective information management and access for society. It plays an integral part in educating next-generation professional workers and researchers. The research will also help integrate data for rural Illinois fire fighters, and train them in access and use of the integrated information systems. The project information will be disseminated via publications, workshops, tutorials, and the Web site http:\/\/www.cs.wisc.edu\/~anhai\/projects\/career.html that will include the resulting research results, data and system artifacts.","title":"CAREER: Evolving and Self-Managing Data Integration Systems","awardID":"0712836","effectiveDate":"2006-08-31","expirationDate":"2010-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["499351"],"PO":["427499"]},"118263":{"abstract":"Unlike traditional I\/O designs where data is stored and retrieved by request, a new I\/O architecture for High End Computing (HEC) based on a novel \"Server-Push\" model where a data access server proactively pushes data from a file server to the compute node's memory. The objective of this research is two fold: <br\/>1) increasing fundamental understanding of data access delay,<br\/>2) producing an effective I\/O architecture that minimizes I\/O latency. The PIs plan to increase the fundamental understanding through the study of data access pattern identification, prefetching algorithms, data replacement strategy, and extensive experimental testing. The PIs will verify the performance improvement with their file server design for various critical I\/O intensive applications by using a combination of simulation and actual implementation in the PVFS2 file system.","title":"HECURA: The Server-Push I\/O Architecture for High End Computing","awardID":"0621435","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7583","name":"ITR-HECURA"}}],"PIcoPI":["557487","557489","521549"],"PO":["565272"]},"109441":{"abstract":"Many environmental phenomena (e.g., changes in global levels of atmospheric carbon dioxide) can be modeled as variations of attributes over regions of space and time, called dynamic spatial fields. The goal of this project is to provide efficient ways for sensor networks to monitor such fields, and to report significant changes in them. The focus is on \"qualitative\" changes, such as splitting of areas or emergence of holes in a region of study. The approach is to develop qualitative and topological methods to deal with changes. Qualitative properties form a small, discrete space, whereas quantitative values form a large, continuous space, and this enables efficiencies to be gained over traditional quantitative methods. The combinatorial map model of the spatial embedding of the sensor network is rich enough so that for each sensor, its position, and the distances and bearings of neighboring sensors, are easily computed. The sensors are \"responsive\" to changes to the spatial field, so that sensors are activated in the vicinity of \"interesting\" developments in the field, while sensors are deactivated in quiescent locations. All computation and message passing is \"local\", with no centralized control. Optimization is addressed through use of techniques in qualitative representation and reasoning, and efficient update through a dynamic and responsive underlying spatial framework. Effective deployment of very large arrays of sensors for environmental monitoring has important scientific and societal benefits. The project is integrated with the NSF IGERT program on Sensor Science, Engineering, and Informatics at the University of Maine, which will enhance educational and outreach opportunities. The project Web site (http:\/\/www.spatial.maine.edu\/~worboys\/sensors.html) will be used for broad results dissemination.","title":"Monitoring Dynamic Spatial Fields Using Responsive Geosensor Networks","awardID":"0534429","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7485","name":"DATA MANAGEMENT SYSTEMS"}}],"PIcoPI":["409353",289731],"PO":["563751"]},"125084":{"abstract":"This research is to investigate statistical and computational methods for simultaneous clustering of data matrices and their extensions to handle data hypercubes using spectral techniques. It uses techniques of cluster analysis, which is method of extracting information from large data sets. Many existing methods rely on clustering the data objects using all the attributes for similarity measurement. However, often the natural groupings of the data objects do not involve all attributes. For example, in gene expression analysis, for data generated by DNA chips under various conditions (tissue types, individuals, external stimuli etc.), it is unlikely that biologically related genes will behave similarly across all conditions, nor related set of conditions will involve all the genes. The focus of this project is to develop clustering algorithms that can, for example, find subsets of genes that behave similarly across subsets of conditions. The techniques are based on spectral methods for simultaneous clustering of data matrices. The results, algorithms, and techniques developed will have applications in bioinformatics and text analysis applications.<br\/><br\/>The focus of the research is on identifying classes of cluster patterns in a data matrix that can be recovered by the spectral information of the data matrix. The research explores various objective functions that characterize desirable grouping patterns, and develops algorithms for cluster membership assignment from the spectral information. The methodology is being extended to the case of multi-way data hypercubes and to exploring connection of clustering and dimension reduction.","title":"Matrix Algorithms for Data Clustering and Nonlinear Dimension Reduction","awardID":"0701796","effectiveDate":"2006-08-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["549456"],"PO":["565157"]},"119320":{"abstract":"Physical Layer Dependent Neighbor Discovery and Topology Management in Ad hoc Networks<br\/><br\/>Award 0626912<br\/><br\/>S. Krishnamurthy, M. Faloutsos and N.E. Young<br\/><br\/>Under realistic wireless channel representations, the project re-examines a node's neighborhood with three physical layer technologies: (a) rate controllable transmissions, (b) directional antenna capabilities, and (c) Multi-Input Multi-Output (MIMO) capabilities. To limit the overhead incurred with these technologies, topology control is incorporated. Specifically, with rate control, the best trade-offs between rate and range are achieved. In cases (b) and (c), per-neighbor channel state information (CSI) needs to be maintained. Maintaining CSI for large numbers of neighbors is overhead intensive. The topology control framework limits the CSI by having each node communicate with only a carefully chosen sub-set of neighbors while ensuring connectivity and short end-to-end paths. <br\/><br\/>For each technology, the project develops: (i) centralized algorithms to study the trade-offs between the operational parameters and (ii) deployable distributed neighbor discovery protocols. The schemes are evaluated via simulations and analyses. In addition, the rate control mechanisms are implemented on an experimental testbed at UCR.<br\/><br\/>Impact: Neighbor discovery and maintenance are critical in any self-organizing wireless network. The project addresses these aspects with realistic physical layer representations. This is critical for the deployment success of wireless networks. <br\/><br\/>Expected Results: New cross-layer protocols that combine neighbor discovery and topology management will be developed. The centralized approaches will provide fundamental bounds on the performance. The distributed protocols will be amenable to implementation. The developed software will be made available on a project website.","title":"NeTS-NBD: Physical Layer Dependent Neighbor Discovery and Topology Management in Ad hoc Networks","awardID":"0626912","effectiveDate":"2006-08-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["486542","549003","550738"],"PO":["557315"]},"109442":{"abstract":"Motion is an important component in temporal datasets representing a variety of sensor devices. This project investigates the design of scalable motion-content-based indexing\/retrieval mechanisms and an activity recognition system for applications that employ large motion data archives. A unified mathematical framework is developed for representing motion features that allows integration of indexing\/retrieval formulation as well as semantic-based intelligent recognition systems. Motion trajectories are segmented into sub-trajectories using computationally efficient techniques that exploit curvature information and cope with occlusions and missing data. Representation of sub-trajectories is based on principle component analysis (PCA) of the motion data which allows compact low-dimensional representation as well as real-time query processing. Extension of this representation to multiple motion trajectory data is based on three-dimensional tensor singular value decomposition (SVD). Innovative use of these analytically-motivated feature spaces is relied upon for developing robust indexing and retrieval systems and scalable activity recognition systems based on Hidden Markov Models. The techniques developed are prototyped and the performance of the system is evaluated using several video archives. The project is a giant step forward towards unifying query-by-example-based indexing and retrieval systems and high-level semantic query-based activity recognition systems. This project will significantly enhance the current state of the art in content-based indexing and retrieval and activity recognition systems for applications that employ temporal datasets. It will facilitate the development of diverse motion-based applications for entertainment and security applications. The project web site (http:\/\/multimedia.ece.uic.edu\/motionsearch) provides access to resulting research papers and implementation code.","title":"MotionSearch: Motion Trajectory-Based Object Activity Retrieval and Recognition from Video and Sensor Databases","awardID":"0534438","effectiveDate":"2006-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7496","name":"COLLABORATIVE SYSTEMS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["415103","532978"],"PO":["563751"]},"118275":{"abstract":"This project investigates system-level techniques to efficiently support concurrent I\/O workloads on cluster-based parallel storages. At the server operating system level, research will focus on the reduction of disk seek\/rotation overhead during concurrent I\/O. At the storage cluster level, research will focus on the synchronization within each parallel I\/O operation under concurrent workloads. For parallel I\/O embedded with computing tasks (like parallel data aggregation), research will be performed on storage server load adaptation under concurrent workloads.<br\/>Efforts will be made to integrate proposed techniques with the server operating system, clusterbased parallel file system, and I\/O middleware. The resulted software should be transparent to parallel I\/O applications so they can benefit without any changes.","title":"HECURA: Concurrent I\/O Management for Cluster-based Parallel Storages","awardID":"0621472","effectiveDate":"2006-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7583","name":"ITR-HECURA"}}],"PIcoPI":["550397"],"PO":["565272"]},"116790":{"abstract":"CSR-AES: Interactive Parallel Platforms for Multi-Experiment<br\/>Computational Studies<br\/><br\/>Scientists and engineers increasingly rely upon computational studies<br\/>involving multiple experiments (runs of simulation software) in domains<br\/>ranging from engineering design-space exploration to drug design.<br\/><br\/>This collaborative project develops foundations for a system that<br\/>facilitates interactive computational studies involving large numbers of<br\/>experiments, permitting the user to continuously monitor and steer how<br\/>the study unfolds, based on partial results. The work specifically<br\/>targets engineering design applications involving small-to-medium size<br\/>simulation problems running on tightly-coupled parallel machines, and<br\/>emphasizes (1) higher-level user control of the overall study; (2) reuse<br\/>of data from prior experiments in carrying forward new computations; (3)<br\/>dynamic management of system resources by relying on a tighter coupling<br\/>between application and system software; and (4) software reuse based on<br\/>common component architecture (CCA) compliance and standardization of a<br\/>more permeable system-\/solver-level interface.<br\/><br\/>The system architecture builds upon the SCIRun2 framework and<br\/>incorporates modules for translating high-level user specifications into<br\/>required experiments, for allocating parallel machine resources to<br\/>experiments to optimize study progress, and numerical methods and<br\/>algorithms for estimating simulation time and resource costs.<br\/><br\/>The primary impact of the work is expected in engineering design, with<br\/>broader applicability to additional classes of biomedical and geometric<br\/>modeling applications. The project will also have important educational<br\/>applications, by creating hands-on simulated exploration experiences for<br\/>students, and by training system computer scientists with a deep<br\/>understanding of specific scientific domains, simulation frameworks, and<br\/>numerical solver interfaces.","title":"Collaborative Research: CSR--AES: Interactive Parallel Platforms for Multi-Experiment Computational Studies","awardID":"0614770","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["554341"],"PO":["535244"]},"116593":{"abstract":"With the widespread use of the World Wide Web (WWW), programs are increasingly run on virtual machines, which are compiled dynamically to achieve high performance. However, the energy efficiency of the dynamic compilation itself and energy-oriented optimizations that can be efficiently performed by the dynamic compiler at runtime are still largely unexplored. This project studies the dynamic compilation process from the energy consumption perspective and is developing a variety of novel optimization strategies, ranging from pure software-based dynamic transformations to compiler-directed dynamic energy management, runtime adaptation and architectural customization. This effort seeks to systematically and substantially reduce the energy consumption of mobile applications running on virtual machines, without significant impact on performance.<br\/><br\/>The success of this research is expected to accelerate the application of Java programming language to a wider variety of energy-constrained embedded systems, such as mobile phones and PDAs. With improved energy efficiency and prolonged battery lifetime, new applications with rich functionality can be developed for mobile devices. Undergraduate and graduate students are involved in all aspects of this research. New and enhanced courses at the graduate and undergraduate level are being offered as an outcome of this project. The developed software packages and course material are made publicly available through the research website, for use by other researchers or institutions.","title":"CSR---EHS: A Dynamic Compilation Framework for Energy Reduction on Mobile Devices","awardID":"0613633","effectiveDate":"2006-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["121660"],"PO":["561889"]},"116296":{"abstract":"Astroinformatics is a rising field at the interface between Computer Science and Astronomy with new discoveries made possible by the abundance in galactic data created by the Sloan Digital Sky Survey (SDSS). This work provides the statistical framework for astronomical model checking and inference from data. The computational bottleneck in the probabilistic approaches is one of the main obstacles, with grid computing offering a promising solution. In order to use grid technologies, a middleware lay that permits decentralized resource management is necessary to deal with a variety of issues. The research focuses on the development of modular, highly customizable, decentralized coordination using peer-to-peer protocols and methods to optimize the inclusion of nodes in the network as well as generic algorithms for distribution of large problems in parallel computational environments. The project will provide a seamless framework for testing models that address fundamental questions in astronomy. The tools will enable a wide range of other parallel adaptive applications in physics, materials science and ecology. In addition, curricula and public demonstrations are part of the project.","title":"SEI(AST): A Dynamic Grid for Astroinformatics: Data-Driven Discovery of the Milky Way Origin and Evolution from the Sloan Digital Sky Survey","awardID":"0612213","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0700","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"1217","name":"EXTRAGALACTIC ASTRON & COSMOLO"}}],"PIcoPI":["430756","447331","489824",307820],"PO":["565136"]},"118265":{"abstract":"The performance of many high-end computing applications is limited by the capacity of memory systems to deliver data. As processor speeds increase, I\/O performance continues to lag substantially. Thus, I\/O is likely to remain a critical bottleneck for high-end computing.<br\/> <br\/>In this research project The PIs propose to build a prototype of a streaming B-tree for deployment in a database or file system. This prototype will realize t fast insertions, fast range queries, and platform independence. The PIs will simultaneously work on how to deal with different-sized keys, how to support transactions, how to scale to multiple disks and processes, and how to provide O\/S support for cache-obliviousness and memory-mapped massive data. The proposed work represents a promising new direction in how to manipulate massive data and overcome classic I\/O bottlenecks.","title":"HEC: Collaborative Research: Techniques for Streaming File Systems and Databases","awardID":"0621439","effectiveDate":"2006-08-01","expirationDate":"2010-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7583","name":"ITR-HECURA"}}],"PIcoPI":["533341"],"PO":["565272"]},"119288":{"abstract":"0626741 Kamal<br\/>High-performance networks are expected to support applications with multipoint traffic type, e.g., one-to-many, many-to-one and many-to-many. Since high-performance networks usually employ optical network infrastructures, and since most applications require sub-wavelength bandwidth, several streams are usually groomed on the same wavelength. It is therefore important that such networks be designed in a way that is optimal in terms of cost, while effectively supporting this type of traffic. This project deals with the design and analysis of survivable optical networks for multipoint traffic grooming. The project considers the design of the traffic multiplexing equipment to support multipoint traffic grooming. It also investigates the use of network coding and its implementation in such devices, and how such a technique can be used to reduce network implementation cost, enhance network traffic handling capabilities, and support network survivability. Both static and dynamic traffic conditions are considered. Optimal as well as accurate heuristic approaches will be developed for network design and operation under static traffic conditions. Under dynamic traffic conditions, the dynamic provisioning of multipoint sessions, subject to the availability of resources, and the dynamic nature of sessions and users within sessions is considered, and algorithms to facilitate this provisioning will be developed. <br\/>The broader impact of this research includes the development of algorithms, which can be used by network designers and operators to support high performance applications efficiently. It also includes training of students in the area of optical networks, as well as enhancing existing and creating new graduate and senior undergraduate-level courses.","title":"NeTS-NBD: Survivable Multipoint Traffic Grooming in Optical Networks","awardID":"0626741","effectiveDate":"2006-08-15","expirationDate":"2011-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["521840","417502"],"PO":["564993"]},"116890":{"abstract":"CSR-PDOS-Collaborative: Virtual Machines Meet Application Clusters: A<br\/>Highly Responsive Global Utility Computing Platform for Internet<br\/>Applications<br\/><br\/>With the omni-presence of Internet applications, service-oriented computing<br\/>increasingly plays a dominant part in global computing. Thus,<br\/>understanding how to build efficient platforms for service-oriented<br\/>computing is critical in supporting continued Internet proliferation. The<br\/>overriding goal of this research is to gain such understanding, and in<br\/>particular to investigate basic principles in building a global Utility<br\/>Computing for Internet Applications (UCIA) platform that is highly<br\/>responsive in resource reallocation, provides resource isolation to<br\/>different applications, and supports heterogeneous execution environments.<br\/><br\/>This research encompasses a number of specific directions. This includes<br\/>studying tradeoffs between different architectures for resource sharing in<br\/>a global UCIA platform and investigating efficient algorithmic approaches<br\/>to request distribution and application placement that account for the<br\/>computational cost of executing the algorithms and the interaction of these<br\/>two policies. It focuses in particular on the interaction between two<br\/>foundational technologies in global UCIA, wide-area application clustering<br\/>and virtual machines. By leveraging these technologies in a novel way,<br\/>this research promises a significant speed-up in resource redistribution<br\/>among applications. To quantify its findings, this project utilizes a<br\/>wide-area testbed running a sample of off-the shelf Internet applications<br\/>and emulating several data centers.<br\/><br\/>Internet applications are transforming the Web from an information system<br\/>into a global service-oriented computing platform. By improving our<br\/>ability to build highly responsive, global utility computing platforms for<br\/>Internet applications, this research will support continued progress in<br\/>this important direction.","title":"CSR-PDOS-Collaborative: Virtual Machines Meet Application Clusters: A Highly Responsive Global Utility Computing Platform for Internet Applications","awardID":"0615190","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["409444"],"PO":["493916"]},"116594":{"abstract":"We are now entering a new phase for software development where millions of people are not only using software but also becoming involved in its development to widely varying degrees. Existing software design methodologies that focus primarily on productivity-driven systems are insufficient to cope with the emergence of situated uses and fluctuating requirements encountered by such wide and diversified user involvement. Rather, a new class of participative software systems is needed, the design of which does not end at the time of deployment. For participative systems success hinges on continued user participation, and an important goal is to achieve the \"best fit\" between the software system and its ever-changing context of use, problems, domains, users, and communities of users. In this project, the PI will develop a meta-design framework to address fundamental challenges and guide software developers in the design of such systems. Grounded in an assessment of existing design theories as well as the systematic analysis of successful participative software systems, this research will start with a partially articulated meta-design framework, founded on the assumption that meta-designed systems can be supported by the Seeding, Evolutionary Growth, and Reseeding (SER) process model. The PI will identify and correlate the technical and social characteristics of participative software systems that support users to collaboratively engage in the design of solutions to their own problems. The identified characteristics will be used to guide future development of the Envisionment and Discovery Collaboratory (EDC), which will be used by real users to solve complex real-world problems in different design domains. The work will be integrated with a specific major, multi-year urban planning project relating to public transportation, for which an initial collaboration among the stakeholders has already been formed. Careful and systematic assessment of design decision impacts, guided by the initial meta-design framework, on this real-world problem-solving situation will feed back into the refinement of the meta-design framework. The resulting meta-design framework will delineate a design space, define a design process, and identify a set of evaluation criteria for the creation of participative software systems.<br\/><br\/>Broader Impacts: As software systems are being increasingly woven into our daily lives and reshape the way people interact, collaborate, work, and think, requirements for software systems have become more individually differentiated and continuously change during their ongoing use. This research will create the scientific foundation for the design of participative software systems that do not have fixed requirements at any point in time, and necessitate user participation and contribution as a fundamental part of the system. The research will contribute to a better understanding of the complicated interactions of technical and social aspects essential to this challenging domain of a science of design. The project will bring together researchers from design theory, software engineering, human-computer interaction, and cognitive science to gain insight into how to put owners of problems in charge and make them independent of \"high-tech scribes.\" The many undergraduate and graduate students who will be involved in the research activities will as part of their experience be exposed to new approaches to software design.","title":"SoD-Team: A Meta-Design Framework for Participative Software Systems","awardID":"0613638","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7372","name":"ITR-SCIENCE OF DESIGN"}}],"PIcoPI":["483372","483373",308541,"377546"],"PO":["565227"]},"109554":{"abstract":"The goal of this research project is to empower users to retrieve, modify and reuse 3D data reliably to create assemblies simply by drawing a freehand sketch. This will serve as the foundation for a new \"sketching computing\" paradigm. The approach consists of (1) allowing users to express design ideas in the form of freehand sketches while detecting 2D sketch and 3D assembly constraints. 2D and 3D constraints are detected from the freehand drawing using relative shape histogram and 3D pose determination. This allows the system to capture the user's design intentions without explicit user specifications. (2) A 3D model segmentation method is used to facilitate partial shape replacement and search through operations such as \"cutting,\" and \"pasting\" partial shapes. (3) A 3D assembly technique using 2D and 3D constraint mapping is then used to enable model construction from search results. <br\/><br\/>The research goals will make design more accessible for people who are not trained in using complex Computer-Aided Design (CAD) tools. The results of this project will lead to a workable sketch-based system that could be more intuitive for designers than conventional CAD systems. This will promote better creativity during the design process and reduce the need for user training. It will also demonstrate new useful ways to integrate pen-based computing into many existing computer-application paradigms. The project Web site (http:\/\/www.purdue.edu\/sketchlab and http:\/\/www.purdue.edu\/shapelab) will be used for dissemination of results and providing access to the experimental system.","title":"3D Sketch-Based System for Conceptual Design","awardID":"0535156","effectiveDate":"2006-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"1504","name":"GRANT OPP FOR ACAD LIA W\/INDUS"}}],"PIcoPI":["553653"],"PO":["563751"]},"118266":{"abstract":"As high end computing systems (HECs) grow to several tens of thousands of nodes, file I\/O is becoming a critical performance issue. Current parallel file systems such as PVFS2 and others, can reasonably stripe data across a hundred nodes and achieve good performance for bulk transfers involving large aligned accesses. Serious performance limits exist, however, for small unaligned<br\/>accesses, metadata operations, and accesses impacted by the consistency semantics (any time one process writes data that is read by another).<br\/>The proposed research would study scalable metadata operations, small, unaligned data accesses, reliability through redundancy, and management of I\/O resources. The employed techniques include active caching and buffering, server-to-server and client-to-client communication, and autonomics. To enhance portability and control complexity proposed research intend to employ middleware whenever possible, and use PVFS2 file system that allows a large degree of configurability. The proposed research intends to enhance that file system so that it will scale to very large sizes.","title":"HECURA: Improving Scalability in Parallel File Systems for High End Computing","awardID":"0621441","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7583","name":"ITR-HECURA"}}],"PIcoPI":["521239"],"PO":["565272"]},"109477":{"abstract":"Current database management systems require all data to be modeled in terms of precise values. However, there is a large number of application domains where data values are imprecise or uncertain. Examples of such data include measurements for sensors, locations of moving objects, and experimental data. For these applications there is a need to develop a database management system that supports uncertain data types. <br\/><br\/>The project aims to develop a comprehensive database management system for storing and querying uncertain, or imprecise data. The project encompasses the creation of a comprehensive model for uncertain data based upon the relational model, the extension of SQL to support probabilistic queries over uncertain data, techniques for efficient and accurate evaluation of probabilistic queries, and the development of a prototype system. The specific optimization issues addressed include indexing, join algorithms, and query optimization for uncertain data. <br\/><br\/> The prototype will be developed as an extension of the open-source PostgreSQL database management system. A realistic moving objects' application is targeted for testing of the prototype. In addition, collaboration with experts in biology and chemistry will serve as validations of the applicability of the developments in these domains. <br\/><br\/> The project is expected to have a significant impact on application domains that are in need of an uncertain data management system, and also on the database community. The proposal is expected to provide a single model for multiple types of uncertainty, and to develop indexing, join, and query optimization techniques for uncertain data. <br\/><br\/>This project will integrate research and education through student participation in research projects, course development, and research seminar. The results from this research will be included in course projects and will be disseminated via peer-reviewed publications in journals and conferences, conference presentations, and the Web pages (http:\/\/wwww.cs.purdue.edu\/homes\/sunil\/UncertainDB) that will also provide the prototype dissemination.","title":"Design and Development of a Data Management System for Uncertain Data","awardID":"0534702","effectiveDate":"2006-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7485","name":"DATA MANAGEMENT SYSTEMS"}}],"PIcoPI":["470080"],"PO":["563751"]},"109488":{"abstract":"The goal of this project is to provide efficient techniques for querying objects in geographic information systems (GIS) with \"functional\" attributes. Emerging GIS applications (e.g., transportation networks, traffic management, meteorological, sensor-based surveillance, mobile services) involve objects that employ one or more functional attributes. These attributes are typically functions of time and\/or space (e.g., vehicle speed, precipitation, traffic flow etc.) The importance of functional attributes has been recently recognized by GIS users (especially researchers) as well as developers; however, their support is still primitive. Functional attributes drastically affect query processing speed, as they are typically computationally intensive and the query performance is based on the efficient evaluation of the attribute functions. Novel methods and solutions are thus needed. While functions can be very complex, this study concentrates on functions described (and thus stored) in constant space (e.g., polynomials of constant degree). Solutions to various query variations are proposed (aggregations, selections, joins, nearest neighbors, etc.) while both historical and predictive queries are examined. The approach taken consists of maintaining specialized indices that incrementally compute query results. A prototype that serves as a toolbox of efficient techniques for processing complex objects is also created. The results of this research will improve querying capabilities for the many applications that contain objects with functional attributes, including meteorological, geospatial, cellular, demographic, social, surveillance and traffic management environments, to name a few. The prototype will be available for use by researchers and students via the project Web site (http:\/\/www.cs.ucr.edu\/~tsotras\/functional.html). Course materials using this prototype will be developed as well. Through an existing collaboration with a GIS vendor, the results of this project have the potential to enhance the implementation of future GIS systems.","title":"Query Processing Over GIS Objects With Functional Attributes","awardID":"0534781","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7485","name":"DATA MANAGEMENT SYSTEMS"}}],"PIcoPI":["543515","430635"],"PO":["563751"]},"116891":{"abstract":"CSR-AES: Interactive Parallel Platforms for Multi-Experiment<br\/>Computational Studies<br\/><br\/>Scientists and engineers increasingly rely upon computational studies<br\/>involving multiple experiments (runs of simulation software) in domains<br\/>ranging from engineering design-space exploration to drug design.<br\/><br\/>This collaborative project develops foundations for a system that<br\/>facilitates interactive computational studies involving large numbers of<br\/>experiments, permitting the user to continuously monitor and steer how<br\/>the study unfolds, based on partial results. The work specifically<br\/>targets engineering design applications involving small-to-medium size<br\/>simulation problems running on tightly-coupled parallel machines, and<br\/>emphasizes (1) higher-level user control of the overall study; (2) reuse<br\/>of data from prior experiments in carrying forward new computations; (3)<br\/>dynamic management of system resources by relying on a tighter coupling<br\/>between application and system software; and (4) software reuse based on<br\/>common component architecture (CCA) compliance and standardization of a<br\/>more permeable system-\/solver-level interface.<br\/><br\/>The system architecture builds upon the SCIRun2 framework and<br\/>incorporates modules for translating high-level user specifications into<br\/>required experiments, for allocating parallel machine resources to<br\/>experiments to optimize study progress, and numerical methods and<br\/>algorithms for estimating simulation time and resource costs.<br\/><br\/>The primary impact of the work is expected in engineering design, with<br\/>broader applicability to additional classes of biomedical and geometric<br\/>modeling applications. The project will also have important educational<br\/>applications, by creating hands-on simulated exploration experiences for<br\/>students, and by training system computer scientists with a deep<br\/>understanding of specific scientific domains, simulation frameworks, and<br\/>numerical solver interfaces.","title":"Collaborative Research: CSR--AES: Interactive Parallel Platforms for Multi-Experiment Computational Studies","awardID":"0615194","effectiveDate":"2006-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["558600","342952"],"PO":["493916"]},"115230":{"abstract":"This award establishes a NSF-FDA Scholar-in-Residence (SIR) project at the U.S. Food and Drug Administration. With NSF support, two graduate students from North Carolina State University will participate in a research project to study technology for medical device evaluation at the FDA's Center for Research in Devices and Radiological health. This SIR project contributes towards the goal shared by NSF and the FDA of technology-supported, rigorous evaluation methods for embedded systems in software-intensive medical devices. This research focuses on applying the C-Wolf data abstraction and software analysis tool, developed at NCSU, to medical device software. This is part of an overall effort to explore the utility of software analysis tools in pre-approval device evaluation and post-incident forensic analysis. The longer-term goal of NSF-FDA SIR projects is to enable a more comprehensive, evidence-based approach for evaluation of medical devices and other safety-critical, software-centric systems.","title":"Forensic Analysis of Medical Devices","awardID":"0607886","effectiveDate":"2006-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["78952","78952","553865"],"PO":["561889"]},"116254":{"abstract":"Researchers who study ecological systems strive to understand the factors that influence extremely complex systems, in which tens if not hundreds of environmental factors can affect the distribution and abundance of a species. Challenges in managing a species across its entire geographic range are especially great, as scaling up insights from small local studies to management over an entire continent may be impossible. Further, initial management decisions may need to be made under very short time deadlines, and in the absence of much prior knowledge about a species. Often, the necessary data to inform timely management decisions for little-known species already exist; however, what is limiting is ready access to the data and especially to the analytical tools needed to explore these data. This project joins the strengths of data mining and machine learning tools with statistical methods, to create a suite of powerful new predictive and inferential tools in a new analytical framework for data mining and machine learning that will permit extracting more relevant information from the available data and by incorporating prior information into a hybrid hierarchical\/data mining model. The result will be new data-mining techniques that allow statistical inferences about large numbers of environmental variables and their potential interactions. This will greatly enhance the ability to model the landscape-level response of bird populations to multiple risk factors and to develop prescriptions for reversing population declines through land management. This project will expose new data resources and advances in computational analysis, data visualizations, and manipulations to vast new audiences: from biologists, conservation agencies, and land-use planners to school classrooms and tens of thousands of citizens who participate in environmental monitoring, including the millions of people across the country who watch birds. Additionally, the project trains new researchers in the union of powerful statistical techniques with machine learning and data mining","title":"SEI+II:Ecological Discovery & Inference: Tools for Data-driven Exploration and Testing of Observational Data","awardID":"0612031","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1629","name":"BE: NON-ANNOUNCEMENT RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}}],"PIcoPI":["513285","342321","514003","451421","358210"],"PO":["565136"]},"116265":{"abstract":"The genetic analysis of spatial patterns of gene expression relies on the direct visualization of the presence or absence of gene products at a given developmental stage (time) of a developing animal. In order to facility effect use of the fast growing collection of fruit fly (Drosophila) embryonic gene patterns from high throughput experiments, a computational framework for finding genes with overlapping expression patterns is being developed. The first step is to develop a learning system to identify automatically the developmental stage by image analysis. Once the developmental stage is determined, expression patterns are compared for spatial overlaps. The works deals with both the representation and manipulation of advanced data types and are intended to build a novel framework using machine learning techniques. In addition to facilitating both machine learning and molecular biology research, the work will engage students and the database used as a teaching resource.","title":"SEI: Machine Learning Approaches for Biological Image Informatics","awardID":"0612069","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}}],"PIcoPI":["538597","456042"],"PO":["565136"]},"119257":{"abstract":"Toward Building a Performance-Predictable Wireless Mesh Network<br\/><br\/>Award 0626584<br\/><br\/>Jennifer Hou<br\/><br\/>Community wireless networks have gained tremendous attention. Although initial success has been reported in several city-wide wireless access projects, a number of performance related problems have also been identified, including excessive packet losses, unpredictable channel behaviors, inability to find stable and high-throughput routes, and throughput loss due to intra-flow and inter-flow interference. These problems are all rooted in the fact that the notion of a link no longer exists in wireless environments. The UIUC team led by Jennifer Hou takes a bottom-up approach, and tackles issues with better definition and characterization of wireless links and their implications for higher-layer protocol design and optimization. They would like to (i) understand how, and to what extent, wireless links are affected by PHY\/MAC attributes and other environmental factors, (ii) characterize the behavior of wireless links in such a way that they become amenable to rigorous analysis, and (iii) identify control knobs in the MAC\/PHY layers with which the network capacity can be optimized. To make such a study with measurement, characterization, design components, the UIUC team works with Champaign-Urbana Wireless Mesh Network (CUWiN) to substantially extend its operational software infrastructure, and lays a virtual device driver on top of firmware. The virtual device driver enables dynamic tuning of control knobs to improve network capacity, and exports PHY\/MAC attributes through well-defined APIs to facilitate cross-layer design and optimization. The anticipated results of this project are an understanding (based on real-life measurements) of factors that affect the behaviors of wireless links, control knobs and their corresponding control mechanisms based on a rigorous, analytical foundation, and their validation and assessment with software system building and experimentation on CUWiN.","title":"NeTS-NBD: Toward Building a Performance-Predictable Wireless Mesh Network","awardID":"0626584","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["541861","342042"],"PO":["557315"]},"109489":{"abstract":"The BlogoCenter project is a collaborative effort (0534784, Junghoo 'John' Cho,<br\/>University of California-Los Angeles and 0534323, Dragomir Radev, University of<br\/>Michigan Ann Arbor) with a goal to develop innovative technologies for building a<br\/>system that (1) continuously monitors, collects, and stores personal Weblogs (or blogs)<br\/>at a central location; (2) discovers hidden structures and trends automatically from the<br\/>blogs; and (3) makes them easily accessible to general users. By making the new<br\/>information on the blogs easy to discover and access, this project is helping blogs<br\/>realize their full potential for societal change as the \"grassroots media.\" It is also<br\/>collecting an important hypertext dataset of human interactions for further analysis by<br\/>the social and behavioral sciences research communities.<br\/><br\/>In developing such a system, the project investigates new research challenges in three<br\/>areas: (1) novel monitoring algorithms that discover and download new information from<br\/>rapidly-changing distributed sources with minimal delay; (2) new text and graph mining<br\/>techniques appropriate for large-scale hypertext corpora; and (3) novel text ranking and<br\/>summarization algorithms to help the users access new and high-quality information<br\/>quickly from the rapidly-evolving blogs.<br\/><br\/>The project will make a significant impact to the scientific community by making the<br\/>collected datasets and the source code of the prototype available to other research<br\/>groups via the Web (http:\/\/www.eecs.umich.edu\/~radev\/blogocenter), accelerating<br\/>progress in the blog-related research. The new research findings will be disseminated<br\/>via scientific conferences and journals, spurring significant advancements in distributed<br\/>Web-source monitoring, text summarization and ranking, and large-scale text and graph<br\/>mining. In addition, this project will support graduate and undergraduate student<br\/>research and foster cross-institution collaboration.","title":"Collaborative Research: BlogoCenter - Infrastructure for Collecting, Mining, and Accessing Blogs","awardID":"0534784","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["316294"],"PO":["563751"]},"117783":{"abstract":"This project, creating a scientific visualization facility, supports research in fluid dynamics, geotechnical engineering, human factors in medical systems, image reconstruction and tomography, computational geometry, robotics, chemical mechanical planarization, computational anatomy, and visualization. The facility, with a visualization wall, motion capture equipment, 3D rendering device, and an SGI prism to provide computing power as main components, provides local access for visualization and motion capture. Subproject areas address fluid dynamics, chemical mechanical planarization (science and engineering); computational anatomy, medical visualization, tomography, medical imaging (medical informatics); visualization and graphics, immersive environments, computational geometry (computer science), etc. The infrastructure will be further advanced with an AccessGrid node, enabling researchers to conduct virtual collaborations with colleagues at other institutions that combine visualization with teleconferencing.","title":"Acquisition of a Scientific Visualization Facility","awardID":"0619447","effectiveDate":"2006-08-01","expirationDate":"2011-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}}],"PIcoPI":["519872",311839,311840],"PO":["557609"]},"128366":{"abstract":"This NSF CAREER project represents an effort towards the development of embedded control software that is correct by design. The pursuit of this ambitious objective relies on novel ideas fostering a paradigm shift in embedded software design by integrating control with software design. In particular, through the use of finite abstractions of continuous control systems, control theoretic ideas are being applied to the design of software enforcing dynamic constraints (control), software constraints (e.g., shared resources, real-time properties) and hardware constraints (e.g., power consumption, execution times). In addition to alleviating the need for testing and formal verification this research is also developing automated synthesis methods allowing for faster design cycles and an increase in functionality and complexity of embedded applications. This correct by construction approach to embedded control software design has immediate technological, economical and societal consequences triggered by a reduction in software development time and cost. Furthermore, the research outcome of this project is also contributing to the advancement in functionality, robustness and dependability of the large networks of embedded systems that are becoming essential infrastructures of our society. Important contributions to graduate and undergraduate education complement the research component of the project. A new graduate course on verification and synthesis of embedded control systems is being offered at Notre Dame. The lecture notes supporting this course will be published to further disseminate the novel ideas developed in the context of this project and to promote the creation of similar courses in other universities. Undergraduate education at Notre Dame is being improved through the participation of undergraduate students in research and by revising the laboratorial component of the introductory course to electrical networks in order to familiarize second year electrical engineering students with embedded systems and basic skills in embedded programming.","title":"CAREER: Automated Synthesis of Embedded Control Software","awardID":"0717188","effectiveDate":"2006-08-22","expirationDate":"2010-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}}],"PIcoPI":["526859"],"PO":["561889"]},"119434":{"abstract":"David Evans<br\/>University of Virginia<br\/>0627527<br\/>Disk-Level Malware Detection and Response<br\/><br\/>Abstract <br\/><br\/>This project explores ways to improve the efficiency and effectiveness of malware detection and response by using the disk drive processor. <br\/>Disk drive processing power and memory capacity are steadily increasing which presents the possibility of using disks as data processing devices rather than merely for storing and transferring data. Current anti-virus engines are limited by computational constraints and by their inability to closely observe the behavior of running processes efficiently. The behavioral detection techniques this project is developing detect malware based on observing disk I\/O activity. The research develops methods for expressing disk-level behavioral malware signatures, explores ways to incorporate various levels of semantic information into those signatures, and invents techniques for automatically generating these signatures using dynamic inference. Since the disk can mediate all I\/O requests, detectors for checking disk-level I\/O signatures can be efficiently and securely implemented using the disk processor. This project is also researching opportunities for using the disk processor to improve response to viruses that evade detection and infect the host. <br\/> The disk processor can be used to limit the damage that these viruses can do by protecting critical disk blocks, and can improve recovery by tracking questionable updates and automatically backing up disk blocks. <br\/> In addition, this project is developing techniques to aid rootkit detection by providing low-level access to data on the disk. Our work offers the promise to provide practical results that will improve virus detection and response on commodity systems with little overhead.","title":"CT-ISG: Disk-Level Malware Detection and Response","awardID":"0627527","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["483825","325247"],"PO":["529429"]},"119445":{"abstract":"Andreas Terzis<br\/>Thinking Ahead: A Proactive approach for countering future Internet malware<br\/>Johns Hopkins University<br\/>0627611 <br\/><br\/><br\/>Abstract<br\/><br\/>Malware continues to pose one of the gravest threats to the Internet.<br\/>While existing research efforts are producing promising defenses to<br\/>counter today's threats, the landscape is rapidly changing as<br\/>attackers become increasingly savvy. In this project, rather than<br\/>blindly following the current practice in which defenses trail malware<br\/>advances, we apply a first principles approach to Internet<br\/>infection. Specifically, we explore a wide range of networked systems,<br\/>including corporate networks and emerging wireless and mobile<br\/>networks, and examine a list of potentially crippling attack<br\/>strategies against these networks. The attacks we explore are faster,<br\/>stealthier, or more virulent than current infection<br\/>strategies. Moreover, they all share the characteristic of<br\/>overwhelming existing defenses. The goals of this project are to<br\/>develop analytical models that capture the unique behavior of such<br\/>malware, and to use these models to gain a better understanding of<br\/>emerging threats. Armed with this knowledge, we explore novel defenses<br\/>that include camouflaged responders resilient to evasive attacks and<br\/>distributed mobile network monitors capable of tracking mobile<br\/>infections. We fully anticipate that results from this research will<br\/>provide guidelines on how to secure future network architectures<br\/>against emerging threats.","title":"Thinking Ahead: A Proactive Approach for Countering Future Internet Malware","awardID":"0627611","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["530045","565326"],"PO":["529429"]},"124230":{"abstract":"James, Doug<br\/>Carnegie Mellon University<br\/>CCF-0347740<br\/><br\/><br\/>Deformation phenomena are a rich and integral part of our lives; it affects our appearance (e.g., skin, hair), the sounds we make (e.g., clothing, vocal cords), beauty in nature (e.g., a forest blowing in the wind), and important decisions (e.g., medical planning). Deformation modeling has made enormous progress, but we still desire increasingly realistic levels of geometric and dynamic complexity. Deformation also plays an important role in multimodal feedback for virtual environments: feeling contact forces using haptic interfaces, seeing realistic deformable appearances with shadows and interreflections, and hearing contact sounds. Not only are accurate deformations required at high rates, but the phenomena can also be extremely complex.<br\/><br\/>Given the conflicting demands of real-time interactivity and complex large-scale simulation, one logical algorithmic strategy is to do as much work ahead of time as possible. Exploiting massive precomputation and data-driven tabulation is appealing, but how this can be done, and to what extent, remains a mystery for most nonlinear systems. Nevertheless, preliminary evidence suggests that potential precomputation speedups are easily a million-fold. By researching precomputation techniques today, we stand to exploit million-fold speedups for multimodal simulation on supercomputers of tomorrow.<br\/><br\/>Our scientific objective is to understand how to systematically precompute, simulate and experience data-driven models of large-scale nonlinear deformable systems. We address these goals in three ways: (1) precomputation techniques for data-driven deformable models based on reduced coordinate representations; (2) deformable motion databases of complex motions for real-time ``playback;'' (3) multimodal aspects of interactive simulation, including haptic rendering of contact forces, data-driven deformable sound models, and precomputed deformable object appearance models. Our research is driven by real-world applications, and will be explored in the broad context of interactive computer animation, virtual medicine, robotics and manufacturing, and simulation of large-scale natural environments.","title":"CAREER: Precomputing Data-driven Deformable Systems for Multimodal Interactive Simulation","awardID":"0652597","effectiveDate":"2006-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["402591"],"PO":["532791"]},"116223":{"abstract":"Satellite and ground-based remote sensing produces large quantities of heterogeneous and multisource spatial-temporal data. This offers promise for highly accurate retrievals of geophysical parameters on a global scale, but it also opens a number of computational challenges related to the construction of efficient and accurate retrieval algorithms. This project is exploring this opportunity through development of data mining methods to: (a) improve existing single-sensor retrieval algorithms; and (b) allow high-quality joint-sensor retrieval. Aerosol-related data from the TERRA and AQUA satellites and the AERONET network of ground-based sensors is being used for development and validation of the proposed algorithms. The intellectual merit of the proposed work is in: addressing this challenge through the use of complex forward-simulation models; exploring spatial-temporal properties of large, heterogeneous and multi-resolution data; conditional probability modeling and uncertainty estimation; sampling design; use of advanced data structures; and integration and handling of multi-TB data. The broader impacts stem from development of accurate aerosol retrieval methods that will allow improved characterization of the effects of aerosols on the Earth's energy and water cycles. Additionally, the project is providing guidelines for developing accurate and fast retrieval algorithms in other geoscience applications, and will lead to advancements in spatial-temporal data mining. The project is assuring a broad participation of students through incorporating the research results into several courses, exposing diverse groups of students to research, and widely disseminating the results through publications and the project web site (www.ist.temple.edu\/IIS-0612149).","title":"Collaborative Research: Data Mining Support for Retrieval and Analysis of Geophysical Parameters","awardID":"0611892","effectiveDate":"2006-08-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}}],"PIcoPI":["559080"],"PO":["565136"]},"116586":{"abstract":"A critical requirement for any science is the ability to measure. Without measurement, it is difficult to evaluate and improve. Not only is our ability to measure and evaluate software designs today weak, we also lack a thorough understanding of the shortcomings of the strengths and weaknesses of existing software design evaluation methods. To learn more about the shortcomings of current evaluation methods, the PI will in this project study two software products from the systems domain which share the important design criteria of modifiability and performance, the Click modular router and the Jetty http server and servlet container. For each of these two programs, there exist clear design goals and extensive change histories. Using change history data, the PI will create an approximate \"master list\" of modifiability and performance flaws in early versions of each program. For example, a feature request that required changes to many files could be flagged as a modifiability flaw. She will then apply several evaluation methods (e.g., quantitative software metrics, architecture-based evaluation, and semiautomatic methods such as design snippets) to early versions of each subject program, and compare the output of each method to the approximate master list of design flaws. Project outcomes will include establishment of a benchmark and experimental protocol that can be used to critique new techniques or tools for evaluating software designs using change history logs, and an increased understanding of the deficiencies of existing techniques and tools for evaluating software designs.<br\/><br\/>Broader Impacts: Software designs matter because software matters. To improve software designs, we must have adequate tools for evaluating candidate designs. This project will provide insight into new tools and techniques for software design evaluation. Programmers using these new tools and techniques will produce better software designs and thus better software. In addition, the benchmark produced by this experiment will prove valuable to software engineering educators; instructors will be able to design assignments and projects that involve the benchmark, and which will expose students to issues in evaluating software designs and empirical software engineering research.","title":"SoD-HCER: Evaluation of Complex Designs--A Comparative Study","awardID":"0613601","effectiveDate":"2006-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7372","name":"ITR-SCIENCE OF DESIGN"}}],"PIcoPI":["550282","410225"],"PO":["565227"]},"116234":{"abstract":"Bayesian analysis has the power to combine information efficiently from diverse sources, helping to provide confidence bounds on theoretical models and methods for both model selection and hypothesis testing. This project brings state-of-the-art statistical and computational algorithms to bear on a set of data and theory comparison in astronomy. The wok bears on a variety of problems in other sciences, helping to fill the need for optimized data-mining tools. The system can be controlled and operated remotely and collaboratively. The introduction of a persistence system will permit saving of both data and metadata, making it accessible for future use. The statistical approach make the most efficient use of all the available information and permit the testing of hypotheses directly. Bayesian statistical models provide maximum flexibility in incorporating and using all the information, making a virtual observatory test-bed. Multi-disciplinary training opportunities are provided for graduate students and the work disseminated at both meetings, training sessions and for individual users through downloads.","title":"High-performance Computational Bayesian Inference for Astronomy","awardID":"0611948","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0700","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"1217","name":"EXTRAGALACTIC ASTRON & COSMOLO"}}],"PIcoPI":["482443","404568","550864","482442"],"PO":["565136"]},"119754":{"abstract":"In this project the PI, who is an attorney whose principle legal focus is computer-related law and also a widely known author on software quality control, will develop learning units that focus on topics of such active public interest that there is ongoing, rapid change in the laws that provide context for discussions of the associated professional ethics issues. Examples include whistle-blowing; reverse engineering; investigation of security vulnerabilities in running systems; and conflicts of interest and intellectual property rights associated with university laboratories and faculty-owned businesses that commercialize university-developed research. While all of the topics to be covered in these learning units are important for software engineering, a number of them are also significant for other engineering areas. Each topic can be studied in terms of ethics issues that the student might face while conducting research as a student, or later as a faculty member (supervising research students) or engineer (working in industry). Materials will be developed in a modular manner, so that they can be easily customized for other areas later on as needed. Each learning unit will provide: video lectures and slides; background briefing papers, including a literature review that explains the engineering and engineering ethics issues to the law-specialist reader and another review that explains the legal issues to the engineering reader; study guide questions; grading suggestions in a restricted-access website for instructors; suggestions for in-class activities; and guidance for the student who will search the legal and engineering literature to gain the most current information on the issues covered in this learning unit. This multimedia blended approach to learning, wherein students watch video-based lectures before coming to class and class time is spent on instructor-guided activities that have obvious relevance or application, is already in use at Florida Tech; it has the advantage of being suitable both for classroom instruction and web-based instruction. Initial feedback has been provided by a coalition of universities, corporations and independent trainers; whose ongoing input will guide the current project. Members of the PI's team for this project include an expert in computer security (especially the study of mobile malicious code), an expert in reverse engineering and program comprehension, and two experts on assessment.<br\/><br\/>Broader Impacts: The learning units developed in this project will be published electronically at the project website and made available to the public under a Creative Commons license that allows free distribution and customization. They will also be submitted to peer-reviewed course collection sites such as MERLOT.org and well-indexed academic journals, and publicized via conferences and mailing lists. Based on past experience the PI is confident that as the project provides materials of value and builds credibility, external instructors and subject matter experts will adopt and use the materials, and provide additional detailed feedback that can be used to refine and improve their content. Collaboration with external colleagues in a focused manner relating to specific individual learning units will be an inherent part of this work.","title":"Learning Units on Law and Ethics in Software Engineering","awardID":"0629454","effectiveDate":"2006-08-01","expirationDate":"2012-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7496","name":"COLLABORATIVE SYSTEMS"}}],"PIcoPI":["340480",317665],"PO":["565227"]},"116289":{"abstract":"This project is addressing a systemic problem in scientific research: although datasets collected through scientific protocols may be properly stored, the protocol itself is often only recorded on paper or stored electronically as the script developed to implement the protocol. Once the scientist who has implemented the protocol leaves the laboratory, this record may be lost. Collected datasets become meaningless without a description of the process used to produce them; furthermore, the experiment designed to produce the data is not reproducible. <br\/><br\/>This research is developing a database (ProtocolDB) to manage scientific protocols and the collected datasets obtained from their execution. The approach will allow scientists to query, compare and revise protocols, and express queries across protocols and data. The research is also addressing the issue of recording and querying the provenance (the why and where) of data. ProtocolDB will benefit scientists by providing a scientific portfolio for the laboratory which not only enables querying and reasoning about protocols, executions of protocols and collected datasets, but enables data sharing and collaborations between teams. <br\/><br\/>The intellectual merit of the research includes the design of a model for scientific workflows, and a query language to retrieve, transform, compare scientific workflows, integrate datasets, and reason about data provenance. This theoretical contribution will establish advances in the development of systems supporting the expression of scientific protocols. The ProtocolDB implementation will be evaluated by our scientific partners. The broader impact resulting from the project is the development of a general-purpose system for managing scientific protocols and their collected datasets. The established collaborations, involving academic, governmental, and private institutions, will contribute significantly to the breadth of its use.","title":"Collaborative Research: SEI+II ProtocolDB: Archiving and Querying Scientific Protocols, Data and Provenance","awardID":"0612177","effectiveDate":"2006-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}}],"PIcoPI":["541878"],"PO":["565136"]},"118258":{"abstract":"The performance of many high-end computing applications is limited by the capacity of memory systems to deliver data. As processor speeds increase, I\/O performance continues to lag substantially. Thus, I\/O is likely to remain a critical bottleneck for high-end computing. <br\/><br\/>In this research project The PIs propose to build a prototype of a streaming B-tree for deployment in a database or file system. This prototype will realize t fast insertions, fast range queries, and platform independence. The PIs will simultaneously work on how to deal with different-sized keys, how to support transactions, how to scale to multiple disks and processes, and how to provide O\/S support for cache-obliviousness and memory-mapped massive data. The proposed work represents a promising new direction in how to manipulate massive data and overcome classic I\/O bottlenecks.","title":"HEC: Collaborative Research: Techniques for Streaming File Systems and Databases","awardID":"0621425","effectiveDate":"2006-08-01","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7583","name":"ITR-HECURA"}}],"PIcoPI":["531670"],"PO":["565272"]},"122240":{"abstract":"SGER: The Robotic Vision Semantic Challenge<br\/><br\/>The web contains vast collections of unstructured image databases that could be exploited to generated useful models for image recognition. Search engines currently only use keywords found in image filenames rather than the image data itself. However, the thousands of images retrieved in such a search could be used to <br\/>generate models for recognizing specific objects. The goal of this research project is to develop the infrastructure for a new research competition designed to push the state of the art in image understanding and automatic acquisition of knowledge from large unstructured databases of images, such as those generally found <br\/>on the web. This competition will be held at the AAAI (American Association for Artificial Intelligence) Mobile Robot Competition and Exhibition which has been co-located with the AAAI conference for the past ten years. By providing the necessary infrastructure for organizing and managing such a competition, there is a strong chance to attract the best and the brightest in the computer vision, robotics and AI research fields to push the envelope of the state of the art in image and video understanding technologies. Competitions such as these provide a standardized testbed on which researchers can compare the results of their research. At the end of the competition, the PIs will hold a workshop so that the specific technical aspects of each entry can be presented and discussed. In addition, the competitors will have to share their code under an open source license, so that newcomers of 2008 will stand on the shoulders of the winning teams of 2007.<br\/><br\/>Project URL: http:\/\/www.cs.cmu.edu\/prybski\/AAAI RVSC","title":"SGER: The Robotic Vision Semantic Challenge","awardID":"0642732","effectiveDate":"2006-08-15","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7339","name":"COMPUTER VISION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["402502","513331"],"PO":["403839"]},"116300":{"abstract":"A complete understanding of any biological system or disease necessitates a detailed analysis of how its proteins interact with other molecules. Most methods for predicting and understanding protein function have focused on determining evolutionary relationships in amino acid sequences. However, the molecular function of a protein is determined also by its 3D structure (i.e., how atoms interact within its active sites), and thus a great deal of attention has recently been devoted towards solving the 3D structures of proteins with the hope that computer algorithms can infer functional relationships between them. 3D atomic coordinates are available for tens of thousands of proteins and the number has been increasing exponentially over the last several years. The goal of this project is to develop novel computer algorithms for analyzing protein structures, detecting similarities between them, visualizing how they interact with other molecules, and automatically providing functional classifications for them. For example, given a novel protein structure, new geometric algorithms will be used to determine the locations and shapes of its active sites. Next, the model of the structural and chemical properties of those sites will be used to search large databases for sites with similarities. Finally, the best matches are aligned so that functional annotations can be transferred from the active site of one protein to another. These algorithms will not only be useful for molecular biology, but they will drive research on a broader class of computation methods for detecting features in noisy 3D data, matching shapes of complex 3D structures, and searching large repositories of 3D data. Beyond the research, the project will have impact through its interdisciplinary collaborations, educational and outreach programs, and public dissemination of information. The project is a collaborative effort across diverse disciplines, aiding the project to promote cross-pollination of ideas between fields, and provide new educational opportunities for students to learn in an inter-disciplinary environment. Everything developed as part of this proposal will be made freely available to the public through talks, workshops, web pages, course notes, software libraries, bibliographies, and data sets.","title":"SEI: New Shape Analysis Methods for Structural Bioinformatics","awardID":"0612231","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["553259","533355"],"PO":["565136"]},"117884":{"abstract":"Review Analysis: Major Research Instrumentation (MRI) Program FY06<br\/><br\/>Proposal #: CNS 06-19843<br\/>PI(s): Kosar, Tevfik<br\/> Allen, Gabrielle D.; Seidel, Edward; Twilley, Robert R.; Wischusen, E. William<br\/>Institution: Louisiana State University<br\/> Baton Rouge, LA 70803-2701<br\/>Title: MRI\/Dev: Dev. of PetaShare: A Distributed Data Archival, Analysis and Visualization System for<br\/> Data Intensive Collaborative Research<br\/>Ratings: E, V, V, V Panel Ranking: Competitive (C) Result: Recommend<br\/>Amount Req: $ 957,678 Amount Rec: $ 957,678<br\/><br\/>Project Proposed:<br\/><br\/>This project, developing a distributed data archival, analysis, and visualization instrument (called PetaShare) for data intensive collaborative research, enables transparent handling of underlying data sharing, archival, and retrieval mechanisms and makes data available to the scientist for analysis and visualization on demand. Designed to scale to the petabyte level, the instrument responds to an urgent need of scientists working with large data generation, sharing, and collaboration requirements. Involving five universities in the state (LSU, LaTech, Tulane, ULL, and UNO), the infrastructure consists of three layers of storage distributed at multiple sites:<br\/>Primary very high speed RAM storage for data visualization;<br\/>Secondary disk storage for data analysis and processing; and<br\/>Tertiary tape storage for data archival and long term studies.<br\/>Unlike existing approaches, PetaShare treats data resources and the tasks related to data access as first class entities just like computational resources and compute tasks, and not simply the side effect of computation. Expected key technologies include data-aware storage systems and data-aware schedulers, which take the responsibility of managing data resources and scheduling data tasks from the user, performing these tasks transparently. The instrument supports many important data intensive applications from different fields, including coastal and environmental modeling, geospatial analysis, bioinformatics, medical imaging, fluid dynamics, petroleum engineering, numerical relativity, and high energy physics. <br\/><br\/>Broader Impact: The system complements the high-performance computing resources at the five interconnected campuses in this EPSCoR state, boosting interdisciplinary research among them. In addition to directly servicing and promoting research, PetaShare contributes in the training of hundreds of students. The system exhibits a high potential of increasing the accuracy and efficiency of storm surge models and hurricane tracking predictions, thereby enabling rapid and effective disaster responses that could affect millions of people in the world.","title":"MRI: Development of PetaShare: A Distributed Data Archival, Analysis and Visualization System for Data Intensive Collaborative Research","awardID":"0619843","effectiveDate":"2006-08-15","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1629","name":"BE: NON-ANNOUNCEMENT RESEARCH"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["565247","558513","464022","352149","345581","496127"],"PO":["557609"]},"116795":{"abstract":"Data stored on computers is the most precious, irreplaceable component.<br\/>File systems and databases are the two most common ways to provide regulated access to the data. Databases provide transactions, which allow arbitrary sequences of operations to be applied atomically; but databases use a wide variety of incompatible APIs. File systems, however, provide a standard POSIX API to data, but are less reliable because they do not provide facilities to apply a sequence of operations atomically.<br\/><br\/>This project integrates full database (ACID) properties into commodity<br\/>operating systems, while offering user-level applications a POSIX-compliant API with transactions support. We are porting the Berkeley Database (BDB) to commodity kernels---a highly portable, efficient, and versatile embeddable database. Aside from integrated kernel support, we are also developing two file systems with ACID semantics.<br\/><br\/>We are developing several highly practical applications: a Provenance-Aware Storage System (PASS) that tracks the origin and history of file ownership; a transaction-aware wrapper shared library that provides transaction capabilities to unmodified legacy applications; and a mail-delivery server that atomically updates mailboxes, access control lists, and more.<br\/><br\/>The end goal of this project is to develop and evaluate a new operating<br\/>system architecture that offers transactions all the way to user<br\/>applications, even unmodified applications; the resulting increase in<br\/>application reliability and security will help society's ever-growing use of software. This will allow developers to write safer software more rapidly. The long term impact will be that society as a whole will benefit from more reliable, secure, and robust software.","title":"CSR---PDOS: Support for Atomic Sequences of File System Operations","awardID":"0614784","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["541948","543574"],"PO":["493916"]},"124198":{"abstract":"Abstract<br\/><br\/>Program: NSF 04-588 CISE Computing Research Infrastructure<br\/>Title: CRI: Collaborative Research: Reconfigurable Computing Cluster <br\/><br\/>Lead Proposal: CNS 0551688 <br\/>PI: Sass, Ronald<br\/>Institution: University of Kansas Center for Research Inc<br\/><br\/>Collaborative Proposal: CNS 0551678<br\/>PI: Chatha, Karamvir<br\/>Institution : Arizona State University<br\/> <br\/>Researchers at the University of Kansas, Arizona State University and Clemson University will acquire a 64-node experimental Reconfigurable Computing Cluster to support on-going research projects investigating High-Performance Computing. They will use off-the-shelf components including field programmable gate arrays (FPGA's) and an inexpensive custom network adapter to enable new research that is a natural out-growth of established research programs. The experimental cluster will enable the researchers to conduct their research projects and to evaluate two novel aspects of the proposed architecture: (a) using the FPGAs as the primary processor on the node, and (b) integrating the network switching components into the configurable resources of the FPGA. If successful, this approach could lead to significant advances in high performance computing. Projects supported will include: network scalability to assess how the number of nodes and distance between nodes affects performance; assessing use of these FPGA based clusters for common applications such as computation fluid dynamics; and use of these models for RC-BLAST, an important bio-informatics application. The investigators will develop undergraduate research projects using these resources.","title":"CRI: Collaborative Research: Reconfigurable Computing Cluster","awardID":"0652468","effectiveDate":"2006-08-02","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["329570"],"PO":["550859"]},"119414":{"abstract":"The project will advance the state of the art in network forensics. For the first time, methods will be available to interactively investigate large datasets and then later detect similar scenarios when they recur. This is critical for large organizations so that they can respond quickly and correctly to cyber attacks. Because the methods are built upon a graph framework, analysts can easily interact with automated results to refine the investigation or rule out incorrect results from the system. Also, the methods developed can be refined by training on labeled data to improve the accuracy of automated investigation system.<br\/><br\/>This project uses models from physics and spectral graph theory to extract attack scenarios from data collected in computer networks. The primary goals of the project are to provide the first mathematically well founded and tunable methods to extract and recognize attack scenarios in huge databases of network alerts, network flows, and expert knowledge. Secondarily, the methods are well suited to being transitioned to high performance computing technology and collaborative computing methods using established methods from the computational sciences. These methods derive from flow models in heat transfer and eigen analysis of graphs to extract meaningful features.","title":"CT-ER: Physical Diffusion and Spectral Models for Network Forensic Investigation","awardID":"0627409","effectiveDate":"2006-08-15","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["441080"],"PO":["529429"]},"121691":{"abstract":"Improvements in the speed of 3D graphics rendering hardware have been accompanied by even more drastic increases in the size of displayed models. Full-system CAD, 3D model scanners, procedurally generated models, and visualization data sets are now approaching hundreds of millions or even billions of polygons in size. Researchers trying to display these models have been forced either to reduce display speed and interactivity, or instead to reduce the fidelity of the displayed views of their models. What are the best methods for preserving visual fidelity as model complexity is automatically reduced or \"simplified\"? What is the most effective way of striking the display speed vs. visual fidelity compromise? And in the increasingly important graphics application of visualization, how can we preserve the meaningful elements of the displayed data, and make users effective managers of information complexity? This research will take its three complementary directions from the three above questions. The PI will develop prototype systems and investigate their effectiveness with user studies. Many of these studies will take place in the context of driving applications developed for existing collaborations with colleagues in academia and the gaming industry. Specific goals will include the development and evaluation of automatic methods for measuring fidelity; an examination of the hypothesis that fidelity control should minimize visual error, whether it is introduced by compromises in visual fidelity or display speed; and for abstract information visualization, study of fidelity measures and summarization techniques not necessarily inspired by knowledge of perception in the natural world. While many technical solutions have addressed the issues of measuring similarity and summarizing complex data, only a few of them have been evaluated in rigorous usability studies. This research will fill this gap, producing knowledge, guidelines, heuristics and software that will improve the usability of interactive 3D graphics applications.","title":"CAREER: Managing Complexity: Fidelity Control for Optimal Usability in 3D Graphics Systems","awardID":"0639426","effectiveDate":"2006-08-01","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}}],"PIcoPI":["326088"],"PO":["565227"]},"119029":{"abstract":"Physically Aware Agile Networking<br\/>PI: Brendan Mumey<br\/><br\/>This research project considers agile constraint-based routing and wavelength assignment (RWA) strategies to mitigate physical layer impairments that affect the end-to-end performance of next generation all-optical networks. The RWA methods being developed take into account changing traffic patterns, resource availability, and the behavior of the underlying physical layer under transient conditions to minimize impairments and assure that Quality of Service (QoS) requirements are achieved. Physical layer network impairments that affect end-to-end path performance include switching transients, amplifier gain fluctuations, and channel cross talk. Temporal and geographic variations in network traffic can also affect network performance. A general framework for studying the cumulative effects of such impairments and traffic variations is being designed and conducted using the Montana State University optical network testbed. This work requires a combination of modeling, simulation and validation steps. Based on this new framework, state-of-the-art physically aware RWA algorithms are being designed, implemented and tested.<br\/><br\/>Broader Impact:<br\/><br\/>The outcomes of this research will become an important component for future cyber infrastructure by exploring methods to manage the underlying network that are consistent with the new application-driven network demands. This project will integrate teaching and research activities in electrical and computer engineering with computer science, bringing together faculty and students from both disciplines to address system-level design issues spanning both disciplines. The project team will engage undergraduate students in the research through interdisciplinary senior design courses and individual research projects. Outreach to minorities will be facilitated through the well-established programs at MSU that engage Native Americans in the sciences and engineering.","title":"NeTS-NBD: Physically Aware Agile Networking","awardID":"0624874","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["505393","443099"],"PO":["565090"]},"116840":{"abstract":"Large scale parallel systems are critical to take on the challenges <br\/>imposed by highly demanding applications of critical importance. Pushing the <br\/>limits of hardware and software technologies to extract the maximum <br\/>performance can increase their susceptibility to failures. This arises as a <br\/>consequence of growing hardware transient errors, hardware device failures, <br\/>and software complexity. These failures can have substantial consequences <br\/>on system performance, and add to the costs of maintenance\/operation, <br\/>thereby putting at risk the very motivation behind deploying these large <br\/>scale systems. Rather than treat failures as an exception and take<br\/>reactive remedies, this project intends to anticipate their occurrence <br\/>and take pro-active runtime measures to hide their impact.<br\/><br\/>This research is expected to make three broad contributions towards<br\/>developing a runtime fault-tolerance infrastructure.<br\/>The first set of contributions is on collecting and analyzing<br\/>system events from an actual BlueGene\/L system over an<br\/>extended period of time. The second set of contributions are models for<br\/>online analysis and prediction of evolving failure data.<br\/>The third set of contributions are on failure-aware parallel job <br\/>scheduling and checkpointing. On the educational front, in addition to <br\/>enhancing graduate curriculum and research, this project intends to involve <br\/>undergraduate students and women. The tools developed in this project and the <br\/>related results will be made available in public domain and published in <br\/>leading journals\/conferences. In addition, the PIs will also push these <br\/>tools to be incorporated on actual systems, to enhance their fault-tolerance<br\/>abilities.","title":"Collaborative Research: CSR-SMA+AES: Pro-Active Runtime Health Enhancement of Large-Scale Parallel Systems Using PROGNOSIS","awardID":"0614976","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["564747"],"PO":["535244"]},"116851":{"abstract":"The objective of this project is to develop a theoretic framework and a hierarchical methodology for autonomic power and performance management of distributed computing centers through (a) online modeling, monitoring, and analysis of power consumption and performance; (b) adaptive learning and automatically identifying strategies to minimize power consumptions while maintaining the required quality of service requirements for a wide range of workloads and applications; and (c) dynamically reconfigure the computing, storage and network resources according to the selected optimization strategies. The proposed methodology exploits the emerging hardware and software standards to improve power efficiency of processors and devices such as such as Intel's quickstart and SpeedStep processors, disk spindown, power aware page allocation and RDRAM that offer a wider range of low-power states and reducing the cost of transitions. <br\/><br\/>The impact of this project is in the significant reduction of power consumptions of Internet services and Web servers that account for 8% of the US electricity consumption. In addition, the project results have a profound impact on the environment because by reducing the demand for energy, the amount of CO2 produced each year by electricity generators is reduced significantly.","title":"Collaborative Research: CSR: Autonomic Power and Performance Management in Distributed Computing Systems","awardID":"0615047","effectiveDate":"2006-08-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["559680"],"PO":["551712"]},"116873":{"abstract":"A wide variety of systems, including web farms, virtual machines,<br\/>multi-tasking OSes, GRID computing systems, and sensor networks<br\/>improve their accessibility, availability, resilience and fairness by<br\/>``sharing'' resources across the consumers they support. However,<br\/>research that explores how to share resources generally derives point<br\/>solutions, where different resource\/consumer configurations require<br\/>separately-designed sharing mechanisms. For instance, a scheduler<br\/>often has implemented separately a single policy<br\/>(e.g., FCFS, PS, Foreground Background, Shortest Remaining Processor<br\/>Time), optimized for a particular load setting<br\/>and cannot easily be switched to another policy when the situation changes.<br\/><br\/>This project is developing and analyzing Adaptive Sharing<br\/>Mechanisms (ASMs) in which the mechanism used to share resources<br\/>adapts dynamically to both the set of available resources and the<br\/>current needs of the consumers, such that the system is truly<br\/>autonomic. The study has been initiated with a modularization of the ASM<br\/>into separate components, defined by the timescale of operation. A<br\/>study of the various components using both cutting edge novel control<br\/>theoretic and scheduling analyses is being performed.<br\/>The design and analysis of ASMs will provide a theoretical<br\/>grounding for fully autonomic systems, and the project will lead to<br\/>efficient utilization of resources in diverse systems like server<br\/>farms, GRID computing and Sensor Networks.","title":"SMA\/PDOS Collaborative Research: Design, Analysis, and Control of Adaptive Sharing Mechanisms","awardID":"0615126","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["451494","493395","497480","522280"],"PO":["535244"]},"116895":{"abstract":"Developers often extend large, C-based software systems, including<br\/>operating systems, databases, and web servers, in an ad-hoc manner to<br\/>meet their performance and functionality requirements. Many of the<br\/>extensions represent crosscutting concerns in that they do not fit<br\/>within a single program module and are scattered throughout the<br\/>source. Maintaining and applying such extensions with commonly used<br\/>tools, notably diff and patch, is time consuming and error prone.<br\/>Furthermore, it is challenging to ensure correctness when composing<br\/>multiple extensions. This work makes crosscutting concerns part of<br\/>the architecture of C-based systems by leveraging aspect-oriented<br\/>software development techniques. Specifically, extensions are<br\/>captured as aspects, which provide a language-supported methodology<br\/>for expressing crosscutting concerns. The work also builds a new set<br\/>of tools that extract, inject, and translate system extensions<br\/>represented as aspects. Moreover, the work develops static program<br\/>analysis technology that aids in the semantic separation of extension<br\/>from mainline code and safe composition of extensions. To validate<br\/>the tools' effectiveness, the PIs conduct case studies on the Linux<br\/>kernel and open source extensions such as the Nooks system that<br\/>provides device driver isolation and recovery. For the educational<br\/>community, the work offers an attractive approach to hands-on learning<br\/>about real-world systems. For the system software community, the work<br\/>offers the ability to more rapidly and seamlessly move from idea to<br\/>design to implementation for new system-level extensions. Finally,<br\/>for the broader community of commercial developers and their<br\/>customers, the work offers a path to more flexible reuse of system<br\/>software.","title":"Collaborative Research: CSR-PDOS: Managing OS Extensibilty via Aspect-oriented Programming Technology","awardID":"0615213","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["483683",309314],"PO":["493916"]},"116301":{"abstract":"The ultimate goal of this research is to integrate visual and computational descriptions of complex metabolic and regulatory networks to aid biologists in evaluating hypotheses for how these dynamic networks function under different conditions. These networks will combine graph models from pathway databases, text-mining programs, machine learning systems, and other sources, together with multiple classes of experimental data. The unique features of the proposed graph visualization and analysis platform are: 1) Evaluation of the structural effects of dynamic links that change depending on time and other conditions. 2) The ability to immediately integrate current research hypotheses with available published results to evaluate their impact and explanatory power. 3) Interactive display of large metabolic and regulatory networks in either user- or automatically selected levels of detail. 4) Creation of visual graph display tools specifically designed for improved biological network display, comparison, and analysis. As part of this process, significant problems in the analysis of variable graph structures, incremental graph layout, and effective visualization and labeling will be addressed with an interdisciplinary focus. The software will be open source and freely available to academic institutions. It will be evaluated and validated using three interrelated but only partially understood signal transduction networks: ethylene, jasmonate and salicylic acid. These pathways interact complexly to direct specific plant defense responses to stress. The software will contribute to the research community's open source software toolbox by providing more effective ways to visualize and manipulate graphs. By actively integrating biologists in the design and development we will ensure practical applicability and usability for non-computer-expert users. Education and outreach activities will promote research, K-12 and undergraduate education, and dissemination of results to a broad audience, while developing a new generation of scientists that employ the powers of computers to their fullest to advance all sciences.","title":"(SEI+II (BIO)) Interactive Visualization and Analysis of Large-Scale Graphs for Biological Network Modeling","awardID":"0612240","effectiveDate":"2006-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}}],"PIcoPI":["431463","431463","496031",307837],"PO":["565136"]},"124199":{"abstract":"Sass - Abstract<br\/><br\/>Advantages in Information Technology continue to play a vital role in our nation's ability to innovate and compete in theglobal market. Advancements in computing performance, especially in the embedded computing systems domain, are enabling these advantages. This project combines commercially available, hybrid devices (that is, single integrated circuits with processors, memory, and configurable hardware) and a novel run-time system with the goal of building systems with better performance and fewer resources. To accomplish this, the project is investigating and developing technology in two steps. First, every subroutine in the embedded systems application is processed to find those suitable for acceleration by configurable hardware and a new hardware feature is synthesized. Then, as the application executes, the run-time system continually reconfigures the hardware to keep the most profitable features resident. By carefully managing the overhead introduced, the aim of this work is to provide the performance advantages of custom hardware with fewer physical resources. The advantage of the particular system under investigation is that it automates reconfiguration -- which presently is an engineering-intensive, manual process. To test the effectiveness of this approach, the University of Kansas has teamed with Grand Valley State University to judge the performance of the system on applications developed by senior undergraduate students.","title":"EHS: Dynamic Hardware Reconfiguration to Accelerate Java-Based Embedded Systems","awardID":"0652471","effectiveDate":"2006-08-02","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":[329570],"PO":["561889"]},"117677":{"abstract":"This project, facilitating the development and execution of complex software applications (such as the seamless, fault-tolerant integration of wired and wireless health care networks), proposes the development of an Arkansas Intelligent Coordinating Entities Emulab at the University of Arkansas at Little Rock. The emergence of new large-scale application domains combined with new distributed computing scenarios such as ad-hoc, mobile, peer-to-peer, and pervasive computing techniques motivate the need for novel approaches to support complex software applications. In critical situations, embedded hardware and software elements in the applications are resource-constrained and power limited devices. Effective coordination of these distributed elements is often contextual, and often strictly related to the environment in which they reside. However, dynamically changing group structures and environments require a configurable, flexible, scalable, and easy to use computing environment that supports composition and dynamics of free-ranging aggregates. The lab permits quick set-up of experiments that scale with minimal effort and are repeatable under different parameters. Emulab offers the flexibility to change parameters and network scenarios, allowing repeatability. Supporting research activities that include health-related projects, the infrastructure enables common net-centric research training and industrial collaboration. The project addresses the following problems: <br\/><br\/>-Intelligent Communication and Coordination of Sensor Networks; <br\/>-Implantable Antennas, <br\/>-Advanced Bio-Electromagnetic Modeling and Simulations and Telecommunications Applied to Wireless E-Health Technologies; <br\/>-Ultra Low Power UHF Wireless Subdural Electroencephalogram Electrode; <br\/>-Modeling and Simulation of Access Point Coverage and Capacity; <br\/>-Real Time Data Compression Applied to Advanced Electromagnetic Modeling and Telecommunications; <br\/>-Developing Dynamic Distributed Applications Using Adaptive Middleware Disaster Engineering","title":"Development of an Interdisciplinary Arkansas Emulation Laboratory","awardID":"0619069","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["411431",311376,"557523","348553","474701"],"PO":["557609"]},"117457":{"abstract":"Abstract<br\/>0618163<br\/>PI: Chung-Kuan Cheng<br\/>CSE Dept., UC, San Diego<br\/><br\/>Title: Hybrid Clock Networks Using Distortionless Transmission Lines<br\/><br\/>With the advance of the VLSI technology, the variation of interconnect delay is becoming critical since interconnect delay plays a dominant role in system performance. Process, voltage, and temperature variations can have significant effects on interconnect delay. Therefore, the robustness of interconnect design is important. This is especially crucial for clock distributions because the delay variations contribute to clock jitters and skews.<br\/>In a recent invention, Cheng's group devised a distortionless transmission line which achieves the speed of light at an 85% or greater reduction in power consumption over traditional wires. The proposed project explores the utilization of the distortionless transmission line integrated with the interconnect topologies, circuit styles, and electromagnetic wave techniques into a hybrid network. The exploration can lead to the design of the speed of light, extremely low power, and low jitter clock distributions. The SGER is the best means for this exploratory and high return project because of the availability of the funding in a timely manner.","title":"Hybrid Clock Networks using Distortionless Transmission Lines","awardID":"0618163","effectiveDate":"2006-08-15","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["451456"],"PO":["562984"]},"121120":{"abstract":"Intellectual merit: The proposed research program will integrate concepts from both computer graphics and photography, drawing on the extensive experience of the PI in both endeavors. The underlying notion is the application of computer graphics techniques to photography to solve fundamental shortcomings in the photographic process. This involves extending our thinking for algorithm development beyond what is physically realizable.<br\/>Methods: For a group photograph that has non-uniform illumination, we will develop brightness<br\/>compensation techniques to modify an exposed portrait such that every face would have approximately the same brightness. Our approach will extract underexposed facial regions with their average brightness values and locations, and then compensate for their underexposure by adding brightness according to the classification of the layout of the subjects. The proposed method will involve a sequence of image processing steps: extracting skin-colored objects and facial regions, extracting and determining a layout classification, and adding brightness using average brightness and spatial variation.<br\/>To achieve generalized control over focus in photography, we propose to develop algorithms that will combine and process photographs. One approach will involve first taking many pictures, each with different focus settings, and then combining these images to produce a composite in which only the desired region is in focus. It will be possible to quickly take many different pictures with precisely calibrated focus settings using a digital camera under the control of our software. In the case of a moving scene that would appear different in different exposures if multiple exposures were taken, we propose a different approach that synthetically adds blur as a postprocess, to closely approximate the desired effect.<br\/>Impact: The results of this research could have applications in various aspects of digital photography, both for cameras and software, and will impact the nascent and currently inchoate field of computational photography. Our algorithms will initially be prototyped as software on a computer as a postprocess, but eventually we hope to see them integrated into the firmware of digital cameras.","title":"SGER: Computational Photography: Lighting and Focus","awardID":"0636661","effectiveDate":"2006-08-01","expirationDate":"2007-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["518667"],"PO":["532791"]},"116940":{"abstract":"CSR-AES: Intelligent Optimization of Parallel and Distributed Applications<br\/><br\/>ABSTRACT<br\/>This project derives a systematic solution for performance optimization and adaptive application mapping to obtain scalable performance on parallel and distributed systems consisting of tens of thousands of processing nodes. With expert domain scientists in molecular dynamics (MD) simulation, we expect to achieve performance levels on MD codes even better than what has been derived manually after years of development and many ports to a variety of architectures.<br\/>The application components are viewed as dynamically adaptive algorithms for which there exist a set of variants and parameters that can be searched to develop an optimized implementation. A workflow is an instance of the application where nodes represent application components and dependences between the nodes represent execution ordering constraints. By encoding an application in this way, we capture a large set of possible application mappings with a very compact representation. The system layers explore the large space of possible implementations to derive the most appropriate solution. Because the space of mappings is prohibitively large, the system captures and utilizes domain knowledge from the domain scientists and designers of the compiler, run-time and performance models to prune most of the possible implementations. Knowledge representation and machine learning utilize this domain knowledge and past experience to navigate the search space efficiently.<br\/>This multidisciplinary approach impacts the state-of-the-art in the sub-fields of compilers, run-time systems, machine learning, knowledge representation, and accelerates advances in MD simulation with far more productive software development and porting. More broadly, this research enables systematic performance optimization in other sciences.","title":"CSR---AES: Collaborative Research: Intelligent Optimization of Parallel and Distributed Applications (WP2)","awardID":"0615412","effectiveDate":"2006-08-15","expirationDate":"2010-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["490009","542054","517887","535329"],"PO":["493916"]},"116841":{"abstract":"The goal of this project is to implement and leverage a system that can<br\/>browse the past execution of a computer. \"Browsing\" refers to the ability<br\/>for a user to search, analyze, summarize, restore, or replay arbitrary data<br\/>or events that existed or occurred sometime in the past on that user's<br\/>computer. These capabilities depend on two foundational techniques.<br\/>Virtual-machine introspection allows the system to understand the execution<br\/>of a virtual machine as it executes or replays, without perturbing that<br\/>execution or replay. Virtual-machine replay allows the system to re-execute<br\/>a past time interval of the virtual machine instruction-by-instruction, yet<br\/>at only a few percentage overhead in time and space.<br\/><br\/>The ability to browse the past execution of one's computer can benefit<br\/>society by providing new capabilities to administrators, users, and<br\/>programmers. Administrators can use this ability to secure computers more<br\/>effectively by detecting past intrusions, which may help shrink the ranks<br\/>of \"bot armies\" controlled by criminals and spammers. Elderly people with<br\/>memory loss can use this ability to recall the events that occurred on<br\/>their computers, such as e-mail exchanges and GUI interactions. Programmers<br\/>can use this ability to fix difficult non-deterministic bugs and thereby<br\/>improve the overall robustness of the software on which society has come to<br\/>depend.","title":"CSR---PDOS: Browsing the Past Through Virtual-Machine Introspection and Replay","awardID":"0614985","effectiveDate":"2006-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["556912"],"PO":["535244"]},"116863":{"abstract":"CSR-PDOS-Collaborative: Virtual Machines Meet Application Clusters: A<br\/>Highly Responsive Global Utility Computing Platform for Internet<br\/>Applications<br\/><br\/>Abstract:<br\/><br\/>With the omni-presence of Internet applications, service-oriented computing<br\/>increasingly plays a dominant part in global computing. Thus,<br\/>understanding how to build efficient platforms for service-oriented<br\/>computing is critical in supporting continued Internet proliferation. The<br\/>overriding goal of this research is to gain such understanding, and in<br\/>particular to investigate basic principles in building a global Utility<br\/>Computing for Internet Applications (UCIA) platform that is highly<br\/>responsive in resource reallocation, provides resource isolation to<br\/>different applications, and supports heterogeneous execution environments.<br\/><br\/>This research encompasses a number of specific directions. This includes<br\/>studying tradeoffs between different architectures for resource sharing in<br\/>a global UCIA platform and investigating efficient algorithmic approaches<br\/>to request distribution and application placement that account for the<br\/>computational cost of executing the algorithms and the interaction of these<br\/>two policies. It focuses in particular on the interaction between two<br\/>foundational technologies in global UCIA, wide-area application clustering<br\/>and virtual machines. By leveraging these technologies in a novel way,<br\/>this research promises a significant speed-up in resource redistribution<br\/>among applications. To quantify its findings, this project utilizes a<br\/>wide-area testbed running a sample of off-the shelf Internet applications<br\/>and emulating several data centers.<br\/><br\/>Internet applications are transforming the Web from an information system<br\/>into a global service-oriented computing platform. By improving our<br\/>ability to build highly responsive, global utility computing platforms for<br\/>Internet applications, this research will support continued progress in<br\/>this important direction.","title":"CSR-PDOS-Collaborative: Virtual Machines Meet Application Clusters: A Highly Responsive Global Utility Computing Platform for Internet Applications","awardID":"0615079","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["435447"],"PO":["493916"]},"116632":{"abstract":"This research addresses one of the most critical problems emerging in the interface design community - access by individual designers, and groups of designers, to computational tools that facilitate rather than inhibit the process of creative thinking in the early stages of design. The early stages of design are when interactive systems designers are first thinking about the concept, content and layout, and desired interactive behavior of a design solution. These stages are critical, as studies show that's when 70% of a final design solution is determined. As designers are increasingly pressured to produce effective solutions in less time, they are turning to the use of computer tools in these early design stages, but most computer tools were never developed to support creative thinking and could thus have the opposite effect. As the interface often accounts for over 50% of the overall development effort, software intensive projects cannot afford to correct creative lapses in the early stages later on in the design cycle. Design and creativity theory explain that the creative process can best be facilitated by support for a combination of sketching, alternative representations, working with multiple ideas in parallel, and collaboration. With this in mind, the PI will first develop a visual sketching language (VSL) that allows designers to sketch representations of content and behavior within an informal design tool, This tool will be embedded within a runtime system that allows the sketched designs to be executed, thereby producing functional prototypes through which designs can be better evaluated. To design the VSL, the PI will collect conduct field studies of designers building prototypes using low-fidelity tools and will analyze their problem solving strategies to elicit their conceptual models. The PI will also develop a groupware extension to the informal tool, that allows small design teams (consisting of 2-5 users) to work efficiently with multiple ideas in parallel and to collaborate effectively. The approach is to have each team member run the PI's informal tool on his or her personal device, all of which are networked to a single machine driving a large display that offers a shared visual workspace. An interactive iconic map will show thumbnail representations of designs on the local interface. Once connected, functionality will be available that allows each design to be separately configured as private (only accessible locally); public (viewable but not editable by others); and shared (viewable and editable by others). Group creativity will be facilitated by allowing individual designers to view different ideas (those created by other designers), and by allowing the group to re-interpret or modify each other's ideas, or to generate new ones. Finally, rigorous evaluations will be conducted as the project progresses, to quantify the utility of the PI's approach and of the tools developed. The results from these evaluations will provide the most extensive evidence to date of how computational tools affect individual and group creativity for interactive systems design.<br\/><br\/>Broader Impacts: The results of this work will advance the science of how to design computational tools that better facilitate creative thinking in the early stages of design. The developed software, empirical results, and lessons learned from this research should be applicable to many design and creative problem solving situations in which sketching, alternative representations, working with multiple ideas in parallel, and collaboration are paramount. This includes other interactive design domains as well as architectural, industrial, graphics, and mechanical design.","title":"SoD-TEAM: Developing Computational Tools that Facilitate Individual and Group Creativity in the Early Stages of Design","awardID":"0613806","effectiveDate":"2006-08-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7372","name":"ITR-SCIENCE OF DESIGN"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":["515821","506710"],"PO":["565227"]},"116874":{"abstract":"Developers often extend large, C-based software systems, including<br\/>operating systems, databases, and web servers, in an ad-hoc manner to<br\/>meet their performance and functionality requirements. Many of the<br\/>extensions represent crosscutting concerns in that they do not fit<br\/>within a single program module and are scattered throughout the<br\/>source. Maintaining and applying such extensions with commonly used<br\/>tools, notably diff and patch, is time consuming and error prone.<br\/>Furthermore, it is challenging to ensure correctness when composing<br\/>multiple extensions. This work makes crosscutting concerns part of<br\/>the architecture of C-based systems by leveraging aspect-oriented<br\/>software development techniques. Specifically, extensions are<br\/>captured as aspects, which provide a language-supported methodology<br\/>for expressing crosscutting concerns. The work also builds a new set<br\/>of tools that extract, inject, and translate system extensions<br\/>represented as aspects. Moreover, the work develops static program<br\/>analysis technology that aids in the semantic separation of extension<br\/>from mainline code and safe composition of extensions. To validate<br\/>the tools' effectiveness, the PIs conduct case studies on the Linux<br\/>kernel and open source extensions such as the Nooks system that<br\/>provides device driver isolation and recovery. For the educational<br\/>community, the work offers an attractive approach to hands-on learning<br\/>about real-world systems. For the system software community, the work<br\/>offers the ability to more rapidly and seamlessly move from idea to<br\/>design to implementation for new system-level extensions. Finally,<br\/>for the broader community of commercial developers and their<br\/>customers, the work offers a path to more flexible reuse of system<br\/>software.","title":"Collaborative Research: CSR-PDOS: Managing OS Extensibilty via Aspect-oriented Programming Technology","awardID":"0615129","effectiveDate":"2006-08-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["508475"],"PO":["493916"]},"117864":{"abstract":"This project, developing a platform to overcome the barriers to high performance wireless testbeds, addresses a critical challenge in the shared quest to achieve pervasive high-speed wireless. The work explores how to evaluate and deploy innovative architectures, algorithms and protocols in a real-world environment, without incurring the high costs of conventional custom design cycles. The Wireless Open-Access Research Platform for Networks (WARPnet), built from the ground up, enables researchers, equipment vendors, and network operators to experiment with a vast array of network architectures using a shared set of tools. Key features to be found in WARPnet follow.<br\/><br\/>-Clean-Slate Programmability in Deployed Networks: WARPnet enables programming of completely clean-slate designs at any layer, while providing access to a rich set of both research and standardized algorithms and protocols at every layer. Furthermore, the WARPnet nodes can be programmed remotely even after deployment, which is crucial to validate, refine, and research new concepts in at-scale networks.<br\/>-In-Depth Observability of AT-Scale Networks: WARPnet provides the ability to observe, record, and collect accurate state information at each node in the network at all network layers. The ability to collect fine-grain measurements is crucial to derive accurate network models, understand the impact of new protocols on network efficiency, and gain fundamental understanding of operational networks to facilitate on-line network management.<br\/>-Open-Access Collaborative Development: The WARPnet open access repository provides a uniform environment for development of shared, inter-operable components. With both a common hardware and software platform, researchers can reproduce, compare and enhance network instantiations in their local deployments.","title":"MRI: Development of WARPnet - A Platform for Programmable and Observable Deployed Wireless Networks","awardID":"0619767","effectiveDate":"2006-08-15","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}}],"PIcoPI":["542042","50058","548310","548311",312197],"PO":["557609"]},"127302":{"abstract":"The control of networked embedded systems poses challenging new problems questioning standard assumptions in systems and control theory. Control design has traditionally benefited from a useful abstraction that enabled the separation of continuous mathematical models of control systems and feedback laws from hardware\/software and real-time implementation details such as sensor quantization, sampling rates, real-time scheduling, etc. The prevailing assumption that control loops were implemented in highly engineered dedicated hardware systems can no longer be made. Networked embedded systems have limited resources that drastically reduce the quality of control. In the context of this project, formal methods for the integration of control design with real-time scheduling are being developed in order to overcome some of the limitations imposed by the separation of these two aspects of embedded control design.<br\/><br\/>Based on new stability abstractions for control systems, computational tools for automated synthesis of real-time schedulers enforcing control, timing, scheduling and power consumption requirements are being built. The resulting schedulers satisfy the desired specifications by construction thus providing formal guarantees of operation and performance. The results of this project are being evaluated by implementing stabilizing feedback control laws on MICA motes for two familiar benchmark problems in control engineering: the double inverted pendulum, and the ball and beam.<br\/><br\/>This integration between control and real-time scheduling allows practicing engineers to fully exploit the limits of existing embedded technology and results in cost reductions for the industry relying on embedded hardware. A particularly relevant example is the automotive industry where a small reduction in the cost of embedded hardware multiplied by the large number of produced units results in a considerable reduction in production costs.","title":"CSR - EHS: Formal Methods for Control and Real-Time Scheduling Co-Design","awardID":"0712502","effectiveDate":"2006-08-22","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["526859"],"PO":["561889"]},"116775":{"abstract":"The goal of this project is to implement and leverage a system that can<br\/>browse the past execution of a computer. \"Browsing\" refers to the ability<br\/>for a user to search, analyze, summarize, restore, or replay arbitrary data<br\/>or events that existed or occurred sometime in the past on that user's<br\/>computer. These capabilities depend on two foundational techniques.<br\/>Virtual-machine introspection allows the system to understand the execution<br\/>of a virtual machine as it executes or replays, without perturbing that<br\/>execution or replay. Virtual-machine replay allows the system to re-execute<br\/>a past time interval of the virtual machine instruction-by-instruction, yet<br\/>at only a few percentage overhead in time and space.<br\/><br\/>The ability to browse the past execution of one's computer can benefit<br\/>society by providing new capabilities to administrators, users, and<br\/>programmers. Administrators can use this ability to secure computers more<br\/>effectively by detecting past intrusions, which may help shrink the ranks<br\/>of \"bot armies\" controlled by criminals and spammers. Elderly people with<br\/>memory loss can use this ability to recall the events that occurred on<br\/>their computers, such as e-mail exchanges and GUI interactions. Programmers<br\/>can use this ability to fix difficult non-deterministic bugs and thereby<br\/>improve the overall robustness of the software on which society has come to<br\/>depend.","title":"Interacive Search of Complex Non-Indexed Data","awardID":"0614679","effectiveDate":"2006-08-01","expirationDate":"2011-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["463128","475390",309009,"561943"],"PO":["493916"]},"116797":{"abstract":"The network computing model is theoretically deep, and it has enabled<br\/>a range of revolutionary technologies from global information and communication resources to real time software control of complex systems. Nevertheless, every aspect of network computing would be simplified and improved by a more abstract logical approach. This project is developing a theory of events that provides one such approach. The intellectual core of this work is be a formal semantic account of distributed computation based on event structures. This formalism is considerably more abstract than the standard state sequence or temporal logic semantics. The aim of the research is to move event structures from pure theory toward support for more effective design, programming, and verification of real systems. Since the 80's, an event style theory has held considerable unrealized promise. It is the goal of this research to show that (1) a formal theory of events can directly capture intuitive features and relationships used by designers and can serve as the basis for a formal theory of distributed computing; (2) provides concepts and tools that programmers of real-time systems can trust; and (3) enables new programming tools that assist in building reliable and adaptable distributed protocols. This abstract formal theory of events is expected to have implications for many other aspects of network computing as well, and it will increase opportunities to use such a network computing model in diverse areas of science.<br\/><br\/><br\/>The project publishes on the Web the precise specifications of some important protocols, as well as detailed and formal accounts of key concepts in network computing in a form that can be processed by a variety of formal methods tools. This material is expected to assist expert programmers as well as those just learning about distributed systems.","title":"CSR-EHS: Developing a Theory of Events to Improve Distributed Systems","awardID":"0614790","effectiveDate":"2006-08-01","expirationDate":"2009-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["531903"],"PO":["561889"]}}