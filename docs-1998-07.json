{"30849":{"abstract":"9804078 Current software design doctrine rests on largely structural concepts: information hiding, spiral processes, delaying decisions, program families, reuse, etc. These idiosyncratic concepts are not explained or unified by scientific theory or mathematical models. At their heart is a common emphasis on flexibility in software products and processes. Flexibility incurs costs, e.g., as investments in architecture. What has remained unclear, even in principle, is what flexibility is worth, on what parameters and relations its value depends, and thus under what circumstances investments in it are warranted. This work will appeal to the theory of real options in an attempt to develop a scientific account of the value of flexibility as a framework for understanding important software design principles. Real options theory models the value of flexibility in capital budgeting and corporate strategy through analogies with financial options, such as call options on stocks. Conditions for using arbitrage-based pricing are unlikely to hold for many design decisions, so valuations will sometimes depend on subjective estimates of parameters. Even so, the real options view appears to provide an intellectual framework within which designers can reason about the value of flexibility as afforded by such mechanisms as modularity and phased project structures.***","title":"Foundations of Software Design in Theories of Contingent Value","awardID":"9804078","effectiveDate":"1998-07-15","expirationDate":"2002-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["469318"],"PO":["397849"]},"30709":{"abstract":"Current research on electronic commerce focuses on means for secure and efficient mechanisms for payments, largely supported by cryptographic techniques. Such mechanisms are indeed necessary for e-commerce, but they are not sufficient. Commercial activities are not limited to simple exchange of funds and merchandise between a client and a vendor. They often consist of multi-step transactions, sometimes involving several participants, that need to be carried out in accordance to a certain policy. Such policies may be concerned with issues that do not lend themselves to purely cryptographic treatment, such as: preventing certificates from being duplicated; ensuring that credit card are used only for the specified transactions; guaranteeing that a payment for services is refundable under specified circumstances; securing the privacy and anonymity of clients; providing a degree of fault tolerance; and establishing access control. This project proposes a general mechanism that can be used to formulate and enforce a wide range of such policies for electronic commerce, in a unified, scalable, and easily deployable manner. The policy is to be stated explicitly, and be enforced by a distributed set of trusted generic controllers. This mechanism is based on the concept of ``Law-Governed interaction,'' developed under a current NSF grant.","title":"The Formulation of Policies for Electronic Commerce and Their Enforcement","awardID":"9803698","effectiveDate":"1998-07-15","expirationDate":"2003-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["406322"],"PO":["241298"]},"28191":{"abstract":"This is an investigation of combinatorial optimization problems involving multiple objectives. Such problems arise in a variety of application areas including communication networks, very large scale integrated systems, facility location and management of hazardous materials. For many such problems, even optimizing one objective is often computationally intractable. Motivated by the practical importance of these problems, the focus of this research is on developing efficient algorithms that produce solutions which are near-optimal with respect to all the objectives. The major goals of the proposed research include identifying classes of multiobjective optimization problems from various application areas, developing efficient approximation algorithms for the problems and evaluating their performance through analysis\/experimentation, developing a software library of multiobjective approximation algorithms that can be used by researchers and practitioners, and obtaining insights into the intrinsic difficulties encountered in developing approximation algorithms for multiobjective problems. Both graduate and undergraduate students will be encouraged to participate in this work. The results obtained will be incorporated into seminar courses suitable for graduate and advanced undergraduate students. A number of practical situations require a careful analysis of constraints and objectives. For example, a business organization may want to upgrade the communication network interconnecting its branches so that information can be exchanged among the branches at a faster rate. Often, only a limited budget is available for the upgrade. It is of interest to the organization to obtain the best possible upgrade whose cost is within the available budget. Such situations involving constraints and objectives arise in a number of contexts including determining appropriate locations for facilities (such as hospitals, fire stations, etc.) and management of hazardous materials. Ma thematically, the problems arising in these contexts can be expressed as optimization problems involving multiple objectives. However, computing the best solutions to such problems is often infeasible. The focus of this research is on developing procedures that can quickly compute solutions which are close to the best solutions with respect to all the objectives. The research will investigate problems from a number of application areas. One of the goals of this research is to develop a library of software procedures that can be used by both practitioners and researchers.","title":"Combinatorial Optimization Involving Multiple Objectives: Approximation Algorithms and Applications","awardID":"9734936","effectiveDate":"1998-07-01","expirationDate":"2002-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":[70935],"PO":["528421"]},"28193":{"abstract":"This project will focus on applying results developed by learning theory researchers to real-life problems. Such application-based theoretical work is important so that the learning models and problems studied capture as best possible the needs of real-life problems. Working to apply theoretical techniques to real problems creates a better understanding of the real-world problems and thus can help direct the future theoretical work, facilitating the transfer of results from theory to practice. Many networking protocols (as well as other system control algorithms) utilize one or more tunable parameters, e.g. thresholds and window sizes. Frequently the methods used to set or adjust the values of the parameters are ad hoc and are based on certain assumptions about the operating environment, e.g. assuming a particular distribution on the traffic patterns in a communication network. This project will develop framework based on formal learning methods for automatic parameter tuning in system control algorithms to study if better performance can be obtained. One such networking application this project will study is that of dynamically adjusting delays of acknowledgements in the TCP protocol. Delaying acknowledgements has two main advantages. First, it allows a single acknowledgement for more than one packet. Second, if a data packet is being sent in the opposite direction, then we can piggy-back the acknowledgement too much can increase the latency. Most TCP implementations used today employ some sort of acknowledgement delay mechanism. This project investigates several schemes to dynamically adjust acknowledgement delay, including ones based on the Weighted Majority (WM) algorithms and ones based on the Exponentially Weighted Moving Average (EWMA) algorithm. These schemes will be contrasted based on efficiency and efficacy , as well as proving theoretical results about them in terms of how well they respond to \"volatile\" TCP connections. That is, if the connecti on occasionally switches from sparse data transmission (where the goal might be to minimize latency, as in the case of an interactive application) to dense data transmission (where the goal might be to minimize the number of acknowledgements and latency is not as important, as in the case of a file transfer) and back again. Simulation results will be used to supplement the theoretical results. Applying learning theory results to this problem and other networking problems will then provide guidance in defining new theoretical learning models that better model real-life scenarios. This project will also carefully develop and study such new learning models.","title":"Applying Learning Theory to Networking Problems","awardID":"9734940","effectiveDate":"1998-07-15","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["228082"],"PO":["528421"]},"29481":{"abstract":"One of the most fundamental problems in theoretical computer science, perhaps next in importance to only the P vs. NP problem, is the P vs. NC problem. Earlier work by the PI has shown that many important combinatorial optimization problems such as mincost flow and maxflow do not have fast parallel algorithms in a PRAM model without bit operations; this is like the usual PRAM model, the main difference being that the instruction set of the processors does not contain any bit operations. Since the maxflow and mincost-flow problems are P-complete, they do not have fast parallel algorithms even in the unrestricted PRAM model assuming P NC. The significance of the result was in the fact that this could be proved unconditionally, i.e., without assuming P NC, in a model that is natural and realistic for the problems under consideration. In fact, the PRAM model without bit operations has been widely used in practice in the design of parallel algorithms for a large number of algebraic and weighted combinatorial optimization problems. These include fast parallel algorithms for solving linear systems, and for minimum-weight-spanning trees, shortest paths, global mincuts in weighted undirected graphs, blocking flows and max flows, approximate roots of polynomials, and several problems in computational geometry. Thus, our lower bound provided a concrete support for the belief that P-completeness implies high parallel complexity, and for the P NC conjecture itself, by proving its weaker implications in a restricted, but realistic parallel model of computation. This project extends these techniques to investigate parallel complexity of several other problems that are not known to be, or expected to be, P-complete, and consequently, whose parallel complexity is not well- understood at present. These include problems from several different areas: network flows, matroidal optimization, computational geometry, numerical computation, approximate optimization, and so fo rth. Investigating parallel complexity of these problems in a unified manner is of considerable practical as well as theoretical significance in the design and analysis of parallel algorithms. The project includes further applications of deep techniques from algebraic to questions of lower bounds in complexity theory.","title":"Lower Bounds in Parallel Complexity","awardID":"9800042","effectiveDate":"1998-07-01","expirationDate":"2003-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["451397"],"PO":["499399"]},"28073":{"abstract":"9734115 Model checking is emerging as a practical tool for automated debugging of complex reactive systems. In model checking, a high- level description of a system is compared against a logical correctness requirement to discover inconsistencies. This CAREER research aims to enhance applicability and efficiency of this paradigm by pursuing three objectives in research and education. First, to make results in computer-aided verification more accessible to nonspecialists, a modeling method called \"reactive modules\" is developed as a unified framework. In addition, an analysis tool that supports a combination of techniques, a standard textbook on computer-aided verification, and an advanced course on computer-aided verification will all be created. Second, to develop techniques that can analyze systems beyond the reach of existing tools, two new topics, open systems and heterogeneous systems, are investigated. An open system is a reactive system interacting with an unspecified environment, and for analysis of such systems, novel specification paradigms such as alternating-time temporal logics are studied. For analysis of systems consisting of components with different synchrony assumptions and described in different source languages, the utility of reactive modules as a common semantic framework is investigated. Finally, to integrate concepts in formal methods into undergraduate education at Penn, changes to existing courses in theory and systems are proposed.***","title":"CAREER: Computer-Aided Verification of Reactive Systems","awardID":"9734115","effectiveDate":"1998-07-01","expirationDate":"2003-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["497082"],"PO":["564388"]},"28185":{"abstract":"Current theory does little to predict, explain or analyze the empirically observed success of search and optimization heuristics for some domains of NP-complete problem and their failure for others. Without such a theory, implementers of heuristics have no guidance as to whether a particular heuristic method is suitable for a particular problem domain, what kind of performance to expect, or how to set the various parameters for better performance. Implementation is often done in a haphazard way based on little more than guess-work or trial-and-error. The following inter-related lines of theoretical research will be explored to address this gap: (1) Extending average-case complexity to consider reductions to and between problem distributions that arise naturally ( in real-life, testing, cryptanalysis or combinatorics). (2) Extending average-case analysis techniques to a more general characterization of the relevant combinatorial properties of random problem instances from naturally arising distributions. In particular, the properties of associated search spaces for such problems. (3) For experimentally successful heuristic methods, identify the combinatorial characteristics of problem instances that determine their performance. (4) Investigate more efficient worst-case algorithms for NP complete problems, identify those NP complete problems with nontrivial worst-case algorithms, and explore the connection between lower and upper bounds. Although the techniques used are solely mathematical, the motivation and justification come from the experimental literature.","title":"Developing a Theory of Heuristics","awardID":"9734911","effectiveDate":"1998-07-15","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["515841","515842"],"PO":["528421"]},"28097":{"abstract":"This research addresses the need to consider details of the analog behavior of digital circuits and interconnect in order to ensure correct functionality. Specifically it focuses on analysis of timing and noise in deep submicron circuit designs. All noise sources in a digital integrated circuit are being considered - coupled and ringing noise on signal lines, power supply noise, and noise from the circuits The effect of noise on delay is being considered in performance verification. Because many of the emerging timing and noise problems are associated with on-chip inductance, techniques for practically extracting on-chip inductance will be developed. The question of how the complex time-domain responses that result from inductive interconnect can be used in static timing and noise analysis is being investigated. Additional explorations are on using the complex time-domain responses that result from inductive interconnect for static timing and noise analysis. Other areas of investigation include a static solution to on-chip power grid integrity analysis and noise considerations in synthesis and circuit tuning. The educational plan includes building a VLSI CAD research laboratory, and development of courses in hardware design using FPGAs.","title":"CAREER: Design Tools and Techniques for Analog Effects in Digital Integrated Circuits","awardID":"9734216","effectiveDate":"1998-07-01","expirationDate":"2002-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["529662"],"PO":["562984"]},"34082":{"abstract":"The 1998 ACM SIGCOMM Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication will be held in Vancouver, British Columbia, from September 2-4, 1998. This conference is the premier technical meeting that examines the state-of-the-art in computer networks and communications. This proposal request funding to assist fourteen United States-based graduate students in attending this meeting. Participation in conferences such as SIGCOMM is an extremely important part of the graduate school experience, providing the opportunity to interact with more senior researchers and be exposed to leading edge work in the field. The support requested in this proposal will enable the participation of students who would otherwise be unable to attend SIGCOMM'98.","title":"Travel Support For ACM SIGCOMM '98 Conference","awardID":"9813874","effectiveDate":"1998-07-01","expirationDate":"1998-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["527253"],"PO":["150490"]},"27152":{"abstract":"This joint work between Prof. Mani Soma (U. of Washington) and Jacob Abraham (U. of Texas). The research is on fault models, test generation, and design verification for analog and mixed-signal Integrated circuits. A top-down approach to test and verification in mixed-signal design is being pursued. Research topics include the following. Develop algorithms for abstracting a circuit from the description of a mixed-signal circuit. Define testability figures of merit for major analog blocks such as converters, filters, etc., and develop methods to compute them. Investigate algorithms to evaluate testability of mixed-signal design using high level design information. For design verification, the group is finding accurate transformation algorithms to map analog blocks to discretized form. Also, abstractions to reduce state space complexity during verification are being explored. The algorithms and methods are being built into testability and test tools.","title":"Hierarchical Testability Analysis and Design Verification for Analog and Mixed-Signal Systems","awardID":"9730919","effectiveDate":"1998-07-15","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["166463"],"PO":["564898"]},"28087":{"abstract":"The use of proprietary designs (reusable cores) as part of VLSI systems on a chip depends on having reliable and efficient techniques for intellectual property (IP) protection. This research investigates techniques for such protection. It includes a watermarking (signature hiding) approach for protecting CAD tools, reusable cores, and embedded software. Also being explored is a fingerprinting scheme, and a covert channel-based technique for the efficient detection of misappropriated (stolen) IP. The watermarking approach is the addition of design and\/or timing constraints in the design specification which encode the author's signature. Fingerprinting techniques are meant to deter people from illegally distributing IP by enabling the author of the IP to uniquely identify the original buyer of a resold copy. The concept of covert channels is the basis for techniques which convey to the author information without alerting an illegal owner of IP. The effectiveness of the proposed techniques and algorithms will be demonstrated on industrial strength designs. The educational plan includes the development and use of watermarking techniques and video games for teaching IP protection techniques and other material.","title":"CAREER: CAD Techniques and Tools for Intellectual Property Protection","awardID":"9734166","effectiveDate":"1998-07-01","expirationDate":"2003-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["472184"],"PO":["562984"]},"27890":{"abstract":"Due to the exponential growth in the demand for wireless communication services, new techniques for optimizing system quality and capacity are imperative. Our proposed research program strives to meet these challenges in the following areas: (i) Accurate channel modeling. New statistical models for multipath and shadow fading will be developed that are both accurate in describing the propagation environment and also useful in analysis. These models will provide a foundation for proposed optimization techniques. (ii) Information theory for wireless links. The goal here is to develop useful information theoretic limits for wireless multiuser systems. An approach based on throughput analysis is proposed that will yield new insights into the optimization of wireless systems, particularly for multirate applications. (iii) Optimization of Wireless Code Division Multiple Access (CDMA) systems. Hybrid systems that combine the advantages of using long spreading sequences (R-CDMA) with those of short sequences (D-CDMA) will be explored. Techniques will also be developed for the accurate analysis of CDMA capacity and coverage for both single-user and multiuser detection systems. (iv) Dynamic resource allocation. The three primary resources for wireless access -bandwidth, space and power - need to be allocated efficiently and dynamically in a mobile wireless environment. A major goal of the proposed research program is to develop a mathematical foundation for dynamic resource allocation. The proposed decentralized dynamic decision making (DDDM) framework will be essential to this development. The educational objectives of the proposed program are: (i) to promote meaningful learning in the classroom; (ii) to promote ties with industry so students are exposed to real-world needs; (iii) to exploit new technologies to expand classroom boundaries; (iv) to design classes that will better prepare students for new opportunities in telecommunications; and (v) to incorporate research in all educational activ ities.","title":"PECASE: New Techniques for Optimizing the Quality and Capacity of Wireless Communication Systems","awardID":"9733204","effectiveDate":"1998-07-01","expirationDate":"2000-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["223414"],"PO":["187585"]},"27340":{"abstract":"This project studies the design and analysis of dynamic computer processes. Past research in theoretical computer science has focused mainly on static computation problems, where the input is known before the start of the computation and the goal is to minimize the number of steps till termination with a correct output. Many important processes in today's computing are dynamic processes, whereby input is continuously injected to the system, and the algorithms is measured by its long term, steady state, performance. Examples of dynamic processes include communication protocols, memory management tools, and time sharing policies. The goal of this project are: (1) To develop new tools for analyzing the performance of dynamic processes, in particular through modeling the dynamic process as an infinite stochastic processes. (2) Use the insight obtained from the above analysis to obtain provably better algorithm for fundamental dynamic processes such as (a) dynamic data structures, (b) communication protocols, and (c) resource sharing protocols. (3) Validate the analysis though simulations to develop algorithms of both practical and theoretical interest.","title":"Design and Analysis of Dynamic Processes: A Stochastic Approach","awardID":"9731477","effectiveDate":"1998-07-15","expirationDate":"2003-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["531608"],"PO":["543507"]},"29485":{"abstract":"The focus of this research is the Hirsch Conjecture which claims that the edge-diameter of a (d,n)-polytope -- a d-polytope with n facets -- is at most n-d. The edge-diameter of the polyhedral feasible region of a Linear Program is of interest since it provides a lower bound on the worst-case behavior of any edge- following Linear Programming algorithm. Considerable research effort has been expended in the past on the Hirsch Conjecture and its relatives due to their crucial role in the quest to understand and improve the worst case behavior of the Simplex method. Despite four decades of research however, even a polynomial upper bound on the edge-diameter of a (d,n)-polytope has remained elusive, and the Hirsch Conjecture and its relatives remain among the most important unresolved problems in the theory of Linear Programming. In contrast to earlier attacks on the conjecture, which analyze the combinatorial structure of polytopes, this research attempts to determine whether or not the space of all Hirsch polytopes (polytopes for which Hirsch Conjecture is true) is a proper subspace of the space of all polytopes. The research will study the geometric properties of the space of Hirsch polytopes in an attempt to determine if the complementary subspace of counterexamples is empty.","title":"Hirsch Conjecture and Linear Programming","awardID":"9800053","effectiveDate":"1998-07-01","expirationDate":"2002-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":[74519],"PO":["381214"]},"27330":{"abstract":"This joint work between Prof. Mani Soma (U. of Washington) and Jacob Abraham (U. of Texas). The research is on fault models, test generation, and design verification for analog and mixed-signal Integrated circuits. A top-down approach to test and verification in mixed-signal design is being pursued. Research topics include the following. Develop algorithms for abstracting a circuit from the description of a mixed-signal circuit. Define testability figures of merit for major analog blocks such as converters, filters, etc., and develop methods to compute them. Investigate algorithms to evaluate testability of mixed-signal design using high level design information. For design verification, the group is finding accurate transformation algorithms to map analog blocks to discretized form. Also, abstractions to reduce state space complexity during verification are being explored. The algorithms and methods are being built into testability and test tools.","title":"Hierarchical Testability Analysis and Design Verification for Analog and Mixed-Signal Systems","awardID":"9731433","effectiveDate":"1998-07-15","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["225904"],"PO":["564898"]},"27583":{"abstract":"Motivated by problems in several applied areas, such as computer graphics, robotics, computer vision, computer aided design, image processing, and geographic information systems, computational geometry emerged as a discipline about twenty years ago. Numerous efficient geometric algorithms and sophisticated algorithmic paradigms have been developed, and computational geometry is by now a rich and mature discipline. The link between computational geometry and application areas is, however, still not as strong as one would have hoped for. The purpose of this project is to narrow the gap between geometry and the related applied areas. The project will address the issues beyond the traditional framework of algorithmic design, and simple algorithms will be developed and implemented that work well in practice. Geometric problems motivated by various application areas, including visualization, robotics, data mining, and metrology will be studied. The algorithms will be developed and analyzed in a more realistic model of computation and will be implemented and tested on ``real'' inputs.","title":"Simple and Efficient Geometric Algorithms and Their Applications","awardID":"9732287","effectiveDate":"1998-07-01","expirationDate":"2003-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["554177"],"PO":["321058"]},"31290":{"abstract":"9805548 Donald, Bruce Randall Dartmouth College CISE PostDoc: Microrobotics and MEMS Combining rapidly evolving technologies -- MicroElectroMechanical Systems (MEMS), distributed robotics, and biotechnological systems -- to create large collections of autonomous, intelligent micro-machines offers new capabilities that can be exploited for a variety of useful purposes. By merging sensing and actuation with computation and communication, MEMS devices can be distributed throughout the environment, coated on surfaces, or embedded within everyday objects to create distributed systems for sensing, reasoning about, and manipulating events in the physical world on a scale never before possible. A primary component of this research is the exploration of how to program massively-parallel MEMS microactuator arrays. Drawing on biological inspiration, arrays of artificial flagella and cilia provide actuation in the form of manipulation or locomotion. Asserting a coordinated effort by the aggregate array requires addressing the parallel actuation of individual robotic agents. The impact of a postdoctoral candidate includes: (1) new designs and processes for massively-parallel MEMS devices, (2) biologically-inspired systems and devices to implement massively-parallel manipulation and locomotion, and (3) control software and algorithms for arrays of artificial flagella and cilia. Experiments will be performed to validate the theory. This work is interdisciplinary, combining results from computer science, biology, and engineering.","title":"CISE PostDoc: Microrobotics and MEMS","awardID":"9805548","effectiveDate":"1998-07-01","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["213293"],"PO":["564318"]},"49067":{"abstract":"","title":"CAREER: Mathematical Optimization for Inductive Machine Learning","awardID":"9996044","effectiveDate":"1998-07-01","expirationDate":"2002-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":[125561],"PO":["564456"]},"27431":{"abstract":"Nonsmooth optimization problems involve objectives or constraints which are not differentiable everywhere. The term structured nonsmooth optimization means that the specific nonsmooth nature of the problem is known. One especially interesting class repeatedly arises in many applications: problems involving eigenvalues of matrices. The project primarily focuses on various aspects of eigenvalue optimization, including semidefinite programming, quasiconvex eigenvalue optimization, and non-Lipschitz eigenvalue optimization. The goal is fourfold: the development of fast, robust numerical algorithms; analysis of theoretical questions concerning optimality conditions and algorithm convergence; development of software which can be used by the general scientific community; and application to the solution of important interesting problems which arise in practice.","title":"Numerical Methods for Non-Smooth Optimization","awardID":"9731777","effectiveDate":"1998-07-01","expirationDate":"2002-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["549376"],"PO":["179846"]},"27696":{"abstract":"Zeilberger 9732602 Zeilberger plans to develop algorithms for automatic discovery and proof of results in combinatorics and related areas. In particular, he plans to mechanize Dodgson's method evaluating hypergeometric determinants, to use techniques from computational linguistics to empirically discover and then rigorously prove `grammars' of combinatorial families, and to develop a computational Ansatz for multi-variate rational generating functions. He also proposes to investigate combinatorial analogs of techniques from computational chemistry and to try to prove Haiman's Diagonal Harmonics conjecure. This research is in the general area of Combinatorics. One of the goals of Combinatorics is to find efficient methods of studying how discrete collections of objects can be arranged. The behavior of discrete systems is extremely important to modern communications. For example, the design of large networks, such as those occurring in telephone systems, and the design of algorithms in computer science deal with discrete sets of objects, and this makes use of combinatorial research. This research is also in the general area of Symbolic Computation, that attempts to teach computers to perform research that previously required extensive human resources. Progress in this area promises to have important ramifications to science and technology.","title":"Targeted Proof Machines in Combinatorics","awardID":"9732602","effectiveDate":"1998-07-01","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1264","name":"ALGEBRA,NUMBER THEORY,AND COM"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["399257"],"PO":["49528"]},"37376":{"abstract":"9870270 To test a piece of software, a set of possible inputs is selected, the software is executed on each of them, and the results are checked against the specification. This research addresses the following two issues involving the development of cost-effective testing techniques: evaluation of the effectiveness of existing testing techniques and development of efficient methods for checking test results against their specifications. The first provides data to help practitioners make informed choices between competing testing techniques; the second lowers the cost of testing certain types of programs, allowing more thorough testing within a given budget. The research on evaluation of cost-effectiveness of testing techniques is based on a probabilistic approach, since most testing techniques involve some random choice among alternatives. Models of cost are incorporated into several probabilistic measures of effectiveness. The work on checking test results focuses on testing data abstractions, an increasingly important kind of program unit. New techniques for partially checking test results are developed and their effectiveness is investigated analytically and through experimentation.***","title":"Assessing and Enhancing Software Testing Effectiveness","awardID":"9870270","effectiveDate":"1998-07-15","expirationDate":"2002-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["528387"],"PO":["397849"]},"27586":{"abstract":"Voxel-based volumetric objects normally have much more complex physical properties and spatial structures than surface-based geometric models. Thus, traditional physically-based deformation modeling techniques are often ineffective and costly in the volumetric domain. This project will focus on developing efficient and accurate modeling techniques, computational methods and visualization algorithms for deformable volumetric objects. A new landmark-based volume deformation model and related rendering algorithms will be developed. In this model, a volume deformation is represented by a relatively small set of landmark points defined in a volume space. Three-dimensional scattered data interpolation methods will be applied to generate smooth deformation functions over the volume space. Landmark points and their movements can be used for both the interactive deformation manipulations and the deformation pattern representations of specific types of deformable objects. Instead of directly modeling the object's physical or biological properties, this approach employs an inverse method to derive the deformation pattern of a given class of objects, using a parameterized spring model, directly from existing or experimental data. Fast deformable volume rendering algorithms will also be developed to support the visualization of the volume deformation process. To avoid unnecessary deformation computation and multiple volume resampling, the deformation computation will be integrated into the rendering process without explicit volume reconstruction. For region-specific deformations of different sub-structures in a complex and hierarchical volumetric environment, deformation operations can also be applied to a Volumetric-CSG model to support deformable volumetric object manipulation. Several applications of this research will be pursued, including craniofacial growth, volume morphing, medical object modeling and interactive volumetric animation.","title":"Deformable Volumetric Modeling","awardID":"9732297","effectiveDate":"1998-07-15","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":[69600],"PO":["179846"]},"29577":{"abstract":"9800351<br\/>Tetali<br\/><br\/>This research concerns the hard-core lattice gas model on the integer lattice, with special emphasis on the square lattice. The project includes the following problems:<br\/>(i) To establish a rigorous, quantitative connection between the rate of approach to equilibrium of certain discrete dynamics and the uniqueness of (infinite--volume) Gibbs measure for the hard-core model on general graphs<br\/>(ii) To analyze the rate of mixing of certain dynamics with the intention of improving the existing bounds on the critical activity of the hard-core model on the square lattice.<br\/>(iii) To investigate the role of percolation and other techniques in this context. In graph-theoretic terms, one of the objectives is to generate independent sets of a large n by n grid with probabilities favoring the bigger independent sets, in particular, with hard-core distribution with activity > 1. The proposal also includes a student project on estimating the mixing rates of Markov chains on combinatorial structures, whose counting function is the nth Catalan number.<br\/><br\/>The lattice gas model is of independent interest and significance to researchers in statistical physics, theory of computing, probabilistic combinatorics, and communication networks. The easiest-to-describe motivation is that of a telephone (loss) network with Poisson arrival rates and independent holding times for calls. The hard constraint demands that a call be accepted\/active only if all the neighboring cells (neighborhood according to an arbitrary topology) are inactive. The PI hopes to contribute to the understanding of the connections between spatial correlations (i.e. the effect of the presence of a call in one location on calls at reasonably far locations) and the convergence of the dynamics (i.e. the rate at which the network approaches, if it eventually does, a unique stable configuration of active calls).","title":"Uniqueness of Gibbs Measures and Rapidly Mixing Dynamics","awardID":"9800351","effectiveDate":"1998-07-01","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1263","name":"PROBABILITY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["565106"],"PO":["517169"]},"39015":{"abstract":"","title":"Power-Efficient Ad Hoc Mobile Networking","awardID":"9896343","effectiveDate":"1998-07-15","expirationDate":"2001-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["518079"],"PO":["125800"]},"49069":{"abstract":"","title":"Visualizing Learned Models and Data for Exploratory Machine Learning","awardID":"9996046","effectiveDate":"1998-07-01","expirationDate":"2000-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":[125565],"PO":["183208"]},"28158":{"abstract":"This research is on asynchronous, or self-timed, design. Such designs eliminate the global synchronizing clock, thus permitting higher performance, scalability, and lower power. The project is investigating problems in datapath design: (1) the design of high-performance and low-power datapath components, and (2) a system-level application to compressed- code embedded processors. In (1), a technique, \"speculative completion\", for designing asynchronous datapath components which give high performance, yet have little area and power overhead is being developed. This technique allows use of existing synchronous components, with small amounts of added circuitry and a multi-slotted completion signal, to allow early completion. As part of this research, (a) the technique is being applied to design fast adders, multipliers, and comparators; and (b) new optimizations are being developed, which target statistically-skewed (i.e. non- random) input data that appear in real-world applications. In (2), research activity being carried out is focused on a system-level application: the design of embedded systems with compressed memories. The investigation includes (a) exploration and evaluation of a variety of memory compression techniques; (b) design of a small and fast asynchronous decompression circuit, which can decompress such memories, on the fly, at acceptable rates.","title":"High-Performance and Low-Power Asynchronous Datapaths: Design and Applications","awardID":"9734803","effectiveDate":"1998-07-15","expirationDate":"2002-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["518562"],"PO":["201974"]},"30490":{"abstract":"Questions about what happens to a solution to a problem of <br\/>optimization when the parameters on which the problem depends <br\/>are perturbed are important not only in assessing the stability <br\/>of mathematical models, but also in the design and justification <br\/>of computational procedures. Issues of parametric dependence <br\/>are also the key to effective utilization of `cost-to-go' functions <br\/>in dynamical optimization, whether in optimal control or stochastic <br\/>programming. This project would advance the methodology for dealing <br\/>with such dependence and explore its consequences for computation.<br\/><br\/>The latest tools in variational analysis, which are essential because<br\/>of inherent nonsmoothness in parametric dependence, would be applied.<br\/>Alternative forms of optimality conditions, focused especially on <br\/>perturbational robustness, would be investigated in a broad framework,<br\/>both finite- and infinite-dimensional. Cost-to-go functions in convex<br\/>dynamical optimization would be studied from the new perspective both <br\/>in deterministic continuous-time models, with their connections to <br\/>Hamilton-Jacobi theory, and in stochastic discrete-time models, where<br\/>the numerical potential will dominate.","title":"Parametric Methodology in Optimization","awardID":"9803089","effectiveDate":"1998-07-15","expirationDate":"2001-12-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1266","name":"APPLIED MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0706","name":"Division of DESIGN & MANUFACTURING INNOV","abbr":"DMI"},"pgm":{"id":"5514","name":"OPERATIONS RESEARCH"}}],"PIcoPI":["271252"],"PO":["209579"]},"30380":{"abstract":"9802773 Balas The research funded by this grant addresses some basic theoretical and methodological aspects of integer and combinatorial optimization. Over the last few years the principal investigators have developed a technique called lift-and-project for solving mixed integer programs. When embedded in an enumerative framework, called branch-and-cut, this approach has shown itself to be highly robust and competitive with the best available alternatives. A major goal of the research is to consolidate these results and develop the approach in new directions, by solving several open problems concerning the properties of the cutting planes used; the way of generating and handling them; and, the interplay between cutting and branching. Part of this research will combine polyhedral methods with some tools borrowed from artificial intelligence. A closely related research topic is focussed on a heuristic procedure called OCTANE, which uses a neighborhood search defined by a construction based on polarity. Another topic involves ideal 0-1 matrices, which make certain integer programs defined by them solvable as linear programs. Finally, a substantial part of the research will focus on the traveling salesman problem, and some of its generalizations, focusing on a dynamic programming approach that can efficiently solve large classes of problems in this area. The research envisaged here is expected to substantially enhance the state of the art in solving integer and combinatorial optimization problems in general, traveling salesman-type problems in particular. Some of the investigations are aimed at gaining new theoretical insights and a deeper understanding of the structures involved, but most of the research is methodological in nature and is therefore expected to result in more efficient algorithms and computer codes. The problems to which such algorithms may be applicable range from investment decisions, capacity expansion models, location and distribution problems, to industrial scheduling and sequencing.","title":"Combinatorial Optimization and Integer Programming: Polyhedral Analysis and Algorithms","awardID":"9802773","effectiveDate":"1998-07-15","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"5514","name":"OPERATIONS RESEARCH"}}],"PIcoPI":["539128","539129"],"PO":["185422"]},"26652":{"abstract":"Abstract - Miller CTS - 9729578 A numerical model for a flickering, or time-varying, flame is developed; this model is intended to accurately and efficiently predict emission levels for nitrogen oxides. The model consists of three sections: (1) prediction of flame structure through solution of conservation equations in mass, momentum, energy, and mixture fraction; (2) application of a flamelet library approach to predict concentrations of carbon, hydrogen, and oxygen species; and (3) post-processing nitrogen chemistry to predict local levels and emissions of nitrogen oxide species. The unsteady flame structure is predicted using an adaptive spectral element discretization of the conservation equations on both serial and parallel machines. The existing incompressible spectral element code is revised to permit variable density. At each step in the process, model predictions are compared with measurements of concentration from tunable-diode laser absorption spectroscopy (TDLAS) on a methane-fueled flame, including in situ measurements of carbon monoxide, carbon dioxide, and methane and conditional sampling of the flame using a pulsed quartz microprobe to determine concentrations of trace nitrogen species including nitric oxide, nitrogen dioxide, ammonia, and hydrogen cyanide. This effort introduces a new computational approach for the modelling of pollutant formation and flame behavior.","title":"Measurements and Prediction of Nitrogen Oxide Formation in Flickering Flames","awardID":"9729578","effectiveDate":"1998-07-15","expirationDate":"2001-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1407","name":"COMBUSTION, FIRE, & PLASMA SYS"}}],"PIcoPI":["525311","312541"],"PO":["202863"]},"32790":{"abstract":"Abstract ANIR-9810444 PI: Joseph A. Roos Christ the King Seminary East Aurora, New York This proposal requests funds for the installation of a T1 line that will connect Christ the King Seminary to the Internet. Internet access will promote the sharing of information and the dissemination of research results. It also allows faculty to explore areas of interest, integrate new methodologies of teaching into their coursework; and facilitates the computerization of the library's collection. The award provides partial support of the project for two years.","title":"Connectivity for Christ the King Seminary","awardID":"9810444","effectiveDate":"1998-07-01","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4091","name":"NETWORK INFRASTRUCTURE"}}],"PIcoPI":[82605,"448933"],"PO":["198445"]},"31140":{"abstract":"The objective of this program is to design an efficient VLSI implementation for certain algebraic geometry codes, to fabricate a chip, and to identify applications where these codes would be competitive. The codes to be considered are Hermitian codes and other codes similar in structure. The advantage of these codes is that, for a given symbol size, they are longer than Reed- Solomon codes and can therefore take better advantage of the law of large numbers to give much greater error correction capability. A number of decoding algorithms for these codes exist, including those developed by the co-PIs. We will combine the best elements of these algorithms into an explicit computational algorithm that is well suited to VLSI implementation. The goal is to produce a chip that uses parallel processing, regular and simple structures, simple logic, and a minimal number of iterations. We will verify the logic design using a VHDL simulation. We will also identify systems where these codes would be appropriate and test the performance of the decoder in channel simulations appropriate to those applications.","title":"Implementation and Applications of Practical Codes on Curves","awardID":"9805080","effectiveDate":"1998-07-01","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["409512","381437"],"PO":["150411"]},"33033":{"abstract":"The increasing capacity of integrated circuits (ICs) permits complex components, referred to as intellectual property or cores, to reside as a system on a single IC. A key difference from the past, where each component was a distinct IC, is that now the component interfaces are flexible and can thus be optimized for a particular system. This project develops an approach for specifying system behavior such that cores are sufficiently encapsulated but still have optimizable interfaces. The approach addresses modeling and refinement through multiple specification levels, starting from an object-oriented model and ending with a connection of components, from which existing methodologies take effect. The specification approach is being applied to several examples, which span a variety of interface architectures with diverse performance, power consumption, and size metrics.","title":"Core IP Support in System Specifications for Systems-Level Interface Optimization","awardID":"9811164","effectiveDate":"1998-07-01","expirationDate":"2003-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["450944"],"PO":["562984"]},"27951":{"abstract":"The basic research component of this project is concerned with transient faults and unexpected environmental changes that occur in distributed systems and networks. Transient faults include spontaneous data corruption and any temporary deviation from software specification. The project explores how effects of transient faults can be contained within desired boundaries of time or application-specific objectives. Using methods of stabilizing algorithms, which automatically recover from transient state disruptions, issues of containment will be studied. Basic research investigations will yield new algorithms for tolerating transient faults and will demonstrate the inherent resource conflicts between stabilization and containment objectives. Another goal is to alleviate compute-intensive and complexity disadvantages often associated with stabilizing algorithms, using methods of encapsulation and probabilistic approaches. The potential significance of the new stabilizing containment techniques will be demonstrated by case studies: interfaces between software layers that contain effects of faults are simplified; optimistic treatment of faults improves efficiency of recovery; distributed programs can manipulate objects while limiting contamination due to temporary object corruption. The impact of the basic research and its case studies will be to bring stabilization and containment techniques closer to widespread application in new generations of distributed systems. The plan's applied research and educational components emphasize student projects implementing recent distributed computing algorithms.","title":"CAREER: Stabilizing Containment for Networks and Distributed Systems","awardID":"9733541","effectiveDate":"1998-07-01","expirationDate":"2004-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["282016"],"PO":["309350"]},"27764":{"abstract":"This project studies approximation algorithms for NP-Hard optimization problems. Many of these are important, real-world problems. Because for these problems there probably are no efficient, exact algorithms, the project studies approximation algorithms. These algorithms are guaranteed to be fast and to return a near-optimal answer. Either this near-optimal solution can be used directly, or it can be used as a starting point for a heuristic which attempts to improve the solution. Among the problems studied are MAX SAT, the problem of satisfying as many disjunctions as possible in a given set of disjunctions of Boolean literals, variants of MULTICUT, which involve finding, in a graph, a smallest set of edges whose removal disconnects given vertices; and STEINER TREE, the problem, given a graph, of finding a cheap subgraph which connects a given set of terminals.","title":"Approximation Algorithms","awardID":"9732746","effectiveDate":"1998-07-15","expirationDate":"2002-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":[70035,"381502"],"PO":["528421"]},"26973":{"abstract":"This research investigates a test data compression method which fully utilizes the unique characteristics of test data. The key idea is to perform the Burrows-Wheeler (BW) transformation on individual test sequences, and then to apply two different compression schemes. The BW transformation reduces the number of transitions for test sequences, which leads to a higher compression ratio compared with the original test sequences. Research topics are: 1. study characteristics of test data that form a basis for the work and to measure redundancy of test sequences along pins and across pins; 2. determine how best to merge correlated test sequences to achieve a higher compression ratio; 3. study the BW transformation and the strings generated by successive applications of the BW transformation to enable one to construct a test set with a minimal number of transitions; 4. integrate the research findings into the P.I.'s existing tool for test data compression.","title":"Development of an Efficient Method for Test Data Compression","awardID":"9730372","effectiveDate":"1998-07-01","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["475415"],"PO":["564898"]},"24135":{"abstract":"The grant supports research in the design and analysis of algorithms and improving the education infrastructure at the PI's department. The research focuses primarily on the following areas: (i) fast approximation algorithms for intractable (NP-hard) problems; (ii) fast approximation algorithms for very large problems requiring nearly linear- time solutions; (iii) competitive analysis of on-line caching problems. The style of research emphasizes the following: (i) general techniques for understanding, unifying, and simplifying large classes of algorithms; (ii) theoretical measures that are more realistic than either the standard worst-case or average-case models; (iii) empirical studies of new algorithms demonstrating their effectiveness. The education plan consists of the following. (i) Developing a training course for a core group of advanced undergraduates who will them lead small weekly discussion sections in the introductory courses. (This will simultaneously improve the introductory courses and provide a training ground for students to become educators.) (ii) Working with an outside evaluator to extensively evaluate the experience of majors and prospective majors. Two primary goals are to determine the effects of the aforementioned discussion sections (both on the students in the sections and those leading them), and to identify reasons for the low rate of retention of women undergraduates by the department.","title":"Career: Combinational Approximation Algorithms","awardID":"9720664","effectiveDate":"1998-07-01","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["486542"],"PO":["528421"]},"27897":{"abstract":"Data security and cryptography are growing concerns for the rapidly expanding information infrastructure. This project treats this emerging engineering discipline with a systematic exploration of the use of reconfigurable hardware. The research in this project will: develop arithmetic architectures for public-key algorithms on reconfigurable hardware; classify private-key algorithms according to the kernel functions needed in their implementation; establish a public-domain VHDL library of algorithms for both public and private key cryptosystems; and develop a board-level reconfigurable device for implementation of cryptographic algorithms. Educational activities will include development of material for teaching cryptography to beginning graduate students, inclusion of VHDL design projects in the undergraduate curriculum, and an exchange program for graduate students with a cryptography research group in Germany.","title":"CAREER: Cryptography on Recongfigurable Hardware: Algorithmic and System Aspects","awardID":"9733246","effectiveDate":"1998-07-01","expirationDate":"2002-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["549951"],"PO":["197478"]},"24157":{"abstract":"The objectives of this project are to develop practical tools for online analysis and visualization of experimental video data that should be applicable in both research and teaching laboratories. The system will have a familiar web-based interface, promote collaborative visualization and remote access and take advantage of distributed computing resources to attain near-realtime performance. The system will be particularly oriented towards the seamless acquisition and analysis of video data in order to detech transitions during the running of experiments. Fast display techniques and spatial Karhunen-Loeve reconstructions will be among the techniques implemented to allow experimentalists to map out bifurcation structure as experimental parameters are changed.","title":"Realtime Visualization and Analysis of Scientific Video Data","awardID":"9721348","effectiveDate":"1998-07-01","expirationDate":"2003-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}}],"PIcoPI":["385350"],"PO":["551992"]},"32660":{"abstract":"EIA-9810146 Freeman, Peter Computing Research Association Special Project: CRA Executive Fellowship Program Administrative Support This award to Computing Research Association will support the administrative costs of an Executive Fellowship program to identify and then arrange for a one-year assignment of senior university faculty at high levels within Federal agencies, to assist in the development of strategy and policy related to information technologies. Two positions will be established in FY1998, four in FY1999, and 6 in FY2000.","title":"Special Project: CRA Executive Fellowship Program Administrative Support","awardID":"9810146","effectiveDate":"1998-07-01","expirationDate":"2004-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["183382","334792","208531"],"PO":["371077"]},"33661":{"abstract":"This CISE Educational Innovation award provides support to develop, test and disseminate innovations in the computer engineering undergraduate curriculum at this institution to emphasize real-time information processing systems to introduce undergraduate students to the areas of signal processing, image processing, cognition, human-computer interaction, and computer technology, in preparation for transition to graduate study or to industry. This laboratory builds on the existing and developing laboratories in Interactive Design and in Microcomputers. The institution has a strong record of involvement with underrepresented groups and that will continue in this project. Further, the project is planned such that key components will be able to be replicated at other institutions at reasonable cost.","title":"Educational Innovation: A Software\/Hardware Integrated Approach for Real-Time Information Processing and Computer Design","awardID":"9812636","effectiveDate":"1998-07-15","expirationDate":"2002-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["420405","558105","256830","333704","435839"],"PO":["289456"]},"27821":{"abstract":"For over thirty years, computational complexity theory has provided the computer science community with a theoretical backbone from which one can understand the power of computation. Computational complexity has produced the tools that allows one to understand what likely can and cannot be computed in a reasonable amount of time and memory. This research will continue this tradition. While this research will look at a wide range of problems in many different areas of computational complexity it will focus on two interesting directions. The project first looks at a new model of computation, quantum computing. Computer scientists have recently discovered the powerful applications of the cancellation effect of quantum physics. Though these quantum computers do not yet exist, nice theoretical models of these machines allow study of their complexity. The research will look at ways to apply the cancellation effects in the well-studied area of counting complexity to help the understanding of the complexity of quantum computation. The research will also embark on a more ambitious plan of attempting complexity class separation, one of the most important and least successful directions in the area. In particular, the research will try to show languages in computable in nondeterministic polynomial time, such as the famous traveling salesman problem, cannot be computable in (logarithmic) amount of space. The research well use tools recently developed by the PI of simulating space and time by alternation and applying Post's program of looking at properties of these and other classes. By understanding the relationship among complexity classes, one can better understand the nature of computation and provide the necessary directions one needs to solve problems on various models of computation. This research will help strengthen the theoretical foundations from which computer science stands.","title":"Topics in Complexity Theory","awardID":"9732922","effectiveDate":"1998-07-01","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["557660"],"PO":["543507"]},"27854":{"abstract":"Future wireless systems based on Code Division Multiple Access (CDMA) schemes will impose stringent interference rejection requirements at the receiver's front end. The development of appropriate signal processing algorithms to suppress multiuser interference is an essential factor in the success of third generation wireless networks. The objective of research is to explore the connections between interference rejection problems appearing in wireless, multiuser communications and classical signal processing concepts like array processing and multichannel deconvolution. By developing those links and establishing a DSP framework for multiuser communication problems, we will facilitate the application of a large body of DSP algorithms and research results to those problems. Similarly, the integration of communication and DSP links in the Electrical Engineering curriculum provides the students with a global understanding of DSP aspects of wireless communication systems. The first research goal is to develop appropriate discrete-time models for multiuser CDMA systems with chip rate sampling, and identify the analogies with well established array processing models. The second objective is to develop simple, adaptive, linear receivers based on these models, which are self-recovering, yet attain a performance comparable to that of the trained MMSE receiver. These blind solutions borrow ideas from standard array processing techniques like Capon and MVDR beamforming. The educational goal of this work is to promote linear deconvolution ideas as a significant and unifying component in the systems thread of the EE curriculum. This component is introduced in various courses through laboratory and design work. The approach is based on developing an innovative lab infrastructure which allows remote experimentation and capitalizes upon the campus networking resources. Additionally, a focus on ``signal processing for communications'' is being developed in the graduate and under graduate curriculum through course development and restructuring.","title":"Career: Multichannel Deconvolution Techniques in Multiuser Wireless Communication Systems","awardID":"9733048","effectiveDate":"1998-07-15","expirationDate":"2002-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["126034"],"PO":["564898"]},"34059":{"abstract":"9813820 Engineering of systems with computerized components is an important research area for better quality systems as well as speeding up the construction process. Building quality computer systems that can meet user needs effectively and reliably is currently a major problem. Formal methods that can be partially or completely automated provide a promising approach to this problem. A three-day workshop on this subject is proposed, to take place in Carmel. The purposes of the workshop are to identify criteria for determining potential practical impact of automatable methods for engineering of computer based systems, to assess current research efforts in this area, to identify results and directions that can increase the degree of automation, to aid tool integration by building a common understanding, and to increase the practical use of formal methods via automation.***","title":"Workshop: Engineering Automation for Computer-Based Systems on October 26-29, 1998 at Carmel, CA","awardID":"9813820","effectiveDate":"1998-07-01","expirationDate":"1999-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["157430"],"PO":["150697"]},"26458":{"abstract":"This research is to develop a high level, semi-automated process for validating models. The approach is based on the principle of modeling the environment surrounding the system that the model represents. There are four objectives: 1) developing initial sensor models with high-level graphics- based tools that allow one to concentrate on the system mathematics to insure sensor model correctness, 2) refining sensor models over time into a library structure, 3) exploring automated mechanisms for requirements capture and processing and linking the model validation system to specification requirements, and 4) creating a goal tree based test planning system to guide the selection of and development of model tests. Validation of VHDL models of DSP algorithms is being done under this research.","title":"System-Level Model Validation","awardID":"9729168","effectiveDate":"1998-07-01","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":[66605,66606],"PO":["564898"]},"27558":{"abstract":"The development of numerical methods for large algebraic systems is central in the development of efficient codes for computational fluid dynamics, elasticity, and other core problems of continuum mechanics. Many other tasks in such codes parallelize relatively easily. The importance of the algebraic system solvers is therefore increasing with the appearance of parallel and distributed computing systems, with a substantial number of fast processors, each with relatively large memory. A very desirable feature of iterative substructuring and other domain decomposition algorithms is that they respect the memory hierarchy of modern parallel and distributed computing systems, which is essential for approaching peak floating point performance. The development of improved methods is, together with more powerful computer systems, making it possible to carry out simulations in three dimensions, with quite high resolution, relatively easily. This work is now supported by high quality software systems, such as Argonne's PETSC library, which will facilitate code development as well as the access to a variety of parallel and distributed computer systems. Work willcontinue in developing iterative substructuring and other domain decomposition methods for increasingly difficult partial differential equations. Domain decomposition algorithms are iterative methods, often of preconditioned conjugate gradient type, for the parallel solution of the large linear, or nonlinear, systems of algebraic equations that arise when partial differential equations are discretized by finite elements, finite differences, or spectral methods. In each iteration step, local problems representing the restriction of the original problem to a potentially large number of subregions are solved approximately. The subregions, which can be allocated to individual processors of a parallel computer, form a decomposition of the entire domain of the problem. In addition, the inclusion of a coarse proble m often substantially increases the efficiency of the preconditioner. This study will combine mathematical analysis with the design and numerical testing of algorithms. A special emphasis will be placed on the study of spectral elements and other high order finite element methods, as well as on nonconforming methods such as the mortar and Nedelec finite element methods. The latter have been developed for Maxwell's equation. There will also be a focus on the often very ill-conditioned problems which arise in finite element approximations of elasticity. Iterative methods and production codes will also be developed for Helmholtz's equation and other time-harmonic models arising, e.g., from Maxwell's equations. These problems pose very real challenges for the development of iterative solvers and are also of great importance in a number of engineering applications.","title":"Iterative Substructuring Methods for Elliptic Problems","awardID":"9732208","effectiveDate":"1998-07-15","expirationDate":"2002-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["517232"],"PO":["179846"]},"27867":{"abstract":"The proposed research investigates techniques to enhance the dual properties of robustness and adaptivity in communications systems. Robustness allows the same transmission to work consistently well for a wide variety of channel conditions while adaptivity permits transmitter specialization to match estimated channel and traffic conditions. We propose investigation of five specific techniques for improving robustness and adaptivity in practical systems. First, we will develop new high-rate robust trellis codes to meet industry needs for robustness in digital audio broadcast and asymmetric digital subscriber loops. Second, we will identify new families of rate-compatible trellis codes that provide rate flexibility for transmissions employing large constellations. Third, we will explore the application of concatenated codes and iterative decoding (i.e. turbo codes) to the robust coding problem. The fourth topic is the investigation of channel estimation for robust and rate-compatible trellis codes, and the fifth topic is an examination of how channel estimation accuracy affects the information rates achievable with Tomlinson-Harashima precoding.","title":"CAREER: Robust Coded Modulation for Fading Channels and Rate-Compatible Puncturing","awardID":"9733089","effectiveDate":"1998-07-01","expirationDate":"2003-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["562262"],"PO":["188393"]},"26778":{"abstract":"This project is driven by recent applications of mathematical programming to machine learning, data mining, medical diagnosis and prognosis and include the following problems: FEATURE SELECTION: This is the problem of discriminating between two finite sets in n-dimensional feature space by a separating plane that utilizes as few of the features as possible. A step function that appears in the objective of a linearly-constrained mathematical programming reformulation is approximated by a concave exponential on the nonnegative real line. This leads to a very fast iterative linear-programming-based algorithm that terminates in a finite number of steps. Extensions to minimum- support solutions of linear systems and complementarity problems and neural networks with minimal number of hidden units will be investigated. CLUSTERING: The clustering problem of determining k centers in n- space such that the sum of distances of each of m given points to its nearest center is minimized. A 1-norm distance is used in order to formulate the problem as that of minimizing a piecewise- linear concave function on a polyhedral set. A finite successive linear approximation algorithm terminates very quickly at a stationary point which, for breast cancer medical databases, is extremely useful as a mining tool for distinct survival curves. Extensions to clustering around other geometric entities such as planes or convex sets, clustering with feature selection and applications to knowledge discovery in medical databases will be pursued. ROBUST REPRESENTATION: Relations within a database will be modeled in a manner that remains valid when the database changes moderately. A simple linear model shows that if a sufficiently small error is PURPOSELY TOLERATED in constructing the model, then for a broad class of perturbations the model will be a more accurate than one obtained by a conventional zero error tolerance. The effect of feature selection within tolerant training, as well its use to improve generalization in neural networks will be studied.","title":"Applied Mathematical Programming","awardID":"9729842","effectiveDate":"1998-07-01","expirationDate":"2002-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["277902"],"PO":["179846"]},"30573":{"abstract":"In the past 40 years, spline functions (in their simplest form,<br\/>piecewise polynomials) have become a well-established<br\/>computational tool, and are now widely used by scientists<br\/>and engineers. They are used for a variety of purposes,<br\/>including approximating curves and surfaces,<br\/>fitting data, computer-aided geometric design (CAGD),<br\/>computer-aided manufacturing (CAM), solution of differential equations,<br\/>image processing, etc. The aim of this research is to continue to develop<br\/>the theory and applications of splines,<br\/>and to create and test algorithms for solving some specific<br\/>applications problems, especially problems arising in<br\/>CAGD, CAM, geology, geophysics, and meteorology.","title":"Theory And Application of Splines","awardID":"9803340","effectiveDate":"1998-07-01","expirationDate":"2001-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1266","name":"APPLIED MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["529384"],"PO":["370317"]},"33477":{"abstract":"Networks of workstations are poised to become low-cost alternatives to massively parallel processors. Such networked systems rely on high-performance router switches that efficiently utilize available network bandwidth. Irregularities in the distributed system owing to arbitrary interconnection topology, disparate link length, variable traffic demands (real-time, bursty, best-effort), etc., can significantly complicate high-performance routing. This project develops and implements efficient deadlock-free adaptive routing techniques applicable to irregular networks. Research activities being carried out under this grant include (a) developing classification schemes for irregular topologies useful for characterizing message blocking\/deadlock phenomena and evaluating performance, (b) developing efficient deadlock-free routing algorithms applicable to irregular NOW-type networks, and (3) developing router switch architectures that maximize routing adaptivity, minimize latency, and utilize bandwidth efficiently over long and variable-length network links.","title":"Efficient Adaptive Techniques for Irregular Switch-based Networks","awardID":"9812137","effectiveDate":"1998-07-15","expirationDate":"2002-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["325495"],"PO":["197478"]},"27812":{"abstract":"Basic research in theoretical computer science is studied. Fundamental questions, about the analysis of algorithms and complexity theory are researched. This seminar series focuses on inviting distinguished outside speakers who are able to give an overview of a research area to first and second year graduate students. It is hoped that the interaction between graduate students, researchers in the DC metropolitan area, and outside visitors will be very productive and useful in stimulating new research and facilitating new collaborations. Students will also get an opportunity to present their work to the faculty. A special effort will be made to involve honors undergraduate students in this endeavor.","title":"Capital Area Theory Seminar","awardID":"9732907","effectiveDate":"1998-07-01","expirationDate":"2000-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["69811","538795","538796"],"PO":["150516"]},"37867":{"abstract":"The purpose of the workshop is to discuss and develop a plan for a research program to advance the state of the art in speech synthesis technology. A group of participants will include government, industry, and academic representatives, who have expertise in a number of areas directly or indirectly related to speech synthesis. The workshop program includes both plenary and breakout sessions, with presentations from many of the participants. The focus will be on identifying key technology during the first day and on developing new ideas for evaluation and research infrastructure needs during the second day. A report of the workshop findings will be presented to the sponsors and the public.","title":"Workshop for Discussing Research Priorities and Evaluation Strategies in Speech Synthesis","awardID":"9872796","effectiveDate":"1998-07-01","expirationDate":"1999-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}}],"PIcoPI":["562965"],"PO":["565227"]},"27428":{"abstract":"This research project in theoretical computer science focuses on problems in two interrelated areas: algorithms for graph problems, and the design of data structures. The common theme is the investigation of efficient computation in these area. The goals are to generate improved techniques, and characterize significant complexity relationships. A central issue is the efficient coordination of the acquisition of information during a complex computational task. Three problems concerning graphs are being investigated: (1) balancing competing demands. An example is finding a spanning tree of a graph subject to balancing mutually contending terms in the objective function. (2)The sensitivity of algorithmic solutions to changes in the problem input. (3) Search strategies for relocatable objects in graphs. In addition, the project investigates data structures for dynamic maintaining of information about graphs.","title":"Graph Algorithms and Data Structures","awardID":"9731758","effectiveDate":"1998-07-01","expirationDate":"2002-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":[69168],"PO":["528421"]},"31894":{"abstract":"EIA9807619 John K. Flanagan Brigham Young University Experimental Systems: A National Trace Collection and Distribution Resource. Trace-driven simulation is an important technique for research in computer architecture and compiler design. A trace-driven simulation uses actual execution traces as input to a compuer system simulator that can estimate resource usage or execution time. If both the system model and the input trace data represent the system under test, trace-driven simulation can be very accurate. This project collects and distributes accurate and representative trace data from a variety of computer systems running various operating systems and application workloads. Trace data is collected using commercial logic analyzers and a previously developed hardware monitor, which has successfully collected traces with billions of addresses from a variety of machines. Once collected, traces are managed and stored using large disk arrays and automated tapes, and are made available to users through the World-Wide Web, on tape, and on CD-ROM.","title":"CARE: A National Trace Collection and Distribution Resource","awardID":"9807619","effectiveDate":"1998-07-15","expirationDate":"2003-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4725","name":"EXPERIMENTAL SYSTEMS\/CADRE"}}],"PIcoPI":["233444"],"PO":["241298"]},"31311":{"abstract":"9805602<br\/>Todd<br\/><br\/>The goal of this project is to continue a broad set of ongoing studies concerning optimization algorithms and the mathematical theory underlying them. The project covers continuous and discrete optimization algorithms, both exact and approximate, their computational complexity, practical large-scale implementation, performance guarantees (in the case of approximate algorithms), and applications in such areas as crew-scheduling, image-processing, facility location, financial modeling, electrical power systems, and statistical learning theory.<br\/><br\/>The research to be conducted can be roughly grouped into three areas. The first is interior-point methods, including the study of: semidefinite programming, algorithm design and analysis; infeasible-interior-point methods for both linear and convex programming, including detection of infeasibility; the complexity of target-following methods and of semidefinite programming; and methods for large-scale nonlinear problems arising in image-processing, financial modeling, and statistical learning theory. The second area of research is combinatorial optimization, encompassing: investigation of stable-set and crew-scheduling problems; the study of linear congruence relations and their use in branch-and-cut methods; analysis of inconsistent linear inequality systems, with applications in computer vision, data compression, and statistical discriminant analysis; and design of approximation algorithms for facility location problems. The third is concerned with numerical linear algebra, and will study: methods to solve the linear systems that arise at each iteration of an interior-point semidefinite programming algorithm in a stable manner; and special methods for obtaining accurate solutions to ill-conditioned linear systems arising in electrical power systems.<br\/><br\/>This research will lead to improved algorithms to find exact or approximate solutions to large-scale optimization problems arising in industry, finance, the military, science, and engineering. Emphasis is placed on the interplay between practice and theory.","title":"Computational and Mathematical Investigations in Optimization","awardID":"9805602","effectiveDate":"1998-07-15","expirationDate":"2002-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0706","name":"Division of DESIGN & MANUFACTURING INNOV","abbr":"DMI"},"pgm":{"id":"5514","name":"OPERATIONS RESEARCH"}}],"PIcoPI":["392859",78948,78949],"PO":["565027"]},"37724":{"abstract":"Abstract CTS-9871919 Cummings This is a grant to undertake a fundamental study of lubrication at manometer scale, including experiments with surface rheometry and non-equilibrium molecular dynamics simulation. The project will be a multi-disciplinary, multi-institutional collaboration. The first goal of the research is to achieve overlap in shear rate between experiments and simulations with the same systems. This overlap, sought for over a decade, will be achieved through significant advances in the capabilities of both the experimental and numerical approaches. A second goal is to extend both the experimental and computational efforts to more complicated systems and surface characteristics, including surfaces with chemical and topographical heterogeneity, that are of primary technological importance. A third goal is to study not only the steady-state shear response of nano-tribology systems but also their transient behavior, including the technologically important issues related to adhesion. A final, but overarching, goal of the work is to seek new methods to reduce the friction and wear of moving surfaces separated by only nanometers. These goals will be attained through coordinated experiments and calculations that probe the fundamental phenomena involved at a molecular level. The motivation for this work is that devices with moving parts separated by only nanometers are already of immense technological and economic importance, magnetic recording devices such as computer disk drives, for example. Many other novel micro-electro-mechanical systems (MEMS), such as micro-motors, are under development. The fluid between the moving surfaces in such devices is subjected to extremely high rates of shear strain, 108 s-1 or higher, more than an order of magnitude higher than previously attained in any controlled experiment. Often, lubrication is essential to the practical use of such devices, and the US data storage industry has identified the development of new lubricants and surf ace finish as one of six major technical objectives to achieving increased recording density and read\/write speed. This project results from a proposal submitted in response to NSF 98-20 Partnership in Nanotechnology: Synthesis, Processing and Utilization of Functional Nanostructures (FNS).","title":"Nanotechnology with Emphasis on Tribology: A Combined Experimental and Simulation Study","awardID":"9871919","effectiveDate":"1998-07-15","expirationDate":"2002-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1406","name":"THERMAL TRANSPORT PROCESSES"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1414","name":"INTERFAC PROCESSES & THERMODYN"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1415","name":"PARTICULATE &MULTIPHASE PROCES"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1443","name":"FLUID DYNAMICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1444","name":"SURFACE ENGINEERING"}}],"PIcoPI":["542671",95699,"466700","156097","156099"],"PO":["255964"]},"33489":{"abstract":"Asynchronous designs are an attractive alternative to synchronous designs due to their lack of clock skew problems, potential for average-case delays, adaptability to physical properties, and power savings. This project focuses on techniques for performance-analysis and performance- driven synthesis that together can facilitate the design of high-performance asynchronous circuits. For performance analysis, the investigator is exploring analytical and simulation-based analysis techniques that can guide architectural design as well as guide controller synthesis tools to optimize for user-specified system performance metrics. For synthesis, the research is leveraging off an existing technology mapping tool that uses minimal system information to identify and then optimize common transitions. By increasing the amount of system information available, selected critical transitions can be optimized. In these designs common transitions need not be critical and critical","title":"Performance-Driven CAD Tools for Asynchronous Circuits","awardID":"9812164","effectiveDate":"1998-07-15","expirationDate":"2001-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["485748"],"PO":["564898"]},"27737":{"abstract":"Self-adjusting data structures have considerable practical importance; they offer efficient performance and they are easy to code since they are not required to enforce structural constraints. This same lack of structural constraints, however, makes it difficult to predict the behavior of these data structures over a lengthy sequence of operations. Recently, and contrary to expectation, the widely used and highly practical pairing heaps data structure has been shown to require more than constant amortized time for the decrease key operation, thus underscoring the need to have better methods for anticipating behavior of self-adjusting data structures. The major focus of this project is the development of such methods. Goals for this project include (i) reaching a definitive understanding of the pairing heap data structure, utilizing both analytical and experimental methods; (ii) the development of a formal theory of self-adjusting data structures, placing them at one end of the spectrum of graded structure with emphasis on obtaining an understanding of the performance limitations that are incurred as structure is diminished; and (iii) an exploration of non-linear amortized analysis for the purpose of predicting the frequency and severity with which time consuming operations can take place.","title":"Understanding Self-Adjusting Data Structures","awardID":"9732689","effectiveDate":"1998-07-15","expirationDate":"2002-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":[69968],"PO":["528421"]},"27979":{"abstract":"Networks of workstations (NOWs) have been emerged as a primary infrastructure for scientific computing. NOWS are currently used to provide desktop sequential computing and visualization, high throughput opportunistic computing of batched sequential jobs, and dedicated parallel computing. In addition, we envision NOWs being used to store and retrieve data sets using scientific database management systems (DBMSs), provide opportunistic computation of parallel programs, allow interactive visualization of large disk resident data sets. The current state of knowledge provides most of the tools to enable this envisioned NOW usage, but lacks the needed scheduling policies. To remedy this, this project will: * Devise new scheduling algorithms to handle mixed workloads of workstations jobs, batched opportunistic sequential jobs, and batched opportunistic parallel jobs. * Characterize scientific DBMS workloads and develop designs on how best to integrate scientific DBMSs into the NOW. * Determine how best to integrate indexing techniques to provide support for interactive visualization of large disk resident data sets. * Develop system wide scheduling policies that are cognizant of all aspects of NOW usage. The goal of such policies is to provide good aggregate performance of all concurrently running applications including computation, visualization, and data access. The proposed work will develop comprehensive analytical and simulation models of NOW performance, including all of the above factors, to determine how to optimize overall performance and will develop a working prototype of the system.","title":"CAREER: of Computational and Data Access Scheduling in NOWs","awardID":"9733658","effectiveDate":"1998-07-15","expirationDate":"2003-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}}],"PIcoPI":["315564"],"PO":["562362"]},"30740":{"abstract":"9803774 Model Checking is an automatic verification technique for finite state concurrent systems such as sequential circuit designs and communication protocols. By using special data structures like Binary Decision Diagrams, it is possible to verify properties of systems with extremely large numbers of reachable states. Although the technique is beginning to be used by companies like Intel, Motorola, and Siemens, additional research is needed to realize the full potential of the method. This project will develop a number of new techniques that should enable larger hardware systems and certain types of software systems such as security protocols and probabilistic programs to be verified. The new techniques involve extending the partial order reduction to permit symbolic model checking of real-time programs, combining model checking and theorem proving, using program slicing to reduce the state explosion problem in model checking, and combining abstraction with binary decision diagrams.***","title":"Automatic Verification of Finite-State Concurrent Systems in Hardware and Software","awardID":"9803774","effectiveDate":"1998-07-01","expirationDate":"2002-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["553671"],"PO":["564388"]},"30212":{"abstract":"With the exploding demand in Internet applications and multimedia communications, image compression has become one of the most important areas in signal processing and communication. Well compressed images are close to the original images, but take much less space to store or are faster to transmit. Indeed, the network computing trend is moving towards high quality images for Web surfing and real- time video for video conferencing, and compression is necessary for their real-time transmission and reasonably small memory storage. Much engineering wisdom and heuristics have accumulated on image compression in recent years, and adaptivity (to the local characteristics of an image) is found to be the key to efficient image compression. This research follows an approach underlying many, if not all, important developments in statistics. That is, it aims at identifying problems from an applied field --(wavelet) image compression, developing their solutions in a statistical framework, and seeking answers and insights in this framework relevant to the original image compression problems. On one hand, this research uses and extends modern statistical estimation theory; on the other hand, it summarizes or formalizes engineering heuristics. Therefore it builds a bridge between image compression and statistical estimation literatures. The investigators are studying adaptive thresholding methods for wavelet image coding from the point of view of denoising and compression. They are also studying estimation and adaptive quantization methods based on quantized data for general digital signal compression including wavelet-based image compression. The statistical research establishes a framework for adaptive wavelet thresholding for images, and provides solutions to the general statistical problem of estimation based on quantized data, which are available in large quantities in the modern communications age. A level of effort statement. At the recommended level of support, the PI will make every attempt to meet the original scope and level of effort of the project.","title":"Adaptive Estimation in Wavelet Image Compression: Thresholding and Quantization","awardID":"9802314","effectiveDate":"1998-07-15","expirationDate":"2002-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"1269","name":"STATISTICS"}}],"PIcoPI":["521186"],"PO":["564898"]},"33655":{"abstract":"EIA-9812623 Stine, Deborah D National Academy of Sciences Special Project: On Being a Scholar in the Digital Age This grant provides support for development of a guide for use by students and faculty which provides advice on issues in regard to the opportunities and implications of conducting research in a digital environment, digital age communications within the research community, and issues associated with new behavioral norms. It addresses a number of points including use of digital libraries and databases, changing research apparatus, collaborative research, use of computation as a third research paradigm (along with theory and experimentation), communication of research, ethical issues, and career patterns.","title":"Special Project: On Being a Scholar in the Digital Age","awardID":"9812623","effectiveDate":"1998-07-15","expirationDate":"2001-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["267507"],"PO":["329035"]},"27859":{"abstract":"The focus of this research project is to develop an integrated compiler and run-time system for global data distribution. The goal is for the integrated system to execute large-scale, multi-phase parallel scientific applications more efficiently than can be done with static analysis alone. First, compiler analysis will be developed to divide a program into its component phases as well as pass useful hints to the run-time system about intra-phase behavior, such as the communication pattern. Second, the necessary run-time analysis will be developed to support multi-phase applications and to make use of the compiler information. A framework will be investigated to determine at run time an efficient global data distribution over a reasonable set of possible distributions. This means that a distribution will be determined for each array in each program phase, with possible redistribution between phases, that results in good application performance. Furthermore, if application characteristics change during execution, the distribution will be changed accordingly. The integrated system will be measured on a variety of large-scale, adaptive parallel scientific programs.","title":"Career: An Integrated Compiler\/Run-Time System for Global Data Distribution","awardID":"9733063","effectiveDate":"1998-07-01","expirationDate":"2003-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["517411"],"PO":["241298"]},"30851":{"abstract":"9804087 Data abstraction is of central concern in program design while ``parametricity'' is a mathematical formalization of this concept. Using parametricity, one can argue that two program modules that export types and operations are equivalent as long as the behavior observable by client programs is the same. In this project, Prof. Uday Reddy addresses key issues of parametricity theory in joint research with Prof. Peter O'Hearn at Queen Mary and Westfield, London. The issues addressed include finding an abstract framework for parametricity that encompasses various programming language phenomena and their mathematical models, integrating parametricity with subtyping type systems, and the application of these results for modeling object-oriented programming with mutable state. The research spans theoretical and practical issues, ranging from abstract categorical frameworks to type systems and practical reasoning principles. The issues addressed are of vital importance for integrating parametricity with the vast body of programming theory developed over the years. Prof. O'Hearn's expertise in parametricity theory will complement Reddy's work in the study of data abstraction aspects of local variables. This collaboration enhances their research effectiveness in addressing issues of mutual interest.***","title":"Parametricity, Abstraction and Objects","awardID":"9804087","effectiveDate":"1998-07-15","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["451105",77846],"PO":["150697"]},"31643":{"abstract":"Two significant components of VLSI manufacturing test cost are the test length, and the reject rate. The latter is the rate at which bad devices escape detection by the test. This research explores a new approach to estimate the reject rate so that optimum balance can be struck between the test length and the reject rate. The approach includes extensions to handle multiple types of tests that are commonly employed by the manufacturers, e.g. stuck-at, IDDQ, delay, and functional. Analytical methods for estimating the reject rate are too complex to capture accurately all interactions among parameters, which leads to unreliable reject rate estimates. In this project an empirical, yet robust model is being developed. It is based on properties observed in tester data that are demonstrated to be invariant for a wide range of manufacturing technologies and types of tests.","title":"Quality vs. Cost Tradeoffs in VLSI Testing: An Empirical Analysis of Sematech Test Data","awardID":"9806795","effectiveDate":"1998-07-15","expirationDate":"2001-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["485828","113161"],"PO":["564898"]},"31346":{"abstract":"9805743 Sameh, Ahmed H. Grama, Ananth Y. Purdue University CISE PostDoc: Computational Methods in VLSI Design This research project will develop innovative computational methods and software for problems in electromagnetics arising in VLSI design. The project focuses on developing robust, effective, and parallelizable solvers and preconditioners for linear systems arising from finite element and boundary element modeling of inductive and capacitive effects in high speed integrated circuits. Techniques based on a hierarchy of representations using multipoles and block low-rank approximations of the coefficient matrix are investigated. The implications of these techniques for approximate inverse preconditioners and multilevel schemes for sparse solvers are also addressed. Portable parallel formulations of the techniques along with theoretical estimates for convergence and parallel performance are targeted. In addition to development of innovative techniques and training of the post-doctoral research associate, this project serves to strengthen the recent initiative in computational electromagnetics at Purdue University. The presence of a post-doctoral researcher in electromagnetics also complements the PIs' areas of expertise, contributing to the interdisciplinary nature of the project.","title":"CISE PostDoc: Computational Methods in VLSI Design","awardID":"9805743","effectiveDate":"1998-07-01","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["501195","540776"],"PO":["564318"]},"26605":{"abstract":"The common good of our information infrastructure depends on well designed network security that is embraced by the public and private sectors. Well designed network security requires well formed technical mechanisms and responsiveness to underlying moral and societal values, as well as a well thought out system of user interactions. In recent years, significant efforts have been directed toward developing the technical dimensions of network security, but little systematic work investigates and integrates the corresponding dimensions of human values and user experience. This collaborative project provides a model of interdisciplinary collaboration that can deepen our understanding of the cognitive, ethical and social implications of new types of inter-activity. It will study and implement security for a network browser that integrates these three key considerations: technical excellence, responsiveness to moral and societal values, and sensitivity to users' perceptions. It will: (1) develop a conceptual framework, or model, for network security that accounts for human values and user experience; (2) design and implement a working prototype of a network security system guided by the conceptual model; and (3) apply the experience of this project toward a better understanding of methodology for the general purpose of designing technology that is responsive to human values. Drawing on the technical, philosophical, and social science expertise of the three investigators, the work will begin with a close study of the network security in existing browsers such as Netscape 4.0 and Internet Explorer 4.0. The goal is to characterize the technical mechanisms, grasp value implications, and understand users' perceptions of these systems. Based on this study, the investigators will develop a conceptual model that represents the interaction among technical characteristics, values supported by (or embodied in) the system, and users' perceptions of their interactive experience with it. This model will guide the next phase of the project: to design and implement a prototype for a security configuration that is explicitly responsive to values and users' perceptions. User studies and further philosophical analysis of the prototype will help to refine the security configuration and, ultimately, to refine and assess the model itself. Through industry contacts and other traditional methods, the investigators will disseminate the results of their study, including the conceptual model, prototype, and aspects of the multidisciplinary methodology they develop.","title":"Collaborative Research: Network Browser Security and Human Values-Theory and Practice","awardID":"9729447","effectiveDate":"1998-07-01","expirationDate":"2002-01-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"7915","name":"Ethics & Values of SET"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["467986","563668"],"PO":["163103"]},"27739":{"abstract":"The models used in inductive inference have their roots in the models used by the philosophers of science who were discussing the scientific method. The goal there, and in prior work in learning theory, was to come up with an explanation of the phenomenon under consideration. However, scientists rarely work directly for the grand goal of a complete explanation, seeking rather the more modest goal of finding features and facts about the observed data. In like manner, this project pursues several modifications to the traditional models used in inductive inference so as to study the pursuit of more modest scientific goals. This study is particularly relevant to contemporary science as automated data generation techniques produce sufficient volumes of data to overwhelm the analysis abilities of humans. The goal of our work is to illuminate precisely what can and cannot be accomplished by automatic data analysis algorithms.","title":"The Capabilities and Limitations of Atomated Discovery","awardID":"9732692","effectiveDate":"1998-07-01","expirationDate":"2001-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["69811","538795"],"PO":["528421"]},"30742":{"abstract":"----------------------------------------------------------------------- Proposal Number: DMS 9803780 PI: James Allen Fill Institution: The Johns Hopkins University Project: Probability and Combinatorial Structures Abstract: The theme of the this research is the study of certain important combinatorial structures using probabilistic methods. One important class of structures is that of self-organizing data structures, which dynamically maintain a file of records in easily retrievable order while using up little memory space and which have been investigated by probabilists and computer scientists for more than 25 years. Such self-organizing systems have been applied to problems in very large-scale integration (VLSI) circuit simulation, data compression, communications networks, and genetics. The research analyzes more realistically complex probability models than have heretofore been treated, and in doing so provides a unifying framework for previous studies. Trees form another important class of combinatorial structures. The investigator analyzes the \"shape\" of random m-ary search trees, fundamental structures in computer science that also arise naturally in connection with self-organizing data structures. The work involves generalizing and analyzing the already large class of recursive trees, which have been used to model such things as the spread of epidemics, family trees of ancient manuscripts, and pyramid schemes. The researcher also develops a continuous-time model for pyramid schemes and derives for it operational characteristics which have not been obtained under the corresponding discrete-time model. Another facet of this work is a generalization of the analysis of the height of an incomplete digital search tree, or trie; the generalization has applications to the election of multiple leaders in a computer network. This work relates clearly to the Federal Strategic Area of high-performance computing and communi cation.","title":"Probability and Combinatorial Structures","awardID":"9803780","effectiveDate":"1998-07-15","expirationDate":"2001-09-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1263","name":"PROBABILITY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["319269"],"PO":["331535"]},"33932":{"abstract":"The purpose of this Small Grants Exploratory Research (SGER) project is to determine the feasibility of combining tools from (discrete) computational geometry and (continuous) analytic computations using theory of R-functions. Specific tasks to be accomplished during this exploratory study are: 1. development and implementation of algorithms for automatic construction of (implicit) real-valued functions for objects represented by Boolean and\/or boundary representations; 2. conduct experiments to verify computational and numerical properties of constructed functions predicted by the theory. The results of these explorations will be used to define and undertake a significantly larger scale effort to develop a computational environment for modeling and solving engineering and scientific problems. The unique feature of such an environment will be seamless integration of geometric and analytic computations.","title":"Explorations in Constructive Analytic Geometry","awardID":"9813507","effectiveDate":"1998-07-01","expirationDate":"2000-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["560677"],"PO":["179846"]},"30478":{"abstract":"Bin Yu<br\/>DMS 9803063<br\/><br\/>Hyperspectral data consist of intensity readings of hundreds of bands from ground or airborne spectrometers. The proposed research is to identify forest species by means of (1) hyperspectral data measured directly from above forest canopies in the field, and (2) hyperspectral data from airborne instruments based on the understanding from part (1). This research is motivated by the belief that the rich amount of spectral information contained in hyperspectral data should improve the level of discrimination of forest species and by the desire for a relatively simple method that can handle the large number of spectral bands in hyperspectral data while tolerant of spectral noise. Data reduction will be carried out via nonparametric techniques such as spline fitting and penalized discriminant analysis (PDA) for interpretation and classification purposes. Model selection criteria derived from the Minimum Description Length (MDL) principle will be investigated as both general model selection tools and criteria for spline knots selection and band selection for data reduction based on curve data. Spatial PDA will be developed to classify hyperspectral images from airborne spectrometers to take into account the spatial dependence of pixels in the image.<br\/><br\/>Correct recognition of forest species is important in natural resource management, environmental protection, biodiversity and wildlife studies. Conventionally reliable methods for tree species recognition depend mainly on inventory in the field or on interpretation of large-scale aerial photographs. The use of these methods is frequently limited by cost and time and not applicable to large areas. Digital remote sensing has been used to identify forest species of large areas, but two problems are encountered: different tree species often have similar spectral characteristics partly due to the lack of high spectral resolution and lack of large number of spectral bands; and the same tree species may have distinct spectral properties due to illumination conditions on which optical remote sensing is based.","title":"Discriminant Analysis of Hyperspectral Data for Bio Species Recognition","awardID":"9803063","effectiveDate":"1998-07-01","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1269","name":"STATISTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0504","name":"Division of MICROELECTRONIC INFOR PROCESS","abbr":"MIP"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["521186"],"PO":["331535"]},"31028":{"abstract":"Information theory celebrates its 50-th birthday. Although it is a mature area of research by any standard, new challenges arise due to new applications and new theoretical developments. (For example, there is a resurgence of interest in source coding for multimedia applications.) In the 1997 Shannon Lecture Jacob Ziv presented compelling arguments for \"backing off\" to a certain degree from the (first-order) asymptotic analysis of information systems in order to predict the behavior of real systems where we always face finite (and often small) lengths of sequences, files, codes, etc. One way to overcome these difficulties is to increase the accuracy of asymptotic analysis by replacing first- order analyses (e.g., a leading term of the average code length) by full asymptotic expansions and more accurate analyses (e.g., large deviations, central limit laws). We propose to accomplish this goal by exploring problems of information theory by analytic methods, that is, those in which complex analysis plays a pivotal role. Among others we propose research on lossless Lempel-Ziv schemes, lossy extension of Lempel-Ziv schemes (based on approximate pattern matching), context quantization (which aims at extending context-tree weighting to the lossy environment), prediction schemes based on pattern matching, and hierarchy of redundancy rates. Analytic methods discussed here are: asymptotic analysis of functional-differential equations, poissonization and depoissonization, and complex asymptotics.","title":"Towards Analytic Information Theory: Data Compression, Prediction and Universal Coding Through Analytic Methods","awardID":"9804760","effectiveDate":"1998-07-01","expirationDate":"2003-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["425343"],"PO":["188393"]},"27608":{"abstract":"Numerous applications in sciences, engineering and mathematics give rise to problems involving structured matrices such as Toeplitz, Hankel, Vandermonde, controllability, observability, Cauchy, Bezoutians, along with many other patterns of structure. In many of these applications the use of standard mathematical software tools (such as MATLAB, Mathematica, Maple, LAPACK, etc.) is not appropriate, because their ignoring of structure requires unnecessary storage as well as an extremely large amount of CPU time. Secondly, many structured matrices, e.g., Hankel, Pick, Hilbert, Vandermonde, are extremely ill- conditioned, so that all available standard methods often fail to produce even one correct digit in the computed solution. The objective of this project is the study of theoretical and computational problems related to structured matrices which arise in several applied areas, including signal and image processing, system theory, and control theory. New accurate fast and superfast algorithms will be developed for several new classes of structured matrices, arising in rational matrix interpolation and approximation problems with norm constraints, in Gaussian quadrature as well as in signal and image processing. Along with these direct methods, the approach will be used to design new classes of preconditioners based on discrete real transforms to speed- up the convergence of the conjugate gradient method for block Toeplitz-plus-Hankel matrices.","title":"Fast and Accurate Algorithms for Structured Matrix Computations","awardID":"9732355","effectiveDate":"1998-07-01","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["290781"],"PO":["179846"]},"30611":{"abstract":"Hyperbolic systems of conservation laws arise in many problems where the<br\/>conservation of physical quantities such a mass, momentum, and energy are<br\/>modeled. These equations must typically be solved by approximate numerical<br\/>methods. Discontinuities in the data and\/or solution (e.g. shock waves)<br\/>cause difficulties in developing accurate and stable methods. <br\/><br\/>This proposal concerns the development of high-resolution methods and their<br\/>implementation as software that can be widely used in solving problems<br\/>that arise in many different fields. The P.I. has been actively<br\/>involved in developing the CLAWPACK and AMRCLAW software for<br\/>multi-dimensional hyperbolic systems. This software is freely<br\/>available and allows students and researchers studying a wide range of<br\/>phenomena to use the technology of high-resolution methods and adaptive<br\/>mesh refinement. This software will be further developed and used to<br\/>explore a number of particular applications in science and<br\/>engineering. One application concerns computing acoustic or elastic<br\/>waves in heterogeneous media. Such problems often arise in geophysics<br\/>and materials science, for example. Another application is to<br\/>numerical relativity, where there is interest in simulating<br\/>gravitational waves that may soon be detectable by astronomers.<br\/>This can be accomplished by using a hyperbolic formulation of the Einstein<br\/>equations.","title":"Numerical Methods for Conservation Laws","awardID":"9803442","effectiveDate":"1998-07-01","expirationDate":"2001-12-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1266","name":"APPLIED MATHEMATICS"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}}],"PIcoPI":["517341"],"PO":["209579"]},"31338":{"abstract":"The PIN diode is a semiconductor device used in a wide variety of applications such as high frequency communications circuits and high power generation equipment. This project is developing and testing a general CAD model for the PIN diode. The model is applicable to PIN diodes made of either elemental semiconductors or compound materials. The project builds upon current and past modeling efforts to develop a model for the PIN diode that can be incorporated into SPICE-like simulators. The project work also includes exploring a methodology for extracting simulator modeling parameters from experimental measurements. Undergraduate students are being involved in the project to develop automated test equipment, measure various semiconductor devices at both dc and high frequency, and creating and maintaining a web site for dissemination of research results.","title":"RUI: CAD and Modeling of High Power High Frequency Devices","awardID":"9805718","effectiveDate":"1998-07-15","expirationDate":"2002-06-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"5979","name":"CENTRAL & EASTERN EUROPE PROGR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["182743"],"PO":["201974"]},"33648":{"abstract":"This award supports a workshop on Distributed Information, Computation, and Process Management for Scientific and Engineering Environments, held in Herndon, VA on May 15-16, 1998. The workshop organizer is Professor Nicholas M. Patrikalakis from MIT. Workshop participants are researchers in the field of computer science and domain specialists from the sciences and engineering disciplines. Advances in the research on complex physical and man-made systems, especially those exhibiting interacting dynamic processes and disparate spatial and temporal scales, generate new requirements for information and computational environments and infrastructure. Towards the goal of satisfying these requirements, the primary topics of the workshop include the application of digital library technology for scientific simulation; the design and implementation of cross-domain simulation integration; metadata models and search\/retrieval mechanisms for scientific software; networking issues for transparent access and sharing of data, including automatic generalized data translation and remote software invocation; and emerging standards for distributed simulations. The goal of the workshop is to stimulate research activities in fundamental technologies that will enable easy access to distributed computational, data and various information resources by scientists and researchers in diverse fields. The workshop will produce an advisory document outlining open problems and proposed avenues of research in distributed simulation, analysis, and information systems. The report will be widely disseminated and also available on-line. The application of further research efforts along these lines will help to increase the availability, effectiveness, and utilization of large-scale, cross-disciplinary distributed scientific systems, and facilitate research activities. http:\/\/deslab.mit.edu\/DesignLab\/dicpm\/","title":"Invitational Workshop on Distributed Information, Computation, and Process Management for Scientific and Engineering Environments","awardID":"9812601","effectiveDate":"1998-07-01","expirationDate":"1999-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0604","name":"Division of OCEAN SCIENCES","abbr":"OCE"},"pgm":{"id":"5740","name":"CLIMATE & LARGE-SCALE DYNAMICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"1519","name":"INTEGRATIVE SYSTEMS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"4725","name":"EXPERIMENTAL SYSTEMS\/CADRE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"1442","name":"CONSTRUCTION AND INFRASTRUCTUR"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1100","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"14","name":"Office of OFFICE OF POLAR PROGRAMS                ","abbr":"OPP"},"div":{"id":"1401","name":"Division of ARCTIC SCIENCES DIVISION","abbr":"ARC"},"pgm":{"id":"5240","name":"INFORMAT & ADVIS SVC(ARCTIC RE"}}],"PIcoPI":["317581"],"PO":["563751"]},"27818":{"abstract":"Research will be conducted on lock-free and wait-free shared- object algorithms for multiprogrammed systems in which several processes may execute on the same processor. In such systems, process delays are quite common, due to preemptions. Most lock- based synchronization algorithms perform poorly in the face of such delays, because a delayed process holding a lock can impede the progress of other processes waiting for that lock. Furthermore, lock-based algorithms are susceptible to problems such as deadlock and priority inversion. Lock-free and wait-free algorithms do not suffer from these problems. Previous research on lock-free and wait-free algorithms has almost exclusively focused on asynchronous execution models in which processes may interleave arbitrarily. Such models can be a hindrance when designing algorithms for multiprogrammed systems, because they force interleavings to be considered that cannot arise. What is needed is a new framework for lock-free and wait-free synchronization directed toward multiprogrammed systems. The main objective of this project is to develop such a framework. This framework will be established through a combination of research on lock-free and wait-free algorithms for multiprogrammed systems, and lower-bound results relevant to the development of such algorithms. The framework will be experimentally evaluated using simulation models, synthetic workloads, and real-world applications.","title":"Lock-Free and Wait-Free Synchronization in Multiprogrammed Systems","awardID":"9732916","effectiveDate":"1998-07-15","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["31436"],"PO":["250083"]},"33957":{"abstract":"The International Conference on Multiagent Systems, being held July 4-7, 1998 in Paris, has as its purpose bringing together researchers in the important area of agent-based software design, a major factor in the successful exploitation of the World Wide Web, digital libraries, and electronic communities, among other applications. This grant will provide travel funds for representation of American research, including some graduate students, at the conference and its related workshops collectively called \"Agents World\". http:\/\/euler.mcs.utulsa.edu\/~sandip\/ http:\/\/cosmos.imag.fr\/MAGMA\/ICMAS98","title":"Support for International Travel to Conference on Multiple Agents","awardID":"9813573","effectiveDate":"1998-07-01","expirationDate":"1999-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["362927"],"PO":["495796"]},"30239":{"abstract":"The goals of this research are to bring new implicit polynomial 2D curve and 3D surface object recognition concepts to a state of general usefulness to researchers in computer vision and image processing, and to develop computationally-fast shape-based indexing into 2D image and 3D image databases. The approaches to be used include new fitting concepts and algorithms, new types of invariants, new concepts and algorithms for single-computation pose estimation for implicit polynomial 2D curves and 3D surfaces, and indexing by matching rich sets of 2D curvelets or rich sets of 3D surface patchlets with those that have been autonomously extracted and stored in the image databases. This work will assess the value of implicit polynomial methods for modeling and making inferences about object shape in 2D and 3D data. The research will also produce useful tools for the research community for applications, and will provide an understanding of the strengths and weaknesses of this technology. Searching and indexing into image databases is a rapidly growing activity in science and commerce. This project will provide an understanding of the geometric shape-based indexing accuracy and speed and the automation of database preparation possible with the new implicit polynomial methodology.","title":"REU: Implicit Polynomial Technology for Computer Vision and Image\/Video Databases","awardID":"9802392","effectiveDate":"1998-07-01","expirationDate":"2002-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["520864"],"PO":["179262"]},"33649":{"abstract":"ABSTRACT: CMU, Bonnie John, PI<br\/><br\/>This CISE Educational Innovation award provides funds to support the design, implementation, evaluation and dissemination of a new introductory-level course in computing which teaches the Strategic Use of Computer Systems. This strategic knowledge has been developed under a 1994 NSF Young Investigator Award to the PI. It helps users decompose tasks effectively and efficiently with respect to the powers and limitation of their computer tools and has been shown to produce significant improvements in productivity. The new course is being developed with a pilot section of students in the Computing Skills Workshop (CSW) course at CMU beginning in 1999 and is expected to then be adopted by all of the CSW sections in the next year. The project has the potential to make major impact on undergraduate education in computing at a national level.","title":"Educational Innovation: The Strategic Use of Complex Computer Systems","awardID":"9812607","effectiveDate":"1998-07-15","expirationDate":"2003-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["413598",84660],"PO":["565090"]},"30845":{"abstract":"9804067 Managing the process of developing and maintaining software has become the focus of organizations that need to deliver reliable software in a cost-effective manner. To this end, two orthogonal directions have been pursued: industry has developed standards, while academic research efforts have focussed on formal models. The goal of this research is to integrate these two approaches through data analysis and measurement. In this project, new techniques are devised for combining process data analysis with process models, including analysis of concurrent behavior, attribute relations, and real-time performance of processes. In addition, an existing framework for process data analysis is extended to provide support for these new methods, and tools are constructed embodying these new techniques. Evaluation of the new methods is undertaken by applying them to industrial, real-world data, in conjunction with industrial collaboration. Providing these techniques will empower those who develop software to maintain truly optimizing processes---the rigorous framework of a formal model allows the data analysis to measure the process in an unambiguous manner, thus feeding back clear and insightful information to the process. In addition to this practical impact, this project will enhance and extend the scientific knowledge of the process of developing reliable software systems.***","title":"Software Process Analysis: Integrating Models and Data","awardID":"9804067","effectiveDate":"1998-07-01","expirationDate":"2002-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["557313"],"PO":["397849"]},"33727":{"abstract":"Advanced networking infrastructure initiatives, such as that represented by NSF's vBNS or the government's Next Generation Internet initiative, are typically accessible in their early stages only to a small number of leading research institutions of higher education. Though dissemination of results is an expected outcome of these initiatives, it can be extremely difficult for the rest of higher education, in very practical terms, to replicate the experiences of the early adopters and developers. Typically, those who follow require information, consultation, and other services of a rather intense and dedicated, case-by-case type. The intent of this proposal is to seed the establishment of such a service, through the formation of an outreach program, that would help to grow the involvement of more of higher education and related communities in the use and implementation of emerging high performance research and education networks.","title":"National Outreach Program for Advanced Networking in Higher Education","awardID":"9812797","effectiveDate":"1998-07-01","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4091","name":"NETWORK INFRASTRUCTURE"}}],"PIcoPI":["84879","427208","43608"],"PO":["198445"]},"26907":{"abstract":"ABSTRACT NCR-9730162 Eric Friedman Rutgers University with a subcontract to Scott Shenker Xerox PARC Learning and the Design of the Internet This project will study some foundational issues in the application of game theoretic ideas to the design of the Internet and other decentralized networks. Many researchers apply game theoretic ideas to the analysis of the modern Internet and in particular assume that Nash equilibria will arise in this setting. Based on recent theoretical analyses and simulations, the PIs on this project have found that convergence to Nash equilibrium is not guaranteed in Internet-like environments, due to limited information, noise, and asynchrony. This calls into question the application of the Nash Implementation\" on the Internet and makes the design of mechanisms, which are robust to learning by adaptive agents, much more problematic. The goal of this project is to understand precisely what kinds of mechanisms are learnable on the Internet and use this to design protocols and price mechanisms that implement socially desirable outcomes under this constraint. For example, preliminary results show that the FIFO queuing protocol is not learnable while fair queuing can be learned quite easily by adaptive agents. In particular, the PIs previous work has begun to identify the set of outcomes that are attained by adaptive learners. This set contains the Stackelberg undominated actions and is contained within the serially unoverwhelmed set. Several important mechanisms work in these settings, e.g. fair queuing, the uniform mechanism, fixed path methods, and also many problems with enough players and capacity, in addition the PIs have just begun to analyze the general implications of these results for general design problems. For example only strictly coallitionally strategy-proof social choice functions are implementable on the Internet. However, there still remain many open questions, which this project will attempt to resolve. This project also has i mplications for Economics and Game Theory. Besides the Internet, there are many decentralized systems in Economics for which we believe these results are applicable. In particular, oligopolists, joint producers, and polluters operate asynchronously with limited observability and often with little knowledge of the underlying payoff matrix. This project should increase our understanding in these settings. This project will utilize three complementary methodologies: i) A continuing theoretical and analytical study of these issues ii) this will be complemented with computer simulations, and iiii) experiments with human subjects who will be studied under settings designed to mimic the scenarios faced by actual users on the Internet. The interplay of these three approaches should help create a robust and realistic theory for designing learnable mechanisms for the Internet.","title":"Learning and the Design of the Internet","awardID":"9730162","effectiveDate":"1998-07-01","expirationDate":"2001-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"1320","name":"ECONOMICS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"1321","name":"DECISION RISK & MANAGEMENT SCI"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["516972","560562"],"PO":["250082"]},"31638":{"abstract":"9806777 Cross, James H. Hendrix, T. Dean Auburn University Experimental Software Systems: Scaleable Visualizations to Improve and Measure Comprehensibility of Software Systems: A Framework for Evaluation Software visualization is an active area of research that investigates efficient and effective ways of automatically producing graphical representations of program source code, algorithms, or the runtime behavior of software. The investigators have designed and implemented a set of new scaleable graphical representations which specifically addresses problems with other static visualizations reported in the literature. This research focuses on the experimental evaluation and refinement of this set of scaleable visualizations in the context of GRASP, a prototype best-practices software engineering tool. This research also investigates the manner in which software visualizations are used in practice by software professionals. Partners from government and industry are cooperating with the investigators to provide access to production software systems for experiments and case studies. The impact of this research on the software engineering community will include (1) providing a experimental software support system which provides seamless support for an integrated set of visualizations, (2) providing empirical evidence that directly addresses the open question of the relative effectiveness of visualizations on production software, and (3) stimulating organizations to modify their software development processes to include visualizations based on those experimental results which indicate the potential for substantial improvements both in technical and economic terms.","title":"CISE Experimental Software Systems: Scaleable Visualizations to Improve and Measure Comprehensibility of Software Systems: A Framework for Evaluation","awardID":"9806777","effectiveDate":"1998-07-15","expirationDate":"2002-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"4725","name":"EXPERIMENTAL SYSTEMS\/CADRE"}}],"PIcoPI":["426670","489515","426671"],"PO":["179487"]},"30814":{"abstract":"9803971 Many reasoning and specification tasks require the analysis of logically complex syntactic objects. Such tasks arise, for instance, in using typing systems, in describing and prototyping programming languages, in effecting program transformations, in demonstrating program correctness, in realizing theorem provers, in describing the semantics of natural languages and in constructing corresponding parsers for them. A satisfactory framework for performing such tasks is obtained from using lambda- terms to represent the objects that are of interest and a constructive logic to describe their properties. This research addresses questions of implementation and use of lambda Prolog, a programming language that provides such a framework. The starting point for this work is an implementation of lambda Prolog that embodies the first serious attempt to realize many of its new features in an efficient manner. Using this system, the project conducts an extensive empirical study of the impact on efficiency of choices in the representation of lambda terms and in the compilation of unification and other operations on these terms. Refinements to the structure of lambda terms and to other language features are considered towards understanding the tradeoffs between efficiency and expressiveness. Issues relevant to constructing a flexible programming system around the language are studied. Finally, the strength of the programming system and of the methods supported by it are tested by employing them to implement a compiler for lambda Prolog.***","title":"An Effective Framework for Implementing Derivation Systems","awardID":"9803971","effectiveDate":"1998-07-15","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["364876"],"PO":["150697"]},"30858":{"abstract":"9804111 This research project attempts to develop new ways to analyze and test the integration aspects of software components, particularly for object-oriented software. As more software is developed using object-based designs and object-oriented languages, the problems of integrating the components become more crucial to the success of the software. This research project addresses these integration problems through software couplings, which are the paths through which software components communicate. The project applies coupling in four related directions. (1) Develop practical, effective, formalizable, automatable techniques for testing connections between components during software integration. (2) Extend and refine traditional coupling metric definitions to handle language features of modern languages. Use couplings to develop precise measurements, and develop complete algorithms for measuring complexity based on couplings. (3) Develop algorithms for using couplings to compute how much a proposed change will affect the rest of the system. This change impact analysis is used for planning, cost estimation, and decision making. (4) Finally, use couplings to determine the amount of regression testing that needs to be done after a maintenance change is made.***","title":"Coupling-Based Analysis for Integration Testing of Object-Oriented Software","awardID":"9804111","effectiveDate":"1998-07-01","expirationDate":"2002-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["151307"],"PO":["397849"]},"30748":{"abstract":"Richard L Smith<br\/>DMS-9803794<br\/><br\/>The classical theory of signal processing is based on models which are stationary, linear and in many cases also Gaussian. Recent advances in time series and the theory of signal processing have drawn attention to many new models and methods. Among these are nonlinear autoregressive and nonlinear state-space models, state-space models with time-varying or state-dependent coefficients as models for nonstationary and nonlinear series, linear non-Gaussian processes which pose some specific problems not encountered with Gaussian processes, methods derived from the theory of dynamical systems, and many others. There has been a parallel growth in the applications of signal processing in many areas such as engineering, finance, the environment, etc. The current project aims to develop new research in both the theory and applications of this diverse range of topics.<br\/><br\/>The project will provide funds for US-based researchers to attend a series of workshops taking place within a six-month program on \"Nonlinear and Nonstationary Signal Processing\" at the Isaac Newton Institute for Mathematical Sciences, Cambridge, England. The overall theme of the program is to bring together researchers in different areas of statistics and signal processing, with the intention of fostering research links between the two groups. Within this overall structure, a number of workshops on specific themes will be organised. The themes include Bayesian approaches to signal processing, financial applications, environmental applications, dynamical systems and the analysis of large data sets in industry. Participants from the USA will receive travel and subsistence support from the grant; some of the money is reserved for women, minorities and new researchers.","title":"Workshops on Nonlinear and Nonstationary Signal Processing","awardID":"9803794","effectiveDate":"1998-07-01","expirationDate":"1999-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1269","name":"STATISTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0504","name":"Division of MICROELECTRONIC INFOR PROCESS","abbr":"MIP"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["563514"],"PO":["331535"]},"30848":{"abstract":"9804076 Result checking of computations is investigated using a certification-trail technique. Certification trails offer an effective and efficient alternative to result checking approaches employing replication or N-version programming. Certification- trail techniques are designed to support a secondary computation of a result by using the same input together with a special output, the certification trail, utilized by the primary computation. By making use of the certification trail, the cost of the check can be substantially less than that of the primary computation. This research extends the certification trail technique to new application domains, including important computationally intensive problems for which best known solutions generally require extensive computing time and commonly used systems programming operations. The research also develops a distributed applet-based certifiable processing technique which distributes computational problems to clients across a network and then certifies the correctness of the accumulated solution efficiently using certification trails. Finally, by using properties of computations and solutions, certification-trail techniques are developed to support result checking with predetermined degrees of correctness rather than total precision. An important goal to assure a significant impact of this research is to establish a WWW library of certification-trail techniques and solutions for general use by researchers and software developers.***","title":"Certifying Computational Results","awardID":"9804076","effectiveDate":"1998-07-15","expirationDate":"2001-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["406250"],"PO":["150697"]}}