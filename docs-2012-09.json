{"199551":{"abstract":"The Internet has evolved into an essential medium that permeates most aspects of our lives. We consume information and entertainment online, cultivate relationships, exchange ideas, and handle business transactions. Not surprisingly, this new medium has also attracted malicious elements who seek to use the Internet to take advantage of others. Information manipulation is a new, emerging frontier in cyber security. Information manipulation denotes all attempts by adversaries to distort information with the goal to influence opinion, thought, or action. It can take many shapes and forms, from blatant attacks, such as search-poisoning, to misinformation, such as bogus on-line reviews, and more subtle distortion, such as personalized search and biased news. Unlike more traditional attacks, which typically aim to take control of computational resources or sensitive data, information manipulation targets human minds and their ideas. Left unchecked, information manipulation can harm our economy, culture, and democracy. <br\/><br\/>In this research project, the PIs aim to systematically study the ways in which attackers can manipulate information along its flow from the source where it is created to the recipient. Of particular interest are systems that help to discover, organize, and present information to users. These systems, such as search engines and news portals, reach large audiences and act as filters that often determine what content users will see or not. Thus, attackers can achieve significant leverage when successfully manipulating the filter mechanisms to their benefit. As one example, attackers can carry out search engine poisoning attacks to trick search engines into ranking their content higher than it should be based on its organic value. However, attackers do not need to target search engines directly; it is also possible to manipulate ranking by targeting users of search engines and their search history. Based on the study and analysis of attacks, the PIs will develop general detection approaches to identify when systems are under attack. This information can then be leveraged to design appropriate countermeasures.","title":"EAGER: Attacking (and Defending) Information","awardID":"1255546","effectiveDate":"2012-09-01","expirationDate":"2014-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[535035,535036],"PO":["565264"]},"187231":{"abstract":"With the popularity of real-time 3D\/4D data capturing capabilities, there is an emerging need to compute the deformable models over the networks. Traditional model-driven deformable models have their bottlenecks since the spatial information for large-scale datasets cannot be efficiently solved and adaptively minimized over different network conditions. This project centers on the concept of spectrum-driven deformable models. Analogous to Fourier analysis being applied to image processing, the spectral deformable models employ manifold harmonics to efficiently and effectively perform segmentation, registration, physics-based simulation, compression, and streaming of 3D deformable surfaces and volumes.<br\/><br\/>In this project, manifold harmonics are used to transform arbitrary scanned datasets into a reduced diffusion subspace, in which real-time segmentation, registration, and physics-based simulation can be performed. Besides the stretching deformations, the rotational and tensor fields are encoded with manifold harmonics, which provides a \"spectral multiresolution\" structure to compress and stream deformable models over different network conditions.<br\/><br\/>The PI works with the medical imaging experts at UT Southwestern Medical Center, to build a tele-diagnosis system for evaluating each component in the spectral deformable models. The test-bed on tele-medicine has impacts on the next-generation diagnosis and treatment services, as well as on clinical education. The theoretical and technical breakthrough can benefit our society at large, from tele-immersion, remote sensing, to speech training, through the PI?s further outreach activities. The research and education are integrated by taking research advances into existing and future courses; developing the visualization software for education; and attracting more undergraduate students into research.","title":"CAREER: Spectral Deformable Models: Theory and Applications","awardID":"1149737","effectiveDate":"2012-09-01","expirationDate":"2017-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[502215],"PO":["564316"]},"199331":{"abstract":"This project supports participation for 20 US-based students to the 14th International Symposium on Stabilization, Safety, and Security<br\/>(SSS 2012) to be held in Toronto, Canada during October 1?4, 2012. The purpose of the participation is to expose students to the theoretical modeling of important properties such as safety, robustness, stability, etc. in large systems.","title":"Student Travel Support for the Symposium on Stabilization, Safety and Security (SSS 2012)","awardID":"1254216","effectiveDate":"2012-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["563358"],"PO":["565255"]},"198484":{"abstract":"This RAPID project focuses on porting existing collaborative software in support of project-based science -- WeMap and WeKWL -- to the iPad. Initial software design and development has been done for Android machines as part of a complementary research project, but iPads are available in so many schools that it would be a shame to miss the opportunity to make available for the 2012-2013 academic year software that could be immediately used in science classes. The work consists in moving the core collaboration support, concept mapping, and KWL facilities to the IPad during summer, 2012, along with development of sample lesson that model how the software can be integrated into classroom activities. The apps will be available in Fall, 2012. Additional capabilities (file management and message board) will be ported in fall and winter and made available to schools as they are available. Together the apps will form what is being called the WeLearn Collaboration Platform. The first apps to be made available form a core of apps that teachers are used to using and ask for when they have a new device available; more general-purpose apps (e.g., drawing and animating, collaborative reading and writing) and science-specific apps (e.g., data collection and analysis tools) will be added to the suite as more is learned from complementary research projects. The purpose of this RAPID is to establish the platform into which those apps can be added and attract significant teacher buy-in with those apps. That infrastructure and the credibility gained through its use will form the basis for a more complete app set and reason for teachers and school systems to see that tools developed through a research endeavor can have value. <br\/><br\/>This project is addressing a real, imminent need: Throughout the country, schools are buying iPads this summer for use in the fall. Teachers need to be able to use the iPads productively in science class immediately when school begins, yet there is little in the way of educational software available in support of science learning. Given that public=supported bonds are often used to support large-scale technology purchases, it will be devastating (long term) to K-12 school budgets if, like their desktop and laptop cousins before them, iPads are not having the kind of positive impact on student achievement that is expected. Yet, without available apps and models of how to use them effectively for science education, there is little possibility of the technology being used well. This project addresses real needs -- making easy-to-use software for promoting science learning available to teachers and doing it in such a way that they have that software in time to use it on their new devices and have available models of its use to spur their imaginations.","title":"RAPID: Enabling Collaborative Science Learning Experiences on Mobile Devices","awardID":"1249312","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":["561136"],"PO":["560894"]},"189541":{"abstract":"Datacenters and clouds have become the main compute platform for many large scale corporations. Petabyte-scale datasets are stored throughout the datacenter and hundreds to thousands of different users submit jobs to collect business intelligence, gather statistics, or to compute essential data, such as a large scale index or a list of top users or their message posts. However, a significant challenge to these centers arises from user manipulation by some or all of the many tenants (both intentional and unintentional) of the underlying resource allocation mechanisms through misreporting of true job characteristics.<br\/><br\/>This project is designing and testing new algorithms combining ideas from computer science and economics which will make datacenters and clouds more robust to user manipulations. It is initially focusing on two important abstractions. The first allocates the total amount of resources and the second allocates individual machines (or virtual machines). The former is the standard abstraction for datacenters and the latter for many clouds, such as Facebook's internal cluster and Amazon's public EC2. For the former, where there are existing non-manipulable algorithms, the PIs are developing extensions to support new requirements, such as jobs with constraints. For the latter, the PIs are inventing new non-manipulable algorithms based on their preliminary studies. In addition, this project is applying recent results from algorithmic mechanism design and game theory to develop general procedures for converting existing manipulable protocols into non-manipulable ones.<br\/><br\/>This project will lead to more robust mechanisms for datacenters and clouds, reducing costs and energy usage.","title":"CSR: Medium: Limiting Manipulation in Data Centers and the Cloud","awardID":"1161813","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["516972",508219,508220],"PO":["564778"]},"198011":{"abstract":"Processing 3D shape information (geometry) efficiently is crucial for many domains: for example, computer-aided design, scientific computing, urban planning and cultural heritage preservation. The amount of geometric data generated and stored is rapidly increasing. The most common way to represent geometric data is with unstructured meshes. Unstructured meshes enjoy many attractive features, but inherently limit the efficiency and accuracy of many algorithms for geometry processing and physical simulation, as well as compactness of representations, compared to image processing algorithms. Mesh parametrization is the fundamental geometric processing technique used both in the context of converting surfaces to image-like representations, and for mapping data to surfaces. While significant progress has been made in the development of high-quality global parametrization algorithms a number of important questions are unresolved, limiting the potentially broad applicability of these techniques.<br\/><br\/>This exploratory project is developing mathematical and algorithmic bases for controlling global parametrization quality as well as limiting the possible amount of local distortion. The techniques being developed, based on the theory of quasiconformal maps and efficient greedy optimization algorithms, will serve as a foundation for future work on robust, high-quality and scalable global parametrization.","title":"EAGER: Foundations of robust surface parametrization and resampling","awardID":"1247240","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["550936"],"PO":["565227"]},"189552":{"abstract":"Femto-aided cellular networks appear to be one the best solutions to achieve multi-fold capacity needed for future wireless networks. However, Femto-aided cellular systems have an information architecture that is very different from current planned and centrally managed cellular architecture. In this project, both the design of information architecture to acquire network state information and the optimal use of the resulting NSI will be addressed. The project is organized into three symbiotic research thrusts on network-aware physical-layer (PHY) coding schemes, network protocols and algorithms leveraging advanced PHYs, and their architectural prototypes. The first thrust utilizes recent innovations in deterministic models of wireless networks and develops novel physical-layer cooperative encoding and decoding schemes that operate with delayed, inconsistent, and erroneous NSI. The second thrust builds on the new physical-layer coding schemes to design network-scheduling algorithms to address performance issues. Finally, the third thrust utilizes the WARP programmable radios and studies implementation challenges of the protocols. The project goals of foundational design for Femto-aided cellular networks will have significant impact on industry practice. The PIs will facilitate technology transfer through their established industry affiliate program. A broad range of education and outreach activities will also complement the research agenda, including integration of research findings into the courses, promoting underrepresented and undergraduate populations, and engaging with the middle\/high school community to raise the level of interest in engineering and mathematics.","title":"NeTS: Medium: Collaborative Research: Information Architectures for Femto-Aided Cellular Networks","awardID":"1161868","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560222"],"PO":["565303"]},"198264":{"abstract":"Location Based Service (LBS) is one of the most popular types of applications in mobile networks. As the name suggests, the success of an LBS application depends on two pipelined procedures: localization and information transmission. In other words, an LBS application cannot start until all the mobile users have obtained their positions. The localization time of current methods is too long to support time-critical applications based on mobile networks, where users continually change their positions. This project envisions a radically new alternative to the intuitive pipelined procedures approach, where the LBS application can start before all the users? positions become available.<br\/><br\/>The intellectual merit lies in the concept of mobile essential localization, which is expected to significantly reduce both (i) localization time and (ii) energy consumption, while enhancing the location privacy and guaranteeing the success of LBS applications. The proposal entails high-risk as it is applied to real-time environments, which are highly unpredictable and dynamic. If successful, this novel paradigm could motivate scientific investigations aimed at a plethora of time-critical mobile network applications. One can expect high-reward in terms of applicability to areas of strategic interest including social and vehicular networks, and performance enhancements of such applications.<br\/><br\/>The broader impact of this project is reflected in several aspects: (i) The outcomes of this NSF project will have societal impact on facilitating the spread of mobile network usage; (ii) The new approaches may be adopted by US-based industry in their future designs and protocols for enhancing the location based service availability and its integrity; (iii) This EAGER projects investigates the time critical localization challenge from an interdisciplinary perspective combining Computer Science, Theoretical Computing, Electronic Engineering, and Communications; (iv) The resulting software codes will be disseminated to the public under open source license; and (v) New interdisciplinary graduate curriculum will be offered to students in MA\/OH including minorities and underrepresented groups. Demos will be offered to Toledo Public School students.","title":"EAGER: Collaborative Research: Time Critical Localization in Mobile Networks","awardID":"1248381","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[532060,"545691"],"PO":["565303"]},"187055":{"abstract":"Ecology is about to face the data deluge that other biological disciplines have already experienced. With ecological data increasing rapidly in quality and size, new methods are needed to extract the most relevant biological information from massive data-sets. The objective of this project is to develop new mathematical, computational and statistical tools for the analysis of three ecological problems. First, when a species goes extinct, the impact reverberates through the ecological network, possibly causing the extinction of other species. A new method to predict such \"secondary extinctions\" will be developed. Second, the number and size of published ecological networks is increasing rapidly, making it possible to answer one of the oldest questions in ecology: how many species traits (e.g., body size, swimming speed, metabolic rate) does one need to measure to predict whether two species will interact? A new computational method, coupled with a large dataset will attempt to answer this question. Knowing which are the critical traits determining the possibility of interactions could find application in the study of invasive species. Third, the spatial structure of ecosystems mediates many ecological processes. A new method will be developed to measure the impact of spatial heterogeneity on the structure of ecological networks.<br\/><br\/>The development of these new tools require sophisticated methods, which are not typically included in the curriculum of biologists. The educational goal of the project is to train ecologists in the computational methods that will be needed to advance the discipline in the decades to come. Graduate students will learn how to automate the analysis of biological data, distribute computation over large computer clusters, organize data into relational databases, program in different languages, collaborate on data, code and manuscripts, automatically managing versions and conflicts, and pick the right tool for each task. Outreach activities will be provided through lectures and media interviews and with activities carried out in collaboration with local elementary schools and the Museum of Science and Industry.","title":"CAREER: Scientific Computing for a New Generation of Ecologists","awardID":"1148867","effectiveDate":"2012-09-01","expirationDate":"2017-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7334","name":"MATHEMATICAL BIOLOGY"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"1182","name":"POP & COMMUNITY ECOL PROG"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"7275","name":"CROSS-EF ACTIVITIES"}}],"PIcoPI":[501850],"PO":["564596"]},"189497":{"abstract":"People care greatly about the appearance of translucent materials such as food, skin, soap, and marble, and they are able to distinguish subtle differences in these materials based on their appearance. The translucent appearance of these materials is caused by internal volumetric scattering, which is challenging to simulate, especially because humans are so sensitive to their subtleties. Since in the natural world scattering materials are the norm, not the exception, it makes sense that the human visual system is so well engineered to analyze them. However, very little is known about how this analysis is achieved because the perception of volumetric translucency is almost unstudied.<br\/><br\/>This collaborative project, involving faculty from three universities with complementary expertise in computer graphics, human vision, machine learning, and computer vision, addresses the fundamental unsolved problem of understanding translucency for graphics. The PIs will develop a perceptually-motivated pipeline for translucency, contributing new scattering representations, perceptual dimensions, and computational algorithms to computer graphics. The scattering representations, based on a polydispersion model, will provide analytic expressions for wavelength-dependent bulk scattering properties of translucent media; this will significantly expand the range of materials that can be simulated with high visual fidelity. Finding perceptual knobs that relate physical scattering parameters with visual appearance will be achieved by coupling large-scale computation (using cloud computing) with controlled perceptual studies. Novel acquisition approaches that employ hyperspectral imaging will be created, as will editing and rendering applications that use the new perceptual representations of translucency. Low-dimensional models to represent scattering media will be developed and used to enable efficient and accurate acquisition and rendering. A suite of test materials and scenes will be developed to evaluate the fidelity of rendered images based on the developed theory and computational applications.<br\/><br\/>Broader Impacts: Currently, the simulation of translucency presents challenges in terms of both computation and visual fidelity. This restricts the ability of practical algorithms to predictively simulate translucent materials, thus fundamentally limiting the use of graphics in real applications. By building the computational tools to characterize, study, and use knowledge of translucency perception, this research will fundamentally change the graphics pipeline for translucent materials. and will potentially revolutionizing industrial design, interior design, skin care and cosmetics, and entertainment.<br\/><br\/>The project includes an education program that is tightly coupled to the research program. The PIs have already been meeting twice a week for more than six months, and their graduate students already share data, code, and equipment. During the activity, the students will make week-long and month-long visits to each other's laboratories to collaborate, and in this way the project will produce a generation of researchers who are \"T-shaped\" in the sense of being both deep in their respective fields and able to work effectively across these synergistic disciplines. The PIs also plan to organize a workshop that will brins together researchers in vision science, computer graphics, and computer vision, so that the important ties between these fields are strengthened even further.","title":"CGV: Medium: Collaborative Research: Understanding Translucency: Physics, Perception, and Computation","awardID":"1161564","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["515747"],"PO":["565227"]},"193380":{"abstract":"This project seeks to discover new algorithms and develop algorithmic tools to address fundamental open problems in the theory of algorithms under the following focus topics: (1) Rounding. The power of affine transformations in the design of algorithms and in their analysis, including for solving LP's in strongly polynomial time and approximately sandwiching convex bodies. (2) Learning. Algorithms for learning polyhedra, learning subspace juntas and identifying planted cliques in random graphs. (3) Isoperimetric inequalities. Extensions of Cheeger's method to higher eigenvalues and multi-partitions, and the KLS hyperplane conjecture. (4) Lattices and convex geometry. Optimization and sampling problems over lattices, including: (a) the complexity of integer programming (determining whether a convex body intersects a given lattice), (b) the complexity of cutting plane methods, and (c) conditions under which lattice points in a convex body be sampled efficiently.<br\/><br\/>The problems explored are of a basic nature, and originate from many areas, including optimization (both discrete and continuous), sampling, machine learning and data mining. With the increasing availability of high-dimensional data in important application areas, efficient tools to handle such data are a necessity. This award addresses some of the most basic questions arising from this need. <br\/><br\/>The PI, an active member of the Algorithms and Randomness Center (ARC), served as its founding director and continues in-depth collaborations with scientists from various fields to identify problems and ideas that could play a fundamental role in understanding the complexity of computation. The project will contribute to graduate courses with online notes, textbooks and up-to-date survey articles.","title":"AF: Small: Fundamental High-Dimensional Algorithms based on Convex Geometry and Spectral Methods","awardID":"1217793","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["565103"],"PO":["565157"]},"192170":{"abstract":"Over the last half century, the Internet has moved from a medium for resource sharing to one centered on the access and distribution of content. This research effort leverages insights from social science research to characterize shared interest in content distributing services and explore the implications of these findings on the design of existing and future services. Its agenda is predicated on the observation that a thorough understanding of shared interest in content - what content people want to share, when, and where - is key to the design, implementation and management of content distribution services, dictating these services' architectures and dynamic organizations, determining performance experienced by users and the impact they have on the underlying network. The effort leverages the view of users in a popular content distribution system to explore these and other aspects of content distribution and serve as a testbed for gaining social scientific insights in the evolution and dynamics of shared interest and content distribution networks.<br\/><br\/>Broader Impact: Research findings from this effort will be made available as publications, datasets and software. When applicable, the software will be integrated into existing systems such as BitTorrent, building on our previous successes. The impact of the proposed work will naturally extend beyond existing services and networks to inform the design of future content distribution services and new content-centric Internet architectures through close interaction with the Internet Engineering Task Force and collaborating research labs. In addition to the promising research questions and practical benefits, the project will have a direct impact on education in communication, network and distributed systems.","title":"SoCS: Leveraging Shared Social Interest in a Content Centric Internet","awardID":"1211375","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["532398","518224"],"PO":["565090"]},"194491":{"abstract":"This project explores the hypothesis that compelling learning games based on contemporary science that offer opportunities to contribute to scientific inquiry will lead to increased interest in science, increased career choice of science, increased conceptual understanding of science content, and better scientific literacy around what scientists do. The idea is to capitalize on crowd sourcing both to shed light on the answers to open scientific questions and to engage the public in authentic and needed scientific inquiry in meaningful ways. The PIs will extend four games that are already designed and built or that are under construction and develop a platform for supporting a broad range of participatory science games that offer the public opportunities to contribute to scientific inquiry. The chosen games all encourage sustained and deep participation, include apprenticeship opportunities and opportunities for practicing authentic science, promote reflection in and on action, and are designed to be emotionally compelling. Games come from four game genres: role-playing, strategy, action, and puzzle, as different people are drawn to different types of experiences. All are in the areas of bioscience and biotechnology, and each addresses some open question in bioscience or biotechnology that participants might shed light on. The broad range of games serves several purposes -- offering a substantial enough range of experiences that a broad range of participants can be expected to join in, offering enough diversity to know that the infrastructure tying the games together has all of the functionality required to support a broad range of such games, and offering enough diversity to answer targeted research questions. Research focuses on identifying the challenges in creating a broad and diverse public gaming community that interacts with more formal and established scientific and educational cultures, how learning occurs in such an environment and how to promote sustained engagement and deep learning, identifying core features and mechanisms of games that promote sustained engagement and science learning, and understanding the design features in the particular games being studied that contribute to sustained engagement and learning.<br\/><br\/>There is an increasing awareness among scientists that many contemporary science problems require (or could benefit tremendously from) an actively engaged public. Communicating the challenges and opportunities of science, and mobilizing the public to participate in and support scientific inquiry, requires shared understandings about the values, methods, and epistemologies of science (e.g., observation, data collection and analysis, reasoning from evidence, skepticism). This project focuses on design of learning opportunities that are both engaging and informative with respect to scientific literacy. The public is invited to participate in a variety of science-related \"games,\" experiences with scientific inquiry that are engaging and exciting and that can contribute to scientific findings. Participants engage as scientists, carrying out the practices of scientists and reasoning about evidence to draw conclusions, in the process experiencing the thrills and frustrations involved in scientific discovery and inquiry. Investigators observe the participants in these games to draw out principles for designing additional learning experiences that can engage the public in science and promote scientific literacy and learning at the same time. What is learned in this analysis will also be applicable to designing engaging science experiences for use in schools.","title":"DIP: BioSourcing: A Crowdsourcing Approach to Increasing Public Understanding in Computational Biosciences","awardID":"1227530","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":[520931,520932,520933,"557849","538314"],"PO":["562669"]},"193281":{"abstract":"Communication complexity is the study of computational problems where the input is split amongst multiple locations, described as parties playing a communication game. These parties must communicate with one another according to a protocol to solve the problem of interest, while minimizing the amount of communication (number of bits exchanged). Besides its intrinsic motivation (enhanced by the coming \"cloud computing\" era), communication complexity derives its importance from its implications in all sorts of other areas of theoretical computer science, even ones that do not directly involve communication; examples are circuit complexity, data streaming, query complexity, property testing, and game theory.<br\/><br\/>Under this award, the PI and his students will investigate a number of concrete communication games, attempting not just to establish new bounds on specific problems, but also to broaden the foundations of the field through new techniques and paradigms. Results and ideas thus discovered will be applied to some of the areas mentioned above, with a particular focus on data stream algorithms. Some representative research goals are as follows. <br\/>(1) Developing the theory of Merlin-Arthur communication, with a view towards applications to data stream algorithms that interact with a powerful but untrusted helper. <br\/>(2) Deepening our understanding of a number of graph streaming problems, either through new communication lower bounds or improved algorithms. <br\/>(3) Relating the recent technique of information complexity to older established techniques for analyzing communication complexity.<br\/><br\/>The broader imapcts of the award include the training of up to two graduate students who may work on any aspect of communication complexity or its applications, and the design and teaching of a new graduate-level course on communication protocols and complexity. Results obtained will be disseminated at international conferences, targeted workshops and seminars at other institutions.","title":"AF: Small: Foundational Research in Communication Complexity and Its Applications","awardID":"1217375","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["538173"],"PO":["565157"]},"200178":{"abstract":"The rising cost of long-term patient care, the shortage of nurses, and the increasing number of seniors in the United States make it imperative to investigate the possibility of intelligent systems for elder\/patient care. One challenge is how to prevent falls, which often result in serious injury and considerable hospital and patient costs. In this exploratory project the PI and her team will focus on analyzing sensory data of patient actions in an effort to develop algorithms for the automatic detection and prediction of falls among elderly patients. Their goal is to gain a good understanding of how multimodal sensory data combined with domain knowledge of falls can be used to characterize pre-fall patient actions, in order to determine the feasibility of developing automatic alert systems that incorporate machine learning algorithms to assist human nurses and robotic caregivers by warning of potential falls. <br\/><br\/>Broader Impacts: Project outcomes will pave the way for future development of intelligent systems to reduce the incidence of patient falls, which is a major societal concern. The project will provide a rich spectrum of interdisciplinary training for graduate student researchers, and will also strengthen UNC Charlotte's existing programs in broadening participation in computing and in research experiences for undergraduates (REU) by deepening involvement of women and minority undergraduate students in research.","title":"EAGER: Data Analysis for Nursing Care Assistance","awardID":"1258335","effectiveDate":"2012-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["475621",536619,536620,"553786"],"PO":["565227"]},"198760":{"abstract":"The big question being addressed in this project is, \"How can technology support the teaching and learning of mathematical argumentation?\" This EAGER proposal focuses on the first steps in moving towards the vision of helping youngsters learn mathematical\/algebraic argumentation. The project has two complementary goals: to better define the technological tools needed to support elementary students learning about proof and argumentation and to understand better how elementary school students learn to make and defend mathematical claims when such tools are available. The PIs envision and are developing an animation tool to be implemented on tablet computers (so each child has his\/her own electronic notebook) that provides infrastructure for sharing and refining arguments in small groups and across the class and for promoting concrete math discussions. A big challenge is providing the right tools for expression; for sharing to happen, learners need to first be able to express their understanding, and much research shows that a concrete \"written\" (sharable) expression of understanding provides better foundations for promoting concrete discussion than do expressions of understanding that are simply verbal. The particular advance in expression that is being made in this project is providing tools for dynamic representations; that is, they are able to animate what happens when mathematical operations are carried out. These concrete expressions of understanding can then be played back, paused, and so on. Students create animations by drawing, erasing, duplicating, moving, and grouping objects. They can edit each others' animations, and the teacher will also be able to create animations for students to view and edit. They record and save their oral explanations along with the animations and play them back together, thus making their verbal descriptions concrete, examinable, and sharable. <br\/><br\/>The ability to prepare and present a mathematical argument is a key component of the mathematical competence students need to achieve in upper elementary school (grades 3 through 5). Many students struggle with the subject matter and therefore struggle as well with making mathematical arguments. The PIs envision a computational tool set that young students will use to construct and share mathematical arguments, in the service of learning to be competent algebraic reasoners. In this EAGER project, they focus on first steps in developing that tool set and on investigating how young learners make and defend mathematical arguments when they have such tools available. This project represents work in its early states on an untested but potentially transformative idea and is likely to catalyze rapid and innovative advances in helping young learners become mathematical reasoners.","title":"EAGER: Collaborative Research: Technology to Support Mathematical Argumentation","awardID":"1250802","effectiveDate":"2012-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":[533247],"PO":["562669"]},"195273":{"abstract":"The obesity epidemic among children has become a widespread problem in the United States. This trend is disturbing because overweight children tend to become overweight or obese adults with potentially life threatening chronic conditions. By focusing on children?s physical activity, we can shift the problem from treatment to prevention. There are numerous academic and commercial applications that aim to help individuals monitor and make proactive decisions about their physical activity; however they do not integrate well into an individual's daily life because they may require manual activity input, asynchronous visualization, and non-instinctive awareness of the application for actionable feedback. Thus, while existing devices have had some success in monitoring, inferring, and presenting activity, they do not always convey the value of physical activity in an intuitive visual abstraction. The feedback design is important in designing wearable technology for children because children are less likely to connect quantifiable measurements - in this case with their health.<br\/><br\/>In response to these issues, we design innovative wearable computing components that empower children to craft their own intuitive abstractions of wellness data for physical activity promotion. This project builds on existing socio-technical research in health informatics by extending the nascent research subarea, wellness informatics, that studies how technology can be utilized to empower lay populations to stay well and adopt preventative health behaviors. The research objectives of this project are to: (1) Design plug-and-play wellness monitoring Health Sense systems; (2) Design a graphical programming environment to control the actions of the Health Sense systems; and (3) Understand how children use Health Sense systems. The research methodology is inspired by participatory design activities including participant observations, design workshops, and iterative evaluation of prototypes. Overall, the proposed system provides innovations in computing by creating new, wearable computing prototypes and paradigms of interaction. <br\/><br\/>The broader impacts of Health Sense include undergraduate and graduate research assistant interdisciplinary research training. The research team is introducing low socioeconomic status K-12 students to computing, electronics, and health through Health Sense workshops. Research methodology and results is being integrated into the PIs' established 1st year general engineering projects courses. In addition, the PIs and their students are helping increase the pipeline of future scholars by developing teaching and outreach materials that are being distributed through the project website. The PIs and their students are disseminating their research by publishing results in health informatics and traditional computing venues. Finally, the system also helps fulfill Healthy People 2020 Educational and Community-Based Programs goals.","title":"SHB: Type I (EXP): Health Sense: Motivating Health Awareness in Children through Wearable Computing","awardID":"1231645","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[523483,523484],"PO":["564768"]},"198782":{"abstract":"Deep packet inspection (DPI) is an established methodology used by ISPs for performance enhancements, security protections, behavioral advertising, and content filtering. However, the limitations of DPI and its applications are becoming more and more evident with the increase in network traffic and the variations in usage patterns. In this exploratory project, the PI will introduce the notion of Deep ``Network\" Inspection (DNI) that will go beyond DPI in exploring correlations among multiple networks and other aggregated parameters from multi-genre networks and behaviors. DNI will use broader knowledge including social network relevancies, information network, modalities of accesses, device characteristics, past and present user profiles at various levels of aggregations; thus going far beyond the realm of isolated characterizations of communication networks. Primary goals of DNI include the reduction in the ?search space? for real-time analysis and the complexity of pattern discoveries, and the discovery of relationships which may not be detectable by single-network inspection (such as DPI). The goal of this project is to do an initial study to motivate and explore the capabilities of DNI, the challenges therein, scope of inspections, and potential applications. The outcome of this exploratory study would potentially open up an enriched area for further research in the domains of network science. In terms of broader impact, the proposed project will also instigate researchers in both academics as well as industry to explore this new domain on network inspection, which may have significant potential in a variety of applications, and education of students.","title":"EAGER: Deep Network Analysis","awardID":"1251029","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550540"],"PO":["551712"]},"189663":{"abstract":"The dominant manufacturing paradigm for human technology has been top-down construction of objects, in the sense that a large entity manipulates smaller entities to put them together into a functional device. In contrast, for billions of years biological organisms have constructed objects using a bottom-up technology, in the sense that the pieces self-assemble or grow without outside assistance. For example, to make a complex molecular machine, enzymes within the cell might synthesize a number of proteins that then diffuse randomly until they bump into each other and click into place; while on a larger scale, a single cell might grow into an elephant. <br\/><br\/>The bottom-up manufacturing paradigm has advantages that top-down methods are unlikely ever to achieve, such as the ability to create meter-scale objects from components with atomic-scale (nanometer) resolution and chemical functionality but it requires a level of exquisite control over molecular structure and function that human science and technology has not yet attained. We believe that the primary missing ingredient is information science and technology: information must be encoded within synthetic molecules to control their behavior and to create programmable molecular systems. <br\/><br\/>In this research, the aim is to push the frontiers of information-based molecular self-assembly using DNA nanotechnology. The past fifteen years have seen the development of an abstract theory of algorithmic self-assembly (initiated by Winfree) that merges the mathematical theory of geometrical tiling, the statistical mechanical and kinetic theories of crystal growth, and the algorithmic theory of Turing machine computation. This theory shows how, in principle, synthetic DNA molecules called ?tiles? can be designed to carry information that directs their assembly into complex and sophisticated shapes and patterns. Just as a small program can produce a large and intricate output, a small tile set can result in the self-assembly of a large and intricate object the tile set is a program for controlling the molecular self-assembly process. Laboratory experiments in the past fifteen years have demonstrated the foundations of this theory using DNA tile sets on the order of two dozen tile types, i.e. very small molecular programs.<br\/><br\/>In the past year, a new molecular motif for DNA tiles (developed by Yin) has been used to self-assemble molecular structures using up to 1000 distinct tile types that each has a unique target position within the structure, like a self-assembled molecular-scale jigsaw puzzle. This is the simplest type of molecular program. A major goal of the proposed work is demonstrating that the new ?single strand tile? motif can be used to create significantly more complicated self-assembly programs than have been seen to date by reusing distinct tile types in many locations and in an algorithmic fashion, much like living systems that reuse the same molecules in many different ways. Sophisticated algorithmic tile reuse of two dozen to perhaps 1000 or more distinct components vastly expands the capabilities of self-assembly programs. To achieve this, proposed work will (a) improve techniques for an important subroutine for controlling molecular growth, a binary counting process that terminates after growing a pre-specified distance; (b) develop methods and molecular structures for nucleating the growth of single-strand tiles with pre-specified information that serves as ?input? to the molecular program; (c) demonstrate algorithmic growth of single-strand tiles that perform Turing machine and\/or cellular automaton computations; (d) investigate proofreading techniques for reducing the rate of errors during self-assembly; and (e) create software tools that facilitate the design and analysis of these complex molecular systems.","title":"SHF:Medium:Collaborative Research:Scaling Up Programmable and Algorithmic DNA Self-Assembly","awardID":"1162589","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["558957","518688","518689"],"PO":["565223"]},"198188":{"abstract":"This INSPIRE award is partially funded by Human-Centered Computing Program and by Social-Computational Systems Program both in the Division of Information and Intelligent Systems in the Directorate for Computer & Information Science & Engineering, and by the Social Psychology Program in the Division of Behavioral and Cognitive Sciences and the Political Science Program in the Division of Social and Economic Sciences in the Directorate for Social, Behavioral and Economic Sciences.<br\/><br\/>With regards to intellectual merit, the goal of this project is to forge an interdisciplinary collaboration that examines the impact of social media on political behavior. First, from social psychology and political science, fundamental hypotheses will be developed about how, why and when social media affects citizens' cognition and motivation with respect to political participation. Second, these questions will be expressed as testable hypotheses derived from behavioral models. And third, drawing from biology and computer science, the project adapts sophisticated computational methods of approximate inference and machine learning (adapting methods developed for the analysis of Systems Biology data) to evaluate the behavioral models using extremely large social media and social network datasets. <br\/><br\/>The scientific opportunities afforded by the use of social media are readily apparent when we consider the richness and precision of data on participation in elections, protests, riots, and other spontaneous political events. This project will construct a comprehensive data set of incoming and outgoing social media messages messages using systematically structure formats that are ideally suited to machine learning methods, and this information will be integrated with information on social network connectivity and a vast array of metadata on individuals and their social contacts. By developing new methods to harvest and combine these data sources effectively, it will be possible to transform the scientific study of social and political attitudes and behavior. Every time individuals use social media, they leave behind a digital footprint of what was communicated, when it was communicated, and, to whom it was communicated. Typically, such precise estimates of these variables are available only to laboratory investigators working in artificial settings. No previous study has successfully used fine-grained social influence data such as these to predict consequential behavioral outcomes, such as attendance at a given protest or rally. The structure of the data means that we will have panel data on respondents, many of potentially long duration. In addition, the investigators will conduct a panel survey, which is essential for drawing causal inferences about the cognitive and motivational processes whereby social media use facilitates political participation.<br\/><br\/>With regards to broader impacts, this research will enhance interdisciplinary training for graduate and undergraduate students. These include students in psychology, political science, computer science, and biology and also includes students from groups that are underrepresented in these sciences. In addition, opportunities will be provided for high school students to become involved in the research process. The research program will foster broad dissemination of scientific understanding by leveraging past experience of the principal investigators with disseminating large code-bases, data-bases, and data-sets to share work with other scientists (pre-publication). Finally, the researchers are committed to making their research available to the general public and have extensive experience doing so.","title":"INSPIRE: Computer Learning of Dynamical Systems to Investigate Cognitive and Motivational Effects of Social Media Use on Political Participation","awardID":"1248077","effectiveDate":"2012-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"1371","name":"POLITICAL SCIENCE"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"8078","name":"INSPIRE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"1332","name":"SOCIAL PSYCHOLOGY"}}],"PIcoPI":[531869,531870,531871,"552159"],"PO":["559351"]},"202720":{"abstract":"Helping users find relevant information is undeniably an important problem vital to the functioning of today's information-based societies. It is therefore no surprise that millions of people worldwide make use of search engine technologies each and every day. Although existing search technologies work well, there is still considerable room for improvement. Search engine innovation is driven by the ability to rapidly, and repeatedly, measure the quality of the results produced by a given system. This type of measurement typically requires some form of human input. For example, a human expert may be hired to assess the relevance of search results, or the search engine may log user interactions, such as the queries entered and the results clicked. After a sufficiently large amount of data has been collected, it can then be used to accurately measure search engine quality. It can also be used to improve the quality of existing search engines via a process known as \"tuning\" or \"training\". However, gathering large amounts of this information typically requires a significant amount of human effort or computational resources. Therefore, sustained innovation is only possible at a very steep cost.<br\/><br\/>Techniques for constructing large information retrieval test collections that require no human effort are the primary focus of this research study. Rather than relying on human-curated information, implicit relevance signals from the Web are mined to automatically construct large, reusable test collections for a variety of search tasks, including Web search, news search, and enterprise search. The observation that the Web contains a large number of implicit relevance signals is the starting point of the research. The simplest example of an implicit relevance signal is the hyperlink, which can be interpreted as a signal acknowledging the relevance of the target page by the source author. The hypothesis that such implicit relevance signals can be effectively mined and aggregated in a completely unsupervised manner to create test collections without any human effort is investigated in this research. Automatically generated test collections are evaluated in two different ways. First, the test collections are evaluated according to their ability to accurately measure the quality of search systems compared to human-generated test collections. Second, the quality of search engines tuned using the automated test collections are compared against engines tuned using manual test collections.<br\/><br\/>The broader impact of this project is derived from automatically constructed test collections that are freely distributed to the broader research community. Advances in search engine technologies are expected as the result of increased availability of training data to systematically evaluate and tune search engines, both in industrial and academic settings. Additional broader impact is expected from the integration of research and education at both the graduate and undergraduate levels and from engaging women and underrepresented students through various outreach programs.","title":"III: EAGER: Automatically Building Test Collections Using Implicit Relevance Signals from the Web","awardID":"1304939","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[543277],"PO":["565136"]},"202731":{"abstract":"This project addresses optimizing energy efficiency in the execution of parallel algorithms.<br\/><br\/>High energy cost is a salient constraint when running large scale parallel applications on the next generation of supercomputers that contain heterogeneous multicore processors and interconnections, motivating a rethinking of conventional approaches to modeling, designing and scheduling parallel tasks by taking energy-efficiency into consideration. <br\/><br\/>In this collaborative research, this team explores energy-efficient parallel task design, scheduling, and implementation and develops an power profiling tool (PowerPack) that can measure decomposed runtime power consumption of different computing components (e.g. processors, memory, networks and disks) when running large scale parallel applications.<br\/><br\/>The results of the research will be widely disseminated by maintaining an active project website, publishing peer-reviewed journal and conference papers, making the code available to other researchers, and presenting the research results in professional meetings. The availability of the research outcomes will provide ample opportunities for other researchers to further study the energy-efficiency of parallel applications. Through the collaboration of Texas State University ? San Marcos, Colorado School of Mines, and the Marquette University, PIs promote teaching, learning, and training by exposing graduate and undergraduate students to technological underpinnings in the fields of high performance computing in general and energy-efficient computing in particular. The close partnerships with a number of universities, data centers and national laboratories will also facilitate the broad dissemination of the proposed energy-efficient parallel tasks designing and scheduling techniques as well as the developed power profiling toolkits.","title":"CSR: Small: Collaborative Research: EEDAG: Exploring Energy-Efficient Parallel Tasks Generation and Scheduling for Heterogeneous Multicore Systems","awardID":"1304969","effectiveDate":"2012-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["543712"],"PO":["551712"]},"194690":{"abstract":"This project aims at developing efficient methods for protecting the privacy of computations on outsourced data in distributed settings. The project addresses the design of an outsourced storage framework where the access pattern observed by the storage server gives no information about the actual data accessed by the client and cannot be correlated with external events. For example, the server cannot determine whether a certain item was previously accessed by the client or whether a certain algorithm is being executed. This property provides a high level of privacy protection that goes far beyond standard data encryption. The project also deals with advanced methods for verifying the correctness of outsourced computations, focusing on keyword searches and graph algorithms. The educational component of the project includes a curricular development effort for introductory computer security courses.<br\/><br\/>The project has applications to a broad range of web services widely used by business and consumers. Privacy-preserving access for outsourced data is relevant to web-based email and office applications. Also, it is especially important for the management of proprietary business data, medical data, and other sensitive personal data.","title":"TWC: Medium: Collaborative: Privacy-Preserving Distributed Storage and Computation","awardID":"1228639","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[521484],"PO":["562974"]},"193370":{"abstract":"Signal processing and communication systems often use Bayesian methods, which require a statistical characterization of the input to be available.When statistics are unavailable, one can use universal algorithms that adapt to the data at hand and perform as well as any other system asymptotically.<br\/>Unfortunately, the impact of universal algorithms has been limited to lossless compression.<br\/>To take universal algorithms beyond compression, this project will develop theory and algorithms for universal signal estimation, where an input signal is estimated from knowledge of its noisy measurements and the structure of the measurement system but without knowledge of the input statistics.<br\/>Our formulation is broad, and the research could lead to<br\/>(i) higher quality medical imaging;<br\/>(ii) improved seismic methods for predicting the likelihood of earthquakes and knowing where to perform oil and gas drilling;<br\/>(iii) communicating better-compressed data over more challenging unknown channels; and (iv) allocating capital more efficiently in financial markets.<br\/><br\/>We perform universal signal estimation in (potentially nonlinear) signal processing systems from noisy measurements. The theoretical component of our this project is inspired by Kolmogorov complexity and the minimum description length principle. The algorithmic component combines scalar quantization, universal lossless compression, and Markov chain Monte Carlo. We evaluate the estimated input over a quantized grid and optimize for the trade-off between information complexity of the estimated input and how well it explains the measurements.","title":"CIF: Small: Universal Signal Estimation from Noisy Measurements","awardID":"1217749","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[517955],"PO":["564898"]},"196780":{"abstract":"This INSPIRE award is partially funded by the Stellar Astronomy and Astrophysics Program in the Division of Astronomical Sciences in the Directorate for Mathematical and Physical Sciences, by the Software and Hardware Foundations Program and the Information Technology Program in the Division of Computing and Communication Foundations in the Directorate for Computer and Information Science and Engineering, and by the Experimental Program to Stimulate Competitive Research in the Office of Integrative Activities.<br\/><br\/>This award will support a large-scale computational effort to model the disruption and merger of white dwarf stars. The major goal is to include significantly improved physical realism than in current models. White dwarf stars are the low-mass endpoints of stellar evolution for stars like the Sun. Many of these are found in close binary systems, and it is well known that such close binaries will merge on time scales of 1 to 10 billion years. White dwarf mergers have recently been proposed as an important additional production channel for Type Ia supernovae, which are the most important probes of the expansion of the universe. The merger process and subsequent explosion requires that a large number of physical processes all be modeled at once, including magnetohydrodynamics, nucleosynthesis, radiative transport, and rapidly-changing gravitational fields. These various processes have quite different natural length, time, and density scales, and the level of complexity required for highly realistic modeling of stellar mergers is not achievable in current codes.<br\/><br\/>The project will require advances in computational techniques. One of the key goals is to improve performance of multi-physics simulations on massively parallel architectures, which is currently limited by problems of scale and overhead in data distribution and resource allocation. The effort will explore the various tradeoffs between overhead and parallelism, and will enable improved strategies in order to enable more efficient and more scalable computation for astrophysical and other problems.<br\/><br\/>The project is expected to have a broad applicability of the project?s computational techniques beyond the direct problem of stellar mergers. A number of related problems in stellar astrophysics also require integrating the treatment of fluid dynamics, dynamic gravity, thermal and radiative transport, and nuclear energy generation. The group anticipates that the largest direct impact will come in the areas of supernova explosion modeling, the mergers of stars of various types, and stellar evolution when tidal effects and rotation are important.","title":"INSPIRE: STAR: Scalable toolkit for Transformative Astrophysics Research","awardID":"1240655","effectiveDate":"2012-09-01","expirationDate":"2017-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0302","name":"Division of ASTRONOMICAL SCIENCES","abbr":"AST"},"pgm":{"id":"1215","name":"STELLAR ASTRONOMY & ASTROPHYSC"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0302","name":"Division of ASTRONOMICAL SCIENCES","abbr":"AST"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"8078","name":"INSPIRE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[527877,527878,"563331",527880],"PO":["564831"]},"193282":{"abstract":"Smartphones equipped with powerful embedded sensors (e.g. accelerometers, GPS, microphones, etc.) can be used to monitor multiple dimensions of human behaviors including physical, mental, and social behaviors of wellbeing. In particular, such enhanced capabilities in mobile devices enable people to better manage their health. Existing mobile health applications mostly rely on manual data entry which may not be sufficient for certain population e.g. seniors and students with emotional behavioral disorders (EBD). This project aims to build a multimodal sensing system which provides continuous and efficient monitoring of users? activities using mobile phones and wearable sensors. Our system analyzes and correlates different sensor streams to infer certain behaviors as well as possible environmental factors that may trigger such behaviors. Furthermore, our system provides non-intrusive peer assisted localization technique that allows caregivers to track the whereabouts of monitored users. We also develop efficient schemes to infer higher layer information e.g. activity levels of monitored individuals; social relationships among monitored users. Additionally, the communities extracted from a mobile phone enabled social network in our system not only enable mobile healthcare systems but can also be exploited for securing certain components of the system (e.g., coping with clone attacks). Our system allows users to be monitored for their mental, cognitive, and physical well-being and can potentially reduce the cost for special need education as a result of increasing the productivity of teachers and caregivers.","title":"CSR: Small: Collaborative Research: Smartphone Enabled Social and Physical Compass System (SENSCOPS)","awardID":"1217379","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[517746],"PO":["565255"]},"193293":{"abstract":"This research introduces novel recharging systems and algorithms to supplement existing systems and lead to autonomous, sustainable energy management on sensor networks. Applications such as bridge fault detection that rely on sensor networks operating away from buildings often lack energy for long-term monitoring. In these scenarios traditional recharging methods (e.g. solar panels) are unavailable or cannot provide sufficient energy (e.g. at night). To achieve this, the research has three key components. The first component develops an unmanned aerial vehicle (UAV) to wirelessly recharge sensor nodes, a localization system based on magnetic field intensity, and autonomous control algorithms that optimize power transfer. Based on this system, the second part develops online algorithms for UAV trajectory optimization in systems with multiple UAVs as well as distributed algorithms that induce energy deficits in a subset of nodes to enable efficient recharging. Finally, the third component provides models and distributed algorithms to predict future energy recharging and usage for sensor nodes. <br\/><br\/>This research impacts a range of societal, educational, and scientific topics. This project addresses a critical national need of enabling regular monitoring of bridge integrity through autonomous, energy efficient sensor network and robot systems. Improving bridge fault detection is necessary given aging infrastructure and limited local budgets for performing such work through current manual visual inspection processes. Educationally, at the K-12 level, this provides demos and workshops to enhance existing programs, encouraging young students (especially women) to pursue STEM fields.","title":"CSR: Small: Collaborative Research: Adaptive and Autonomous Energy Management on a Sensor Network Using Aerial Robots","awardID":"1217428","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[517774],"PO":["564778"]},"194031":{"abstract":"The vast majority of the code in most applications comes from the libraries it imports, rather than the program itself. As a result, hackers often exploit flaws in libraries like glibc or openssl that are used across multiple applications instead of attacking individual flaws in code specific to the application. This makes it easier for an attacker to compromise many applications at once with a single exploit. This work isolates the impact of flaws in a deployed program into the smallest area possible. This will dramatically increase the security of applications in the cloud, on mobile phones, and everything in between.<br\/><br\/>To achieve this goal, this research develops a new abstraction that acts as a lightweight and extremely efficient intra-process isolation mechanism that builds on recent advances from operating system virtualization and memory-safe code execution (such as SFI). This abstraction, called a cage, allows different pieces of code that execute in the same process to be isolated from each other. This means that a flaw within a piece of code can only be used to exploit the code within that cage. Each cage also conceptually is its own process from an resource accounting standpoint. In addition, calls between cages are extremely lightweight and do not require a context switch or OS intervention. The cage abstraction provides an isolation mechanism that is high-performance and with very low overhead while improving application security.","title":"TWC: Small: Caging Libraries To Control Software Faults","awardID":"1223588","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["561066"],"PO":["564388"]},"197551":{"abstract":"The ACM Special Interest Group on Bioinformatics, Computational Biology, and Biomedical Informatics (SIGBioinformatics; http:\/\/www.sigbioinformatics.org\/) has been instituted in 2010 with the aim of focusing on theory and practice of processing, storing, analyzing, mining and knowledge management of biological and biomedical data. The mission of ACM SIGBioinformatics is to support advanced research, training, and outreach in Bioinformatics, Computational Biology, and Biomedical Informatics by stimulating interactions among researchers, educators and practitioners from related multi-disciplinary fields. The third ACM Conference on Bioinformatics and Computational Biology will be held in Orlando, Florida in October 2012. As a flagship conference of ACM SIG Bioinformatics, it provides a premier forum for interdisciplinary and multidisciplinary research encompassing disciplines of computer science, mathematics, statistics, biology, bioinformatics, and biomedicine. This award provides travel support for 20 graduate students to attend the conference. This will allow the students to participate in the conference, workshop and tutorials. Additionally special activities such as a doctoral consortium and student poster session will be specifically targeted for them. Participation in premier research conferences in bioinformatics and computational biology is an integral component of doctoral research-based training. It will allow them to interact and network with and potentially collaborate with leading researchers in the discipline. In addition, it will provide them access to potential career opportunities for full time employment after graduation in industry, academia and government.","title":"Student Travel Sponsorship for Third ACM BCB Conference, 2012","awardID":"1244794","effectiveDate":"2012-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["538607",530024],"PO":["565136"]},"195153":{"abstract":"The NSF Sustainable Energy pathways (SEP) Program, under the umbrella of the NSF Science, Engineering and Education for Sustainability (SEES) initiative, will support the research program of Prof. David Shonnard and co-workers at Michigan Technological University. Drop-in, renewable replacements for petroleum-based liquid transportation fuels is a national strategic goal for energy security. The four-year Wood to Wheels (W2W) SEP project will achieve this goal by conducting transformative, multidisciplinary, comprehensive, and integrated research in the area of forest-based infrastructure-compatible liquid biofuel for vehicular transportation. Hypothesis-driven research is to be organized into three main thrusts plus a cross-cutting thrust integration activity; 1) Sustainable Forest Systems, 2) Two-Stage Torrefaction\/Pyrolysis-Based Conversion Processes, 3) Energy Utilization of Advanced Biofuels, and 4) Integrated Sustainability Assessment and Decision Making. The Sustainable Forest Systems research thrust will feature research in forest productivity modeling, ecosystem nutrition and productivity, and genomics-guided feedstock (poplar) improvement. The Conversion Processes thrust will investigate a novel two-stage torrefaction and pyrolysis based processing strategy to prepare an improved bio-oil for multi-functional catalytic upgrading to a hydrocarbon green diesel fuel product. The Energy Utilization thrust will incorporate a surrogate fuels approach to determine the relationship between fuel component classes and combustion characteristics, and to provide feedback to the Conversion thrust team on targets for optimal GD composition. The Sustainability Assessment thrust will produce decision support tools including indicator sets, perform process simulation and optimization, technoeconomic analyses, life cycle assessments, greenhouse gas analyses, and energy balances.<br\/><br\/>The goal of this project is to achieve scientific and engineering breakthroughs for production of an infrastructure-compatible green diesel (GD) with system-wide benefits; such as clean combustion in engines (low particulates and NOx), reduced life-cycle greenhouse gas emissions compared to fossil fuel, low cost per gallon, rural job creation, increased energy independence, high productivity per acre of forest biomass, plant genotypes with favorable composition for conversion, and engines optimized to use the prescribed component makeup of the GD. Researchers, including 11 faculty, 7 PhD students, and one postdoc from Forestry, Social Sciences, Chemical Engineering, Mechanical Engineering, will develop new knowledge about complex coupled natural\/industrial\/societal systems. This SEP project will create a diverse highly skilled biofuels workforce with the technical research experiences and broad sustainability education needed to support a renewable transportation fuels industry. The research team will interact with local communities to gain information on what they believe to be important measures of sustainability in their communities. Through this interaction, these communities will receive education on biofuel production technologies and what sustainability means, how it can be measured, and whether trade-offs among goals are necessary to institute sustainable biofuel systems in their area. The team will implement a W2W SEP diversity plan to: (1) recruit women, under-represented minorities, and persons with disabilities as graduate students, and (2) implement integrated practices that enable the academic and professional success of the SEP students and postdoc. Results from the Sustainability Assessments research thrust will be fed back to the other thrust teams in order to guide research and overcome sustainability challenges that arise at key processing stages along the life cycle.<br\/><br\/>The project will contribute to the development of biomass-based biofuel production in the US in order to displace nearly all imported petroleum, to support domestic jobs, and to reduce greenhouse gas emissions. Project deliverables will help establish a new forest-based biofuels industry featuring high productivity forest energy crops, sustainable forest management practices, catalysts and process technologies, innovations in engine systems, sustainable decision-making databases, and analysis methods\/software tools.","title":"SEP: Sustainable Forest-Based Biofuel Pathways to Hydrocarbon Transportation Fuels: Biomass Production, Torrefaction, Pyrolysis, Catalytic Upgrading, and Combustion","awardID":"1230803","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"8026","name":"Sustainable Energy Pathways"}}],"PIcoPI":["529460","546383",523115,"533692","548022"],"PO":["556345"]},"198673":{"abstract":"The research provides a method to detect and mitigate the insider threat. Currently insider threat detection is focused only on the malicious person attempting to harm the organization. Most employees seek to assist their employers. Very few people want to hurt the business providing their livelihood. However, many employees take risks (sometimes very serious risks) on the network. We simultaneous help the benevolent employee and detect the malicious one.<br\/><br\/>Our system helps employees by showing them network risks, and helping them decrease the risk. Sometimes risk-taking is worth it; for example, emailing a document to a superior in dire straights using gmail. Sending documents over gmail is risky. Our system helps the employee mitigate the risks they are taking. In the gmail example, our system automatically changes the settings to encrypt the email. Rather than walking through changing setting (which can be intimidating) or just popping up a confusing and technical dialogue box, we just encrypt the email for the employee. Also, in this case our system shows the employee that choosing not to encrypt the email will be very risky. The document (if it is not encrypted) can be seen by anyone on the Internet.<br\/><br\/>An important part of our system is that it treats employees as partners to the organization. At the same time our system detects insiders by watching across the organization for the person taking both large one-time risks and small cumulative risks. This proposal is innovative, and a very different approach than industry uses today.","title":"EAGER: Human-Centered Mitigation of the Insider Threat","awardID":"1250367","effectiveDate":"2012-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["537066"],"PO":["565327"]},"198794":{"abstract":"Large-scale computing environments such as data centers and cloud computing are becoming the core computing infrastructure, making the availability of such services extremely critical. However, these environments are increasingly vulnerable to both hardware and software failures. This project designs failure-aware techniques for modeling, prediction, and resource management in large-scale computing environments with the presence of hardware and software failures at various levels. Intellectually, this project develops fundamental understanding of workload and reliability characteristics, and investigates how improved capacity planning models and prediction techniques can obtain useful information for system design and maintenance. This project further provides insights of the impact of software\/hardware component failures in the area of resource management. <br\/><br\/>The results of this project will include new capacity planning models that evaluate both reliability and performance of a given system and new prediction techniques that forecast the future failure occurrences by taking advantage of temporal dependence in failure events. Based on the modeling and prediction techniques, this project will develop new failure-aware runtime strategies for job scheduling, node allocation, and system maintenance, aiming to achieve high system performance and reliability in complex large scale systems.","title":"CSR: EAGER: An Integrated Framework for Performance and Reliability in Large-scaled Computing Systems","awardID":"1251129","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[533332],"PO":["565255"]},"187321":{"abstract":"This project aims to develop new mathematical and computational tools for understanding the basic information-processing strategies of neurons and neural populations in the brain. Recent technological advances have enabled large-scale recordings of neural activity from intact neural circuits, but there is a severe shortage of theoretical methods for revealing what this activity means--that is, what information it carries, and how it gives rise to behavior. The research described in this proposal will address these questions using novel statistical techniques for studying the neural code in single neurons and neural populations, using both extracellularly and intracellularly recorded neural data. <br\/><br\/>There are at least two important statistical aspects to the proposed research: first, new methods for reliably estimating the neurobiological variables of interest (e.g., spikes, membrane currents, synaptic conductances, etc.) from noisy experimental recordings; and second, powerful, flexible, model-based methods for understanding the complex, high-dimensional, and time-dependent relationship between sensory stimuli, behavioral responses, and neural activity. The three specific aims of the proposal focus on: (1) the encoding and decoding of decisions from multi-neuron spike trains in parietal cortex; (2) intracellular signals in visual cortex, at the level of membrane potential and synaptic currents, and their relationship to the information conveyed in spike trains; and (3) advanced methods for adaptive, \"closed loop\" neurophysiology experiments, leading to more informative experimental designs and more interpretable neural datasets. All three aims will involve intensive collaborations with experimental groups and will tightly integrate theory and experiment.<br\/><br\/>The proposed research will reveal new features of visual and cognitive representations in cortex, and will unlock the neural code at multiple levels of biophysical detail in sensory, motor and cognitive systems. More broadly, the research will shed new light on information flow in groups of neurons, with implications for both the treatment of brain disorders and the design of new technology.","title":"CAREER: Unlocking the neural code with spikes, currents and conductances","awardID":"1150186","effectiveDate":"2012-09-01","expirationDate":"2017-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"7713","name":"ACTIVATION"}}],"PIcoPI":[502398],"PO":["564318"]},"199663":{"abstract":"CAREER: Model-based Reconstruction of Ancient Biological Networks<br\/><br\/>New experiments are revealing interactions between many molecules, such as proteins, in present-day bacterial and animal cells. These interactions have evolved over time, resulting in the networks of interactions we see today. Often, however, we are interested in what such a network looked like in the past in a now-extinct ancestral species. This project will develop new algorithms for recovering lost, ancient biological networks from present-day networks. To do this, we view the reconstruction problem as a network design task where the designed network is subjected to random modifications according to a model of network evolution. We then seek to design an ancestral network that is likely to have evolved into the observed, present-day networks. The developed techniques will be applied to find precursor networks of a single network at various points in time and to find the common ancestor network of several extant organisms. In concert with the reconstruction task, we will create more realistic computational models of network evolution by efficiently searching a large space of possible evolutionary models. Our examination of recovered ancient networks will advance our understanding of how biological interactions evolve and how that evolution has shaped the function of the cell. The application of the algorithms to retrieve the history of social networks will also be explored.<br\/><br\/>The project further aims to excite undergraduate and high school students about a career in science by expanding a successful summer internship program in bioinformatics. The program will host additional interns to conduct research on systems biology, genomics, and other topics at the interface of computer science and molecular biology. We will also create improved online resources to connect undergraduates interested in bioinformatics research with faculty mentors. The research on ancestral network reconstruction will be incorporated into several undergraduate and graduate bioinformatics and algorithms courses.","title":"CAREER: Model-based Reconstruction of Ancient Biological Networks","awardID":"1256087","effectiveDate":"2012-09-01","expirationDate":"2016-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["550675"],"PO":["565223"]},"189653":{"abstract":"This research characterizes the benefits of feedback in communication and develops techniques to achieve those benefits. Today's communication systems seek to move information as rapidly as possible from transmitter to receiver. This research involves using feedback (messages sent from the receiver back to the transmitter) to allow communication systems to approach the highest possible communication rate (the channel capacity) using less transmission time (latency) and lower-complexity decoding. A key aspect of this research is the development of new error control codes and new techniques to use those codes to facilitate transmissions that approach capacity with much lower latency than systems that do not use feedback. Broader impacts include training high school students through the UCLA Engineering (HSSEAS) High School Summer Research program and training undergraduates through the UCLA Engineering undergraduate research program.<br\/><br\/>Traditional techniques approach capacity without feedback by using long block lengths and complex decoding. However, information theory indicates that feedback permits capacity to be approached with shorter block lengths and simpler decoding. This research employs a rate-compatible sphere-packing analysis to provide a quantitative analysis of the latency reduction possible with feedback. This analysis provides decoding error trajectories that guide the development of rate-compatible code families needed to approach capacity with feedback. Practical benefits of these rate-compatible code families with feedback will be characterized in the context of a typical wireless communication system operating in additive white Gaussian noise. These techniques are extended to fading channels and higher-order modulations. The overall goal of this research project is the development and promulgation of a fundamental understanding of how code families should be designed to work with feedback to achieve capacity with very short block lengths.","title":"Collaborative Research: Code Design and Analysis to Approach Capacity with Short Blocklengths Using Feedback","awardID":"1162501","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[508494,"562262",508496],"PO":["564924"]},"199575":{"abstract":"The long-term goal of this project team is to learn how to design interactive graphic novels and associated serious games to help adolescents learn social problem solving skills. The intention is that these skills will not simply be learned in a way that allows the teens to say what they should do but, rather, that they will be learned in a way that results in behavior change. The project is investigating the use of graphic novels to engage teens in thinking about difficult social situations and to model for them ways of dealing effectively and in non-violent ways with those tricky situations, and they are investigating the use of associated serious games and other interactive components to promote reflection on what has been read, promote discussion around the situations, and provide opportunities for practice. This novel idea has its foundations in the approach to therapy called Cognitive Behavioral Modification and resonates with what the approach to education called Cognitive Apprenticeship suggests about promoting skills learning. The project brings together experts in Cognitive Behavioral Modification, social psychology, interactive narrative, design of graphic novels, serious games, and adolescent health and well-being. The goals of this EAGER project are to (i) synthesize social psychology, interactive narrative, and serious games approaches to envision the experiences learners need to have to learn and take on new social problem solving behaviors, (ii) begin the design of an interactive graphic novel and experiences around it that has a good chance of promoting behavior change among the targeted population of at-risk teens, and (ii) develop a strong research team that will collaborate over the long term in following through on worthy ideas that come from this initial effort.<br\/><br\/>The potential broader impacts of this work lie in the potential for (i) using graphic novels, which are easily accessible and can be of high interest to young people, to promote thinking and doing that can help teens learn new problem solving behaviors, (ii) learning how to promote productive behavior change, and (iii) identifying the roles technology can play in such learning and how to use technology well as a resource in promoting productive behavior change.","title":"EAGER: Adolescents Learning Social Problem-Solving Skills Using an Interactive On-Line Graphic Novel","awardID":"1255694","effectiveDate":"2012-09-01","expirationDate":"2014-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":["560972"],"PO":["562669"]},"187123":{"abstract":"The research objective of this proposal is to create novel computational algorithms and image processing tools that will make it possible for biologists to reconstruct large-scale neural circuits from electron microscopy volumes. Electron microscopy is a key technology in reconstruction of neural circuits at the level of individual neurons and synapses, also known as connectomics. While an important motivation of connectomics is providing anatomical ground truth for neural circuit models, the ability to decipher neural wiring maps at the individual cell level is also important in studies of many neurodegenerative diseases. State-of-the-art image analysis solutions are still far from the accuracy and robustness of human vision and biologists are still limited to studying small neural circuits using mostly manual analysis. The proposed computational models will provide biologists a tool for segmenting individual neurons and detecting other structures such as synapses in very large electron microscopy volumes, and proof reading these automatically produced results in a time efficient manner.<br\/><br\/>Reconstruction of a neural circuit from an electron microscopy volume involves pixel-by-pixel annotation of these images into classes such as cell membrane, mitochondria and synaptic vesicles and the segmentation of individual neurons in three dimensions. This task demands extremely high accuracy. Even with 99% pixel accuracy, an acceptable accuracy for many other applications, it is virtually certain that almost every neuron in a volume will be incorrectly segmented due to their global, tree-like structure and correspondingly large surface area. Therefore, lack of reliable automated solutions is a critical bottleneck in the field of connectomics. In this project, a novel hierarchical model will be created by combining the representation power of sparse dictionaries and their ease of learning with an inference and proof reading capability. Human experts will contribute to the process by providing ground truth for supervised learning and proof reading of automatically produced results. The combination of deep sparse dictionaries with inference using connection weights from conditional probabilities can provide a very fast way to learn hierarchical models. Several variants of the model will be studied for understanding the relative importance of feature representation, inference, symmetric connections, deep and lateral connections. The model will be applied to general object classification and image parsing problems in computer vision as well as connectomics datasets. Success will be evaluated on real datasets annotated by experts.","title":"CAREER: Deep sparse dictionary context models and their application to image parsing and neuron tracking for connectomics","awardID":"1149299","effectiveDate":"2012-09-01","expirationDate":"2017-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[501995],"PO":["564318"]},"198497":{"abstract":"The National Science Foundation (NSF) is pleaserd to announce the selection of MIT's Scott Aaronson, an Associate Professor of Electrical Engineering and Computer Science, to receive its 2012 Alan T. Waterman Award. Dr. Aaronson works with the Computer Science and Artificial Intelligence Laboratory, MIT's largest interdepartmental lab. <br\/><br\/>The Waterman Award is the National Science Foundation's (NSF) highest honor. The annual award recognizes outstanding researchers under the age of 35 in any field of science or engineering NSF supports. This is the first year that two awardees have been selected. <br\/><br\/>In addition to a medal, each of this year's awardees will receive a $1 million grant---twice the amount of last year's award---over a five-year period for further advanced study in his field.<br\/><br\/>Prof. Aaronson, a theoretical computational scientist, pursues research interests that focus on the limitations of quantum computers and computational complexity theory more generally. His research addresses a variety of topics, including the information content of quantum states, the physical resources needed for quantum computers to surpass classical computers, and the barriers to solving computer science's vexing P versus NP question, that is, whether every problem whose solution can be quickly verified by a computer can also be quickly solved by a computer.","title":"2012 Waterman Award","awardID":"1249349","effectiveDate":"2012-09-01","expirationDate":"2017-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[532609],"PO":["565157"]},"198387":{"abstract":"This travel support enables U.S.-based students to attend the 20th ACM SIGSPATIAL GIS 2012 Conference, held in Redondo Beach, CA, USA, November 6-9, 2012 (http:\/\/acmgis2012.cs.umd.edu\/). The ACM SIGSPATIAL GIS conference has established itself as the world's premier conference to foster research in the areas of Spatial Data and Analysis and Geographic Information Systems (GIS). The conference provides a forum for original research contributions covering all conceptual, design, and implementation aspects of GIS ranging from applications, user interfaces, and visualization to storage management and indexing issues. It brings together researchers, developers, users, and practitioners carrying out research and development in novel systems based on geospatial data and knowledge, and fostering interdisciplinary discussions and research in all aspects of GIS. It is the premier annual event of the ACM Special Interest Group on Spatial Information (ACM SIGSPATIAL). The conference seeks to continuously advance the state of-the-art in spatial data management and spatial data analysis and broaden its impact.<br\/><br\/>This grant provides partial travel support and conference registration for 30-35 qualified U.S. based graduate and promising undergraduate student participants. The students will greatly benefit from attending this conference, as they will be able to partake in the current state-of-the-art in the area of geospatial systems and applications, present their work, and potentially make connections for research collaborations and research mentoring. The total number of ACM SIGSPATIAL GIS participants in the past has been in excess of 250 participants, with a majority of the participants from the U.S., followed by Europe and Asia. The conference participation has shown a steady increase in the past few years due to the growing importance of geographic information. A strong representation of U.S.-based graduate students at ACM SIGSPATIAL GIS is useful in maintaining U.S. competitiveness in the important research areas crucial for U.S. infrastructures and applications that critically depend on geo-referenced information. Those who receive the award will be featured in the NSF Student Supported Research special section of the combined Poster, Demo, and PhD Showcase Session, a major event in the conference that is attended by all conference participants.","title":"Student Travel and Activities Support: ACM SIGSPATIAL 2012 International Conference on Advances in Geographic Information Systems","awardID":"1248961","effectiveDate":"2012-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["561230"],"PO":["563751"]},"189576":{"abstract":"Comparison is an essential part of data analysis and, therefore, of many visualization tasks. While the published literature provides a wealth of visualization tools for looking at individual objects (graphs, volumes, time series, gene sequences, molecular motions, etc.), there has to date been less consideration of support for comparison. The PIs argue that comparison tasks are best supported by tools explicitly designed for that purpose. The problem is that visual comparison becomes more challenging as the number of objects, their size, and the complexity of the objects and\/or of the relationships among them increases. The difficulty is further compounded by our rapidly growing ability to collect and generate data. In prior work the PIs have developed some encouraging initial examples of comparison tools, but these are specialized successes that offer little guidance for future endeavors. Addressing a wider range of comparison problems at greater scale with our present limited understanding thus largely remains an art that requires considerable effort. The PIs' goal in this project is to move towards a science of visual comparison. By studying visual comparison as a general problem, they will establish a domain-independent foundation for the field that facilitates the design of future tools which allow the creation of more effective and scalable comparisons. To these ends the team will pursue three interconnected research threads. They will define theories that are grounded upon principles of visual cognition. They will explore case studies (derived from real problems suggested by domain collaborators) that challenge and extend these theories, provide examples for empirical study, and suggest or use general concepts. And they will identify common tasks, designs, and strategies that enable development of generalized techniques, guidelines, and software components. This approach uniquely combines empirical studies, design explorations, and software development to take the field of visual comparisons to a new level that is both rooted in theory yet viable in practice. <br\/><br\/>Broader Impacts: Because visual comparison plays a key role in diverse domains (including essentially all of the sciences, engineering, and medicine), the potential benefits from an improved science of visual comparison tools are far reaching. To ensure maximum applicability for project outcomes, the PIs are directly collaborating with physical, biological, social, educational, and medical scientists, as well as with engineers and scholars in the humanities. The project will generate visualization tools, software components, and resources for visualization development by others. Visual comparison will serve as a mechanism to expose students at all levels to issues in data understanding. This project will also provide training for visualization specialists, engage non-technical students in visualization, and explore the role of visualization in public outreach efforts.","title":"CGV: Medium: Collaborative Research: Visualizing Comparisons","awardID":"1162013","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["558600"],"PO":["565227"]},"198178":{"abstract":"This exploratory project applies the design approach of Named Data Networking (NDN) to generate benefits for cyberphysical systems (CPS). NDN is an emerging network architecture that shifts the thin waist of the Internet from IP's host-centric model to a data-centric model. It uses names to directly fetch data and binds names to data with cryptographic signatures. The project uses Building Automation Systems (BAS) as a driver and representative case of CPS encompassing the control, monitoring and management of heating, ventilation and air conditioning (HVAC), lighting, water, physical access control and other building systems. It will evaluate whether, in such real-world building automation systems, NDN can provide: (1) quantifiably better performance and reliability characteristics; (2) equivalent or better functionality for device addressing as typical middleware and application-specific protocols; (3) reduced application development complexity; (4) authentication, verification, and access control through fundamental NDN capabilities and strategies. The project also considers NDN device and service naming approaches that provide new functionality. To provide an environment on which to build and evaluate NDN support for BAS, the project will deploy a closed loop control system on the NDN testbed consisting of industry-standard electrical demand monitoring and lighting control. <br\/><br\/>Broader Impact: Cyberphysical systems are a new and rapidly progressing frontier in the broad use of computing technologies for critical infrastructure. However, existing CPS can be complex, often difficult to build and maintain, brittle to changes and vulnerable to faults resulting in potentially large impacts. This effort aims to pave a new direction that enables rapid development of reliable and secure CPS, and to bridge CPS with traditional IT for applications including energy management, remote operation, monitoring and data mining, and new types of human-computer interaction.","title":"EAGER: Bridging The Gap Between Application Architecture and Network Architecture In Cyberphysical Systems Via Named Data Networking","awardID":"1248049","effectiveDate":"2012-09-01","expirationDate":"2014-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["543560","552479"],"PO":["565090"]},"198068":{"abstract":"This award supports the NSF Workshop: Data Curation: Ensuring Quality and Access to Enable New Science, to be held in September 2012 in Arlington, VA. The value of data to the global economy has been well-documented and spawned calls for training professionals who practice data curation and stewardship, data analytics, and \"big data\" management. It is evident that poor data is worse than no data because it wastes time, leads to poor science and decisions, and diminishes trust in the entire data enterprise. Data curation demands tools and techniques at each phase of the data life cycle that lead to effective and efficient data services that people trust. This workshop brings together leading researchers in data curation to establish a research agenda to guide development of these tools and techniques. <br\/><br\/>This workshop will have impact on the emerging data curation research and development community by defining directions for tools and techniques that support selection, metadata annotation, storage, access, use and reuse, and preservation of scientific and scholarly data. Such tools and techniques will make science and scholarship more effective and may be adapted to personal data management applications such as personal health or educational records. The workshop web site (http:\/\/datacuration.web.unc.edu\/) provides will be used to disseminate further information, including the resulting workshop report that will provide a roadmap for the future data curation research and follow-up activities.","title":"Workshop: Data Curation: Ensuring Quality and Access to Enable New Science","awardID":"1247471","effectiveDate":"2012-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["335186",531548],"PO":["563751"]},"198189":{"abstract":"This INSPIRE award is partially funded by the Communication and Information Foundations Program in the Division of Computing and Communication Foundations of the Directorate for Computer & Information Science & Engineering (CISE\/CCF) and the Economics Program in the Division of Social and Economic Sciences of the Directorate for Social, Behavioral & Economic Sciences (SBE\/SES), and addresses engineering and economic challenges in developing a sustainable pathway to an electric-vehicle based transportation system. In particular, the project aims to develop transformative technologies and economic\/policy solutions that facilitate a paradigm shift from individual and on-demand charging of today to one of network-switched, interactive, and managed charging. The major benefits of the new paradigm include reduced peak power demand from large scale charging, improved profit potential for charging facilities, enhanced consumer experience, and ultimately the wider adoption of electric vehicles.<br\/><br\/>The project pursues joint economic and engineering solutions based on an architectural innovation that integrates renewable sources, responds to real time electricity pricing, and interacts with consumers through dynamic and service differentiated pricing. The project employs economic modeling and optimization techniques to characterize demand and profit conditions. A dynamic model will be developed to investigate the interactions between charging facility investments and electric vehicle ownership. Counterfactual analysis will be conducted to gain insights into the roles of consumers, investors, and the government and the impacts of different economic, policy and technological factors in the diffusion process of electric vehicles and charging infrastructure.","title":"INSPIRE :An Engineering and Economic Pathway to Electric Vehicle-Based Transportation","awardID":"1248079","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"8078","name":"INSPIRE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"1320","name":"ECONOMICS"}}],"PIcoPI":[531874,531875],"PO":["564924"]},"193580":{"abstract":"This project develops efficient computer vision algorithms based on distributed message passing for solving crowd-scene analysis tasks such as detection and tracking of closely spaced individuals. These and other vision tasks can be formulated as discrete combinatorial optimization problems, e.g., binary linear or quadratic programs, and studying their underlying mathematical structure can yield insights that allow larger and more challenging problem instances to be addressed. Recent theoretical work proving the correctness of message passing for some classes of binary linear programming problems is being leveraged to develop practical vision algorithms for crowd scene analysis and extended to develop algorithms for finding good approximate solutions to harder problems. The project team is also exploring approximate inference methods based on randomization and on decomposition of large-scale problems into collections of interrelated subtasks that can be solved more efficiently and in parallel. <br\/><br\/>Automated vision systems can continuously monitor crowded public spaces to provide real-time situational awareness of crowd density and to detect early signs of dangerous behavior or deviations from normal traffic flow. The ability to track individuals through a crowd and to detect the interactions of groups of people has applications in the areas of homeland security, law enforcement, and defense. Results from this project will be disseminated through collaboration with other scholars, publication of peer-reviewed articles, presentations at professional meetings, introduction of course modules into the graduate and undergraduate computer science curriculum, and through public release of source code.","title":"RI: Small: Distributed Combinatorial Optimization for Crowd-Scene Analysis","awardID":"1218729","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[518440],"PO":["564316"]},"193470":{"abstract":"This research targets the design and evaluation of protocols for<br\/>secure, privacy-preserving data analysis in an untrusted<br\/>cloud. Therewith, the user can store and query data in the cloud,<br\/>preserving privacy and integrity of outsourced data and queries. The<br\/>PIs specifically address a real-world cloud framework: Google's<br\/>prominent MapReduce paradigm.<br\/><br\/>Traditional solutions for single server setups and related work on,<br\/>e.g., fully homomorphic encryption, are computationally too heavy and<br\/>uneconomical and offset cloud advantages. The PIs' rationale is to<br\/>design new protocols tailored to the specifics of the MapReduce<br\/>computing paradigm. The PIs' methodology is twofold. First, the PIs<br\/>design new protocols that allow the cloud user to specify data<br\/>analysis queries for typical operations such as searching, pattern<br\/>matching or counting. For this, the PIs extend privacy-preserving<br\/>techniques, e.g., private information retrieval or order preserving<br\/>encryption. Second, the PIs design protocols guaranteeing genuineness<br\/>of data retrieved from the cloud. Using cryptographic accumulators,<br\/>users can verify whether data has not been tampered with. Besides<br\/>design, the PIs also implement a prototype that is usable in a<br\/>realistic setting with MapReduce.<br\/><br\/>The outcome of this project enables privacy-preserving operations and<br\/>secure data storage in a widely-used cloud computing framework, thus<br\/>remove one major adoption obstacle, and make cloud computing available<br\/>for a larger community.","title":"CSR: Small: Privacy and Security for MapReduce Clouds with PASMAC","awardID":"1218197","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[518181,518182],"PO":["565255"]},"193591":{"abstract":"Building on recent progress in applying algebraic methods to traditional problems of computational and combinatorial geometry, the PI will explore further use of the tools of algebraic geometry in this subject. In particular, the PI will develop novel algebraic techniques<br\/>-- as an alternative to random sampling,<br\/>-- for addressing geometric incidence problems,<br\/>-- for tackling range searching questions,<br\/>-- for making progress on the problem of repeated distances in the plane, and<br\/>-- to facilitate multilevel partitioning schemes, <br\/>by extending the ideas of Guth and Katz, and of Sharir and co-authors, combining algebraic tools such as Bezout's theorem, fast Fourier transform, and Veronese lifting with existing methods from computational and combinatorial geometry.<br\/><br\/>This work will significantly expand the arsenal of tools available to researchers in computational and combinatorial geometry. The techniques of this field, in turn, have wide-ranging applications in a variety of practical subjects, such as computer graphics, geographic information systems, machine learning, and robotics path planning, amongst others.<br\/><br\/>PI's home institution (Polytechnic Institute of NYU) has historically had a very diverse student body. Education is much more effective when in the classroom students encounter easily accessible research problems that remain open to this day. Such problems have been and will be discussed in computational geometry and algorithms courses taught by PI, increasing accessibility and public appreciation of the somewhat nebulous \"research in theoretical computer science.\"","title":"AF: Small: Exploring Algebraic Methods in Computational and Combinatorial Geometry","awardID":"1218791","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[518464],"PO":["565157"]},"193492":{"abstract":"Unfortunately for individuals who are blind and visually impaired, although access to text has greatly improved with computers, the computer has also greatly facilitated the ease of producing, storing, transmitting and using graphical representations to convey information. This has created a serious obstacle for the millions of people in the United States who are visually impaired or blind, because graphics are now ubiquitous and used in many instances as the sole information presentation method. Although presenting graphical information in terms of tactile diagrams is one alternative that has been proven useful, creating these diagrams remains a complex art that usually requires participation of a trained human. This is because to be effective tactile diagrams must be simplified; otherwise, they may be impossible to understand. Automating this process would have advantages in terms of cost, in terms of providing diagrams in a timely fashion (or even providing them at all), and in terms of independence for the intended users. In this project, which takes a first step toward this goal, the PI and her team will focus on the automatic conversion to tactile diagrams of two kinds of graphics: photographs and line drawings. To this end, a multi-step process is envisaged. First, techniques to segment images without a lot of fragmentation will be examined, modified and\/or developed based on the current computer vision literature. Next, techniques will be developed for automating the simplification process, based on the manual steps as outlined by the Braille Authority of North America. Two main aspects will be considered: simplifying lines\/curves in the diagram, and reducing clutter (defined as a situation where components of the graphic are too close together or so similar that they are hard to distinguish tactually). Then, automatic, metric rectification techniques will be explored, modified and\/or developed to remove perspective from an image and replace it with a standard canonical view (because removing perspective seems to improve the user's ability to understand a tactile diagram). Finally, user studies will be conducted to evaluate the effectiveness of the tactile graphics created by the new automatic methods in comparison to those created manually by expert tactile diagram makers.<br\/><br\/>Broader Impacts: The ultimate goal of this line of research is to provide people who are blind or visually impaired with immediate and automatic access to any desired information, and thereby to remove the current barriers due to the graphical nature of computers and visual digital media. Project outcomes will be useful not only to adult members of the target communities; they will also make it possible to provide access to children's picture books to promote development in blind and visually impaired youngsters. The project will train at least one graduate and several undergraduate students in understanding the needs of the target communities and developing assistive technology for them. Results will be disseminated through the usual scientific channels and also in presentations to relevant stakeholders including individuals who are visually impaired, their teachers and other rehabilitation professionals. Results from this work will also be presented in workshops to K-12 students at the Math, Science, Innovation Center of Richmond to foster interest in STEM fields.","title":"HCC: Small: Automatic Simplification Methods for Tactile Graphics","awardID":"1218310","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[518233,518234],"PO":["565227"]},"201104":{"abstract":"One of the ultimate goals of efforts in structural biology is to have a comprehensive molecular understanding of the biological processes in an organism. A fundamental step towards this goal is to elucidate the structure of, and relationships between, the large numbers of proteins involved in these processes. Such large-scale studies are necessary to uncover, for example, the genetic and molecular basis for diseases, as well as for designing effective treatment of these diseases. Thus, a holistic understanding of such biological systems necessarily requires high-throughput computational methods that can process and interpret experimental data recorded on proteins, for example from X-ray crystallography, or Nuclear Magnetic Resonance (NMR), and synthesize it with other empirically available data (e.g., a repository of protein structures such as the Protein Data Bank). Currently, practitioners in structural biology make use of manual or ad hoc approaches for interpreting and synthesizing data that lack guarantees on solution quality or running time (or both). To enable large-scale studies in structural biology, we propose to study several basic problems from a computational point of view, and provide formulations and algorithms that are compatible with the goals of biologists and biochemists. For example, practical structure determination methods that incorporate experimental data are typically based on techniques such as simulated annealing or molecular dynamics, which typically have no guarantees on solution quality or running time. Due to their heuristic nature, even automated methods require manual intervention, and can be quite time consuming (e.g., months to years, depending on the desired accuracy and the difficulty of processing and interpreting experimental data. Understanding biological systems at a molecular level requires the study of tens to hundreds of proteins, so it is clear that traditional approaches, both manual and automated, are a bottleneck to proteomics research, and we must develop efficient computational approaches to enable large-scale proteomics efforts. Using a combination of experimental and modeling data, the research spans three problem areas: protein structure, protein-protein interactions, and allosteric regulation. A key question when designing formulations for biological problems is, how much input (and how much experimental uncertainty or noise) admits efficient and accurate algorithms? The high-level objectives in each of the proposed problem areas is to: 1. Consider available experimental and modeling data, and define realistic optimization criteria that are compatible with the goals of biologists and biochemists. 2. Design algorithms that efficiently compute optimal or near-optimal solutions, and provide worst-case analysis on solution quality and running time. If such algorithms are not possible, provide lower bound proofs that show the extent to which input data is not adequate. The work will be evaluated through collaboration with biologists. The research actively engages graduate and undergraduate students in the interdisciplinary research as well as more theoretical computer science. A summer project has been developed for a high school student that will provide the basis of a set of locl high school outreach activities.","title":"CAREER: Algorithms for Experimental Structural Biology","awardID":"1263305","effectiveDate":"2012-09-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[539179],"PO":["565136"]},"193382":{"abstract":"In business intelligence and data-driven science, users often wish to consider various \"what-if scenarios\": hypothetical updates and query refinements. Unfortunately current techniques do not support this type of exploration when query answers have high latency, when data sources charge fees, or in mobile, disconnected settings. This project considers how, given a particular set of query aspects and updates, one can precompute a special data representation that can be stored on a client machine and can be used to directly answer queries under a variety of updates and what-if scenarios, without direct access to the data sources. The project achieves this goal by developing \"provisioned representations\" that capture a form of parameterized data instances, from which complex queries (even with multiple levels of aggregation) can be answered. The work develops: (1) the provisioned representation (PR) formalism, (2) means of encoding and storing PRs, (3) a query system and query processing techniques for PRs, (4) a \"wizard\" for generating PRs from parameterized scenarios, and (5) interactive tools for exploring changes to data and queries over PRs. The work will improve decision support systems and help enable \"information foresight\" - the ability to provide, given a question, answers that include additional data relevant to a user's interests. The project supports Ph.D. students, and also develops a new course on networked information management for the University of Pennsylvania's innovative Market and Social Systems Engineering undergraduate degree program on networks and markets. Data and code will be disseminated through public collaborative portals (GitHub, Google Code) and the project Web site (https:\/\/dbappserv.cis.upenn.edu\/home\/?q=node\/173).","title":"III: Small: Provisioning for Autonomous Data Analysis and Scenario Exploration","awardID":"1217798","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["541876",517980],"PO":["563727"]},"193272":{"abstract":"This team is creating a new kind of video-game, one that incorporates the changing characteristics of the person playing the game into the game play itself. This provides game players (learners) with an alternate perspective on their own capabilities and the effects and impacts of their choices and behaviors. In this case, the game is aimed at children learning about health and nutrition, and learners (adolescents and pre-adolescents) wear a wrist band that captures personal-health data (e.g., heart rate, breathing) and incorporates that data into the capabilities of the game player within the game. Game design and game play are based on literatures on game design (especially for promoting learning), embodied cognition, identity development, and effecting behavior change. Research focuses on how learning, identity, and changes in real-life behavior unfold over time and what it is about the game that is influencing or driving those changes. <br\/><br\/>The U.S. experiences one of the highest rates of chronic disease in the world, and health during childhood is a critical predictor of disease onset in later adulthood. Technological innovations that can help children understand the effects of their nutrition and behavior choices on health and that provide information at times when children are interested in seeking that information have potential to play a role in promoting good habits. This project is aiming to create a video game that will be engaging enough to stimulate curiosity and understanding of personal health status and of the effects of personal choices on personal health. Ultimately, the goal is to learn more about how to instill healthy habits early in life. While this project is aimed at promoting habits that will lead to good health, what is learned from the investigation will have potential to affect not only public health but also more basic understanding of how habits develop, how to promote habit development, and how to design engaging video games as vehicles for promoting the kind of learning that results in behavior change.","title":"EXP: Educating Teens to Understand Personal Health (GET-UP)","awardID":"1217317","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":[517724,517725],"PO":["562669"]},"193393":{"abstract":"Macro molecular complexes that act as nano-scale machines provide the<br\/>function of biological systems. Understanding the geometry and functioning of<br\/>the complex as a machine, for instance, how do the various parts move relative<br\/>to each other, is a central goal of biology. Cryo electron microscopy provides<br\/>one noisy image of each of many (e.g., 100,000) instances of the complex. The<br\/>objective of this research is to compute a statistical description of the machine<br\/>from the images and then compute a mechanical model of the machine from<br\/>the statistical description. Understanding how existing complexes function is<br\/>central to engineering changes in their function. Achieving changes would have<br\/>broad impact, for instance, in cancer treatment (inhibiting complexes that pro-<br\/>tect tumor cells by pumping chemotherapy drugs out of tumor cells) and in<br\/>improving the efficiency of complexes involved in the production of biofuels.<br\/>Further impacts include the training of two Ph.D. students who will come from a diverse pool of students.<br\/><br\/>The complex in question will be described as a weighted sum of basis functions with random<br\/>Gaussian weights. A maximum likelihood estimator is used to estimate the<br\/>mean and covariance of the weights. The estimator is computed by an expecta-<br\/>tion maximization algorithm which requires substantial computation due to the<br\/>unknown projection directions of the images. A \"spring and mass\" mechanical<br\/>model in thermodynamic equilibrium predicts the mean and covariance. By<br\/>comparing the predictions of the mechanical model to the estimated mean and<br\/>covariance by Kullback-Leibler divergence, the parameters in the mechanical<br\/>model are estimated.","title":"AF:CIF:Small:Computational structural biology: Reconstruction and understanding for heterogeneous biological macro molecular complexes based on electron microscopy images","awardID":"1217867","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[518003],"PO":["564898"]},"194020":{"abstract":"Software is responsible for many critical government, business, and educational functions. This project aims to develop new methods for finding and repairing some of the most challenging, poorly understood security vulnerabilities in modern software that have the potential to jeopardize the security and reliability of the nation's cyber infrastructure.<br\/><br\/>The first objective of this project is to design and implement a robust program analysis framework that is capable of finding exploitable semantic bugs in modern applications, such as accidental omission of access-control checks, unintentional exposure of sensitive operations such as native calls and database queries to untrusted code or users, high-complexity control structures vulnerable to denial of service, misconfigurations of security policies, and other errors in programs' security logic.<br\/>The second objective is to develop methods for automatically repairing semantic vulnerabilities by applying program transformations that insert correct implementations of appropriate security logic.","title":"TWC: Small: Finding and Repairing Semantic Vulnerabilities in Modern Software","awardID":"1223396","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[519591,519592],"PO":["564388"]},"195121":{"abstract":"The NSF Sustainable Energy pathways (SEP) Program, under the umbrella of the NSF Science, Engineering and Education for Sustainability (SEES) initiative, will support the research program of Prof. Sridhar Viamajala and co-workers at the University of Toldeo, Prof. Robin Gerlach and co-workers at Montana State University, and Prof. Gregory Characklis of the University of North Carolina at Chapel Hill. This project will focus on high lipid-producing native alkaliphilic algae which are less susceptible to detrimental contamination (due to their extreme growth environment) and able to accumulate large amounts of lipid. In addition, the project will develop and test low-energy options for cell harvesting as well as for fuel and high value product generation. Through integration of unique and robust advances in algal culture stability and productivity as well as research targeted on the critical processes of algae harvesting and conversion of biochemicals, scalable, environmentally and economically acceptable processes to produce renewable fuels and chemicals will be developed. <br\/><br\/>The results of this project will be of interest to industry, local communities, regulators, and academia. Specific outreach efforts will be directed towards each of these primary stakeholders through: (1) dissemination of research outcomes to local community members and industry stakeholders at conferences, trade meetings and by local community and legislator engagement; (2) engagement of underrepresented Native American students from Montana high schools and tribal colleges in summer research activities as well as undergraduate researchers in the PIs' laboratories; (3) education and training at the K-12 level through training of high school teachers; (4) development of an interdisciplinary distance-learning course sequence on \"Sustainable Biofuels\" that will cover broad topics on the fundamental biology, chemistry, engineering and sustainability aspects of biofuel production; (5) generation of information useful in making informed judgments regarding tradeoffs between cost and environmental impact using the results of the life-cycle analyses.<br\/><br\/>This sustainable energy pathway minimizes energy and materials requirements through use of low-energy chemical and biological processes coupled with nutrient and water recycle. The global warming potential (GWP) of such biorefineries would be significantly lowered through the use of energy-efficient cultivation, harvesting and conversion methods as well as by minimizing external demands for nutrients and water. Overall, these solutions to the challenge of economic and sustainable energy from algae will be transformative through the development of novel scientific and technical advances, balanced with environmental, economic and societal merits. These algal farms will not compete with arable lands, food production, or use high quality water.","title":"SEP Collaborative: Alkaliphilic microalgae-based sustainable & scalable processes for renewable fuels and products","awardID":"1230609","effectiveDate":"2012-09-15","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"8026","name":"Sustainable Energy Pathways"}}],"PIcoPI":["525461",523007,523008],"PO":["556345"]},"193185":{"abstract":"This PI team aims to use artificial intelligence to exploit data collected from intelligent tutoring systems to provide feedback both to students and to teachers effectively and at the right times. The team is using a new analytic approach, which introduces hierarchical modeling to learning analytics, to investigate how to better understand students' learning states. Algorithms make valid interpretable and actionable inferences from student-learning data, drawing on cognitive theories and statistics to make it work. As in tutoring systems, analysis is at the level of component skills rather than looking at end performance on a task as a whole. Research is around construction of the algorithms for deducing student learning and student learning states and around learning ways of signaling both to learners and to their teachers what concepts and skills learners understand and are capable of and which they are having trouble with. A learning dashboard will allow teachers to visualize the learning needs of a whole class and adapt activities to student needs. Feedback aimed at learners themselves will help learners recognize activities they need to engage in next to better their skills or understanding. Evaluation will include the degree to which learners development of metacognitive skills when such tools are available. <br\/><br\/><br\/>The proposed work will contribute towards the next generation of intelligent tutoring systems as well as contribute to the data analytics needed to make use of large-scale educational data repositories. Because the Learning Dashboard will be independent of any particular domain, and because metacognition and self-assessment are foregrounded, the Learning Dashboard and what is learned about designing an effective learning dashboard should be applicable across disciplines and classes. The proposal brings together what is known about learning, metacognition, and intelligent tutoring systems to address timely learning analytics issues.","title":"EXP: Building a Learning Analytics System to Improve Student Learning and Promote Adaptive Teaching Across Multiple Domains","awardID":"1216977","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"7511","name":"TUES-Type 2 Project"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7625","name":"REESE"}}],"PIcoPI":["530302",517505],"PO":["562669"]},"194043":{"abstract":"Software bugs and vulnerabilities are primary causes for cyber-security breaches in today's society. Runtime monitoring, a technique to enforce safety and security properties at program execution time, is essential to detect intrusions and keep the system healthy. One of the main obstacles to adopt runtime monitoring techniques in practice is high performance overhead. Inlined security monitoring enforcement often delays and blocks the execution of protected programs. Conventional concurrent runtime monitors have not been able to leverage the multicore architectures for performance due to synchronization issues. If conventional synchronization primitives are used, when the monitor is crashed or blocked due to external events, the protected program will also be blocked even if the monitor is not monitoring. The goal of this proposal is to develop an innovative security monitoring technology, called Software Cruising, to explore multicore architectures for non-blocking concurrent security monitoring using lock-free data structures and algorithms. Software cruising eliminates the blocking effect and achieves efficient and scalable security monitoring. This can result in a game-changing capability in large-scale security monitoring for both cloud-based and traditional computing systems and applications.<br\/><br\/>The software cruising applications include, but are not limited to, heap buffer integrity checking, kernel memory cruising, data structure and object invariant checking, rootkit detection, and information provenance and flow checking. Three related sets of prototypical toolkits?Cruiser, Kruiser, and iCruiser?will be developed to demonstrate the effectiveness and practicality of large-scale software cruising. Cruiser is for lock-free heap buffer overflow monitoring of user-space programs. Kruiser is for kernel cruising on OS kernel heap buffer overflows and other security vulnerabilities. iCruiser is for user- and kernel-space data structure and object invariant cruising. The proposed research, upon completion, would make large-scale security monitoring more efficient and scalable in the increasingly popular multicore architecture and cloud environment, and thus significantly enhance system security. With the proposed tech transfer effort, applications as well as OS kernels will have better protection with the deployed software cruising technology. Broader impacts will also result from the education, outreach, and dissemination initiatives. Educational resources from this project, including course modules on software cruising and teaching laboratory designs, will be incorporated into online courses and disseminated through a dedicated web site. The project outcomes of this project will be disseminated broadly through publications, software releases, and technology transfer.","title":"TWC: Phase: Small: Software Cruising for System Security","awardID":"1223710","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["277956","550920"],"PO":["564388"]},"198520":{"abstract":"An international Data Web Forum (DWF) has been proposed [DWF] to promote cross-community coordination and development of global research data infrastructures with the goal of accelerating global data-driven research and innovation. The DWF will a) convene to coordinate, create, adapt, and identify community efforts and deliverables that facilitate greater research data discovery, sharing, exchange, and use, and b) bring DWF-vetted approaches and deliverables back to their stakeholder \/ member organizations, institutions, nations and communities for implementation and adoption. To support the efforts of the DWF and to ensure that it is a public organization, national non-commercial non-governmental structures (NGSs) are needed. <br\/><br\/>The DWF proposes: the development, implementation, and adoption of shared approaches, practices, policies, standards and technologies that facilitate the international sharing and exchange of research data; The development, implementation, and adoption of a framework and appropriate tools for greater discoverability and usability of research data that can be used broadly; the creation and sharing of economic models for stewardship, management, and preservation of research data that support research practice and broad use and the development of analytics about the research data landscape that promote strategic planning and resource allocation, as well as informed policy and technology <br\/><br\/>A successful DWF will be a locus for action and development of the global research data community. The U.S. NGS will work internationally to create, launch, and sustain the DWF as an effective community forum that lowers technical and other boundaries and facilitates cross-community data access, sharing, exchange and use; promotes the creation of a global marketplace for data services, tools, approaches, and enabling infrastructure; and raises awareness of the importance of research data as a driver for innovation.","title":"RCN: Increasing the Impact of Research Data","awardID":"1249473","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"7231","name":"CYBERINFRASTRUCTURE"}}],"PIcoPI":["562621"],"PO":["565292"]},"197310":{"abstract":"This award sponsors undergraduate and graduate student attendance at the 28th ACSAC, to be held December 3-7, 2012 in Orlando, Florida. The ACSAC conference is a top-tier academic security conference which attracts about 200 highly skilled security professional attendees per year. ACSAC regularly brings together leading minds in academic, governmental and commercial computer security to address the most pressing problems in applied computer security and to discuss seminal works in Computer Security. In addition to keynote Invited Essays and Distinguished Practitioner talks), ACSAC includes a \"Classic Papers\" series, in which two or three authors of seminal papers in computer security are invited to update those papers and present lessons learned. These papers, available free on the ACSAC web site, familiarize a new generation of students with key security research developments of the past, and provide a valuable resource for undergraduate and graduate instruction. Supported students have an opportunity to meet and interact with notable figures at the conference.","title":"ACSAC 2012 student support","awardID":"1243272","effectiveDate":"2012-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"L620","name":"U.S. Department of Homeland Se"}}],"PIcoPI":[529389],"PO":["565264"]},"195264":{"abstract":"Over 1 million hospitalizations for acute decompensated heart failure (ADHF) occur every year. Fluid accumulation plays an important role in the genesis of ADHF. Monitoring of fluid status can provide a reliable warning of impending decompensation and an opportunity for preventing hospitalization. There is a need for low cost, non invasive devices that can provide continuous home monitoring of fluid status and other related variables in order to reliably predict impending decompensation in ADHF patients. This project will lead to the development and evaluation of instrumented socks for tracking disease status in patients with chronic forms of heart failure. Thin film flexible sensors on the socks will measure patient weight, ankle circumference, leg tissue elasticity, and blood pressure in the lower legs. These sensor measurements will be used to determine if a patient is at increased risk of acute decompensation. Measurements from the socks will be transmitted wirelessly to a computer in the home and then to a medical provider. The transmitted data will allow health professionals to monitor the patient and make decisions on whether intervention is needed. By enabling continuous patient monitoring at home, better treatment outcomes, fewer hospitalizations and lower costs are expected.<br\/><br\/>The project will address several technical challenges related to development of sensors in the socks for making reliable fluid status measurements. Innovative sensing principles will be used to enable measurement of weight, ankle circumference, tissue elasticity and lower leg blood pressure in the wearable socks. These measurements will be made without requiring controlled application of forces or displacements and without requiring strict sensor alignment. The ability to measure these variables automatically will remove the need to depend on patients making these measurements regularly which has been shown to be unreliable. The basic functionality of the sensors will first be evaluated using in-vitro tests in the laboratory. Subsequently, tests with a planned selection of volunteers will be used for evaluation of all the measurements from the instrumented socks. <br\/><br\/>The broader educational activities in the project include recruitment of undergraduate students for summer projects, outreach to high school students and website development for dissemination of research results from the project.","title":"SHB: Type I (EXP): Instrumented Socks for Prediction and Prevention of Acute Decompensated Heart Failure","awardID":"1231582","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[523459],"PO":["565136"]},"197574":{"abstract":"Trends in the design of high-performance computing systems are making them more difficult to use effectively. This EAGER award focuses on the problem of managing massive parallelism while effectively exploiting locality. Its goal is to develop breakthrough techniques for parallel runtime systems that will support libraries, applications, and other software infrastructure on the next generation of high-performance systems.<br\/><br\/>The PI proposes to develop the Parallel Runtime Scheduling and Execution Control system (PaRSEC), which will serve as a prototype for novel ideas about parallel runtime systems. The PI's approach will be based on scalable directed acyclic graph (DAG) scheduling techniques that will track data dependencies between tasks. The scheduling structures will be designed to handle billions of tasks running on millions of computational nodes. The scheduling framework will also have to handle task migration and load balancing to maximize parallelism while preserving data locality. The prototypes developed as part of this EAGER will provide the foundation for future research on parallel linear algebra routines for extreme-scale computing systems.","title":"EAGER: PaRSEC: Parallel Runtime Scheduling and Execution Control","awardID":"1244905","effectiveDate":"2012-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["558550"],"PO":["564588"]},"195275":{"abstract":"This project develops a ubiquitous human health monitoring system that collects not only vital signs, but also daily activities and environmental context of a human subject in an everyday life setting. From these collected data, higher level knowledge, such as behavioral and vital sign anomalies, is extracted to assist health evaluation, medical diagnosis\/prognosis or healthcare delivery. The research team first develops a low-cost and power-aware wearable Smart Health Monitoring (SmartMon) system, which is integrated into human clothing with minimized obtrusiveness to the wearer. The research team then employs a minimalist approach to understand human?s daily activities and environmental context using the data collected by the SmartMon system. The research team further develops adaptive and intelligent signal processing algorithms to detect anomalies in human daily activities and vital signs for health assessment applications. <br\/><br\/>This research can significantly improve the ubiquitousness, accuracy, and reliability of wearable human health monitoring. The technologies developed in this project have many different applications, from improving quality of life for elderly people to enhancing capability of first responders during emergency responses. Through the involvement of female, minority (Native American) students, this project prepares a more diversified workforce in the area of biomedical engineering for the State of Oklahoma and the nation.","title":"SHB: Type I (EXP): Context-aware Ubiquitous Human Health Monitoring","awardID":"1231671","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[523489,"518429"],"PO":["564316"]},"194065":{"abstract":"Traditionally, security on the Internet has been concerned with threats posed by edge nodes (hosts) to other hosts and to the middle nodes of the network (routers). However, in recent years,a rising number of instances in which hosts seek to defend themselves against the middle of the network can be seen. Examples include censorship and network neutrality violations, which fall into a general category of ?network manipulation?.<br\/><br\/>This project is exploring how to detect network manipulation through ?friendsourcing?, a strategy in which individuals use their social networks to get measurements from their friends. The project is developing a framework to facilitate this basic mechanism of analysis by addressing coverage, instrumentation, and co-operation. To obtain coverage, it must be possible to carry out recruitment that finds a collection of hosts in the right network locations. To deploy instrumentation, a software system capable of making the necessary measurements must be set up in such locations. To gain co-operation, it is necessary to rely on friending to get the help needed to realize the coverage and use the instrumentation.<br\/><br\/>Initial studies use limited coverage based on close friending and manual instrumentation. Later studies use broader coverage with theoretical underpinnings, more modular instrumentation, weaker friending ties, and more participants. Studies use a blend of theory (of coverage), software architecture (for instrumentation) and social network binding (to assess levels of cooperation). These studies provide better foundations for understanding the capacity of social networks and friendsourcing to measure Internet behavior and address network manipulation.","title":"TWC: Small: Friendsourcing to Detect Network Manipulation","awardID":"1223967","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["553855"],"PO":["562974"]},"199510":{"abstract":"An increasing number of organizations and information conduits, ranging from news outlets to information intermediaries like search engines can censor or manipulate citizens' access to information. The practices of these intermediaries can create \"filter bubbles'', whereby the information any user sees is highly controlled by an information intermediary and depends largely on factors that may not be immediately apparent, such as the user's geographic location or past behavior. <br\/><br\/>This project will study the effects of filter bubbles on the availability and sentiment of news sources in different geographic regions, for both social and mainstream media. To study these effects, this project will build a large-scale, distributed monitoring system to discover and view news sources from different geographic regions, and for users with different context. The first portion of the project, which will be to characterize filter bubbles in news media, will involve two separate studies: one for information intermediaries for mainstream news media, and one for social media. The second portion of our project will involve developing and deploying a prototype system that exposes bias in news sources, to provide users with systematic ways to observe and evaluate the extent of bias that may exist in media sources. The last component of our project will investigate how the presenting evidence of bias or information manipulation affects users' perceptions of and attitudes towards bias in both mainstream and social media. To do so, the project will design and instrument user studies through software distribution, recruitment, and laboratory-based studies, where cases of bias or information manipulation are presented to users through different types of interfaces. These studies will highlight instances of bias using different visualizations and interfaces and observe how users' attitudes change depending on whether and how this information is presented.","title":"EAGER: Characterizing and Exposing Bias in Social and Mainstream Media","awardID":"1255314","effectiveDate":"2012-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["561756"],"PO":["565264"]},"198663":{"abstract":"This project is developing methods and tools for ordinary web content creators to indicate the structure inherent in their content by drawing a few simple lines or figures over their web site. Their motivation for doing so is to use enhanced browsing and searching capabilities in their local site based on these mappings. These new browsing and searching capabilities are based on the definition of canonical structures (i.e., data model fragments) and domain patterns (a set of instantiated canonical structures) with associated navigation and access paths where domain patterns are easily recognizable by content creators and easily articulated using a simple drawing approach. This work is complementary to yet distinct from much existing effort to transition to a more semantic Web; the focus here is on (simple) local specification (drawing) of mappings with local benefit. This project uses a form of crowd-sourcing to create ontology mappings and (indirectly) create ontologies. This project applies decades of work on data modeling and schema mapping but with structural fragments rather than complete schemas\/ontologies, without view update problems (because of the focus on browsing\/searching), and with immediate local benefit. The research is motivated by and will be showcased in a series of websites that support public access to instructional materials. In general, this work is expected to contribute (nearly effortlessly yet in a high-quality way) to achieving the vision for the semantic web.","title":"EAGER: Quick Draw Semantics","awardID":"1250340","effectiveDate":"2012-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[533018],"PO":["565136"]},"195187":{"abstract":"The NSF Sustainable Energy pathways (SEP) Program, under the umbrella of the NSF Science, Engineering and Education for Sustainability (SEES) initiative, will support the research program of Prof. Se-Hee Lee and co-workers at the University of Colorado at Boulder to develop a new generation of energy storage materials and devices. The team of investigators includes researchers with expertise in materials science, battery engineering and environmental and economic assessment at an early stage in battery research and development. Energy storage materials play a crucial role for finding a sustainable solution to transportation via electric vehicles. Today's approaches for developing such materials do not account of the complex tradeoffs between various performance criteria, currently used to design batteries, and sustainability goals, including life cycle costs and economic factors. In this project, the team of investigators will adopt concepts from multi-disciplinary optimization for coordinating the sustainability and material design problems. A novel multi-scale modeling framework will be established to predict the performance of 3-D structured electrode architectures and cell layouts. The model development will be supported by fundamental research on the thermodynamic and kinetics characteristics of solid state lithium pyrite (SS-LP) batteries, using advanced experimental techniques. Life-cycle analysis and environmental impact studies will be carried out to assess the sustainability of the proposed battery technology with respect to manufacturing and use. <br\/><br\/>Through coupling research discoveries with ongoing and new educational activities, students at all levels (K-12 through graduate, including students from typically underrepresented groups) will be exposed to the excitement of renewable energy in general and the world of energy storage material systems for electric vehicles in particular. Interdisciplinary, tightly integrated research will provide an environment for educating a new cadre of engineers and economists, who will not only be experts in their disciplinary fields but also understand the broader context of sustainable energy and thus are equipped to lead the design of a new sustainable energy future.<br\/><br\/>The proposed research will create a new paradigm to design energy storage materials bridging the gap between materials research and the environmental and economic impact of technologies in which these materials play a crucial role. The proposed research specifically focuses on SS-LP batteries, a new battery material system with extraordinary properties. The SS-LP battery development holds the promise of a major breakthrough in reaching a market beyond the small-capacity vehicles of urban drivers.","title":"Sustainable Energy Pathways: A Lab-to-Market Paradigm for the Optimal Design of Sustainable Energy Storage Materials","awardID":"1231048","effectiveDate":"2012-09-15","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0307","name":"Division of MATERIALS RESEARCH","abbr":"DMR"},"pgm":{"id":"8026","name":"Sustainable Energy Pathways"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[523226,"558952",523228,523229,523230],"PO":["546933"]},"189511":{"abstract":"This research develops general frameworks for efficient graph algorithms, which allow to solve entire categories of computational problems all at once. The PIs aim for a general theory of algorithms, wherein a given problem of interest can simply be adapted into the general approach. This approach differs from the traditional study of algorithms, which often focuses on individual solutions to specific problems.<br\/><br\/>The type of computational graph problems the PIs consider are \"optimization problems\", where the task is to find a solution whose cost, quality, size, profit, energy, or speed is as large or as small as possible. Most interesting graph optimization problems are NP-hard, essentially implying that there are no efficient algorithms to find the very best solution. This research considers the two main types of algorithms for solving NP-hard graph optimization problems. Approximation algorithms allow the result to be a small factor away from the optimal, but still require a fast running time. Fixed-parameter algorithms allow the running time to be exponential, but confine that exponentiality to a (typically small) parameter other than the problem size, while requiring an optimal solution.<br\/><br\/>The type of graphs the PIs consider include planar graphs, which can be drawn in two dimensions without any edges crossing each other, and nearly planar graphs such as graphs of bounded genus and graphs excluding a fixed minor. Many graphs of practical interest---for example, computer networks and road networks, which are \"drawn\" on Earth---are planar or nearly planar. In these settings, the PIs aim to develop general frameworks for approximation and fixed-parameter algorithms.","title":"AF: Medium: Collaborative Research: General Frameworks for Approximation and Fixed-Parameter Algorithms","awardID":"1161626","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["527736"],"PO":["565157"]},"198223":{"abstract":"To address the growing complexity of societal and global challenges, research is increasingly conducted by interdisciplinary teams of researchers, research centers, and institutes. The Science of Team Science is a new interdisciplinary field that empirically examines the processes by which these collaborations organize, communicate, and conduct research to achieve scientific breakthroughs that would otherwise not be attainable. The National Research Council, via its Board on Behavioral, Cognitive and Sensory Sciences, will conduct a consensus study and appoint a committee of experts to assemble, synthesize, and communicate important findings from the Science of Team Science and related fields such as social psychology, science policy, organizational\/business management, human resource development, organizational studies, social cognition, and industrial\/organizational psychology. The project will include two public workshops to gather information on team dynamics, team management, and institutional structures and policies that affect large and small science teams. The committee's final report will provide conclusions and recommendations to strengthen the efficiency and productivity of science teams in order to build their capacity for major scientific and technological advances. The report will both contribute to the advancement of research on science teams and inform those who conduct, fund, and manage interdisciplinary research collaborations in research universities, federal agencies and industry.","title":"The Science of Team Science","awardID":"1248170","effectiveDate":"2012-09-01","expirationDate":"2015-02-28","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7642","name":"VIRTUAL ORGANIZATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["532626"],"PO":["565255"]},"189522":{"abstract":"People care greatly about the appearance of translucent materials such as food, skin, soap, and marble, and they are able to distinguish subtle differences in these materials based on their appearance. The translucent appearance of these materials is caused by internal volumetric scattering, which is challenging to simulate, especially because humans are so sensitive to their subtleties. Since in the natural world scattering materials are the norm, not the exception, it makes sense that the human visual system is so well engineered to analyze them. However, very little is known about how this analysis is achieved because the perception of volumetric translucency is almost unstudied.<br\/><br\/>This collaborative project, involving faculty from three universities with complementary expertise in computer graphics, human vision, machine learning, and computer vision, addresses the fundamental unsolved problem of understanding translucency for graphics. The PIs will develop a perceptually-motivated pipeline for translucency, contributing new scattering representations, perceptual dimensions, and computational algorithms to computer graphics. The scattering representations, based on a polydispersion model, will provide analytic expressions for wavelength-dependent bulk scattering properties of translucent media; this will significantly expand the range of materials that can be simulated with high visual fidelity. Finding perceptual knobs that relate physical scattering parameters with visual appearance will be achieved by coupling large-scale computation (using cloud computing) with controlled perceptual studies. Novel acquisition approaches that employ hyperspectral imaging will be created, as will editing and rendering applications that use the new perceptual representations of translucency. Low-dimensional models to represent scattering media will be developed and used to enable efficient and accurate acquisition and rendering. A suite of test materials and scenes will be developed to evaluate the fidelity of rendered images based on the developed theory and computational applications.<br\/><br\/>Broader Impacts: Currently, the simulation of translucency presents challenges in terms of both computation and visual fidelity. This restricts the ability of practical algorithms to predictively simulate translucent materials, thus fundamentally limiting the use of graphics in real applications. By building the computational tools to characterize, study, and use knowledge of translucency perception, this research will fundamentally change the graphics pipeline for translucent materials. and will potentially revolutionizing industrial design, interior design, skin care and cosmetics, and entertainment.<br\/><br\/>The project includes an education program that is tightly coupled to the research program. The PIs have already been meeting twice a week for more than six months, and their graduate students already share data, code, and equipment. During the activity, the students will make week-long and month-long visits to each other's laboratories to collaborate, and in this way the project will produce a generation of researchers who are \"T-shaped\" in the sense of being both deep in their respective fields and able to work effectively across these synergistic disciplines. The PIs also plan to organize a workshop that will brins together researchers in vision science, computer graphics, and computer vision, so that the important ties between these fields are strengthened even further.","title":"CGV: Medium: Collaborative Research: Understanding Translucency: Physics, Perception, and Computation","awardID":"1161731","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[508175],"PO":["565227"]},"189533":{"abstract":"This research project explores ways to solve optimization problems where the targets of optimization are programs containing general-purpose control and data constructs. Such optimization questions arise often in the everyday practice of software engineering. While it may seem that standard optimization packages could solve these problems, it is often not so. White-box optimization approaches like linear programming are ruled out here because they only permit very restricted classes of objective functions. Black-box optimization techniques like gradient descent and Nelder-Mead search are applicable in principle, but they work well only in relatively smooth search spaces, and due to arbitrarily nested branches and loops, even simple programs can have highly irregular, ill-conditioned behavior.<br\/><br\/>The central insight guiding this project is that program analysis techniques from the field of formal reasoning about programs can work together with blackbox optimization toolkits, and make it possible to solve many more problems of the above sort than are currently possible. Ultimately, the project will produce a unified system for optimizing programs that can leverage flexible combinations of optimization techniques and program analysis strategies. As numerous real-world problems faced in the development of everyday software are optimization problems, this system will offer a new range of capabilities to the end programmer. In addition, the research will foster synergy between two different research areas customarily housed in different academic departments.","title":"SHF: Medium: Collaborative Research: Marrying program analysis and numerical search","awardID":"1161775","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[508201],"PO":["565264"]},"198003":{"abstract":"This project synthesizes techniques from interaction design, creative cognition, visual design, programming languages, and information retrieval and visualization to help people draw on big data to stimulate innovation. Sensemaking is the process of understanding a collection of information resources. Ideation means the process of generating new ideas. In performing information-based ideation tasks, people use information for developing new ideas, such as planning a paper, thesis, or invention. This project will provide new tools for presenting information visually. \"Information composition\" is a medium for representing each information collection as a connected whole. To better support innovation and creative visual thinking, this research brings diagramming, along with collection curation, to information composition. Pen, touch, and in-air sensing will transform interaction into an extension of the body, helping people express, understand, and remember. Embodied interaction will be based on the Interface Ecology Lab's ZeroTouch, a novel multi-finger sensing technology.<br\/><br\/>Intellectual merit: The objective of this proposal is to develop \"Embodied InfoComposer\", a toolset that uses pen, touch, and other modalities for authoring visual semantic information collections. The principal hypothesis is that embodying interaction, making representations visual, and connecting rich metadata semantics will stimulate sensemaking and ideation, helping people collect, reflect, create, and invent. This research will result in significant outcomes in important areas of human centered computing, including: (1) new understanding of how integrated diagramming and information composition promotes creative visual thinking; (2) new fluid embodied interaction techniques; (3) new methods for measuring reflection, ideation, and sensemaking; and (4) new implications for design of embodied creativity support environments.<br\/><br\/>Broader impacts: This research will transform how people work with information, leading to greater innovation in a variety of domains including business and education. The work is likely to have broad societal impact because innovation is a key factor leading to job creation and economic success. The project will also have educational impact through the training of graduate students and by the use of Embodied InfoComposer to foster creative visual thinking by undergraduate students from diverse majors in a design process course. Undergraduate computer science students in capstone senior design will use resulting technologies as building blocks in innovative projects. Recruitment of female and minority student researchers at the graduate and undergraduate levels will be sought.","title":"EAGER: Embodying Visual Semantic Information Composition to Stimulate Sensemaking and Ideation","awardID":"1247126","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[531380],"PO":["564456"]},"198124":{"abstract":"Recently, the idea of simultaneous activation (or transparent coexistence) of secondary and primary nodes is being explored. Under this new paradigm, secondary nodes are solely responsible for canceling their interference with the primary nodes so that the primary nodes do not feel the presence of the secondary nodes. Although this new paradigm has the potential of offering much greater spectrum efficiency and network capacity than those under the existing interference avoidance paradigm, it is still in its infancy and current results are only limited to very simple network settings. The goal of this project is to make a fundamental advance in the transparent coexistence paradigm for multi-hop secondary networks. Specifically, this project aims to study the following important problems in the context of multi-hop networks: (1) developing new analytical models for the transparent coexistence paradigm; (2) exploring performance bounds and theoretical limits for multi-hop secondary networks; and (3) developing distributed algorithms for multi-hop secondary networks that can offer performance approaching that of a global optimal solution.<br\/><br\/>The findings from this project are expected to make a timely contribution to the research community by removing some fundamental barriers associated with the transparent coexistence paradigm. An important educational activity of this project is to develop new cross-disciplinary course materials for wireless networking, particularly efficient sharing of the radio spectrum. This project also has plans to involve undergraduates and under-represented students in wireless networking research.","title":"Transparent Coexistence for Multi-Hop Secondary Cognitive Radio Networks: Theoretical Foundation, Algorithms, and Implementation","awardID":"1247830","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7976","name":"EARS"}}],"PIcoPI":["560139","564848","564847"],"PO":["557315"]},"198487":{"abstract":"Many emerging applications of data mining call for techniques that can deal with data instances with millions, if not billions of dimensions. Hence, there is a need for effective approaches to dealing with extremely high dimensional data sets. <br\/><br\/>This project focuses on a class of novel theoretically well-founded hashing algorithms that allow high dimensional data to be encoded in a form that can be efficiently processed by standard machine learning algorithms. Specifically, it explores: One-permutation hashing, to dramatically reduce the computational and energy cost of hashing; Sparsity-preserving hashing, to take advantage of data sparsity for efficient data storage and improved generalization; Application of the new hashing techniques with standard algorithms for learning \"linear\" separators in high dimensional spaces. The success of this EAGER project could lay the foundations of a longer-term research agenda by the PI and other investigators focused on developing effective methods for building predictive models from extremely high dimensional data using \"standard\" machine learning algorithms. <br\/><br\/>Broader Impacts: Effective approaches to building predictive models from extremely high dimensional data can impact many areas of science that rely on machine learning as the primary methodology for knowledge acquisition from data. The PI's education and outreach efforts aim to broaden the participation of women and underrepresented groups. The publications, software, and datasets resulting from the project will be freely disseminated to the larger scientific community.","title":"EAGER: Preliminary Study of Hashing Algorithms for Large-Scale Learning","awardID":"1249316","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["565250"],"PO":["565136"]},"196067":{"abstract":"Adverse drug reactions (ADR) (undesired or excessive responses drugs) have been linked with significant morbidity and mortality, and account for as much as 5% of all admissions. A drug-drug interaction (DDI) is a type of ADR involving two or more drugs. Reports suggest that 50% percent of the drugs withdrawn in the U.S. by the Food and Drug Administration (FDA) from 1999 to 2003 were linked with significant DDIs. The ADR profile of a given drug is rarely complete at the time the drug is approved by FDA. Hence, after a drug has been in use by the general population (with significant diversity in race, gender, age, lifestyle), often previously unidentified DDIs are discovered. To complicate matters, certain populations of patients, e.g., psychiatric patients, are often concurrently treated with multiple medications. The potential interactions between multiple drugs are neither well understood nor completely characterized. Voluntary reporting, the basic mechanism used by the FDA to monitor new drugs, suffers from underreporting, delayed reporting, uneven quality of reports, and even lack of reports of rare DDIs.<br\/><br\/>Against this background, this collaborative project aims to explore the feasibility of a novel computational approach to the problem of drug-drug interaction surveillance. It seeks to develop new methods for predicting molecular level interactions between drugs from data gleaned from online sources and digital social media. The project aims to test the hypothesis that such online data, in combination with with data from traditional drug related databases can be used to reliably predict potential DDIs much sooner than possible using current methods. The effectiveness of the approach is assessed through verification of predictions against future reports. <br\/><br\/>If successful, the project could lead to effective, proactive computational approaches to drug interaction surveillance, with benefits to federal, local and public health agencies, drug companies, clinical practitioners, the patients, and the public at large. Early detection of adverse DDIs could lead to improved patient care, and significant reduction in healthcare costs and lawsuits involving DDIs. The project offers enhanced opportunities for collaboration among investigators with expertise in computational and health sciences. It also offers research-based training opportunities to students at West Virgina University and the University of Virginia. Results of the research will be freely disseminated to the broader academic and research community.","title":"EAGER: Collaborative Research: Computational Public Drug Surveillance","awardID":"1236983","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[525556,525557,525558,525559],"PO":["565136"]},"189544":{"abstract":"","title":"Collaborative Research: Code Design and Analysis to Approach Capacity with Short Blocklengths Using Feedback (JPL Task Plan 82-17473)","awardID":"1161822","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[508227],"PO":["564924"]},"198135":{"abstract":"This research project will develop a theoretical and computational framework to understand and enable the socio-technical dynamics shaping the assembly of teams in distributed global contexts. The main barrier to understanding and explaining the role of human centered computing in team assembly is finding a suitable research environment where (1) geographically distributed individuals from potentially different cultures are assembling in teams of varying sizes to accomplish a variety of tasks over varying durations; (2) their actions, interactions and transactions are captured with precise time-stamps; and (3) their outcomes would be recorded with well-defined metrics. Massively multiplayer online role-playing games offer a research environment that meets all of these requirements. EVE Online, a massively multiplayer online role-playing game, offers a potentially suitable research opportunity to study the assembly of teams and ecosystems of teams. It is notable for allowing as many as tens of thousands of people to interact simultaneously on a single server cluster, from around the world, through a well-developed economic system and serious long-term coalitions, in a more flexible action framework than many other popular games possess. <br\/><br\/>This high-risk high-payoff project will explore the feasibility of using data from EVE Online to identify the socio-technical and cultural mechanisms that explain the assembly of teams more generally. If successful, the study will serve as a model for larger scale studies that, in addition to identifying the assembly mechanisms also assess the impact of these mechanisms on the performance of global teams. The most important and complex decisions in society are made in teams. And yet, assembling effective teams is a daunting task. While there is an awareness of how team collaborations can spearhead socio-economic change, we still have sparse sociotechnical knowledge of how globally distributed cross-cultural teams and systems of teams are assembled. This project seeks to address this limitation. First, the proposed research offers the promise to launch a new generation of theorizing and research on the assembly mechanisms of teams and ecosystem of teams. The empirical data that will be used to develop and test these theories will be a high risk effort but with potential for unprecedented scale, size, and completeness. Second, the research will arguably be the first effort in the field of social networks to develop hypergraph techniques to study assembly of teams and ecosystems of teams. <br\/><br\/>The knowledge and tools developed in this research will allow practitioners to cultivate more effectively the emergence and performance of ad hoc teams in business, science and gaming. It will also provide other scientific disciplines with new computational statistical modeling methodologies and tools to model hypergraphs.","title":"EAGER: Collaborative Research: Some Assembly Required: Understanding the Emergence of Teams and Ecosystems of Teams","awardID":"1247861","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["561056"],"PO":["564456"]},"199587":{"abstract":"The distinction between computing and communication has blurred with the improvements in semiconductor technology as well as the speed and reliability of computer networks. At a macroscopic level, individuals increasingly rely upon smart phones, cloud computing, and similar infrastructure that combines computing systems with networking to accomplish their daily tasks. Advantages are realized from the seamless interconnection of computing systems and the network. Many end-users even consider the client device, the server, and the network as one unit that is used for productivity and\/or entertainment. At the microscopic level, similar efficiencies present themselves when computing and networking blend. In an ideal case, the linkage between the two areas should not require the use of special-purpose software, because installing software on a network node to enable this blending can potentially cause the node to be unstable, more complex, and introduce security flaws. However, there is a significant challenge in linking the two domains without the use of additional software. This research focuses on understanding and characterizing the connection between the computing node and the network. <br\/><br\/>Since the internal components of a node are shared resources between all processes, including those that require network-based I\/O, it is possible to infer the load on the internal components by observing variations in delay between successive network packets that are generated by the node. This inference materializes as a \"delay signature,\" and can be used to blend the areas of architecture and networking. Specifically, this information can be used to develop algorithms for network security and management. For example, by simply probing a node and collecting its responses, it can be determined that the internal components (e.g., microprocessor) are heavily utilized. If the node is expected to be idle, this could be an indication that the node has been compromised and is running unauthorized software. This information can also be used for job scheduling in cluster grids. By monitoring Message Passing Interface (MPI) messages between grid nodes, the loads on the nodes can be determined without querying nodes directly. As a result, resource discovery messages are not needed. Another use of this information can be to predict system degradation and failure. As a node's resources become exhausted, the node generates a unique traffic pattern. This pattern is emitted prior to node failure and can be used to signal a switch to a secondary server.<br\/><br\/>This project uses a holistic approach that combines computer architecture and computer networking to investigate and characterize how the microarchitecture affects the network packet generation process. The delay signature provides information that can be attributed to the internal state and settings of the microarchitecture. Architectural settings, such as processor affinity, multi-threading, and power-saving modes, affect the delay signature. The PIs use a hardware testbed and a system simulator to characterize the basic mechanisms within the microprocessor that are manifested in the observable delay signature. <br\/><br\/>The investigators incorporate team-based laboratory projects within their computer architecture and computer networking courses to demonstrate the relationship between the two domains and to promote integrated learning by students in both areas. Potential applications of the delay signature include providing security for networked nodes by monitoring unauthorized utilization and increasing resiliency of a computing system by detecting patterns that predict a node failure.","title":"EAGER: Collaborative Research: Characterizing Microarchitectural mechanisms for network delay signatures","awardID":"1255758","effectiveDate":"2012-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["560166"],"PO":["366560"]},"199499":{"abstract":"This award allows the PIs to plan and run an NSF-sponsored workshop on the topic of ?Computing Clouds for Cyber-Physical Systems?. This workshop is to be held in Arlington, VA on March 14th and 15th, 2013","title":"CSR: Workshop: Computing Clouds for Cyber Physical Systems (CC-4-CPS), March 14-15, 2013, Arlington, VA","awardID":"1255247","effectiveDate":"2012-09-15","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[534923,"556687","536823"],"PO":["565255"]},"189588":{"abstract":"Comparison is an essential part of data analysis and, therefore, of many visualization tasks. While the published literature provides a wealth of visualization tools for looking at individual objects (graphs, volumes, time series, gene sequences, molecular motions, etc.), there has to date been less consideration of support for comparison. The PIs argue that comparison tasks are best supported by tools explicitly designed for that purpose. The problem is that visual comparison becomes more challenging as the number of objects, their size, and the complexity of the objects and\/or of the relationships among them increases. The difficulty is further compounded by our rapidly growing ability to collect and generate data. In prior work the PIs have developed some encouraging initial examples of comparison tools, but these are specialized successes that offer little guidance for future endeavors. Addressing a wider range of comparison problems at greater scale with our present limited understanding thus largely remains an art that requires considerable effort. The PIs' goal in this project is to move towards a science of visual comparison. By studying visual comparison as a general problem, they will establish a domain-independent foundation for the field that facilitates the design of future tools which allow the creation of more effective and scalable comparisons. To these ends the team will pursue three interconnected research threads. They will define theories that are grounded upon principles of visual cognition. They will explore case studies (derived from real problems suggested by domain collaborators) that challenge and extend these theories, provide examples for empirical study, and suggest or use general concepts. And they will identify common tasks, designs, and strategies that enable development of generalized techniques, guidelines, and software components. This approach uniquely combines empirical studies, design explorations, and software development to take the field of visual comparisons to a new level that is both rooted in theory yet viable in practice. <br\/><br\/>Broader Impacts: Because visual comparison plays a key role in diverse domains (including essentially all of the sciences, engineering, and medicine), the potential benefits from an improved science of visual comparison tools are far reaching. To ensure maximum applicability for project outcomes, the PIs are directly collaborating with physical, biological, social, educational, and medical scientists, as well as with engineers and scholars in the humanities. The project will generate visualization tools, software components, and resources for visualization development by others. Visual comparison will serve as a mechanism to expose students at all levels to issues in data understanding. This project will also provide training for visualization specialists, engage non-technical students in visualization, and explore the role of visualization in public outreach efforts.","title":"CGV: Medium: Collaborative Research: Visualizing Comparisons","awardID":"1162067","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[508333],"PO":["565227"]},"193460":{"abstract":"The goal of this research project is to design and develop highly efficient spatial and spatio-temporal database systems on flash memory storage. More specifically, this project conducts research, develops requisite scientific knowledge, builds software infrastructure, and integrates teaching activities with research for four specific aims: (1) Supporting efficient spatial indexing on flash memory, which includes data- and space-partitioning index structures, (2) Supporting efficient spatial query processing and optimization, which includes supporting various forms of the spatial join operation and query cost estimation, (3) Supporting spatio-temporal indexing and querying, which includes extending the spatial index data structures and the query processor to support the high update frequency common in spatio-temporal applications, and (4) Exploiting a storage hierarchy of flash and magnetic disks where spatial and spatio-temporal indexing, query processing, and optimization can exploit the full potential of both storage media. Besides its impact on industry, this project will have significant broader impact across multiple segments of society that include enhancing productivity, graduate and undergraduate student education, curriculum development, and tutorial presentations. Publications, technical reports, open-source software, and experimental data from this research are disseminated via the project web site (http:\/\/www.cs.umn.edu\/~mokbel\/flash).","title":"III: Small: Towards Spatial Database Management Systems for Flash Memory Storage","awardID":"1218168","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[518156,"550903"],"PO":["565136"]},"193251":{"abstract":"The central theme of this project is research into properties and applications of polar codes, a new method of coding information for transmission over noisy channels that for the first time realizes the full potential of Shannon's theorems that relate to data rate and transmission reliability. Polar codes have been shown to advance a range of classical and new information-theoretic problems that rely on efficient encoding of the data. This project addresses properties of polar codes in nonbinary communication channels, the design of optimal polarizing transformations, and applications to unequal error protection, hierarchical source coding, broadcast channels, signal design, and other problems of importance for network communication.<br\/><br\/>The analysis of polar codes and their applications in this project relies on the concept of ordered distances that have been shown to control the reliability of transmitted symbols on nonbinary channels. Ordered distances contribute new ideas to the study of linear codes and related concepts such as multipartite and hierarchical secret sharing schemes. The project draws on these ideas to study new algebraic polarization transformations as well as the advances in the theory of linear code-based constructions for a number of models of practical communication systems.","title":"CIF: Small: Ordered Metrics and Their Applications","awardID":"1217245","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["518024"],"PO":["564924"]},"193493":{"abstract":"Applications as diverse as manufacturing, medicine, earth science, finance, and entomology generate massive amounts of temporal or spatio-temporal data. More specifically, information about moving objects, events, and atmospheric measurements that are geo-referenced may be derived from high-resolution satellites, sensors, ground and aerial imagery, GPS, and RFID. Such data present challenges to current approaches for mining time series data. For example, shape-based similarity measures used for classification and clustering consistently fail to produce satisfactory results for long sequences, or trajectories modeling objects that move in 2D or 3D space which may often exhibit similar motion patterns but differ in locations and orientations. In addition, algorithms for finding frequent patterns and anomalies assume known, fixed pattern lengths. This project aims to address the limitations of current approaches to time series data analysis by adapting statistical language processing algorithms and approaches. Specifically, fast algorithms for learning context-free grammars can expose hierarchical structure in time series and thus enable efficient discovery of variable length patterns and facilitate human understanding of time series structure. Also, using the hierarchy to populate a \"bag of patterns\" can result in significantly more effective similarity measures for long time series, much like the familiar bag of words representation used with documents is effective for a variety of similarity-based language processing tasks on massive corpora.<br\/><br\/>Given the ubiquitous nature of time series data, advances in algorithms that can help uncover the structure of such data are likely to impact a broad range of applications. All of the results of this research, including publications, algorithms and software, would be made freely available to the broader research and educational community. The project offers enhanced research-based training opportunities for graduate and undergraduate students. The project leverages existing programs at George Mason University and the University of Maryland at Baltimore County to to increase the participation of women members of other groups that are under-represented in Computer Science.","title":"III: Small: Collaborative Research: Finding and Exploiting Hierarchical Structure in Time Series Using Statistical Language Processing Methods","awardID":"1218318","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[518236],"PO":["565136"]},"193394":{"abstract":"Integrating heterogeneous data is a major challenge that manifests itself across a wide spectrum, from government and business to science and health care. A critical task underlying this challenge is deriving the relationship between different database schemas. During the past decade, schema mappings have emerged as the right tool for this task. Schema mappings are high-level, declarative specifications of the relationships between two database schemas that provide the appropriate level of abstraction and, at the same time, can be compiled into executable code.<br\/><br\/>The first main aim of this project is to develop a framework and tools for designing schema mappings. This framework is based on the systematic use of data examples. The project investigates fundamental algorithmic tasks in using data examples as a device to illustrate and understand the behavior of already derived schema mappings, and also as inputs to a schema-mapping design system that will derive a suitable schema mapping based on the given data examples. The second main aim is to investigate the uses of schema mappings in integrating and exchanging inconsistent data that arise when bringing together data from heterogeneous sources. Since the current framework of data exchange does not handle inconsistencies well, this project re-examines data exchange and extends it to gracefully handle inconsistencies.<br\/><br\/>This project will advance the state of the art in designing schema mappings and managing inconsistent databases. Furthermore, it will contribute to the development of human resources in science and engineering through the teaching and research training of graduate students.","title":"III: Small: Aspects of Integrating Heterogeneous and Inconsistent Data","awardID":"1217869","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[518005,518006],"PO":["565136"]},"194010":{"abstract":"The Network File System (NFS) is a popular method for computers to access files across networks. The latest major version of this IETF protocol, version 4, is widely accepted and includes numerous new features to improve security, performance, and usability when used over wide-area networks. However, the NFSv4's security focus is on network-wide encryption (ensuring that user data cannot be intercepted) and user authentication (ensuring that only legitimate users can access their files); it does not address end-to-end data security (i.e., persistently stored data), does not address data integrity (malicious or benign data corruptions), and more.<br\/><br\/>This project extends NFSv4 with a security layer that allows one to develop multiple, composable plugin modules to enhance the protocol's security. This layer allows for interception of protocol requests between clients and servers to perform various useful security functions: logging access to files by users and hosts, useful for regulatory compliance reports and audits; inspecting files for malware patterns and automatically quarantining them; verifying the integrity of long-lived files against malicious changes (e.g., Trojan intrusions) and benign but serious ones (e.g., storage media degradation and hardware corruptions); detecting denial-of-service attempts and ensuring quality-of-service to legitimate users through load-balancing and redirection; automatic snapshotting and logging to allow for forensic analysis and recovery from failures and intrusions. In a cloud-based era where more data lives longer and is accessed over wide-area, insecure networks, this project helps elevate the level of security of every user's data files.","title":"TTP: Small: NFS4Sec: An Extensible Security Layer for Network Storage","awardID":"1223239","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["543574","553485"],"PO":["564246"]},"196793":{"abstract":"The American Association for Artificial Intelligence (AAAI) Fall Series Symposium (FSS) is the first international gathering in North America in the field of computational aspects of affective narrative, bringing together participants from a long list of contributing disciplines. One of the aims of the Symposium is to attract students to a new and exciting multidisciplinary area, where it is still easier to attract the experts' attention and mentoring. The goal of this grant is to subsidize travel, registration fees, and housing expenses of students selected to participate in the Symposium which will be held, along with several other AAAI Fall Symposia, on November 2-4, 2012, in Arlington, VA. <br\/><br\/>The Symposium calls for long and short papers both from leaders in the field of computational aspects of affective narrative and pertinent areas and from graduate students as well as poster presentations from the undergraduate students interested in the subject. Papers from undergraduates, attracted through Research Experience for Undergraduates (REU) and Senior Research Opportunity Program (SROP) networks as well as solo graduate contributions will be carefully mentored to the level of poster or short paper eligibility. The multi-format program of the Symposium will also accommodate special student sessions, especially for promising but not fully developed ideas. <br\/><br\/>The AAAI FSS Symposium on computational aspects of affective narrative provides a valuable opportunity for the next generation of multidisciplinary researchers in a variety of pertinent disciplines to enter the computational affective narrative research community. It is expected that the Symposium will attract underrepresented populations as well as provide benefit to future development of computational systems from better understanding of affective narrative as the inherently human phenomenon.","title":"Support for student participation in a 2012 AAAI Fall Series Symposium","awardID":"1240710","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[527911,527912],"PO":["565215"]},"194494":{"abstract":"This project team is investigating the interaction among citizen scientists working both with each other and with professionals, along several dimensions. The cyberlearning environment in which these interactions takes place is built on an existing cyberinfrastructure, the International Biological Information System, that the PI team is enhancing to support collaborative ecosystem modeling. The resultant online, collaborative model-based learning system enables citizen scientists to make field observations, discuss and represent data, and collaboratively generate models and recommendations for land use resource management. Research questions center on how citizen scientists engage in scientific practice, use models to share understandings, work with professionals, and use representational tools to interpret their observations. Additional questions address the use of these tools in the context of land use management and the nature of collective and individual knowledge that results from participation in this collaborative model-based learning community. The project features collaboration among learning scientists, ecologists, and computer\/information scientists, and merges citizen science with cyberlearning and social networking. Further contributing to its intellectual merit is its position as one of the first citizen science projects to encourage modeling practices on a regional scale. The broader impacts of this project are being felt by its promotion of a better understanding of how cyber-enabled tools can contribute to learning disciplinary knowledge and scientific practices in informal settings with adult learners. The project is also enabling citizens to play a role in locally based environmental management; and it is working with a statewide master naturalist program through which the participation of underserved groups in science learning and resource management is encouraged. Finally, as the project continues, it offers the opportunity to serve as a model for other statewide master naturalist programs that exist across the country.","title":"DIP: Sustaining ecological communities through citizen science and online collaboration","awardID":"1227550","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":["532679",520944,520945,520946,"558481"],"PO":["560894"]},"193284":{"abstract":"The project is to develop protocols, mechanisms, and a Java implementation of fault-tolerant distributed transactional memory (DTM). DTM promises to alleviate the programmability, scalability, and performance challenges of lock-based distributed concurrency control. Fault-tolerance is essential to DTM to cope with node\/network failures, and object replication is central toward achieving this. Replication protocols must be scalable and ensure transactional correctness and progress properties. The expected outcome is a novel replicated DTM framework, whose key idea is to split transactions into two independent phases with orthogonal responsibilities: 1) regular read\/write phases, which quickly look-up and fetch latest copies of required objects without concurrency control, and 2) a request-commit phase, which does (distributed) concurrency control. The project investigates the use of quorum-based replication protocols, which maintain transactional metadata in read\/write quorums, and do scalable concurrency control by exploiting the quorum intersection property. The replicated DTM framework and protocols are implemented in the open-source HyFlow DTM Java package (hyflow.org). <br\/><br\/>Fault tolerant DTM has potential to improve both reliability and performance of a broad range of advanced distributed computing applications, including defense systems. The project has plans to transitioning this technology (techniques and HyFlow implementation) to a production system of the US Department of Defense, to leverage the benefits of fault-tolerant DTM. This is a direct potential economic and social benefit of the research. Additionally, the project's results are being incorporated into a graduate course at Virginia Tech that includes students at Blacksburg, VA, scientists and engineers at US Naval Surface Warfare Center Dahlgren Division (NSWCDD), VA through Virginia Tech's graduate outreach program at NSWCDD, and students in the Middle East and North Africa through Virginia Tech's VT-MENA program at Egypt.","title":"CSR: Small: Fault-Tolerant Distributed Software Transactional Memory: Theory, Protocols, and Java Package","awardID":"1217385","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[517750],"PO":["564778"]},"193053":{"abstract":"Field-programmable gate arrays (FPGAs) and application-specific integrated circuits (ASICs) are two very important processing elements for computation. FPGAs are very attractive because of their lower design cost and shorter time-to-market compared to ASICs. Still, the marketshare of FPGAs remains less than a fifth of that of ASICs because ASICs enjoy an advantage over FPGAs in terms of circuit area, power consumption, and delay. The objective of the proposed work is to significantly reduce these area\/power\/delay gaps through a new dynamically reconfigurable FPGA design and thus enable FPGAs to become much more competitive with ASICs. Continued scaling of bulk CMOS technology faces significant hurdles. To alleviate these problems, Intel and TSMC have already announced a switch to multi-gate field-effect transistors, e.g., Trigate and FinFETs, at the upcoming semiconductor technology nodes. Another important trend is towards 3D integrated circuits (ICs), in which multiple die layers are stacked on top of each other. 3D ICs promise a revolution in so called ``More than Moore\" computing. The proposed work aims to take advantage of the multi-gate and 3D IC technologies to further reduce the gaps mentioned above.<br\/><br\/>The proposed FPGA architecture significantly deviates from the conventional island-style FPGA architecture by enabling the logic element to either perform computation or local communication or both. It is aided by the key concept of temporal logic folding that allows a circuit to be drastically folded, aided by on-chip reconfiguration memory, before being mapped to the FPGA. It attacks the main reason for the area\/power\/delay gaps -- the vast amount of chip resources allocated to reconfigurable interconnects in FPGAs. Logic folding makes the communication local, thus making it possible to reduce the amount of resources devoted to interconnects very significantly. The work entails design space exploration of the different components of the architecture, investigation of novel multi-gate computation\/communication structures, and algorithms and design automation tools to map arbitrary circuits to the FPGA architecture. It is expected to yield a well-characterized and highly versatile family of 3D multi-gate transistor based FPGAs that are competitive with ASICs. Work on various design methodologies and tools developed in this research will be disseminated through conference and journal articles. Technology transfer will be done through companies interested in using such FPGAs as accelerators. The material will be included in a senior-level course on Design with Nanotechnologies and a graduate-level course on Low Power IC and System Design introduced by the PI. Female and minority students will be attracted to this research through Princeton's Presidential Fellowship Program.","title":"SHF:Small: Fine-grain Dynamically Reconfigurable FPGA Architecture Aimed at Reducing the ASIC-FPGA Gaps","awardID":"1216457","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["550002"],"PO":["366560"]},"198740":{"abstract":"The Secure and Trustworthy Cyberspace (SaTC) program is the successor to the Trustworthy Computing (TC) program. With the increasing importance of cybersecurity to the nation as a whole, and to the Foundation as a research area, improving communication between program officers and researchers supported by NSF and other government funding agencies, coordination among PIs from the different perspectives sponsored by SaTC, and outreach to the broader community is increasingly important.<br\/><br\/>The SaTC program provides national visibility with the participation of the Social, Behavioral, and Economics (SBE) Directorate, the Office of Cyberinfrasture (OCI), the Mathematics Division of the Mathematics and Physical Sciences Directorate (MPS), and the Engineering Directorate (ENG) in addition to the Education and Human Resource (EHR) directorate. It is arguably the largest single research program in CISE. Across the Foundation, the FY expenditure is estimated to be greater than $100M. There are currently over 500 active awards in the program. The PI meeting will be a large, major event for the Foundation and the community. For this event there is a pressing need to meticulously plan and organize the technical program, the venue and conference logistics.<br\/><br\/>This grant provides funding for the venue and conference logistics, including conference registration, audio visual, and meeting space.","title":"2012 SaTC PI Meeting","awardID":"1250645","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"1668","name":"FED CYBER SERV: SCHLAR FOR SER"}}],"PIcoPI":[533198,"564430"],"PO":["565327"]},"195133":{"abstract":"The NSF Sustainable Energy pathways (SEP) Program, under the umbrella of the NSF Science, Engineering and Education for Sustainability (SEES) initiative, will support the research program of Prof. Suman Banerjee and co-workers at the University of Wisconsin-Madison, and Prof. Sandipan Mishra and co-workers at Rensselaer Polytechnic Institute. The project takes a holistic approach to develop a framework for unified control of commercial and institutional buildings that reduces overall energy consumption through human mediation. The framework consists of multiple components: sensor networks deployed in buildings that will monitor and measure various parameters, e.g., energy, lighting, temperature, humidity, etc. that lead to efficient models; software components that allow human occupants to interact and provide feedback; and actuation outcomes that allow control of building components, such as heating, cooling, airflow and lighting sub-systems and optimize these controls jointly. The novel aspect of this effort is that it combines the following elements in the feedback control of building energy systems: (i) Forecasting of external variables such as energy pricing, energy demand, and weather, as can be determined from the smart grid or the web; (ii) Predicting internal variables such as occupancy, user comfort preferences, and state variables as obtained from predictive dynamic models; (iii) Extracting and then exploiting pattern repetition (daily, weekly, and yearly cycles in temperature, occupancy, usage etc.) in a computationally efficient fashion, an (iv) Incorporating human and psychological factors in the model, by obtaining and processing human-in-the-loop feedback effectively. Through the design of the right human-machine interfaces, creating appropriate incentives for human participation, effective feedback collection, and integrated processing of sensory measurements (obtained from an in-building sensing network) and human inputs, the project aims at providing a by-demand comfort level that is mediated by end-users through their personal communication \"apps\". This approach differs significantly from the current research and practices of modeling, controlling and optimizing building energy sub-systems in isolation, and providing by-default comfort level everywhere in the building independent of occupancy level and demand level. <br\/><br\/>The project explores techniques that can provide major savings in energy consumption in commercial and institutional buildings leading towards a more sustainable design. The educational component of the project includes a laboratory-based curriculum which includes a cross-disciplinary capstone course, \"Smart Energy Laboratory\", suitable enhancements to existing courses, and co-development of new campus-wide sustainability certificate programs. Further, multiple campus dormitories and institutional buildings are being incorporated as \"living laboratories,\" thus educating their occupants about green consumption practices. Other aspects of the project provide interactions with local high schools as well as related industry.<br\/><br\/>A significant fraction of energy consumption in the modern world is within buildings. This project is focused on the development of an intelligent control system to manage energy consumption of buildings by actively incorporating human mediation in this process. The unique aspect of this project includes mechanisms by which multiple tenants of a commercial building can participate in the energy management process and allow the various control and actuation functions to efficiently meet their collective needs. The goal is to develop a blueprint for a more sustainable design of buildings. In addition to the significant impact on energy efficiency and sufficiency of next-generation buildings, the techniques being developed here also have transformative impact on sustainability research and sustainable technologies as a whole.","title":"SEP Collaborative: A Unified Framework for Sustainability in Buildings through Human Mediation","awardID":"1230687","effectiveDate":"2012-09-15","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"8026","name":"Sustainable Energy Pathways"}}],"PIcoPI":["555555","531799","534609"],"PO":["535244"]},"193197":{"abstract":"Modern communication networks are constantly growing in size and sophistication. New applications require these networks to be reliable, computationally efficient, and have small latency. To meet these demands it is critical to have low-complexity, rate-efficient codes for communication and compression. Since Shannon's fundamental results, there has been a flurry of activity to design capacity achieving, computationally efficient coding schemes. For the channel coding problem, it was not until the early 1990s that capacity achieving codes were implemented. Similarly, many good quantizer designs were developed for lossy compression, but unfortunately none of these low-complexity codes provably attain the rate-distortion bound. The divergence between information-theoretic results and code construction is even more pronounced in network communication problems. Despite a sharp characterization of information-theoretic limits for several network models, the best practical codes for these problems fall short of the capacity limits.<br\/><br\/>This research involves the development of computationally efficient codes for Gaussian sources and channels. To this end we leverage recent advances in high-dimensional sparse regression. These are the first low-complexity codes that provably attain the information-theoretic limits codes for Gaussian sources and channels. The main objectives of this research project are: (1) Determining the fundamental limits of sparse regression codes in a variety of communication theoretic settings; (2) Developing low-complexity encoding and decoding schemes for our sparse regression codes. This part of the project draws on ideas from function approximation and sparse signal recovery. The project also provides an opportunity for training graduate students and postdoctoral researchers in the disciplines of communication theory, data compression, statistics and networks.","title":"CIF: Small: Fast Rate-Efficient Codes for Data Compression and Transmission via Sparse Regression","awardID":"1217023","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[517534],"PO":["564924"]},"195144":{"abstract":"The NSF Sustainable Energy pathways (SEP) Program, under the umbrella of the NSF Science, Engineering and Education for Sustainability (SEES) initiative, will support the research program of Prof. Suman Banerjee and co-workers at the University of Wisconsin-Madison, and Prof. Sandipan Mishra and co-workers at Rensselaer Polytechnic Institute. The project takes a holistic approach to develop a framework for unified control of commercial and institutional buildings that reduces overall energy consumption through human mediation. The framework consists of multiple components: sensor networks deployed in buildings that will monitor and measure various parameters, e.g., energy, lighting, temperature, humidity, etc. that lead to efficient models; software components that allow human occupants to interact and provide feedback; and actuation outcomes that allow control of building components, such as heating, cooling, airflow and lighting sub-systems and optimize these controls jointly. The novel aspect of this effort is that it combines the following elements in the feedback control of building energy systems: (i) Forecasting of external variables such as energy pricing, energy demand, and weather, as can be determined from the smart grid or the web; (ii) Predicting internal variables such as occupancy, user comfort preferences, and state variables as obtained from predictive dynamic models; (iii) Extracting and then exploiting pattern repetition (daily, weekly, and yearly cycles in temperature, occupancy, usage etc.) in a computationally efficient fashion, an (iv) Incorporating human and psychological factors in the model, by obtaining and processing human-in-the-loop feedback effectively. Through the design of the right human-machine interfaces, creating appropriate incentives for human participation, effective feedback collection, and integrated processing of sensory measurements (obtained from an in-building sensing network) and human inputs, the project aims at providing a by-demand comfort level that is mediated by end-users through their personal communication \"apps\". This approach differs significantly from the current research and practices of modeling, controlling and optimizing building energy sub-systems in isolation, and providing by-default comfort level everywhere in the building independent of occupancy level and demand level. <br\/><br\/>The project explores techniques that can provide major savings in energy consumption in commercial and institutional buildings leading towards a more sustainable design. The educational component of the project includes a laboratory-based curriculum which includes a cross-disciplinary capstone course, \"Smart Energy Laboratory\", suitable enhancements to existing courses, and co-development of new campus-wide sustainability certificate programs. Further, multiple campus dormitories and institutional buildings are being incorporated as \"living laboratories,\" thus educating their occupants about green consumption practices. Other aspects of the project provide interactions with local high schools as well as related industry.<br\/><br\/>A significant fraction of energy consumption in the modern world is within buildings. This project is focused on the development of an intelligent control system to manage energy consumption of buildings by actively incorporating human mediation in this process. The unique aspect of this project includes mechanisms by which multiple tenants of a commercial building can participate in the energy management process and allow the various control and actuation functions to efficiently meet their collective needs. The goal is to develop a blueprint for a more sustainable design of buildings. In addition to the significant impact on energy efficiency and sufficiency of next-generation buildings, the techniques being developed here also have transformative impact on sustainability research and sustainable technologies as a whole.","title":"SEP Collaborative: A Unified Framework for Sustainability in Buildings through Human Mediation","awardID":"1230751","effectiveDate":"2012-09-15","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"8026","name":"Sustainable Energy Pathways"}}],"PIcoPI":[523085,"560207","565072",523088],"PO":["535244"]},"199621":{"abstract":"People make choices, trying to choose the best of many options, for example, choosing items at a grocery store based on their cost, value and their budget. Sometimes to choose the truly best option requires solving hard computational problems. <br\/><br\/>Economic theory has mostly ignored these computational issues, or has used very simple cost models of computation. The field of computational complexity has developed sophisticated models for handling computational costs and this project will apply the models and tools from computational complexity to economic situations. The project will apply these tools to answer a variety of questions such as<br\/><br\/>- How do we give an economic justification for a cryptographic protocol?<br\/><br\/>- How do we model complex interactive games such as chess?<br\/><br\/>- How do people choose from a large range of possibilities (such as choosing a restaurant in a large city)?<br\/><br\/>- Is there an economic difference between true randomness and pseudorandom number generators?<br\/><br\/>With the vast number of options and data that one has from the ever-growing Internet, the limited computational power of humans and even our computers cannot hope to give a complete analysis of the best choices. This research will generate a large number of tools that will help us understand the limits of our decision-making ability as well as guide the techniques we need to make choices in our ever-more-complex society.","title":"EAGER: Bounding Rationality by Computational Complexity","awardID":"1255900","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":["557660"],"PO":["565251"]},"198653":{"abstract":"Software's increasing role in aviation, medical devices, and other safety- and mission-critical tasks is driving a major research effort in software verification, in both academia and industry. This effort involves proving, using formal mathematical methods, that software does what its authors intend it to do. Interactive theorem provers (ITPs) are a key tool in software verification, enabling users to create complex proofs of deep properties beyond the reach of automated provers. In spite of the increasing need for their use, ITPs have limited user interfaces that have hardly evolved in the past 20 years. This makes it difficult for novices to begin using these tools, and limits the productivity of experts. The objective of this research is to design, develop, and evaluate powerful user interfaces for ITPs. The resulting user interfaces will be made freely available to the public as open-source code.<br\/><br\/>The hypothesis is that a novel ITP user interface that addresses ITP users' information needs through advanced editing techniques will enable novices to prove theorems and understand proofs more quickly and accurately than current ITP user interfaces, and increase productivity for experienced users. Advanced editing techniques will include inference rule and complex syntax visualization and manipulation, as well as proof previews. Together, these techniques will enable users to understand how proofs evolve, more easily read complex formulas, and quickly explore ways of advancing a proof. The hypothesis will be tested using Coq, a widely adopted ITP. The evaluation of the advanced editing techniques will include a comparison with a widely used ITP user interface in terms of efficiency for completing and understanding proofs. Successfully applying modern human-computer interaction techniques to interactive theorem provers will result in a major step forward in the usability and applicability of ITPs. This in turn will help facilitate the increased use of formal methods and verification in academic research, but also with industrial applications. Likewise, it will provide a useful tool for teaching software verification courses by helping students concentrate on proving theorems instead of focusing their attention on how to interact with software. Project results will be disseminated by submission to venues in human-computer interaction and interactive theorem provers.","title":"Powerful User Interfaces for Interactive Theorem Proving","awardID":"1250306","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[532995,532996],"PO":["565264"]},"198664":{"abstract":"Most machine learning algorithms operate on fixed dimensional feature vector representations. In many applications, however, the natural representation of the data consists of more complex objects, for example functions, distributions, and sets, rather than finite-dimensional vectors. This project aims to develop a new family of machine learning algorithms that can operate directly on these complex objects. The key innovation is efficient estimation of certain information theoretic quantities for learning predictive models from complex data. The research is organized around three specific aims: (a) Development and analysis of nonparametric estimators for certain important functionals of densities, such as entropy, mutual information, conditional mutual information, and divergence; and study of the theoretical properties of these estimators including consistency, convergence rates of the bias and variance, and asymptotic normality. (b) Use of the preceding estimators to design new learning algorithms for clustering, classification, regression, and anomaly detection that work directly on sets, functions, and distributions without any additional, hand-made feature extraction, histogram creation, or density estimation steps that could lead to loss of information. (c) Study of the theoretical properties of these new machine learning algorithms (computation time, sample complexity, generalization error) and empirical evaluation of the algirithms them to a variety of important real-world problems, including nuclear detection astronomical data analysis, and computer vision in collaboration with researchers at Lawrence Livermore, University of Washington and Johns Hopkins University, and Carnegie Mellon University respectively.<br\/><br\/>Broader Impact. The project, if successful, could substantially advance the current state-of-the-art in building predictive models from complex data. The results of research, including publications and open source software, will be freely disseminated to the larger scientific community. The project provides enhanced research-based training opportunities for graduate and undergraduate students at Carnegie Mellon University as well as the collaborating institutions.","title":"EAGER: Nonparametric Machine Learning on Sets, Functions, and Distributions","awardID":"1250350","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["565056",533021],"PO":["565136"]},"195177":{"abstract":"The NSF Sustainable Energy pathways (SEP) Program, under the umbrella of the NSF Science, Engineering and Education for Sustainability (SEES) initiative, will support the research program of Prof. Ben Stuart and co-workers at Ohio University and Georgia Institute of Technology. This project will lead to a shift in the knowledge base required to address a significant national need for alternative energy for the next generation of sustainable buildings. It will provide the fundamental information required for designing, constructing, optimizing, and scaling up of an algae-based power system that will significantly contribute to the energy requirements of houses or residential communities. The project proposes the following aims: a) Evaluate the bench-scale feasibility of the technology through compositional analysis of various residential waste streams, determining biochemical methane potentials, calculating specific growth rates and biomass yields of local algae strains, and processing the cultivated biomass into biofuels. Process modeling software will employ comprehensive mass and energy balances to develop the descriptive and predictive understanding of system parameters necessary to design, construct and operate a pilot-scale system in both open- and closed-loop modes; b) Determine the interrelationships of architectural design and planning parameters for the algae-powered house at the rural, suburban, and urban scales using the design studio and GIS to test hypotheses and develop novel scenarios; and c) Evaluate elements of integration, constructability, reliability, safety and environmental impact on the use of the algae-based technology in residential structures using a comprehensive economic risk and feasibility assessment to investigate the costs of installation, training, operation, material transfer, maintenance, and evaluation of selected technologies.<br\/><br\/>The economic analysis described in aim 3 above includes comprehensive surveys that will elicit public perceptions and tolerance for the costs associated with sustainable housing incorporating integrated material and energy flows. Investigating the holistic development of these communities will have positive impacts in the fields of architecture, building construction, engineering, sustainable\/renewable energy, environmental stewardship, multi-scale economics, and education, and will lay the foundation for a significant shift in the approach to cross-disciplinary research in these fields. This effort will engage students from several of these disciplines, and will produce educational materials that will be incorporated into academic instruction as well as informative videos for younger students and adults. Jobs could be created for manufacturing the proposed algae-based systems in rural community developments of Appalachian counties with historically high unemployment rates.<br\/><br\/>While biofuels hold the potential to contribute significantly to global energy demands, the majority of algal biofuel research to date has been directed towards meeting transportation needs. The proposed research will assess the potential of algal cultivation and processing in the management of liquid and solid waste streams, using the algae produced to supplement waste biomass in the production of energy for use in residential applications. Including water and waste management with the potential for food production and generation of biofuels will augment existing off-grid power technologies (e.g. solar PV, solar thermal, wind) that provide many homeowners with desired energy security, and will extend the sustainability and resource independence of residential communities.","title":"SEP: Sustainable Housing through Holistic Waste Stream Management and Algal Cultivation","awardID":"1230961","effectiveDate":"2012-09-15","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"8026","name":"Sustainable Energy Pathways"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[523190,523191,523192,523193],"PO":["560215"]},"189611":{"abstract":"Computer performance has doubled many times over during the past 40 years, but the very techniques used to achieve these performance gains have made it increasingly difficult to build systems that are provably safe, secure, or reliable. This fact significantly impedes progress in the development of our most safety-critical embedded systems such as those found in medical, avionic, automotive, and military systems. A transformation in the way that these systems are created is needed, one that uses new hardware design techniques, computer architectures, and programming languages to create classes of hardware\/software systems with formal and provable safety properties that are verifiable all the way down to the implementation level of bits and logic gates.<br\/><br\/>This research will change the way that hardware and embedded systems designers approach the problem of provable properties, enabling them to directly control and analyze the system at the lowest level and to statically determine if their designs are in compliance with a given policy. For example, if a system must be real-time this property can be verifiable for a full system, from gates to software, by ensuring that the architecture design carefully manages interference through a set of new hardware primitives, software designed to exploit these new primitives, specialized hardware analysis tools, and new design languages. To ensure this technology will have impact beyond academia the PIs are making these new technologies available and accessible through easy to use tools, continuing to include undergraduates at all levels of research to help train a new generation of engineers capable of designing safety-critical systems, and integrating concepts from information assurance into their extensive outreach activities. Over the long term this research will help create the skills and tools that embedded system engineers need to evaluate the trustworthiness of their systems, and it will ease the development of those critical systems on which we all depend on for our safety and livelihood.","title":"SHF: Medium: Collaborative Research: Building Critical Systems with Verifiable Properties Using Gate Level Analysis","awardID":"1162177","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["560817"],"PO":["565264"]},"198202":{"abstract":"This CREATIV award is partially funded by the Networking Technologies and Systems (NeTS) program in the Division of Computer Networks and Systems in the Directorate of Computer & Information Science & Engineering, the Animal Behavior program through the the Divisions of Integrative Organismal Systems and Emerging Frontiers in the Directorate of Biological Sciences, the Experimental Program to Stimulate Competitive Research (EPSCoR), the Office of the Division Director in CISE\/CNS and the Office of the Assistant Director in CISE. This project aims to address the major barriers to adoption of wireless sensor networks (WSNs) in multiple cross-disciplinary domains, particularly high cost, low customizability, lack of rugged designs and complex programming models. The project team aims to surmount these barriers to provide a potentially transformative wireless sensor network design framework that can be used by anyone with minimal technical skills, and yet achieve the benefits of pervasive monitoring and sensing through large-scale ubiquitous wireless sensor networks. The PIs will leverage their multi-disciplinary and cross-domain expertise to address these challenges using experimental biology research as their platform. <br\/><br\/>The goals of this project are to provide and\/or enable: 1) a hardware framework for low-cost, rugged, and customizable sensor nodes, in a wide range of form factors, 2) autonomous manipulation and monitoring of electro-physiological parameters of electro-motor circuits in vivo and in vitro using WSNs, 3) novel network protocols and algorithms for monitoring aquatic animals in the field, and 4) a software framework that makes programming WSNs easy and intuitive for users with minimal programming experience. By removing the barriers to adoption through plug-and-play, and easy customization and programming, this proposed research hopes to make WSNs ubiquitous in our daily life in general and in biology research in particular. <br\/><br\/>In the short term, this project will enable experimental researchers in labs and in the field to stimulate and monitor animals\/specimen in real-time and without human intervention, which will significantly improve understanding of animal responses to diverse stimuli. In the long term, the outcomes of this research will help WSNs become ubiquitous in our daily life and as easy to use as computers today. The project will provide undergraduate and graduate students including women and minorities in the classes and labs of the PIs the benefit of an unique interdisciplinary learning and research environment. It will leverage NSF GK-12 DISSECT, BPC, and YWiC initiatives in the computer science department of New Mexico State University to expose middle and high school students in the city of Las Cruces to STEM research and teach them computational thinking.","title":"CREATIV: Towards Ubiquitous Adoption of Wireless Sensor Networks in Experimental Biology Research.","awardID":"1248109","effectiveDate":"2012-09-01","expirationDate":"2017-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"8078","name":"INSPIRE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"7275","name":"CROSS-EF ACTIVITIES"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[531915,"177233","561140"],"PO":["565303"]},"199665":{"abstract":"The 12th ACM SIGCOMM Internet Measurement Conference (IMC) is sponsored by ACM SIGCOMM and ACM SIGMETRICS, in cooperation with USENIX and held in Boston, MA, November 14?16, 2012. Funding from this award assists approximately 9 graduate students from US institutions to attend this conference. IMC is the primary venue for presenting new research results on collecting and analyzing measurements of the Internet. Attending conferences such as IMC is of paramount importance for graduate students pursuing research in the field. Authors have the opportunity to present their work and all attendees have a chance to interact with many others performing leading-edge research in the field.<br\/><br\/>Intellectual Merit: This award serves to widen the audience attending the Internet Measurement Conference (IMC), raising the level of interaction and the potential for new collaboration, new investigations, and higher quality research. The grant enables students (who otherwise do not have sufficient funds) to attend the conference in Boston. <br\/><br\/>Broader Impact: This award, by enabling students to attend who might not otherwise be able, will increase the dissemination of the conference?s research results to a larger and more diverse audience. It also integrates research and education of graduate students by allowing students to observe high-quality presentations and interact with senior researchers in the field. By giving preference in grant awards to women and minority students, we hope to widen the participation among these underrepresented groups. Furthermore, by advertising to a wide range of colleges and universities, participants from a more diverse set of institutions should be able to attend and benefit from the conference.","title":"Student Travel Support for the 2012 Internet Measurement Conference, November, 14-16, 2012, Boston, MA","awardID":"1256093","effectiveDate":"2012-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["563433"],"PO":["565090"]},"189413":{"abstract":"Conventional software testing checks whether each output is correct for the set of test inputs. But for some software, it is not known what the correct output should be for some inputs -- yet it is still important to detect coding errors in that software, so they can be fixed. This dilemma arises frequently for machine learning, simulation and optimization applications, often \"Programs which were written in order to determine the answer in the first place. There would be no need to write such programs, if the correct answer were known.\" As these kinds of applications are frequently used in public infrastructure and biomedical research (domains targeted in this research), it is critical to detect and fix errors before a calamity occurs.<br\/><br\/>Fortunately, many such applications reflect 'metamorphic properties' that define a relationship between pairs of inputs and outputs, such that for any previous input i with its already known output o, one can easily derive a test input i' and predict the expected output o'. If the actual output o'' is different from o', then there must be an error in the code. This project investigates methodology for determining the metamorphic properties of software and for devising good test cases from which the secondary tests can be derived. The project extends the inputs\/outputs considered in previous work on metamorphic testing to focus on application state, before and after, rather than just functional parameters and results. The research also extends the pairwise relations implied by metamorphic properties to 'semantic similarity' for nondeterministic applications, applied to profiles from numerous executions, since an exact relation cannot be expected to hold for a single pair of test executions. These extensions enable treatment of more sophisticated properties that preliminary experiments have shown to reveal defects that were not detected otherwise.","title":"SHF: MEDIUM: Achieving Software Reliability without True Test Oracles","awardID":"1161079","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["541922"],"PO":["564388"]},"199698":{"abstract":"This research aims to overcome the extreme challenges that need to be solved to realize a 1000-core (kilocore) processor. Processors with tens of cores are already in commercial products today. A kilocore processor could take us into the era of Server-on-Chip and Supercomputer-on-Chip. On-chip network is the medium through which two nodes in a processor can communicate, and therefore constitutes the backbone of a kilocore processor. Unfortunately, current on-chip network solutions are inadequate as they do not scale in terms of both power and performance beyond a few tens of cores. To reach the ambitious design goal of 1000+ cores with realistic power budgets, the interconnect technology needs to be at least 15 times more power efficient while providing at least the same level of throughput-per-core as today. <br\/><br\/>This project investigates three interrelated solutions to meet the above challenge in an evolutionary manner: (1) Developing a low-power and energy-proportional interconnect architecture that employs a larger number of narrower networks, (2) Using high-radix Swizzle-Switches as the building blocks for interconnecting the multiple networks, and (3) Re-designing network architecture with multiple networks and Swizzle-Switches using 3D integration with Through-Silicon-Vias to achieve scalability beyond 1000 cores. This project will demonstrate the feasibility of kilocore processors. If such processors can be built, they could have a tremendous impact on future exascale systems such as cloud computing servers and HPC systems that have many applications including drug discovery, defense, information analysis, and social networking.","title":"EAGER:Scaling On-Chip Interconnects for Exascale Systems","awardID":"1256203","effectiveDate":"2012-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[535404,535405],"PO":["366560"]},"199588":{"abstract":"Information Centric Networking (ICN) is a new networking architectural paradigm in which information rather than packets (units of transmission) are given primacy. This concept is central to several of the NSF's recent Future Internet Architecture projects as well as other US based and international projects. The paradigm is transformational because the objective is not to move bits from one place to another but rather to provide access to information, without regard to location. Hence at the core of an information or content centric networking design is identifiers. This research focuses on identifiers and the system that services them. In this EAGER proposal, the PI plans on a set of first steps in validation and evaluation of a design for identity management that supports both persistence and pervasiveness of identifiers. The plan is that this capability can reside on top of any one of the approaches to ICN. Thus, this identification approach can provide effective persistence and pervasiveness and can be translated into current ICN identifiers, which generally are intended for delivery of bits in a location-independent way.<br\/><br\/>The project is to validate and evaluate the effectiveness of providing an indirection layer on top of two of the current ICN projects that are significantly different from each other. The demonstration of validity will focus specifically on persistence and minimization of opportunities denial of service attacks, two capabilities not supported in the ICNs themselves. The requirement for persistence of identifiers and identification management is critical to supporting longevity of the information itself. Mitigation of denial-of-service attacks is selected as the second challenge for two reasons. First, denial-of-service attacks are only possible in pervasive systems, in which attacks can be coordinated widely across a system. Second, one of the key questions across the set of ICN projects is the security and integrity of the infrastructure. All these systems support end-to-end integrity, privacy, confidentiality, but none focuses on the security of the infrastructure that is providing that end-to-end service. Hence denial of service attack mitigation has been selected as the second challenge for this project.<br\/><br\/>This project is a necessary proof of concept setting the stage for a larger effort to explore a whole Pervasive Persistent Identification System (PPInS). At the core of the design is a set of idspaces that are distinct in several ways: the id syntax they support, the management of ids (such as assignment and resolution of them) and the security they provide. Each will translate a globally unique, persistent identifier into the identifiers of the underlying ICN. A global resolution scheme will map each id to the appropriate idspace management facility. In this preliminary work, the researchers will design one of those idspaces and evaluate it on top of two of the competing ICN approaches, for validity and evaluation. The contributions of the larger project can be enumerated by intellectual merit and broader impact.<br\/><br\/>Intellectual Merit: The proposed clean separation of identification from the supporting ICN layers, if successful, will result in three specific contributions: the persistence and ubiquity of identification, achieved through isolation and layering; the extensibility and evolvability of approaches to identification to meet varying performance, security, and scalability requirements through modularity within the identification layer; and the extension of the end-to-end principle over time by recognizing the separation of identification from the activities of location independent expressions of interesting and delivery including differentiated end-to-end and infrastructure security.<br\/><br\/>Broader Impact: There are three central broader impacts of this work: the role and support of persistent information (Independent of information centric networking, as the Internet continues to expand in its role and influence on economic, civic, and military\/intelligence components of contemporary society?the value of information is not only in its short term effect, but in the persistence over extremely long periods of time); the education and training of women (The PI is a woman and has consistently supported and will continue to support young women in science, through her research. ) and international collaboration (This work is part of a productive research collaboration between MIT and the University of Cambridge, specifically the leadership of the PURSUIT ICN project.)","title":"First Steps in Exploring Pervasive Persistent Identification for Information Centric Networking","awardID":"1255761","effectiveDate":"2012-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["125800"],"PO":["565090"]},"187136":{"abstract":"This project addresses fundamental issues in the White-Cover network which provides data coverage services in the densely populated areas with the TV White Space spectrum. It is motivated by the fact that a White-Cover cell will likely host hundreds of users while supporting highly dynamic data traffic, a scenario beyond the capabilities of existing network protocols. In addition, the White-Cover devices will likely have to coexist in the same channel with heterogeneous devices due to the lack of free TV channels in the densely populated areas. These challenges are addressed by a combination of novel physical layer techniques and advanced machine learning techniques, and the solutions are enhanced by further optimizations. This project studies: 1) efficient physical layer schemes for node state detection with which the transmissions in the cell can be scheduled very efficiently, 2) advanced protocols that adapt to the heterogamous interferences conditions with the reinforcement learning technique, 3) optimized protocol for power consumption and integrated partial packet recovery, and 4) network-wide performance analysis and planning. <br\/><br\/>The White-Cover network designed in this project provides a better alternative to the current technologies for the TV White Space. Users may enjoy data coverage at much less cost than from the cellular phone networks and new business may be enabled. The expected results of this project include the protocols and algorithms optimized for the unique features of White-Cover and tested with experiments. The results will be disseminated in conferences and journals; the source code will be freely available online.","title":"CAREER: Addressing Fundamental Challenges for Wireless Coverage Service in the TV White Space","awardID":"1149344","effectiveDate":"2012-09-01","expirationDate":"2017-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["537230"],"PO":["557315"]},"198026":{"abstract":"Scientific data is being collected at a higher rate than ever. A striking example is in elementary particle physics (EPP) experiments, where collaborations of thousands of scientists collect huge amounts of data at the Large Hadron Collider (LHC), but other disciplines have and are continuing to observe similar growth. <br\/><br\/>The complexity and time frame of these experiments is such that the full scientific potential can only be realized when the data remains accessible and analyzable through extended periods. <br\/><br\/>The possibility of successfully meeting this goal for the necessary long term data preservation requires a novel approach that will make the data and necessary software management more solid and survivable. The long term data preservation will become an even more critical issue as present experimental efforts evolve and the Big Data paradigm develops. The initial efforts of the US community to analyze the large volume of LHC data is being satisfied by the Open Science Grid project, designed to facilitate such large and distributed experiments. DASPOS provides an opportunity to continue to study today's analysis over the long term. <br\/><br\/>The DASPOS project incorporates the present state-of-the-art knowledge in working with data in EPP. This project aims to provide a generic technological framework where the basic difficulties are identified and solved with the aim of advancing these goals simultaneously for several disciplines, which should facilitate the emergence of commonalities and standards.<br\/><br\/>The milestones and the work plan are well structured and adapted to present knowledge. Intense communications via workshops is planned and is a natural path for the goal of inclusion of the various disciplines. The intention to document these workshops is a valuable component of this project, as are concrete goals such as prototypes and software challenges.<br\/><br\/>The DASPOS project is not only sound but also timely. The recent dynamics in data preservation and large data management is now reaching several countries and funding agencies. In fact, several projects at national levels are now installed, including for instance, the PREDON project, financed by CNRS-France in 2012 to prepare a multidisciplinary novel approach to big data management. <br\/><br\/>Other similar initiatives are under study in Germany and Italy. It is no question that synergies will emerge at an international scale, and is also clear that DASPOS will play a pioneering and leading role in this context. <br\/><br\/>In conclusion, the impact and merit of the DASPOS proposal is innovative and potentially transformational. This can be an historical opportunity to make a significant advance in the scientific data management in the context of the \"Big Data\" challenge.","title":"Data and Software Preservation for Open Science (DASPOS)","awardID":"1247316","effectiveDate":"2012-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"1221","name":"ELEMENTARY PARTICLE ACCEL USER"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"7553","name":"PHYSICS AT THE INFO FRONTIER"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"7231","name":"CYBERINFRASTRUCTURE"}}],"PIcoPI":[531440,"547371","565244",531443,"559182"],"PO":["560726"]},"199379":{"abstract":"The Symposium On Usable Privacy and Security (SOUPS) brings together an interdisciplinary group of researchers and practitioners in human computer interaction, security, and privacy. The program features technical papers, workshops and tutorials, a poster session, panels and invited talks, and discussion sessions. The ninth SOUPS will be held July 24-26, 2013 at Northumbria University in Newcastle, UK. The funds support travel grants for American students to attend the conference. SOUPS is the top conference devoted to usable privacy and security. By increasing student participation at the SOUPS conference, it may encourage more students to get involved in usable security research and pursue further graduate education and careers in this area.","title":"Student travel grants for Symposium On Usable Privacy and Security 2013","awardID":"1254508","effectiveDate":"2012-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["553878"],"PO":["565327"]},"194770":{"abstract":"Despite the Internet's status as critical infrastructure, there is little scientific instrumentation dedicated to monitoring global Internet behavior. In particular, we have no rigorous framework for measuring, analyzing, or quantifying the impact of network outages, filtering, or other abnormal connectivity dynamics on a global scale.<br\/><br\/>This project applies successful research results in analyzing recent macroscopic Internet connectivity disruptions to the development, testing, and experimental deployment of an operational capability to detect, monitor, and characterize such large-scale infrastructure outages. The investigators are seeking to validate and extend a methodology for identifying not only which networks have been affected by an outage, but also which mechanisms have been used to effect a deliberate disruption. The two intellectual themes of the research are: (1) extracting signal from malware-induced background radiation in Internet traffic (IBR); and (2) combining multiple types of data (active probing, passive IBR, routing data, geolocation, and registry databases) to delineate the scope and progression of the outage. The project will also develop quantitative indicators to gauge the impact of geophysical disasters on Internet infrastructure, including the dynamics of loss and restoration of service. A transition of these research outcomes into practice will yield a system specification, implementation, and experimental operational deployment to detect and monitor global connectivity failures on a planetary scale. In addition to improving our understanding of how measurements yield insights into network behavior, and strengthening our ability to model large scale complex networks, such a system will illuminate infrastructure vulnerabilities that derive from architectural, topological, or economic constraints, suggesting how to mitigate or eliminate these weaknesses in future Internet architecture and measurement research.","title":"TTP: Medium: Detection and Analysis of Large-Scale Internet Infrastructure Outages","awardID":"1228994","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[521741,521742],"PO":["564246"]},"193681":{"abstract":"The goal of this project is to develop and evaluate novel methods for telecollaboration - remote collaboration that effectively integrates video and voice communication, computer vision based tracking, and augmented reality display in order to enable participants to more fully leverage the local physical environment in their remote interactions. In this telecollaboration paradigm, remote and local users will interact with the physical environment using models derived from live imagery from a camera that the local user holds or wears, rather than merely passively viewing the video stream. A key aspect of the approach is that it does not require preparation of the environment or model information, so it can be viewed as an \"anywhere, anytime\" mobile communication technology.<br\/><br\/>Intellectual merit: The proposed research builds on promising preliminary work on telecollaboration showing the effectiveness of world-stabilized \"telepointers\" - markers controlled by the remote user that stick to the real-world referents in a dynamic environment. The project will advance the state of the art in remote collaboration by providing new capabilities to integrate real and virtual, verbal and spatial, local and remote. The proposed developments are needed in order to make the physical space a more fundamental part of telecollaboration, and significant user studies will be conducted to acquire a better understanding of the opportunities and limitations of physically-grounded remote interaction. <br\/><br\/>Broader impacts: Better, more compelling tools for telecollaboration can have a tremendous impact in terms of productivity and environmental consequences, as improved remote interaction reduces the need for physical collocation and thus travel. The educational impacts of the project include the training and mentoring of graduate students and a new seminar course. The research team will disseminate research results and collected data widely and use the developed technologies to provide outreach opportunities for select groups to participate in lab open houses.","title":"HCC: Small: Telecollaboration in Physical Spaces","awardID":"1219261","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["558448",518684],"PO":["565342"]},"192471":{"abstract":"This project will develop and evaluate methods by which large numbers of humans, together with computers, can advance the field of synthetic biology by assembling a corpus of creative designs of molecular machines built from DNA segments as well as other molecular structures. Specifically, it will develop a massively-distributed DNA machine construction game that will enable human worldwide collective creativity to be applied to problems ranging from the design of novel self-organizing materials to smart therapeutics that can sense and respond to their environment. The innovative approach is to cast problems of constructing molecular nano-machines with specific functions as a collaborative machine design game governed by the rules of DNA strand interactions. <br\/><br\/>This approach points to a new paradigm for future science, in which a large group of people together with computers work on difficult creative problems, finding solutions that could not be found by computers alone, or by people alone, or without the massive participation of users. If successful, this approach could change science profoundly, with wide-ranging impact on many disciplines including nanotechnology, biochemistry, medicine, and even social and economic behavior analysis. Although the project specifically focuses on games that use DNA strands as principal building blocks of nano-machines, the potential set of applications is large, and encompasses three of the most significant problems facing humanity today. <br\/><br\/>The primary goal of the computer game is to develop and focus collective creativity towards a design space of machines governed by DNA molecular mechanisms. It is currently not known whether this form of sophisticated scientific design creativity can be developed rapidly with non-experts. It is also unknown whether this developed creativity can exceed the current capabilities of the scientific community. This project aims to answer a number of fundamental questions: How does one develop computer games to maximize targeted human design creativity? What are the guiding principles of successful molecular design games? How do we generalize game-development principles to the widest possible range of synthetic biology problems? How can we develop a collective creative design process that outperforms any individual creativity? How do we learn from the way people play the game, and distill their strategies towards stronger automated approaches? <br\/><br\/>The successful outcomes of this project can have a wide ranging impact on health and medicine. One such problem is the design of diagnostic devices and imaging technologies. The game players will work to develop DNA sensors and circuits that can autonomously analyze and interpret the information encoded in a set of molecular disease markers. This approach will enable new devices for multi-analyte testing in low resource settings and will lead to novel medical imaging technologies. Another challenge is design of novel targeted therapeutics, in this case novel RNA-based therapeutics that can autonomously sense and analyze their environment and activate a therapeutic response only where required. A third problem is design of novel materials. This project will develop DNA nanostructures with the potential for the massively parallel self-assembly materials with desired electronic, optical, or chemical properties. These materials will find applications in areas from artificial photosynthesis to biofuels production. <br\/><br\/>This effort will have positive broader impacts for informal science education. The game will reach out to people of all demographic profiles in hope of educating everyone about key molecular research challenges, empowering them to solve important scientific problems, and engaging them in research and science in general. Hopefully, the best scores in these games turn into seminal discoveries with deep impact on people's lives. Also, undergraduates will be involved directly in game development, and a course centered around prototyping of molecular games will be offered. Furthermore, the research team will work with education scientists to develop a new curriculum about DNA and how nature uses molecular mechanisms to achieve function. The curriculum will be anchored around the DNA Machine game and will be piloted in US high schools.","title":"HCC: Large: Collaborative Research: DNA Machine Builder: Creative molecular-machine design through mass-scale crowdsourcing","awardID":"1213127","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["562975","558957"],"PO":["564456"]},"193450":{"abstract":"Use-case scenario-based specifications are frequently used to capture the most important requirements for a software system. Several techniques have been proposed for representing the scenario models and for mapping them to software system behavior models. The resulting behavior models yield several important benefits, including the ability to perform early system assessment and to aid the software engineers in implementing the required functionality. The two key observations guiding this research are that (1) use-case scenarios are inherently partial and (2) modern software systems are typically built by composing independent components. Existing techniques support either modeling the partial behavior of an entire system, or modeling component-level behaviors under the assumption that they are known completely.<br\/><br\/>To bridge the above disconnect, this research provides a trio of formally correct techniques for mapping use-case scenario models of a system's requirements to partial-behavior models of the constituent system components. The resulting behavior models are then used to validate existing and elicit new requirements, which in turn, result in further refinements of the components models. The resulting techniques are evaluated theoretically for correctness, completeness, and complexity, and empirically for practical usefulness and scalability. The research yields several broader impacts: it improves the current state of software requirements specification and formalizes its relationship to the prevalent component-based software system development; its reliance on popular scenario-based modeling notations renders the resulting techniques easy to adopt in practice; the support for eliciting currently unspecified requirements leads to improved understandings of systems under development; finally, the supported early discovery and resolution of system behavior discrepancies helps to mitigate significant costs that would be incurred if detected at later stages of a system's lifecycle.","title":"SHF: Small: From Scenario-Based Software Requirements to Component-Level Behavior","awardID":"1218115","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["551145"],"PO":["564388"]},"193571":{"abstract":"This research investigates how Millennials, having grown up with the Internet, can become effective future information workers. Studies are suggesting that multitasking with digital media is associated with errors, stress and degraded performance. This study provides two main research contributions. First, to date no one has conducted an in situ investigation of multitasking among the Millennial generation. Second, whereas most investigations have approached multitasking as an individual activity, this research will instead take a new perspective on multitasking as a collaborative social system. This study will examine whether connectivity leads to information overload and distraction, how online media experience affects learning, communication, and behavior offline, as well as the relationship between degree of connectivity and work performance. This study will use a mixed-methods approach involving ethnographic techniques, sensors, and diaries to collect detailed activity. The results can contribute to an understanding of how young adults use digital media, it can inform the design of requirements for future technologies, and it can be used for the design of media literacy programs in K-12 schools. <br\/><br\/>Broader impacts: The results will contribute towards plans and policies that schools and organizations can enact to help young people manage their work and use of digital devices more effectively. A media literacy curriculum developed from this research can serve as a model for K-12 schools. While there has been much concern given to preventing worker \"burnout\" and lowering stress among information workers, this study can provide concrete results of how digital technologies contribute to distraction and stress, especially among the Millennial generation. The study will elicit requirements for technology design that could help people better manage multitasking, increase situational awareness and reduce errors. Results of this study will help young people improve their effectiveness in using digital media, which could improve future work life, productivity and satisfaction. Finally, the project will provide educational impact through the participation of undergraduate and graduate in the research and through the development of a new doctoral seminar.","title":"HCC: Small: Multitasking as a Collaborative System: Examining the Millennial Generation","awardID":"1218705","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[518418,"535531",518420],"PO":["565342"]},"193340":{"abstract":"Social, technological, and biological systems are often represented as a complex network, whose structure reveals important properties of the system and leads to insights about its behavior. Many methods have been proposed over the past several decades to analyze the structure of complex networks, for example, to identify influential people in a social network or functional modules in a protein-protein interaction network. Most of these methods examine connections between entities only, and ignore interactions between them. In recent years, however, it has been recognized that network structure is the product of both its connections (i.e., topology) and the interactions taking place between entities in the network. These interactions determine how ideas, signals, pathogens, or influence flow along the connections, and different interactions may lead to different views of network structure.<br\/><br\/>This research project will lay the foundation for understanding the interplay between network structure, topology and dynamical interactions. It will develop a mathematical framework for interactions-aware network analysis that will lead to principled metrics and algorithms for finding communities or modules, measuring proximity between entities in a network, and distance between networks. Theoretical findings will be empirically validated using real-world network data on tasks such as identifying modules, predicting missing links and others. This new framework for network analysis will translate into new discoveries in computer science, sociology, biology and medicine.","title":"CIF: Small: BCSP: Rethinking Network Structure: The Role of Interactions in the Analysis of Network Structure","awardID":"1217605","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[517887],"PO":["564924"]},"193461":{"abstract":"Evaluating complex, interactive visual analytics systems is challenging for many reasons. The exploratory nature of using visualization makes quantitative measurements of individual components of the visualization task infeasible. The range of potential users and their differing goals render standardized metrics too restrictive. And environmental conditions can influence experimental outcomes, making it difficult to compare and generalize the results of separate evaluations. Although numerous methods have been proposed for evaluating visualizations and HCI, few can be readily applied to objectively evaluate visual analytics systems in real-world settings. In this project the PI will address this open challenge by developing a method to evaluate complex, interactive visual analytics systems using objective measures that can be performed in-situ to yield reproducible, generalizable results. His approach is to integrate noninvasive brain imaging using functional near-infrared spectroscopy (fNIRS) and cognitive factors measurements. The PI argues this will allow him to address issues in visual analytics evaluation by explaining the user's cognitive processes at a deeper level. Lightweight, noninvasive brain imaging techniques such as fNIRS have become more mature and reliable in recent years. fNIRS is easy to set up, robust to movement, and has been demonstrated in studies to be effective in determining a user's cognitive load, preferences, and perception when using a visualization. Cognitive factors such as locus of control, spatial visualization ability, and perceptual speed have recently been shown to correlate with a user's ability to interact with a visualization, and can be generalized to predict the behavioral patterns of users with different cognitive profiles. Both approaches aim to better understand the user's cognitive state and abilities. In this research cognitive factors measurements will provide low-level, baseline information about the user which is stable and unchanging (\"traits\"), while fNIRS provides immediate, real-time feedback on the user's current cognitive state when interacting with a visualization (\"states\"). In practice, without accounting for the individual user's traits, it is difficult to generalize the signals provided by fNIRS (for example, right- and left-handed subjects produce very different brain signals). By combining information on both \"traits\" and \"states,\" evaluation results can generalize to a larger population based on cognitive profiles. The PI and his team have conducted two preliminary experiments that demonstrate the feasibility of the approach. They have replicated the classic experiment by Cleveland and McGill using fNIRS, and successfully distinguished participants' brain signals when using bar charts versus pie charts. In another experiment, they successfully correlated participants' locus of control with their ability to use hierarchical visualizations with different visual metaphors.<br\/><br\/>Broader Impacts: The results of this work will have both immediate and long term impact on the field of visualization. In the short term, project outcomes will provide a robust and reliable evaluation mechanism for measuring the effectiveness of complex, interactive visual analytics systems. Ultimately, the findings of this research will help open the human-cognition \"black box\" and illuminate how interacting with a visualization helps a user gain insight. Such an understanding may in turn lead to the realization of insight-based evaluation and the emergence of a new visualization theory that is based on human cognitive processing. Finally, by integrating real-time fNIRS into visual analytics systems, effective adaptive mixed-initiative visual analytics systems can become one step closer to reality.","title":"CGV: Small: Toward Objective, In-Situ, and Generalizable Evaluation of Visual Analytics by Integrating Brain Imaging with Cognitive Factors Analysis","awardID":"1218170","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["559567","519872",518161],"PO":["565227"]},"193582":{"abstract":"The complexity and power demands for System-on-Chips are projected to grow in coming years, making low-power design and low-loss power delivery critical for power-efficiency of future embedded systems. The objective of the proposed research is to explore innovative technology and methodologies for effective power management in embedded processors considering the interdependence between power delivery and low-power design. A system platform is being developed in which the power management unit, consisting of the power delivery and the power control circuits, is integrated vertically with a processor using 3D heterogeneous integration. An integrated approach is pursued that couples the circuit innovations in the 3D power management tier with the on-line control of the processor power to maximize the power-efficiency of the system while ensuring reliable operation. <br\/><br\/>Embedded systems are ubiquitous in modern society in various applications including medical systems, handheld devices, aviation systems, networking, and security, to name a few. Power management is often considered to be the most critical problem for future embedded systems. The 3D approach to power management can enable transformative solutions to the power problem in embedded systems, removing barriers to major advancements in their power-performance, relaxing packaging constraints, and reducing system footprint. The research results are disseminated through conference and journal publications, short-courses, tutorials, and project website and integrated in the graduate and undergraduate VLSI courses. The project is engaged with the Summer Undergraduate Research in Engineering\/Science (SURE) and Facilitating Academic Careers in Engineering and Science (FACES) programs to increase participation of undergraduate and under-represented students in computer systems research.","title":"CSR: Small: Exploiting 3D Integration for Power Management in Embedded Processors","awardID":"1218745","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[518444],"PO":["565255"]},"193593":{"abstract":"Access to mathematics education is critical to facilitating careers in the sciences, engineering, technology, and in many professions, as well as to providing the mathematical literacy needed in everyday life. The PI's goal in this project is to increase real-time access in the classroom to mathematical material for low vision students (who are visually impaired but not blind), which is currently mostly lacking as these students must primarily rely on assistive technology and human note takers to provide access to course materials after the class meeting. The PI's approach is to bring together expertise in computer science, mathematics, and accessibility to provide a useful and usable solution to this problem for the iPad. Called AccessMath, the prototype application will provide zoom-able camera views as well as a view of notes written at the whiteboard (captured by a Mimio), which may be altered through magnification and contrast adjustment features. The system will support consulting and searching course content during lecture, including textbooks, handouts, notes written at the whiteboard, and audio in video (e.g., to find the word \"eigenvalue\" in recorded lectures for the course). A novel note-taking facility will be employed, where notes are represented on note \"cards\" that can be attached to a specific location in the current view (e.g., at a spot in the whiteboard view), then manually moved, resized, rotated, stacked, and \"flicked\" out of view, providing a natural means for interacting informally with notes created during lecture. Notes are created as blank cards, or as cards containing views of whiteboard data, video excerpts, or existing notes. Notes are also used in constructing search queries. Linear algebra (in particular matrices) is the pilot scope for the project, due to the many challenges in conveying a matrix, individual items within the matrix, following derivations, and the scale of the matrix needed when completing non-trivial problems. AccessMath users will have a single iPad which connects to a server providing video feeds and recognition and retrieval services.<br\/><br\/>Broader Impacts: AccessMath will assist low-vision students with mathematical instruction in and out of class, at the high school and university levels, by providing immediate access to lecture materials, including searches for mathematical content in whiteboard notes, handouts, textbooks, and lecture videos (through word spotting in audio). The system will afford student ownership in note taking and customizing access, which will be significantly better than current solutions, and will reduce or eliminate the extent to which visually impaired students fall behind their sighted peers in the classroom setting. The project will also advance the state-of-the-art in recognition and retrieval for mathematical notation, and will create a novel note-taking model using the metaphor of photos on a tabletop, which should be applicable to domains other than mathematics.","title":"HCC: Small: AccessMath: Improving Mathematics Lectures for Low Vision Students through Integrated Video, Note-Taking and Search","awardID":"1218801","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[518469,"527961",518471,518472],"PO":["565227"]},"193483":{"abstract":"Change pervades the entire software development process. Software may be changed in response to market forces, changing customer requirements, or new hardware and software dependencies. The thread of changes, along with the decisions behind those changes, is often transient and is rarely directly captured by a development team. Source code drifts away from requirement and design documents (and other artifacts) that explain the motivations and decisions behind the code. There is a high overhead in maintaining consistency between these artifacts and the code. Project schedules have tight deadlines, with little or no time to explicitly document the decisions behind code changes. Thus, further code modifications are often expensive because the software engineers lack the understanding of past decisions.<br\/><br\/>This project aims to investigate a lightweight, flexible, and systematic approach to identifying and connecting related changes to support future maintenance activities. By leveraging traceability and refactoring techniques, we can represent change as a first-class artifact so that software engineers can better understand the nature of change and how it impacts related artifacts. Our approach is novel because it allows developers to reason about changes as varied as high-level concepts to low-level code that cuts across several modules. We also investigate techniques for bridging any gaps between these connections.<br\/><br\/>The approach is applicable to organizations that maintain legacy systems or acquire software from other organizations. The results will also be valuable to any medium- or large-scale development context in assimilating new personnel and in coordinating distributed development.","title":"SHF: Small: Collaborative Research: Tracing and Reasoning about Changing Artifacts","awardID":"1218266","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["562923"],"PO":["564388"]},"195430":{"abstract":"This award provides funding for theoretical and software development of novel algorithms for processing large-scale optimization models arising in Signal Processing,<br\/>Medical Image Reconstruction, Machine Learning, and high-dimensional Statistical inference, where huge and steadily growing amounts of underlying data result in the<br\/>necessity to process optimization problems with hundreds of thousands of variables and constraints. In addition, some of applications, such as low rank matrix<br\/>approximations, lead to problems with difficult geometry, which amplifies significantly the challenges caused by sheer problem sizes. These challenges will be<br\/>met via developing algorithms with cheap iterations utilizing state-of-the-art approaches, primarily bilinear saddle point reformulation of the problem of interest<br\/>combined with duality-based handling difficult geometry and accelerating algorithms via various types of randomization. Theoretical and algorithmic developments<br\/>will be adjusted to several generic applications (sparsity- and low-rank oriented Signal Processing and Machine Learning, extensions of total variation-based Image<br\/>processing, and some others) and will be aimed at developing optimization techniques with good theoretical performance guarantees and visible practical potential;<br\/>the latter will be validated by extensive numerical experimentation with both simulated and real life problems.<br\/><br\/>If successful, the research will advance theory and practice of optimization by enriching its abilities to process large-scale\/complex geometry problems and thus will<br\/>contribute significantly to the computational toolboxes in Signal Processing, Image Reconstruction, Machine Learning, and some other subject domains. As a byproduct,<br\/>the research will contribute to recent tendency of bridging the corresponding research communities, with clear mutual benefits. In addition, the results of<br\/>the research could form the base of new Ph.D.-level optimization courses.","title":"Design of Efficient Saddle Point Algorithms for Large-scale\/Complex Geometry Convex Optimization","awardID":"1232623","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"5514","name":"OPERATIONS RESEARCH"}}],"PIcoPI":[523883,"565107"],"PO":["564999"]},"193252":{"abstract":"The PIs are studying and refining use of infrastructure support for an online learning community that engages local students, teachers, fishermen, and scientists in rural communities in a non-hierarchical learning environment. The team is testing the efficacy of and refining an online platform that supports inquiry in the context of place-based education. They are investigating how these different populations learn together with each other and seek to determine what influences their understanding of STEM concepts and dialogues, and they are working towards a pedagogy that combines the best elements of each population's needs and potential contributions so that a true learning community can develop. The technological innovation is an infrastructure for community learning. Research looks at information diffusion, emergent communication networks, learning among each of the communities, and participation, with the aim of understanding affordances and challenges that must be addressed in making such learning opportunities work effectively for all. The effort will be carried out in a variety of locales -- six in Maine and two in coastal Alaska. Each of these is rural and in many ways disconnected, and each is experiencing shifts in weather and climate that are affecting the local ecosystems and livelihoods of residents.<br\/><br\/>The endeavor looks at the ways technology can be used to foster sophisticated learning and access to resources that is otherwise unavailable in these detached and often impoverished communities. The project aims to show how to bring science home to a community, using its issues and resources to make science relevant, hopefully leading to renewed interest in science among older residents and interest and understanding among students and teachers. Over the long term, PIs are seeking to develop a model for place-based non-hierarchical learning communities that might be put to use in a variety of places, each with its own community issues and resources. Several populations of learners are addressed: school children (K-8), who can learn about science in the context of enterprises going on around them in the community; fishermen, who contribute their experiences and wisdom but may not know the science behind what they experience; other community members with similar roles; parents; and teachers. Added in will be scientists, who may or may not come from the same community, who comment on the data collection and analysis and interpretations being done by the community. Scientists, too, will be learners, as they will need to learn how to communicate well with the target populations.","title":"EXP: Collaborative Research: WeatherBlur","awardID":"1217247","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7625","name":"REESE"}}],"PIcoPI":[517676,517677,517678,517679],"PO":["562669"]},"198950":{"abstract":"Our physical world presents an incredibly rich set of observation modalities. Recent advances in wireless sensor networks (WSNs) enable the continuous monitoring of various physical phenomena at unprecedented high spatial densities and long time durations and, hence, open new exciting opportunities for numerous scientific endeavors. Since sensor nodes are unattended and battery-powered, network monitoring\/inference from indirect measurements at the sink(s) and energy conservation are critical in the deployment of large-scale environmental WSNs. Therefore, a viable framework for energy-efficient network monitoring and data collection is fundamentally important to significantly improve WSN management\/operations and reduce its deployment costs. <br\/><br\/>This proposal is devoted to a fundamental investigation of energy-efficient network monitoring\/inference and data collections in large-scale WSNs, based on the recent breakthrough of compressed sensing (CS) through an integrated theoretical and empirical approach. This research plan aims to develop a novel and rigorous framework of topology inference for real-world WSNs operated in highly noisy communication environments. This proposed exploratory research is different from current approaches, which may create a new paradigm of optimal design, development, and management\/operations for large-scale WSNs to significantly extend their lifetime. This, in turn, would lead to a substantial reduction of the current prohibitive cost of WSN deployment, and thus could be high-reward for the deployment of large-scale monitoring WSNs for scientific, civic, national security, and military purposes in the near future. The proposed education plan creates a new interdisciplinary educational practice for both undergraduate and graduate students through hands-on experience with our extended WSN testbed. The outreach plan includes summer camps for school students using an extended WSN testbed.","title":"EAGER: Collaborative Research: Network Inference and Data Collection Based on Compressed Sensing in Large-Scale Wireless Sensor Networking","awardID":"1252066","effectiveDate":"2012-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["550733"],"PO":["565303"]},"195441":{"abstract":"Social and economic decisions cannot be fully explained by \"rational\" attempts to maximize monetary gain, even in very simple game-theoretic scenarios. Complex emotional processes such as anger, guilt or generosity act as hidden forces that lead to observable actions. Such \"non-rational\" motivations can drive our own decisions and they affect our beliefs about what motivates others' decisions as well. The goal of this project is to use automatic measurements of dynamic facial expressions, in combination with other measurements such as functional MRI (fMRI) and eye-tracking, to investigate the role of non-rational motivations in social decision making. The core of the approach is to use state-of-the-art computer vision techniques to extract facial actions from video in real-time while participants interact with a computer or with each other, in some cases viewing live video of each others' faces. The investigators will use powerful statistical machine learning techniques to make inferences about the participants' internal emotional states during the interactions. The goal is to use the inferences concerning emotional state (a) to predict participants' behavior; (b) to explain why a decision is made in terms of the hidden forces driving it; and (c) to build autonomous agents that can use this information to drive their interactions with humans. <br\/><br\/>This multidisciplinary project contributes to several fields such as psychology, neuroscience, and economics. First, it develops new methodologies to study decision processes. Second, it uses these methods to test hypotheses about social decision-making and to bridge the gap between observable actions and the internal states that generated them. Third, the investigators intend to make available a dataset and toolset that should be an extremely useful for other investigators analyzing facial expression in multiple contexts. Additionally, automatic and on-line decoding of internal motivational states lays the groundwork for \"affectively-aware\" interactive computers, or artificial systems that can make inferences about the emotions and intentions of their users. Through the development of these systems, this project will make a significant contribution to the growing field of human-machine interaction.<br\/><br\/>[Supported by Perception, Action and Cognition, Decision, Risk and Management Sciences, and Robust Intelligence]","title":"Collaborative Research: Emotional Sophistication - Studies of Facial Expressions in Decision Making","awardID":"1232676","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"1321","name":"DECISION RISK & MANAGEMENT SCI"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"7252","name":"PERCEPTION, ACTION & COGNITION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[523911],"PO":["563458"]},"193384":{"abstract":"The theme of this project is control of hybrid systems based on limited (sampled and quantized) information about their state. The project aims to bring together, for the first time, two research topics: hybrid systems, and control with limited information. The project will seek to develop a novel method for propagating over-approximations of reachable sets for hybrid systems, and use it to define and validate a control strategy based on sampled and quantized measurements of the continuous state. This method will be combined with state-of-the-art analysis tools for hybrid and switched systems, such as multiple Lyapunov functions, average dwell-time switching, and input-to-state stability.<br\/><br\/>Hybrid systems are important for modeling and controlling the behavior of cyber-physical systems, such as fly-by-wire aircraft and power grids. Hybrid systems combine continuous dynamics and discrete transitions. This hybrid nature enables one to capture many processes encountered in practice which switch between different modes of operation. Controllers for such systems typically have limited information about the system state, due to limitations of available sensors and delays and losses in communication. A possible scenario is controlling an autonomous robot which switches between the search mode and the pursuit mode and, for security or implementation cost reasons, is connected to the control center via a very low-power communication link. Educational and outreach activities of the project include support of a graduate student, integration of the research with graduate courses in hybrid systems and control, workshops and short courses, and involvement of undergraduates in translating theoretical developments into software tools.","title":"CSR--EHS: Small: Limited-information control of hybrid systems via reachable set propagation","awardID":"1217811","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["523280"],"PO":["564778"]},"193285":{"abstract":"Smartphones equipped with powerful embedded sensors (e.g. accelerometers, GPS, microphones, etc.) can be used to monitor multiple dimensions of human behaviors including physical, mental, and social behaviors of wellbeing. In particular, such enhanced capabilities in mobile devices enable people to better manage their health. Existing mobile health applications mostly rely on manual data entry which may not be sufficient for certain population e.g. seniors and students with emotional behavioral disorders (EBD). This project aims to build a multimodal sensing system which provides continuous and efficient monitoring of users? activities using mobile phones and wearable sensors. Our system analyzes and correlates different sensor streams to infer certain behaviors as well as possible environmental factors that may trigger such behaviors. Furthermore, our system provides non-intrusive peer assisted localization technique that allows caregivers to track the whereabouts of monitored users. We also develop efficient schemes to infer higher layer information e.g. activity levels of monitored individuals; social relationships among monitored users. Additionally, the communities extracted from a mobile phone enabled social network in our system not only enable mobile healthcare systems but can also be exploited for securing certain components of the system (e.g., coping with clone attacks). Our system allows users to be monitored for their mental, cognitive, and physical well-being and can potentially reduce the cost for special need education as a result of increasing the productivity of teachers and caregivers.","title":"CSR: Small: Collaborative Research: Smartphone Enabled Social and Physical Compass System (SENSCOPS)","awardID":"1217387","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550063"],"PO":["565255"]},"193296":{"abstract":"Improving the usage of communication spectrum resources is critical to future wireless systems. The OSTARA project focuses on the development of RF photonic techniques that support the ability to simultaneously transmit and receive in wireless devices. The effort involves a mix of theoretical development (specifically investigating potential improvements in capacity), as well as systems validation efforts involving building an opto-cancellation circuit capable of cancelling out co-site interference associated with simultaneous transmission and reception. . Specifically, the theoretical component of the effort will involve using ray-tracing to understand the role of cancelation of multipath components on communication rate, as well as an investigation into the impact of idealized cancellation on network capacity using graph coloring. The systems component of the effort will involve developing photonic circuits that subtract off the transmitted signal from the receiver chain, as well as potential multipath images of the transmitted signal. Validation will involve field testing the opto-canceller by setting up test scenarios on the ORBIT testbed at WINLAB.<br\/><br\/>Broader Impact: The proposed research will improve the spectrum utilization of future wireless systems, an issue of critical national importance. Additionally, the project will educate students and post-doctoral fellows in the inter-disciplinary area of RF-photonics as applied to advanced radio systems.","title":"NeTS: Small: Collaborative Research: OSTARA: An Optically-based Simultaneous Transmit and Receive Architecture for Enhancing Wireless Communications","awardID":"1217435","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["559694","531431"],"PO":["564993"]},"194034":{"abstract":"One of the cornerstones of modern cryptography is that new constructions of cryptographic protocols should be accompanied by a proof of security. Such proofs show that a construction satisfies a given definition of security, under certain assumptions and in a specific model. Widely used models include various forms of setup (such as the existence of a public-key infrastructure or common reference string); idealized models such as the random oracle model where a hash function is treated as a truly random function; or hardware models where physical devices with some additional functionality are assumed.<br\/><br\/>Many of the models used widely in cryptography are still poorly understood, especially insofar as their relation to practice. The goal of this work is to develop a better understanding of these models, investigating in particular their relations and implications; the possibility of constructing cryptographic protocols in weaker (or at least incomparable) models; and the feasibility of designing schemes with \"fallback\" security that provide more basic security guarantees in case the assumed model fails.","title":"TWC: Small: Exploring Cryptographic Models and Setup Assumptions","awardID":"1223623","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[519626],"PO":["565264"]},"198511":{"abstract":"This EAGER proposal, developing a dense deformable object tracking method for testing and ground-truthing highly dynamic maneuvers of robotic vehicles, offers to prototype a radically new approach to instrumentation for highly agile machines of many types. Using heterogeneous fusion of numerous sensing modalities, the PI proposes to create a high resolution, high bandwidth map of deformable and articulated bodies such as cars with suspensions, humans, legged robots, and such for the performance evaluation and algorithm development for these highly dynamic research artifacts.<br\/><br\/>Broader Impacts: This work will facilitate a wide variety of research, including studies of agile robotics in dynamic environments. The impacts to robotic science, especially agile and fast moving robots, are clear. The system will also have impact on any other science, such as human motion analysis, ergonomics and medical rehabilitation, where accurate, dense tracking and mapping of deformable scenes is required.","title":"EAGER: Prototype Dense Motion Capture for Large-Scale Deformable-Scene Tracking","awardID":"1249409","effectiveDate":"2012-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["557148"],"PO":["543539"]},"195134":{"abstract":"The NSF Sustainable Energy pathways (SEP) Program, under the umbrella of the NSF Science, Engineering and Education for Sustainability (SEES) initiative, will support the research program of Prof. Martin O. Saar and co-workers at the University of Minnesota - Twin Cities. This project is motivated by the need to simultaneously reduce emissions of carbon dioxide (CO2) to the atmosphere while expanding the production of electricity, preferably using renewable resources. The project will develop CO2 Plume Geothermal (CPG) technology as a method to achieve both goals. CPG injects CO2 that is captured from a CO2 emitter (e.g., a coal-fired power plant) underground where the majority is permanently stored. CPG can also be used as an energy storage technique by compressing the CO2 into the subsurface reservoirs. In this case, slightly heated CO2 is circulated to the surface for electricity production to offset demand or to arbitrage prices. This is an approach to energy storage that uses CO2 to moderate differences in timing between the time electricity is produced by variable sources, such as wind and solar, and the time electricity is demanded by society. The objectives are to investigate the feasibility of CPG technology options, the implications of their deployment, the potential for broader spillovers, and the production educational material about geothermal energy, CPG, and their potential roles within the broader energy system.<br\/><br\/>This project will enhance the transition to sustainable energy systems in part by training researchers in interdisciplinary teams and by raising the awareness of geothermal energy and CPG as parts of the low-carbon, renewable energy portfolio. The overall purpose of CPG is develop an environmentally benign energy source that uses fewer resources (e.g. water) and with less negative externalities (e.g., CO2 emissions) than conventional approaches. This research will thoroughly investigate environmental returns that can be gained by storing and using CO2 to produce electricity. In addition, investigations of CPG deployment produce fundamental understanding in areas of electricity market dynamics, decision science, the economics of low-carbon energy sources, and energy policy. In association with the Hubert Project at the Humphrey School of Public Affairs (www.hubertproject.org), a CPG case study detailing the challenges and benefits of developing geothermal energy into a significant sustainable energy resource will be developed. Interactive online visuals will be produced to explain CPG to the public and for use in undergraduate courses. Collabration with the University of Minnesota's Diversity and Outreach program will increase the diversity of the participants in this project.<br\/><br\/>The transformative nature of the project involves its investigation of (a) CPG for economically storing CO2 and for using the stored CO2 to utilize geothermal energy to produce electricity and\/or distribute heat, (b) the economic, financial, and operational issues of CPG technology development and commercial deployment, and (c) how the CPG technology may enable the deployment of other renewable and low-carbon energy technologies. If successful, this project will produce the understanding necessary for the development of a new environmentally benign approach to energy production or storage. The understanding and awareness of the challenges and opportunities for increasing the sustainability of renewable energy systems will be increased. In addition, the CPG technology has the potential to make carbon sequestration economically possible, thereby mitigating global warming.","title":"SEP: A Novel Method Using CO2 and Geothermal Resources for Sustainable Energy Production and Storage","awardID":"1230691","effectiveDate":"2012-09-15","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"8026","name":"Sustainable Energy Pathways"}}],"PIcoPI":[523049,523050,523051,523052,523053],"PO":["565270"]},"194045":{"abstract":"This project studies Internet censorship as practiced by some of today's nation-states. The effort emphasizes analyzing the techncial measures used by censors to perform censorship, the extent to which their operations inflict collateral damage (unintended blocking, or blocking of activity wholly outside the censoring nation), and vulnerabilities due to the specifics of how censorship operates. Regarding this latter, we analyze flaws in either how the censorship monitoring detects particular network traffic to suppress, or in how the monitor then attempts to block or disrupt the target traffic. This facet of the research focuses on forms of monitoring that eavesdrop on network links, analyze copies of transmitted traffic, and then inject forged traffic, seemingly sent from one of the communication endpoints to the other, instructing the other party to cease communication. Such \"on-path\" monitoring is subject to a number of potential manipulations and evasions due to the inexact view the monitor has of the comunication as actually seen by the communicating parties. We in particular then work towards developing tools and changes to Internet technology that can resist these forms of disruption and thus enable users to access the Internet freely.","title":"TWC: Phase: Small: Censorship Counterstrike via Measurement, Filtering, Evasion, and Protocol Enhancement","awardID":"1223717","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["562327"],"PO":["564223"]},"188732":{"abstract":"Intellectual Merit: This EAGER project addresses distribution issues for systems executing on heterogeneous computing architectures, that is, architectures that have been configured with graphics processing units (GPUs) and field-programmable gate array (FPGAs).<br\/><br\/>Heterogeneous architectures may offer considerable increase in throughput when compared to simple multi-processor architectures. But, to achieve maximum gain and resource utilization in heterogeneous architectures, an application?s workload needs to be distributed among accelerators and CPUs according to the computational capabilities of those components. The optimal distribution of tasks and data among processing units is an important concern for such platforms. <br\/><br\/>Dynamic partitioning can better utilize all computational units during execution. However, even though this type of partitioning is addressed in a few published studies, full utilization gains have not been reported. This team will attempt to develop ?near ideal? partitioning schemes which require: <br\/><br\/>? devising monitoring mechanisms for each type of accelerator, <br\/>? quantifying tasks and data as computational blocks, and <br\/>? estimating performance throughout execution. <br\/><br\/>These load balancing schemes will be application and device independent and fully automated without the need for prior training runs before the actual run. The goal is to integrate these schemes with programming models to seamlessly expose near optimal utilization of heterogeneous multiprocessor architectures.<br\/><br\/>Broader Impact: The software and hardware platforms developed in this research will be publicly released as open source so that others may experiment with them. The research will be conducted with cooperation of Intel researchers enabling possible future transfer of technology to industry. Funding of this project will provide support for recruiting underrepresented minority and female students for the project. In addition, the research content will be integrated to graduate courses to provide training to students for designing and programming future heterogeneous systems.","title":"EAGER: Developing a Programming Environment for Heterogenous Multiprocessors","awardID":"1157377","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["516924","549718"],"PO":["551712"]},"196366":{"abstract":"Intellectual Merit:<br\/>This award funds a workshop that focuses on the impact of rapidly evolving information and communications technology, i.e., cyber-infrastructures, on the activities of discovery, innovation, and learning. Cyber-infrastructure in discovery and learning is of significant current interest. Paradigm shifts that have impacted many industries appear poised to transform higher education and the academic research environment.<br\/><br\/>The goals of the workshop are to set an agenda for how to transform the what, the how, and who participates in discovery and learning; to personalize and broaden participation in discovery and learning; and to accelerate discovery and the transfer from discovery to innovative use. The specific workshop objectives are to: 1) explore and articulate key research questions, likely game-changers, and possible paradigm shifts, 2) frame an interdisciplinary research agenda for the next decade, and 3) identify possible research programs, experiments, and organizational structures that would best meet the needs of the nation in this rapidly changing environment. <br\/><br\/>Broader Impacts:<br\/>New paradigms are rapidly emerging for learning and education that challenge the use of cyber-infrastructure as a platform for enhancing knowledge communities and for expanding their scope and participation unconstrained by time and distance. Our world has entered a period of rapid and profound economic, social, and political transformation driven by knowledge and innovation. Much of this workshop focus is to set an agenda for understanding the rapidly changing needs of society for workforce learning and skills, new knowledge, research, innovation, and creativity in a world increasingly integrated and transformed by digital technology. The impact of demographic change, workplace needs (adaptive, ubiquitous, and lifelong learning opportunities), and learning structures (explicit, tacit, and intuitive knowledge) are considered as well as redesigns for learning systems at the K-12, higher education, workplace, and lifelong learning. And, the discussion and products of this workshop will likely be useful in the pursuit of new science.","title":"Workshop for the Future of Discovery, Innovation, and Learning, October 9, 2012, University of Michigan","awardID":"1238464","effectiveDate":"2012-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"1698","name":"DEVELOP& LEARNING SCIENCES\/CRI"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"7231","name":"CYBERINFRASTRUCTURE"}}],"PIcoPI":[526514],"PO":["551712"]},"195277":{"abstract":"This project develops a portable power-assist orthosis to address the problems of impaired mobility due to lower-extremity weakness. This robotic orthosis actively assists the user's joint motion according to his or her motion intent, and thus enables the user to perform certain critical, power-consuming tasks (such as the sit-to-stand motion) independently. The orthosis is powered with a high-performance actuation approach, namely chemo-fluidic actuation, which combines the high-power-density pneumatic actuators with a high-energy-density monopropellant-based pneumatic supply. In addition to the new actuation approach, the orthosis also features a new structure and user interface for effective load transfer and easy donning-doffing; and an effective motion control algorithm to enable interactive power assist according to the user's motion intent. With the portable power-assist orthosis, the users reduce the reliance on the assistance by caregivers, enjoy a significantly improved life quality, and stay physically active to avoid the aforementioned issues associated with the sedentary life style.<br\/><br\/>This project has broader impact to assistive technologies and can improve mobility of elderly individuals and people suffering from the impaired mobility due to lower-extremity weakness. The project can potentially reduce a considerable amount of physical assistance taking care of these individuals, and the cost of time and manpower in the care. The research of the project is incorporated into education activities by utilizing the rehabilitation robotics as an innovative education medium.","title":"SHB: Type I (EXP): Collaborative Research: A Portable Power-Assist Orthosis to Aid Elderly Persons in Locomotion","awardID":"1231676","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":["563067",523496],"PO":["564316"]},"195288":{"abstract":"This project explores the use of a gas selective resistive type sensing technology to detect and quantitate nitric oxide (NO) in exhaled breath for diagnostic purposes. The goal of the project is to develop a technique for personalized monitoring of the fraction of nitric oxide (FeNO) in exhaled breath, with the long term objective of prevention or control of airway diseases, such as asthma. FeNO is a known biomarker for measuring airway inflammation and the technology studied in this project provides an effective and practical means to quantitate NO levels in breath in a relatively simple and noninvasive way. This work involves the use of single crystal metal oxide nanowires that are expected to improve the detection threshold of NO-selective sensing nanoprobes by at least two orders of magnitude down to the few ppb level and below. A sensor microsystem is being developed that quantifies the gas sensor response to generate and display an accurate measure of the NO concentration in a single exhaled breath. The design of independent component analysis (ICA) algorithms, to enhance the gas discrimination and improve the robustness of the sensor response, is one of the objectives of this project. The implementation of the ICA algorithms and readout circuitry incorporating baseline tracking in mixed-signal VLSI will lead to a low-power autonomous system-on-chip solution for the measurement of gas concentrations from a handheld gas-measuring unit. The head space from cell cultures that have been stimulated to generate NO and CO are being used, along with breath-simulating samples, to assess the performance and reliability of the NO-breathalyzer. The same studies help to understand the biochemistry of NO production in response to inflammation. <br\/><br\/>The expected outcome of this work is a smart health breath analysis tool that will empower the individual who may be susceptible to airway diseases to stay healthy and that provides a means for self-monitoring of early signs of illness in the home, instead of the hospital setting in which monitoring would require the assistance of health care professionals. The new tools being developed for personalized diagnostics should be easily employed by the lay public to promote their health and well-being. Furthermore, the device will be especially suitable for use by a wide range of compromised individuals, such as the very elderly, young children and otherwise incapacitated patients. This project will engage students, including underrepresented groups in research activities in an interdisciplinary field spanning nanomaterials, sensor nanotechnology, microelectronic device fabrication and diagnostic instrumentation, biophysics and biochemistry, and ultimately nanomedicine. Interactions with National Laboratories and the medical diagnostics industry are anticipated. These interactions are expected to lead to the translation of the technology embodied in the NO-breathalyzer resulting from this work in the laboratory to the marketplace. The results of this work will be disseminated through publications, presentations, outreach events and multimedia products to be posted on the project web site <br\/>(https:\/\/web.stonybrook.edu\/cnsd\/formservertemplates\/pro7.html).","title":"SHB: Type I (EXP): Personalized Asthma Monitor Detecting Nitric Oxide in Breath","awardID":"1231761","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[523522,523523,523524],"PO":["563751"]},"199655":{"abstract":"Individuals on the move, e.g., tourists on a sightseeing trip in an unfamiliar city often find themselves overwhelmed by the challenges of coping with unfamiliar environments. This presents a need for tools and methods that will guide them by providing them useful recommendations while they are \"on the move.\" Recent advances in mobile and sensor-based technologies have made it possible to collect and process location traces across many different mobile applications. Such data, when combined with other spatio-temporal, contextual, and user-specific information can, in principle, be used to generate useful recommendations for individuals on the move. <br\/><br\/>This exploratory research project formulates and explores a novel variant of recommender systems, namely, mobile sequential recommender systems for mobile users where each recommendation takes into account the trajectory and history of past recommendations, as one of selecting a sequence of locations to recommend under a set of spatio-temporal, contextual, and privacy constraints. Given the combinatorial nature of the problem (where the size of the search space grows is exponential in the relevant parameters) the project aims to explore heuristics. It will also develop appropriate measures for assessing the effectiveness of alternative solutions.<br\/><br\/>The project, if successful, would establish the feasibility of a line of investigation that could lead to the development of effective approaches to sequential recommendation problem with obvious benefits to mobile users. The project enriches research based advanced training opportunities for graduate and undergraduate students. All of the data, software, and publications resulting from the project will be made freely available to the broader research community.","title":"EAGER: Collaborative Research: Sequential Recommender Systems in Mobile and Pervasive Environments","awardID":"1256036","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[535295],"PO":["565136"]},"187203":{"abstract":"In a rapidly developing emergency situation the timely discovery of discovery of information about the inside of a building, such as temperature during a fire, is key to a successful response. A challenge is that the needed sensors are difficult to deploy and maintain in these situations. While robots can be used to gather some information, considerations of deployment logistics, dynamic environment, infrastructural dependence, reliability, and speed have limited their adoption. To address these problems, this project explores a novel approach of using a collection of simple controlled mobile air vehicles with sensors (SensorFly). By taking a minimalistic approach, where each device has few sensors, the SensorFly project will develop a basic understanding of such controlled-mobile networked systems, including trade-offs between per device capability and system capability, and low-level collaborative techniques to counter system non-determinism. To test models and evaluate different approaches, the project builds on testbeds involving SensorFly nodes, a low-cost 30-gram flying sensor node.<br\/><br\/>The SensorFly project has the potential for broad social impact. Studies that improve information gathering in emergency situations will improve safety for both the responders and building occupants. Although the size and weight of available sensors and platforms may decrease over time, the application of minimal mobile sensing platforms will remain attractive due to their reduced intrusiveness. Therefore, the investigation into minimalistic approaches will have a lasting impact that extends beyond today's sensing systems. Finally, the project continues the PI's efforts for advising students in research and encouraging members of under-represented groups into science and engineering fields.","title":"CAREER: SensorFly: Minimalistic Dynamic Sensing and Organization in Groups of Semi-Controllable Mobile Sensing Devices","awardID":"1149611","effectiveDate":"2012-09-01","expirationDate":"2017-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["429041"],"PO":["564778"]},"198104":{"abstract":"Few would disagree about the importance of creativity in human lives. Science depends on the creative mind. So does the economic viability of nations today. The goal of this grant is to open up a new frontier in human-robot interaction whereby it becomes possible to augment human creativity through human-robot interaction. This possibility could emerge by embedding sophisticated search functions and AI software in a social robot, which then engages in dialog with the user, decides on key terms for a search, filters the results (based on unique and long-standing histories of the user), and decides which results to bring forward at specific junctions in the human-robot dialog. <br\/><br\/>Intellectual Merit: There are four overarching goals: (1) To conceptualize the creativity domain and to generate creativity methods in human-robot interaction. (2) To develop human-robot interaction patterns that set up (a) people's prior social relationships with a social robot such that people are open to creating with the robot, and (b) the interactions with the robot for the creative process itself. (3) Piloting research toward fostering creativity in interaction with ATR's humanoid robot, Robovie. And (4) conducting a formal research study to test new forms of creativity with ATR's humanoid robot, Robovie.<br\/><br\/>Broader Impacts: This research will (1) lead to the mentoring of undergraduate and graduate students; (2) broaden the participation of females in HCI; and (3) promote the transfer of expert knowledge from a leading Japanese laboratory to the United States. More broadly, (4) this new vision for HRI could be transformative insofar as over the next 3-10 years this form of human-robot interaction could provide an entirely new way that people generate new knowledge, and thereby help promote exponential growth in the sciences, as well as in some of the humanities.","title":"EAGER: Augmenting Human Creativity Through Human-Robot Interaction","awardID":"1247690","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["546850"],"PO":["564456"]},"199688":{"abstract":"Evaluating information retrieval systems, such as search engines, is critical to their effective development. Current performance evaluation methodologies are generally variants of the Cranfield paradigm, which relies on effectively complete, and thus prohibitively expensive, relevance judgment sets: tens to hundreds of thousands of documents must be judged by human assessors for relevance with respect to dozens to hundreds of user queries, at great cost both in time and expense. This exploratory project investigates a new alternative to information retrieval evaluation paradigm -- based on \"nuggets\". \"Nuggets\" are atomic units of relevant information, and one instantiation of these nuggets is simply the sentence or short passage that causes a judge to deem a document relevant at the time of document assessment. The hypothesis is that while it is likely impossible to find all relevant documents for a query with respect to web-scale and\/or dynamic collections, it is much more tractable to find all or nearly all nuggets (i.e., relevant information), with which one can then perform effective and reusable evaluation, at scale and with ease. At evaluation time, relevance assessments are dynamically created for documents based on the quantity and quality of relevant information found in the documents retrieved. This new evaluation paradigm is inherently scalable and permits the use of all standard measures of retrieval performance, including those involving graded relevance judgments, novelty, diversity, and so on; it further permits new kinds of evaluations not heretofore possible.<br\/><br\/>The project plan includes the development and release of nugget-based evaluation data sets for use by academia and industry. In fostering this effort, the project team has close ties with the US National Institute of Standards and Technology (NIST) and the Japanese National Institute of Informatics (through NTCIR), two of the premier organizations that develop and release information retrieval data sets. All research results and data sets developed as part of this project are available at the project website (http:\/\/www.ccs.neu.edu\/home\/jaa\/IIS-1256172\/). The project also provides educational and training experience for students and the development of curricular materials based on the project results.","title":"EAGER: A Nugget-Based Information Retrieval Evaluation Paradigm","awardID":"1256172","effectiveDate":"2012-09-15","expirationDate":"2014-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[535376],"PO":["563751"]},"189216":{"abstract":"The world's linguistic diversity is diminishing at an alarming rate, and there are not enough resources (trained field linguists or funding for them) to document all the endangered languages before they are gone. Thus there is a critical need for software tools to support the efficiency of field linguists. This project will develop software tools to assist in the documentation of endangered languages by merging two types of resources: Collections of linguistic examples curated by linguists and a cross-linguistic computational grammar resource, called the Grammar Matrix. The result will be a system for creating machine-readable, or implemented, grammars from data collected and annotated by field linguists.<br\/><br\/>Implemented grammars can contribute to endangered language documentation in several ways: The grammars themselves provide a very rich resource, allowing linguists to explore analyses at a level of precision not usually achieved in prose descriptions. Furthermore, implemented grammars can be used to create treebanks, that is, collections of utterances associated with syntactic and semantic structures. The process of creating the treebank can provide important feedback to the field linguist about aspects of the linguistic data not covered by current analyses. The resulting treebanks can be used to create further computational tools and are also a rich source of comparable data for qualitative and quantitative work in linguistic typology, grounding higher-level linguistic abstractions in actual utterances in a computationally tractable fashion.<br\/><br\/>While building an implemented grammar is typically not within the scope of a field linguistics project, field linguists do routinely create collections of examples of glossed, translated text (called \"IGT\"), which encapsulate the result of extensive linguistic analysis. This project will further develop computational methods for extracting typological information from IGT like those pioneered by the RiPLes project (Xia & Lewis 2007, Lewis & Xia 2008) and combine that information with the cross-linguistic resource produced by the Grammar Matrix project (Bender et al 2002, 2010) to create implemented grammars for endangered languages.<br\/><br\/>The Division of Information & Intelligent Systems of the Directorate for Computer & Information Science & Engineering is funding this award as part of its commitment to support the development of computational tools and methods for the documentation of endangered languages.","title":"AGGREGATION: Automatic Generation of Grammars for Endangered Languages from Glosses and Typological Information [ctn, ing, inh]","awardID":"1160274","effectiveDate":"2012-09-15","expirationDate":"2015-02-28","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"7719","name":"DEL"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":[507284,507285],"PO":["564750"]},"189458":{"abstract":"Most scientific and engineering disciplines today have enormous opportunities for creation of knowledge from massive quantities of data available to them. But the lack of appropriate algorithms and analysis tools for processing, organizing, and querying this data deluge makes this task extremely challenging. A large portion of the data being acquired today has a geometric character, and even non-geometric data are often best analyzed by embedding them in a multi-dimensional feature space and exploiting the geometry of that space. This data is invariably full of noise, inaccuracies, outliers, is often incomplete and approximate, yet most of the existing geometric algorithms are unable to cope with any data uncertainty in relating their output to their input.<br\/><br\/>The project aims to fill this void by investigating uncertainty-aware geometric computing, with an express goal of designing algorithmic techniques and foundations that will help extract ``knowledge'' from large quantities of geometric data in the presence of various non-idealities and uncertainties. It focuses on a number of fundamental geometric problems, all dealing with uncertain data. A unified set of models will be developed for modeling uncertainty that can deal with multiple uncertainty types, and attention will be paid to handling noise\/outliers in heterogeneous and dynamic data. Algorithms will be investigated for understanding how input uncertainty carries over to output uncertainty (e.g. by associating a confidence level or likelihood with each output, or computing certain statistics of the output) and how the input uncertainty impacts the quality of the output (e.g. by defining and computing the stability of the output in terms of the input uncertainty). Since exact solutions are likely to be computationally infeasible, the emphasis will be on simple, efficient approximation techniques (e.g. computing a compact, approximate distribution of geometric\/topological structures such as Delaunay triangulations and their subcomplexes of uncertain data).<br\/><br\/>A key ingredient of the award is to address a variety of computational issues that arise in the presence of uncertainty using a few key problems, and to develop a core set of techniques that illuminate algorithmic design under uncertainty not only on these key problems but that can also be transferred to other geometric problems, as needed. This research touches upon many topics in theoretical computer science and applied mathematics including discrete and computational geometry, discrete and continuous optimization, estimation theory, and machine learning. This study will strengthen connections of computational geometry with a variety of disciplines, including machine learning, probabilistic databases, statistics, and GIS. Since so many problems require geometric data analysis, the project has the potential of enhancing the capability of various government, commercial, and civic units to make informed decisions that impact the society at large.","title":"AF:Medium:Collaborative Research: Uncertainty Aware Geometric Computing","awardID":"1161359","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["554177"],"PO":["565157"]},"189579":{"abstract":"While races in multithreaded programs have drawn huge attention from the<br\/>research community, little has been done for API races, a class<br\/>of errors as dangerous and as difficult to debug as traditional thread<br\/>races. An API race occurs when multiple activities, whether they be<br\/>threads or processes, access a shared resource via an application<br\/>programming interface (API) without proper synchronization. Detecting<br\/>API races is an important and difficult problem as existing race<br\/>detectors are unlikely to work well with API races. <br\/><br\/>Software reliability increasingly affects everyone, whether or not<br\/>they personally use computers. This research studies and<br\/>automatically detects for the first time an important class of races<br\/>that has a significant impact on software reliability. The study<br\/>quantitatively demonstrates how API races are numerous, difficult to<br\/>debug, and a real threat to software reliability. To address this<br\/>problem, this research is developing RacePro, a new system to<br\/>automatically detect API races in deployed systems. RacePro checks<br\/>deployed systems in-vivo by recording live executions then<br\/>deterministically replay and check them later. This approach<br\/>increases checking coverage beyond the configurations or executions<br\/>covered by software vendors or beta testing sites. RacePro records<br\/>multiple processes and threads, detects races in the recording among <br\/>API methods that may concurrently access shared objects, then explores<br\/>different execution orderings of such API methods to determine which races<br\/>are harmful and result in failures. Technologies developed will help<br\/>application developers detect insidious software defects, enabling <br\/>more robust, reliable, and secure software infrastructure.","title":"SHF: Medium: RacePro: Automatically Detecting API Races in Deployed Systems","awardID":"1162021","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["508477",508314],"PO":["565264"]},"199149":{"abstract":"The main objective of the proposed research project is to develop holistic approaches to the design of power optimization strategies for heterogeneous cloud computing environment. The focus will be on exploring the tradeoffs among the cloud computing physical infrastructure, including power-managed servers and cooling technology, virtualized infrastructure, and the middleware and service infrastructure. Contrary to cross-layer designs for energy optimization, where solutions are obtained through piecemeal approaches, the layered architecture is used to cast cloud computing energy optimization as an extended monotropic programming problem and derive a systematic analysis and design of global energy optimization strategies, whereby energy policy at a given layer uses subsets of the decision variables to achieve individual optimality and reduce the impact of carbon footprint on the environment. The research project provides a unique opportunity for graduate and undergraduate students to gain deep understanding of the basic science and engineering design principles of cloud computing and energy consumption in data centers. The outreach plan builds on existing minority and under-represented programs at the University of Pittsburgh to recruit and retain a diverse population of undergraduate and graduate students, and also seeks to establish collaborations with industrial institutions to leverage their educational programs and cloud infrastructure to advance the research project agenda.","title":"EAGER: A Framework for joint optimization of power management and performance in virtualized, heterogeneous cloud computing environments","awardID":"1253218","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["194325",534213],"PO":["565255"]},"194870":{"abstract":"Proposal #: 12-29316<br\/>PI(s): Katti, Dinesh R; Denton, Anne M; Khan, Samee U; Ossowski, Martin M; Sun, Wenfang;<br\/>Institution: North Dakota State University Fargo<br\/>Title: MRI\/Acq.: Data-Intensive Cyberinfrastructure for Research and Education (DICRE) at NDStU <br\/><br\/>Project Proposed:<br\/>This project from an EPSCoR state, acquiring a storage-heavy Beowulf cluster with an HDD storage appliance and a tape storage subsystem for archival purposes, enables a variety of research projects in experimental HPC and applications in bioinformatics, data-aware materials modeling, and others, all of which will both increase the institution?s resources for scientific computing and build a dataset to assist their HPC research projects. Within the state and beyond, the proposed instrument is expected to break barriers to research in the areas of computational materials science and chemistry, computational mechanics and biomechanics, data informatics, and data-aware scalable computational sciences where ?big-data? increasingly complicates traditional computational workflows and paradigms.<br\/><br\/>Broader Impacts: <br\/>Due to a convincing educational and outreach plans, as well as expected scientific discoveries in the areas of science proposed, the proposal showcases strong broader impacts. The programs to enrich broader impact aspects will not only be felt locally, but will also help ensure that the nation maintains leadership and innovation within the addressed research domains.","title":"MRI: Acquisition of Data-Intensive Cyberinfrastructure for Research and Education (DICRE) at North Dakota State University","awardID":"1229316","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[522177,522178,"543472",522180,522181],"PO":["557609"]},"200667":{"abstract":"Online Service Providers (OSPs) host a wide range of application services, including email, Web search, video streaming, and multiplayer games, on servers in data centers all over the world. Each service has specific performance requirements. For example, Web search and multiplayer games need low latency, whereas video streaming and bulk file transfers need high throughput. Clients access these services from a wide variety of geographic locations over access networks with wildly different performance. Offering good performance to these diverse clients at a reasonable cost is the life blood of any OSP.<br\/><br\/>OSPs affect client performance by controlling content routing (selecting which data center should serve a client request) and network routing (selecting interdomain paths to clients, or paths within the OSP's own backbone), and by longer-term planning of future data centers and relationships with upstream ISPs. Unfortunately, OSPs have relatively poor visibility into end-to-end performance and do not adapt both content and network routing to maximize performance; in addition, OSP operators lack good models for deciding where to place the next server or data center, or which ISPs to select as neighbors.<br\/><br\/>To address the wide-area networking needs of online services, this project is designing, implementing, deploying, and evaluating practical techniques that allow OSPs to perform content and network routing (and make longer-term placement decisions), based on timely and accurate information about end-to-end performance and transit costs. The project is developing techniques to help OSP operators measure, control, and plan the wide-area connectivity between distributed services and their clients, and between the servers themselves. The project tasks include: (1) designing performance-measurement techniques and conduct measurement-driven studies of OSP traffic management; (2) designing, modeling, and prototyping protocols for joint optimization of content and network routing, and traffic management within an OSP backbone; and (3) driving long-term planning of server placement and ISP peer selection based on models of transit costs.<br\/><br\/>To evaluate our algorithms together, and \"in the wild\", the project will use experimental platforms for network monitoring (BISmark, M-Lab, and, where available, measurement servers in ISP backbone networks), content and network routing (DONAR and Transit Portal), cloud computing (VICCI), and programmable networking (OpenFlow). <br\/><br\/>Broader Impact:<br\/>The PIs are working with industry to evaluate and deploy the solutions on operational networks. They will also continue their close collaboration on graduate networking curriculum development to include the research topics and experimental platforms in this project. As part of the project outreach, the PIs are organizing \"summer camps\" (drawing on their earlier experiences with summer camps for the VINI and BISmark projects) to bring under-represented students to their institutions for summer internships. The PIs will also work with under-represented regions and institutions to deploy their infrastructure and engage faculty and students in research projects using the platforms.","title":"NeTS: Medium: Collaborative Research: Optimizing Network Support for Cloud Services: From Short-Term Measurements to Long-Term Planning","awardID":"1261357","effectiveDate":"2012-09-01","expirationDate":"2016-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["561756"],"PO":["564993"]},"194760":{"abstract":"Access control schemes are traditionally compared in terms of raw expressive power (i.e., the policies they can encode and how those policies can be changed); however, such comparisons ignore the needs of the application within which a scheme will be deployed. For some applications, the most expressive scheme may be overly complex and not necessarily the best fit. To this end, this project investigates the suitability analysis problem: Given a system's access control workload, a set of candidate access control schemes, and a set of application-specific cost metrics, which scheme best meets the needs of the system?<br\/><br\/>The goal is to create a suitability-analysis framework that is sufficiently rigorous to be useful to researchers and theoreticians, while remaining accessible to security practitioners. Such a framework will help formalize an access control scheme's application-specific strengths and limitations, enable researchers to precisely describe the scenarios for which a scheme is best suited, allow assessment of the novelty and utility of proposed schemes, and help analysts diagnose shortcomings in existing systems. In particular, the project will develop (1) an application-specific, workload-based framework for analyzing the suitability of access control schemes that is sufficiently rich to compare logical, extensional, and hybrid schemes in both sequential and concurrent systems; (2) a cost analysis component that quantifies a scheme's suitability using custom metrics; and (3) tools that automate a range of suitability analysis tasks. A real-world security workload, PKI-based authentication and authorization on the web, will be used to evaluate the results.","title":"TWC: Medium: Collaborative: Foundations of Application-Sensitive Access Control Evaluation","awardID":"1228947","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["362818","362818",521710],"PO":["562974"]},"193671":{"abstract":"This project addresses the next major impediment to the continued adoption<br\/>of \"big-data\" analytics---the management of their life cycle, which<br\/>includes debugging, tuning, and auditing. Today, data-intensive analytics<br\/>are improving operations across multiple industries, translating terabytes<br\/>of raw data into useful data analysis. Taking advantage of big data will<br\/>be necessary to sustain competitive advantages for areas ranging from power<br\/>generation, to retail, oil exploration, manufacturing, various scientific<br\/>disciplines, and national security. However, the extreme scalability of<br\/>these data processing architectures hides inefficiencies and obfuscates<br\/>performance analysis, creating both obvious and hidden costs to their<br\/>adoption. Tuning and debugging large data-intensive workflows is currently<br\/>a black art that mostly consists of tedious manual analysis.<br\/><br\/>The research seeks to dramatically alter how data scientists design and<br\/>debug their analytics to sidestep this authoring and deployment bottleneck.<br\/>In particular, the PI's are developing scalable, efficient architectures<br\/>for capturing fine-grain data lineage, information that tracks the use of<br\/>data through the analytic pipeline, from a range of data-intensive scalable<br\/>computing (DISC) systems. Such lineage serves as a basis for discovering<br\/>inefficiencies and suggesting optimizations via step-wise debugging, fault<br\/>tracing, anomaly detection, and lineage-driven data cleaning and data<br\/>mining. The development and open-source release of such lineage-capture<br\/>and analysis platforms promises to dramatically accelerate the adoption of<br\/>big-data analytics.","title":"CSR: Small: Scalable Fine-Grain Lineage for Debugging Data-Intensive Workflows","awardID":"1219220","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["518658",518657,518658],"PO":["565255"]},"191493":{"abstract":"This project, developing a systematic methodology for the design of multi-fingered robotic hands and grasping devices for a desired kinematic task, represents a novel formalization of the kinematic synthesis of articulated systems as a tree structure. The kinematic task is to be defined as positions and higher motion derivatives of the fingers, with accelerations related to the contact geometry at the fingertips for grasping actions. This research team aims to develop multi-fingered grasping devices for human-robot and anthropomorphic tasks, however the method will be a general tool for the design of any kind of multiple-finger grasping device. <br\/><br\/>This research has a number of broader impacts affecting both the academic community and society at large. First, the project will directly result in a design tool for multi-fingered robotic hands to enable the automatic transformation from task specifications to design alternatives ? an important development in its own right. This design tool will increase the ability of industry to design high performance, cost-effective multi-fingered robotic hands and other end effectors. This directly impacts manufacturing by speeding the development of end-of-arm tooling, with secondary benefits to the cost and quality of the final product. This will assist the U.S. to maintain its leadership and encourage the creation of high-quality jobs. The proposed curriculum additions resulting from this project will produce competent engineers for industry with a greater ability of approaching and solving design problems.","title":"NRI-Small: Collaborative Research: A Design Methodology for Multi-fingered Robotic Hands with Second-order Kinematic Constraints","awardID":"1208412","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":["561764",513260],"PO":["564069"]},"193561":{"abstract":"Though many children use mobile applications to support their learning and entertainment, the devices and underlying interactions were not designed specifically for children. The goal of this project is to make touch and gesture interactions more accessible and user-friendly to young users. This research will yield new understanding about the appropriate and successful ways to sense, recognize, and recover from errors in touch-based interactions with children. The approach involves studying children interacting with mobile applications that gather data on their touch and gesture interactions, as well as conducting design sessions with children to elicit their preferences for mobile device interactions and error feedback and recovery strategies. This approach will result in design guidelines for those creating applications and tools for young users. The proposed research contributes towards the evolution of alternative interaction technologies such as touch and gesture, and the understanding of child-computer interaction with new gesture-based technologies. <br\/><br\/>Broader impacts: The broader impacts of this project lie in contributions towards the evolution of alternative interaction technologies such as touch and gesture, and the understanding of child-computer interaction with new gesture-based technologies. This work also will develop and validate an approach for investigating such interaction issues and designing improvements for them that can be used in future work with other populations such as older individuals or those with varying physical abilities. The grant will support two female young investigators, and will fund research experiences to benefit computer science students attending Bowie State University, a minority serving institution.","title":"HCC: Small: Collaborative Research: RUI: Mobile Gesture Interaction for Kids: Sensing, Recognition, and Error Recovery","awardID":"1218664","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[518395,"526653"],"PO":["565227"]},"193451":{"abstract":"There is increasing demand to deploy web applications across multiple data<br\/>centers to improve fault tolerance and reduce network delays to<br\/>users. As application servers need to share data, their<br\/>construction can be significantly simplified if a storage backend exists for<br\/>applications to seamlessly access replicated data at different data centers.<br\/><br\/>A geo-replicated storage system faces the unpleasant tradeoff of consistency<br\/>vs. performance because of large inter-data-center communication delay. This<br\/>proposal investigates novel consistency and programming models for<br\/>geo-replicated storage that are easy-to-use and can achieve good performance.<br\/>In particular, this project proposes parallel snapshot isolation, a novel <br\/>consistency model that enables efficient implementation with minimal<br\/>coordination across data centers. Parallel snapshot isolation provides much<br\/>stronger guarantees than existing weak consistency models by disallowing<br\/>write-write conflicts and preserving the causality of operations. The PI<br\/>builds Walter, a geo-replicated transactional key-value store that guarantees<br\/>parallel snapshot isolation. A number of common web applications are written<br\/>on top of Walter and evaluations demonstrate that the new consistency model is<br\/>easy to program for and enables applications to achieve high performance. The<br\/>success of this project will bring much improvement to the state-of-art in<br\/>writing scalable and fault tolerant web applications.","title":"CSR: Small: Practical Geo-Replicated Storage for Web Applications","awardID":"1218117","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[518136],"PO":["565255"]},"193572":{"abstract":"Object categorization and segmentation are arguably among the most important and challenging problems in computer vision. While these two problems are clearly related, most of the existing literature treats these tasks separately. This project bridges this gap by developing algorithms for joint categorization and segmentation of objects, which simultaneously use category-level information (top-down) and pixel-level information (bottom-up). This project develops a novel graph-theoretic paradigm that combines principles from conditional random fields and sparse representation theory. In this framework, each semantic region is represented in terms of an over-complete dictionary of objects, object parts, subparts and superpixels. To simultaneously estimate both the segmentation and a sparse representation for each region, the research team defines an energy function for the random field, which includes new higher order potentials obtained as the output of a classifier applied to the sparse representation of a segmented region. The research team also explores methods based on structured-sparse dictionary learning and latent support vector machines for learning the dictionaries and the classifier parameters. Furthermore, the research team investigates efficient discrete optimization techniques for minimizing the new energies resulting from the combination of structured-sparse models with different classifiers.<br\/><br\/>Applications of this research include image search, autonomous navigation (localization and identification of the road, street signs, pedestrians and vehicles), medical diagnostic tools (detection, localization and classification of lesions and tumors in medical images), surveillance (localization of suspicious people, weapons and vehicles) and robotics (identifying the boundaries and extent of objects to be interacted with). The project involves students of different levels.","title":"RI: Small: Structured Sparse Conditional Random Fields Models for Joint Categorization and Segmentation of Objects.","awardID":"1218709","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["555788"],"PO":["564316"]},"193594":{"abstract":"With the development of low cost, high endurance uninhabited vehicles, it is now possible to acquire imaging data persistently over long periods of time and space using multiple distributed sensors. Such persistent multi-pass sensing systems have several advantages over single-pass systems including the ability to monitor a dynamic medium, wider spatial coverage, increased resolution and the ability to acquire three or higher dimensional information. While such persistent systems have the potential to revolutionize sensing and imaging across many domains of applications, one of the fundamental bottlenecks for the deployment of these systems is the challenges in image formation: First, the reconstructions of 3D deformations, velocity fields and imaging in unknown complex environments are highly non-linear large scale inverse problems. Secondly, such systems can acquire hundreds of terabytes of data daily and forming a standard image using even a single-pass data cannot currently be done in real-time.<br\/><br\/>This project develops a unified mathematical framework and new classes of novel, computationally efficient analytic image reconstruction methods to address these large scale, computationally demanding, non-linear inverse problems. Central to our development is the synergistic combination of inverse scattering theory, sparse signal recovery methods and microlocal analysis. Our research involves the following topics: (i) Development of accurate forward models for 3D deformation-rate imaging, velocity imaging and imaging in unknown heterogenous environments using multiple sensors. (ii) Reformulation of the resulting nonlinear problems as linear problems by embedding them into larger dimensional spaces coupled with sparsity constraints. (iii) Design of analytic, computationally efficient methods for inversion by synergistically combining ideas from microlocal analysis and sparse signal recovery methods.","title":"CIF: Small: Computationally Efficient Analytic Reconstructions via Embeddings and Sparsity for Non-Linear Dynamic Imaging Problems","awardID":"1218805","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[518474],"PO":["564898"]},"193242":{"abstract":"Socio-technical systems provide access to ever-increasing quantities of information online. To help people cope with information overload, these systems implement \"algorithmic curation\": automated selection of what content should be displayed to users, what should be hidden, and how it should be presented. Virtually every Internet user who reads online news, visits social media sites, or uses a search engine has encountered algorithmic curation at some point, probably without even realizing it. In a socio-technical system, user contributions, social relationships and behavior, and features of the technology are interdependent, and determine what the system is used for, how it is used, and how it evolves over time. The goal of this research project is to investigate the relationship between social behavior and algorithmic curation, in order to better predict the effects of this pervasive practice on what we read, contribute, and communicate about online.<br\/><br\/>This project uses a multi-method approach to identify ways in which social and technical mechanisms influence individual users' information production and consumption, and thereby shape system-level properties of the user population and the corpus of contributions. Lab experiments investigate how social processes, such as obeying social norms and altering communications for an intended audience, are affected by different types of algorithmic curation. Field studies augment the lab experiments, using technology interventions to demonstrate how these changes play out for people in the real world over time, and as algorithms change. At the system level, agent-based models connect individual-level processes with system-level effects of algorithmic curation, and large-scale data collection looks for signs of those effects on real systems.<br\/><br\/>This project advances the current understanding of forces that shape information access and use in an increasingly connected and automated environment. Results will be used to provide guidance to system designers who create and manipulate algorithms, in the form of design patterns that will support a systematic, generalizable way of planning for effects of algorithmic curation at different scales. The project Web site (http:\/\/bitlab.cas.msu.edu\/curation) provides information. Undergraduate and graduate students involved in the project will become better problem solvers, and work effectively on collaborative interdisciplinary projects.","title":"III: HCC: Small: Effects of Automated Information Selection and Presentation in Online Information Systems","awardID":"1217212","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[517650],"PO":["563751"]},"193374":{"abstract":"In many large economic markets, goods are sold through auctions. Examples include eBay, wireless spectrum auctions, the New York Stock Exchange, and the Dutch flower auctions. This project focuses on one particular real-world auction domain: the Dutch flower auctions (DFA). The project will perform an in-depth analysis of this domain both from the point of view of the bidders and from the point of view of the auctioneers.<br\/><br\/>This project involves several component tasks. (1) Creation of a configurable auction server, comprised of basic auction building blocks, like simultaneous and sequential auctions, and sealed-bid, ascending, and descending auctions. (2) Construction of an interactive DFA simulation using the configurable auction server that is capable of handling decisions made by both human bidders and autonomous agents; this simulation will model DFA bidder preferences, which will be learned automatically using inverse reinforcement learning techniques from historical data and manually by surveying and interviewing DFA experts. (3) Creation of autonomous DFA bidding agents and comparison of their performance to that of expert human DFA bidders using the interactive simulation. (4) Further simulation of these agents to empirically find game-theoretic equilibria under various settings of the auction parameters so that those parameters can be optimized. The project will also develop a prototype of a mixed-initiative system that can be used to assist DFA bidders.<br\/><br\/>Potential broader impacts of this research include increased knowledge and understanding of how to design and implement artificially intelligent agents that can effectively assist humans with their decision-making efforts, particularly in information-rich and time-critical environments. Although this project focuses on DFA-type auctions, methodologies developed here will transfer to other domains that use auction mechanisms, such as automated bidding for resource allocation in smart grids. Detailed focus on the DFA provides a concrete starting point for the study of various auction-related topics, for instance, how to build mixed-initiative decision support tools to improve the quality of bidding practices, rigorous comparison of various auction mechanisms and parameter choices, and advancing bidding agent design from a heuristic approach to one that is theoretically grounded.<br\/><br\/>The project research team includes both graduate and undergraduate students whose participation in this research will strengthen their understanding of the various fields that are critical to the development of decision support systems (e.g., autonomous agents, preference elicitation and representation, machine learning, software engineering) and provide them experience collaborating across disciplines, and working on a real-world application. In addition, there are plans to develop introductory lessons on the general topic of autonomous bidding agents for use in the Artemis project, a five week summer program in which female rising ninth graders are exposed to the breadth of applications of computer science, and are introduced to a variety of technologies underlying computing.","title":"RI: Small: Agent-Assisted Trading in Real-World Auctions","awardID":"1217761","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[517963],"PO":["565035"]},"193495":{"abstract":"Applications as diverse as manufacturing, medicine, earth science, finance, and entomology generate massive amounts of temporal or spatio-temporal data. More specifically, information about moving objects, events, and atmospheric measurements that are geo-referenced may be derived from high-resolution satellites, sensors, ground and aerial imagery, GPS, and RFID. Such data present challenges to current approaches for mining time series data. For example, shape-based similarity measures used for classification and clustering consistently fail to produce satisfactory results for long sequences, or trajectories modeling objects that move in 2D or 3D space which may often exhibit similar motion patterns but differ in locations and orientations. In addition, algorithms for finding frequent patterns and anomalies assume known, fixed pattern lengths. This project aims to address the limitations of current approaches to time series data analysis by adapting statistical language processing algorithms and approaches. Specifically, fast algorithms for learning context-free grammars can expose hierarchical structure in time series and thus enable efficient discovery of variable length patterns and facilitate human understanding of time series structure. Also, using the hierarchy to populate a \"bag of patterns\" can result in significantly more effective similarity measures for long time series, much like the familiar bag of words representation used with documents is effective for a variety of similarity-based language processing tasks on massive corpora.<br\/><br\/>Given the ubiquitous nature of time series data, advances in algorithms that can help uncover the structure of such data are likely to impact a broad range of applications. All of the results of this research, including publications, algorithms and software, would be made freely available to the broader research and educational community. The project offers enhanced research-based training opportunities for graduate and undergraduate students. The project leverages existing programs at George Mason University and the University of Maryland at Baltimore County to to increase the participation of women members of other groups that are under-represented in Computer Science.","title":"III: Small: Collaborative Research: Finding and Exploiting Hierarchical Structure in Time Series Using Statistical Language Processing Methods","awardID":"1218325","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[518241],"PO":["565136"]},"193264":{"abstract":"In this project, the PI is developing theoretical foundations for performing iterative computations on massive data in a distributed environment. Based on the developed theory, the PI aims to build highly scalable and efficient distributed frameworks for iterative computations. The distributed framework takes the burden of describing the iterative process away from programmers and performs the iterative updates in an efficient manner. A series of programming models will be developed aiming to challenge the conventional wisdom that synchronization is essential and iterative computations have to be performed in an ?iteration by iteration? manner. The goal of these proposed programming models and supporting distributed frameworks is to lift the burden of the programmers in specifying execution order of iterative updates and communication mechanisms, and automatically optimize the execution of the computation in a cluster of machines. <br\/><br\/>The technologies developed in this project will have immediate important applications with broader societal impacts such as road traffic prediction, biological information discovery, online marketing, and computer forensic analysis.","title":"CSR: Small: Theoretical Foundations and Distributed Frameworks for Iterative Computations on Massive Data","awardID":"1217284","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["564706"],"PO":["565255"]},"193396":{"abstract":"Pattern classification is a fundamental problem in a vast number of applications, ranging from detection of abnormal heartbeats in cardiac patients, to identification of defective chips in microchip manufacturing, to classification of nuclear sources in nonproliferation tasks. The conventional approach to designing classifiers is to leverage training data comprised of labeled examples of the different object classes under consideration. However, a fundamental assumption of standard approaches is that training data are representative of future observations to which the classifier will be applied. In a growing number of applications, including those mentioned above, this assumption cannot be justified because of subject-to-subject variability arising from biological, technological, or environmental factors. In response, this research is developing new fundamental approaches to classification and prediction that adapt trained classifiers to the characteristics of future patterns.<br\/><br\/>In particular, this research develops a theoretical and algorithmic framework for distribution-adaptive prediction and classification. A critical feature of the framework is the use of distributions as predictive features. Several statistical learning problems are studied that incorporate distributions as features; some are generalizations of existing learning problems, while others are new and uniquely motivated by distribution-adaptive problems. General solutions are developed to these problems using the framework of complexity regularization over a reproducing kernel Hilbert space. Methodological contributions include novel kernels on distributions and new methods of generalization error analysis. The work is concretely motivated by and evaluated in diagnostic applications of flow cytometry, a high-throughput assay for cellular analysis used in the study of blood-related diseases. The research component is complemented by educational initiatives involving graduate, undergraduate, and high school students.","title":"CIF: Small: Distribution-Adaptive Prediction and Classification","awardID":"1217880","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[518010,518011],"PO":["564898"]},"193286":{"abstract":"This research introduces novel recharging systems and algorithms to supplement existing systems and lead to autonomous, sustainable energy management on sensor networks. Applications such as bridge fault detection that rely on sensor networks operating away from buildings often lack energy for long-term monitoring. In these scenarios traditional recharging methods (e.g. solar panels) are unavailable or cannot provide sufficient energy (e.g. at night). To achieve this, the research has three key components. The first component develops an unmanned aerial vehicle (UAV) to wirelessly recharge sensor nodes, a localization system based on magnetic field intensity, and autonomous control algorithms that optimize power transfer. Based on this system, the second part develops online algorithms for UAV trajectory optimization in systems with multiple UAVs as well as distributed algorithms that induce energy deficits in a subset of nodes to enable efficient recharging. Finally, the third component provides models and distributed algorithms to predict future energy recharging and usage for sensor nodes.<br\/><br\/>This research impacts a range of societal, educational, and scientific topics. This project addresses a critical national need of enabling regular monitoring of bridge integrity through autonomous, energy efficient sensor network and robot systems. Improving bridge fault detection is necessary given aging infrastructure and limited local budgets for performing such work through current manual visual inspection processes. Educationally, at the K-12 level, this provides demos and workshops to enhance existing programs, encouraging young students (especially women) to pursue STEM fields.","title":"CSR: Small: Collaborative Research: Adaptive and Autonomous Energy Management on a Sensor Network Using Aerial Robots","awardID":"1217400","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[517754],"PO":["564778"]},"194023":{"abstract":"The most fundamental service for the delivery of data on the Internet is routing, the task of computing the path that messages must follow in order to go between networks that are not directly connected. While a large body of work has studied the task of ensuring that these paths are computed correctly, surprisingly little work has been done to study the behavior, when under attack, of the system of computers, software and protocols that compute these paths, what we call the routing system. <br\/><br\/>This project is investigating the resilience of the Internet routing system to attacks that induce \"churn\" by forcing programs or computers to (temporarily) stop participating in the routing system. The project is devising experiments and simulations that will allow the development of mathematical models that can measure the vulnerability of the routing system to \"cascading failures,\" caused by resource depletion, software faults, and protocol errors, that cause the entire routing system to become unavailable. The project is also developing methods to mitigate the effects of these attacks.<br\/><br\/>The project is expected to result in new data, models, and software that can be used by the community to evaluate and improve the behavior of the current routing system and proposed \"future Internet\" designs under destabilizing attacks, positively impacting the safety and economic health of the United States and other nations.","title":"TWC: Small: Measuring and improving BGP churn resilience","awardID":"1223421","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["548224"],"PO":["565327"]},"198500":{"abstract":"This project will deploy a pilot OpenFlow network (a form of Software-Defined Network [SDN]) for the Computer Science and the Physics and Astronomy buildings at the University of Washington. This capability will enable high-performance layer-2 connections to the desktop for both GENI experimentation and for high performance computing applications. The project will provide an opportunity to develop an operational model for the innovations promised by OpenFlow and advance the understanding of how to integrate OpenFlow into campus networking infrastructures. Travel budget is included for sharing and presentations of findings to the broad GENI community and non-technical user communities.<br\/><br\/>Although OpenFlow is currently being widely discussed and are key elements in the GENI architecture, there is little operational or campus-level architectural experience with using it. In particular, the integration of OpenFlow and other SDN technology into science DMZs and other issues of campus security and policy are not fully understood in operational contexts. The project outcomes include reporting of results and lessons to other campus network operators and to SDN researchers and industry.<br\/><br\/>Broader Impact:<br\/>OpenFlow and other software defined networking approaches have the potential to transform highcapacity data transfer and networking in our emerging world of data-driven discovery. The UW's OpenFlow proposed deployment, along with the commitment of a full-time engineer devoted to managing the facility in an operational network setting, will advance our understanding of these methodologies and serve to inform our broader campus-wide network planning and deployment efforts prospectively. The University of Washington will share data from these pilot deployments with both the University of Washington research community and more broadly with the Research and Education Network Community, including at one NSF sponsored conference for such purposes.","title":"EAGER: University of Washington (UW) Openflow Research","awardID":"1249362","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["549890",532616],"PO":["564993"]},"199952":{"abstract":"This project is to support two meetings sponsored by the High Confidence Software and Systems (HCSS) Coordinating Group (CG)of the Networking and Information Technology Research and Development (NITRD) Program, the Nation's primary source of Federally funded revolutionary breakthroughs in advanced information technologies such as computing, networking, and software. The two meetings are the 2012 National Workshop on the New Clockwork for Time-Critical Systems, which is scheduled for October 25-27, 2012 at the Hyatt Regency Baltimore Inner Harbor in Baltimore, Maryland, and the 2012 CPS Education Workshop Planning Meeting, which is scheduled for October 24, 2012 at the Royal Sonesta Harbor Court Baltimore, also in Baltimore, Maryland. The objective of the New Clockwork workshop is to define a list of needs for research on time-critical aspects of cyber-physical systems so that future research can develop robust foundations for reasoning about time in cyber-physical systems across scales, managing resources to meet timeliness requirements, and ensuring service agreements through new tools, techniques and methodologies. The workshop will be structured as a sequence of panels, presentations and breakout sessions. The workshop will produce a report for the HCSS agencies. The objective of the CPS Education Planning Meeting is to lay groundwork for a workshop that would perform a similar analysis of future educational needs and directions in support of high confidence cyber-physical systems. Both meetings will include participation by invited researchers and representatives from Government and industry.","title":"2012 National Workshops on the New Clockwork for Time-Critical Systems- October 24, 2012, Baltimore, Maryland and October 25-27, 2012, Baltimore, Maryland","awardID":"1257344","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"L509","name":"National Security Agency"}}],"PIcoPI":["564429","564430"],"PO":["564778"]},"194035":{"abstract":"This project brings together computer scientists, social scientists, and other stakeholders in an attempt to integrate social sciences into the design of future cyber security mechanisms and systems. The workshop fosters the development of new models of and paradigms for cyber security, and will lead to the development of communities of researchers who today do not interact, but whose cooperative work is necessary for the development of cyber security mechanisms and systems. It will also produce a research agenda in economics and other social sciences related to cyber security that addresses user, economic, and sociopolitical realities. <br\/><br\/>Established economists will interact with computer scientists who believe that a better alignment of incentives is necessary in order to produce more secure systems. Established social scientists will interact with computer scientists and others who believe that advanced technological security systems must also satisfy non-technological constraints (such as easy to use human-computer interfaces and societal acceptability) in order to be effectively used to provide more secure computer systems. <br\/><br\/>This workshop will generate interdisciplinary dialogue among experts in cyber security, computer science, economics, business, government, and public policy. It will catalyze and inform new scholarship on the economic impact and effectiveness of global and national cyber security policies using social sciences perspectives and expertise. <br\/><br\/>By highlighting where current marketplace and other incentives fail and building on the tools from economics and other social sciences to address these issues, this work could lead to the development of actual, working incentives for building cyber security into systems -- rather than the much less effective and much more prevalent security mechanisms that have been added to existing systems. Armed with these results, designers of cyber security systems in mobile, desktop, and network environments will be able to develop more effective mechanisms to solve or mitigate cyber security problems. <br\/><br\/>Cyber security may present challenges for existing social science theories, since cyber security has global and digital underlying problems, rapidly changing and sometimes unidentifiable actors, and accountability difficulties. Thus, this workshop may lead to the refinement of existing theories. Adapting previous work in the social sciences may inform changes in the architecture and design of hardware and software to ameliorate cyber security problems in the future. Clearer understanding of incentive mechanisms to design cyber security systems will encourage the production of more secure systems in the future, thus promoting the progress of science and advancing national defense and international welfare by having more secure systems in place.","title":"SBES: Small: Cyber Security Workshops for Social Science Researchers","awardID":"1223630","effectiveDate":"2012-09-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["529428"],"PO":["550223"]},"193188":{"abstract":"This project takes an ethnographic and design-based approach to understanding how and what people learn from participation in makerspaces and explores the features of those environments that can be leveraged to better promote learning. Makerspaces are physical locations where people (often families) get together to make things. Some participants learn substantial amounts of STEM content and practices as they design, build, and iteratively refine working devices. Others, however, simply take a trial and error approach. Research explores the affordances are of these spaces for promoting learning and how to integrate technology into these spaces so that they are transformed from being makerspaces where learning happens, but inconsistently, into environments where learning is a consistent outcome of participation. One aim is to learn how to effectively design such spaces so that participants are encouraged and helped to become intentional, reflective makers rather than simply tinkerers. Research will also advance what is known about effective studio teaching and learning and advance understanding of how to support youth to help them become competent, creative, and reflective producers with technology(s). The project builds on the Studio Thinking Framework and what is known about development of meta-representational competence. The foundations of these frameworks are in Lave and Wengers communities of practice and Rogoff's, Stevens et al.'s, and Jenkins et al.'s further work on participatory cultures for social networks that revolve around production. A sociocultural approach is taken that seeks to understand the relationships between space, participants, and technologies as participants set and work toward achieving goals.<br\/><br\/>Engaging more of our young population in scientific and technological thinking and learning and broadening participation in the STEM workplace are national imperatives. One way to address these imperatives is to engage the passions of young people, helping them recognize the roles STEM content and practices play in achieving their own personal goals. Maker spaces are neighborhood spaces that are arising in many urban areas that allow and promote tinkering, designing, and construction using real materials, sometimes quite sophisticated ones. Participating in designing and successfully building working devices in such spaces can promote STEM learning, confidence and competence in one's ability to solve problems, and positive attitudes towards engineering, science, and math (among other things). The goal in this project is to learn how to design these spaces and integrate learning technologies so that learning happens more consistently (along with tinkering and making) and especially so that they are accessible and inviting to those who might not normally participate in these spaces. The work of this project is happening in an urban setting and with at-risk children, and a special effort is being made to accommodate making and learning with peers. As with Computer Clubhouses, maker spaces hold potential for their participants to identify what is interesting to them at the same time their participation gives them the opportunity to express themselves, learn STEM content, and put it to use.","title":"EXP: Learning in the Making: Studying and Designing Makerspaces","awardID":"1216994","effectiveDate":"2012-09-01","expirationDate":"2015-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7625","name":"REESE"}}],"PIcoPI":[517511,517512],"PO":["562669"]},"198754":{"abstract":"This project examines user-generated content (UGC) in interactive media, in order to improve the functioning of copyright law with respect to important areas of computer software and online communications. UGC is currently generating interest among businesses, researchers, scholars, and game software designers. In recent years, increasingly powerful, simple, and cheap digital authoring tools have extended the power of amateur creativity. This project will provide: (1) a new structural theoretical framework for the analysis of UGC in games, (2) new empirical data on UGC in computer games, and (3) a legal analysis of the applicability of copyright's \"fair use\" doctrine to UGC in games.<br\/><br\/>Videogames are a new form of interactive media often combine traditional media forms with software interfaces that enable forms of player authorship. Content authored by players has the potential to infringe copyright law. While copyright infringement lawsuits have been filed based on UGC technologies, there have been few empirical studies of interactive media technologies that depend on UGC. Additionally, very few legal or media theorists have provided analytical structures that can be used to explore the complex relationship between player authorship and traditional authorship in the video game industry. <br\/><br\/>This project endeavors to map the intersection between copyright law and UGC authorship in video games. The payoff of this research will be to provide additional insight to the market, to help ensure the development of important emerging technologies, and to contribute to the contemporary debate over appropriate legal rules for the interactive media industry. The data collected and the theoretical framework developed will aid those researching interactive media in speaking about evaluating tools for user-generated content in games and other interactive media, and clarify the legal constraints on game software design.<br\/><br\/>This research will provide data on how interactive media technologies facilitate creativity, thereby helping policy makers and technologists understand how user-generated content intersects with new media forms. Additionally, by analyzing the legality of user-generated content, this research will aid policy makers and technologists in efforts to reform copyright law to take into account new forms of authorship.","title":"EAGER: A Legal and Structural Investigation of Online User-Generated Content Systems","awardID":"1250774","effectiveDate":"2012-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[533233],"PO":["564456"]},"195256":{"abstract":"The importance of sleep to human health and well-being has long been recognized. Contemporary research emphasizes two central processes by which sleep affects our daily lives: Memory-consolidation and emotional regulation. However, the ability of lab-based sleep research to fully characterize the role of sleep in brain function has been hampered by experimental requirements that heretofore have necessitated subjects spending a night or two in a sleep lab wired to an EEG recorder, a setting of limited ecological validity that is usually practical for only one or two nights. These requirements limit our ability to answer important questions regarding the long-term effects of sleep on cognition and mood. This project aims to answer these questions using: (i) Long-term Mobile Sleep and Activity Monitoring to enable the economical, practical, and parallel assessment of sleep patterns of multiple participants in their own homes for several weeks; and (ii) Mobile Individualized Cognitive Assessment to deliver twice-daily short cognitive tests and other self-assessments in participants' homes. The project aims to develop a smart health approach that integrates these two technologies to assess the effect of sleep-wake patterns on the cognitive performance of participants for a period of several weeks, thus obtaining the necessary data needed to answer the research questions regarding the long-term effects of sleep on cognition and mood including: (i) What is the cumulative effect, over many days, of fluctuations in sleep patterns on cognitive and emotional wellbeing? (ii) What are the effects of sleep on the gradual consolidation of memory in activities which require ongoing practice for days or weeks to master? <br\/><br\/>Intellectual Merit: Anticipated results of the project include answers to important unanswered questions about the complex interactions between natural fluctuations in sleep and their influence on cognitive and emotional well-being through innovations in (i) Utilization of mobile sleep, activity, and cognitive assessments to allow long-term studies to take place in participants' homes, (ii) Use of cognitive tasks that have previously been validated in a wide range of clinical populations, and which measure subtle variations in two key brain regions involved in sleep-related changes in cognition: the basal ganglia and medial temporal lobe. (3) Application of mathematical model-based methods for deriving learning strategies used by participants to provide a novel and parsimonious approach to analyzing and interpreting large sets of learning data from the cognitive assessments to extract the key neuro-cognitive parameters which can be related to variations in sleep patterns.<br\/><br\/>Broader Impacts: Integrating mobile sleep monitoring with cognitive and emotional assessments will further the SHB goal of empowering patient-centric wellness using unobtrusive monitoring of individual baselines. Mobile sleep monitoring may be especially useful for impaired individuals for whom a sleep-lab is not viable. The project offers enhanced research-based training opportunities for graduate and undergraduate students, including members of under-represented groups, at Rutgers University. All of the research results, data, publications, mathematical models, will be made freely available to the larger research community.","title":"SHB: Type I (EXP): Long-term Mobile Monitoring and Analysis of Sleep-Cognition Relationship","awardID":"1231515","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[523437],"PO":["560586"]},"198644":{"abstract":"Disasters cause damages estimated in many billions of dollars and many lives lost every year. Disaster management is a challenging task due to the seemingly unpredictable alterations of the environment and impact on people. With the primary focus on the application of information technology and Big Data, this award establishes a \"virtual institute\" for Global Research on Applying Information Technology to Support Effective Disaster Management (GRAIT-DM). It will foster research collaborations and community activities, with the goal of improving our preparedness for, response to, and recovery from disasters. Led by partners at the Georgia Institute of Technology and the University of Tokyo, the virtual institute is a U.S.-Japanese cooperative effort that should grow to become a global collaboration in the near future.<br\/><br\/>Information technology has transformed modern disaster management, as demonstrated by Twitter which was a valuable information source during the Tohoku Earthquake. A Big Data-based approach to disaster management research can be both transformative and challenging, at both human and social scales. Reflecting this, the GRAIT-DM project supports the collection of large data sets from environmental sensors and information networks shared by many researchers working on various aspects of disaster management. This virtual institute promotes global research on the application of information technology by engaging the big data producers (e.g., sensor networks researchers), big data consumers (e.g., disaster management researchers), and big data managers (e.g., data analytics researchers) who connect the big data producers to consumers. Concrete activities include community-building workshops in the U.S. and Japan, outreach and publication of research reports, educational activities such as summer schools for graduate students and junior researcher exchanges, and a web portal to provide access to data and support for software tools for community use. Broader impacts include beneficial leveraging of international research and infrastructure investments, enhancement of on-going projects through cross-fertilization, an accelerated rate of innovation relevant to disaster management, and the development of a work-force with specialized talent, capable of excelling in a new, highly interconnected world that must cope with disasters.<br\/><br\/>This award has been designated as a Science Across Virtual Institutes (SAVI) award and is being co-funded by NSF's Office of International Science and Engineering.","title":"SAVI: EAGER: for Global Research on Applying Information Technology to Support Effective Disaster Management (GRAIT-DM)","awardID":"1250260","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"8077","name":"Science Across Virtual Instits"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[532971],"PO":["557315"]},"194057":{"abstract":"Software is a critical element in a wide range of real-world applications. Attacks against computer software can cause substantial damage to the cyber-infrastructure of our modern society and economy. In fact, many new software security vulnerabilities are discovered on a daily basis. Therefore, it is vital to identify and resolve those security issues as early as possible. This research aims to investigate a scientific foundation and a novel methodology for automated detection, prevention, and resolution of prior-known software security vulnerabilities in software systems. The results will help to detect and prevent prior-known security vulnerabilities from recurring in other software systems.<br\/><br\/>In this research, the key philosophy is that the software systems having the same\/similar software security vulnerabilities share the protocols, algorithms, procedures, libraries, frameworks, modules, or source code with the same flaws, and they suffer the same\/similar exploitation mechanisms. Based on that, empirical studies are conducted to investigate the nature and the characteristics of recurring software vulnerabilities in different software systems, and to validate that hypothesis. Based on the knowledge gained from the studies, new vulnerability models, representations, and similarity measurements are developed to capture recurring software security vulnerabilities, and the corresponding vulnerable code and exploitation mechanisms. Novel algorithms and techniques are designed to (semi-)automatically build graph-based vulnerability models from vulnerability reports and from vulnerable code and patches, aiming to construct a database of prior-known vulnerabilities. A new methodology is developed to help to identify the prior-known vulnerabilities in other systems and to suggest the resolution. Specifically, the automated methods and advances include 1) an algorithm to compare and match against vulnerability models in the database, 2) a technique to map software concepts between security reports and from a report to the corresponding source code fragments, modules, or components; 3) an algorithm to determine the modules and source file locations in the new system that correspond to the vulnerable modules and locations in a system with a prior-known vulnerability; and 4) a technique to suggest the patch to the new system from the prior fixes. In brief, the results of this research help to resolve early software security vulnerabilities. They will lead to more reliable software because the process of detecting and patching for recurring security vulnerabilities will be more efficient and effective.","title":"TWC: Small: Detection and Prevention of Prior Known Software Security Vulnerabilities","awardID":"1223828","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["562663"],"PO":["564388"]},"198655":{"abstract":"Future cloud services are expected to increasingly involve and synthesize capabilities from multiple clouds. Applications from different organizations may establish collaborative relationships and share information dynamically in cloud computing. In this increasingly complex scenario, both consumers and service providers will face new challenges. For example, consumers will need to be able to identify the best service providers from a potentially huge pool, which could be computationally demanding. Service providers will need to be able to ensure the security and privacy of data shared among loosely connected subcontractors.<br\/><br\/>This project proposes a novel brokerage-based architecture to promote cost-effective cloud provisioning. Specifically, the PIs will devise efficient indexing structures to facilitate the management of massive information generated by a large number of service providers with a variety of properties. The PIs are developing necessary services to allow effective cloud-brokerage, such as service selection for consumers, service negotiation between consumers and their service providers, and service agreement delegation among service providers involved in a compound service. Along with the service development, the work will produce new policy analysis, composition and delegation techniques that accommodate the unique characteristics of the cloud.<br\/><br\/>The research in this project will help significantly streamline the selection and management of cloud computing services, and will open up new business opportunities by providing cloud brokerage services. Moreover, the proposed approach may also help reduce the vendor lock-in problem which is a long standing major concern among consumers.","title":"CSR: EAGER: Collaborative Research: Brokerage Services for the Next Generation Cloud","awardID":"1250319","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["563413"],"PO":["565255"]},"195278":{"abstract":"Telemedicine technologies offer the opportunity to frequently monitor patients' health and optimize management of chronic illnesses. Given the diversity of home telemedicine technologies, it is essential to compose heterogeneous telemedicine components and systems for a much larger patient population through systems of systems. The objective of this research is to thoroughly investigate the heterogeneity in large-scale telemedicine systems for cardiology patients. To accomplish this task, this research seeks to develop (i) a novel open source platform medical device interface adapter that can seamlessly interconnect medical devices that conform to interoperability standards, such as IEEE 11703, to smart phones for real-time data processing and delivery; (ii) a set of novel supporting technologies for wireless networking, data storage, and data integrity checking, and (iii) a learning-based early warning system that adaptively changes patient and disease models based on medical device readings and context.<br\/><br\/>Cardiovascular disease is a major health problem and the leading cause of death in the United States. Telemedicine technologies developed in this project have the potential to dramatically improve the quality of home health care with low cost for medical community. This research acquires a clear understanding of how to address heterogeneity issues in telemedicine systems, which allows effectively compose and interconnect individual telemedicine components together with low cost. For developers, this research significantly reduces the design and development costs for building interoperable large-scale telemedicine systems. The research content is being integrated into undergraduate, graduate system courses, clinician training course as well as high school research projects.","title":"SHB: Type I (EXP): Collaborative Research: Heterogeneous Large-Scale Telemedicine for Cardiology Patients","awardID":"1231680","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":["541635"],"PO":["564778"]},"199887":{"abstract":"This project explores a new way to increase the expressive power of Markov Random Fields (MRF) while at the same time improving the computing efficiency and the quality of solutions. The research focuses on utilizing quadratic mutual exclusion constraints (QMCs) expressed in quadratic equality form. Current approaches to increasing the expressive power of MRFs face a very challenging problem of higher computing time. In contrast, this approach is able to restrict the solution search space with QMCs, which in turn not only leads to significantly better solutions but also to reduced computing time.<br\/><br\/>Many problems in computer vision, including but not limited to image and video segmentation, stereo, and image restoration, object detection and recognition, tracking, and activity recognition, are formulated as optimization problems involving inference of the maximum a posteriori (MAP) solution of a Markov Random Field (MRF). QMCs are more general than mutex constraints expressed in a linear equality form. Hence QMCs offer increased expressive power to more accurately model many computer vision problems. This property is particularly important when unary and binary MRF potentials are unreliable and uninformative, which is the rule rather than an exception in real applications. Hence, this project can increase the ability of computer vision systems to broaden their application scope, ranging from image retrieval to computer vision systems on mobile robots.","title":"EAGER: Solving Markov Random Fields with Mutual Exclusion Constraints","awardID":"1257024","effectiveDate":"2012-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["541851"],"PO":["564316"]},"189514":{"abstract":"People care greatly about the appearance of translucent materials such as food, skin, soap, and marble, and they are able to distinguish subtle differences in these materials based on their appearance. The translucent appearance of these materials is caused by internal volumetric scattering, which is challenging to simulate, especially because humans are so sensitive to their subtleties. Since in the natural world scattering materials are the norm, not the exception, it makes sense that the human visual system is so well engineered to analyze them. However, very little is known about how this analysis is achieved because the perception of volumetric translucency is almost unstudied.<br\/><br\/>This collaborative project, involving faculty from three universities with complementary expertise in computer graphics, human vision, machine learning, and computer vision, addresses the fundamental unsolved problem of understanding translucency for graphics. The PIs will develop a perceptually-motivated pipeline for translucency, contributing new scattering representations, perceptual dimensions, and computational algorithms to computer graphics. The scattering representations, based on a polydispersion model, will provide analytic expressions for wavelength-dependent bulk scattering properties of translucent media; this will significantly expand the range of materials that can be simulated with high visual fidelity. Finding perceptual knobs that relate physical scattering parameters with visual appearance will be achieved by coupling large-scale computation (using cloud computing) with controlled perceptual studies. Novel acquisition approaches that employ hyperspectral imaging will be created, as will editing and rendering applications that use the new perceptual representations of translucency. Low-dimensional models to represent scattering media will be developed and used to enable efficient and accurate acquisition and rendering. A suite of test materials and scenes will be developed to evaluate the fidelity of rendered images based on the developed theory and computational applications.<br\/><br\/>Broader Impacts: Currently, the simulation of translucency presents challenges in terms of both computation and visual fidelity. This restricts the ability of practical algorithms to predictively simulate translucent materials, thus fundamentally limiting the use of graphics in real applications. By building the computational tools to characterize, study, and use knowledge of translucency perception, this research will fundamentally change the graphics pipeline for translucent materials. and will potentially revolutionizing industrial design, interior design, skin care and cosmetics, and entertainment.<br\/><br\/>The project includes an education program that is tightly coupled to the research program. The PIs have already been meeting twice a week for more than six months, and their graduate students already share data, code, and equipment. During the activity, the students will make week-long and month-long visits to each other's laboratories to collaborate, and in this way the project will produce a generation of researchers who are \"T-shaped\" in the sense of being both deep in their respective fields and able to work effectively across these synergistic disciplines. The PIs also plan to organize a workshop that will brins together researchers in vision science, computer graphics, and computer vision, so that the important ties between these fields are strengthened even further.","title":"CGV: Medium: Collaborative Research: Understanding Translucency: Physics, Perception, and Computation","awardID":"1161645","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[508159],"PO":["565227"]},"189646":{"abstract":"Smartphones are increasingly ubiquitous. Many users are forced to carry multiple smartphones for work, personal, and geographic mobility needs. This research is developing Cells, a lightweight virtualization architecture for enabling multiple virtual smartphones to run simultaneously on the same physical device in a securely isolated manner. Cells introduces a new device namespace mechanism and novel device proxies that multiplex phone hardware devices efficiently and securely across multiple virtual phones while providing native hardware device performance to all applications. Virtual phone features include fully accelerated graphics for gaming, complete power management features, easy-to-use security and safety mechanisms that can control the availability of phone features transparently and dynamically, and full telephony functionality with separately assignable telephone numbers and caller ID support. Cells is implemented in Android, the most widely used smartphone platform, to transparently support multiple Android virtual phones on the same phone hardware. While the primary focus of this research is smartphone devices, the development of these ideas is also explored in the context of tablet devices. <br\/><br\/>The results of this research provide a foundation for future innovations in smartphone computing, enabling new uses and applications and transforming the way the devices can be used. This research promises to improve not just system security, but also user safety; especially for young people. Integrating this research with the CS curriculum provides students with hands-on learning through programming projects on smartphone devices, enabling them to become contributors to the workforce as smartphones become an increasingly dominant computing platform.","title":"CSR: Medium: A Virtual Smartphone and Tablet System Architecture","awardID":"1162447","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[508477],"PO":["564778"]},"199579":{"abstract":"This project supports 10 students to attend the seventh ACM International Workshops on Underwater Networks (WUWNet)to be held in Los Angeles, California, November 5 - 6, 2012. This will provide students exposure to the challenges and techniques for setting up underwater networks and using them for continuous monitoring of significant events.","title":"The Seventh ACM International Conference on Underwater Networks & Systems (WUWNet'12) - Student Travel Awards","awardID":"1255708","effectiveDate":"2012-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550654"],"PO":["565255"]},"199106":{"abstract":"This project addresses the foundational question in Robust Intelligence of how an autonomous agent can learn use low-level sub-symbolic (pixel-level) sensorimotor experiences with its environment to learn higher level effective concepts, ranging from learning to use a hand to manipulate objects on a tabletop, to learning to balance and walk, to learning to move through a complex environment without collisions with walls or pedestrians. This project will develop computational models of how this learning process could take place and will implement and test these computational models on an actual robot. Understanding such autonomous concept learning has the potential to impact a range of disciplines including Cognitive Science, Psychology, AI in general, and robotics, computer vision, and machine learning in particular. Understanding how concepts come into being and evolve in the specific domain of robot navigation also has the potential to contribute to advances in systems that help persons with physical and learning disabilities.<br\/><br\/>The project draws on insights from two different approaches from the PI's lab that have complementary strengths: (1) QLAP (Qualitative Learner of Action and Perception), and (2) MPEPC system (Model Predictive Equilibrium Point Control). The QLAP system exploits a qualitative abstraction of continuous sensor input in order to learn causal contingencies, DBN (Dynamic Belief Network) and MDP models of the causal world, and to build a hierarchy of action models. It uses perception with laser rangefinders and correlation peaks between changes to the motor vector and events in the sense vector -- so-called contingencies -- to discern motor signals that produce resulting perceptual events that may be more than random variation. Reliable episodes can be remembered as cases and used in learning. The MPEPC system factors the continuous navigation problem for a mobile robot into a local unconstrained control and a global optimization process that balances constraints such as progress and collision avoidance. Both methods have a local phase (learning contingencies and local control laws), and a global phase (learning a hierarchy of actions and finding extended routes that balance constraints). These two approaches will be augmented by learning methods from Case-Based Reasoning (CBR) that use features of the presenting case to retrieve related cases from case memory. Two levels of case representation will be employed. The lowest level case representation is a simple feature vector: in the case of local motion control, it specifies the target pose location in the egocentric frame of reference, along with the parameters of the motion control law that attempts to reach it, and the quality of the resulting trajectory. Retrieval will be done using Nearest Neighbor, combining information from the retrieved cases by Locally Weighted Regression or Locally Weighted Projection Regression. At the higher level of action learning, a case is to be described by identifying the critical environmental constraints that determine the global structure of the action.","title":"EAGER: Memory-based learning of effective actions","awardID":"1252987","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[534124],"PO":["565035"]},"198017":{"abstract":"A study of software code has revealed a surprising result: that software code may be just as (if not more) \"natural\" as natural language itself (e.g., English) in that code is highly predictable and repetitive; statistical natural language techniques may be applied quite competently for some software engineering tasks. For example, N-grams may be quite effective at suggestion and completion tasks in code. The evidence supports further exploration of the applicability of statistical NLP techniques and tools to software development activities and processes. The project explores the feasibility of establishing a scientific basis and tools for a variety of code-level software engineering functions -- including natural language summarization, code retrieval, software question answering, automated code completion, and assistive tools for disabled developers to support software engineering, forming not only a new and important domain for further research in NLP, but also a totally new approach to software development.","title":"EAGER: Exploiting the Naturalness of Software","awardID":"1247280","effectiveDate":"2012-09-01","expirationDate":"2015-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[531418,"562712","562714"],"PO":["564388"]},"189459":{"abstract":"This research develops general frameworks for efficient graph algorithms, which allow to solve entire categories of computational problems all at once. The PIs aim for a general theory of algorithms, wherein a given problem of interest can simply be adapted into the general approach. This approach differs from the traditional study of algorithms, which often focuses on individual solutions to specific problems.<br\/><br\/>The type of computational graph problems the PIs consider are \"optimization problems\", where the task is to find a solution whose cost, quality, size, profit, energy, or speed is as large or as small as possible. Most interesting graph optimization problems are NP-hard, essentially implying that there are no efficient algorithms to find the very best solution. This research considers the two main types of algorithms for solving NP-hard graph optimization problems. Approximation algorithms allow the result to be a small factor away from the optimal, but still require a fast running time. Fixed-parameter algorithms allow the running time to be exponential, but confine that exponentiality to a (typically small) parameter other than the problem size, while requiring an optimal solution.<br\/><br\/>The type of graphs the PIs consider include planar graphs, which can be drawn in two dimensions without any edges crossing each other, and nearly planar graphs such as graphs of bounded genus and graphs excluding a fixed minor. Many graphs of practical interest---for example, computer networks and road networks, which are \"drawn\" on Earth---are planar or nearly planar. In these settings, the PIs aim to develop general frameworks for approximation and fixed-parameter algorithms.","title":"AF: Medium: Collaborative Research: General Frameworks for Approximation and Fixed-Parameter Algorithms","awardID":"1161365","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[508020],"PO":["565157"]},"193650":{"abstract":"Markov chain Monte Carlo (MC) algorithms are important tools throughout the physical and biological sciences, with applications ranging from simulating new materials to reconstructing phylogenetic trees. They explore a space of states of a physical system, or potential solutions to a problem, by making a series of small changes. One of our main challenges is knowing whether the algorithm has run long enough to reach equilibrium, i.e., if it has spread throughout the space enough to obtain good estimates of important quantities. Here, there is a major divide between theoreticians and practitioners. Physicists use non-rigorous techniques that are much more optimistic than what theorists know how to prove. On the other hand, they are often based on deep ideas about the physical properties of these systems and their asymptotic behavior, and are backed up by numerical experiments. The main theme of the research under this award is to answer the question: how can we bridge the divide between these two camps?<br\/><br\/>The PIs will focus on three areas where stronger bridges can be built. In two-dimensional spin systems, they will use power-law decay of correlations to prove polynomial mixing times at critical points, and to show that we can efficiently \"remix from equilibrium\" even below phase transitions where worst-case mixing times are exponential. They will give a rigorous understanding of the efficiency of cluster algorithms widely used in physics, which are believed to avoid or reduce the phenomenon of \"critical slowing down\" as we approach a phase transition. Finally, the PIs will go beyond traditional Markov chain analysis techniques on discrete state spaces, and prove new results on systems whose states are continuous, such as the hard-sphere model in the plane.<br\/><br\/>This work is cross-disciplinary between physics and computer science. MC algorithms also offer an excellent opportunity to involve undergraduates in the research process: they can implement algorithms used in physics and computer science, and gain a \"hands-on\" feeling for their performance in theory and practice. They can also produce educational applets to let other students, in turn, see these algorithms in action.","title":"AF: Small: Collaborative Research: The Physics of Markov Chains: Closing the Gap Between Theory and Practice","awardID":"1219115","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[518608],"PO":["565157"]},"200657":{"abstract":"The workshop on Quantum Information Science in Computer and Natural Sciences is being organized by the Physics Frontier Center at the Joint Quantum Institute of the University of Maryland to help the Computer and Natural Sciences community become aware of the possibilities of developments in Quantum Information Science. This is in connection with the recent program solicitation from the National Science Foundation NSF 12-540 CISE-MPS Interdisciplinary Faculty Program in Quantum Information Science. The workshop plans to have about 65 participants from academic institutions of the United States including 15 speakers.<br\/><br\/>The Intellectual Merit of this workshop stems from the potential to connect people in the computer sciences and other areas of MPS with leading researches in Quantum Information in a favorable environment to foster collaboration, including spending sabbaticals at the QI primary centers in the United States. This will help fulfill the United States National Science and Technology Council report A Federal Vision for Quantum Information Science.<br\/><br\/>Broader Impacts of this activity include the multiplicative effect that the participants, when returning to their institutions, will have for the expansion of Quantum Information Science.","title":"Workshop on QIS in Computer and Natural Sciences, hosted by Joint Quantum Institute, University of Maryland, College Park, MD. September 28-29, 2012","awardID":"1261307","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["544655"],"PO":["564326"]},"193540":{"abstract":"The objective of this project is to design and develop a data management system that supports query processing on continuous uncertain data by returning a full probability distribution of query output and optimizes such processing for performance. This project includes four thrusts: (1) supporting continuous uncertain data processing using both the traditional relational model and the array model; (2) addressing complex correlation that arises in continuous uncertain data processing using new statistical graphical models; (3) supporting arbitrary user-defined functions, besides standard query operations, by exploring advanced techniques such as Gaussian processes and functional interpolation; and (4) developing a prototype system and evaluating it using real-world applications. Expected results include statistical models and techniques, data storage schemes, query processing and optimization techniques, and a publicly available prototype to fully support query processing on continuous uncertain data. <br\/><br\/>The results of the project can benefit applications such as severe weather monitoring and computational astrophysics, as well as the broader scientific community. Since applications such as tornado detection may trigger actions based on derived information, the ability to characterize uncertainty of output may result in significant social impacts. This project also integrates research and education with curriculum development and engaging women in research through college outreach and CRA's distributed mentor program. The results of the project are disseminated at the project web site: http:\/\/claro.cs.umass.edu.","title":"III: Small: High-Performance Complex Processing of Continuous Uncertain Data","awardID":"1218524","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[518346,518347],"PO":["565136"]},"193441":{"abstract":"Wireless sensor networks (WSNs) are widely used in applications such as environmental monitoring, surveillance and health monitoring of large structures. A major challenge when using WSNs is their limited life expectancy. However, in practice the phenomena of interest in a sensed field are quite localized and affect a small number of sensors. This property of locality induces sparsity in sensor data statistical descriptors such as the covariance matrix. This project involves the development and analysis of efficient algorithms that uncover sparse structures in the sensor data covariance, and determine in a distributed fashion which sensors acquire informative measurements and have to remain active. Identifying the `informative' sensors can lead to significant energy savings. The research focuses on the novel utilization of covariance sparsity in developing distributed informative sensor selection algorithms that have the ability to adaptively learn the statistical behavior of the sensed field, without relying on a priori known data models. <br\/><br\/>The investigators consider the design and performance analysis of a generalized sparsity-aware framework that is capable to analyze the sensor data covariance matrix into sparse factors. Norm-one regularization mechanisms are employed to estimate and identify the support (nonzero entries) of the unknown sparse covariance factors. The factors' support is used to identify the informative sensors. A novel blending of the sparsity-based factorization techniques with distributed optimization tools is also studied to obtain distributed algorithms that enable sensors to collaboratively learn the underlying sparse covariance structure, even with noisy inter-sensor communications and overlapping sources. The research also involves adaptive implementations that track online the set of informative sensors in non-stationary settings formed by mobile sources, using stochastic approximation toolboxes properly tuned to exploit sparsity.","title":"CIF: Small: Distributed Informative Sensor Selection via Sparse Covariance Factorization","awardID":"1218079","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[518115],"PO":["564898"]},"193331":{"abstract":"Many high-end computing and data-intensive applications, such as transaction processing systems, large-scale scientific simulations, and on-demand services, are limited by the performance of the underlying memory and storage systems. The goal of this project is to improve the memory\/storage hierarchy by integrating new and emerging memory\/storage technologies with the existing memory\/storage hierarchy. Flash memory based Solid State Drives (SSDs) and Phase Change Memory (PCM) are two emerging memory\/storage technologies that show tremendous promise to improve the performance of current computer systems. Shingled Write Disks (SWDs) have been recently proposed to further improve the magnetic disk space capacity to another level. This project is to investigate effective data placement in the new memory\/storage hierarchies to better support high-end computing and data-intensive applications. Considering the special characteristics of these new technologies, this project provides innovative solutions for prediction-based data placement in the new memory\/storage hierarchies to effectively improve the performance of both memory and storage data accesses. It speeds up the integration of PCM with DRAM as a new memory hierarchy and flash memory-based SSDs and SWDs with the existing storage hierarchy. Providing efficient solutions to the fundamental performance issues greatly improves the performance of many critical applications including weather forecasting, large-scale scientific simulations, e-commerce, etc. Therefore, the project makes huge impact on our daily life. Quickly integrating SWDs into the existing storage hierarchy will also enhance our capability to handle huge amounts of available data. This project creates positive impact on every layer of the memory and storage hierarchies.","title":"CSR: Small: Prediction-Based Data Placement for New Memory and Storage Hierarchies","awardID":"1217569","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["543507"],"PO":["565255"]},"193452":{"abstract":"Two distinct milestones of any software development lifecycle are requirements gathering and acceptance testing, where a software product is verified against its requirements. Yet this verification is one of the most difficult tasks, since it involves bridging an abstraction gap between high-level descriptions of requirements and their low-level implementations in the source code. Determining how different requirements are covered by acceptance tests is very hard, since it means tracing each acceptance test to specific requirements. Many companies and organizations do not have or cannot invest significant resources into recovering links among requirements, acceptance tests and other artifacts. As a result, software development is not as efficient as it could be, lacking controls to steer the overall testing and bug-fixing effort, and involving extra work peripheral to the core tasks. The end result is a situation in which it is unclear how well software is tested and how much confidence stakeholders can have in it.<br\/><br\/>We are addressing this fundamental problem by defining and developing a new, integrated model for recovering traceability links using execution artifacts, diverse models, and requirements. We develop techniques for automatically generating additional test cases that execute untested code to recover additional traceability links and verify existing ones. To ensure that our approach is effective, we will perform rigorous case studies in real industrial scenarios to evaluate the model, techniques, and methodologies. As a result, the state-of-the-practice in software development will be improved that faces difficulties in ensuing that software products are tested fully with respect to their requirements. Among the broader impacts the project includes developing educational course content, involving underrepresented categories of students, producing software tools under open source licenses, and collaborating with industry to transfer technology.","title":"III: Small: Collaborative Research: Linking Evolving Software Requirements and Acceptance Tests","awardID":"1218129","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["534438"],"PO":["564388"]},"193463":{"abstract":"Occlusion contour (OC) is well known to play important roles in many computer vision tasks. Unlike regular photographs, an OC image removes the effects of illumination, texture, and appearance while preserving important depth edges and silhouette. This project develops a comprehensive framework for acquiring, processing, and utilizing OCs in visual inference tasks. On the sensor front, the research team develops a new Occlusion Contour Camera or OC-Cam. The new OC-Cam extends the multi-flash camera by coupling an array of controllable infrared (IR) LEDs and a visible-IR camera pair. On the algorithm and application fronts, the research team systematically develops OC-assisted visual inference algorithms. For recognition, the acquired OCs are used as a feature filter to improve category-level object recognition. For tracking, the PIs apply OCs to enhance target representation by filtering out the background and texture edges. Furthermore, the research team investigates the previously under-explored problems of OC-assisted image summarization and privacy protection.<br\/><br\/>This project can cast deep impact on broad areas of computer vision, artificial intelligence, criminal justices, and robotics, both in research and education. Due to the importance of OCs in human vision, the results can produce a testbed for the study of visual psychology. Furthermore, the OC-Cam is expected to serve as conceptual inspiration for constructing the next-generation surveillance systems. Finally, the captured OC datasets and relevant tools are made available to other researchers, to provide a platform for validating new OC-based computer vision algorithms.","title":"RI: Small: Collaborative Research: Contour-Assisted Visual Inference: Systems, Algorithms, and Applications","awardID":"1218177","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["550477"],"PO":["564316"]},"194794":{"abstract":"Proposal #: 12-29064<br\/>PI(s): Camacho, Carlos J; Chong, Lillian T<br\/>Institution: University of Pittsburgh<br\/>Title: MRI\/Acq.: Computational Resources for Research in Computational and Systems Biology<br\/><br\/>Project Proposed:<br\/>This project, acquiring a computational instrument, fosters interdisciplinary collaborations and training that promote breakthroughs in the biological sciences. The project is lead by the Department of Computational and Systems Biology (DCSB) in conjunction with the joint Ph.D. program between two institutions in the area: Pittsburgh and Carnegie Mellon Universities. The acquisition, a state-of-the-art 57-node 3392 core computing cluster, is dedicated to research and development of applications and the dissemination of new computational methods. The cluster supports the following research projects:<br\/>- Novel molecular methods to access biological timescales of interest; <br\/>- Deep-sequencing technologies for high throughput ?omic? data collection; and, <br\/>- Methods to leverage high-resolution multi-modal biomedical images\/videos in basic research.<br\/><br\/>Broader Impacts: <br\/>Broader impacts should be felt both regionally and nationally. At the involved institutions, the research initiatives the incorporation of developed applications in teaching modules for use at local city high schools, as well as in undergraduate and graduate courses. Access to dedicated computational resources will provide valuable hands on experiences for students. More broadly, the software developed exploits the new computational resources that will be made available to other researchers nationwide.","title":"MRI: Acquisition of Computational Resources for Research in Computational and Systems Biology","awardID":"1229064","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[521829,521830],"PO":["557609"]},"193584":{"abstract":"Broadcast is an important operation in ad hoc networks, especially in distributed multi-hop multichannel networks. Although the broadcasting issue has been extensively investigated in traditional single channel and multi-channel ad hoc networks, there are unique challenges that are un-explored in the broadcast design in cognitive radio ad hoc networks. Existing schemes can have serious performance degradation due to the neglect of the dynamics in the spectrum availability in cognitive radio networks. The research objective of this project is to design, analyze, and evaluate new broadcast protocols for multi-hop cognitive radio ad hoc networks without a common control channel. The broadcast design is aimed at maximizing the broadcast success rate and minimizing the average broadcast delay simultaneously. The approach is focused on exploiting the spectrum correlations of neighboring nodes and the spectrum diversity of different nodes in designing new channel rendezvous, scheduling, and collision avoidance algorithms to achieve the broadcast performance goals in practical scenarios. <br\/><br\/>This project will provide fundamental and complementary solutions to existing cognitive radio networking research on other network operations. It will also help generate innovative techniques to numerous applications of the cognitive radio and dynamic spectrum access technology. This project provides an excellent opportunity for graduate and undergraduate research students to gain valuable educational training and research experiences. The research results will be presented at IEEE\/ACM journals and international conferences.","title":"NeTS: Small: Broadcast in Cognitive Radio Ad Hoc Networks","awardID":"1218751","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560198"],"PO":["565303"]},"193353":{"abstract":"Specialized network appliances or \"middleboxes\" are expensive and closed systems with little\/no hooks for extension; they come with custom management APIs and are deployed as standalone devices with little cohesiveness in how the ensemble of middleboxes is managed. These drawbacks put network infrastructure on a trajectory of growing device sprawl with mounting capital and management costs. This research introduces a new approach to building and managing middlebox infrastructure. Instead of an ad-hoc clutter of specialized and standalone boxes, the research develops a middlebox architecture in which software-centric middlebox applications run consolidated on a shared hardware platform, managed by a single, unified controller. This approach offers extensibility (since new applications are deployed on existing hardware and integrated into a unified management architecture) and yet efficiency (due to amortization of both hardware and management overheads).<br\/><br\/>Broader Impact: Modern society's growing reliance on networked systems has been astounding. This growth has not come easily however. Today's networks are highly complex systems and middleboxes are a significant contributor to this complexity; even the experts that build and run networks struggle to manage and diagnose their operation. Spiraling costs related to the manageability and evolution of networks impacts the networking industry and hence eventually the broader society that relies on them. This research aims to ameliorate this trajectory through a simpler, unified design for middlebox infrastructure.","title":"NeTS: Small: The Design and Implementation of a Consolidated MiddleBox Architecture","awardID":"1217654","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["559247"],"PO":["565090"]},"193595":{"abstract":"As the cost of computing and communication resources has plummeted, applications have become data-centric with data products growing explosively in both number and size. Although accessing such data using the compute power necessary for its analysis and processing is cheap and readily available via cloud computing (intuitive, utility-style access to vast resource pools), doing so currently requires significant expertise, experience, and time (for customization, configuration, deployment, etc). This work investigates new models of cloud computing that combine domain-targeted languages with scalable data processing, sharing, and management abstractions within a distributed service platform that \"scales\" programmer productivity. To enable this, this research explores new programming language, runtime, and distributed systems techniques and technologies that integrate the R programming language environment with open source cloud platform-as-a-service (PaaS) in ways that simplify processing massive datasets, sharing datasets across applications and users, and tracking and enforcing data provenance. The PIs' plans for research, outreach, integrated curricula, and open source release of research artifacts have the potential for making cloud computing more accessible to a much wider range of users: The data analytics community who use the R statistical analysis environment to apply their techniques and algorithms to important problems in areas such as biology, chemistry, physics, political science and finance, by enabling them to use cloud resources transparently for their analyses, and to share their scientific data\/results in a way that enables others to reproduce and verify them.","title":"CSR: CC: Small: Collaborative Research: Language and Runtime Support for Large-Scale Data Analytics","awardID":"1218808","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["561463"],"PO":["565255"]},"195784":{"abstract":"This collaborative research award provides funding for the development of new and stronger techniques for the solution of optimization problems with complementarity constraints to global optimality. Complementarity problems are pervasive in business, engineering, and economics, since complementarity conditions arise in optimality conditions for nonlinear programs and in models of equilibria. Algorithms for complementarity problems have until recently focused on feasibility problems by employing local optimization techniques. This project focuses on the development of convex relaxations for these problems, with the goal of incorporating them into branch-and-bound algorithms for global optimization. The research is aimed at deriving procedures that (i) exploit the combinatorial and disjunctive structure of complementarity constraints, (ii) focus on relaxations with a provable guarantee of strength, and (iii) target problems in which some of the constraints (besides complementarities) are nonlinear. The benefits of relaxation techniques will be studied relative to mature implementations of global optimization algorithms.<br\/><br\/>If successful, the new relaxations developed with this research, along with factorable decomposition and separation techniques, will advance the state of the art in the global optimization of complementarity programs, bringing many practically relevant problems within the range of tractability. Because complementarity constraints arise in equilibrium analyses of supply and demand, adversarial relationships between strategically interacting entities, traffic equilibria, and in the analyses of multistage optimization problems, this research could lead to improved efficiencies in various sectors of the economy. Further, since bilevel programs have numerous applications in defense planning, including interdiction and protection of critical infrastructure, this research could impact positively various areas of national defense. From an educational perspective, related material will be incorporated into undergraduate and graduate education and doctoral students will be trained in relevant technologies including integer programming and global optimization. In addition, a website will be designed to disseminate prototype implementations and problem data sets.","title":"Collaborative Research: Novel Tighter Relaxations for Complementarity Constraints with Applications to Nonlinear and Bilevel Programming","awardID":"1234897","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"5514","name":"OPERATIONS RESEARCH"}}],"PIcoPI":[524799],"PO":["565139"]},"194574":{"abstract":"The ubiquity of computing technology and the Internet have created an age of big data that has the potential to greatly enhance the efficiency of our societies and the well-being of all people. The trend comes with problems that threaten to prevent or undermine the benefits. An immediate concern is how to fuse, integrate and analyze data while respecting privacy, security and usage concerns. A second issue is allowing data to remain distributed, enabling its owners to maintain and control quality as well as to enforce security and privacy policies. A final underlying challenge is helping to produce sound and useful results by assuring that systems understand the meaning of the data being integrated and analyzing access and usage policies. For some domains, like health informatics and clinical research, solving these problems will have a significant impact on society.<br\/><br\/>This project explores an approach to solving these problems by developing a policy-compliant integration system for linked healthcare data. The system models data, schemas and policies using open Web standards such as Semantic Web languages, federates queries to independent Linked Data stores based on content, provides policy enforcement by modifying incompliant queries, and uses formal methods to guarantee correctness of key components.<br\/><br\/>This project provides new approaches to solving one of the most significant problems our society faces in the 21st century: benefiting from the integration of distributed linked data while respecting security, privacy, and usage requirements. The prototype tools and systems are incorporated into our educational activities and made available to others via appropriate open source licenses.","title":"TWC: Medium: Collaborative Proposal: Policy Compliant Integration of Linked Data","awardID":"1228198","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["551857","558641","522482"],"PO":["549626"]},"193485":{"abstract":"The use of cloud-based data processing platforms is an increasingly attractive alternative for large-scale data processing. There is active investigation into their use for various types of processing tasks on large-scale unstructured and structured data. However, due to an increased interest in many communities to enable more automatic sharing and exchange of data on the Web using Semantic Web techniques, there is a rapid surge in the availability of very large, real-world, Semantic Web datasets. Such data are semi-structured and have more complex processing requirements than relational data processing due to the fine-grained modeling of data and also the need for inferencing during processing. Consequently, existing optimization techniques for cloud data processing platforms which often adapt relational processing optimization techniques do not address the needs of such workloads. Further, such techniques do not adequately account for the nuances of cloud runtime platforms such as Hadoop e.g., dataflow length as a cost metric, no a-priori existence of indexes and statistics. <br\/><br\/>This project contributes insight into query optimization requirements for Semantic Web data processing on Map Reduce platforms. Its contributions include a novel Nested TripleGroup data model and Algebra (NTGA), algebraic and dynamic cost query optimization techniques; inter and intra-work sharing techniques, data representation formats and system architecture issues of integrating Semantic Web optimization techniques into frameworks such as Apache Pig. The impact of this project will cut across the increasing range of communities that are aggressively adopting Semantic Web tenets such as, scientific, business, government and other general-purpose communities.","title":"III: Small: Optimization Techniques for Scalable Semantic Web Data Processing in the Cloud","awardID":"1218277","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[518218],"PO":["563727"]},"193375":{"abstract":"Finding bugs in modern complex microprocessors is a critical and daunting task that must be deftly mastered to move designs from first silicon to launch. Escaped bugs may lead to the demise of a digital silicon company. At the same time, looking for design errors on first silicon prototypes lacks the observability, controllability and repeatability afforded by pre-silicon simulation frameworks. To complicate the process further, many of the bugs that manifest in real silicon are the result of complex asynchronous interactions and\/or electrical anomalies that are often not easily or frequently repeatable. Because of these challenges, debugging these \"fleeting bugs\" in early silicon is a black art that can significantly impact design schedules if the debugging process does not proceed smoothly.<br\/><br\/>This project investigates solutions to support the efficient diagnosis of these most challenging post-silicon validation bugs, those that manifest only occasionally. These bugs may be functional, timing or electrical errors, or also missed manufacturing defects. The approach entails placing lightweight instrumentation on-chip to collect data during a prototype's test executions. The data is then analyzed offline using statistical inference algorithms to quickly point verification engineers to offending components. The research explores a range of ideas to find the most promising instrumentation and algorithms for analysis. The results of this research effort allow semiconductor companies to shorten their time to market while delivering high quality products, with low incidence of escaped bugs; in turn, the work benefits society in that it unlocks further scaling and growth for the electronics industry.","title":"CSR: Small: Accelerating Microprocessor Post-Silicon Diagnosis with Statistical Inference","awardID":"1217764","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[517965],"PO":["565255"]},"193496":{"abstract":"Learning and inference in distributed settings is an important from both a scientific and engineering perspective. A typical instance of the problem is a network of individual sensors or agents attempting to infer a global distribution that governs their local observations. By passing messages the agents can individually make inference about a global phenomenon. This research investigates communication and networking paradigms that can enable a network of individual agents to collaboratively estimate distributions over high dimensional spaces, even when individual observations are severely limited in accuracy, space, or time. <br\/><br\/>In particular, the investigators study how individual decision makers can integrate two kinds of information: local observations and messages from their neighbors in the network. Both observation and messaging can be thought of as sampling : individuals sample their own environment and sample the opinions of their neighbors. Central to the approach is that the agents generate simple messages at random from an internal estimate of the global distribution of interest. The first major goal of this project is to develop a mathematical framework and analysis techniques to understand if and when this limited form of learning and communication is sufficient for an individual to estimate and learn distributions and\/or global parameters governing the observations of all nodes. The technical approach is a blend of analysis techniques ranging from stochastic approximation, randomized algorithms, and statistical physics. <br\/><br\/>Applications for this work range from mathematical modeling of messages and opinion formation in social networks, communication protocols for distributed optimization, and estimation of parameters in data networks. The work will cover several related problems : estimating high-dimensional histograms of data held in the network, parametric estimation using a mix of Bayesian and non-Bayesian techniques, and estimation of more complex generative models. The final part of the work is to apply these methods to peer-peer networks and social network modeling. The broader impact of this work is to further develop the interdisciplinary field of network science, which impacts both quantitative social sciences and engineering. The PIs will develop educational materials and organize research activities to help bring together different research communities interested in networks and social learning.","title":"CIF: Small: Collaborative Research: Inference by social sampling","awardID":"1218331","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[518243],"PO":["564924"]},"193265":{"abstract":"This project team, led by a learning scientist and a computer graphics and augmented reality expert are working together to design a new kind of science laboratory environment that uses augmented reality (AR) to make invisible scientific phenomena visible and continuously reinforce the conceptual principles at work during hands-on scientific experimentation. The envisioned technology visually captures the what students see as they are physically carrying out experiments, interactively processes the imagery to make key aspects available for analysis and exploration, and, in real time, automatically augments the imagery with visualizations that overlay visualizations of scientific phenomena on the real-world phenomena students are experiencing, allowing students to experience real-world phenomena and the conceptual models that describe those phenomena simultaneously. The base technology is a camera-equipped tablet. Initial content is on force, work, and motion. The technological innovation includes, first, recognizing the components in a scene, even when the lighting is bad and people and other objects occlude some of it, and second, calculating the positions of the objects so that the virtual imagery can be transformed to match the real-world positions. Foundations for the innovation can be found in what is known about the affordances of integrating multiple representations in reasoning and problem solving and the challenges and difficulties in doing that. The aim is to overcome those challenges so that the affordances of multiple representations, each of which can communicate different things, can be taken advantage of by learners. Scientists do this regularly, and a visceral understanding of how this is done by scientists is expected to help students better understand what scientists do and what counts as evidence. Research addresses how students' thinking processes and domain understanding are influenced by the addition of augmented reality visualizations to their hands-on scientific investigations. <br\/><br\/>There is broad agreement that the current state of educational preparedness of students in STEM areas is inadequate and that improvement in these areas is critical both for American technological leadership and for an informed, policy-making citizenry. This research works to improve science education with engaging tools that tackle one of the most difficult science educational issues: deep conceptual understanding applied to real-world situations. This project team applies an elegant technological approach to an helping learners connect the abstract science concepts they are learning about to the real world they live in. Computer vision and augmented reality will be integrated and refined in a way that addresses the needs of learners. The team will make the programs and curriculum freely and broadly available via Web-based distribution and access.","title":"EXP: Deepening Conceptual Understanding with Hands-on, Augmented-Reality Experimentation","awardID":"1217301","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":[517707,"553187"],"PO":["562669"]},"193386":{"abstract":"The security of cryptographic tasks is formally defined by precisely specifying the physical assumptions regarding the attack model, and cryptographic protocols are proven secure based on well-defined computational intractability assumptions. Understanding what the minimal computational and physical assumptions are for secure cryptographic protocols is of central importance to this study which will address the following problems:<br\/>1. New Barriers for Computational Assumptions: There exists a large body of work on, so-called, black-box separations aiming at elucidating when a cryptographic task cannot be based on a particular computational assumption using certain black-box proof techniques. However, many known constructions and proofs of security do not fall into the framework of such techniques, and as such it is not clear to what extent such separations represent a real barrier. One of the principal goals of this proposal is to develop a framework for providing non-black-box separations between cryptographic tasks and assumptions. <br\/>2. New Barriers for Physical Assumptions: Formal definitions of security make explicit assumptions about how the adversary can access or modify information exchanged during a cryptographic process. Traditionally, it is assumed that the attacker participates in a single execution of a protocol, does not get to see the internal state of honest parties, and does not get to tamper with the internal state of honest parties. Recent work has focused on relaxing the first two assumptions. Another principal goal of this proposal is to investigate to what extent the third physical assumption regarding tampering may be weakened.<br\/><br\/><br\/>Progress in this area could have broad impacts on barriers not only in cryptography but also computational complexity and secure systems. The research focusing on physical assumptions bears a promise to have broader impacts on hardware design. The results of this work will be widely disseminated via conferences, journals, workshops, and invited talks, and incorporated into the PI graduate courses.","title":"AF: Small: New Barriers in Cryptography","awardID":"1217821","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[517989],"PO":["565264"]},"199931":{"abstract":"Project description: This is funding to support the third annual doctoral symposium and meeting of the Principal Investigators (PIs) for the NSF Social-Computational Systems (SoCS) program that will be held in the summer of 2013. All PIs and co-PIs funded through the 2010, 2011, and 2012 SoCS programs will be invited to attend, as well as a few other distinguished researchers. Researchers will share ideas and insights with each other about research in the emerging new area of social computational systems, with the specific goal of helping to strengthen the nascent research community. A doctoral symposium will be held prior to the beginning of the PIs meeting. Participating students will experience a full day of presentations and discussions of doctoral research, mentored by a diverse set of experienced faculty.<br\/><br\/>Intellectual merit: Systems in which people and computers work together in a socially intelligent manner represent a new form of computing that brings together the challenges of traditional computing (e.g., algorithms, information representation, information acquisition, data quality) with those of human interaction (e.g., cognition, social interaction, culture, learning) and indeed a whole host of new challenges related to the combination of humans and computers (e.g., computer reasoning about human knowledge and abilities, socially-intelligent human-computer interaction, social computing). Individuals and groups have been working on particular problems in this space for decades, but this work has often been carried out in research pockets connected to existing fields, and unfortunately isolated from each other. As the NSF SoCS program illustrates, there is good reason to believe that the widespread work in social-computational systems would benefit from cross-fertilization and from bringing together diverse researchers into a meaningful community. The SoCS doctorial symposium and PI meeting is one step in that process. Doctoral students pursing SoCS research face numerous challenges, including defining research that spans computing and human elements, but also identifying meaningful evaluation for their research (often in the absence of close precedents) and positioning their research to fulfill the requirements of disciplinary dissertation committees. The doctoral symposium will help students hone their dissertation projects so that they can make better contributions to the solution of these intellectual challenges, and also help them build a social network of fellow doctoral students and more senior researchers to support their careers. The PI meeting will feature tutorials that build common ground among researchers from various disciplinary backgrounds. A series of small poster sessions will allow PIs to engage with the emerging results of other SoCS-funded projects and get feedback on their own work.<br\/><br\/>Broader impacts: Many of the biggest challenges in successfully deploying computer systems in organizations come down to the difficulty of adapting technology to human organizations and vice versa. The development of the SoCS field will directly create new knowledge and understanding in how to more successfully manage the relationship between social (human) organizations and the computer tools they use to work together more effectively. This new understanding has the potential to directly benefit a wide variety of users of information technology. The development of doctoral students is itself a key broader impact. As a result of the PI Meeting, participants will be in a stronger position to do SoCS research. New collaborations and new grant proposals are two anticipated concrete outcomes.","title":"SoCS: Workshop: Principal Investigator Meeting 2013","awardID":"1257254","effectiveDate":"2012-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["543781"],"PO":["565342"]},"197511":{"abstract":"Network simulation continues to be an indispensable tool for performance evaluation of wireless network protocol stacks for it's ability to explore fine-grained causal input-output relations and network scalability aspects, that cannot be readily studied by other means. This project will add much needed ingredients to ns-3 (the most commonly used open source simulation tool for networking research) and extend its capabilities beyond those in comparable commercial tools in important ways. <br\/><br\/>Network simulation methodologies face a fundamental dilemma - increased realism only comes with greater simulator complexity. The pathways proposed provide the best, most realistic approaches to achieving a proper balance. The agenda broadly concentrates on a new wireless protocol stack library that efficiently incorporates cross-layer design approaches that capture the coupling between parameters at Layers 1-2 and protocol elements at Layers 3-4. Further, coupled simulation-emulation approaches that balance the flexibility of the former (software simulation) with the fidelity of the latter (testbed or emulator) will enable new design and performance analysis techniques. All freeware will be disseminated via the ns-3 website (www.nsnam.org) under usual GPL and publicized via tutorials at conferences and workshops.","title":"CISE EAGER: Achieving Realism in ns-3 Wireless Network Simulation","awardID":"1244643","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[529904],"PO":["557315"]},"198974":{"abstract":"What drives ethical treatment of others? Do we learn ethical values\/behavior only as children or can ethics be taught effectively later and, if so, how can ethics best be taught in the high-tech age? Can computer games successfully pose moral dilemmas ranging from personal choices to ones specific to certain professions such as medicine, law, computer science, and engineering? Can we develop games that are culturally and contextually-rich yet universal enough to have broad appeal while not privileging one set of values or ethical system? The PI's goal in this exploratory research is to tackle questions such as these, as Stage 1 of the Ethical Games Project to include a summer internship program, an undergraduate class, and a graduate seminar testing the importance of an empathy-inducing intervention on students' ethical action and ethical self-examination, as measured by a variety of psychometric and ethnographic tests. Pre- and post-tests of ethics will be administered to 40-50 students participating in journal writing and conducting\/analyzing narrative interviews with someone \"different\" (an elder) as well as with a moral exemplar (a philanthropist or someone who has saved another person's life). The \"intervention\" will consist of the students putting themselves in the place of another via the narrative interviews, and will ask about the impact of such empathetic intervention on students' ethical action and ethical self-examination. The project thus will focus on two foundational conceptualizations of ethics: ethics as behavior that furthers human well-being, and ethics as thinking reflectively about the consequences of one's action. The project will ask about both the reliability of such tests and the relationship between empathy and ethics, by comparing results of different measures on subject and control groups. By these means the PI hopes to understand how best to conceptualize, operationalize and measure ethical self-reflection, ethical action and empathy, and also the possible relationships existing among empathic involvement and the diverse measures of these ethical phenomena. In particular, she will attempt to determine how the different measurements relate to each other, whether and how the substantive relationship detected between empathy and ethics is affected by the different measures employed, and whether certain measures privilege particular values (justice vs. compassion, deliberative vs. non-reasoning) or groups<br\/><br\/>Broader Impacts: If successful, project outcomes will lay the groundwork for future work on socio-cultural variations and will elucidate the value-structures latent in psychometric and ethnographic tests and ethical games, which in turn will form the basis for a larger project that will develop a game for computers, tablets, and mobile phones, thus utilizing 21st century technology to test one of the oldest ideas in ethics, namely that empathic involvement with another fosters and encourages more compassionate and ethical treatment of that person or group. Such a game could provide a cost-effective way to teach ethics and reach audiences now left untouched by traditional teaching methods.","title":"EAGER: The Ethical Games Project: Measuring Empathy and Ethical Action, Detecting Empathy's Impact on Ethics","awardID":"1252209","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7787","name":"EESE"}}],"PIcoPI":[533797],"PO":["565227"]},"193287":{"abstract":"This project presents a software system to have the smartphone itself deal with the abnormal battery drain (ABD) issues that are caused by 'battery bugs' in smartphone applications or system software as well as by battery-related configuration errors and environmental changes. The proposed system architecture contains four subsystems, namely information collection, data analysis, diagnosis, and resolution, to self-detect, self-diagnose, and self-recover with little user intervention if possible when ABD events happen. Various technical methods, including machine learning and statistical approaches, will be investigated to achieve the design goal.","title":"CSR: SMALL: Automatically Detecting, Diagnosing and Resolving Abnormal Battery Drain Issues on Smartphone Systems","awardID":"1217408","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["525662","551097"],"PO":["565255"]},"198501":{"abstract":"In wireless networks it is critical that power consumption by the communication system is minimized. This calls for new exploratory approaches which incorporate coding, power minimization, and transmission techniques integrated in a system design beyond the current methods. Wireless relay networks in the context of cooperative communications provide favorable platform to address this challenge. Cooperative communications is regarded as one of the few enabling physical layer technologies for wireless networking. By employing relays for joint power and location optimization in cooperative communications, the potential benefits are substantially enhanced. The goal of this proposal is to investigate a mixed-integer nonlinear program (MINLP) which is NP hard, in the formulation and solution of the problem of joint power allocation, relay location, and extended to coding. Lower energy consumption is achieved due to smaller distances between relays and the terminals, spatial diversity, and efficient signal processing schemes such as distributed beam-forming and distributed space time coding. The near optimal solution is found using the combinatorial problem under several relaying architectures. The following cases are investigated: 1) BS-only architecture, 2) single relay per MS, 3) multiple relays per MS, 4) distributed beam-forming, and 5) distributed space-time coding. This project also develops interdisciplinary educational material and courses on wireless communications with the goal of bridging the gap between networking and wireless communications curricula via new interdisciplinary courses. Undergraduate and graduate students will be involved with components of the project that are applicable to their level of interest and ability.","title":"EAGER: Optimal Power Allocation and Relay Selection with Spatial Diversity in Wireless Relay Networks","awardID":"1249364","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[532618],"PO":["557315"]},"195125":{"abstract":"The NSF Sustainable Energy pathways (SEP) Program, under the umbrella of the NSF Science, Engineering and Education for Sustainability (SEES) initiative, will support the research program of Prof. Sridhar Viamajala and co-workers at the University of Toldeo, Prof. Robin Gerlach and co-workers at Montana State University, and Prof. Gregory Characklis of the University of North Carolina at Chapel Hill. This project will focus on high lipid-producing native alkaliphilic algae which are less susceptible to detrimental contamination (due to their extreme growth environment) and able to accumulate large amounts of lipid. In addition, the project will develop and test low-energy options for cell harvesting as well as for fuel and high value product generation. Through integration of unique and robust advances in algal culture stability and productivity as well as research targeted on the critical processes of algae harvesting and conversion of biochemicals, scalable, environmentally and economically acceptable processes to produce renewable fuels and chemicals will be developed. <br\/><br\/>The results of this project will be of interest to industry, local communities, regulators, and academia. Specific outreach efforts will be directed towards each of these primary stakeholders through: (1) dissemination of research outcomes to local community members and industry stakeholders at conferences, trade meetings and by local community and legislator engagement; (2) engagement of underrepresented Native American students from Montana high schools and tribal colleges in summer research activities as well as undergraduate researchers in the PIs' laboratories; (3) education and training at the K-12 level through training of high school teachers; (4) development of an interdisciplinary distance-learning course sequence on \"Sustainable Biofuels\" that will cover broad topics on the fundamental biology, chemistry, engineering and sustainability aspects of biofuel production; (5) generation of information useful in making informed judgments regarding tradeoffs between cost and environmental impact using the results of the life-cycle analyses.<br\/><br\/>This sustainable energy pathway minimizes energy and materials requirements through use of low-energy chemical and biological processes coupled with nutrient and water recycle. The global warming potential (GWP) of such biorefineries would be significantly lowered through the use of energy-efficient cultivation, harvesting and conversion methods as well as by minimizing external demands for nutrients and water. Overall, these solutions to the challenge of economic and sustainable energy from algae will be transformative through the development of novel scientific and technical advances, balanced with environmental, economic and societal merits. These algal farms will not compete with arable lands, food production, or use high quality water.","title":"SEP Collaborative: Alkaliphilic microalgae-based sustainable & scalable processes for renewable fuels and products","awardID":"1230632","effectiveDate":"2012-09-15","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"8026","name":"Sustainable Energy Pathways"}}],"PIcoPI":[523023,"552035",523025],"PO":["556345"]},"194036":{"abstract":"While policy interest and empirical research on cyber attacks have both increased substantially in recent years, very little attention has been focused on the local ecology of actively operating computer networks. In the research proposed we focus on a bazaar computing environment (i.e. weakly fortified computer networks where a wide variety of users engage in a range of activities with minimal security in largely unregulated settings) and seek to answer three broad research questions: (1) can users within bazaar environments be educated to engage in less risky on-line behavior? (2) can hackers within bazaar environments be deterred through available options? and (3) if users can be educated and hackers can be deterred what is the optimal environment in which IT management can maximize education of users and deterrence of hackers within weakly fortified environments? The proposed research represents a collaboration between criminologists, psychologists, and computer security experts and will evaluate criminological theories within cyberspace using, in addition to survey data and experimental design, detailed network and target computer data drawn from the real time operation of an organization network. <br\/><br\/>Intellectual Merit <br\/>A major goal of this project is to move toward a new integrated social science perspective on cybercrime. The pathway to such integration is through the social ecology of a local computing environment. The research proposed here, which simultaneously examines the characteristics of users-victims, offenders-hackers and the computing environment where they interact, will provide a rare opportunity to integrate these situational components. In addition to providing new insights into criminology theory, the proposed research will provide detailed information on the interaction of hackers and users within the context of a weakly fortified computing environment.<br\/><br\/>Broader Impact <br\/>We believe that our ecological approach to cyber security will offer useful insights for ways of improving online security by identifying those system configurations that discourage victim behaviors that are especially likely to result in attacks and deter attackers from malicious activities. Bringing information together from potential victims and offenders within the world of an operating computer environment will allow the development of more efficient safety programs and strategies and has the potential to increase the security of computer systems and strengthen users' confidence and trust in their systems and the cyber environment more generally.","title":"SBES TWC: Phase: Small: Protecting the Bazaar: The Ecology of Cybersecurity in Weakly Fortified Networks","awardID":"1223634","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["535155",519631,519632,519633],"PO":["550223"]},"199602":{"abstract":"The distinction between computing and communication has blurred with the improvements in semiconductor technology as well as the speed and reliability of computer networks. At a macroscopic level, individuals increasingly rely upon smart phones, cloud computing, and similar infrastructure that combines computing systems with networking to accomplish their daily tasks. Advantages are realized from the seamless interconnection of computing systems and the network. Many end-users even consider the client device, the server, and the network as one unit that is used for productivity and\/or entertainment. At the microscopic level, similar efficiencies present themselves when computing and networking blend. In an ideal case, the linkage between the two areas should not require the use of special-purpose software, because installing software on a network node to enable this blending can potentially cause the node to be unstable, more complex, and introduce security flaws. However, there is a significant challenge in linking the two domains without the use of additional software. This research focuses on understanding and characterizing the connection between the computing node and the network. <br\/><br\/>Since the internal components of a node are shared resources between all processes, including those that require network-based I\/O, it is possible to infer the load on the internal components by observing variations in delay between successive network packets that are generated by the node. This inference materializes as a \"delay signature,\" and can be used to blend the areas of architecture and networking. Specifically, this information can be used to develop algorithms for network security and management. For example, by simply probing a node and collecting its responses, it can be determined that the internal components (e.g., microprocessor) are heavily utilized. If the node is expected to be idle, this could be an indication that the node has been compromised and is running unauthorized software. This information can also be used for job scheduling in cluster grids. By monitoring Message Passing Interface (MPI) messages between grid nodes, the loads on the nodes can be determined without querying nodes directly. As a result, resource discovery messages are not needed. Another use of this information can be to predict system degradation and failure. As a node's resources become exhausted, the node generates a unique traffic pattern. This pattern is emitted prior to node failure and can be used to signal a switch to a secondary server.<br\/><br\/>This project uses a holistic approach that combines computer architecture and computer networking to investigate and characterize how the microarchitecture affects the network packet generation process. The delay signature provides information that can be attributed to the internal state and settings of the microarchitecture. Architectural settings, such as processor affinity, multi-threading, and power-saving modes, affect the delay signature. The PIs use a hardware testbed and a system simulator to characterize the basic mechanisms within the microprocessor that are manifested in the observable delay signature. <br\/><br\/>The investigators incorporate team-based laboratory projects within their computer architecture and computer networking courses to demonstrate the relationship between the two domains and to promote integrated learning by students in both areas. Potential applications of the delay signature include providing security for networked nodes by monitoring unauthorized utilization and increasing resiliency of a computing system by detecting patterns that predict a node failure.","title":"EAGER: Collaborative Research: Characterizing Microarchitectural Mechanisms for Network Delay Signatures","awardID":"1255809","effectiveDate":"2012-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["549985"],"PO":["366560"]},"198755":{"abstract":"The University of California at Berkeley proposes to support an emerging online Community of Practice (CoP) for the CS10K Project. CS 10K is a transformational initiative to engage, prepare, and train 10,000 high school teachers to teach two new computing courses: Exploring Computer Science and CS Principles. The National Science Foundation (NSF) is funding a number of projects that are developing models of professional development (PD) for these courses and as many as 500 teachers will have taken some form of this PD by the Fall of 2012. Many of those teachers will begin teaching these courses this fall, but will find themselves somewhat isolated as the only Computer Science teachers in their schools. To better support them and provide an ongoing learning community for them, an online CoP is being developed that will serve as a testbed for future CoP development. This proposal aims to create and oversee a Technical Working Group (TWG) that assist with the content and operation of the initial testbed CoP as it is refined and eventually grows into a tool to support all computing teachers. The work will maximize the impact of CoP effort by (1) engaging the leaders of the current NSF-funded CS 10K PD in contributing content and seeding online interactions, (2) providing feedback and suggestions to the developers of the CoP, and (3) responding in real-time to the data that is being collected on how the CoP is being used and how it serving or not serving the needs of the teachers.","title":"RAPID: Facilitating a CS-10K Community of Practice Testbed","awardID":"1250783","effectiveDate":"2012-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[533235],"PO":["561855"]},"195268":{"abstract":"This project develops a portable power-assist orthosis to address the problems of impaired mobility due to lower-extremity weakness. This robotic orthosis actively assists the user's joint motion according to his or her motion intent, and thus enables the user to perform certain critical, power-consuming tasks (such as the sit-to-stand motion) independently. The orthosis is powered with a high-performance actuation approach, namely chemo-fluidic actuation, which combines the high-power-density pneumatic actuators with a high-energy-density monopropellant-based pneumatic supply. In addition to the new actuation approach, the orthosis also features a new structure and user interface for effective load transfer and easy donning-doffing; and an effective motion control algorithm to enable interactive power assist according to the user's motion intent. With the portable power-assist orthosis, the users reduce the reliance on the assistance by caregivers, enjoy a significantly improved life quality, and stay physically active to avoid the aforementioned issues associated with the sedentary life style.<br\/><br\/>This project has broader impact to assistive technologies and can improve mobility of elderly individuals and people suffering from the impaired mobility due to lower-extremity weakness. The project can potentially reduce a considerable amount of physical assistance taking care of these individuals, and the cost of time and manpower in the care. The research of the project is incorporated into education activities by utilizing the rehabilitation robotics as an innovative education medium.","title":"SHB: Type I (EXP): Collaborative Research: A Portable Power-Assist Orthosis to Aid Elderly Persons in Locomotion","awardID":"1231604","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[523469],"PO":["564316"]},"199503":{"abstract":"This work seeks to understand the extent and impact of personalization algorithms in popular on-line forums. In particular, the PI is studying web search engines, social networking sites, and recommendation services like Pintrest, Yelp and Reddit. While it is well known that each of these classes of information sources perform extensive personalization, there has not been a careful analysis on the impact of their efforts on what users see. This effort is working to answer a number of fundamental questions: How different are the experiences of distinct users? What features do the services use as input to their personalization algorithms? How are they gathered, and where are they stored? To the extent that the services display different information to different users, are users aware, and can they - or third parties - manage and exploit these changes? <br\/><br\/>This research project aims to understand the impact of various forms of information manipulation - as opposed to outright censorship - on the Internet. Personalization algorithms in particular are known to have the potential to place users inside ?filter bubbles?, where they see only information that already aligns with their viewpoints. In the worst case, adversaries can actively manipulate how content is produced, discovered, and accessed. This work will develop technologies to give users control over the information that they see to mitigate the effects of information manipulation. Concrete outcomes of this effort include prototype mechanisms to help users ?normalize? personalization technologies and potentially move between alternate on-line ?personalities.?","title":"EAGER: Personalization in the Information Age","awardID":"1255274","effectiveDate":"2012-09-01","expirationDate":"2014-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["548363"],"PO":["565264"]},"198777":{"abstract":"This proposal provides funding for the first GREPSEC: Underrepresented Groups in Security Research workshop, which will be affiliated with the annual IEEE Symposium on Research in Security & Privacy, in May 2013, in San Francisco CA. <br\/><br\/>USC\/ISI will organize a day-and-a-half long workshop for women and underrepresented minorities in computer security and privacy. The workshop will be held May 18-19, 2013. This is the weekend before the IEEE Computer Society's Security and Privacy Symposium, the premier conference in security, and this workshop will be co-located in San Francisco, California.<br\/><br\/>The broad goal of the workshop is to increase the number of women and underrepresented minorities in computer security research. Security is a wide field, encompassing network security, operating system security, language-based security, forensics, privacy, as well as legal and policy issues.<br\/><br\/>The goal of the organizers is to encourage PhD students who are female and from underrepresented groups to choose security as their field of specialization. Their approach is to show the wide range of problems within the field and how women and underrepresented groups are working towards solving those problems.","title":"GREPSEC: Underrepresented Groups in Security Research","awardID":"1250972","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["561510"],"PO":["565327"]},"194069":{"abstract":"To lower costs and improve outcomes in current medical practice we need integrated interoperable medical systems to provide machine-assisted care, interaction detection, and improved alarm accuracy, to name just a few uses. This project is developing both the theory and practice to ensure the safety of next-generation medical devices by allowing secure coordination and composition, in facilities as small as a local doctor's office or as large as a multi-campus hospital. Connected devices are part of a \"medical coordination platform,\" which allows execution of \"clinical workflows,\" such as having a blood pressure cuff automatically take a reading once an infusion pump stops delivering medication, or determining in real time whether prescribed medications are contraindicated by a patient's past health history.<br\/><br\/>Such manufacturer- and integrator-agnostic communication is difficult to bootstrap and perform securely, but security is required, since networked insecure systems are fundamentally unsafe. Furthermore, medicine is more complex than many other domains: security and quality of service properties must hold even environments where many different people have physical access to devices and communication infrastructure. Without fully trusting individual components, we must provide strong resource isolation, patient privacy protection, and real-time trust reasoning in highly-dynamic, adversarial, and life-critical systems.<br\/><br\/>We aim for speedy transition to practice by providing reusable security, privacy, and logging components for existing open medical application platforms, supporting varying hardware capabilities, laws, regulations, and facility-local policies, as well as software for pre-deployment and run-time trustworthiness reasoning about the system and individual devices.","title":"TWC TTP: Small: Security, Privacy, and Trust for Systems of Coordinating Medical Devices","awardID":"1224007","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["563763","559268","562257"],"PO":["565327"]},"195169":{"abstract":"The NSF Sustainable Energy pathways (SEP) Program, under the umbrella of the NSF Science, Engineering and Education for Sustainability (SEES) initiative, will support the research program of Prof. Hemant Pendse and co-workers at the University of Maine. The highly multi-disciplinary team will develop a framework for evaluating and comparing biofuel technologies by integrating the disciplines of engineering, environmental science, economics, and policy. As a baseline, the framework will be applied to Formate Assisted Pyrolysis (FORMAP) which is a transformative new \"drop-in\" (infrastructure compatible) hydrocarbon biofuel technology. Project efforts will culminate in a multi-criteria decision-making analysis (MCDA) tool. The research will include work to (1) Evaluate the environmental impacts of each stage of the product life cycle based on various feedstock, processing, component recycling and production scenarios related to the FORMAP technology, and (2) Evaluate possible policy, legal and social acceptance barriers to swift implementation of the new technology. This combined with the MCDA tool will culminate in an Energy Pathway Readiness Level (EPRL) scale, by which this FORMAP technology and other energy technologies could be evaluated for their \"readiness\" for deployment in the commercial arena in other regions. The FORMAP chemistry is transformative as it makes possible a paradigm shift away from the heterogeneous catalytic post-processing, which is currently the most studied pathway to improve pyrolysis. This project takes FORMAP to real biomass derived intermediates rather using synthetic reagents. <br\/><br\/>The research will provide guidance on the most sustainable pathway for public and regulatory acceptance, and commercialization. While the proposed research is focused on the Northeast region, the research results will be broadly applicable other regions in the United States. Since a broad suite of technologies will be necessary to reduce the overall dependence on petroleum, the analyses will make it possible to systematically marry feedstock production, fuel production, and product distribution technologies for a particular region. Education initiatives will utilize online delivery to improve the size and scope of the audience. Taken in total, education and outreach efforts will promote applied workforce development for those entering or currently working within the biofuels industry. Experience in interdisciplinary research collaboratives and undergraduate and graduate student research projects will promote the next generation of scientists and scientific discoveries.<br\/><br\/>The research will support development of a new process, FORMAP, which has the potential to renewably replace petroleum products with new drop-in biofuels that can be used for aviation and ground transport. The proposed research will result in the development of a multi-criteria decision-making analysis (MCDA) tool that will allow national and international researchers in other regions to optimize the overall sustainability of advanced biofuels through alterations to feedstock choices, production processes, and transportation and distribution alternatives that are locally appropriate. Detailed chemical characterization and process models developed by the project will provide data for the economics and integration of FORMAP into existing petroleum fuels infrastructure.","title":"SEP Integrated National Framework for Cellulosic Drop-in Fuels","awardID":"1230908","effectiveDate":"2012-09-15","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"8026","name":"Sustainable Energy Pathways"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[523166,523167,523168,523169,"547255"],"PO":["556345"]},"189614":{"abstract":"Computer performance has doubled many times over during the past 40 years, but the very techniques used to achieve these performance gains have made it increasingly difficult to build systems that are provably safe, secure, or reliable. This fact significantly impedes progress in the development of our most safety-critical embedded systems such as those found in medical, avionic, automotive, and military systems. A transformation in the way that these systems are created is needed, one that uses new hardware design techniques, computer architectures, and programming languages to create classes of hardware\/software systems with formal and provable safety properties that are verifiable all the way down to the implementation level of bits and logic gates.<br\/><br\/>This research will change the way that hardware and embedded systems designers approach the problem of provable properties, enabling them to directly control and analyze the system at the lowest level and to statically determine if their designs are in compliance with a given policy. For example, if a system must be real-time this property can be verifiable for a full system, from gates to software, by ensuring that the architecture design carefully manages interference through a set of new hardware primitives, software designed to exploit these new primitives, specialized hardware analysis tools, and new design languages. To ensure this technology will have impact beyond academia the PIs are making these new technologies available and accessible through easy to use tools, continuing to include undergraduates at all levels of research to help train a new generation of engineers capable of designing safety-critical systems, and integrating concepts from information assurance into their extensive outreach activities. Over the long term this research will help create the skills and tools that embedded system engineers need to evaluate the trustworthiness of their systems, and it will ease the development of those critical systems on which we all depend on for our safety and livelihood.","title":"SHF: Medium: Collaborative Research: Building Critical Systems with Verifiable Properties Using Gate Level Analysis","awardID":"1162187","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["527086","550234"],"PO":["565264"]},"198205":{"abstract":"This INSPIRE award is partially funded by Research in Networking Technology and Systems Program in the Division of Computer and Network Systems in the Directorate for Computer and Information Science and Engineering, the Manufacturing Enterprise Systems Program in the Division of Civil, Mechanical and Manufacturing in the Directorate for Engineering, and the Communications and Information Foundations Program in the Division of Computing and Communications Foundations in the Directorate for Computer and Information Science and Engineering. <br\/><br\/>This project addresses common problems across two traditionally separate disciplines of manufacturing and networking by focusing on the following applications in the two fields-advanced semiconductor manufacturing and virtualized data center networking. Research in each field has heretofore focused on different problems, with semiconductor manufacturing largely focused on throughput maximization, mean cycle time minimization and system stability and cloud networking on network performance guarantees. However, the two areas would benefit from sharing a common integrated focus and a unifying stochastic processing network model for modeling and analyzing problems. This project contributes this new mathematical foundation along with a set of practical service disciplines and scheduling algorithms to enable reasoning about and to provide performance guarantees in stochastic processing networks. In particular, this project will concurrently investigate the problems of delivery guarantees in semiconductor manufacturing and network performance guarantees in virtualized data centers so that the two application domains can inform each other and by doing so develop new solutions that might not otherwise be imagined. <br\/><br\/>The central contribution of the proposed work will be a new mathematical foundation, which the principal investigators call Stochastic Processing Calculus that will allow researchers and practitioners to reason about and provide performance guarantees for diverse range of applications that can be modeled as stochastic processing networks. Scientific discoveries often happen at the intersection of two disciplines. This project involves very competent and accomplished researchers (in the areas of networking, network theory, and industrial systems engineering and operations research) and crosses diverse disciplines with the intension of looking at a set of intersections as it explores and advances Stochastic Processing Calculus. The contributions from this effort include exploring this new area of mathematics and in its potentially transformational application to each of the two research areas. <br\/><br\/>Broader Impact: This INSPIRE project is transformational in that it promises to deliver a new rigorous modeling and analytical framework that can encompass a broad range of emerging networking problems. New analytical and algorithmic results that will be developed for the general abstraction of stochastic processing network are expected to have broad applications in a diverse range of fields. More broadly speaking, the proposed work is transformational in that it will contribute to a larger body of 'Network Science'. Network Science is being recognized as an emerging field in its own right in that many of the mathematical foundations and network algorithmics developed in the networking community are finding wide applications in many other fields.","title":"INSPIRE: Stochastic Processing Calculus: A New Methodology for Advanced Semiconductor Manufacturing and Data Center Networking","awardID":"1248117","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"8078","name":"INSPIRE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0704","name":"Division of EMERGING FRONTIERS IN RES & IN","abbr":"EFRI"},"pgm":{"id":"7951","name":"ENG INTERDISC RES (IDR)"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0706","name":"Division of DESIGN & MANUFACTURING INNOV","abbr":"DMI"},"pgm":{"id":"1786","name":"MANFG ENTERPRISE SYSTEMS"}}],"PIcoPI":[531923],"PO":["565090"]},"198106":{"abstract":"Spectrum efficiency refers to the information rate that can be transmitted over a given bandwidth in a specific communication system. It is a measure of how efficiently a limited frequency spectrum is utilized. In this project, innovative spectrum efficient waveform designs are studied towards narrower mainlobe and lower sidelobe in spectrum. It has been recognized that judicious use of properly designed waveforms, coupled with advanced receiver strategies, is fundamental to fully utilizing the capacity of the electromagnetic spectrum. This project seeks innovative approaches on nested and co-prime samplers for spectrum efficiency, and subsequently applies it to wireless networks. Different waveforms designs and diversities are studied based on nested and co-prime samplers. Co-prime samplers are used for Multi-Input Multi-Output communication system. In the application to spectrum efficient wireless networks, nodes exchange information over a common wireless channel. Under different traffic scenarios and different constraints, e.g., bandwidth and signal to noise and interference ratio, the amount of data exchanged among these nodes may vary. A key question then is how the throughput capacity of wireless network improves with the new waveform design schemes and different network setup and how it grows with the number of nodes in the network. This project seeks to help reach the nation's broadband goals and the larger objective of alleviating growing pressure on limited spectrum resources. This project will attract minority and woman students to participate in the project.","title":"Collaborative Research: Spectrum Efficient Waveform Design with Application to Wireless Networks","awardID":"1247694","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7976","name":"EARS"}}],"PIcoPI":[531651],"PO":["557315"]},"188679":{"abstract":"The Team for Research in Ubiquitous Secure Technology (TRUST) REU Site integrates cyber security, privacy, and trustworthy systems with science and technology education to be intellectually, socially, and politically relevant and attractive to a diverse set of participants?in particular underrepresented minorities and women. The program project is a collaborative effort led by the TRUST Science & Technology Center that has six components: (1) an eight-week summer immersion research residency; (2) a series of symposia and advising workshops targeted at recruiting undergraduate Science, Technology, Engineering, and Mathematics (STEM) students interested in security and privacy; (3) a novel and innovative curriculum with learning activities coupled with social interaction and fun aspects of computer science and cyber security for two-year and four-year students; (4) cyber-enabled learning environments to connect participants and researchers; (5) industry seminars and field trips to highlight research trends and career opportunities in cyber security; and (6) post-session research conference participation.<br\/><br\/>Keeping information and computer systems secure is one of the country?s most formidable challenges. Daily headlines chronicle the fraud, viruses, privacy abuses, network outages, and security vulnerabilities across the spectrum of critical systems that support the nation?s financial, energy, healthcare, and transportation infrastructure. As such, technological research must consider security in a hierarchy of approaches that range from secure embedded systems to complex interdependent systems. However, creating secure, private, and trustworthy systems cannot be accomplished solely through technological means. To create secure, private, and trustworthy technology and systems requires an understanding of the relationship between the component parts and how one domain interacts with the other. Thus, there is an acute need for human resources who possess a deep understanding of the technical and non-technical foundations of STEM and trustworthy systems. In order to address this, the TRUST REU Site will blend cyberinfrastructure-enhanced discovery and learning opportunities with interdisciplinary research using the active-learning Peer-Led Team Learning approach to incorporate STEM, cyber security, and trustworthy systems science and technology concepts to create a research and education environment that will train the next generation of computer scientists and engineers who will develop new trustworthy systems.<br\/><br\/>Beyond the main goal of increasing the number of women and underrepresented minorities attaining baccalaureate degrees in STEM and continuing on to graduate education and technical careers, this program will have a broader impact on the cyber security and trustworthy systems community by becoming a model for collaborative secondary education partnerships that incorporate community college and undergraduate programs within a STEM educational framework. The program will emphasize four stages of the education pipeline (Recruitment, Transfer, Retention, and Advancement) and aim to capture students early enough in the pipeline that they will consider pursuing a major or career in STEM in general and cyber security in particular. The TRUST REU Site will also demonstrate how collaborative partnerships with operational strategies that support effective and engaging learning experience can inject resources designed to stimulate interest in STEM and cyber security among female and URM community college and four-year baccalaureate students and serve as a model for cyber security and trustworthy systems research and education projects at similar institutions in the future.","title":"REU Site: TRUST-REU SITE: Cybersecurity and Trustworthy Systems Research","awardID":"1157075","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"1139","name":"RSCH EXPER FOR UNDERGRAD SITES"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"1668","name":"FED CYBER SERV: SCHLAR FOR SER"}}],"PIcoPI":["526900",505946],"PO":["564264"]},"198139":{"abstract":"Spectrum efficiency refers to the information rate that can be transmitted over a given bandwidth in a specific communication system. It is a measure of how efficiently a limited frequency spectrum is utilized. In this project, innovative spectrum efficient waveform designs are studied towards narrower mainlobe and lower sidelobe in spectrum. It has been recognized that judicious use of properly designed waveforms, coupled with advanced receiver strategies, is fundamental to fully utilizing the capacity of the electromagnetic spectrum. This project seeks innovative approaches on nested and co-prime samplers for spectrum efficiency, and subsequently applies it to wireless networks. Different waveforms designs and diversities are studied based on nested and co-prime samplers. Co-prime samplers are used for Multi-Input Multi-Output communication system. In the application to spectrum efficient wireless networks, nodes exchange information over a common wireless channel. Under different traffic scenarios and different constraints, e.g., bandwidth and signal to noise and interference ratio, the amount of data exchanged among these nodes may vary. A key question then is how the throughput capacity of wireless network improves with the new waveform design schemes and different network setup and how it grows with the number of nodes in the network. This project seeks to help reach the nation's broadband goals and the larger objective of alleviating growing pressure on limited spectrum resources. This project will attract minority and woman students to participate in the project.","title":"Collaborative Research: Spectrum Efficient Waveform Design with Application to Wireless Networks","awardID":"1247875","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7976","name":"EARS"}}],"PIcoPI":["554394"],"PO":["557315"]},"198029":{"abstract":"This project will deploy a pilot Software-Defined Science Network (SDSN) to interconnect research computing resources on the University of Wisconsin-Madison campus and link them to national WAN circuit fabrics via Internet2. This pilot deployment will support both Computer Science applications such as GENI WiMax experiments and prototyping activities for the University of Wisconsin?s Science DMZ between campus partner sites and the Internet. <br\/><br\/>The project will provide an opportunity to develop an operational model for the innovations promised by OpenFlow. In particular, significant effort will be expended in integrating management tools such as the UW developed web application Authorized Agent Network Tool Suite (AANTS), network monitoring tools such as PerfSONAR and traffic engineering tools such as Netflow\/IPFIX. The GENI toolsets (Expedient, FOAM) will be examined for suitability for enterprise use. UW will partner with Cisco for the OpenFlow rollout. Travel budget is included for sharing and presentations of findings to the broad GENI community and non-technical user communities.<br\/><br\/>Broader Impact:<br\/>The pilot will provide an opportunity to gain experience with architectural, deployment, administrative and operational issues of OpenFlow in campus settings. Integration with WiMax as an extension of the UW production network will allow for advanced opportunities to the research and education communities such as streaming live high definition video from campus natural areas into classrooms. The PIs will report on issues and operational experience associated with the deployment. These reports and the PI?s willingness to share their experience with other universities will reduce barriers to use of GENI from campuses, establish GENI technologies and OpenFlow as building blocks for science networking, inform ongoing upgraded to campus infrastructure in support of domain sciences on campus, and via the partnership with Cisco facilitate the broader deployment of SDN technologies.","title":"EAGER: Central IT Operational Support for Production OpenFlow Networks","awardID":"1247322","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[531450],"PO":["564993"]},"192980":{"abstract":"For centuries, the discovery of scientific laws has been driven by empirical investigation of natural phenomena. However, human capabilities of relationship discovery get strained in multi-dimensional spaces, which in particular may explain why we have not seen any fundamental laws postulated for the structure or behavior of such complex constructs as social networks.<br\/><br\/>This project will exploit the methodological toolbox based on symbolic regression with the objective to assist the human mind in simultaneously searching through multiple social network datasets and detecting stable relationship patterns across them, thus allowing for the discovery of natural social network behavior laws. This project will identify objectively measurable, macroscopic metrics pertaining to social network phenomena and explore under what conditions the computer-enabled empirical approach to knowledge discovery can be successful. The scientific inquiry approach based on the computer-enabled empirical learning paradigm will rely on recent advances in stochastic processes, systems theory, symbolic regression, evolutionary algorithms, and data fusion. Using standard social network metrics, computational experiments will be conducted and their results manually traversed in search for robust expressions (explicit formulae and invariants) corresponding to hidden symbolic laws. This project will benefit organizations and institutions that rely on fundamental understanding of social structures. It will further advances in communications, economics, engineering, psychology, sociology, epidemiology, and other domains engaged in studies of social interaction and behavior. On a broader level, this project will enrich the methodological toolbox of inquiry for other unexplored areas of modern science. Through student involvement activities and outreach, this research effort will enhance the educational environment supported by NSF and fostered at the University at Buffalo.","title":"ICES: Small: Discovering Fundamental Structural and Behavioral Laws of Social Networks","awardID":"1216082","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"1320","name":"ECONOMICS"}}],"PIcoPI":[516976,516977,516978],"PO":["565251"]},"200746":{"abstract":"The complexity of modern high-end computers has made it exceedingly <br\/>difficult for scientific applications to effectively manage resources <br\/>such as extreme-scale parallelism, single-chip multi-processors, <br\/>and deep hierarchy of shared\/distributed caches and memories. In <br\/>particular, as machines and applications have both evolved to become <br\/>complex and massively parallel, compilers have failed to automatically <br\/>bridge the gap between complex software and diverse hardware platforms.<br\/>Optimization models for parallel computing have lagged far behind <br\/>those for serial applications, and conventional compilers are <br\/>increasingly unable to accommodate emerging high-end architectures.<br\/><br\/>This research develops a new optimization model that allows<br\/>1) developers to effectively interact with advanced optimizing <br\/>compilers to provide both domain-specific knowledge and high-level <br\/>optimization strategies (e.g., directions to enable new or choose <br\/>amongst differing parallelization strategies); 2) computational <br\/>specialists to easily define arbitrary domain-specific transformations <br\/>to directly control performance optimizations to their code; <br\/>3) architecture-sensitive optimizations to be easily parameterized <br\/>and empirically tuned to achieve portable high performance.<br\/>The optimization model is supported with an integrated environment <br\/>that contains two main components: ROSE, a C\/C++\/Fortran2003 <br\/>source-to-source optimizing compiler developed at DOE\/LLNL; and POET, <br\/>a transformation language together with an empirical optimization <br\/>engine developed at UTSA. This framework permits different levels <br\/>of automation and programmer intervention, from fully-automated tuning <br\/>to semi-automated development to fully programmable control. The research <br\/>targets both the optimization needs of computational kernels and the more <br\/>general requirements of whole program optimizations. The framework is <br\/>integrated as an external development mechanism for the widely-adopted <br\/>ATLAS library and is connected with empirical tuning research under <br\/>DOE SciDAC program to improve the efficiency of large-scale scientific <br\/>applications.","title":"Programmable Code Optimization and Empirical Tuning For High-end Computing","awardID":"1261778","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["538267"],"PO":["565272"]},"200757":{"abstract":"Mobile robot networks are recently emerging as the most efficient way to address a large variety of tasks ranging from surveillance and search-and-rescue missions to cooperative manipulation and robotic surgery. These networks consist of large and highly interconnected groups of cheap, small and agile agents that collectively result in more modular, robust and scalable systems that can efficiently handle uncertainties, faulty components and design complexity. At the same time, the limited computation, power and communication capabilities of the agents require new communication, cooperation and specialization techniques, that raise fundamental problems on the interface of modern control theory and robotics with the discrete science of communications and networking.<br\/><br\/>The goal of this project is to develop formal methods and algorithms to address the control issues related to integration of the physical (robots) and communication domains, that define mobile robot networks. In particular, the PI is developing distributed techniques to integrate robot mobility, dynamics and constraints with rich models of communication, including power control, fading, priority flows etc. Ensuring task completion, ?loop closure? with graph theoretic approaches in the literature and experimentation are major parts of this research, which offers a number of advantages over other approaches including more realistic models of robot networks that can be implemented with fewer assumptions, lower computational complexity and easiness of distributed implementation.<br\/><br\/>Recent advances in robotic and communications can not be efficiently integrated on real platforms without the necessary theoretical and experimental support. This research provides these necessary components in facilitating the design of mobile autonomous systems and fostering their adoption. An integral part of the research program is also an educational agenda that involves K-12, undergraduate, and graduate level education. The broader impact of the educational program is to introduce new engineers and researchers to the potentials of multidisciplinary research as well as to promote research and engineering careers among pre-college students.","title":"CAREER: Control of Mobile Robot Networks: Integrating the Communication and Physical Domains","awardID":"1261828","effectiveDate":"2012-09-01","expirationDate":"2016-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["541930"],"PO":["565303"]},"193640":{"abstract":"As the number of wireless devices and their prevalence in our lives increases, and as the wireless infrastructures progress from micro-cells to pico-cells and even femto-cells, the interference dominated regime of operation becomes ever more important, and its management ever more critical, for the wireless applications of tomorrow.<br\/><br\/>Interference alignment is an exciting recent development in wireless communication theory that addresses the fundamental problem of interference. The basic idea is to coordinate transmissions in a network so that interfering sources will overlap and concentrate instead of infesting the entire signal space, thus opening up clean signal space at each receiver and allowing a much larger throughput than previously thought possible. However, interference alignment also requires conditions that, in the current state of engineering knowledge, are impractical. Among them are the requirement of global channel state information, and a phenomenon known as bandwidth expansion that has to do with the resolution of observations and the geometry of spaces which must be \"bent\" to overlap the interference.<br\/><br\/>Due in part to these issues, the practical impact of interference alignment on wireless communication remains a question of intense interest. The proposed activity addresses this question via (1) investigating methods that can reduce the requirement of channel state information; (2) investigating methods that can reduce bandwidth expansion and delay; and (3) exploring practical applications where interference alignment can have the most positive impact. This project has the potential to significantly impact the long-term prospects of a wide array of wireless communication devices and networks, including cellular, femto-cells, unlicensed bands, and vehicular networks.","title":"CIF: Small: Exploring the Limits of Interference Networks under Practical Constraints","awardID":"1219065","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[518585],"PO":["564924"]},"194740":{"abstract":"Secure Computation is a powerful concept from cryptography that enables collaboration in the absence of trust. Despite its great potential for solving practical problems in collaborative situations, it has not yet been widely adopted in practice. Indeed, until recently there were few practical implementations of secure computation protocols, and even recent implementations were forced to restrict themselves to weak forms of security for the sake of efficiency. This is because the dominant paradigm for achieving strong security, since the invention of the first such protocols, has relied on zero-knowledge proofs, and yields protocols that are too inefficient even for simple computations.<br\/><br\/>We are developing radically different new architectures for efficient secure computation protocols that bypass the need for such zero-knowledge proofs. Our architectures are based on a novel principled approach to developing new secure computation protocols, with consequences to the theory and practice of modern cryptography. Our research will identify new (partial) security properties inherent in simple protocols, and study how such properties can add up to strong security guarantees through carefully developed methods for composing protocols.<br\/><br\/>Secure multiparty computation is an idea whose time has come, as evidenced by the several projects around the world engaged in translating the theoretical results to practical implementations, and the number of research projects outside cryptography that seek to exploit it. Widespread availability and deployment of secure computation protocols has the potential to be a disruptive technology, enabling new avenues of cooperation in areas with sensitive information. Apart from the technological impact, we strive to bring the advances in cryptography to a broader computer science audience, by integrating our research into graduate and undergraduate education, and outreach efforts.","title":"TWC: Medium: Collaborative Research: Transformative New Approaches to Efficient Secure Computation","awardID":"1228856","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[521634],"PO":["565239"]},"193420":{"abstract":"This research addresses the design and analysis of efficient algorithms for bipartite matching problems. Weighted and unweighted problems are investigated, as well as stable matching variants based on ordinal preferences. Dynamic variants are also considered; here the goal is to rapidly update an optimal solution when a small change is made to the input.<br\/><br\/>There is an intimate connection between weighted bipartite matching and a class of combinatorial auctions known as unit-demand auctions. For example, one fundamental approach to the problem of allocating and pricing items in a sealed-bid unit-demand auction involves computing a maximum-weight matching in a corresponding bipartite graph. This project addresses the design and analysis of unit-demand auctions with multiple rounds of bidding. Such \"dynamic\" auctions are substantially more difficult to analyze than their sealed-bid counterparts, but offer important practical advantages.<br\/><br\/>Certain scheduling problems are also closely related to bipartite matching. This project addresses the design and analysis of algorithms for scheduling-related variants of bipartite matching problems.<br\/><br\/>In spite of decades of research on combinatorial auctions, the predominant auction format available to the general public for auctioning consumer goods remains the single-item dynamic second-price format, as popularized by eBay. This research addresses the design of a scalable infrastructure for supporting the more expressive class of dynamic unit-demand auctions. The key potential benefit of such an infrastructure is enhanced economic efficiency, that is, improved matching of auction items to the bidders who value them the most. Such enhanced efficiency offers direct benefits to society. In addition, the matching and scheduling problems addressed in this project are fundamental in nature and have numerous practical applications.","title":"AF: Small: Algorithms for Matching, Auction, and Scheduling Problems","awardID":"1217980","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[518067],"PO":["565251"]},"193662":{"abstract":"Managing variation is an important part of software engineering. Many existing software projects can already generate a huge number of distinct programs that run on different platforms and provide different feature sets. Research on software product lines and feature-oriented software development has provided processes and tools for the development of massively configurable software, suggesting that the variability of software systems will only continue to grow. A currently largely unsolved problem is how to systematically transform variation representations to support the creation, refactoring, and migration of variation, as wall as the analysis and querying of variation-rich software repositories. The objective of this research is to investigate the systematic transformation of variation structures and develop language support for it. <br\/><br\/>The following technical approach is pursued. First, gathering variation programming tasks will provide a basis for the understanding of the nature and extent of variation transformations, and assembling a catalog of such tasks will aid the design, evaluation, and comparison of variation languages. Second, the definition of the syntax and semantics of a transformational choice calculus, which extends the (representational) choice calculus with computational features, will support the investigation of formal properties of variation programming. Third, the development of a variation type system facilitates the characterization of different kinds of changes and evolutions of variational structures. Moreover, the development of a variation module system will provide an interface between low-level details required by the intricate scoping and binding issues of the choice calculus representation and a more high-level, declarative view of variations. Finally, the design of a domain-specific embedded language for variation programming will allow the easy description of transformations of variation structures in software artifacts. It also supports the experimentation with variation transformations. Since the scope of this research extends beyond professional software and covers also end-user programming systems, such as spreadsheets, the developed methods will be applicable in a wide variety of contexts and can thus empower millions of users to handle variation in a more systematic way.","title":"SHF Small: Language Support for Variation Maintenance","awardID":"1219165","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["548134"],"PO":["564388"]},"193431":{"abstract":"The recently-ratified C and C++ standards, \"C11\" and \"C++11\"<br\/>respectively, add a concurrency model that supports writing<br\/>high-performance, portable code for machines with multiple processors.<br\/>The concurrency model, however, is large and complicated; it is not<br\/>particularly easy for compiler and library developers to get all of<br\/>its corner cases right. Errors in implementing the new model can<br\/>introduce bugs into important pieces of software, such as operating<br\/>systems, web browsers, web sites, database engines, and embedded<br\/>systems, all of which are written, at least partially, in concurrent C<br\/>and C++.<br\/><br\/>The PI's previous work on randomized testing for C compilers uncovered<br\/>more than 450 bugs in production-quality compilers, most of which were<br\/>fixed by compiler developers. The PI's current project extends this<br\/>research agenda to support stress testing of implementations of the<br\/>C11 and C++11 concurrency model. The intellectual merit of this work<br\/>stems from the need to generate random, but standards-conforming,<br\/>concurrent code; the need to synthesize \"test oracles\" that can<br\/>automatically ascertain the success or failure of a test case; and,<br\/>the need to develop \"hostile\" simulators for flushing out errors in<br\/>compiled concurrent code.<br\/><br\/>The expected impact of the PI's work is to significantly reduce the<br\/>period during which implementations of the C11 \/ C++11 concurrency<br\/>model are flaky and immature, and to reduce the lifetime of compiler<br\/>bugs that are introduced during ongoing development.","title":"CSR: Small: Beating Implementations of C++11 Concurrency Into Shape","awardID":"1218022","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550238"],"PO":["565255"]},"193552":{"abstract":"This project performs fundamental cross-disciplinary cross-layered research into the design, implementation, and deployment of next-generation harvesting-based RFID-scale sensing technologies. The effort involves research at the CRFID hardware\/software interface including energy management, data storage systems, and energy-aware computing to advance knowledge and understanding of zero-power pervasive devices. It addresses several fundamental research challenges including: 1) tradeoffs in energy harvesting, storage and usage that can make RFID sensors more programmable while not compromising energy-efficiency, 2) data storage systems that exploit probabilistic flash writes at low voltages, and that can tolerate frequent interruptions of power, and 3) energy management techniques that expose uncertainty-driven energy management interfaces, and schedule tasks in a harvesting-aware manner. <br\/><br\/>Direct economic and social impacts of this project are expected in the design, development, and deployment of next-generation RFID-based sensing applications and businesses including medical, environmental, energy, military, homeland security, and transportation. Other benefits include involvement of female minority graduate students in research, and involvement of minority graduate students through the NSF-funded Northeast Alliance for Graduate Education and the Professoriate (NEAGEP). Further, the research and teaching from the project impacts students across the Five Colleges, which includes two all-women's colleges, Smith and Mount Holyoke, whose students can enroll in courses taught at UMass because of the consortium's cross-registration policy. Curriculum development includes exposing students to challenges at the hardware\/software boundary of ultra-low power devices through new or existing courses, tutorials in conferences, and seminars and demos in science fairs intended for high-schoolers.","title":"CSR: Small: Towards Autonomous, Ultra-Low Power RFID-Scale Sensing Systems","awardID":"1218586","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["526997","554404"],"PO":["564778"]},"191495":{"abstract":"This project is to develop a new robotic platform with novel 3D modeling and visualization algorithms. An existing \"dumb\" welding robot will be augmented with sensors to observe the work piece, as well as its surroundings. New algorithms will be developed to record and reconstruct in 3D the welding process. The reconstructed data are transmitted to a control room and visualized with augmented reality techniques: A skilled welder can look at the welding process from different angles, as if he\/she was right next to the actual welding system. Welding parameters can be adjusted by the human (with intelligence) and executed by the robot (with precision). More importantly, the adjustment, together with the reconstructed welding process, will be recorded and analyzed. System modeling techniques will be developed to correlate the human adjustment with the 3D reconstruction of the welding process. In this way, a welding robot can \"learn by examples\" the knowledge and experiences of a human welder and make similar intelligent adjustments by itself in the future. <br\/><br\/>The primary use for this new technology is in manufacturing. Successful completion of the proposed project paves the foundation for intelligent welding robots with closed-loop intelligent control. Such a robotic system can perform high-speed and high-precision welding while allowing more variations in the work pieces and environments. In addition, virtualized welding can be integrated with a mobile platform to allow welding in places that are hazardous or unsuitable for human welders. The proposed welding extension platform will significantly expand the use of welding robots as well as reduce manufacturing costs. Under-represented students will be recruited to participate in the research through exiting institutional programs. Additional funding and industrial collaboration to transfer technology from research labs to industry will also be pursued.","title":"NRI-Small: Virtualized Welding: A New Paradigm for Intelligent Welding Robots in Unstructured Environment","awardID":"1208420","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":[513264,513265,"523441"],"PO":["563744"]},"193574":{"abstract":"This project supports new and ongoing research on several topics in algorithms and computational complexity. A major focus of the project will be certain combinatorical optimization problems, such as determining the longest common subsequence of two data sequences, that can be formulated as shortest path problems in special networks. The goal is to develop algorithms that provably give close approximations to the correct answer and are significantly faster than existing algorithms. Another goal of the project is to construct sparse spanners for networks, which are subnetworks with few edges that preserve (partially or approximately) the connectivity or distance properties of the original network. A third part of the project will seek to establish inherent limitations on the efficiency of parallel programs in the MapReduce paradigm, which is an increasingly popular paradigm for parallel programming in which computation occurs in a sequence of precisely defined rounds. The aim is to establish some inherent limitations on this model by proving lower bounds on the number of computation rounds needed for certain basic computational tasks. Another part of the project will develop new algorithms and determine limits to efficiency for the file maintenance problem, in which numbers are presented in an online manner and are loaded into a linear array (possibly with gaps between items) so that the left-to-right order of the items matches the natural order. The cost is measured by the total number of times any item is moved during the loading process. The aim here is to obtain better algorithms than the existing ones using randomization, or to establish that randomization can not significantly improve on the best existing algorithms.<br\/><br\/>By advancing the theory of algorithms and complexity, this award will increase the set of tools available for efficient design of algorithms. The algorithmic techniques developed for efficient estimation of dynamic programs may be useful for practitioners developing algorithms for problems such as string matching, which is a fundamental problem that arises in varied areas such as data retrieval and analysis of biological data. Establishing inherent requirements on computational resources for solving various problems can guide the search for improved algorithms for related problems. An important part of the project is the training of graduate students to do research in the field.","title":"AF: Small: Efficient Approximations for Dynamic Programs and Other Topics in Algorithms","awardID":"1218711","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[518427],"PO":["565157"]},"193343":{"abstract":"In virtually every area of science, engineering and commerce, optimization problems arise for which no known solution method is guaranteed to yield satisfactory solutions to large instances using a reasonable amount of computation time. Computational complexity theory confirms the intractability of most of these problems. Nevertheless, these problems demand to be solved in practice, and very often heuristic algorithms work quite well in most cases, although not in the worst case. The unreasonable success of heuristic algorithms is one of the great mysteries in computer science.<br\/><br\/>This project will undertake four case studies in the design of heuristic algorithms. 1. Implicit hitting set problems are a class of constraint satisfaction problems in which the constraints are too numerous to list explicitly. Many classic optimization problems fit this model. A generic approach will be investigated which aims to enumerate a small set of constraints sufficient to determine the optimal solution. This approach has proved successful in solving a significant group of genome alignment problems. 2. Integer programming can be used to reconstruct a network of interacting genes and proteins from experimental data. A network is modeled as a wiring diagram of interconnected gates, and integer programming is used to reconstruct the logical functions of the gates. The method has successfully mapped the subnetwork of TLM genes that control telomere length in yeast, and will be applied to other models. 3. Another focus of the research is the discovery of aggregates of interacting proteins that form regulatory modules conserved in evolution. Given such a module in one species, the problem of finding a corresponding module in a second species is abstracted as a graph-theoretic problem called the colorful subgraph problem. The plan is to develop fast and accurate heuristic algorithms for the solution of this problem. 4. The final problem is partitioning a graph into a large number of small dense clusters. An application is given from genetics, involving the automatic inference of the familial relationships among a group of genetically related individuals.<br\/><br\/>The problems studied in this project can serve as test cases for understanding the applicability of fundamental algorithmic strategies such as constraint relaxation, integer programming and local search.","title":"III: Small: Combinatorial Optimization Methods for Problems in Molecular Biology and Genetics","awardID":"1217615","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["561682",517894],"PO":["565136"]},"193354":{"abstract":"This collaborative project addresses the need for ocean observational techniques which was highlighted by the recent Deepwater Horizon incident. The proposed project investigates heterogeneous ocean robots (including wave gliders, unmanned surface vessels, and autonomous underwater vehicles) to detect and monitor the propagation of oil plumes. Specific objectives include: 1) the development of a distributed multi-robot cooperative deployment algorithm using partial differential equation (PDE) based methods that match the oceanographic model of oil transport, 2) the development of authentic dynamic model of the new wave glider platform to incorporate in the cooperative control, and 3) assessing the potential advantages of innovative algorithms through simulations and experimental demonstration in a coastal experiment using a network of ocean robot platforms.<br\/><br\/>Broader Impacts: The proposed project will provide novel algorithmic and software support for collective sensing, and address a pressing real-world need for better sensing of underwater hydrocarbon plumes. The techniques developed in the proposal will have long-term impacts in underwater exploration such as oceanographic survey and energy production in deep water. The results may also potentially benefit other environmental monitoring tasks with underlying diffusion and advection processes, such as weather event tracking and climate prediction. The planned work will integrate research projects with education activities through robot-centric undergraduate and graduate education, robotics competition, short course and workshop development, and outreach to K-12 education. Partnering with the Stevens' Center for Innovation in Engineering and Science Education, the project will showcase the proposed research in the curriculum of the Stevens Build IT Underwater Robotics Scale-Up for STEM Learning and Workforce Development Project awarded by NSF.","title":"RI: Small: Collaborative Research: Distributed Heterogeneous Ocean Robots for Detecting and Monitoring Oil Plumes","awardID":"1217659","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["556012"],"PO":["564069"]},"194685":{"abstract":"This research is focused on the creation of new techniques and algorithms to support comprehensive analysis of Android applications. We have developed formally grounded techniques for extracting accurate models of smartphone applications from installation images. The recovery formalization is based on TyDe, a typed meta-representation of Dalvik bytecode (the code structure used by the Android smartphone operating system). In developing TyDe, we are formalizing the TyDe type inferencing, ill-formed bytecode structure management, and creating a generalized Dalvik-to-Java retargeting logic based on bytecode \"instruction templates\". <br\/><br\/>TyDe and the models they represent are being used to perform deep analysis of application structure to infer potential application behaviors that may harm users, their data, or the cellular or Internet infrastructure. In particular, these analyses support whole program analysis, reflection, and smartphone specific data flow analysis. Such analyses provide a means for evaluating an applications adherence to best security practices or organizational requirements by inspecting permission structures, component interfaces, and source code and library origins for signals of malicious behavior. The analysis techniques are being evaluated on a large corpus of real-world applications extracted from real application markets. <br\/><br\/>In the broadest view, this work is providing new avenues for researchers, industry, and consumers to assess potential dangers presented by applications retrieved from smartphone application markets, an advancing the state of the art in application program analysis.","title":"TWC: Medium: Collaborative: Extending Smart-Phone Application Analysis","awardID":"1228620","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["521593"],"PO":["564223"]},"193596":{"abstract":"This project studies fundamental combinatorial, geometric, and graph-theoretical problems related to the design of wireless networks with directional antennas. The goal is to maximize communication robustness and security while minimizing power consumption and interference. The technical focus is on determining theoretical and algorithmic relationships between antenna parameters (orientation, range, angle), and the structure of the induced communication graph (such as connectivity, fault tolerance, and spanning ratio). <br\/><br\/>This study will generate fresh approaches to geometric algorithms tuned to directional antennas, which must necessarily push beyond known geometric techniques. Building a bridge between theoretical computer science and the burgeoning area of communication networks is a key for scientific advancement, with a potential significant economical impact on the design of wireless communication networks.<br\/><br\/>This project will involve collaborations with under-represented students, who will be fully engaged in designing and testing the necessary simulation software, and will explore conjectures both theoretically and through simulations. This will provide a path for talented under-represented students to enter the world of scientific research, who will then serve as role models for the entire body of computer scientists. Theoretical results will be disseminated broadly in conference publications and journal papers. Simulation software will be made available to researchers and teachers worldwide.","title":"AF: Small: RUI: Geometric Graphs for Directional Communication","awardID":"1218814","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[518478],"PO":["565157"]},"193134":{"abstract":"Many-core graphics processing units have been used to accelerate a wide variety of applications and are increasingly a part of high performance computing clusters. Despite the rich body of literature on job scheduling and on virtualization of CPU clusters, resource management frameworks and cloud computing services for heterogeneous clusters that include many-core devices are still in their infancy. The project targets this problem and proposes the design of a set of virtualization and scheduling technologies to allow for the efficient use of heterogeneous clusters that include general purpose processors and many-core coprocessor devices. In particular, the proposed research focuses on the following aspects and on their interactions. First, many-core sharing is explored as a means to improve system utilization while keeping infrastructure costs low. Second, scheduling mechanisms targeting both single- and multi-node applications accelerated using coprocessor devices are proposed. Third, memory unification technologies are proposed in order to hide from the users the complexity of the heterogeneous memory system. Finally, diverse software stacks are integrated into a coherent runtime system.<br\/><br\/>The results of this research will be disseminated through publications and conference presentation. In addition, open-source software modules will be released and made available on the PI?s Lab website. The knowledge generated by this research will allow creating instructional material to teach cluster and cloud computing at both the undergraduate and graduate levels. Undergraduate student involvement will be promoted leveraging the University of Missouri Undergraduate Research Program and a partnership with Truman State University and Lincoln University.","title":"CSR: Small: Scheduling and Virtualization Technologies for Heterogeneous Clusters with Many-core Devices","awardID":"1216756","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550551"],"PO":["565255"]},"193255":{"abstract":"Recent developments in the automotive industry point to a new emerging domain of vehicular wireless networks, in which vehicles equipped with radios can communicate a wide range of information to each other and the wider Internet, including traffic and safety updates as well as infotainment content. The primary goal of this project is to develop a hybrid network architecture for such vehicular networks which combines both the existing cellular infrastructure as well as new vehicle-to-vehicle (V2V) communication capabilities. The hypothesis is that such a hybrid network architecture will improve cost, capacity and robustness, compared to either a purely centralized cellular-based approach or a purely distributed V2V approach. Under a hybrid architecture, the project aims to design information-centric protocols for information dissemination, aggregation, and storage, that can exploit the spatio-temporally localized nature of vehicular applications. Further, through mathematical analysis, computer simulations, as well as experimental implementation on a research fleet of vehicles, this project aims to evaluate the performance of these protocols. <br\/><br\/>This project will be a unique academia-industry collaborative project between researchers at the University of Southern California and General Motors. While the focus will very much be on basic research disseminated to the academic community through publications, the close interaction with a prominent industry partner will enable the research to have a strong impact on real-world vehicular networks. Material from this research project will be incorporated into graduate courses at USC. The aimed-for advance in information technology for the automotive domain could have significant social impact by enabling improvements in traffic safety, efficiency, user comfort and productivity.","title":"NeTS: Small: GOALI: Information Centric Networking on Wheels (IC NoW) - Architecture and Protocols","awardID":"1217260","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["531832","553708"],"PO":["565303"]},"193497":{"abstract":"Cellular system infrastructure deployment is becoming more heterogeneous including random deployment locations and more kinds of infrastructure. Using a mixture of macro, pico, and femto base stations, as well as fixed relay stations and distributed antennas, heterogeneous networks have the potential to break through the capacity bottleneck. While holding great promise, this potential has yet to be realized since the new infrastructure creates a different and challenging distributed interference environment.<br\/><br\/>This research develops new mathematical tools to enable a simplified analysis of cellular systems exploiting concepts from stochastic geometry and random shapes, to model the impact of random interference source locations, accounting for important environmental considerations. It uses these tools to analyze and develop interference management strategies for different proposed technologies including small cell networks with heterogeneous interference and large cell networks with many antennas. A main theme in the analysis and algorithms is the use of antennas to avoid, cancel, align, and otherwise mitigate the effects of interference -- even with limited coordination possible among transmitters.<br\/><br\/>Broader impacts of the proposed theory and algorithms are expected in diverse areas. The mathematical tools and fundamental theory will impact the understanding and design of communication systems taking into account the network geometry. The signal processing algorithms will pave the way for a new understanding of multiple antenna communication techniques. Industry impact will occur through the WICAT \/ Wireless Networking and Communications Group industrial affiliates incorporating research results into their wireless networking technologies. The project will foster the training of graduate students in course projects and will reach out to the community through public demonstrations.","title":"CIF: Small: Interference Modeling and Management for Heterogenous Networks","awardID":"1218338","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["550451"],"PO":["564924"]},"193277":{"abstract":"This research seeks to uncover explanations and principles about how requirements for information systems evolve and how they are managed across project contexts. It will enumerate project design workflows and practices to determine how different forms of artifact and process distribution affect requirements engineering goals and project success. Currently there are no rigorous, theory-based approaches to understanding and explaining large-scale distribution of requirements, though there is evidence of its success. Requirements engineering approaches address spatial and social distribution, and to a lesser extent, structural and temporal distribution. Most importantly, the combination of these issues, in total, has not been considered. Consequently, we cannot say which configuration of practices is best suited to achieve specified development goals, such as reduced time to market, or increased software quality and customer satisfaction. New theoretical models and empirical research are needed to understand the effects of distribution on evolving requirements. <br\/><br\/>The project will (1) conduct field studies and ethnography, (2) analyze work procedures via grounded theory and comparative methods, (3) construct tools for data analysis, model building, and model analysis, and (4) analyze models via simulations and goal analyses. It will apply a distributed requirements framework consisting of four forms of distribution (social, spatial, structural, and temporal) and four requirements tasks (discovery, specification, negotiation, monitoring) in conjunction with the theory of distributed cognition to analyze requirements knowledge evolution in software projects. Additionally, it will design new tools that help acquire, model, and analyze distributed requirements workflows. <br\/><br\/>The research aims to develop critical insights on emerging realities in large-scale design projects, which represent one of the drivers for economic growth and new forms of industrial organization. Yet, many software organizations are constrained by methodological and tool factors that do not recognize the increased challenges for requirements engineering. This research highlights the ways in which designers learn to manage the diversity of inputs and constraints, and seeks to understand processes that enhance software-based open innovation in the future.","title":"HCC: Small: Collaborative Research: Cognitive Approaches to Distributed Software Requirements Engineering","awardID":"1217345","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[517735],"PO":["564456"]},"192067":{"abstract":"This project investigates how education and training methods from traditional work settings can be applied to paid online crowdsourcing. The focus is on how methods such as scaffolding, examples, critique, and apprenticeship affect worker performance, learning, task perseverance, and satisfaction. The project will produce guidelines for a more sustainable crowdsourcing infrastructure where employers can embed relevant domain knowledge into online tasks, and workers can learn key principles and then train less experienced members. The research focuses on worker-centered training strategies in the domain of visual design, which will yield knowledge about effective design principles and instructional methods for visual design. <br\/><br\/>Broader impacts: The project will contribute to increase the availability of online work. It will expand the capabilities and skills of crowd workers, thereby allowing online work to become a more viable part of the American economy. The project will also lead to novel methods for organizations to achieve complex visual design work. More generally, the project will lead to new knowledge about how to train crowds to perform a complex activity and produce practical guidelines to help requesters write tasks and manage the crowd. Finally, the project will provide interdisciplinary training for graduate and undergraduate students in socio-computational system design, HCI concepts, educational theory, and evaluation methodologies. All course materials will be available online for reuse and adaptation. Undergraduate researcher training will focus on supporting underrepresented student groups.","title":"SoCS: Collaborative Research: Strategies for Crowdsourcing Complex Design Work","awardID":"1210836","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["534062",514744],"PO":["565342"]},"193398":{"abstract":"Goal-driven autonomy (GDA) is a reflective model of reasoning about goals to control the focus of an agent's activities by dynamically resolving unexpected discrepancies in the world state, which frequently arise when solving tasks in complex environments. This project is motivated by two observations about GDA agents. First, to perform well, comprehensive GDA agents require substantial domain knowledge; however, few techniques have been investigated for learning this knowledge. Second, while existing GDA agents have demonstrated good performance in a variety of tasks, understanding and generalizing their successes has been hindered by a gap between the kinds of domains that these agents aim to model and the representations that they use; for instance, the bulk of current research on GDA agents assumes STRIPS representations of the agent's goals and actions. <br\/><br\/>This project aims to study GDA agents that are capable of learning expectations, explanations, and goals. This project aims to develop methods that enable creation of GDA agents that can autonomously act and learn to: (1) identify situations where discrepancies take place between what they expect and what actually has happened; (2) explain the discrepancy; (3) decide which goals to try to achieve as a result of these explanations; and (4) act to accomplish these goals. In this work, the objective of each agent is to maximize its expected return as defined in reinforcement learning. This approach fits naturally with the 4-step GDA cycle, facilitates studying properties about GDA using the well-defined reinforcement learning framework, and enables the adoption of representation formalisms such as stochastic policies (i.e., probability distributions of state-action pairs), which are naturally suited to represent GDA agent's actions in the domains that GDA agents aim to interact with. This project aims to develop representational methods that combine FOL (First Order Logic) literals and actions with probabilities as the basis to represent GDA elements.<br\/><br\/>The potential Broader Impact of this research is significant due to the potentially large and widespread applications of goal-driven autonomy. With the pervasive presence of autonomous computing devices and software, there is an increasingly pressing need for technology that enables systems to recognize discrepancies in what they expect from their 'worlds', diagnose them, and then adjust themselves. This is a ubiquitous problem in all areas of computer science. For example, in the general area of ambient intelligence, automated systems, such as an air quality control system, must monitor and control a variety of devices; it is very difficult, if not impossible, for a programmer to foresee all potential situations that such a system will encounter. Another example is cyber security where given the openness that characterizes current networks and the continuous integration of new technologies and services into them, it is not feasible to implement counter measures for all potential threats in advance; instead, an agent-based system must continuously monitor the overall network, learn and reason about expectations, and act autonomously when discrepancies are encountered. <br\/><br\/>This project includes a vigorous educational component. Specifically, it plans to (1) regularly involve undergraduate students in developing and testing carefully scoped components of the project; (2) create a course on adaptive and self-aware GDA agents that transcends traditional boundaries in courses on agents, reinforcement learning, and planning; and (3) create and disseminate testbeds for GDA agents that include not only the project's GDA agents but also simulations and agent-simulation interfaces. Creating and disseminating testbeds will help remediate the lack of systems and agent-simulation interfaces that has been a repeated stumbling block for teaching about GDA agents.","title":"RI: Small: Goal-Driven Autonomy","awardID":"1217888","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[518015],"PO":["565035"]},"197534":{"abstract":"A common scientific challenge is that of merging together results from independent research programs in order to conduct broad, synthetic analyses, as for example when astronomers focus on different segments of the night sky, geologists on specific times spans, and biologists on specific groups of organisms. In these cases, the answers to major scientific questions arise when the independent groups can successfully exchange and integrate their data into a comprehensive framework for analysis. Creating new, large-scale, next-generation data resources in the social, behavioral and economic sciences (SBE) and for education and human resources (EHR) too will require linking independent data sources into larger, coherent data structures. The PaleoCore initiative will create data standards and software tools to facilitate the aggregation of data into federated data networks. The project leverages data standards, and software solutions from other scientific disciplines to rapidly develop solutions relevant to SBE and EHR. The approach taken by the PaleoCore initiative is to start with a specific topic in SBE, human prehistory, and develop solutions that are broadly applicable to other scientific domains within SBE and EHR. Toward this aim the project has three main goals: 1) to develop and publish a data standard for prehistory, 2) to develop software tools that facilitate researchers' ability to record collected data directly into databases, especially geospatial databases, and 3) to develop a web portal that integrates individual project databases online into a federated network of data providers serving information to researchers, students and the general public. Through these objectives scientists in the SBE and EHR sciences will have a mechanism for broad-scale data integration, visualization, analysis and dissemination. This framework creates the foundation for answering big-picture questions beyond the reach of individual research projects and opens the door to new knowledge based on large, aggregated data sets.","title":"PaleoCore: A model for Developing Distributed Data Frameworks in SBE and EHR","awardID":"1244735","effectiveDate":"2012-09-15","expirationDate":"2015-02-28","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"8068","name":"Data Infrastructure"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}}],"PIcoPI":[529972,529973],"PO":["565192"]},"198646":{"abstract":"Analysis of biological sequences, including multiple sequence alignment, motif finding, and genome alignment, is a fundamental problem in computational biology due to its critical significance in wide ranging applications including haplotype reconstruction, sequence homology, phylogenetic analysis, and prediction of evolutionary origins. Most of the sequence analysis problem formulations (particularly those related to alignment) are considered NP-hard. Existing solutions to the sequence alignment problem (both sequential as well as parallel) are extremely limited in their applicability and yield poor performance for large data sets. Moreover most of these solutions have been designed for aligning short length sequences. The genome alignment problem (very long sequences) is significantly harder and very few solutions exist that are capable to construct genomes from short reads while taking significant amount of execution time. This project deals with the design and development of high performance algorithms and implementations for aligning genomes using innovative sampling and domain decomposition strategies. This approach has never been pursued for genome alignment in the past. The proposed algorithms are implemented on hybrid computing platforms consisting of multicore clusters and GPU units.<br\/><br\/>This project brings together tools and applications from multiple disciplines such as bioinformatics, computational biology, statistics, and high performance computing. Therefore the findings will introduce new tools for biology and biomedical applications. It will facilitate rapid reconstruction of genomes and mapping of short reads to the corresponding haplotypes.","title":"EAGER: High Performance Algorithms and Implementatations for Genome Alignment","awardID":"1250264","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[532978,532979],"PO":["565255"]},"194059":{"abstract":"The main research focus of this proposal is to create a platform that allows to automatically find attacks in unmodified binaries of distributed systems. The attacks are conducted through message manipulation by insider attackers and impact primarily performance and availability. The platform combines existent open-source virtualization environments such as KVM, and network simulation and emulation tools such as NS3, to create a realistic environment in which target systems will run. The platform is general, scalable, and can be used for testing a large variety of distributed systems such as intrusion-tolerant and peer-to-peer systems.<br\/><br\/>The platform will improve the trust that distributed systems work according to their intended specifications in spite of faults, misconfigurations, or attacks.<br\/>The platform can serve as a tool for system developers from industry, government labs, and academia to test their systems. In addition, it can be used for programing exercises for distributed systems and computer security courses at both undergraduate and graduate level.","title":"TWC: Small: Automatic Detection of Protocol Manipulation Attacks in Large Scale Distributed Systems Implementations","awardID":"1223834","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[519699,519700],"PO":["565327"]},"198536":{"abstract":"This grant will enhance participation in the fourth Midwest Verification Day 2012 (MVD 12), an informal workshop with the goal of developing a regional research network in the broad area of verification and formal methods. The long-term intention is to make MVD a regular annual event, rotating between universities in the Midwest that have representation in the relevant research areas. A major focus of MVD is to provide undergraduate and graduate students a means for becoming familiar with ongoing research in the Midwest region in the application of formal methods in hardware and software analysis. The workshop also aims to afford students a relaxed, non-competitive forum for presenting their own research to industrial participants and to students and faculty from neighboring universities.<br\/><br\/>For the significant number of graduate and undergraduate students who originate in the Midwest, such an event can help build the connections and the confidence to go on to graduate school, or advance further in academia. This helps strengthen the domestic talent pool for formal methods. MVD 12 will also strengthen the regional connections between academia and industry, which, over the long term, can have a potent regional economic effect.","title":"Midwest Verification Day 2012","awardID":"1249520","effectiveDate":"2012-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["562945",532700],"PO":["565264"]},"195159":{"abstract":"The NSF Sustainable Energy pathways (SEP) Program, under the umbrella of the NSF Science, Engineering and Education for Sustainability (SEES) initiative, will support the research program of Prof. Dennice Gayme and co-workers at Johns Hopkins University, Prof. Aranya Chakrabortty and co-workers at North Carolina State University, and Prof. Judith cardell and co-workers at Smith College to develop a method to integrate heterogeneous energy resources to form sustainable power networks. The objective of this program is to examine how the control and design of large-scale and distributed energy resources can facilitate the grid-integration of large amounts of renewable energy. Wind energy is used as a representative, heterogeneous and variable renewable energy source to address the following three fundamental challenges: (I) the need to manage stability, (II) the need to cost effectively maintain reliable operation, and (III) the need to reflect stability and operational criteria in markets and policy. Models of the power grid, such as continuum representations (partial differential equations that directly support combined spatial and temporal analysis) and network power flows that include storage and demand-side management, will be developed and used to address stability, control, reliability, and performance\/efficiency questions. As input for these continuum and power flow models, the project will utilize outputs from fluid dynamics (\"Large-Eddy\") simulations that model unsteady wind farm and atmospheric boundary layer interactions and have been validated using laboratory and field observations. Analysis using the grid level models will both inform and be shaped by the design of new regulatory and economic reforms that will enable renewable resource purveyors to participate in power markets. Connections between operational and market issues such as power flow regulation, grid operation and risk mitigation strategies using storage and demand-side management will be made by leveraging tools based on optimization, convex relaxations and optimal control theory, which are common to the economics and controls communities. <br\/><br\/>This project will facilitate a more sustainable power system through its technical contributions, education, training and mentorship. Research topics will form the basis for student projects in new sustainable energy related curricula at all three participating institutions. Summer undergraduate research opportunities will provide students with skills for participating in sustainable energy research and future employment in related industries. This program will directly facilitate NSF's STEM related goals through JHU's participation in the NSF-funded Center for Integration of Research, Teaching, and Learning (CIRTL), the Science House partnership between NCSU and local K-12 teachers, and the involvement of the only all-women engineering program in the US (Smith College). At JHU this project will operate under the aegis of E2SHI, which promotes cross-disciplinary research, outreach, and education for critical environmental, energy and sustainability issues. E2SHI is committed to systems-level integrated research and outreach for sustainability.<br\/><br\/>The tools to be developed will help facilitate the transformation of our current fossil fuel based power system to one that is safe, reliable and efficient without compromising energy security or exhausting resources needed for future generations. The project's results will be directly relevant to the electric power industry and its regulators as they are faced with the challenges of incorporating larger fractions of highly heterogeneous renewable resources, such as wind energy, into the grid. Specifically, the results will provide system operators with better representations of the impacts of renewables, and better control tools to mitigate those impacts; planners and investors with a framework for evaluating optimal resource allocation; and policy makers with a systematic means of investigating how new regulations and market rules can incent effective deployment of these tools and resources. Complementary educational programs and mentorship will develop researchers and practitioners with the skills required to create and advance this sustainable energy future.","title":"SEP Collaborative: Integrating Heterogeneous Energy Resources for Sustainable Power Networks - A Systems Approach","awardID":"1230848","effectiveDate":"2012-09-15","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"8026","name":"Sustainable Energy Pathways"}}],"PIcoPI":["553591"],"PO":["564728"]},"198547":{"abstract":"The objective of this EAGER project is to explore a preliminary design of a Scalable and Efficient Resource Discovery system (SERD) that can be utilized in large scale distributed systems. In particular, the PI is investigating the incorporation of the following three key innovations into SERD.<br\/><br\/>(1) A scalable middleware for resource discovery:<br\/>Current resource discovery systems use flat peer-to-peer (P2P) structures that lead to either high overhead in structure maintenance or low efficiency in resource discovery. They also lack proximity-awareness and multi-resource range querying capabilities. By contrast, SERD clusters proximity-close nodes that have the same resource and connects the clusters using a backbone hierarchical P2P structure, permitting efficient range querying of proximity-close resources.<br\/><br\/>(2) Scalable and efficient resource discovery: <br\/>Using the SERD middleware in (1), the PI will develop efficient resource information marshaling and searching algorithms. These algorithms can achieve proximity awareness and can provide range querying capabilities that enables the nodes to find physically close resources within specified ranges. <br\/><br\/>(3) Balanced resource discovery:<br\/>Current resource discovery systems lack a load balance algorithm to balance the resource discovery load among the different nodes. By contrast, SERD incorporates a load balancing algorithm in order to balance the resource discovery load among the different nodes.","title":"CSR: EAGER: A Scalable and Efficient Resource Discovery System for Large-Scale Distributed Systems","awardID":"1249603","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["563519"],"PO":["565255"]},"199768":{"abstract":"This is an exploratory project to investigate, prototype, and demonstrate a computational framework for developing science mission games or game-based virtual worlds. Mission-oriented science is a sizable part of the national agenda for research and development within many science, technology, engineering, or mathematically based disciplines. These missions are complex endeavors that articulate a life cycle of recurring socio-technical and economics-driven processes, such as mission planning, vehicle and payload or instrument design, launch, transit, arrival, landing and deployment, resources collection, return, and debriefing. Increasingly, students, teachers, scientists, engineers, technicians, and others need to become aware of, gain knowledge about, and ultimately encourage support and enthusiasm for new scientific missions. This research will articulate such a framework and provide a proof of concept mockups or prototypes for science mission games that employ this new framework. <br\/><br\/>The results can serve as the basis for developing new research projects of interest to specific science research agencies or programs for creating new, mission-specific science games. Such games represent a new medium for communicating, educating, and engaging a new generation of people interested in new science missions and scientific grand challenges. By design, the approach must be science domain-independent, and a reusable computational framework for producing extensible science mission games would represent a new, high-value engine for innovation that serves to address the new grand challenges for science and technology, and to advance the collective societal mission of producing, sharing, and applying new scientific knowledge and technological practice within and across science disciplines.<br\/><br\/>Mission-oriented science computer games provide game-play mechanics and play experiences that help players to (1) gain awareness, (2) acquire scientific knowledge, or (3) participate in customizing and extending the specified details of a scientific mission or exploratory expedition in a specific domain of interest. Such games can afford opportunities for the public to gain awareness of the mission and its potential consequences, for students to learn about the scientific foundations that characterize the domain or mission challenges, and for domain specialists or citizen enthusiasts to participate in articulating, refining, and optimizing the scope, scale, efficiency, and effectiveness of such science missions.","title":"EAGER: Creating a Framework for Prototyping Science Missions.","awardID":"1256593","effectiveDate":"2012-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":[535599],"PO":["564456"]},"198228":{"abstract":"Distributed algorithms are the foundation of distributed systems, which are an important part of the nation's computer infrastructure. Developing correct and robust implementations of such algorithms is a difficult task. This research project is an ambitious effort to address the problem of programming distributed algorithms by raising the level of abstraction. The investigators will develop a novel very-high-level language, called DistAlgo, for writing distributed algorithms. This language will make it easier to clearly express distributed algorithms and will provide a useful pedagogical notation for teaching distributed programming.<br\/><br\/>The investigators will develop optimizations that will allow efficient implementations to be generated from DistAlgo programs. Thus, this work will bridge the gap between the pseudocode that is typically used to describe distributed algorithms and the efficient implementations of such algorithms. The optimizations are based on automatic incrementalization techniques applied to the logical descriptions of process states and histories. The investigators will evaluate their approach by applying it to well known distributed algorithms.","title":"EAGER: From Clarity to Efficiency for Distributed Algorithms","awardID":"1248184","effectiveDate":"2012-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["552012",531979],"PO":["564588"]},"189648":{"abstract":"The dominant manufacturing paradigm for human technology has been ?top-down? construction of objects, in the sense that a large entity manipulates smaller entities to put them together into a functional device. For example, in an automotive factory, parts such as doors, windshields, wheels, seats, engines are separately manufactured and then brought together and assembled into a car by either humans or robots that know where each part should go and how it should be attached. In contrast, for billions of years biological organisms have constructed objects using a ?bottom-up? technology, in the sense that the pieces self-assemble or grow without outside assistance. For example, to make a complex molecular machine, enzymes within the cell might synthesize a number of proteins that then diffuse randomly until they bump into each other and click into place; while on a larger scale, a single cell might grow into an elephant. <br\/><br\/>The bottom-up manufacturing paradigm has advantages that top-down methods are unlikely ever to achieve, such as the ability to create meter-scale objects from components with atomic-scale (nanometer) resolution and chemical functionality ? but it requires a level of exquisite control over molecular structure and function that human science and technology has not yet attained. We believe that the primary missing ingredient is information science and technology: information must be encoded within synthetic molecules to control their behavior and to create programmable molecular systems. <br\/><br\/>In this research, the aim is to push the frontiers of information-based molecular self-assembly using DNA nanotechnology. The past fifteen years have seen the development of an abstract theory of algorithmic self-assembly (initiated by Winfree) that merges the mathematical theory of geometrical tiling, the statistical mechanical and kinetic theories of crystal growth, and the algorithmic theory of Turing machine computation. This theory shows how, in principle, synthetic DNA molecules called ?tiles? can be designed to carry information that directs their assembly into complex and sophisticated shapes and patterns. Just as a small program can produce a large and intricate output, a small tile set can result in the self-assembly of a large and intricate object ? the tile set is a ?program? for controlling the molecular self-assembly process. Laboratory experiments in the past fifteen years have demonstrated the foundations of this theory using DNA tile sets on the order of two dozen tile types, i.e. very small molecular programs.<br\/><br\/>In the past year, a new molecular motif for DNA tiles (developed by Yin) has been used to self-assemble molecular structures using up to 1000 distinct tile types that each has a unique target position within the structure, like a self-assembled molecular-scale jigsaw puzzle. This is the simplest type of molecular program. A major goal of the proposed work is demonstrating that the new ?single strand tile? motif can be used to create significantly more complicated self-assembly programs than have been seen to date by reusing distinct tile types in many locations and in an algorithmic fashion, much like living systems that reuse the same molecules in many different ways. Sophisticated algorithmic tile reuse of two dozen to perhaps 1000 or more distinct components vastly expands the capabilities of self-assembly programs. To achieve this, proposed work will (a) improve techniques for an important ?subroutine? for controlling molecular growth, a binary counting process that terminates after growing a pre-specified distance; (b) develop methods and molecular structures for nucleating the growth of single-strand tiles with pre-specified information that serves as ?input? to the molecular program; (c) demonstrate algorithmic growth of single-strand tiles that perform Turing machine and\/or cellular automaton computations; (d) investigate proofreading techniques for reducing the rate of errors during self-assembly; and (e) create software tools that facilitate the design and analysis of these complex molecular systems.","title":"SHF:Medium:Collaborative Research:Scaling Up Programmable and Algorithmic DNA Self-Assembly","awardID":"1162459","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["561030"],"PO":["565223"]},"187118":{"abstract":"Is there a common human brain architecture that can be quantitatively encoded and precisely reproduced across individuals? This CAREER project aims to discover and represent common human brain architecture through a map of Dense Individualized and Common Connectivity-based Cortical Landmarks (DICCCOL). Each of the landmarks will be defined by group-wise consistent white matter fiber connection patterns derived from diffusion tensor imaging (DTI) data. In parallel, large-scale multimodal fMRI and DTI datasets will be employed to determine predictive relationships between DICCCOLs and functional localizations. The resulting DICCCOL representation of common brain architecture will be applied to create a universal and individualized brain reference system, construct human brain connectomes, and elucidate the brain's functional interactions. The education objective of this CAREER project is to create and assess a fundamentally novel interdisciplinary higher education approach, namely, transformative interdisciplinary group learning (TIGL). Students and instructors from three courses that are related but emerge from different disciplinary perspectives (Biomedical Image Analysis, Introduction to MRI Physics, and Functional Brain Imaging) will work together in one classroom. During these common sessions, the students will have synergistic learning activities, engage in interdisciplinary group discussions, and design and conduct interdisciplinary group projects.<br\/><br\/>The discovery and representation of common brain architecture will fundamentally advance scientific understanding of the human brain. Broad dissemination of the DICCCOL map and its prediction framework will transform numerous applications that rely on structural\/functional correspondences across individuals. The DICCCOL map offers a generic bridge to compare and integrate neuroimaging data across laboratories, which will stimulate and enable plentiful collaborative efforts. While this project has a focus on brain imaging, the general methodology of predictive modeling of structure and function is expected to influence many other imaging domains. The TIGL approach will advance fundamental understanding of interdisciplinary learning. The TIGL approach will be scaled up to other institutions and disciplines, and will be widely disseminated. This continuous effort will establish the TIGL approach as a general interdisciplinary education methodology to increase the capacity of the next generation of scientists who have an interdisciplinary mindset.","title":"CAREER: Discovering Common Human Brain Architecture","awardID":"1149260","effectiveDate":"2012-09-01","expirationDate":"2017-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7731","name":"OTHER GLOBAL LEARNING & TRNING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["539303"],"PO":["564318"]},"198008":{"abstract":"This study will use the 2012 election cycle as a testbed for examining and developing techniques to analyze the implications of the social web for national elections. The social web - broadly defined as the array of technologies that allow individuals to post their thoughts, pictures, and comments in a public forum - has profoundly changed the way in which political candidates, elected officials, and government agencies engage with potential supporters. As an ever-growing number of people join the plethora of available social networks (including Facebook, Twitter, Pinterest, Tumblr, Flickr, and Instagram), politicians across the world sought to develop increasingly sophisticated social web strategies that maximize their ability to engage directly with the public. At the same time, the social web has facilitated the ability of individuals to share ideas, form communities, and coordinate their actions and responses to political campaigns across time and space. Yet the sheer volume of data produced daily through this online civil discourse is overwhelming for researchers and, until recently, has defied our ability to collect, analyze, and comprehend in its entirety. <br\/><br\/>This research will develop a prototype visualization tool that will allow researchers to explore the online discourse surrounding elections. This tool will capture social media posts related to selected races in the 2012 Congressional election, both incumbent districts and open seats. Monitoring and analyzing the conversations relative to these races, this study will seek to determine any correlation between social media strategies employed by political candidates in the United States and any increase in polarization in the online discourse. To analyze this discourse, the research will explore the extent that those participating in an online discourse move towards a group polarization with more extreme policies and platforms. Group Polarization is a subset of research on Choice Shifts, which reflect instances where individuals alter their opinions based on commonality, unique information surfacing, or other outside influences. Experimental research suggests that group polarization occurs because the individual has had interaction with a group of like-minded peers. The theory suggests that, after discussion among the group, the individuals will come to a consensus opinion together. Thus, when competing groups form and engage in discourse separately, we are more likely to witness increasingly polarizing opinions between the two groups. This study is relevant for computer scientists, who need to develop strategies for managing, archiving, and providing access to large and dynamic datasets, and is particularly important for social scientists because this online social discourse reflects the moods, values, and attitudes of citizens towards participating in offline civil society. Moreover, scholars need to study how the new social media affect the democratic process of elections. <br\/><br\/>This study will provide an opportunity to explore strategies for collecting, aggregating, visualizing, and storing data culled from the social web. It will develop a prototype visualization tool that can be connected via APIs to visualize polarization as manifested through the social web and that will be made available to other researchers interested in studying conversations, sentiment, and the social web. Moreover, this tool will act as a first step in developing a deeper understanding of how to visually map sentiment, political action, and civic discourse over time and space. Additionally, the data collected through this project will provide the basis for future research that will enable a more detailed analysis of the data collected during the election and congressional session.","title":"EAGER: Prototype Tool for Visualizing Online Polarization","awardID":"1247198","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["565271","563666",531395,531396],"PO":["564456"]},"192981":{"abstract":"Market design--economic engineering--has been successful in the redesign of real-world \"two-sided matching markets,\" including the matching of doctors to residencies and the assignment of students to schools. A recent and growing literature has shown that the methods and results of two-sided matching theory extend to substantially more general settings, including \"trading networks\" in which agents negotiate over contracts.<br\/><br\/>Unlike two-sided matching markets, trading networks feature intermediaries, agents who both buy and sell in the market. These intermediaries may be intermediate producers (as in most economic models of supply chains) or may simply facilitate trade (e.g., through provision of information). Although the presence of intermediaries is the defining distinction between the matching-in-networks model and the previous two-sided frameworks, the analysis of intermediaries in these matching models has been limited.<br\/><br\/>This research will further our understanding of the behavior and impact of market intermediaries. Theoretical work using the matching-in-networks framework will be supplemented with detailed empirical analyses using plant-level microdata on production networks, in order to gain insight into the magnitudes of intermediaries' effects on welfare. Simulated counterfactual models will be developed when theory does not provide sharp predictions.<br\/><br\/>This work will inform and support new applications of market design approaches to real-world intermediated matching markets. One focus will be understanding how \"local\" perturbations (e.g., intermediary entrance and exit) affect the \"global\" structure of networks; another will be the identification and reduction of rent seeking by intermediaries.<br\/><br\/>In addition to enabling novel work in applied market design, this research will promote joint work between computer scientists and economists working in the theory and practice of market design.","title":"ICES: Small: Collaborative Research: Understanding the Roles of Intermediaries in Matching Markets","awardID":"1216083","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"1320","name":"ECONOMICS"}}],"PIcoPI":[516980,516981],"PO":["565251"]},"192992":{"abstract":"This is funding to support a Doctoral Consortium (workshop) for approximately 11 graduate students, along with a panel of about 3 distinguished research faculty mentors. The event will take place in conjunction with the 2012 IEEE Symposium on Visual Languages and Human-Centric Computing (VL\/HCC 2012), to be held September 30-October 4, 2012, in Innsbruck, Austria, and sponsored by the IEEE Computer Society. The long-running VL\/HCC series occupies a unique niche among HCI and Programming Language conferences, in that it focuses specifically on how to help end users successfully develop and use software. Recent advances in computing have led to continually deeper integration between computers and human society. People now swim in a \"sea\" of socio-technical systems that synthesize large numbers of contributing users with vast amounts of source code. Examples include social media systems, open source repositories, online marketplaces and massively multiplayer online games. Yet as the socio-technical systems in this sea have grown in complexity, they have become increasingly difficult for end users to understand and direct toward productive ends. <br\/><br\/>The primary goal of this year's VL\/HCC Doctoral Consortium, the tenth to be funded by NSF in this series, is to stimulate graduate students' and other researchers' thinking about how to make computation easier to express, manipulate, and understand. In particular, what methods, models and tools can people use to visualize, analyze, tailor, and direct socio-technical systems? The doctoral consortium aims to stimulate novel approaches that go far beyond simplistic solutions like web browsers and search engines. Although search engines do provide information that is useful in simple situations, they represent only one portion of a socio-technical system (information retrieval). For example, search engines alone are not powerful enough to be used to start new businesses and run them competitively, since they only give people the ability to find resources provided by other people, rather than the ability to create new resources. Effective approaches will bring users and software together in creative and productive ways that bear directly on the needs of modern society. <br\/><br\/>The workshop will build community among young researchers working on different aspects of these problems from the perspectives of diverse fields including computer science, the social sciences, and education. It will guide the work of these new researchers by providing an opportunity for experts in the research field (as well as their peers) to give them advice, in that student participants will make formal presentations of their work during the workshop and will receive feedback from a faculty panel. The feedback is geared to helping students understand and articulate how their work is positioned relative to other human-computer interaction research, whether their topics are adequately focused for thesis research projects, whether their methods are correctly chosen and applied, and whether the results are appropriately analyzed and presented. As in prior years the VL\/HCC 2012 Doctoral Consortium will be part of the regular conference program. A 2-page extended abstract of each participant's work will be published in the conference proceedings. More information about this year's VL\/HCC conference may be found at http:\/\/vlhcc2012.di.unisa.it.<br\/><br\/>Broader Impacts: The workshop will help shape ongoing and future research projects aimed at alleviating a pressing problem of relevance to a great many people within our society. This event will promote discovery and learning, by encouraging the student researchers to explore a difficult and challenging open problem, through involvement of a panel of well-known researchers whose task is to provide constructive feedback, and through inclusion of other conference participants who will also learn from and provide additional feedback to the students and to each other. The PI and the members of the organizing committee will make special efforts to attract a diverse and interdisciplinary group of student participants, with special attention paid to recruitment of students from underrepresented institutions and women. The PI expects that most of the students supported by this award will come from U.S. universities (no more than 2 will be accepted from any one institution), but as in past years due to the highly international make-up of the research community a couple of non-U.S. students may be invited to participate as well.","title":"WORKSHOP: VL\/HCC 2012 Doctoral Consortium","awardID":"1216138","effectiveDate":"2012-09-01","expirationDate":"2013-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["549910"],"PO":["565227"]},"194730":{"abstract":"The goal of our work is to (a) capture people's expectations and surprises in using mobile apps in a scalable manner, and to (b) summarize these perceptions in a simple format to help people make better trust decisions. Our main idea is analyzing privacy in the form of people's expectations about what an app will and won't do, focusing on where an app breaks people's expectations. We are building an App Scanner that combines automated scanning techniques with crowdsourcing. Automated scanning captures the behavior of an app, while crowdsourcing is used to interpret how expected and acceptable this behavior is. This information is used as the basis for building a better privacy summary for apps. We have organized an interdisciplinary team with expertise in mobile computing, computer security, systems, and human-computer interaction.<br\/><br\/>Success in this work will include results in: (a) the design and implementation of an App Scanner that combines automated techniques with crowdsourcing techniques for analyzing and interpreting privacy-related behaviors of mobile apps; (b) a series of evaluations of this app scanner, showing effectiveness, accuracy, and scalability; (c) the design and evaluation of better privacy summaries, which prioritize and highlight the most unexpected behaviors of an app; and (d) demonstration of a new conceptualization of privacy, namely privacy as expectations. Success will also help end-users, corporate and government employees manage their privacy better than can be done today.","title":"TWC: Medium: Collaborative: Capturing People's Expectations of Privacy with Mobile Apps by Combining Automated Scanning and Crowdsourcing Techniques","awardID":"1228813","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["560994","561943"],"PO":["565327"]},"193520":{"abstract":"Due to fundamental power limitations, the energy efficiency of transistors is not improving, thus making computer chips power limited. Without significant innovations in the ways to build microprocessor hardware, the performance improvements that we have grown accustomed to cannot be sustained. Specialization using accelerators, and thereby reducing power, is a promising way forward, as evidenced by the commercial success of SIMD-accelerators and GPUs, and by new computer hardware research concepts. Clearly there are very many choices in this design space of accelerators, ranging from the granularity of the work they target, the baseline processor they accelerate, compilation and execution model, and abstraction presented to the application developer. This wide choice introduces a fundamental problem in that tools and application frameworks do not exist for reasoning about this wide design space. This project's over-arching goal is to develop quantitative tools, mechanisms, and detailed application studies covering the design space of accelerators.<br\/><br\/>The project provides an array of techniques for the specialization era: a novel framework to guide microprocessor designs and application developers to reason about accelerators, architecture mechanisms, and highly optimized applications for accelerators. The tools and mechanisms help sustain performance improvements in future power-constrained technology generations. The project's prototype system, simulation enhancements, and compiler framework are released as tools for the community. The project's focus on computational-physics applications has numerous uses that positively impact broad swaths of society by enabling applications ranging from virtual surgery to modeling vehicle traversal on snow terrains. The PIs continue mentoring under-represented students and undergraduate students as part of this project.","title":"CSR: Small: Accelerating Towards the Hardware Specialization Era: A Holistic Approach","awardID":"1218432","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["533271","521594","534370"],"PO":["565255"]},"194741":{"abstract":"The project explores the influence that offline cues and stimuli, indicating the presence of other human beings in the physical world, and often processed unconsciously by our brains, can have over security and privacy behavior in cyberspace. <br\/><br\/>The project is predicated around an evolutionary conjecture: Human beings have evolved to detect and react to threats in their physical environment, and have developed perceptual systems selected to assess these ?physical? stimuli for current, material risks. In cyberspace, the same stimuli often are absent, subdued, or intentionally manipulated by third parties. Hence, security and privacy concerns that would normally be activated in the offline world are restrained, and defense behaviors are hampered.<br\/><br\/>While it is impossible to test such conjecture directly, indirect evidence compatible with the conjecture can be obtained by investigating the impact that external stimuli in the physical world have on security and privacy behavior in cyberspace. The proposed research consists in a stream of human subjects controlled experiments investigating such impact of various sets of stimuli or cues. <br\/><br\/>This significance of this research is two-fold. First, it attempts to advance the scientific understanding of what makes security and privacy decision making in cyberspace uniquely different from, and sometimes more difficult than security and privacy in the physical world. Second, by investigating a factor that may significantly disrupt user behavior in cyberspace, the research findings could inspire the construction of systems that induce more secure behavior.","title":"TWC SBES: Medium: Collaborative: Evolutionary Approaches to Privacy and Information Security","awardID":"1228857","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["553880"],"PO":["565327"]},"193531":{"abstract":"Networked Sensing Systems (NSSs) interact with the physical world by tightly integrating sensing, computation, networking, and physical processes. NSS systems are being deployed for numerous critical applications such as security, civil infrastructure, healthcare, manufacturing, and transportation. These applications often impose stringent performance requirements. Many computation and communication tasks of NSS systems must be finished within certain timing constraints to avoid undesirable or even catastrophic consequences -- a property known as real-time assurance. In addition, mission-critical NSS systems must maintain their performance at an acceptable level even when noises and errors occur in input and\/or internal system components -- a property known as fidelity. This research is to design a novel NSS control framework that integrates data fusion, calibration, and real-time performance control into a solution that balances requirements for fidelity and real-time assurance. The expected outcomes include: 1) a unified multi-tier performance control framework for both fidelity and real-time assurance; 2) improvements in fidelity assurance through novel model and fusion calibration algorithms; 3) a fidelity-aware real-time performance control mechanism; and 4) integrated fidelity and real-time assurance for several mission-critical domains including real-time volcano monitoring and tomography, and high-fidelity ad hoc surveillance. <br\/><br\/>This project has broad implications for future NSS systems in multiple application domains that require high-fidelity processing of dynamic and complex physical information within stringent timeliness constraints. Educational and outreach activities include introduction of NSS systems into two new graduate courses with software, testbed, and labs developed in the course of this project, and recruitment of women and minority students for participation in the project.","title":"CSR: Small: Collaborative Research: Integrated Control of Fidelity and Real-Time Performance in Networked Sensing Systems","awardID":"1218475","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["554514"],"PO":["564778"]},"194862":{"abstract":"Proposal #: 12-29297<br\/>PI(s): Nooshabadi, Saeid<br\/> Kuhl, Scott; Wang, Chaoli<br\/>Institution: Michigan Technological University<br\/>Title: MRI\/Dev: Infrastructure for Research in Multi-view Video, Graphics, Visualization and Immersive Virtual Environment Systems<br\/><br\/>Project Proposed:<br\/><br\/>This project, developing an instrument consisting of a large-scale tiled display, multiple video capture cameras, and a high-performance GPU cluster for large-scale data analysis and visualization, and multi-view coding and rendering, aims to enable a significant amount of research where graphics, vision, and multi-view video converge (including image-based modeling and rendering (IBMR) and MPEG-4\/7). The instrument additionally includes augmentation of traditional interfaces that support research in 3D merger of graphics and video-coding, augmented reality and human perception research. It will also be used a to further advance the development of novel algorithms and techniques for large-scale data analysis and visualization, immersive virtual environments and image coding, as well as their on-going collaborations with scientists and researchers at national laboratories and industry. As evidenced by the availability of very large flat-panel displays and basic tracking systems such as Xbox Kinect, these types of coders, displays, and tracking systems should become more mature and affordable in the future. <br\/><br\/>Broader Impacts: <br\/><br\/>The proposed instrument can greatly impact the areas of telemedicine, manufacturing, and robotics. It can also be used for classes on computer graphics, virtual environments, data visualization, multi-media, and computer gaming. The PIs propose to organize summer programs to attract high-school students into <br\/>science and STEM related areas.","title":"MRI: Development of Infrastructure for Research in Multi-View Video, Graphics, Visualization and Immersive Virtual Environment Systems","awardID":"1229297","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["550368",522133,522134],"PO":["557609"]},"193652":{"abstract":"Markov chain Monte Carlo (MC) algorithms are important tools throughout the physical and biological sciences, with applications ranging from simulating new materials to reconstructing phylogenetic trees. They explore a space of states of a physical system, or potential solutions to a problem, by making a series of small changes. One of our main challenges is knowing whether the algorithm has run long enough to reach equilibrium, i.e., if it has spread throughout the space enough to obtain good estimates of important quantities. Here, there is a major divide between theoreticians and practitioners. Physicists use non-rigorous techniques that are much more optimistic than what theorists know how to prove. On the other hand, they are often based on deep ideas about the physical properties of these systems and their asymptotic behavior, and are backed up by numerical experiments. The main theme of the research under this award is to answer the question: how can we bridge the divide between these two camps?<br\/><br\/>The PIs will focus on three areas where stronger bridges can be built. In two-dimensional spin systems, they will use power-law decay of correlations to prove polynomial mixing times at critical points, and to show that we can efficiently \"remix from equilibrium\" even below phase transitions where worst-case mixing times are exponential. They will give a rigorous understanding of the efficiency of cluster algorithms widely used in physics, which are believed to avoid or reduce the phenomenon of \"critical slowing down\" as we approach a phase transition. Finally, the PIs will go beyond traditional Markov chain analysis techniques on discrete state spaces, and prove new results on systems whose states are continuous, such as the hard-sphere model in the plane.<br\/><br\/>This work is cross-disciplinary between physics and computer science. MC algorithms also offer an excellent opportunity to involve undergraduates in the research process: they can implement algorithms used in physics and computer science, and gain a \"hands-on\" feeling for their performance in theory and practice. They can also produce educational applets to let other students, in turn, see these algorithms in action.","title":"AF: Small: Collaborative Research: The Physics of Markov Chains: Closing the Gap Between Theory and Practice","awardID":"1219117","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":["531365"],"PO":["565157"]},"194752":{"abstract":"Software Defined Radio (SDR) technology has the flexibility of implementing a large part of physical layer functions in software. It is one of the major technologies that will provide broadband services to millions of US residences. However, unlike conventional radio whose RF signals are tightly regulated by FCC-certified hardware, the software components of SDR can be easily exploited by hackers to create a wide range of unauthorized waveforms to launch attacks on many security-critical wireless systems. The existing preventive software-based security counter measures are not possible to prevent the myriad of potential software security loopholes and themselves often become targets of the malware. <br\/><br\/>The objective of this project is to design an effective hardware-based SDR integrity assessment and behavior regulation device named SDR Shield. SDR Shield resides between the vulnerable SDR software and the security-critical SDR hardware to detect any malicious configuration of the RF device and prevent it from being used to attack wireless systems. The SDR Shield uses side channel and communication channel information from different SDR components to detect deviations from expected execution status. SDR shield also includes a regulation circuit to enforce safety-critical properties of SDR operation. A secure update process is developed to maintain SDR shield?s flexibility and its own security. The generality of SDR Shield?s design provides a unified security mechanism for SDR design and hence can ease the burden on FCC or any future SDR design verification institutes in certifying security measures of SDR products.","title":"TWC: Medium: Title: SDR Shield: A Hardware-based Security Solution for Software Defined Radio","awardID":"1228903","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["560140",521677,"408703"],"PO":["565327"]},"193542":{"abstract":"This project, developing new techniques for enabling planners to automatically learn from experience, offers fast, high-quality solutions to very large motion planning problems that arise in robotics, CAD\/CAM, animation of virtual characters, and surgical planning. These problems are challenging because they require searching high-dimensional state spaces with complex geometric constraints, nonlinear dynamics, often with contact and impact, and long time horizons. Prior approaches have sought to solve these problems efficiently by embedding a great deal of domain knowledge into planning, but have relied heavily on human expertise to develop and exploit this knowledge. This process is tedious, error-prone, and does not scale well to harder problems that do not possess an obvious structure. This project will investigate automated strategies for planning systems to automatically discover common solution structures from past experience and to reuse this knowledge in new problems, with the ultimate goal of demonstrating a system that automatically optimizes planning strategies for a novel domain with minimal training and hand tuning.<br\/><br\/>Broader Impacts: The ability to solve large planning problems efficiently has myriad benefits to many fields of knowledge. But on a human level, this grant will provide the opportunity to recruit an undergraduate or Master's student intern from a minority-serving institution each summer, in cooperation with the Alliance for the Advancement of African-American Researchers in Computing (A4RC). Broader dissemination of the work will be achieved by distributing a research and educational software library for task-and-motion planning (PyTAMP), and integrating software with the open-source ROS and OMPL libraries. Research will be integrated with education in robotics and AI courses at the undergraduate and graduate level, as well as in K-12 robotics outreach.","title":"RI: Small: Discovery and Reuse of Domain Knowledge in Large Motion Planning Systems","awardID":"1218534","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["560558"],"PO":["564069"]},"193432":{"abstract":"Testing is an extremely important part of any software development effort, especially for programs that have access to sensitive resources (personal information, sensor data, etc.) and that can be reached through the Internet. The PIs' work will improve the state of the art in software testing for mobile applications running on the open source Android platform, resulting in fewer bugs and reduced testing effort.<br\/><br\/>The foundation of the PIs' work is random testing, where random numbers are used as inputs to an algorithm for constructing test cases. Although random testing has been shown to be highly effective for discovering serious bugs in complex software systems, it suffers from various problems including the fact that it is very difficult to engineer a random tester that doesn't spend a lot of time re-exploring the same application behaviors over and over again. The PIs will build upon their \"swarm testing\" work, which has been shown to be an inexpensive way to increase the diversity of random test cases, and also to increase their effectiveness in discovering bugs. Additionally, the PIs are investigating how to marry random testing with modern symbolic execution methods, and how to use feedback from executions of the software under test in order to improve the efficacy of random testing.<br\/><br\/>The development of more efficient and effective testing techniques and tools will lower the cost and raise the quality of software. Test coverage is a challenging, open problem that is being addressed here in a novel way.","title":"SHF: Small: Collaborative Research: Diversity and Feedback in Random Testing for Systems Software","awardID":"1218026","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["550238"],"PO":["564388"]},"193674":{"abstract":"Static type checking has brought us more reliable software. Types make programs more readable, prevent entire classes of mistakes, and help compilers optimize data layout and data access. Types also make it easier to use libraries and to design interfaces, and they make it harder to misuse data and write bad programs. An entirely different trend is as old as programming: self-application. In particular, self-application is popular in the form of implementing a language in itself. When the trends of types and self-application meet, a fundamental challenge for type systems arises. For example, what is the type of an interpreter that can interpret a representation of itself? And what is the type of a compiler that can compile a representation of itself? The goal of the project is to enable the next generation of typed, self-applicable interpreters, compilers, and partial evaluators. This next generation will guarantee that the output represents a typed program, and that the type of the output program is related to the type of the input program. The result will be self-applicable meta-programs that are more reliable and have all the benefits of static type checking.<br\/><br\/>Many popular languages have a self-interpreter, that is, an interpreter for the language written in itself; examples include Standard ML, Haskell, Scheme, JavaScript, Python, and Ruby. Similarly, many languages have self-compilers, that is, a compiler for the language written in itself. Also, some languages have a virtual machine written in itself, including Java and Self. The project will bring static type checking to self-applicable interpreters, compilers, and partial evaluators, and take such meta-programs to a higher level of reliability by ensuring that the output programs type check and therefore cannot contain entire classes of mistakes. The investigator will teach the results to students as part of existing undergraduate and graduate courses.","title":"SHF: Small: Typed Self-Application","awardID":"1219240","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["558389"],"PO":["564588"]},"193201":{"abstract":"The project builds on an existing citizen journalism activity to investigate how to use collaborative critique and construction of infographics to foster high school students? science literacy and engagement. Foundations are in sociocultural approaches to human action and learning, using the notions of mediated action and identification over time to explain development and preparation for future learning of individuals. Foundations are also in cognitive science work on spatial and visual thinking that has found that spatial metaphors provide a foundation for more abstract thinking, on notions of meta-representational competence development of understanding of the process of representation itself, and on collaborative idea development. Infographic design and idea development around it are distributed across people and tools in the environment, and learners better their own conceptual understandings through collaboratively bettering the representations they are using to communicate. The technological innovation is the socio-technical system that is being created around design of infographics as a way of promoting science learning and literacy and includes (i) the integration of infographics tools into learning activities to promote science learning and literacy, (ii) a case library of annotated infographics that can be used to promote idea development, ability to read and understand infographics, and critique and construction of infographics, and (iii) a case authoring tool that promotes reflection on one's infographic designs as learners write up their designs and are guided to annotate them with justifications for their designs. Research focuses on design of the socio-technical system that allows infographic design to promote learning and foster scientific literacy.<br\/><br\/>Drawing in more high schoolers to science, promoting scientific literacy, and promoting deeper science learning among high schoolers are huge challenges to the educational system. This project focuses on addressing those challenges through design of citizen journalism activities that can be integrated with other science curriculum activities. The activities themselves revolve around collaborative critique and construction of infographics. Infographics are visual representations of data and\/or information, used to express and communicate science, mathematical, technological, and sociological information and used extensively in journalism today. The project seeks both to help high schoolers learn to make sense of such graphics to use design of such graphics as a way to promote learning. The activities themselves require students to engage in data analysis and synthesis and to use science they are learning to develop visual representations that others can make sense of and learn from. The technology is authentic to what journalists use, and its use and the philosophy around its use could be powerful in drawing high schoolers to the wonders of science and helping them appreciate what scientists do, thus broadly promoting scientific literacy. Activities using the technology for infographic design have potential to engage and draw in not only those who already enjoy manipulating and analyzing data, but in addition, and more importantly, those who consider themselves writers and those who enjoy helping others learn. It also has potential to draw into science and advance science literacy in those who simply want to be recognized as making a contribution to their peer community. This work goes beyond current philosophies of schooling in suggesting that we may help people better their understanding by allowing them active roles in helping others learn and in communicating to the populous.","title":"EXP: Collaborative Infographics for Science Literacy (CISL)","awardID":"1217052","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":[517545],"PO":["562669"]},"192112":{"abstract":"The goal of this project is to develop a next-generation socio-computational citizen science platform that combines the efforts of human classifiers with those of computational systems to maximize the efficiency with which human attention can be used. Dealing with the flood of digital data that confronts researchers is the fundamental challenge of twenty-first century research. New techniques, tools and strategies for dealing with massive data sets, whether they consist of vast numbers of base-pair DNA sequences or terabytes of data from all-sky astronomical surveys, present an opportunity to establish a new paradigm of scientific discovery, but the task is not easy. In many areas of research, the relentless growth of data sets has led to the adoption of increasingly automated and unsupervised methods of classification. In many cases, this has led to degradation in classification quality, with machine learning and computer vision unable to replicate the successes of human pattern recognition. The growth of citizen science on the web has provided a temporary solution to this problem, demonstrating that it is possible to recruit hundreds of thousands of volunteers to make an authentic contribution to results, boosting human analysis through the collective wisdom of a crowd of classifiers. However, human classifiers alone will not be able to cope with expected flood of data from future scientific instruments. <br\/><br\/>This research will be carried out by a partnership between computer and social scientists, addressing research problems both in automated data analysis and social science through systems implementation, alongside field research and experiments with project participants. The intellectual merit of this project lies in its contribution to advancing knowledge and understanding in multiple domains of science. First, the work will contribute to developing new methods of computational data analysis, initially with analysis of astronomical images, and later extending to additional fields. Second, the project includes social science research to test and apply theories of human motivation and learning in an online context, which can then be applied to a broad range of social-computational problems. By mixing human and computational elements, the planned system has the potential to transform the application of citizen science and its approach to data analysis. <br\/><br\/>This project will advance science while promoting teaching, training and learning. One of the most significant broader impacts for its citizen science activities is enabling a community of hundreds of thousands of volunteers to participate in research, a powerful and rapidly developing form of informal science education. By choosing the relatively generic topic of image classification, beginning with astronomy but not limited to that field of science, the techniques developed under this grant will be of significant value to future investigations in similar research areas, thus enhancing the infrastructure for research and education.","title":"SoCS: Collaborative Research: Focusing Attention to Improve the Performance of Citizen Science Systems: Beautiful Images and Perceptive Observers","awardID":"1211071","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["519313","565342"],"PO":["565215"]},"194774":{"abstract":"For nearly 40 years, the United States has faced a critical problem: increasing demand for energy has outstripped the ability of the systems and markets that supply power. Today, a variety of promising new technologies offer a solution to this problem. Clean, renewable power generation, such as solar and wind are increasingly available. Hybrid and plug-in electric vehicles offer greater energy efficiency in transportation. The power grid that manages the generation, transmission and distribution of electric power, however, was designed and constructed in the 1960's and is ill-suited to handle these emerging energy technologies. Operating the electrical grid using power sources with random and uncertain availability, like solar and wind, requires new sensing and control methods. Widespread use of plug-in\/hybrid electric vehicles (PHEV) will not only require far greater power capacity, but will also radically change the peak usage profile, with large evening demand that cannot be shifted. To address this problem, our current power grid must be upgraded with a control system that uses the full power of modern sensor and computing technology to increase efficiency. This new power grid, with an integrated, modern IT control plane is commonly referred to as the Smart Grid, which uses distributed control, customer integration and market based control mechanisms. <br\/><br\/>It is critical to build security features into this Smart Grid from the beginning to ensure fairness, to provide warnings of misuse, to provide control algorithms that minimize damage from malicious behavior, and most importantly, to provide robustness and high-availability of power delivery even in the presence of bad-faith actors. This project develops methods to achieve security in power and market delivery. This entails a study of economic market models with stability as one objective but also in consideration of new sources of power and usage, both on the producer and the consumer sides. To achieve security, the following techniques are used synergistically: vulnerability discovery by formal analysis; on-line monitoring, anomaly and specification-based intrusion detection; and recovery and reconstitution by feedback control. Unique to this project, it is emphasized that the security enhancements take place at both the market level and the system level, requiring separate state-estimation models. These seemingly disparate domains are unified through mapping functions among the states of the respective models. By integrating the two control models, future Smart Grids can detect and respond to activity, either malicious or caused by natural disturbances, that threaten either level; the unification of the models permits the investigation of attacks that possibly impact both levels. Results of this work would lead to a secure and reliable Smart Grid architecture that is robust in the face of attacks on both the power delivery and market control systems. The inherent cross-disciplinary nature of the research will educate future researchers to be conversant in both cyber-security and associated economic issues, through co-advising between the departments of Computer Science and Economics at both UC Davis and Pennsylvania State University and through course modules developed under this work, again involving both campuses. Results will be transitioned to partnership with PG&E, SMUD, the West Davis Village, and other utilities in California, Pennsylvania, and Connecticut.","title":"TWC: Medium: Collaborative: Towards Securing Coupled Financial and Power Systems in the Next Generation Smart Grid","awardID":"1229008","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[521752,521753],"PO":["565264"]},"193564":{"abstract":"This research aims to advance the theory and practice of image and video processing with the emerging 3D cameras. The recent huge commercial success and excitement with low-cost consumer-grade color plus depth cameras such as Microsoft Kinect promise the wide deployment of depth sensors to every computer and display device. This rapid development demands fundamental new methods in processing depth input and its combination with regular color images and videos. Furthermore, this emerging depth-sensing technology has the potential to radically extend the possibilities of image and video processing.<br\/><br\/>Toward these aims, this research involves, (i) calibration and denoising the raw measurements from depth cameras via accurate physical and statistical modeling of the new depth sensors and typical 3D scenes, (ii) improving the quality and resolution of depth images by exploiting the synergy between color and depth cameras, (iii) integration of multiple depth frames as an extension of super-resolution in video from 2D to 3D using computer graphics tools, and, finally, (iv) employing the improved and integrated depth information with color videos in challenging and high-impact applications including color plus depth rendering, relighting, and encoding.","title":"CIF: Small: Image and Video Processing with Depth","awardID":"1218682","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[518402,518403],"PO":["564898"]},"193212":{"abstract":"This PI team is investigating three aspects of the use of video in education: i) how people learn with video, ii) the role of technology in supporting use of the vast corpora of video generated by decades of research, and iii) how video is used in generative ways to help focus learners on phenomena of interest. The researchers are basing their investigations on the Video Mosaic Collaborative (VMC), a rich collection that includes video from multiple longitudinal studies of children's mathematical reasoning, from urban, working class, and suburban communities in both classroom and informal settings, as children work individually and collaboratively on cognitively challenging math problems. The technological innovation of this project lies in the development of a tool for video selection and annotation, the VMCAnalytic. An analytic is a multimedia object that combines selected portions of video with accompanying text in a sequence of clips to yield a narrative for an intended purpose, which might include such objects as a lesson plan or an exploration of a research question. A critical design decision guides the development of this tool, to capture that information in a standard format that: i) could persist outside the tool, ii) is shareable and reusable in different formats (such as PDF with clickable video links), iii) is readily expanded and enhanced as researcher needs change, and iv) is recognized and treated as an information object in its own right. All developments are open-source, which widens the impact of the project. The project features two research and development cycles. The first cycle examines how college professors use analytics to create learning tasks for their students, and how their perception of what the analytic tool can do aligns with the research team's initial socio-cognitive analysis. The researchers are also studying how learners engage with tasks that were designed (e.g., how they make explicit how learning develops or how teacher moves influence student outcomes), allowing the development of conjectures about how students learn through the multimedia construction tasks. From initial analyses of that data the research team seeks to understand what kinds of supports and scaffolds need development and implementation. The second design cycle then builds on the initial studies and tests some of these supports and scaffolds.","title":"EXP: Constructing Multimedia Artifacts Using a Video Repository","awardID":"1217087","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7625","name":"REESE"}}],"PIcoPI":["532679",517569,517570,517571,"517573",517573],"PO":["560894"]},"193575":{"abstract":"Machine learning currently offers one of the most cost-effective approaches to building predictive models from data. However, practical applications of machine learning have to cope with sparsity, noise, and uncertainty of data present. Against this background, this project aims to: 1) Introduce a minimax framework for pattern learning to unify various regularization models, and characterize a variety of data uncertainty (e.g. incomplete data, local nonrigid displacements, lighting variations) and the corresponding regularizations regarding their intrinsic properties (e.g. sparsity, locality, robustness); 2) Establish new feature subset selection methods and quantify group effects as well as confidence levels\/intervals of selecting\/discarding features; 3) Construct new methods of sparse grouping representation for resilience to labeling errors by exploiting effective regularizations and their properties. The project aims to explicitly model various classes of data uncertainty (distortions) within a minimax framework, to optimize pattern learning process based on the worst distortion(s) in a given class, and to exploit regularization properties (e.g. sparsity, robustness).<br\/><br\/>Anticipated results of the project include: (1) New models and methods for accounting for various classes of distortions and for finding optimal solutions under the worst distortion(s) over a given class; (2) New methods for selecting features with confidence analysis and for learning predictive models resilient to labeling errors; (3) Rigorous evaluation of the resulting methods on real-world data sets.<br\/><br\/>The new machine learning algorithms resulting from this research find applications in many areas that rely on predictive modeling from large data sets(e.g. medical analysis, earthquake modeling). All of the software tools developed in this project will be made available to the scientific community, educators and students. The project offers enhanced research-based training opportunities for graduate and undergraduate students, as well as outreach to K-12 students, and efforts aimed at broadening the participation of under-represented groups in Computer Science research and education.","title":"III: Small: Pattern Learning in a Minimax Framework","awardID":"1218712","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[518429],"PO":["565136"]},"185963":{"abstract":"Physics ranks at the bottom of science disciplines in educating the growing US population of African-, Hispanic-, and Native-Americans. The situation is not improving, as the fraction of PhDs in physics awarded to underrepresented minorities (URM) among US citizens, about 5-6%, has not increased over the past decade. We propose to increase, within the next decade, the fraction of physics PhDs awarded to URM students toward levels more representative of the fraction of URMs that currently receive physics Bachelor?s degrees. We will do this by creating a national network of sustainable research-focused programs that bridge the transition from institutions where URM students receive their undergraduate education to top research universities. The American Physical Society (APS) occupies a unique position in the community to catalyze action and leverage resources to succeed in these goals and to bring about sustainable change in physics graduate education. <br\/><br\/>This project will establish \"Bridge Experiences\" that will help diverse students prepare for and make the transition to doctoral studies in physics. These Bridge Experiences will adopt best practices from existing programs, and follow either a Master?s degree or a post-Baccalaureate example. We have brought together Doctoral Granting Institutions (DGIs), Minority Serving Institutions (MSIs), and concerned organizations to inform and help build a national effort that will offer sustainable solutions to improved support, mentoring, and progress monitoring to ensure that students make the transition smoothly and complete their studies. Physics offers an ideal test-bed for Bridge Experiences, as only modest numbers of students are required to demonstrate success in mitigating the losses that currently occur in the transition to doctoral studies. We choose to focus on doctoral students because these students will become a cadre of future leaders who can catalyze national change in science education. In addition, the research and assessment components of this project will identify, document, and disseminate best practices that can serve as a model for other disciplines to encourage more of the nation?s capable underrepresented minorities (URM) undergraduates to pursue doctoral degrees. <br\/><br\/>Intellectual Merit This program will use existing knowledge of Bridge Experiences that have demonstrated effectiveness in increasing minority participation at the doctoral level. Our project incorporates strong evidence about support structures that predict academic success of URM students, and establishes links between MSIs and DGIs through research activities, collaboration, and visits. We will conduct research on admissions and retention in physics doctoral programs, and the correlation of GRE scores with successful completion of a PhD. The program will utilize our 30+ year experience in supporting minorities through our Minority Scholarship Program and its associated mentoring efforts, our long-standing connections with the physics research community, and our decade-long efforts in working with individuals and universities to promote teacher education through the Physics Teacher Education Coalition (PhysTEC) project. <br\/><br\/>Broader Impacts This project will provide a model of graduate education for URM students that can be applied to other Science, Technology, Engineering and Mathematics (STEM) fields as well as improved links between MSIs and DGIs. In addition, physics is taken by nearly every STEM student, and significantly increasing the number of minority PhDs in physics will enhance the diversity of the physics academy and professional workforce. This project is intended to meet the challenges posed by the National Academy?s report Rising Above the Gathering Storm, including ensuring that the workforce brings a diverse perspective to scientific and technological challenges. Since many doctoral students we prepare will become tomorrow?s academic, industrial and government leaders, educating more minority PhDs will have a multiplicative effect in educating and inspiring students at all stages in the system, and will help address disparities that persist today.","title":"Physics Bridge Program","awardID":"1143070","effectiveDate":"2012-09-15","expirationDate":"2017-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"9134","name":"PHYSICS EDUC & INTERDISCIP RES"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1710","name":"CONDENSED MATTER PHYSICS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1106","name":"Division of HUMAN RESOURCE DEVELOPMENT","abbr":"HRD"},"pgm":{"id":"1515","name":"MINORITY GRADUATE EDUC ACTIVIT"}}],"PIcoPI":["167485",499079],"PO":["562518"]},"193344":{"abstract":"Learning and inference in distributed settings is an important from both a scientific and engineering perspective. A typical instance of the problem is a network of individual sensors or agents attempting to infer a global distribution that governs their local observations. By passing messages the agents can individually make inference about a global phenomenon. This research investigates communication and networking paradigms that can enable a network of individual agents to collaboratively estimate distributions over high dimensional spaces, even when individual observations are severely limited in accuracy, space, or time. <br\/><br\/>In particular, the investigators study how individual decision makers can integrate two kinds of information: local observations and messages from their neighbors in the network. Both observation and messaging can be thought of as sampling : individuals sample their own environment and sample the opinions of their neighbors. Central to the approach is that the agents generate simple messages at random from an internal estimate of the global distribution of interest. The first major goal of this project is to develop a mathematical framework and analysis techniques to understand if and when this limited form of learning and communication is sufficient for an individual to estimate and learn distributions and\/or global parameters governing the observations of all nodes. The technical approach is a blend of analysis techniques ranging from stochastic approximation, randomized algorithms, and statistical physics. <br\/><br\/>Applications for this work range from mathematical modeling of messages and opinion formation in social networks, communication protocols for distributed optimization, and estimation of parameters in data networks. The work will cover several related problems : estimating high-dimensional histograms of data held in the network, parametric estimation using a mix of Bayesian and non-Bayesian techniques, and estimation of more complex generative models. The final part of the work is to apply these methods to peer-peer networks and social network modeling. The broader impact of this work is to further develop the interdisciplinary field of network science, which impacts both quantitative social sciences and engineering. The PIs will develop educational materials and organize research activities to help bring together different research communities interested in networks and social learning.","title":"CIF: Small: Collaborative Research: Inference by Social Sampling","awardID":"1217619","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["553607"],"PO":["564924"]},"193355":{"abstract":"As high-performance processor chips continue to integrate more components such as general-purpose cores or special accelerator units, increasing demand for a communication substrate with higher performance and better energy efficiency is evident. Unfortunately, continued device scaling has exacerbated the fundamental challenges facing on-chip metal wires, such as increased loss, delay, dispersion, and cross-talk. Alternatives to the conventional communication schemes are clearly imperative as technology progresses. Existing solutions for off-chip interconnection such as packet-switching networks and optics are finding their way into the on-chip environment. However, these solutions evolve under a different set of constraints and goals in the off-chip environment and are not automatically suitable in the on-chip environment. For instance, a packet-switched interconnect provides scalable throughput, but at significant communication latency and energy costs.<br\/><br\/>This project takes a multidisciplinary approach and explores the design of latency-centric communication substrates based on novel wide-band, pulse-based communication mechanisms and architectural support that dovetails the circuits. Early evidence suggests there are significant potential benefits, including superior latency at sufficiently high throughput and extremely low energy costs. <br\/>The success of this project can critically impact future microprocessor and other complex system-on-chip design methodology. This project also contributes to the training of students at the intersection of digital and analog circuit and architecture design ? an important area for the future of the technology industry.","title":"CSR: Small: Towards a Co-Designed Latency-Centric On-Chip Communication Substrate","awardID":"1217662","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["548271",517923],"PO":["565255"]},"193487":{"abstract":"Although the effect of latency (i.e., how quickly a system can respond to user input) on users has been one of the fundamental research areas in virtual reality (VR) for many years, latency's effect on persons with physical disabilities is still unknown. The PI's objective in this project is to acquire a better understanding of how latency of visual feedback in VR can impact interaction performance, perception, and subjective experience for users with reaction time and reflex deficits (e.g., due to neurological, vestibular, balance issues), and to investigate how this ultimately impacts the effectiveness of VR-based rehabilitation. The PI's central hypothesis, based on preliminary data, is that latency will be less perceivable but will have a more significant impact on interaction performance for persons with disabilities as compared to healthy persons. To test this hypothesis, the PI will focus on the main set of applications typically used in VR rehabilitation: games, exercise, and accessibility. He will explore, for members of the target community, latency's impact in VR rehabilitation games, on the effectiveness of visual feedback during rehabilitation exercises in virtual environments (VE), and on accessibility in a VE. Through a series of empirical studies, the PI will determine latency thresholds in VR with respect to interaction performance, physiological response, perception, and subjective impressions. <br\/><br\/>Broader Impacts: Project outcomes will afford a deeper understanding of the effectiveness of VR as a medium for rehabilitation. If the PI's hypothesis is confirmed, the potentially negative implications for the efficacy of VR-based rehabilitation may disrupt accepted theories and revolutionize design guidelines for this type of rehabilitation. Alternatively, this research may inspire other researchers to develop approaches to combat latency in VR specifically for disabled persons, which will also produce further vertical advancement in the field. More generally, this research will provide a critical step towards the grand challenge of universal usability in VR.","title":"HCC: Small: Determining the Effects of Latency in Virtual Reality Physical Rehabilitation","awardID":"1218283","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["562961"],"PO":["565227"]},"198943":{"abstract":"Our physical world presents an incredibly rich set of observation modalities. Recent advances in wireless sensor networks (WSNs) enable the continuous monitoring of various physical phenomena at unprecedented high spatial densities and long time durations and, hence, open new exciting opportunities for numerous scientific endeavors. Since sensor nodes are unattended and battery-powered, network monitoring\/inference from indirect measurements at the sink(s) and energy conservation are critical in the deployment of large-scale environmental WSNs. Therefore, a viable framework for energy-efficient network monitoring and data collection is fundamentally important to significantly improve WSN management\/operations and reduce its deployment costs. <br\/><br\/>This proposal is devoted to a fundamental investigation of energy-efficient network monitoring\/inference and data collections in large-scale WSNs, based on the recent breakthrough of compressed sensing (CS) through an integrated theoretical and empirical approach. The research plan aims to develop a novel and rigorous framework of topology inference for real-world WSNs operated in highly noisy communication environments. This proposed exploratory research is different from current approaches, which may create a new paradigm of optimal design, development, and management\/operations for large-scale WSNs to significantly extend their lifetime. This, in turn, would lead to a substantial reduction of the current prohibitive cost of WSN deployment, and thus could be high-reward for the deployment of large-scale monitoring WSNs for scientific, civic, national security, and military purposes in the near future. The proposed education plan creates a new interdisciplinary educational practice for both undergraduate and graduate students through hands-on experience with an extended WSN testbed. The outreach includes summer camps for school students using an extended WSN testbed.","title":"EAGER: Collaborative Research: Network Inference and Data Collection Based on Compressed Sensing in Large-Scale Wireless Sensor Networking","awardID":"1251995","effectiveDate":"2012-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["460719"],"PO":["565303"]},"193135":{"abstract":"Bullying has been recognized as a serious national health issue. Traditional approaches to the scientific study of bullying are hindered by data acquisition. For example, the standard approach has been to conduct personal surveys in schools. Due to its relatively small sample size and low temporal resolution, neither the true frequency of bullying over the population nor the evolution of bullying roles can be satisfactorily studied. The traditional approaches are also very labor intensive. <br\/><br\/>Social media has developed to the point where it contains enough signal about bullying. This project develops novel machine learning models that automatically monitor and analyze publicly available social media data to understand bullying. These machine learning models reconstruct hidden bullying episodes from a sequence of social media posts. They automatically determine who participated in which bullying episode as what role. In addition, this project conducts human studies on bullying in school and in social media in parallel, by collecting self-report surveys by school-aged children and their social media posts simultaneously. Such studies correlate the traditional psychological approach and social media data on bullying. Taken together, the project will provide significant new scientific data toward understanding, intervention, and helping policy-making regarding bullying.","title":"III: Small: Advancing the Scientific Understanding of Bullying Through the Lens of Social Media","awardID":"1216758","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["560208",517370],"PO":["565136"]},"193498":{"abstract":"Static formal verification is a crucial last line of defense at the lowest levels of the systems software stack, as at those levels we cannot fall back on dynamic mechanisms to shield against bugs, crashes, or malicious attacks. The last decade saw significant advances in formal verification research but progress has been hindered by the vexing challenge of precisely inferring invariants of data values that are stored within unbounded heap data structures and manipulated by function pointers, callbacks, and other higher-order constructs. These problems have been elegantly addressed by the machinery of dependent types which exploit a syntactic programming discipline, to compositionally propagate correctness invariants through data structures and higher-order functions, thereby facilitating precise formal verification. However, mainstream adoption of dependent types is blocked as the machinery has been largely developed in the context of interactive proof assistants or purely functional languages.<br\/><br\/>This research will develop the theory, algorithms, and tools required to bring the transformative software engineering benefits of dependent type based software verification to mainstream, systems programming languages like C. To this end the PI will use the framework of Liquid Types which demonstrates how the powerful machinery of abstract interpretation and software model checking can be used to automatically infer dependent types, thereby automating their use in formal verification. If successful, this research will directly benefit software developers, by incorporating verification smoothly within a familiar technology (types), and by providing rich API specifications that will simplify code review and component reuse; program analysis designers, by providing a general framework that can be instantiated to obtain multiple domain- and application- specific verification engines; and ultimately, end users, by providing static guarantees for a variety of critical safety and security and reliability properties.","title":"SHF: Small: Next-Generation, Dependent Type-based Software Model Checking for C","awardID":"1218344","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["529115"],"PO":["565264"]},"196776":{"abstract":"Real world data, such as World Wide Web, social networks, corporate knowledge networks, biological networks, semantic networks, etc., can be abstracted in the form of a massive and complex graph, with millions to billions of nodes and edges. With the explosion of such data, there is a pressing need for data mining, analysis, and querying tools to rapidly make sense of and extract knowledge. However, effectively leveraging the resources of modern architectures and mining such large graphs for interesting patterns remains challenging. At the same time commodity desktop architectures that have processors with multiple cores and graphics processors (with hundreds of stream cores) are opening up significant opportunities for parallel graph analytics and management on the desktop.<br\/><br\/>This exploratory research seeks to scale up the performance of graph mining and clustering algorithms on modern desktop supercomputers to leverage the power of multi-core systems equipped with graphics processors, and to explore and develop new algorithms for reducing the search space and and the amount of data processed.","title":"CCF: EAGER: Collaborative Research: Scalable Graph Mining and Clustering on Desktop Supercomputers","awardID":"1240646","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["541893"],"PO":["565272"]},"193388":{"abstract":"Testing is an extremely important part of any software development effort, especially for programs that have access to sensitive resources (personal information, sensor data, etc.) and that can be reached through the Internet. The PIs' work will improve the state of the art in software testing for mobile applications running on the open source Android platform, resulting in fewer bugs and reduced testing effort.<br\/><br\/>The foundation of the PIs' work is random testing, where random numbers are used as inputs to an algorithm for constructing test cases. Although random testing has been shown to be highly effective for discovering serious bugs in complex software systems, it suffers from various problems including the fact that it is very difficult to engineer a random tester that doesn't spend a lot of time re-exploring the same application behaviors over and over again. The PIs will build upon their \"swarm testing\" work, which has been shown to be an inexpensive way to increase the diversity of random test cases, and also to increase their effectiveness in discovering bugs. Additionally, the PIs are investigating how to marry random testing with modern symbolic execution methods, and how to use feedback from executions of the software under test in order to improve the efficacy of random testing.<br\/><br\/>The development of more efficient and effective testing techniques and tools will lower the cost and raise the quality of software. Test coverage is a challenging, open problem that is being addressed here in a novel way.","title":"Diversity and Feedback in Random Testing for Systems Software","awardID":"1217824","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[517993],"PO":["564388"]},"198833":{"abstract":"Security is very difficult to use, and staying safe online is a growing challenge for everyone. It is especially devastating to inexperienced computer users, who may not spot risk indicators and may misinterpret currently implemented textual explanations and visual feedback of risk. This work explores, evaluates, and compares the effectiveness of several online safety education modules for users of various skill levels and the importance and effectiveness of visual feedback when encountering security threats. This interdisciplinary work, with psychologists and computer scientists playing crucial roles, is developing and testing specific user feedback strategies to determine their relative effectiveness in keeping users from making security-critical mistakes, and unambiguously informing users when security failures have occurred. This research is a vital step to determine what works, what does not work, and to get users to pay attention to important risk signals that may otherwise go unnoticed.","title":"EAGER: Education-optional Security Usability on the Internet","awardID":"1251432","effectiveDate":"2012-09-01","expirationDate":"2015-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[533430,"562257"],"PO":["565327"]},"198734":{"abstract":"The Web has made humans smarter, providing ready access to vast amounts of knowledge and facts. The Semantic Web has the capacity to similarly enhance computer programs and devices by giving them access to enormous volumes of data, facts and knowledge. This project is exploring the feasibility of automatically extracting new knowledge directly from data found in spreadsheets, database relations, and document tables and representing it as highly interoperable linked open data (LOD) in the Semantic Web language RDF. The extraction is guided by probabilistic graphical models that use statistical information mined from current LOD knowledge resources. To demonstrate the potential payoff of the research, the system is used to extract knowledge from tables collected from medical journals and tables from web sites like data.gov. <br\/><br\/>While the W3C semantic web languages RDF and OWL are used to represent the knowledge, the results are applicable to other semantic data frameworks such as Microdata (Search Consortium), Freebase (Google), Probase (Microsoft) and the Open Graph (Facebook). The open sourced prototype software allows other researchers to experiment with automatically producing semantically enriched data from tables for their domains.<br\/><br\/>If successful, such software extraction systems are expected to become part of a new online knowledge ecology -- both consuming existing LOD knowledge to understand the intended meaning implicit in a table and producing new facts and knowledge that will become part of Web. This represents a dramatic increase in the breadth and depth of public semantic data that can make \"big data\" analytics more effective.","title":"EAGER: T2K: From Tables to Knowledge","awardID":"1250627","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[533183,"563576"],"PO":["565136"]},"194026":{"abstract":"With the Internet becoming the dominant channel for marketing and promotion, online advertisements (ad for short) are also increasingly used for propagating malware, committing scams, click frauds and other illegal activities. These activities, which we call malvertising, systematically deliver malicious ad content and victimize visitors through an infrastructure, which includes malicious advertisers, ad networks, redirection servers, exploit servers and others. Our preliminary study shows that most of such malvertising activities are missed by popular detection services such as Google Safe Browsing and Microsoft Forefront. This points to a disturbing lack of understanding of such web malvertising activities, which renders existing countermeasures less effective, and an urgent need to study the features of this threat to better prepares us to defend against it. <br\/><br\/>The proposed research endeavors to gain a holistic, in-depth understanding about the scope and magnitude of malicious display, search and contextual advertising, features of their infrastructures and ad content, behavior of malicious ad-related parties, and economics of this underground business. Based upon such a understanding, we continue to develop novel infrastructure-aware technologies to detect these malicious activities, which include effective malvertising analysis techniques that capture malicious ads, advertisers and ad networks through web patrol, client-side defense that protects a user from stepping into exploit servers and publisher-side countermeasures that empower legitimate publishers and ad networks to shield their customers from such attacks. This research involves industry collaborators and also contributes to mitigation of other related threats such as black-hat Search Engine Optimization, SPAM-based phishing and drive-by-downloads.","title":"TWC: Small: Knowing Your Enemy: Understanding and Counteracting Web Malvertising","awardID":"1223477","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["526376"],"PO":["565327"]},"195138":{"abstract":"The NSF Sustainable Energy pathways (SEP) Program, under the umbrella of the NSF Science, Engineering and Education for Sustainability (SEES) initiative, will support the research program of Prof. Sridhar Viamajala and co-workers at the University of Toldeo, Prof. Robin Gerlach and co-workers at Montana State University, and Prof. Gregory Characklis of the University of North Carolina at Chapel Hill. This project will focus on high lipid-producing native alkaliphilic algae which are less susceptible to detrimental contamination (due to their extreme growth environment) and able to accumulate large amounts of lipid. In addition, the project will develop and test low-energy options for cell harvesting as well as for fuel and high value product generation. Through integration of unique and robust advances in algal culture stability and productivity as well as research targeted on the critical processes of algae harvesting and conversion of biochemicals, scalable, environmentally and economically acceptable processes to produce renewable fuels and chemicals will be developed. <br\/><br\/>The results of this project will be of interest to industry, local communities, regulators, and academia. Specific outreach efforts will be directed towards each of these primary stakeholders through: (1) dissemination of research outcomes to local community members and industry stakeholders at conferences, trade meetings and by local community and legislator engagement; (2) engagement of underrepresented Native American students from Montana high schools and tribal colleges in summer research activities as well as undergraduate researchers in the PIs' laboratories; (3) education and training at the K-12 level through training of high school teachers; (4) development of an interdisciplinary distance-learning course sequence on \"Sustainable Biofuels\" that will cover broad topics on the fundamental biology, chemistry, engineering and sustainability aspects of biofuel production; (5) generation of information useful in making informed judgments regarding tradeoffs between cost and environmental impact using the results of the life-cycle analyses.<br\/><br\/>This sustainable energy pathway minimizes energy and materials requirements through use of low-energy chemical and biological processes coupled with nutrient and water recycle. The global warming potential (GWP) of such biorefineries would be significantly lowered through the use of energy-efficient cultivation, harvesting and conversion methods as well as by minimizing external demands for nutrients and water. Overall, these solutions to the challenge of economic and sustainable energy from algae will be transformative through the development of novel scientific and technical advances, balanced with environmental, economic and societal merits. These algal farms will not compete with arable lands, food production, or use high quality water.","title":"SEP Collaborative: Alkaliphilic microalgae-based sustainable & scalable processes for renewable fuels and products","awardID":"1230710","effectiveDate":"2012-09-15","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"8026","name":"Sustainable Energy Pathways"}}],"PIcoPI":[523064],"PO":["556345"]},"195259":{"abstract":"Telemedicine technologies offer the opportunity to frequently monitor patients' health and optimize management of chronic illnesses. Given the diversity of home telemedicine technologies, it is essential to compose heterogeneous telemedicine components and systems for a much larger patient population through systems of systems. The objective of this research is to thoroughly investigate the heterogeneity in large-scale telemedicine systems for cardiology patients. To accomplish this task, this research seeks to develop (i) a novel open source platform medical device interface adapter that can seamlessly interconnect medical devices that conform to interoperability standards, such as IEEE 11703, to smart phones for real-time data processing and delivery; (ii) a set of novel supporting technologies for wireless networking, data storage, and data integrity checking, and (iii) a learning-based early warning system that adaptively changes patient and disease models based on medical device readings and context.<br\/><br\/>Cardiovascular disease is a major health problem and the leading cause of death in the United States. Telemedicine technologies developed in this project have the potential to dramatically improve the quality of home health care with low cost for medical community. This research acquires a clear understanding of how to address heterogeneity issues in telemedicine systems, which allows effectively compose and interconnect individual telemedicine components together with low cost. For developers, this research significantly reduces the design and development costs for building interoperable large-scale telemedicine systems. The research content is being integrated into undergraduate, graduate system courses, clinician training course as well as high school research projects.","title":"SHB: Type I (EXP): Collaborative Research: Heterogeneous Large-Scale Telemedicine for Cardiology Patients","awardID":"1231547","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":["553656","553657"],"PO":["564778"]},"195149":{"abstract":"The NSF Sustainable Energy pathways (SEP) Program, under the umbrella of the NSF Science, Engineering and Education for Sustainability (SEES) initiative, will support the research program of Prof. Dennice Gayme and co-workers at Johns Hopkins University, Prof. Aranya Chakrabortty and co-workers at North Carolina State University, and Prof. Judith cardell and co-workers at Smith College to develop a method to integrate heterogeneous energy resources to form sustainable power networks. The objective of this program is to examine how the control and design of large-scale and distributed energy resources can facilitate the grid-integration of large amounts of renewable energy. Wind energy is used as a representative, heterogeneous and variable renewable energy source to address the following three fundamental challenges: (I) the need to manage stability, (II) the need to cost effectively maintain reliable operation, and (III) the need to reflect stability and operational criteria in markets and policy. Models of the power grid, such as continuum representations (partial differential equations that directly support combined spatial and temporal analysis) and network power flows that include storage and demand-side management, will be developed and used to address stability, control, reliability, and performance\/efficiency questions. As input for these continuum and power flow models, the project will utilize outputs from fluid dynamics (\"Large-Eddy\") simulations that model unsteady wind farm and atmospheric boundary layer interactions and have been validated using laboratory and field observations. Analysis using the grid level models will both inform and be shaped by the design of new regulatory and economic reforms that will enable renewable resource purveyors to participate in power markets. Connections between operational and market issues such as power flow regulation, grid operation and risk mitigation strategies using storage and demand-side management will be made by leveraging tools based on optimization, convex relaxations and optimal control theory, which are common to the economics and controls communities. <br\/><br\/>This project will facilitate a more sustainable power system through its technical contributions, education, training and mentorship. Research topics will form the basis for student projects in new sustainable energy related curricula at all three participating institutions. Summer undergraduate research opportunities will provide students with skills for participating in sustainable energy research and future employment in related industries. This program will directly facilitate NSF's STEM related goals through JHU's participation in the NSF-funded Center for Integration of Research, Teaching, and Learning (CIRTL), the Science House partnership between NCSU and local K-12 teachers, and the involvement of the only all-women engineering program in the US (Smith College). At JHU this project will operate under the aegis of E2SHI, which promotes cross-disciplinary research, outreach, and education for critical environmental, energy and sustainability issues. E2SHI is committed to systems-level integrated research and outreach for sustainability.<br\/><br\/>The tools to be developed will help facilitate the transformation of our current fossil fuel based power system to one that is safe, reliable and efficient without compromising energy security or exhausting resources needed for future generations. The project's results will be directly relevant to the electric power industry and its regulators as they are faced with the challenges of incorporating larger fractions of highly heterogeneous renewable resources, such as wind energy, into the grid. Specifically, the results will provide system operators with better representations of the impacts of renewables, and better control tools to mitigate those impacts; planners and investors with a framework for evaluating optimal resource allocation; and policy makers with a systematic means of investigating how new regulations and market rules can incent effective deployment of these tools and resources. Complementary educational programs and mentorship will develop researchers and practitioners with the skills required to create and advance this sustainable energy future.","title":"SEP Collaborative: Integrating Heterogeneous Energy Resources for Sustainable Power Networks - A Systems Approach","awardID":"1230788","effectiveDate":"2012-09-15","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"8026","name":"Sustainable Energy Pathways"}}],"PIcoPI":["529487","529488","538212"],"PO":["564728"]},"198658":{"abstract":"Future cloud services are expected to increasingly involve and synthesize capabilities from multiple clouds. Applications from different organizations may establish collaborative relationships and share information dynamically in cloud computing. In this increasingly complex scenario, both consumers and service providers will face new challenges. For example, consumers will need to be able to identify the best service providers from a potentially huge pool, which could be computationally demanding. Service providers will need to be able to ensure the security and privacy of data shared among loosely connected subcontractors.<br\/><br\/>This project proposes a novel brokerage-based architecture to promote cost-effective cloud provisioning. Specifically, the PIs will devise efficient indexing structures to facilitate the management of massive information generated by a large number of service providers with a variety of properties. The PIs are developing necessary services to allow effective cloud-brokerage, such as service selection for consumers, service negotiation between consumers and their service providers, and service agreement delegation among service providers involved in a compound service. Along with the service development, the work will produce new policy analysis, composition and delegation techniques that accommodate the unique characteristics of the cloud.<br\/><br\/>The research in this project will help significantly streamline the selection and management of cloud computing services, and will open up new business opportunities by providing cloud brokerage services. Moreover, the proposed approach may also help reduce the vendor lock-in problem which is a long standing major concern among consumers.","title":"CSR: EAGER: Collaborative Research: Brokerage Services for the Next Generation Cloud","awardID":"1250327","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[533006],"PO":["565255"]},"196007":{"abstract":"1236514<br\/>PI: Radhakrishnan<br\/><br\/>Targeted drug delivery is an emerging application of nanotechnology. It involves designing pharmaceuticals by packaging them into nanocarriers and targeting them for intravenous delivery directly to the diseased tissue. Benefits of this approach include optimal drug dosage in-terms of the drug reaching diseased tissue (enhanced therapeutic efficacy) and a concomitant decrease in drug reaching normal tissue (reduced toxicity). Success is directly dependent on the design and synthesis of carrier particles that have specific features such as particle size\/shape and surface coverage with binding molecules specific to the biomarkers (target receptors) of diseases being treated. Optimal design leads to the desired, and necessary, initial event, namely, selective binding and arrest of the carrier particle to endothelial cells in blood vessels within the diseased tissue, followed by carrier internalization into the cells post arrest. Using computational modeling and engineering principles, the project will investigate experimental and design parameters such as receptor density on nanocarriers, nanocarrier size & shape, and binding response to blood flow in order to optimize the targeting the nanocarriers to specific (diseased) cells. The model will integrate multiple length and time scales involving blood flow, nanocarrier arrest, cell membrane mobility, and biomolecular receptor-ligand interactions, all of which contribute to the physical environment for nanocarrier binding, and collectively define the efficacy of nanocarrier arrest on the target cell. The model will delineate nanocarrier binding and arrest influenced by hydrodynamic forces resulting from blood flow, expression-levels of specific (target) receptors on the endothelial cell surface, their lateral diffusion on the membrane, the presence or absence of a glycocalyx, and cell membrane mobility. The model will be validated against quantitative cellular and animal experiments and will be employed to make predictions for optimal design of nanocarriers.<br\/><br\/>Success of targeted drug delivery protocols relies in part on the development of rational technologies designing nanocarrier pharmaceuticals and clinical methods for injecting such functionalized, targeted drug carriers into the blood stream close to the disease tissue. The results of the project will lead directly to a design platform for targeted nanocarriers to endothelial cells, which line blood vessels. The versatility of the modeling combined with experimental approaches will then enable their utility in context specific pharmacological applications, e.g., designing carriers for specific\/different disease states, preventive (prophylactic) versus therapeutic targeting, targeting in arteries versus veins, and exercising control on toxicity. Project results will directly facilitate the optimal engineering design, as well as impact the clinical translation of such drug delivery systems for targeted disease treatment.","title":"Multiscale Modeling of the Nanocarrier-Cell Ahesion Interface in Targeted Drug Delivery","awardID":"1236514","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1415","name":"PARTICULATE &MULTIPHASE PROCES"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1491","name":"BIOTECH, BIOCHEM & BIOMASS ENG"}}],"PIcoPI":[525392,525393,525394],"PO":["564844"]},"198559":{"abstract":"In recent years, there has been an explosive growth in mobile applications, most of which need to serve global audiences. Cloud computing provides unique opportunities for the application service providers to manage and optimize application delivery over geographically distributed computing resources. The PIs of this project are developing an open application delivery network platform which will allow Internet Service Providers (ISPs) to offer load balancing, fault tolerance, and numerous other application delivery services to the application service providers. <br\/><br\/>The PIs also plan to augment the flow abstraction layer of Software Defined Networks to add adequate support for application-level flows using several other recent innovations such as cross-layer communication, ID\/Locator split, MPLS-like label switching. The claims will be validated through a proof-of-concept implementation of a use-case scenario designed over a prototype switch implementation. <br\/><br\/>A goal of the proposed design is to be evolutionary in the sense that it can coexist and is backward compatible with the current Internet and can be deployed incrementally now with a small number of new devices. The in-going research is designed to transform application delivery over the Internet. It would make significant contributions towards developing a set of generic architectural primitives that may be used for developing application specific networks on shared network infrastructure.","title":"Collaborative Research: Eager: An Application Delivery Platform for Mobile Apps on Global Clouds","awardID":"1249678","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[532760],"PO":["565255"]},"189506":{"abstract":"Femto-aided cellular networks appear to be one the best solutions to achieve multi-fold capacity needed for future wireless networks. However, Femto-aided cellular systems have an information architecture that is very different from current planned and centrally managed cellular architecture. In this project, both the design of information architecture to acquire network state information and the optimal use of the resulting NSI will be addressed. The project is organized into three symbiotic research thrusts on network-aware physical-layer (PHY) coding schemes, network protocols and algorithms leveraging advanced PHYs, and their architectural prototypes. The first thrust utilizes recent innovations in deterministic models of wireless networks and develops novel physical-layer cooperative encoding and decoding schemes that operate with delayed, inconsistent, and erroneous NSI. The second thrust builds on the new physical-layer coding schemes to design network-scheduling algorithms to address performance issues. Finally, the third thrust utilizes the WARP programmable radios and studies implementation challenges of the protocols. The project goals of foundational design for Femto-aided cellular networks will have significant impact on industry practice. The PIs will facilitate technology transfer through their established industry affiliate program. A broad range of education and outreach activities will also complement the research agenda, including integration of research findings into the courses, promoting underrepresented and undergraduate populations, and engaging with the middle\/high school community to raise the level of interest in engineering and mathematics.","title":"NeTS: Medium: Collaborative Research: Information Architectures for Femto-Aided Cellular Networks","awardID":"1161596","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["548311"],"PO":["565303"]},"192960":{"abstract":"Modern marketplaces, enabled by recent advances in information<br\/>technology, are becoming ever more complex, dynamic and<br\/>interconnected. Customers are increasingly more informed about the<br\/>choices available to them and are thus able to make better decisions.<br\/>For firms, this presents both opportunities and challenges. On the<br\/>positive side, the firm has a bigger than ever array of tools at its<br\/>disposal that enable it to better sell to its customers. Such tools<br\/>are both computational (pricing algorithms, customer targeting data,<br\/>social networking information) and economical (dynamic mechanisms) in<br\/>nature. The challenging aspect for the firm is that modern technology<br\/>also allows consumers to easily learn the opinions of fellow customers<br\/>and to be strategic in their decision-making. Having such strategic<br\/>and networked customers is not necessarily a net negative for the<br\/>firm, but it certainly makes the firm's problem of how to sell its<br\/>products a more complex one.<br\/><br\/>This project aims to develop a framework for understanding how to<br\/>sell goods in markets that are fundamentally dynamic and<br\/>interconnected. The project will research what mechanisms are revenue-optimal<br\/>(or near-optimal, while being simple and computationally tractable) in<br\/>dynamic settings where customers can learn from each other. The PIs will<br\/>study the effect of network learning on the firm's behavior and<br\/>whether it forces the firm to share some of the costs associated with<br\/>consumer learning. The project will also focus on how the social<br\/>networkstructure affects the optimal mechanism and will try to<br\/>understand whether such network learning effects lead to lower (or<br\/>higher) revenue for the firm and aggregate consumer welfare.<br\/><br\/>Fundamental research in the dynamics of networked markets provides<br\/>deeper knowledge to a broad audience that includes firms, consumer<br\/>groups and regulators. Curriculum development at the interface of<br\/>operations research, information systems and computer science will<br\/>benefit from this research experience.","title":"ICES: Small: Collaborative Research: Selling to Networked Markets","awardID":"1216009","effectiveDate":"2012-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":[516920],"PO":["565251"]},"190793":{"abstract":"This award is to acquire an 8 node multicore hybrid CPU+GPU system in support of research in use of multicore-based, GPU-based and hybrid high performance computing applications in the areas of large and complex system modeling and their solution methods, computational fluid dynamics, high performance data and stream processing, and dependable and high integrity methods on hybrid multicore and GPU methods. The proposed configuration also includes one front node and one storage server node with 80 TB disk capacity interconnected by an existing Infiniband network for multi-tiered, hierarchical parallel computing. Each compute node consists of Quad AMD new Interlagos processor 6220 with 8-core operating at 3.0GHz (can go up to 3.6GHz) and 512 GB of RAM, and a dual 448-core Tesla Fermi GPUs with 6 GB memory. The system will be used to support CISE centric interdisciplinary high performance computing research.<br\/>This project establishes a computational instrument deploying multiple multicore hybrid CPU+GPU systems to support applications requiring hybrid high performance computing machinery. The instrumentation facilitates research in multicore- and GPU-based high performance computing in the context of the diverse set of applications at the frontiers of research: modeling of large and complex systems and their solution methods, such as high performance data and stream processing, dependable and high integrity methods on hybrid multicore and GPU, and computational fluid dynamics.","title":"II-NEW: Distributed Computing Laboratory for Large Scale System Modeling and Analysis","awardID":"1205413","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["521840",511484,511485,511486],"PO":["565272"]},"191420":{"abstract":"This project aims to develop a new, bistable electroactive polymer that combines large actuation strain and energy density with variable stiffness and bistable deformation. The technical approach of the project involves: (1) synthesizing new polymers comprising interpenetrating polymers network to achieve stable, high-strain actuation; (2) investigating ultrathin carbon nanotube coatings for fault tolerance and enhanced operation reliability; (3) reducing the driving voltages of electroactive polymers to around 200 V by synthesizing new polymers with high dielectric permittivity as well as by developing processing techniques to produce high-quality polymer thin films; and (4) fabricating compact modular actuators that can be readily integrated into robotic systems. The potential transformative technical impact of this project is a radically new actuator material that can reproduce the structural, actuation, and sensing functions of muscles, and can be inserted into a broad range of robotic systems for locomotion and manipulation. <br\/><br\/>This project will develop a new actuator material based on a bistable electroactive polymer that behaves like an artificial muscle, and offers a combination of attributes that future robotic systems demand including power output that outperforms human skeletal muscle, flexibility, quietness, and biocompatibility. Actuators based on the new polymer material enable the design of robotic systems that interact with people, such as assistive prosthesis or assistive devices for people with disability, humanoid robots for elderly in-home care, and surgical robots to save lives. The material can also be used for industrial automation for increased production efficiency. This project includes significant outreach and educational activities. It will provide summer research intern opportunities for under-represented minority high school students each year. Undergraduate and graduate students will participate in the proposed research to gain hands-on research experience, as well as analytical, communication, and inter-personal skills.","title":"NRI-Small: Multifunctional Electroactive Polymers for Muscle-Like Actuation","awardID":"1207975","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":["562451"],"PO":["563744"]},"193510":{"abstract":"It is important for many critical software components to be correct and reliable, however verifying that software meets such requirements is difficult, expensive, and error-prone. One approach is to use software contracts as a means to specify and monitor the obligations and guarantees of software components. When the agreements of such contracts are not met during the operation of a program, the program stops and signals a violation and indicates the faulty component. Software contracts have been very important for high-assurance software, since they identify faulty program components, but they offer no guarantees that a component will not fail. The goal of this research project is to investigate approaches to ahead-of-time software verification that can prove the absence of contract failures, thus giving a high level of confidence in the correctness and reliability of critical software components. The research will contribute a new understanding of the interplay between program verification, software contracts, and modern programming languages. Additionally, it will result in the development of tools for verifying software components with contracts. It is expected that by verifying software contracts ahead-of-time, the overhead of monitoring contract agreements during program operation can be eliminated, which will encourage programmers to use contracts far more extensively than they currently do. Such tools can dramatically reduce the difficulty and cost of developing high-assurance software.<br\/><br\/>There are two paramount technical obstacles that must be overcome to achieve the goals of this project: (1) the expressivity of contracts, while crucial for the construction of reliable components, thwarts static reasoning about programs and incurs significant run-time monitoring costs, (2) the expressivity of higher-order programming languages, a mainstay of modern industrial software construction, thwarts static reasoning about contracts, despite the availability of mature automated tools and techniques. This research project rectifies the situation by providing foundations for modular and compositional automated reasoning about behavioral contracts in a higher-order language. Specifically, the project will provide: (1) a foundational theory in terms of a semantics for reasoning about components via their contracts, which enables automated component-based contract verification; (2) an interactive contract verification environment for exploring, testing, and refining programs and contracts; and (3) an evaluation of our approach and tools in the context of the Racket programming language implementation and standard library, which contains extensive use of contracts.","title":"SHF: Small: Behavioral Software Contract Verification","awardID":"1218390","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[518274,"530784"],"PO":["564588"]},"194962":{"abstract":"Proposal #: 12-29766<br\/>PI(s): Alves-Foss, Jim; Barannyk, Lyudmyla L; Potirniche, Gabriel P; Xing, Tao; Ytreberg, Frederick M;<br\/>Institution: University of Idaho<br\/>Title: MRI\/Acq.: Adaptive Computation Server for Support of STEM Research at Univ. of Idaho<br\/><br\/>Project Proposed:<br\/>This project from an EPSCoR state, acquiring an \"adaptive computational server\" with 80 CPUs, 2 TB RAM, and 9.6 TB disk, enables a variety of research projects in the areas of computational fluid and molecular dynamics, with applications in ecology, energy systems, hydraulics, and protein structures. An effort is also starting out in computer security modeling. The proposed instrument supports up to 40 separate concurrent experiments\/simulations each with 2 processor cores and 50 GB of memory, parallel computation across any number of processor cores. It is expected to manage large-scale simulations across hundreds (potentially up to thousands) of virtual machines each running small portions of a parallel algorithm.<br\/><br\/>Broader Impacts: <br\/>The proposal carries potential for strong broader impacts, as the acquisition will be widely used across many disciplines and colleges due to the intrinsic flexibility of this instrument and the lack of existing resources. Proposed is a good educational and outreach plan.","title":"MRI: Acquisition of an Adaptive Computation Server for Support of STEM Research at the University of Idaho","awardID":"1229766","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[522597,522598,522599,522600,522601],"PO":["557609"]},"193752":{"abstract":"Personal healthcare systems based on wearable\/implantable medical devices are being increasingly deployed for a variety of diagnostic, monitoring, and therapeutic applications. A consequence of the increased functional complexity, software programmability, and wireless network connectivity of such devices is that they are now vulnerable to security attacks that have plagued general-purpose computing systems. Recent demonstration of security attacks on commercially deployed systems has raised medical device security concerns significantly. Unfortunately, medical devices come with extreme size\/power constraints and unique usage models, making it infeasible to simply borrow conventional security solutions.<br\/><br\/>This research focuses on developing a non-intrusive medical security monitor that snoops on all wireless communication to\/from medical devices and uses multi-layered anomaly detection to identify potentially malicious transactions. While formal methods have been previously used to check for implementation flaws, they are not geared towards verifying the safety behavior of the medical device software in its interactions with the real world, which can expose logical flaws as well. The work investigates these interactions by transforming properties specified at the real-world interfaces (sensors and actuators) into program properties against which the medical device software can be verified. The findings will be disseminated through conferences and journals. The hardware and software developed will be placed in the public domain, and disseminated to the industry. The knowledge developed will be integrated into various courses. Undergraduates will be encouraged to perform independent research on this topic. Fellowships and outreach programs will be leveraged to encourage participation of female and minority students.","title":"TWC: Small: Collaborative Research: Enhancing the Safety and Trustworthiness of Medical Devices","awardID":"1219587","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["551013"],"PO":["565327"]},"193400":{"abstract":"Within the last decade, with the growth of video on-demand applications and the explosion of data collected via sensors and other devices, computation over massive data sets is becoming the ubiquitous norm. This development calls for a deeper understanding of several issues specific to such contexts. The first issue is one of data placement; when data is located more closely to the demand, the need for network resources is reduced. The second issue pertains to energy minimization: how can one develop algorithmic methods to make data processing more efficient? Both of these issues lead to a host of interesting questions in the vein of scheduling and facility location type problems. In an effort to address these issues, this project focuses on the development of algorithms that manage data storage for processing, with energy efficiency as the primary consideration.<br\/><br\/>Much of the prior scheduling literature assumes a job-centric perspective -- algorithms are developed to optimize tardiness, completion time, makespan, etc. In contrast, this work is motivated by a system-centric view in which utilizing resources in an \"efficient'' way is of the utmost priority, subject to individual jobs being completed in a \"satisfactory'' manner. Such efficiencies are primarily manifested in the form of the energy cost incurred by the system. These problems are particularly eminent in the context of large scale storage devices and data centers. The main focus is on data of all types, ranging from multimedia data stored on a collection of disks to data collected and stored in a distributed storage system. The amount of data to be stored and efficiently accessed is increasing at an unsustainable rate. The costs for managing this data are expected in turn to grow significantly. The main question is how can one develop scheduling algorithms to manage this data effectively and efficiently.<br\/><br\/>Data centers are fast becoming integral to society and have transformed everything from social networking to human communication to scientific collaboration, computation, and data exchange. This research will lead to increased efficiencies in this critical infrastructure. The project will train graduate students in conducting research both at universities and through internships at industrial research labs during the summer. Extensive mentoring and involvement of undergraduate students and women is expected. Over the last few years, the PI has developed a new course on \"Science behind Computing'' and is working on a book for this course, the primary purpose of which is to educate the general public about important scientific concepts related to computing in the 21st century.","title":"AF: Small:Efficient Data Management Algorithms","awardID":"1217890","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["538796"],"PO":["565251"]},"193521":{"abstract":"Expert-management portals like linkedin.com, odesk.com and guru.com are indicative sites that allow people to advertise their work or set of skills to the broader public. For example, linkedin features more than 120 million members which allows potential employers, collaborators, etc. to discover individuals or groups of individuals with the desired expertise. Similarly, review-management sites like Amazon or Yelp collect large number of reviews about products or services. For example, kindle has more than 30,000 reviews on Amazon. Naturally, users cannot go over all these reviews and are helped significantly by the identification of a small subset of reviews that is sufficiently informative. Finally, as online social and media networks grow in importance as sources of news and other information, there is an urgent need for tools that automatically identify and recommend important nodes of the network, that specific users may need to follow to fully exploit the power of online social media. In each of these scenarios, given a collection of entities (e.g., reviews about a product, experts that declare certain skills, network nodes or edges), the goal is to identify a subset of important entities (e.g., useful reviews, competent experts, influential nodes respectively). <br\/><br\/>Existing work on recommender systems attempts to identify important entities either by entity ranking or by entity selection. Entity-ranking methods associate a a score with each entity; They ignore the redundancy between the highly-scored entities. Entity-selection methods try to overcome this drawback by evaluating the desirability of a group of entities taken together; They attempt to identify the best subset of entities, while ignoring other subsets of entities that may be equally-good or almost as good as the best subset. Against this background, this project aims to overcome the drawbacks of existing entity selection and entity ranking methods through a synergistic integration of both into a common framework that allows entity-ranking based on entity selection and entity-selection that based on entity ranking. In the resulting framework, the scores of individual entities are determined in part by the number of good groups of entities they can be part of; and good group of entities consist of entities with high scores. <br\/><br\/>The main challenge addressed by this work is how to explore the solution space of combinatorial problems in order to identify subsets of entities that participate in many good solutions. The resulting new practical methods for exploring the solution space of combinatorial problems find applications related to expert management systems, management of online product reviews, and network analysis (including physical and social networks). The project also offers enhanced opportunities for research-based training of graduate and undergraduate students at Boston University. All of the research results including publications, software, and data will be freely disseminated to the broader research and educational community through the project website at: http:\/\/www.cs.bu.edu\/~evimaria\/sel-and-ranking.html.","title":"III: Small: Entity Selection and Ranking for Data-Mining Applications","awardID":"1218437","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["550882"],"PO":["565136"]},"193642":{"abstract":"Preventable errors in healthcare are a leading cause of patient injury and death. Despite considerable effort and the expenditure of billions of dollars, computerization has yet to improve the efficacy or safety of healthcare. To this problem, the PIs bring a novel insight: a prescription is a program. That is, they hypothesize that prescription writing is a long-lost sibling of software engineering, using many computer programming constructs but without the benefit of the extensive conceptual framework provided by Computer Science. This project will test this hypothesis by exploiting software engineering and programming languages know-how to create a highly intuitive domain-specific language for building and executing prescriptions. The PIs will then build and validate a \"patient-oriented prescription\" to manage the care of patients with Gestational Diabetes Mellitus (GDM), a disease affecting 600,000 women annually.<br\/><br\/>Limitations of current GDM management include low patient adherence, modest efficacy of interventions, time burden for clinicians, and cost. Using extensive archives of rich data from real patients, including diet, activity, glucose readings, and insulin use, the PIs will perform pure computer-based simulations that will help them determine how their POP-GDM program will respond to real-world data. They will also perform simulations with real clinicians, actor patients, and simulated inputs from smartphones, glucometers, and accelerometers in our state-of-the-art medical simulation facility. The PIs expect this work to generate multiple new insights regarding the building and maintenance of multi-stage programs, the development of new kinds of analyses of programs, and the discovery of new general methods for developing high-reliability software that facilitates collaboration between machines and humans.","title":"SHF: Small: Collaborative Research: Designing a Patient-Oriented Prescription Language: An Executable Medical Algorithm for Gestational Diabetes Mellitus","awardID":"1219070","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[518590,518591],"PO":["564588"]},"194621":{"abstract":"Maintaining the security of one's systems and devices in a way that ensures the right balance between functionality, security, and convenience remains complicated for most people. For example, people are routinely asked by their systems whether to accept a security certificate, install an application, heed security warnings, or reconfigure operating-system security settings. While these examples represent situations in which people regularly find themselves, people rarely have any basis to make an informed decision or to establish one conveniently. This research examines the concept of 'crowdsourced security' where the solution lies in people leveraging members of their community to secure their systems and devices.<br\/><br\/>The primary goal of this research is to determine the potential of crowdsourcing as a complementary strategy for enhancing security. An example challenge addressed in this research pertains to the security of one's personal data. Specifically the research seeks to develop security mechanisms that can exploit naturally occurring social relationships and utilize 'human computation' to shift the burden of security via authentication from machines to humans. Within this framework, the research investigates both questions about the technical effectiveness of crowdsourced security solutions, as well as socio-behavioral questions about users' preferences, motivations, and privacy concerns about such systems. This research will benefit society by producing a deeper understanding of how systems can be better secured through human participation and collaboration, moving beyond the status quo of current security mechanisms.","title":"TWC SBES: Medium: Collaborative: Crowdsourcing Security","awardID":"1228364","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["534031","548119"],"PO":["565327"]},"193411":{"abstract":"The fast-advancing modern nonvolatile memory technology includes flash memory and phase-change memory as the two most notable representatives. It is critical to create new schemes and architectures to improve their energy efficiency as well as their write speed, reliability and memory longevity. New schemes should fully utilize the unique properties of the memory technologies, including cell programming models, error models and endurance models. The key is to control cell states more flexibly and robustly by closely coupling novel coding schemes with the physics of these memory technologies.<br\/><br\/>In this project, a novel green storage technology will be developed based on coding theory for nonvolatile memory. The focus will be on flash memory and phase-change memory that share many common features. A new scheme for representing data using relative cell levels will be studied; it optimizes the energy efficiency for both writing and error correction. A novel variable-level cell technology will be developed to maximize storage capacity. New error-correcting codes will be designed to correct memory-specific errors. In addition, new processing techniques will be developed to balance the power consumption at peak and non-peak times. <br\/><br\/>The new designs will be integrated to form a comprehensive solution, and their performance will be analyzed thoroughly. The results will contribute to providing a new platform for high-performance ubiquitous computing based on nonvolatile memories.","title":"CIF: Small: Collaborative Research: Coding for Green Storage Technologies in Nonvolatile Memories","awardID":"1217944","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[518046],"PO":["564924"]},"193301":{"abstract":"Conventional models of computation abstract from the explicit flow of energy (and hence information) in physical realizations of computational devices. The benefits of such an abstract layer are self-evident, and yet it results in a conceptual model of computing that is unsuitable for reasoning about entire classes of applications including systems that aim to optimize the use of energy or that aim to guarantee privacy and security of information in the presence of arbitrary attackers. More fundamentally, the computational model becomes at odds with the basic laws of physics which hinders the general ability to explore, model, and understand nature's interactions, connections, complex relations, and interdependencies. To remedy these problems, the research builds a model of computation based on the physical principle of \"conservation of information,\" uses it to expose information manipulation, and to reason about information-flow security, privacy, and similar applications.<br\/><br\/>Technically, the proposed model builds on the type isomorphisms and categorical structures that underlie models of linear logic and quantum computing, and treats information as a linear resource that can neither be erased nor duplicated. On the theoretical side, the model is expected to unveil deeper and more elegant symmetries of computation than have previously been reported. In particular, in a computational model where information is conserved, it is natural to introduce notions of information debts that are related to continuations. Such notions could be useful to addressing long-standing theoretical problems related to the duality of computation. With an eye towards applications, and hence with the aim of reasoning about open systems which may erase and duplicate information relative to their environment, the model is extended with a layer based on the concept of arrows that allows explicit erasure and duplication of information in a way that is tracked by the type system. By implementing this extended model in a mainstream programming environment, it will become possible to reason about new classes of applications that deal with information manipulation in a systematic manner using the established tools of programming language theory.","title":"SHF: Small: Information Effects","awardID":"1217454","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[517796],"PO":["564588"]},"193422":{"abstract":"The need for resource allocation is pervasive. Often, it involves participants with conflicting interests. Markets and auctions both serve to produce desirable outcomes despite such conflicting interests, and yet other mechanisms are used when money cannot be exchanged (e.g. in kidney exchanges). An important goal is to find stable outcomes, outcomes with which individual participants are content in the sense that they cannot improve the outcome; these outcomes are called equilibria.<br\/><br\/>For existing settings, such as economic markets and widely used mechanisms (e.g. Internet routing protocols or the Generalized Second Price auction used by major search engines), one wants to understand how well the existing mechanisms work. Specifically (i) In what settings are there equilibrium outcomes? (ii) Can they (or near-equilibria) be found? (iii) Are the equilibrium outcomes plausible, i.e. does it seem reasonable that they will be reached due to the interactions induced by the mechanism? This research will focus on matching markets and the housing market in particular.<br\/><br\/>In other settings, where there are no existing mechanisms or the costs of introducing new mechanisms are not prohibitive, one can seek to design mechanisms that produce desirable outcomes. This research will focus on the allocation of divisible goods (i.e. goods that can be split into many parts).<br\/><br\/>The standard modeling of matching markets, such as the housing market, assumes buyers have sharp budget limits. Unfortunately, when this assumption holds there may be no equilibrium solution. Instead, this research will consider a natural soft budget limit based on residual wealth, a setting where equilibria are guaranteed. The main issue is whether equilibria in this setting are predictors of outcomes. Necessary conditions, which will be investigated, are that the equilibria can be computed efficiently, that approximate equilibria are close to the actual equilibria, and that these approximate equilibria could arise as a result of the actions of buyers and sellers.<br\/><br\/>With regard to mechanism design, as is standard, this research will seek truthful mechanisms, mechanisms which give participants no incentive for strategizing. In other words, participants will achieve their best outcomes by making honest declarations (e.g. of their valuations for different possible allocations). In general, it is not possible to allocate all the resources using truthful mechanisms. Instead, this research aims to understand the quality of the solutions produced by under-allocating yet truthful mechanisms. In particular, this research intends to study the class of proportionally fair mechanisms, mechanisms which were first introduced in the context of internet routing.","title":"AF:Small:Markets, Allocations and Dynamics","awardID":"1217989","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[518072],"PO":["565251"]},"193543":{"abstract":"Visible light communication (VLC) is emerging as a viable alternative wireless transmission technology that could potentially alleviate the spectrum scarcity problem. VLC uses ordinary light sources such as light emitting diodes (LEDs) as the communication medium, and superposes a high frequency on\/off operation on top of light sources for data transmissions. Compared to radio communications, the advantages of VLC include several orders broader in bandwidth, very little regulatory restrictions, ubiquitous light sources, and higher level of security for transmissions. One of the main challenges in the design of VLC at the physical layer is the issue of interference caused by simultaneous transmissions of multiple sources due to diffusion of lights emitted from regular light sources. While interference management for the Gaussian model (valid for the strong background light noise regime) is relatively well understood, it is mostly unexplored for the Poisson model (valid for the low background light noise regime). <br\/><br\/>This project will design novel interference management techniques for VLC in the Poisson regime, analyze the corresponding transmission rates\/throughputs for VLC, and develop information theoretic methodologies to characterize the fundamental communication limits on these transmission rates. The proposed research is expected to make substantial contributions to both applications and theory. On the application side, this project is anticipated to substantially advance our understanding of interference management for VLC, and provide important guidelines for designing high throughput and resource efficient VLC networks. On the theoretical level, the project will develop new stochastic calculus and information theoretic tools to advance our understanding of Poisson channels. The PIs will also use this project as a great platform to attract and train students from diverse backgrounds.","title":"CIF: Small: Collaborative Research: Interference Management for Visible Light Communications via Poisson Model","awardID":"1218541","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["551202"],"PO":["564924"]},"194643":{"abstract":"Maintaining the security of one's systems and devices in a way that ensures the right balance between functionality, security, and convenience remains complicated for most people. For example, people are routinely asked by their systems whether to accept a security certificate, install an application, heed security warnings, or reconfigure operating-system security settings. While these examples represent situations in which people regularly find themselves, people rarely have any basis to make an informed decision or to establish one conveniently. This research examines the concept of 'crowdsourced security' where the solution lies in people leveraging members of their community to secure their systems and devices.<br\/><br\/>The primary goal of this research is to determine the potential of crowdsourcing as a complementary strategy for enhancing security. An example challenge addressed in this research pertains to the security of one's personal data. Specifically the research seeks to develop security mechanisms that can exploit naturally occurring social relationships and utilize 'human computation' to shift the burden of security via authentication from machines to humans. Within this framework, the research investigates both questions about the technical effectiveness of crowdsourced security solutions, as well as socio-behavioral questions about users' preferences, motivations, and privacy concerns about such systems. This research will benefit society by producing a deeper understanding of how systems can be better secured through human participation and collaboration, moving beyond the status quo of current security mechanisms.","title":"TWC SBES: Medium: Collaborative: Crowdsourcing Security","awardID":"1228471","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["553884"],"PO":["565327"]},"193433":{"abstract":"This project develops the computational and statistical principles of mining local latent correlations in extremely high-dimensional data. Recent advances in experimental technologies have rendered it possible to collect data of extremely high dimensionality. Examples include gene expression, genetic variation, and protein and DNA sequence data. A key problem in analyzing such data is finding latent local correlations among features. Such local correlations only exist in feature subspaces and may involve more than two features. The large number of features and the noisy characteristics of the data make modeling, identifying, and assessing the statistical significance of such local correlations a challenging research problem. <br\/><br\/>The project aims to develop tools that enable users to mine and explore local correlations efficiently and effectively. It seeks to develop (1) effective models to capture the local correlations among features; (2) scalable algorithms to identify local correlations from extremely high-dimensional data; (3) robust methods to assess the statistical significance of the identified correlations. The proposed methods combine the advantages of dimension reduction, intrinsic dimensionality estimation, information theoretic approach, and hypothesis testing for modeling and identifying significant local correlations. <br\/><br\/>The resuling tools will assist scientists in many disciplines including biologists in their study of gene function and medical doctors in their understanding of disease progression and searching for new and effective treatments. The research results will be published in peer reviewed data mining and bioinformatics journals and conferences and integrated into the educational and outreach programs at CWRU. The project Web site (http:\/\/engr.case.edu\/zhang_xiang) will be used for dissemination of research results including publications, data, and software.","title":"III: Small: Mining Local Correlations in Extremely High-Dimensional Data: Models, Algorithms, and Applications","awardID":"1218036","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[518095,"481368"],"PO":["565136"]},"193554":{"abstract":"Web browsing is one of the most common and important services provided by smartphones. However, it currently suffers from long delays and creates a huge drain on the battery lifetime of smartphones. These limitations are caused by complex interactions between the processing flow in mobile web browsers and specialized characteristics of the wireless radio interface, and by the processing limitations of the smartphones. This project addresses these limitations by focusing on three intertwined issues: (i) various techniques to reorganize the computation sequence of the web browser to let the wireless radio interface enter sleep earlier, are designed, implemented and evaluated; (ii) practical data mining based methods are introduced to predict the user viewing time of webpages and determine when the smartphone should switch to low power state, considering the resource limitations of the smartphone and various tradeoffs between delay and power; and (iii) a new architecture is proposed to shift the computing from smartphones to the virtual-machine based proxy to address the computation limitations in smartphones considering scalability issues and bandwidth constraints. This project will make significant theoretical and technical advances on reducing the power consumption and access delay of web browsing in wireless networks. The success of this project will affect many people's daily life, making smartphones last longer and web browsing faster. The results of the project will be disseminated widely through high quality publications and presentations. The proposed research will also be integrated with the education curricula at the Pennsylvania State University.","title":"NeTS: Small: Efficient Energy-Aware Web Browsing in Wireless Networks","awardID":"1218597","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["550785",518380],"PO":["565303"]},"180486":{"abstract":"This project develops methods to provide citizens information about technologies that obstruct, restrict, or tamper with their access to information. Internet users need an objective, independent, third-party service that helps them determine whether their Internet service provider or government is restricting access to content, specific protocols, or otherwise degrading service. Towards this goal, we are (1) monitoring attempts to block or manipulate Internet content and communications; and (2) evaluating various censorship circumvention mechanisms in real-world deployments}. The project develops a large-scale measurement and monitoring service that measures network reachability and performance from a variety of access networks to various Internet services; infers whether ISPs or governments are restricting or otherwise throttling access to various applications and services; and detects attempts to tamper with information presented to users. The project also studyies the policy ramifications of making information about censorship and information tampering available to Internet users. It will provide up-to-date information about both the extent of censorship and information tampering in countries around the world and technologies countries are using to implement censorship and thwart censorship circumvention tools. Discoveries are disseminated through real-time portals and through regular written reports and academic publications.","title":"TC: Large: Collaborative Research: Facilitating Free and Open Access to Information on the Internet","awardID":"1111539","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["548225"],"PO":["565327"]},"193323":{"abstract":"This project studies counting problems in computational complexity theory. Three related areas will be investigated.<br\/>(1) The approximate complexity on spin systems. It is hoped that progress will be made to understand precisely the boundary between approximable and inapproximable partition functions for spin systems.<br\/>(2) To gain a much better understanding of the dichotomy theorems for Constraint Satisfaction Problems (CSP), and related frameworks of counting problems such as Graph Homomorphisms and Holant Problems. Roughly, there have emerged two types of dichotomy theorems. One type is very explicit and offers a deeper understanding of the tractability criterion. Another type is more infinitary, and often it is not even clear that the tractability criterion is decidable. The strength of the second type is that it currently has a broader coverage in a logical sense. This project will study the interrelationship between various tractability criteria, with the concrete goal of proving a decidable dichotomy theorem for the most general complex-weighted partition functions of counting CSP problems over an arbitrary fixed domain.<br\/>(3) To study holographic algorithms based on matchgates for domain size greater than two. The realizability and transformation theory of matchgates have already been well developed for domain size two and over the general linear group of 2 by 2 matrices over the complex numbers. But for more general transformation groups this is completely unexplored. This project will attempt to develop the theory over more general groups. A concrete aim is to prove a dichotomy theorem for problems over domain size greater than two, which states that all tractable planar CSP problems are defined by constraint functions that are either tractable for general CSP problems or tractable by a holographic transformation followed by the FKT algorithm using matchgates.<br\/><br\/>There has been strong interest in the novel concept of holographic algorithms (American Scientist magazine had a feature article on this development in the Jan-Feb issue of 2008.) A sharper delineation between what is efficiently computable, or approximable, and what is not has broader impact within computer science and beyond. Within computer science there is a lot of interest in AI; a substantial body of work is centered around graphic models. These are some forms of partition functions. Outside computer science, there is a long tradition in statistical physics to study phase transitions, and any provable link between that and computational complexity theory will be of great interest. In addition to graduate student training, there is also a significant amount of computational experimentation in the design of reductions, which could engage undergraduate students in research.","title":"AF: Small: Counting Problems, Holographic Algorithms and Dichotomy Theorems","awardID":"1217549","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[517847],"PO":["565157"]},"192113":{"abstract":"This project will design and implement \"Myrmex\", a novel crowdsourcing system for physical-world tasks. For example, an elderly community member could use Myrmex for help getting mail from a remote post office, as the system would assign the task to a participant who routinely passes that way. Myrmex leverages the capacity of computers (monitoring, matching participants to tasks) to facilitate human activity (assigning and performing tasks). The project will: 1) develop new privacy-preserving methods for location and context tracking; 2) design and implement incentives for continuous use of a new social system; and 3) create and implement models of best times and places to notify and offer tasks for participants.<br\/><br\/>Broader impacts: The Myrmex system will help strengthen bonds and connectivity within a community and provide assistance for community members for running their daily lives. Matching tasks and people based on locations and paths will also help conserve resources and benefit the environment due to the reduced travel miles needed to perform a task. The project will provide multidisciplinary training for undergraduate and graduate students. It will also provide the research community with an anonymized dataset of human mobility patterns and task activities, and tools to analyze human behavior.","title":"SoCS: Collaborative Research: Local Community Crowdsourcing of Physical-World Tasks with Myrmex","awardID":"1211079","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["553648","529950","521585"],"PO":["564456"]},"193213":{"abstract":"The project team is integrating the stories, characters, math content, and research of New York's public television station's (WNET), Cyberchase multimedia project with Teachers' College's research on embodied cognition theory and gesture-base simulation games to create two mobile application prototypes to be used in studies focused on learning with technology that takes embodied cognition theory into account in the context of story narrative. The content focus of the research and development is fractions, a topic that is a major stumbling block for children in the target age group of 8-11, yet lays a crucial foundation for later success in mathematics, science, and related fields. Grounded theory suggests that our cognition is grounded in the physical world we live in and the ways our bodies are able to move and perceive. According to this theory, there are three steps involved in learning something in a grounded way -- having embodied experiences (ones where our bodies take part), learning to imagine that embodied experience, and practicing imagining the experience with symbolic materials. The physical movements do not have to be big ones; simply moving a finger across an expanse to designate numerical magnitude has been shown to help with understanding of magnitude, for example. What is important is that the gestures should be conceptually congruent with knowledge being learned. Research addresses the conditions under which gesture-based math practice (here, in the context of the math games) promotes better math learning and the interactions between gesture and story line that are effective in promoting sustained engagement and content learning. The project's research and design context tests a basic design framework that integrates the promises of new technology, embodied cognition theory, and well-loved story narratives and has potential to be applicable to the the teaching of other mathematics concepts and, more broadly, to a variety of STEM disciplines.<br\/><br\/>This project focuses on fraction learning, a stumbling block for many elementary schoolers. The team is applying what is known about the relationship between body movement and learning to develop engaging apps for smartphones and tablets with touch screens that allow youngsters (ages 8 to 11) to experience mathematical concepts through their gestures and that give them practice applying the mathematics they are learning in a variety of situations. Use of the apps is embedded in discussion and play in the context of a well-loved television series called Cyberchase (developed by New York's WNET) that promotes mathematics learning. Research is investigating the conditions under which use of gesture promotes mathematics learning and effective ways of integrating mathematics practice, reflection, and story telling so that children will better understand and be able to use fractions. Answers to research questions is expected to be applicable in other areas of mathematics and across STEM disciplines.","title":"EXP: Mobile, Movement, and Math","awardID":"1217093","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7625","name":"REESE"}}],"PIcoPI":[517575,517576,517577],"PO":["562669"]},"193334":{"abstract":"Workload consolidation on virtualized datacenters is one common <br\/>technique used to manage the power usage and energy efficiency of <br\/>cloud platforms. However, current solutions limit the available <br\/>insight into exactly how energy is consumed by the various cloud <br\/>tenants. <br\/><br\/>In order to address this gap, this research develops PowerMeter ? a <br\/>set of mechanisms and tools that make it possible to track energy <br\/>usage in virtualized cloud infrastructures, on granularity of <br\/>individual VMs, or sets of VMs corresponding to a specific cloud <br\/>tenant, e.g., a customer or an application. PowerMeter is developed <br\/>for a 3000-core fully instrumented datacenter prototype and a 1000- <br\/>core system based on newest-generation technology, and is evaluated <br\/>using representative workload mixes based on popular cloud <br\/>applications and publicly available cloud traces. PowerMeter will <br\/>provide currently missing capabilities for dynamically assessing in- <br\/>datacenter\/in-cloud energy usage, necessary to enable energy usage <br\/>transparency and accountability to cloud customers, to understand the <br\/>opportunities for improved energy efficiency in virtualized cloud <br\/>systems, and for further development of management methods for energy- <br\/>efficient datacenters.","title":"CSR: Small: PowerMeter: Tracking Energy Usage in the Clouds","awardID":"1217577","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[517873],"PO":["565255"]},"193455":{"abstract":"Networked Sensing Systems (NSSs) interact with the physical world by tightly integrating sensing, computation, networking, and physical processes. NSS systems are being deployed for numerous critical applications such as security, civil infrastructure, healthcare, manufacturing, and transportation. These applications often impose stringent performance requirements. Many computation and communication tasks of NSS systems must be finished within certain timing constraints to avoid undesirable or even catastrophic consequences -- a property known as real-time assurance. In addition, mission-critical NSS systems must maintain their performance at an acceptable level even when noises and errors occur in input and\/or internal system components -- a property known as fidelity. This research is to design a novel NSS control framework that integrates data fusion, calibration, and real-time performance control into a solution that balances requirements for fidelity and real-time assurance. The expected outcomes include: 1) a unified multi-tier performance control framework for both fidelity and real-time assurance; 2) improvements in fidelity assurance through novel model and fusion calibration algorithms; 3) a fidelity-aware real-time performance control mechanism; and 4) integrated fidelity and real-time assurance for several mission-critical domains including real-time volcano monitoring and tomography, and high-fidelity ad hoc surveillance. <br\/><br\/>This project has broad implications for future NSS systems in multiple application domains that require high-fidelity processing of dynamic and complex physical information within stringent timeliness constraints. Educational and outreach activities include introduction of NSS systems into two new graduate courses with software, testbed, and labs developed in the course of this project, and recruitment of women and minority students for participation in the project.","title":"CSR: Small: Collaborative Research: Integrated Control of Fidelity and Real-Time Performance in Networked Sensing Systems","awardID":"1218154","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["554423"],"PO":["564778"]},"193235":{"abstract":"This project explores perception-driven models of human audio-visual emotion using statistical analyses, data-driven computational modeling, and implicit sensing. Emotion underlies and modulates human communication. It is used in the diagnosis of many mental health conditions and is tracked in therapeutic interventions. Research in emotion perception seeks to identify models that describe the felt sense of 'typical' emotion expression -- i.e., an observer\/evaluator's attribution of the emotional state of the speaker. This felt sense is a function of the methods through which individuals integrate the presented multi-modal emotional information. However, the nature of the interaction of the multi-modal cues is still an open question. This project will investigate multi-modal cue integration by studying how emotional inconsistency affects human perceptual judgment. In pursuit of this goal, the research objectives of this proposal are (1) to identify and validate primary and secondary audio-visual cues responsible for emotion perception, (2) to create a data-driven model to automatically predict the emotion perception of an evaluator, and (3) to predict evaluator state using implicit physiological and body gesture cues. <br\/><br\/>The first research objective addresses the open question of how distal cues, the encoding of a speaker's communicative goals, interact and result in the felt sense of specific emotion states. Novel techniques will be used to identify emotionally salient distal cues using emotionally consistent and inconsistent audio-visual information. This identification has implications in the design of emotion classification algorithms and the emotional behavior of affective agents. The second research thrust addresses the open question of how human-centered models (rather than data-driven models) can be designed for use in emotion classification tasks. The project will investigate the efficacy of novel dynamic structures to model emotionally inconsistent information. These new structures will provide insights into the development of human-centered emotion classification inspired by the emotion perception process, rather than solely on data fluctuations. The third research objective addresses the open question regarding the effect of audio-visual emotion evaluation tasks on the evaluator's internal state. We will assess evaluator inattention in the context of emotional evaluation tasks. Models that can accurately predict evaluator inattention have applications in long-term human-computer and human-robot interaction platforms. The insights gained from this project will facilitate the design of emotion-focused algorithms that replicate the process by which humans interpret and integrate emotional audiovisual signals. It will also aid in the creation of emotional interfaces for health informatics applications, which will lead to more specifically targeted interventions and treatments for many mental health conditions including schizophrenia, depression, and autism.","title":"RI: Small: Collaborative Research: Exploring Audiovisual Emotion Perception using Data-Driven Computational Modeling","awardID":"1217183","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"7252","name":"PERCEPTION, ACTION & COGNITION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[517630],"PO":["564318"]},"193477":{"abstract":"Online social networks have played an increasingly important role in connecting people and spreading information. It becomes urgent and necessary to understand the information diffusion process over large scale online social networks. However, due to the intricacy of human dynamics and social interactions, the vast scale of users and information, and the heterogeneity and diversity of online social networks, understanding information diffusion in social networks remains a daunting task. The PIs explore one key question in this project: how does a piece of information travel over time and space in an online social network. Similar questions have been asked and investigated for the outbreak of epidemics, but little attempt has been made in online social networks to model the diffusion of information from both temporal and spatial dimensions due to the challenges in quantitatively modeling the diffusion process in online social networks. The PIs combine the advances in data mining, graph theory, and dynamic mathematical modeling, specifically partial differential equation modeling, to characterize and predict the temporal and spatial dynamics of information diffusion. <br\/><br\/>Broader impact: This work not only builds the first extendable theoretical framework for characterizing, modeling and predicting the diffusion process of information with dynamic mathematical modeling approach, but also helps facilitate the spreading of positive information and limit the distribution of unwanted misinformation such as spam and phishing messages because it can gain an in-depth understanding of information diffusion in social networks. Moreover, this project provides an opportunity for undergraduate students to gain valuable research experiences in mathematical modeling, graph theory and large scale data collection and analysis, and to prepare them for the challenges and opportunities in the increasingly important field of online social networks.","title":"NeTS: Small: RUI: Dynamic Mathematical Modeling Towards Understanding Information Diffusion in Online Social Networks","awardID":"1218212","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["455991","521123",518202],"PO":["565090"]},"193598":{"abstract":"Cloud computing provides many benefits including convenience, consolidation, compatibility, and cost-reduction. However, security is a major concern, since cloud resources are shared with other users who may be adversarial. The goal of this research is to define a framework for security-on-demand: cloud customers can request the security they need and cloud providers can map these security requests to the appropriate secure servers. Since customers have different security needs, a range of threat models is explored together with servers with different security capabilities. Research contributions include (1) new strategies for measuring cloud server security capabilities, and (2) new hardware-software mechanisms for collecting runtime trust evidence that a server is enforcing a customer's requested security policy. (3) Secure protocols are designed for collecting and reporting server security capabilities to cloud management software, as well as (4) a hardware-software security verification methodology to verify these protocols, using model checking and other tools. (5) Novel actionable models of cloud servers? security properties that can be matched to customers' requests are implemented by new trust monitoring and policy enforcement modules. Also, (6) hardware mechanisms and migration protocols for secure Virtual Machine migration to improve cloud security are designed. The broader impact of this work includes providing greater security in cloud computing for customers, allowing cloud providers to differentiate their offerings with security provisioning using different secure server architectures, enabling the specification and provisioning of customized and verifiable security, and providing a research platform for investigating secure hardware and software architecture in a cloud environment.","title":"CSR: Small: Cloud Security on Demand","awardID":"1218817","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[518483],"PO":["565255"]},"193488":{"abstract":"Poor visibility into the network hampers progress in a number of important research areas, from network troubleshooting to Internet topology and performance mapping. While the problem has been long recognized and has served as motivation for several efforts to build new or expand existing experimental platforms, capturing the edge of the Internet at sufficient scale remains an elusive goal. At its roots, the problem is one of incentives - in most of the commercial Internet the goals of those hosting the platform and the experimenters that use it are not the same. This effort explores a new model for Internet experimentation platforms that addresses the incentive problem by explicitly aligning the objectives of the experimenters with those of the users hosting the vantage points. The exploration is done in the context of Dasu, a system for Internet Service Provider characterization and Internet experimentation. The effort investigates (i) the challenges and opportunities offered by these types of platforms, (ii) how such platforms can support easy extensibility while remaining secure, and (iii) how to facilitate the design and deployment of experiments from the Internet edge while reducing the impact on both nodes? resources and the underlying network. <br\/><br\/>Broader Impact: The effort will offer the general Internet community with immediate benefits through a unique view of a user's ISP service levels. It will produce a set of algorithms, monitoring protocols, software systems, and tools that, by not requiring the deployment and maintenance of additional infrastructure, can immediately benefit their users, making a significant impact on society-at-large. The effort will provide the research community with access to an experimentation platform capable of capturing the diversity of the commercial Internet. It will make significant contributions toward a better understood, more transparent Internet and offer a much-needed testbed for evaluating the effectiveness of measurement techniques, tools and networked systems deployed at the edge of the Internet. Research findings and outcomes will be made available as publications, datasets and openly released software. The project will have a direct impact on education in communication, network and distributed systems.","title":"NeTS: Small: A Dual-Objective Platform for Internet Experimentation","awardID":"1218287","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[518224],"PO":["565090"]},"193378":{"abstract":"Operating systems and networks developed largely independently, due to<br\/>the nature of their development -- operating systems were developed by<br\/>groups within organizations\/companies, while networking requiring<br\/>interoperability was developed across organizations. As a result of<br\/>this development history, the boundary between the networking<br\/>subsystem and the rest of the operating system has remained largely<br\/>opaque, with little information regarding the performance or progress<br\/>of transfers being communicated to applications. This research<br\/>addresses this limitation by exploring a richer boundary interface<br\/>that allows programs to see the ongoing behavior of network transfers<br\/>and to control their operation at a fine granularity. These interfaces<br\/>would augment, rather than replace, the existing interfaces, so the<br\/>portions of programs that are satisfied with the current interfaces<br\/>could continue unmodified, and developers could change only the<br\/>portions that can benefit from richer information. This research is<br\/>largely experimental in nature, and will combine the design and<br\/>implementation of new interface abstractions along with the<br\/>development of new or modified programs to take advantage of these<br\/>interfaces. In addition to the design work associated with the<br\/>interfaces, additional criteria for success include examining the<br\/>performance and delay behavior of modified applications, and the<br\/>effort needed to modify such applications. The expected results from<br\/>this work include applications that can more precisely control their<br\/>networking behavior, reducing memory and processor usage, improving<br\/>energy efficiency, and improving delay behavior. High-performance or<br\/>time-sensitive applications, such as networked video, should benefit<br\/>from this research.","title":"CSR: Small: Rethinking the OS\/Network Boundary","awardID":"1217782","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["533299"],"PO":["565255"]},"197998":{"abstract":"A study of software code has revealed a surprising result: that software code may be just as (if not more) \"natural\" as natural language itself (e.g., English) in that code is highly predictable and repetitive; statistical natural language techniques may be applied quite competently for some software engineering tasks. For example, N-grams may be quite effective at suggestion and completion tasks in code. The evidence supports further exploration of the applicability of statistical NLP techniques and tools to software development activities and processes. The project explores the feasibility of establishing a scientific basis and tools for a variety of code-level software engineering functions -- including natural language summarization, code retrieval, software question answering, automated code completion, and assistive tools for disabled developers to support software engineering, forming not only a new and important domain for further research in NLP, but also a totally new approach to software development.","title":"EAGER: Exploiting the \"Naturalness\" of Software","awardID":"1247088","effectiveDate":"2012-09-01","expirationDate":"2014-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[531367,"533936"],"PO":["564388"]},"198977":{"abstract":"This project supports US-India workshop on fostering collaboration in the area of high performance computing particularly as it relates to big data applications. The workshop will bring together participants from US and India to identify promising areas of common interest and models for sustainable collaboration including NSF's SAVI mechanism. Attendees will be chosen to represent 3 areas: Big Data Software Platforms, Accelerated Systems Infrastructure, and Scientific Applications of societal significance. The workshop will be co-located with the well established HiPC conference, to be held in Pune, India in December, 2012. The participants from India will be supported through grants from the Department of Science and Technology, India.","title":"US-India Workshop on Fostering Synergistic Collaborations to Accelerate Big Data Applications, December, 2012, Pune, India","awardID":"1252223","effectiveDate":"2012-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["563658","563659"],"PO":["535244"]},"199703":{"abstract":"EarthCube is a joint venture between the Directorate of Geosciences and the Office of Cyberinfrastructure at the National Science Foundation. It is a community-driven effort to design and implement an effective data and knowledge management system for the geosciences that will integrates disparate data sets and web services and serves all members of the geoscience community. This planning and assesment project collects and synthesizes the prodigious amount of geoscience and cyberinfrastrucutre community input on possible governance structures for EarthCube that were generated in the run up to the June 2012 EarthCube meeting and actities that have happened during the post meeting timeframe. The project focuses on broadening grass roots geoscience engagement in the process, deepening the input and collecting science-drivers from geoscience communities, and organizing and summarinzing all information so it can be used effectively by the initial EarthCube governance body that will be selected in early 2013. The PI and his outreach team will hold face-to-face and virtual meetings as well as attend and run Town Hall meeings at professional society meetings to engage stakeholders. An important aspect of the project will be to identify community needs and incorporate their suggestions into the final summaries. Project goals also include building stakeholder alignment around shared goals in terms of producing ways to establish standardization of data practices and aspects of its management as well as create a community consensus structure for the evaluation of new tools and utilities. Broader impacts of the work are focused primarily on building infrastructure for science in terms of informing the development of an effective and well received community governance structure.","title":"Community Engagement to Inform EarthCube Governance","awardID":"1256235","effectiveDate":"2012-09-01","expirationDate":"2013-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0600","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"8074","name":"EarthCube"}}],"PIcoPI":[535421,535422,"558904"],"PO":[535424]},"198516":{"abstract":"Most modern microprocessors support some form of vector operations that allow the same operation to be applied to small vectors of arguments simultaneously. Studies have shown that use of these instructions can improve the performance of many scientific codes by a factor of 2 or more. Unfortunately, the state of the art in autovectorization falls far short of this goal, only achieving improvements of 20-30% on the same codes.<br\/><br\/>While studies have shown that current autovectorizing compilers do not identify all of the opportunities for vectorization, little is known about why they fail to do so. The PIs plan to evaluate tradeoffs between different compiler optimizations and vectorization in an effort to understand how optimization choices affect opportunities for autovectorization. They will use an extensive set of benchmarks to evaluate these tradeoffs. This research will make it possible to develop better autovectorizing compilers by avoiding optimization choices that interfere with autovectorization. The performance benefits of such compilers will improve the performance of applications ranging from multimedia software to scientific computing.","title":"EAGER: Identifying and Removing Barriers to Autovectorization","awardID":"1249449","effectiveDate":"2012-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[532654,532655,532656],"PO":["564588"]},"199649":{"abstract":"Individuals on the move, e.g., tourists on a sightseeing trip in an unfamiliar city often find themselves overwhelmed by the challenges of coping with unfamiliar environments. This presents a need for tools and methods that will guide them by providing them useful recommendations while they are \"on the move.\" Recent advances in mobile and sensor-based technologies have made it possible to collect and process location traces across many different mobile applications. Such data, when combined with other spatio-temporal, contextual, and user-specific information can, in principle, be used to generate useful recommendations for individuals on the move. <br\/><br\/>This exploratory research project formulates and explores a novel variant of recommender systems, namely, mobile sequential recommender systems for mobile users where each recommendation takes into account the trajectory and history of past recommendations, as one of selecting a sequence of locations to recommend under a set of spatio-temporal, contextual, and privacy constraints. Given the combinatorial nature of the problem (where the size of the search space grows is exponential in the relevant parameters) the project aims to explore heuristics. It will also develop appropriate measures for assessing the effectiveness of alternative solutions.<br\/><br\/>The project, if successful, would establish the feasibility of a line of investigation that could lead to the development of effective approaches to sequential recommendation problem with obvious benefits to mobile users. The project enriches research based advanced training opportunities for graduate and undergraduate students. All of the data, software, and publications resulting from the project will be made freely available to the broader research community.","title":"EAGER: Collaborative Research: Sequential Recommender Systems in Mobile and Pervasive Environments","awardID":"1256016","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[535281],"PO":["565136"]},"199539":{"abstract":"A new, emergent cybersecurity frontier is information manipulation, whereby adversaries may attempt to distort information to influence opinion, thought, or action. Information manipulation can take many shapes and forms, from blatant attacks such as search-poisoning, misinformation such as bogus on-line reviews, to subtle distortion such as personalized search and biased news. Left unchecked, information manipulation can harm our economy, culture, and democracy. Past research efforts have been ad-hoc and focused on specific kinds of information manipulation. <br\/><br\/>This work aims to lay the foundations of research in information manipulation. There are three research components: (1) surveying the long line of relevant scholarly work on information manipulation, and investigating how the established types of manipulation play out on the Internet and if the Internet gives rise to novel types of manipulation, (2) generating an overarching conceptual framework about information manipulation to capture the basic properties of various forms of existing and possible manipulation practices on the Internet, and (3) developing taxonomy of information manipulation that facilitates the development of general countermeasure for each category of manipulation. This project is tightly integrated with social-science research. In particular, political and social behavioral study identifies the important insights from at least two millennia of scholarship on information manipulation and help define models of the actors, goals, mechanisms, and strategies of information manipulation in the Internet era. The historical perspectives and conceptualization of information manipulation provide the foundation for developing a comprehensive framework to counter information manipulation.","title":"EAGER: The Conceptual Landscape of Information Manipulation","awardID":"1255453","effectiveDate":"2012-09-01","expirationDate":"2015-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[535009,"543138",535011],"PO":["565264"]},"199308":{"abstract":"The ability to analyze a text and determine with certainty the author of that document, a task known as Authorship Attribution (AA), can help build a case against an online abuser, determine the trustworthiness of a document, and can also support this country's fight against terrorism by analyzing online communities of interest. This EArly Grant for Exploratory Research investigates new approaches for AA in two specific cross-domain settings: where both the topic and genre of the test documents differ from those of the training data. The research study departs from the standard single feature vector representation in text classification settings and follows a framework where the writeprint of authors is represented as a set of linguistic dimensions. The goal is to understand how each dimension will change in the new domain. <br\/><br\/>The findings from this exploratory research will show the feasibility of building new text representations and approaches for text classification problems where there are larger domain shifts between the training and testing data and the breakout representation into linguistic dimensions is suitable. The results and findings from this work will contribute to building longer-term research projects which will be able to tackle more challenging cross-domain settings.","title":"EAGER: Investigating linguistic dimensions in cross-domain authorship analysis","awardID":"1254108","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["562856"],"PO":["565215"]},"189639":{"abstract":"Mobile devices, such as smart phones and tablets, are increasingly used for multitasking, data access, and computation, while on-the-go. However, mobile devices are typically constrained in terms of their compute power, energy, and network bandwidth, making it a challenge to support the full array of desired applications and behavior in terms of performance, fidelity, reliability, and energy usage. To enhance mobile user experience, this project is investigating how the mobile platform can be extended into the cloud to provide needed resources on-demand. It is exploring the potential of the cloud as an outsourcing platform for mobile applications and developing new techniques for managing cloud resources as the number of applications and users scale. <br\/><br\/>The project adopts a user-centric approach guided by the actions of users, including their patterns, preferences, and activities. The research thrusts include user preference-driven optimization of context-based user activities, enhanced cloud provisioning based on cross-user resource sharing, and user activity-based optimization of collaborative applications. The research is based on a close synergy between systems and data mining techniques. The broader impact of this proposal is to enhance the experience of the mobile user, increasing their productivity, and expanding the range of mobile applications. This project will demonstrate how the cloud is central to realizing this vision. All source code developed and data collected as part of this project will be released. This project is also providing students with greater exposure to the areas of cloud computing, mobile computing, and data mining, both in courses and research experiences.","title":"CSR: Medium: Enriching Mobile User Experience Through The Cloud","awardID":"1162405","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["543508","531622","543510"],"PO":["565255"]},"190860":{"abstract":"This is an Institutional Infrastructure proposal to build a GPU cluster to support research in data-parallel code development and optimization, as well as research applications, in three scientific domains, namely, seismology, biology and astrophysics. These goals build on a close collaboration with an expert team in GPU computing from computer science. The proposed cluster will serve not only as an invaluable resource for computation, but will also aid cross-fostering of techniques and concepts between disciplines and will be used to stimulate collaboration and synergistic research activity in a wide range of areas.<br\/><br\/>Even though domain scientists are increasingly dependent on computation to achieve their research goals, most are not experts in parallel programming or GPU architectures. The difficulty of parallel programming for GPU clusters is an impediment to scientific progress. In order to relieve scientists of the burdens of parallel programming, computer scientists at Princeton have developed systems for automatically parallelizing programs for GPU. Building on this success, the PIs plan to extend these techniques to GPU clusters and work closely with the seismologists, biologists and astrophysicists to accelerate the pace of science.","title":"II-New: A Platform for Data-Parallel GPU Computing at Princeton","awardID":"1205613","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[511660,"520353","533517","239677"],"PO":["565272"]},"190871":{"abstract":"Emotion is the complex psycho-physiological experience of an individual's state of mind. It affects every aspect of rational thinking, learning, decision making, and psychomotor ability. Emotion modeling and recognition is playing an increasingly important role in many research areas, including human computer interaction, robotics, artificial intelligence, and advanced technologies for education and learning. Current emotion-related research, however, is impeded by a lack of a large spontaneous emotion data corpus. With few exceptions, emotion databases are limited in terms of size, sensor modalities, labeling, and elicitation methods. Most rely on posed emotions, which may bear little resemblance to what occurs in the contexts wherein the emotions are really triggered. In this project the PIs will address these limitations by developing a multimodal and multidimensional corpus of dynamic spontaneous emotion and facial expression data, with labels and feature derivatives, from approximately 200 subjects of different ethnicities and ages, using sensors of different modalities. To these ends, they will acquire a 6-camera wide-range 3D dynamic imaging system to capture ultra high-resolution facial geometric data and video texture data, which will allow them to examine the fine structure change as well as the precise time course for spontaneous expressions. Video data will be accompanied by other sensor modalities, including thermal, audio and physiological sensors. An IR thermal camera will allow real time recording of facial temperature, while an audio sensor will record the voices of both subject and experimenter. The physiological sensor will measure skin conductivity and related physiological signals. Tools and methods to facilitate and simplify use of the dataset will be provided. The entire dataset, including metadata and associated software, will be stored in a public depository and made available for research in computer vision, affective computing, human computer interaction, and related fields.<br\/><br\/>Intellectual Merit <br\/>This research will involve construction of a corpus of spontaneous multi-dimensional and multimodal emotion and facial expression data, which is significantly larger than any that currently exist. To elicit natural and spontaneous emotions from subjects, the PIs will employ five approaches using physical experience, film clips, cold pressor, relived memories tasks, and interview formats. The database will employ sensors of different modalities including high resolution 2D\/3D video cameras, infrared thermal cameras, audio sensors, and physiological sensors. The video data will be labeled according to a number of categories, including AU labeling and emotion labeling from self-report and perceptual judgments of na\u00efve observers. Comprehensive emotion labeling will include dimensional approaches (e.g., valence, arousal), discrete emotions (e.g., joy, anger, smile controls), anatomic methods (e.g., FACS), and paralinguistic signaling (e.g., back-channeling). Additional features will be derived from the raw data, including 2D\/3D facial feature points, head pose, and audio parameters.<br\/><br\/>Broader Impact <br\/>Project outcomes will immediately benefit researchers in computer vision and emotion modeling and recognition, because the database will allow them to train and validate their facial expression and emotion recognition algorithms. The new corpus will facilitate the study of multimodal fusion from audio, video, geometric, thermal, and physical responses. It will contribute to the development of a comprehensive understanding of mechanisms involving human behavior, and will allow enhancements to human computer interaction (e.g., through emotion-sensitive and socially intelligent interfaces), robotics, artificial intelligence, and cognitive science. The work will likely also significantly impact research in diverse other fields such as psychology, biometrics, medicine\/life science, law-enforcement, education, entrainment, and social science.","title":"CI-ADDO-EN: Collaborative Research: 3D Dynamic Multimodal Spontaneous Emotion Corpus for Automated Facial Behavior and Emotion Analysis","awardID":"1205664","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[511701],"PO":["565227"]},"192961":{"abstract":"The main objective of the project is to develop and study new incentive and reimbursement mechanisms within the context of the delivery of medical care. The project takes a game-theoretic perspective, with the main players being the government, health plans, healthcare providers, and patients. Some of the design goals of the mechanisms are to motivate the parties involved to improve healthcare quality while controlling costs. Among others, the study will try to extend the algorithmic game theory framework to address the unique challenges that occur in the context of healthcare. A key goal of the study is understanding the extent to which utilizing electronically available medical records may enable new mechanisms in the context of healthcare. In particular, the project studies potential advantages of high quality risk-adjustment schemes that are empowered by the application of machine learning to medical data.<br\/><br\/>In recent years, much of the focus in the US public policy debate has been given to problems surrounding providing and sustaining healthcare services. One of the key problems the US healthcare system faces is that of aligning incentives among the various stakeholders - the government, health plans, care providers, and patients - to ensure favorable outcomes and efficient resource utilization. The study will use tools from algorithms and game theory to develop new alignment strategies. In particular, the study will look at ways in which the collection and data-mining of electronic health records may be used to provide better incentives for the stakeholders, and lead to better overall care at lower cost.","title":"ICES: Small: Collaborative Research: Data-driven mechanisms in healthcare","awardID":"1216011","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":[516922],"PO":["565251"]},"192972":{"abstract":"The total volume of data was estimated to be 0.8 Zettabytes in 2009 (1 Zettabyte = 1 trillion gigabytes) and predicted to grow to a staggering 35 Zettabytes in 2020, doubling every two years. Therefore, one of the primary challenges for machine learning is to develop statistically principled methods that will scale up to very large datasets. Moreover, we would like to (efficiently) learn highly complex models without the worry of overfitting and with confidence levels on our predictions. While Bayesian methods satisfy these latter desiderata, the current state-of-the-art inference procedures based on Markov Chain Monte Carlo (MCMC) posterior sampling do not meet the \"big-data\" challenge.<br\/><br\/>We propose a new family of MCMC procedures that typically requires only a few hundred data-cases per update. These \"stochastic gradient MCMC samplers\" inherit the efficiencies of stochastic approximation methods, but will asymptotically sample from the correct posterior distribution. This endows this family of methods with an \"anytime\" property, namely that one can sample cheaply from a rough approximation of the posterior but can obtain more accurate samples in exchange for more computation.<br\/><br\/>We believe this new class of methods will for the first time unlock the full strength of Bayesian methods for very large datasets. Due to their highly practical nature, the techniques developed under this grant are likely to gain widespread acceptance across a broad spectrum of academic disciplines as well as in industry. To expedite the transfer process we will publish open source software on our webpages and collaborate with a company (ID Analytics) to work on realistic, large scale inference problems. Two students at the University of California, Irvine (UCI) will be employed on this grant who will collaborate with a number of students and postdocs in the UK (University of Oxford and University of Bristol). UCI and UK students will also be exchanged for a few weeks a year to cross-fertilize research and to gain international experience. Research results from this grant will be integrated into artificial intelligence and machine learning courses at UCI through class projects.","title":"RI: Small: Efficient Bayesian Learning from Stochastic Gradients","awardID":"1216045","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[516952,516953],"PO":["564316"]},"192983":{"abstract":"Market design--economic engineering--has been successful in the redesign of real-world \"two-sided matching markets,\" including the matching of doctors to residencies and the assignment of students to schools. A recent and growing literature has shown that the methods and results of two-sided matching theory extend to substantially more general settings, including \"trading networks\" in which agents negotiate over contracts.<br\/><br\/>Unlike two-sided matching markets, trading networks feature intermediaries, agents who both buy and sell in the market. These intermediaries may be intermediate producers (as in most economic models of supply chains) or may simply facilitate trade (e.g., through provision of information). Although the presence of intermediaries is the defining distinction between the matching-in-networks model and the previous two-sided frameworks, the analysis of intermediaries in these matching models has been limited.<br\/><br\/>This research will further our understanding of the behavior and impact of market intermediaries. Theoretical work using the matching-in-networks framework will be supplemented with detailed empirical analyses using plant-level microdata on production networks, in order to gain insight into the magnitudes of intermediaries' effects on welfare. Simulated counterfactual models will be developed when theory does not provide sharp predictions.<br\/><br\/>This work will inform and support new applications of market design approaches to real-world intermediated matching markets. One focus will be understanding how \"local\" perturbations (e.g., intermediary entrance and exit) affect the \"global\" structure of networks; another will be the identification and reduction of rent seeking by intermediaries.<br\/><br\/>In addition to enabling novel work in applied market design, this research will promote joint work between computer scientists and economists working in the theory and practice of market design.","title":"ICES: Small: Collaborative Research:Understanding the Roles of Intermediaries in Matching Markets","awardID":"1216095","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":[516986,516987],"PO":["565251"]},"193720":{"abstract":"1219451 <br\/>This project supports a workshop proposal by Dr. Tarek Saadawi, CUNY City College, New York, NY for a US-Egypt Workshop: Cyber Security, Cairo, Egypt, December 2012. The Egyptian co-organizer is Dr. Ayman El-Dessouki, Electronics Research Institute, Cairo, Egypt. Many cyber security schemes are based solely on preventive or reactive, rather than proactive, measures such as patching of software or detecting already occurred attacks. Most of the network and information system security configurations are performed manually and require experts to monitor, tune security devices and recover from attacks. On the other hand, attacks are getting more sophisticated and highly automated which gives the attackers an advantage in this arms race. The workshop is to address important issues in cyber security and the protection of information systems and network infrastructure. The workshop will bring together leading researchers from academia, industry and the government for a comprehensive update on security and risk management research and development issues. The workshop will have scientists from USA and Egypt. The specific objectives of the proposed workshop are : To convene a gathering of US and Egypt scientists in the areas of cyber security in a workshop setting to explore the synergy between: o The current state-of-the-art in cyber security covering cryptology, network security and intrusion detection, software and operating system security, and software forensic techniques and tools; The current state-of-the-art in collaborative support technologies as they pertain to the support of collaborations between US and Egypt scientists; To identify specific US\/Egypt institutions for faculty and graduate student exchange programs, with the intent that such initial institutions serve as models for wider exchanges; To identify specific areas of Undergraduate and Graduate Education which might be beneficial in the development of young scientists with specific interest in the Workshop areas; To disseminate the outcomes of the Workshop via the Internet and digital hardcopy (CDROM\/DVD).<br\/><br\/>Intellectual Merits: The research problems addressed in this workshop by leading scientists from US and Egypt will advance the research in this area. This workshop will help to identify specific US\/Egypt institutions for faculty and graduate student exchange programs, with the intent that such initial institutions serve as models for wider exchanges.<br\/><br\/>Broader Impacts: Research outcomes of this workshop will greatly benefit industries and educational institutes not only in the US and Egypt but other countries in the world as well. Students trained will acquire unique skills and expertise in the aspects of collaborations. The problems addressed in this project pertain to cyber security in general and information assurance and network security in particular. Thus the outcomes of this project can impact the society in the near future. The applications we target are very vital to the humans and the society. This proposal is supported under the US-Egypt Joint Fund Program where NSF supports the US side and the Government of Egypt funds the Egyptian side.","title":"US-Egypt Workshop on Cyber Security, Cairo, Egypt, December 2012","awardID":"1219451","effectiveDate":"2012-09-15","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"K563","name":"DEPT OF STATE"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7299","name":"Catalyzing New Intl Collab"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[518779],"PO":["561865"]},"193610":{"abstract":"Industry is approaching the limit of the data storage density possible on magnetic disks with the traditional approach of reading and writing data on a single-track. This research considers an alternate approach called two dimensional magnetic recording (TDMR), wherein bits are read and written in two dimensions on conventional magnetic disks. A key problem in TDMR is that a given magnetic grain on the disk retains the polarization of the last bit written on it; hence, if a grain is large enough to contain two bit centers, the oldest bit will be overwritten by the newer one if they have different polarities. Bits are read from the disk by a 2D read head. Because bits are stored at high density, the signal read from a given bit suffers 2D intersymbol interference (2D ISI) from bits in both down and cross track directions. This research allows industry to continue to refine conventional magnetic recording technology, without radical redesign of the recording medium.<br\/><br\/>The investigators study 2D signal processing and coding techniques to combat grain overwriting and 2D ISI in TDMR, with the goal of approaching the recently estimated channel capacity of 0.5 bit\/grain. Specific objectives include:<br\/>1) Investigate detectors for the TDMR magnetic grain channel based on three channel models: rectangular-grain model, discrete-grain Voronoi model, and Voronoi model. <br\/>2) Integrate grain channel detection with 2D ISI detection and with channel decoding. <br\/>3) Develop capacity bounds for the TDMR\/ISI channel models.<br\/>4) Evaluate the developed algorithms against the capacity bounds and against experimental data from the project s industrial partner Hitachi Global Storage Technologies, a Western Digital company.","title":"CIF:Small:GOALI:Signal Processing and Coding for Two-Dimensional Magnetic Recording Channels","awardID":"1218885","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[518515,518516,518517],"PO":["564898"]},"193500":{"abstract":"The goal of this project is to enable the creation of new human-centered computing tools that will help people effectively analyze large collections of textual documents by providing powerful statistical analysis functionality in a usable and intuitive form. To accomplish that, this project investigates \"semantic interaction\" in visual analytics as a method to combine the large-data computationally-intensive foraging abilities of formal statistical mining algorithms with the intuitive cognitively-intensive sensemaking abilities of human analysts. Semantic interaction enables users to inject their domain expertise into the algorithms by interacting directly with the data. For example, analysts synthesize hypotheses about a set of documents by simply re-organizing them within a spatial visualization, highlighting important sentences, or annotating in the margins. Meanwhile, the underlying statistical models learn from these actions and interactively respond to help spatially organize additional relevant information according to the user's feedback. <br\/><br\/>Intellectual merit: Semantic interaction offers a new approach to interactive visual analytics that emphasizes usability. This research will (1) contribute new user interaction and visual feedback techniques for naturally controlling algorithms via the interactive sensemaking process; (2) contribute a flexible visual analytics framework that seamlessly integrates mathematical models with interactive visualization; and (3) evaluate the effectiveness of semantic interaction, which provides a quantitative mechanism to investigate the complex interplay between human intuition and formal statistical methods.<br\/><br\/>Broader impacts: This research will support a broad range of applications in visual text analytics, including intelligence analysis, funding portfolio management, and literature research. Participating agencies will test the software in ecologically valid settings. The software framework will be distributed to enable others to integrate additional models and to provide a usable platform for analysts. The project also proposes an educational and outreach agenda called \"CS for CSI\" that exploits the popularity of crime investigation stories to attract young students to technology research.","title":"HCC: Small: Semantic Interaction for Visual Text Analytics","awardID":"1218346","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[518252],"PO":["565342"]},"193621":{"abstract":"Data and I\/O availability is an increasing concern in today\u00d5s large data centers where both data volume and complexity are increasing dramatically. Most existing solutions are based on multi-replication techniques to provide data redundancy, where data chunks are replicated across storage server nodes. However, multi-replication techniques are insufficient to manage big data: it\u00d5s a big challenge to efficiently replicate N copies of a data set of tens-to-hundreds of petabytes! As an alternative solution, erasure codes tolerating multiple failures can provide reliability and availability at much lower cost. However, the biggest challenge using erasure codes to manage big data is the performance problem due to the complex encoding\/decoding operations, which limits the application of erasure codes in large-scale data centers. <br\/><br\/>This project develops cost effective techniques to exploit erasure codes to achieve high availability and enhance performance in large data centers to efficiently manage big data via several research innovations. This project cohesively investigates how to utilize proper spatial cost and system\/architecture techniques to improve the overall data access performance of server clusters built upon erasure codes. This research has fundamental contributions to pave the way to efficiently deploy data centers using erasure codes. It has potential to benefit numerous big data applications such as online searching, social network, e-business, health care, and so on which are typically data intensive.","title":"CSR: Small: Cost Effective, High Performance Solutions Using Erasure Codes for Big Data Management in Large Data Centers","awardID":"1218960","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550809"],"PO":["565255"]},"194721":{"abstract":"The security of our software is critical for consumer confidence, the protection of privacy and valuable intellectual property, and of course national security. Because of our society's increased reliance on software, security breaches can lead to serious personal or corporate losses, and endanger the privacy, liberties, and even the lives of individuals. As threats to software security have become more sophisticated, so too have the techniques and analyses developed to improve it. Symbolic execution has emerged as a fundamental tool for security applications. Its main idea is to run a program using symbolic instead of concrete values: a set of symbols are assigned to the program inputs, and the outputs are expressed as a set of \"verification conditions\", logical formulas over the input symbols. A number of successful security analyses use symbolic execution and similar methods to recast security questions about programs as constraint satisfaction problems in some formal logic. Automatic reasoners for that logic can then be used to solve those problems. In the last few years, solvers based on Satisfiability Modulo Theories (SMT) techniques have become a natural choice in such approaches to security because of their superior performance and automation compared to more traditional theorem provers and their greater generality with respect to ad-hoc tools or propositional satisfiability solvers.<br\/><br\/>This collaborative project brings together experts in security and in SMT to pursue two complementary research goals: (i) harness the full power of SMT solvers to improve current security tools based on symbolic analysis; and (ii) design and develop new techniques to address the needs of anticipated future security applications. Specific activities addressing these goals include: collecting challenge benchmark problems from existing security analyses and developing targeted SMT optimizations for these benchmarks; developing appropriate security abstractions in the SMT language used to express security verification conditions; developing logical theories and algorithms for reasoning about character strings in such verification conditions; exposing a general framework for extending the verification condition language; and developing techniques for computing symbolic solution sets for SMT constraints. These activities are expected to (i) significantly increase the flexibility, performance, and reasoning capabilities of SMT solvers in support of security applications; (ii) improve the performance and scalability of current security analyses by leveraging the reasoning power of SMT solvers; and (iii) provide a foundation for new, more powerful, and more expressive security analyses. Overall, this project will help create more scalable and expressive security applications which could have a considerable impact on society as they enable the production of software much more resistant to security attacks.","title":"TWC: Medium: Collaborative: Breaking the Satisfiability Modulo Theories (SMT) Bottleneck in Symbolic Security Analysis","awardID":"1228765","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[521573],"PO":["565264"]},"193511":{"abstract":"This project develops a general framework for anomaly detection in dynamic social networks that evolve in both links and nodes. The framework includes first capturing the information of timestamps of dynamic networks by transferring them into carefully selected graph kernel feature spaces. A dynamic modeling method is then designed to learn the dynamism on the target dynamic social network. Anomaly detection methods are finally developed to mine abnormal nodes in the dynamic network. The main innovation of the approaches is to represent dynamic networks by bags of attributes, including graph kernel features to epitome details in each timestamp, learned latent variables for dynamism of networks and user specified features to turn the direction of attributes representation towards aimed tasks. Based on this representation, the project designs innovative methods based on latent support vector machine and transfer learning to detect abnormal nodes. <br\/><br\/>This research provides a clear understanding of evolution patterns, including both normality and abnormality in dynamic social networks. The approaches developed in this project help identify various abnormalities in our life, including detecting spammers in websites, monitoring potential dangerous activities in crime networks, identifying malicious source of infection in disease networks, and many others. The successful modeling of such network dynamics can provide scientific basis for appearance and disappearance of human relationships, improve the prospects for uncovering potentially undiscovered evolution patterns in social networking process and help develop qualitative and quantitative algorithms for more applications.","title":"III: Small: Dynamic Social Network Mining: Feature Extraction, Modeling and Anomaly Detection","awardID":"1218393","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[518277],"PO":["565136"]},"194732":{"abstract":"The security of our software is critical for consumer confidence, the protection of privacy and valuable intellectual property, and of course national security. Because of our society's increased reliance on software, security breaches can lead to serious personal or corporate losses, and endanger the privacy, liberties, and even the lives of individuals. As threats to software security have become more sophisticated, so too have the techniques and analyses developed to improve it. Symbolic execution has emerged as a fundamental tool for security applications. Its main idea is to run a program using symbolic instead of concrete values: a set of symbols are assigned to the program inputs, and the outputs are expressed as a set of \"verification conditions\", logical formulas over the input symbols. A number of successful security analyses use symbolic execution and similar methods to recast security questions about programs as constraint satisfaction problems in some formal logic. Automatic reasoners for that logic can then be used to solve those problems. In the last few years, solvers based on Satisfiability Modulo Theories (SMT) techniques have become a natural choice in such approaches to security because of their superior performance and automation compared to more traditional theorem provers and their greater generality with respect to ad-hoc tools or propositional satisfiability solvers.<br\/><br\/>This collaborative project brings together experts in security and in SMT to pursue two complementary research goals: (i) harness the full power of SMT solvers to improve current security tools based on symbolic analysis; and (ii) design and develop new techniques to address the needs of anticipated future security applications. Specific activities addressing these goals include: collecting challenge benchmark problems from existing security analyses and developing targeted SMT optimizations for these benchmarks; developing appropriate security abstractions in the SMT language used to express security verification conditions; developing logical theories and algorithms for reasoning about character strings in such verification conditions; exposing a general framework for extending the verification condition language; and developing techniques for computing symbolic solution sets for SMT constraints. These activities are expected to (i) significantly increase the flexibility, performance, and reasoning capabilities of SMT solvers in support of security applications; (ii) improve the performance and scalability of current security analyses by leveraging the reasoning power of SMT solvers; and (iii) provide a foundation for new, more powerful, and more expressive security analyses. Overall, this project will help create more scalable and expressive security applications which could have a considerable impact on society as they enable the production of software much more resistant to security attacks.","title":"TWC: Medium: Collaborative: Breaking the Satisfiability Modulo Theories (SMT) Bottleneck in Symbolic Security Analysis","awardID":"1228827","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[521610,521611],"PO":["565264"]},"193522":{"abstract":"Visible light communication (VLC) is emerging as a viable alternative wireless transmission technology that could potentially alleviate the spectrum scarcity problem. VLC uses ordinary light sources such as light emitting diodes (LEDs) as the communication medium, and superposes a high frequency on\/off operation on top of light sources for data transmissions. Compared to radio communications, the advantages of VLC include several orders broader in bandwidth, very little regulatory restrictions, ubiquitous light sources, and higher level of security for transmissions. One of the main challenges in the design of VLC at the physical layer is the issue of interference caused by simultaneous transmissions of multiple sources due to diffusion of lights emitted from regular light sources. While interference management for the Gaussian model (valid for the strong background light noise regime) is relatively well understood, it is mostly unexplored for the Poisson model (valid for the low background light noise regime). <br\/><br\/>This project will design novel interference management techniques for VLC in the Poisson regime, analyze the corresponding transmission rates\/throughputs for VLC, and develop information theoretic methodologies to characterize the fundamental communication limits on these transmission rates. The proposed research is expected to make substantial contributions to both applications and theory. On the application side, this project is anticipated to substantially advance our understanding of interference management for VLC, and provide important guidelines for designing high throughput and resource efficient VLC networks. On the theoretical level, the project will develop new stochastic calculus and information theoretic tools to advance our understanding of Poisson channels. The PIs will also use this project as a great platform to attract and train students from diverse backgrounds.","title":"CIF: Small: Collaborative Research: Interference Management for Visible Light Communications via Poisson Model","awardID":"1218451","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[518302],"PO":["564924"]},"193643":{"abstract":"This project is studying statistical inference from datasets tracking the diffusion of new ideas or behaviors through a population. Game theoretic models for the diffusion are utilized in which members of the population decide to adopt a technology by maximizing a pay-off that depends on an underlying network structure. Example questions include the identification of \"first movers\" and the most likely series of actions that result in a given observed state of the network. Algorithms are being developed for characterizing the maximum likelihood estimate of first movers for an evolutionary game theoretic framework with smoothed best response dynamics. Additionally algorithms to identify influential nodes and the network graph along with the associate payoff functions are being studied. The associated modeling and analysis build upon foundations in probability and statistics, Markov processes, statistical mechanics, optimization and game theory.<br\/><br\/>Understanding diffusions in social networks is broadly applicable across society including areas such as marketing, economics and social sciences; efforts are being made to disseminate the results of this work to such fields as well as to incorporate ideas into undergraduate and graduate courses in EECS.","title":"III: Small: Inferring first movers in large-scale socio-technical networks","awardID":"1219071","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["560218","560219"],"PO":["565136"]},"192202":{"abstract":"Many emerging quantum information technologies require access to some form of quantum entanglement in order to operate. Understanding what is needed and what is possible to achieve with these technologies is frustrated by the large number of types of multiparticle entanglement that could be produced. The role of multiparticle quantum entanglement as a resource and the proliferation of entanglement types with increasing particle numbers motivate a program of classification. A good classification scheme provides a framework for understanding properties of and relationships among quantum states, puts interesting states in a context, and introduces concepts that allow explanation and interpretation of new findings. The goals of this research are to produce such a classification scheme, and to use the resulting knowledge about the structure of quantum states in applications of interest in quantum computation, communication, and cryptography.<br\/><br\/>This project will provide a framework and a language in which to articulate the needs and resources of quantum information processing tasks, and will therefore be of use to researchers trying to make these tasks a reality. A second broader impact of this project is direct influence on the scientific careers of promising young students. Undergraduates will participate as research assistants who will carry out computational experiments, write computer code to generate examples and test hypotheses, and prove special cases of broad conjectures. Engagement in research teaches the process of intellectual inquiry and discovery in a way that classroom work alone cannot achieve. This project will strengthen the research environment at Lebanon Valley College by supporting students in research activities including presentations at scientific meetings and publications in scientific journals.","title":"RUI: Structure and Local Equivalence of Stabilizers and States","awardID":"1211594","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"7281","name":"QUATM INFO & REVOLUTIONARY COM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[515092,515093],"PO":["564326"]},"193654":{"abstract":"This project is focused on developing new speech processing techniques which will transform access to large asynchronous multi-channel and diverse collections of multimedia materials. In particular, the algorithms developed are being employed to create a novel multi-source and multi-scale event reconstruction system that brings together the massive archives of the Apollo lunar missions, to create experiential interaction with historical materials. Specific research advancements are focused on state of the art acoustic environment analysis, speech recognition including keyword spotting, speaker identification under adverse conditions, multimodal content alignment, and automated linking for events and entities from spoken content. Specifically, the research is developing: (i) new techniques for noise- and channel-robust acoustic processing, exploiting missing-features concepts with novel feature extraction and compensation techniques, (ii) a new articulatory framework for speech recognition for robustness to variations in speech production, (iii) environmental \"sniffing\" techniques to automatically characterize acoustic environments to improve robustness, and (iv) automatic detection of novel task-specific audio-events. Since the data is asynchronous, unique speech analytics techniques are being formulated to address the large number of \"local loop\" intercom circuits in the NASA Mission Control Center, audio recorded onboard the two Apollo spacecrafts during specific mission events, and space-to-ground radio circuits. The specific speech, language, and knowledge extraction advancements will be integrated into a new automated evaluation model that reflects specific challenges encountered in the event reconstruction task. This platform will be deployed and evaluated by actual users from the Science and Engineering Education Center (SEEC) of the University of Texas at Dallas. <br\/><br\/>Integration of robust speech processing algorithms with event reconstruction systems will have a direct and immediate impact on education, society, and government organizations. Working with NASA's Apollo mission data allows for the development of speech technology for challenging audio that contains severe communication channel artifacts, cross-talk\/static\/tones, and low signal-to-noise ratios. The software being developed in this project will be made available to any non-profit organization for use in audio\/video search (download with training modules). Students working on senior design teams will also develop a Contact Science station to be deployed in Dallas, TX and overseen by the University of Texas in Dallas Science and Engineering Education Center to illustrate and assess student use of the advancements. As a lasting legacy for this project, this project team includes eminent historians of human space flight, who will explore opportunities to deploy this event reconstruction system in a museum setting where it can support both scholarship and public engagement, and we will make the system itself available on an open-source basis to support other researchers.","title":"RI: Small: Collaborative Research: 'Houston We Have A Solution': Novel Speech Processing Advancements for Analysis of Large Asynchronous Multi-Channel Audio Corpora","awardID":"1219130","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[518617,518618],"PO":["565215"]},"193775":{"abstract":"Much of the internet's business is conducted with dynamically generated documents --- HTML pages, SQL queries, and execution scripts --- that are generated on-the-fly by document-generator scripts written in PHP, Javascript, and JSP. The situation is a threat to internet security because the document-generator scripts are often faulty, generating malformed documents that are vulnerable to attackers. To remove this vulnerability, a new approach, abstract parsing, is developed and applied to enforce, in advance of execution, that every dynamically generated document emitted from a script will be grammatically well formed (spelled correctly). The technique also predicts the range of semantics (intended meanings) of the generated documents, to help prevent attacker exploitation. The impact of the research lies in its tools and methodologies to help programmers assemble a more secure internet.<br\/><br\/>The technical approach starts from a document-generator script and a context-free reference grammar for the document language and generates an LALR(1)-parser from the grammar, applying it within a data-flow analysis of the script to predict the LALR-grammatical structure of the string-documents to be generated by the script. The analysis computes abstract LALR-parse stacks that overapproximate the grammatical structure of the string-documents that the script generates. <br\/>Attribute-grammar machinery predicts the context-sensitive and semantical properties of the documents to be generated. The technology is applied to (i) generate a semantically-aware implementation of taint analysis; (ii) implement automata-defined filters for dynamic string updates; (iii) combine abstract-interpretation technology with abstract parsing to analyze a wider class of program constructions, in particular, dictionary data structures.","title":"TWC: Small: Abstract Semantic Processing for Script Security","awardID":"1219746","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["533701"],"PO":["564388"]},"193423":{"abstract":"This project, developing robust and computationally intelligent randomized sampling based feedback motion planning techniques for constrained systems operating under \"process\" and \"sensing\" uncertainty, addresses an important research area for real-world systems. Such motion planning techniques are valuable because the high computational burden of these problems makes the solution of such problems intractable for anything but the simplest low dimensional systems. In particular, one of the most fundamental requirement of robots is that they operate in a safe, efficient and autonomous fashion in the presence of such uncertainty. Thus, a principled set of computationally intelligent techniques, with guaranteed performance, is required. This proposed work will generalize the Probabilistic RoadMap technique (PRM) of robotic path planning shall such that the roadmap construction incorporates both process and sensing uncertainty. This will result in a computationally tractable solution technique for a large class of constrained Markov Decision Problems (MDP) and Partially Observed MDPs (POMDP), known as constrained stochastic shortest path problems, along with guaranteed performance of the planners in terms of a probability of success. <br\/><br\/>Broader Impacts: The ability to solve high dimensional constrained MDP and POMDP problems in a computationally tractable fashion will have significant impact on multiple different robotic applications including robotic operations in hazardous environments such as disaster areas and battlefields, surgical robotics, prosthetics and unmanned planetary exploration. The impact of such computationally intelligent solution techniques cannot be overstated due to the ubiquitous nature of MDPs and POMDPs, which are fundamental decision making problems inherent in myriad different fields ranging from Engineering through Economics to Biology. The assimilation of K-12\/undergraduate\/graduate students, with a focus on underrepresented minorities, with high school teachers in projects related to the research, through experiments and demonstrations related to the research at the annual \"TAMU Physics and Engineering fair\", and the annual department \"summer camp\" for high school students and their parents, will disseminate the results of the project to a broad audience.","title":"RI: Small: Sampling Based Feedback Motion Planners","awardID":"1217991","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["561154",518075],"PO":["534411"]},"193313":{"abstract":"The World Wide Web has become one of the most popular platforms for deploying rich software applications, and most Web applications include interfaces to persistent databases, many implemented with the SQL language. Mainstream programming techniques provide programmers with little help in construction of correct database interface code. As a result, many Web applications include serious security vulnerabilities that allow attackers to read others' private data, or even delete or corrupt it. Furthermore, programmers expend substantial effort reimplementing similar functionality for each new application and its new data model. This project studies programming tool support that can help solve both of these problems, based on a programming language and compiler that in a sense \"understand\" SQL database access.<br\/><br\/>A connecting thread in the project's technical approach is real-world application of computer theorem proving technology. The programming language, Ur\/Web, is based on dependent type theory, a language paradigm pioneered by interactive mathematical theorem proving tools. In the Web application context, type theory provides a unified framework for enforcing key program properties, such as invulnerability to code injection attacks and other common security problems. On top of this is built support for metaprogramming, or programs that generate programs, where the key security properties ought to be guaranteed for any code outputs of a metaprogram. One major thrust of the project is using metaprogramming to reify coding patterns as reusable libraries, dramatically reducing time and effort needed to construct a new application. The other major thrust is static program analysis, where symbolic execution and automated theorem proving are used to verify formally that Web applications conform to declarative security policies, covering information flow and access control. Metaprogramming will support component-based construction with module-local reasoning, while the static analysis ensures global consistency of programs from a security perspective.","title":"SHF: Small: Capitalizing on First-Class SQL Support in the Ur\/Web Programming Language","awardID":"1217501","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["534221"],"PO":["564588"]},"193324":{"abstract":"This research seeks to uncover explanations and principles about how requirements for information systems evolve and how they are managed across project contexts. It will enumerate project design workflows and practices to determine how different forms of artifact and process distribution affect requirements engineering goals and project success. Currently there are no rigorous, theory-based approaches to understanding and explaining large-scale distribution of requirements, though there is evidence of its success. Requirements engineering approaches address spatial and social distribution, and to a lesser extent, structural and temporal distribution. Most importantly, the combination of these issues, in total, has not been considered. Consequently, we cannot say which configuration of practices is best suited to achieve specified development goals, such as reduced time to market, or increased software quality and customer satisfaction. New theoretical models and empirical research are needed to understand the effects of distribution on evolving requirements.<br\/><br\/>The project will (1) conduct field studies and ethnography, (2) analyze work procedures via grounded theory and comparative methods, (3) construct tools for data analysis, model building, and model analysis, and (4) analyze models via simulations and goal analyses. It will apply a distributed requirements framework consisting of four forms of distribution (social, spatial, structural, and temporal) and four requirements tasks (discovery, specification, negotiation, monitoring) in conjunction with the theory of distributed cognition to analyze requirements knowledge evolution in software projects. Additionally, it will design new tools that help acquire, model, and analyze distributed requirements workflows. <br\/><br\/>The research aims to develop critical insights on emerging realities in large-scale design projects, which represent one of the drivers for economic growth and new forms of industrial organization. Yet, many software organizations are constrained by methodological and tool factors that do not recognize the increased challenges for requirements engineering. This research highlights the ways in which designers learn to manage the diversity of inputs and constraints, and seeks to understand processes that enhance software-based open innovation in the future.","title":"HCC: Small: Collaborative Research: Cognitive Approaches to Distributed Software Requirements Engineering","awardID":"1217552","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["549985"],"PO":["564456"]},"192114":{"abstract":"This project will design and implement \"Myrmex\", a novel crowdsourcing system for physical-world tasks. For example, an elderly community member could use Myrmex for help getting mail from a remote post office, as the system would assign the task to a participant who routinely passes that way. Myrmex leverages the capacity of computers (monitoring, matching participants to tasks) to facilitate human activity (assigning and performing tasks). The project will: 1) develop new privacy-preserving methods for location and context tracking; 2) design and implement incentives for continuous use of a new social system; and 3) create and implement models of best times and places to notify and offer tasks for participants.<br\/><br\/>Broader impacts: The Myrmex system will help strengthen bonds and connectivity within a community and provide assistance for community members for running their daily lives. Matching tasks and people based on locations and paths will also help conserve resources and benefit the environment due to the reduced travel miles needed to perform a task. The project will provide multidisciplinary training for undergraduate and graduate students. It will also provide the research community with an anonymized dataset of human mobility patterns and task activities, and tools to analyze human behavior.","title":"SoCS: Collaborative Research: Local Community Crowdsourcing of Physical-World Tasks with Myrmex","awardID":"1211084","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":[514875,"529982"],"PO":["564456"]},"193214":{"abstract":"This project team is exploring how crowd-based technology can support innovation education through feedback from potential customers and users, specifically looking at how the new forms of authentic feedback can be put to good use to support learning better to design, solve problems, and innovate. Research is around issues in learning through collaborations with potential consumers mediated by technology. What are the affordances of crowd-based technology that can support learning to design, learning to innovate, learning to use feedback well, and learning to effectively iterate towards an effective and innovative result? How does use of such technology and interactions need to be scaffolded to such learning? What crowd-based activities and what types of design challenges afford such learning? Foundations are in Learning by Design (LBD), thick authenticity, and Project-Based Science (PBS). <br\/><br\/>A key to America's economic and social prosperity depends on people's ability to innovate social and technical solutions. Crowd-based technologies provide opportunities for innovators to interact with potential consumers and experts while innovating, but they have not been used in innovation education. Feedback from crowds could, however, be used to provide learners an opportunity to receive rich informative feedback on design ideas and to develop solutions that fit real-world needs. This project will contribute to our nation's ability to better prepare engineers for innovation. The technology suggested here will, if successful, make opportunities for experiencing both the difficulties of innovating and the kinds of support structures that can help and will provide an infrastructure for helping potential innovators learn to use feedback from others wisely. In addition, the results of this project will contribute towards enhancing project-based experiences throughout the curriculum. What is learned in this project about supporting learning to design, learning to innovate, learning to use feedback well, and learning to effectively iterate towards an effective result has potential to inform the effective use of project-based and design-based classes across grades and disciplines.","title":"EXP: Collaborative Research: Engaging Interdisciplinary Students in Innovation Education through Crowd-based Technology","awardID":"1217096","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":[517579],"PO":["562669"]},"193456":{"abstract":"This collaborative project addresses the need for ocean observational techniques which was highlighted by the recent Deepwater Horizon incident. The proposed project investigates heterogeneous ocean robots (including wave gliders, unmanned surface vessels, and autonomous underwater vehicles) to detect and monitor the propagation of oil plumes. Specific objectives include: 1) the development of a distributed multi-robot cooperative deployment algorithm using partial differential equation (PDE) based methods that match the oceanographic model of oil transport, 2) the development of authentic dynamic model of the new wave glider platform to incorporate in the cooperative control, and 3) assessing the potential advantages of innovative algorithms through simulations and experimental demonstration in a coastal experiment using a network of ocean robot platforms.<br\/><br\/>Broader Impacts: The proposed project will provide novel algorithmic and software support for collective sensing, and address a pressing real-world need for better sensing of underwater hydrocarbon plumes. The techniques developed in the proposal will have long-term impacts in underwater exploration such as oceanographic survey and energy production in deep water. The results may also potentially benefit other environmental monitoring tasks with underlying diffusion and advection processes, such as weather event tracking and climate prediction. The planned work will integrate research projects with education activities through robot-centric undergraduate and graduate education, robotics competition, short course and workshop development, and outreach to K-12 education. Partnering with the Stevens' Center for Innovation in Engineering and Science Education, the project will showcase the proposed research in the curriculum of the Stevens Build IT Underwater Robotics Scale-Up for STEM Learning and Workforce Development Project awarded by NSF.","title":"RI: Small: Collaborative Research: Distributed Heterogeneous Ocean Robots for Detecting and Monitoring Oil Plumes","awardID":"1218155","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["513898"],"PO":["564069"]},"193346":{"abstract":"A \"computer user\" can no longer be thought of only as a person sitting at a desk in a consistent and comfortable working environment. Today's typical computer user is now holding a mobile device smaller than his or her hand, is outdoors, under the sun or in the rain, and perhaps even in motion, such as walking or riding. However, mobile devices have no deep awareness of the environments in which they are being used, or how those environments will affect their users' abilities to act. Addressing this challenge is the central idea of this project. The approach is to better understand, through scientific means, and better accommodate, through clever sensing and design, the \"situational impairments\" that affect the new-typical computer user for our age, the mobile user. Although situational impairments have been noted in the past, few research efforts have looked at how to sense impairing effects and what to do about them. Innovations in sensors, inference, and user interfaces have the potential to improve mobile interaction in the presence of situational impairments, showing that accessibility is \"for everyone.\"<br\/><br\/>The intellectual merits of this work include: (a) scientific studies of some situationally-impairing factors on human performance; (b) the invention and evaluation of ten projects designed to address and reduce the negative effects of certain situational impairments; (c) the development of clever reusable sensing techniques to enable the creation of those projects and advance the capabilities of mobile devices; and (d) the study of the \"crossover potential\" of projects to people with physical or health-induced impairments and disabilities.<br\/><br\/>The broader impacts of this work include: (a) pushing the capabilities of mobile devices and sensing technologies to become more useful and usable, especially in varied contexts, which may have relevance to mobile field workers; (b) concretely demonstrating that accessibility research benefits everyone, and that all people incur impairments of one form or another in their lives; (c) contributing to public health and safety by reducing the dangers situational impairments cause, particularly to and from people driving automobiles, and (d) creating a graduate course, an undergraduate workshop, and a grades 6-12 science unit on ability-based design for mobile computing.","title":"HCC: Small: Understanding, Sensing, and Accommodating Situational Impairments in Mobile Computing","awardID":"1217627","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["522921","534402"],"PO":["565227"]},"193467":{"abstract":"As technology scales to 10nm, CMOS-based memory devices may no longer be the technology of choice. Instead, emerging technologies, such as phase-change memory, spin-transfer torque magnetic memory, and ferromagnetic memory, are more scalable and are viable alternatives for the post-silicon era. These memory devices are diverse in their physical operation and performance and there is no winner-takes-all! This project advocates the use of heterogeneous memory systems which combine the advantages of the different memory technologies to deliver superior system performance. <br\/><br\/>The first step involves development of a hierarchical memory model which captures both the generic behavior and unique device physics of the different memory technologies. This model is also capable of predicting the performance and reliability of future technology nodes. The next step is on integration of this model into circuit and architecture-level simulators for exploration of heterogeneous memory systems. The intellectual merit lies in the coordinated effort spanning from device physics to modeling to architecture exploration. Research advances will be made in memory device modeling including predictive modeling, error analysis and modeling, error management for improved reliability and heterogeneous memory system design. The research outcome from this project is expected to have a significant impact on integrated circuit design industry and national economy. The proposed effort will foster a unique environment for multi-disciplinary research and training. It will help bridge the gap between memory device physics and computer architects by training undergraduate and graduate students in cross-disciplinary research and also by providing an open simulation environment for exploratory memory design.","title":"CSR: Small: Heterogeneous Memory Design: Exploiting Device Diversity for Superior System Performance","awardID":"1218183","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[518174,"543501"],"PO":["565255"]},"193357":{"abstract":"It is natural that events of interest in observed scenes manifest themselves across multiple sensing modalities - vision, hearing, smell, etc. The remarkable perceptions of audio-video signals by natural systems, such as humans, also points to superiority of inferences drawn across modalities. It, therefore, seems natural to enhance performance of automated systems by using joint, cross-modal statistical inferences. However, the detection, organization, and understanding of cues and events in real-world scenarios are difficult tasks. This project seeks to develop a pattern-theoretic framework for achieving these goals. The main research items are: (1) development of mathematical quantities to represent audio and visual events and their spatiotemporal relations, (2) use domain-specific ontologies to impose semantic structure and to incorporate prior knowledge, and (3) derive algorithms for Bayesian inferences using efficient adaptations of Markov Chain Monte Carlo sampling. <br\/><br\/>The use of pattern theory allows bridging of gaps between raw signals and high-level, domain-dependent semantics, and helps discovers large groups of audio-visual events likely to represent the same underlying event. This effort combines ideas from perceptual organization in computer vision, computational analysis of auditory signals, pattern theory, and prior developments in ontological structures. The methods developed here are applicable to many scenarios that deploy audio and video sensors, including problems of audio annotations of videos, speaker tracking in teleconferencing, and separation of multiple objects in remote surveillance. Broader impact activities involve the development of teaching modules, innovation and entrepreneurial training of the students, and communication of the findings to the community.","title":"RI: Small: Collaborative Research: Ontology based Perceptual Organization of Audio-Video Events using Pattern Theory","awardID":"1217676","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["522400"],"PO":["564316"]},"193247":{"abstract":"This project team is exploring how crowd-based technology can support innovation education through feedback from potential customers and users, specifically looking at how the new forms of authentic feedback can be put to good use to support learning better to design, solve problems, and innovate. Research is around issues in learning through collaborations with potential consumers mediated by technology. What are the affordances of crowd-based technology that can support learning to design, learning to innovate, learning to use feedback well, and learning to effectively iterate towards an effective and innovative result? How does use of such technology and interactions need to be scaffolded to such learning? What crowd-based activities and what types of design challenges afford such learning? Foundations are in Learning by Design (LBD), thick authenticity, and Project-Based Science (PBS). <br\/><br\/>A key to America's economic and social prosperity depends on people's ability to innovate social and technical solutions. Crowd-based technologies provide opportunities for innovators to interact with potential consumers and experts while innovating, but they have not been used in innovation education. Feedback from crowds could, however, be used to provide learners an opportunity to receive rich informative feedback on design ideas and to develop solutions that fit real-world needs. This project will contribute to our nation's ability to better prepare engineers for innovation. The technology suggested here will, if successful, make opportunities for experiencing both the difficulties of innovating and the kinds of support structures that can help and will provide an infrastructure for helping potential innovators learn to use feedback from others wisely. In addition, the results of this project will contribute towards enhancing project-based experiences throughout the curriculum. What is learned in this project about supporting learning to design, learning to innovate, learning to use feedback well, and learning to effectively iterate towards an effective result has potential to inform the effective use of project-based and design-based classes across grades and disciplines.","title":"EXP: Collaborative Research: Engaging Interdisciplinary Students in Innovation Education through Crowd-based Technology","awardID":"1217225","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":["550967"],"PO":["562669"]},"193489":{"abstract":"Technological advances in devices, computing, communication, and networking have allowed the development and deployment of networked sensing systems of varying scales with diverse applications. The voluminous data collected in these networked systems, however, present some unique challenges. Ensuring that useful data be available at the right location in a timely fashion is difficult in a large scale network because of various limitations inherent in such systems. In addition, the collected data in its raw form often lacks clarity for making an informed decision. The primary goal of the project is to develop theory and methodology that allow the raw data to be reduced to the extent such that 1) their transmission to the desired destination is compliant to the system limitation, and 2) there is no loss of information with respect to the mission of the networked system. <br\/><br\/>The project pursues a comprehensive treatment of data reduction in such inference networks and aims to develop the sufficiency principle and related theory and methods to overcome these challenges. Intimate connection between data reduction for inference and data compression for transmission is exploited and expanded in the network setting. New interpretations using the sufficiency principle for some classical multi-terminal source coding problems will be developed; they provide a new venue for the exploration of the connection between statistics and information theory. The development of theory and methods that guide data reduction in a networked inference system also has the potential to unify existing works that are tailored toward specific inference problems.","title":"CIF: Small: Data Reduction for Networked Inference","awardID":"1218289","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[518226],"PO":["564898"]},"193137":{"abstract":"Online homework help forums exist, but there is no good way, right now, for students to know whether they are getting good advice or not. The innovations here are to take advantage of the fact that many students participating in online homework forums want to give each other good advice and almost all want to do well on their homework. Taking advantage of participants' want to give good advice, these PIs propose to provide scaffolding that will encourage and aid good explanations of the how-tos and whys of worked-out-problem examples students are sharing. Taking advantage of participants' want to get their own homework right, the PIs propose a simple approach to helping them learn to judge the quality of help they receive. The innovation is quite simple; it includes providing users of a homework site a template for sharing answers and a rating rubric that has them reflect on what made a worked-out answer to a question useful to them. The PIs are carrying out a set of experimental studies in a quasi-authentic homework forum to address several issues: How can we help students judge the quality of solutions that are shared? How can we help sharers present better quality worked examples? There is learning to be had for both kinds of participants. The work builds on research on what makes worked-out examples helpful and on what is known about the value of self-explanations.<br\/><br\/>One way middle school and high school students get help with homework is through online homework forums. The most popular current online homework forums hold repositories of worked-out examples that those needing homework help can use as analogues as they work on their own homework problems. But students who go to these sites for help cannot know if the worked examples they are looking at are done well or not, and simply solving one's own homework problem the way someone else solved an analogous problem does not guarantee learning. This project is developing a way to help students who seek help from these forums to know whether a worked example is done well and to promote the best learning possible from worked examples. The worked-example literature reports that structuring worked examples according to the steps in working them out, the goals being addressed in each step, and the means of addressing each goal promotes learning better than structuring worked examples in other ways or note structuring them at all. This project, therefore, is developing a way to encourage and help those who are entering worked examples to structure their examples so that those seeking to learn will get get the most from their answers. The self-explanation literature suggests that such structuring will also allow those offering worked examples to deepen their understanding and capabilities as they work towards presenting their worked examples to others in an organized way. This project is developing a means of helping those who offer worked examples to structure them for promoting learning and a means of helping those who are using those worked examples to know if a worked example is likely to be trustworthy and learn well from the worked example, and it is investigating the benefits to both those offering examples and those using them of using a structured approach. Eventually, such help could be incorporated into the real-life help forums themselves.","title":"EXP: Improving the Quality of Worked Examples in Open, Online, Homework Help Forums","awardID":"1216769","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":[517374,"552467"],"PO":["562669"]},"193258":{"abstract":"Over the last decade, the field of Software Engineering has seen a rapid and widespread adoption of automated refactoring tools: tools that analyze the source code under the direction of the programmer, and make systematic changes to that program that improve its internal structure without affecting its behavior. In the C programming language, which is one of the most popular languages in use, there is only a limited portfolio of refactorings available, with limited scalability and limited applicability to real-world programs. This research will address the technical problems that make it difficult to build automated refactoring tools (and other program transformation tools) for C: the ability to \"configure\" C programs using preprocessor macros, the need to perform sophisticated analyses in the presence of many such configurations, and the need to analyze and transform C when it is mixed with other programming languages. Solving these problems, and producing a tool that incorporates these solutions, will provide much needed tool improvements for C programmers.<br\/><br\/>The research will culminate in a prototype refactoring and program transformation tool for C that addresses the aforementioned problems. Handling multiple preprocessor configurations will involve the exploration of both a parsing algorithm and a program representation: the parsing algorithm extends the LALR(1) algorithm to handle preprocessor directives, while the program representation accommodates multiple configurations in a single abstract syntax tree (AST). Semantic information (from various static analyses) will be superimposed on the AST; however, this will require extending the static analyses to handle the complications presented by multiple preprocessor configurations. The tool will also allow for transforming mixed-language C programs--in particular, C programs mixed with Fortran or Yacc (two languages that are commonly combined with C). Handling multiple languages may be treated as an extension of the multiple configurations problem, where declarations in one language and definitions in a different language are treated, at least conceptually, as different configurations. The tool will be available under an open source license.","title":"SHF: Small: A Practical Program Transformation Infrastructure for C in the Presence of Multiple Configurations","awardID":"1217271","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[517693],"PO":["564388"]},"193379":{"abstract":"With increasing network connectivity available, data generated by embedded sensor devices have been effectively shared in many collaborative applications, such as sensor data collection, environmental monitoring, and wearable computing. Data sharing has been a research topic for many years, with hundreds of related projects. In contrast, the concept of energy sharing among multiple embedded sensor devices has captured very little attention. Until now, energy has been predominately harvested and consumed locally in a single embedded sensor device. In this project, we attempt to lay a foundation for energy sharing among sustainable sensor devices. The outcome of this research will constitute a significant advance in the development of theoretical foundations and practical algorithms for designing and improving energy efficiency of sustainable sensor networks. The broader impact of this work shall be amplified by (i) improving course development and student training; (ii) increasing research participation of minorities, women, and Native Americans; (iii) facilitating international dissemination of research findings; (iv) raising interest in technology among K-12 students and other under-represented minority groups; and (v) fostering interdisciplinary collaborations.","title":"CSR: Small: Energy-Shared Computing in Sustainable Sensor Networks","awardID":"1217791","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[517973],"PO":["565255"]},"196778":{"abstract":"Real world data, such as World Wide Web, social networks, corporate knowledge networks, biological networks, semantic networks, etc., can be abstracted in the form of a massive and complex graph, with millions to billions of nodes and edges. With the explosion of such data, there is a pressing need for data mining, analysis, and querying tools to rapidly make sense of and extract knowledge. However, effectively leveraging the resources of modern architectures and mining such large graphs for interesting patterns remains challenging. At the same time commodity desktop architectures that have processors with multiple cores and graphics processors (with hundreds of stream cores) are opening up significant opportunities for parallel graph analytics and management on the desktop.<br\/><br\/>This exploratory research seeks to scale up the performance of graph mining and clustering algorithms on modern desktop supercomputers to leverage the power of multi-core systems equipped with graphics processors, and to explore and develop new algorithms for reducing the search space and and the amount of data processed.","title":"CCF: EAGER: Collaborative Research: Scalable Graph Mining and Clustering on Desktop Supercomputers","awardID":"1240651","effectiveDate":"2012-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[527873],"PO":["565272"]},"193269":{"abstract":"Multiple-input multiple-output (MIMO) technology provides a means of boosting network capacity without requiring additional spectrum by exploiting spatially multiplexing, interference suppression, and spatial diversity. It has received widespread attention over the past decade from both industry and academic researchers, now forming a key component of nearly all emerging wireless standards. Despite the huge promise and considerable attention, a rigorous algorithm-theoretic framework for maximizing network capacity in multihop wireless MIMO networks is missing in the state of the art. This project establishes both the computational hardness and approximation hardness of maximizing network capacity in multihop wireless MIMO networks, and develops practical approximation algorithms with provably good performance. A polyhedral approach is taken by the project to construct various polynomial approximate capacity subregions of multihop wireless MIMO networks. These approximate capacity subregions not only are the algorithmic foundation of maximizing network capacity in multihop wireless MIMO networks, but also serve as a basis for interesting future projects on cross-layer design and optimizations in multihop wireless MIMO networks. They are also of independent interest to the theoretical computer science community and communications community at large. This project provides scholarships to graduate students and offers research topics for strong dissertation works on multihop wireless networks. The outcome of this project will not only be disseminated to the professional researchers through journals and conference proceedings, but also be integrated into the lecture notes targeted for senior undergraduate students and graduate students.","title":"NeTS: Small: Collaborative Research: Maximizing Network Capacity in Multihop Wireless MIMO Networks","awardID":"1217309","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[517717],"PO":["557315"]},"198714":{"abstract":"Dynamic spectrum access (DSA) technologies are emerging as a promising mitigator against spectrum congestion resulting from the explosive growth in commercial and government wireless systems and services. One remaining challenge is the ability to establish reliable access to sufficient spectrum while avoiding harmful interference to other users when operating with imperfect situational awareness (SA). This research effort is developing the technical underpinnings and system concepts for reliable DSA operations with incomplete and inaccurate SA in programmable wireless networks (PWN). A multi-disciplinary approach is pursued, combining elements of communication theory, multiattribute decision theory, distributed systems theory, and behavioral economics theory. It specifically develops a decision-theoretic core that operates over imperfect SA information, determining what spectrum access opportunities to pursue as well as what information to gather for increased awareness. Information acquisition algorithms encompass access to dynamic and static data sources as well as distributed sensing and fusion approaches for combining data from multiple collaborative PWNs. Representation and reasoning of uncertainty is accomplished by Bayesian decision networks and probabilistic inference technologies. System performance is evaluated and validated via newly-generated spectrum scenarios and existing data collected in previous efforts. The technological developments enable PWN behavior and performance evaluation with respect to technical, regulatory, and economic domains. The research outcome can accelerate DSA fielding and broaden DSA operations to improve public safety and wireless broadband access. Research results will be disseminated through technical publications, conferences, and PWN community collaboration. They will also be integrated into regular classroom, workshop, and short course teaching.","title":"EAGER: Collaborative Decision Processing for Dynamic Spectrum Access in Programmable Wireless Networks","awardID":"1250521","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[533134],"PO":["565303"]},"186988":{"abstract":"Generic programming has the potential of an effective methodology for building large-scale, reliable, maintainable, and efficient software artifacts. It is supported by the C++ programming language through the \"template\" mechanism. In the hands of experts, C++ templates are formidable abstraction tools, key to the success of libraries such as the Standard Template Library, and many freely available and commercial software libraries and products. Unfortunately, the practice of template-based structured generic programming remains restricted to relatively few highly trained individuals. <br\/><br\/>A primary objective of this project is to investigate and develop software tools and programming models that support scalable and modular generic libraries. Bringing structured generic programming methodology to mainstream at the scale done for object-oriented programming entails the invention of new programming language constructs and compiler construction techniques that go beyond conventional technologies. In particular, the apparent complexities of templates and arcane technical details must be concealed; code generation has to surpass C++'s current successful applications of templates both in quality and compile time for industrial scale programs. At the core of this project is the investigation of a direct linguistic support for requirements on template arguments (\"concepts\"), and their implementations in an open source compiler and libraries made freely available to the public, the research and education community.","title":"SI2-SSE: Supporting Generic Programming in C++ for Modular and Reliable Large-Scale Software","awardID":"1148461","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[501668,"502347"],"PO":["565247"]},"194006":{"abstract":"Modern Web browsers provide a \"private browsing\" mode, wherein the browser does not record the user's behavior such as which sites they visited. This mode is valuable to users of all stripes, from the privacy-conscious to those those worried about persecution by totalitarian regimes. Browser implementers therefore take great care to try to ensure these modes function correctly. However, modern browsers are highly extensible: users can install extensions to customize their browser, and millions have done so. Unfortunately, it is technically challenging for browsers to automatically flag which extensions are privacy-preserving and which are not, so browsers currently do not attempt to offer such guidance -- leaving users to fend for themselves.<br\/><br\/>This work presents a type system for verifying whether extensions violate private browsing mode. The types distinguish Safe values (that may always be used in private mode) from Unsafe ones (that may lead to privacy violations). The type system is engineered to be<br\/>\"lightweight\": extensions that never perform unsafe actions should type check without changes, and extension authors must only annotate their extension code when an unsafe action is used. Extensions that pass this check are accompanied by a guarantee that they do not perform privacy-violating actions, and are thus safe to install in private-browsing mode.","title":"TWC: Small: Extensible Web Browsers and User Privacy","awardID":"1223231","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[519555,519556],"PO":["564388"]},"197999":{"abstract":"Integrated electronic systems are pervasive in all aspects of our lives, used in everything from computers to mobile phones to automobiles. However, designing and manufacturing systems that both work and are reliable is becoming extremely difficult due to the significant complexity inherent in the underlying technology. In this NSF EAGER project, we will demonstrate how statistical learning in chip (SLIC) can cope with the non-idealities that arise due to imprecise design and fabrication, and the uncertainty that stems from the system's user and operating environment. Specifically, SLIC will enable an integrated system to \"learn\" optimal operating points across various applications so as to maximize performance, and to minimize power consumption. This will be accomplished by developing customized statistical learning algorithms for in-chip implementation that are capable of deriving actionable information from system data produced both on- and off-line. <br\/><br\/>The principal investigator (PI) is committed to having a broader impact through training a diverse group of undergraduate and graduate researchers. His research group has members from under-represented groups that include women, African Americans, Hispanic Americans, and Native Americans. In addition, as director of the Center for the Silicon System Implementation (CSSI) at Carnegie Mellon University, the PI manages a program that recruits undergrads researchers from various universities (including minority-serving institutions), and the annual convention of the National Society of Black Engineers. This program has been very successful, resulting in the recruitment of many undergraduate researchers, including both women and African-Americans. In the last few years, the PI has supervised nine undergraduate researchers, three of which were African-American (two male and one female), and will continue to recruit a diverse group of students, both at the graduate and undergraduate levels, for participation in this project.","title":"EAGER: Statistical Learning in Chip","awardID":"1247093","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["531467","548338"],"PO":["562984"]},"194028":{"abstract":"The ongoing effort to move data intensive computation to low-cost public clouds has been impeded by privacy concerns, as today's cloud providers offer little assurance for the protection of sensitive user data. This problem cannot be addressed by existing cryptographic techniques alone, which are often too heavyweight to manage the computation involving a large amount of data. As a result, many computing tasks have to be run on individual organizations? internal systems whenever they touch even a very small amount of sensitive information.<br\/><br\/>The research in this project seeks practical solutions to this critical security challenge. The PIs are working on an approach to split a computing job over a hybrid-cloud platform, delegating to a public cloud the computation over public data, while keeping the computation on sensitive data within a private cloud. <br\/><br\/>Specifically, the PIs are developing a privacy-aware MapReduce system, which transparently partitions a computing job and schedules its components across the public\/private clouds according to the security levels of the data involved. The system is designed to achieve high security assurance and outsource most of its workload when possible, at small computational and communication overheads. It includes support for analyzing and transforming the code for legacy jobs as well as developing new jobs. We are also working to extend these techniques to facilitate other secure work-flow processing over hybrid clouds. This research involves industry collaborators and contributes to secure processing of a wide range of computing jobs, from commercial data analysis, to DNA analysis, to intrusion detection.","title":"TWC: Small: Secure Data-Intensive Computing on Hybrid Clouds","awardID":"1223495","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["538992","526376"],"PO":["564223"]},"188825":{"abstract":"This project by Professor Fayer of Stanford University is supported by the Chemical Structure, Dynamics and Mechanisms Program in the Division of Chemistry, and the Solid State and Materials Chemistry and Condensed Matter Physics Programs in the Division of Materials Research. The research involves an interrelated set of experimental and theoretical investigations of dynamics in complex liquids using optical nonlinear experimental methods and theory. The term complex liquid is used to describe systems that have significant nanoscopic structures that arise from anisotropic intermolecular interactions and give rise to complex structural dynamics. Such liquids include liquid crystals in both the isotropic phase and in macroscopically ordered phases and room temperature ionic liquids (RTILs). Very simple liquids like argon or carbon tetrachloride have no significant liquid structure other than that described in terms of featureless solvation shells. However, highly anisotropic molecules with strong interactions arising from large dipole moments or charges can have extended structures that span many nanometers. The range of the liquid structure can depend on temperature or solutes. Solutes can induce or disrupt structure. Long range ordering occurs in liquids in molecular systems that range from technological applications to biology. <br\/><br\/>A variety of experimental methods will be employed to study the interrelations ships among intermolecular interactions, structure, and dynamics. Optical heterodyne detected optical Kerr effect (OHD-OKE) experiments that cover a time scale from hundreds of femtoseconds to microseconds using a new phase cycling methodology will be employed. The OHD-OKE experiments, which measure the orientational dynamics (polarizability-polarizability correlation function) of liquids, will be combined with ultrafast 2D IR vibrational echo experiments, which measure spectral diffusion (structural dynamics). In addition, polarization selective IR pump-probe experiments will be used that measure orientation relaxation of specific solutes. The 2D IR vibrational echo experiments produce two dimensional spectra which depend on both phase and intensity to provide detailed information akin to 2D NMR. The vibrations of a set of novel probe molecules will be used in the 2D IR studies that provide distinct perspectives on the systems, structures, and dynamics. The aim is to understand the interrelationship between structure and dynamics in these nanostructured systems by making measurements with different techniques as a function of the structure of the molecular units that comprise the systems, temperature, solute type, and concentration. The experiments will be combined with theoretical calculations and simulations, a number of which will be conducted in collaboration with theoretical research groups. <br\/><br\/>The proposed experiments will have a broad impact on our understanding of molecular systems that are important in many fields of science. The development of new experimental methods will be shared widely and will be useful to many in the broad research community. The systems under study are both of fundamental interest and technological importance. Liquid crystals are found in many products. RTILs are being used or considered for a wide variety of applications. This work will broaden the scientific community's understanding of important chemical and materials systems, particularly how nanostructuring influences system properties. In addition to the scientific impact, the Professor Fayer is the faculty head of an outreach program that sends graduate students into local high schools to work with the high school students conducting sets of experiments that are tied into the high school chemistry curriculum. Finally, Professor Fayer is involved in the wide dissemination of teaching materials at both the graduate and under graduate levels and has written a book, \"Absolutely Small: How Quantum Theory Explains Our Everyday World\" to explain molecular quantum theory and it applications to laymen, high school students, college students, and scientists who are not specialists in quantum theory.","title":"Dynamics and Structure in Complex Molecular Systems","awardID":"1157772","effectiveDate":"2012-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0307","name":"Division of MATERIALS RESEARCH","abbr":"DMR"},"pgm":{"id":"1762","name":"SOLID STATE & MATERIALS CHEMIS"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"6879","name":"STRUCTURE,DYNAMICS &MECHANISMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1710","name":"CONDENSED MATTER PHYSICS"}}],"PIcoPI":[506320],"PO":["564414"]},"198747":{"abstract":"Today, when a student or industrial programmer faces difficulty in some task assigned to him\/her, this event often goes unrecorded and unobserved by others. As a result, it is not possible to use mechanisms to ameliorate the effect of the difficulty. In this project, the researchers will address this problem by automatically detecting and classifying programming difficulties by mining programmers' interaction with the computer. Specifically, they will investigate (a) whether it is possible to automatically identify the barrier causing a difficulty and (b) whether it is possible to determine the severity of the difficulty. The project will start a new area of research exploring how difficulty-detection mechanisms should be designed, implemented, evaluated, and applied.<br\/><br\/>Broader impacts: If successful this research will lead to future work on a variety of difficulty amelioration mechanisms, including (a) allowing industrial workers and teachers to synchronously push help to developers facing difficulties; (b) informing developers facing difficulties about actions taken by others who overcame similar difficulties, so that they can take similar actions; (c) allowing assignment doers to anticipate the kind of difficulties they will encounter and thus be better prepared for the assignment; and (d) giving assignment definers an understanding of the inherent difficulty level of the assignment, which can lead to redefinition or better explanation of the assignment. These amelioration mechanisms can substantially reduce the high costs associated with software development and quality teaching, and transform collaborative software engineering and education. Such mechanisms can lead to significant productivity gains in industry, especially in distributed software development. An educational setting provides an even more compelling motivation because shyness of students and\/or lack of instructor time prevents student difficulties from being addressed in a timely manner. In computer science this is particularly a problem as a small mistake can prove to be very costly. The difficulty amelioration mechanisms will reduce this problem and thus attract a larger variety of students to computer science and empower those who are already committed to it.","title":"EAGER: Automatic Classification of Programming Difficulties by Mining Programming Events","awardID":"1250702","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":[533215],"PO":["564456"]},"197537":{"abstract":"This project will result in a novel system called SOCRATES that will help transform social media research for scholars working in diverse fields by building a community of researchers and practitioners around various issues of data-intensive research. Social media services such as Twitter and Facebook, used by millions of people worldwide, expose vast amounts of data about people's beliefs, ideas, opinions, behaviors, and activities. At the same time, the sheer scale and volume of the data make them extremely difficult for scholars to study effectively. SOCRATES will address this issue by incorporating a set of socio-computational tools that will allow researchers from multiple fields to collect large-scale social media data; explore and visualize the resulting content items, and analyze the collected content. A community- and human-centered approach to developing the new system will ensure that SOCRATES matches researchers' work practices and mental models, is easy to use, and produces outcomes that significantly contribute to the researchers' goals, especially in solving multi-disciplinary problems. Importantly, the SOCRATES system will employ a social-computational approach--crowdsourcing--to handle some of the challenges of social media research. Thus, the project will take advantage of the intelligence of both computers and people to study online social activities. SOCRATES proposes to use the labor of humans to assist in the collection of data (e.g., by refining and filtering information collected by an automatic crawler); to help explore the data and generate insights (e.g., by allowing the public to view and comment on visualizations of the collected data); and to analyze and annotate the data (e.g., by creating a controlled environment where coders can annotate content items with high reliability). As a result, SOCRATES will provide a first-of-its-kind, end-to-end environment where social media can be studied effectively, with high validity, and at immense scale.","title":"Collaborative Research: BCC-SBE: Building Communities for Transforming Social Media Research with SOCRATES: SOcial and CRowdsourced AcTivities Extraction System","awardID":"1244742","effectiveDate":"2012-09-15","expirationDate":"2015-02-28","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"8068","name":"Data Infrastructure"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}}],"PIcoPI":[529981,529982],"PO":["564343"]},"198418":{"abstract":"This research project will develop a theoretical and computational framework to understand and enable the socio-technical dynamics shaping the assembly of teams in distributed global contexts. The main barrier to understanding and explaining the role of human centered computing in team assembly is finding a suitable research environment where (1) geographically distributed individuals from potentially different cultures are assembling in teams of varying sizes to accomplish a variety of tasks over varying durations; (2) their actions, interactions and transactions are captured with precise time-stamps; and (3) their outcomes would be recorded with well-defined metrics. Massively multiplayer online role-playing games offer a research environment that meets all of these requirements. EVE Online, a massively multiplayer online role-playing game, offers a potentially suitable research opportunity to study the assembly of teams and ecosystems of teams. It is notable for allowing as many as tens of thousands of people to interact simultaneously on a single server cluster, from around the world, through a well-developed economic system and serious long-term coalitions, in a more flexible action framework than many other popular games possess.<br\/><br\/>This high-risk high-payoff project will explore the feasibility of using data from EVE Online to identify the socio-technical and cultural mechanisms that explain the assembly of teams more generally. If successful, the study will serve as a model for larger scale studies that, in addition to identifying the assembly mechanisms also assess the impact of these mechanisms on the performance of global teams. The most important and complex decisions in society are made in teams. And yet, assembling effective teams is a daunting task. While there is an awareness of how team collaborations can spearhead socio-economic change, we still have sparse sociotechnical knowledge of how globally distributed cross-cultural teams and systems of teams are assembled. This project seeks to address this limitation. First, the proposed research offers the promise to launch a new generation of theorizing and research on the assembly mechanisms of teams and ecosystem of teams. The empirical data that will be used to develop and test these theories will be a high risk effort but with potential for unprecedented scale, size, and completeness. Second, the research will arguably be the first effort in the field of social networks to develop hypergraph techniques to study assembly of teams and ecosystems of teams.<br\/><br\/>The knowledge and tools developed in this research will allow practitioners to cultivate more effectively the emergence and performance of ad hoc teams in business, science and gaming. It will also provide other scientific disciplines with new computational statistical modeling methodologies and tools to model hypergraphs.","title":"EAGER: Collaborative Research: Some Assembly Required: Understanding the Emergence of Teams and Ecosystems of Teams","awardID":"1249137","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[532398],"PO":["564456"]},"191642":{"abstract":"This project consists of two components, each motivated by the inference problem for functional magnetic resonance imaging (fMRI) data. In the first part, within the framework of generalized functional linear model (GFLM), a flexible semi-parametric model for neural hemodynamic response in the form of slope functions is introduced. To accommodate the variation of brain activity across different regions, stimulus types, and subjects, the new approach assumes the slope functions share the same but unknown functional shape for a given region and stimulus, while having subject-specific height, time to peak, and width. Several fast algorithms based on B-spline smoothing are proposed to estimate the model parameters for whole-brain analysis. The second part of the research focuses on building a novel Bayesian variable selection framework to study the relationship between individual traits and brain activity. The spline estimates of the brain hemodynamic responses from the first part are taken as predictors in a regression model where the response is the individual traits. Two types of priors are introduced jointly to achieve simultaneous variable selection and clustering.<br\/><br\/>FMRI is one of the most effective neuroimaging technologies for understanding brain activity. In recent years, fMRI data collected from complex studies with multiple subjects have been widely used in psychological and medical research. This project will provide tools for modeling, analysis and computation for this type of fMRI data. Project findings will advance basic understanding of the inter-relations between nature and nurture in shaping individual differences in brain function and behavior, and suggest new directions for interdisciplinary research that combines statistics, neuroscience and psychology. The open source R\/Matlab software developed from the research will provide valuable data analysis and educational tools for the scientific community.","title":"Collaborative Research: Statistical Modeling and Inference for High-dimensional Multi-Subject Neuroimaging Data","awardID":"1209118","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1269","name":"STATISTICS"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"7275","name":"CROSS-EF ACTIVITIES"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"1165","name":"ADVANCES IN BIO INFORMATICS"}}],"PIcoPI":["538098",513667],"PO":["565309"]},"192984":{"abstract":"Finding parking has been a major hassle for drivers in many urban environments for decades. For example, studies conducted in 11 major cities revealed that the average time to search for curbside parking was 8.1 minutes and cruising for these parking spaces accounted for 30% of the traffic congestion in those cities, on average. Each parking slot generated 4,927 vehicle miles traveled (VMT) per year, and the overall increase in traffic is obtained by multiplying this number by the number of parking slots in the city (e.g., 35,000 in Chicago). Motivated by these factors and enabled by the current revolution in wireless communication, sensor networks, and mobile computing, an interdisciplinary team will investigate a number of core algorithmic, game-theoretic, and computational complexity issues to address parking slot selection problems. Thus, this project seeks to contribute to development of more efficient urban transportation systems.<br\/><br\/>The technical merits of the proposal include the investigation and analysis of real-time distributed competition for spatial resources. The competitive nature of the problem leads to a dynamic multi-player game-theoretic framework to analyze the quality of a solution. The investigators will formulate computational problems, study their mathematical properties, design efficient algorithms for them, and implement resulting algorithms to assess accuracy and efficiency. In particular, partly inspired by Newton's laws of gravitation, the investigators will research a broad class of parking navigation strategies loosely termed as the Gravitational Parking Paradigms.<br\/><br\/>The final goal of this project is to develop the theoretical underpinnings of applications that, given the locations of parking slots, will guide a driver to a most appropriate parking slot. Other components of the project include the integration of research and education via several means such as course and curriculum development, effective dissemination of research, mentoring undergraduate and graduate students, and promoting diversity in related research and educational activities.","title":"ICES: Small: Collaborative Research: Dynamic Parking Assignment Games","awardID":"1216096","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":[516989,"557651",516991],"PO":["565251"]},"193600":{"abstract":"Quasi-static ad hoc wireless networks are models for city-wide mesh networks, machine-to-machine networks deployed for control, and certain sensor networks, which are of growing importance in applications such as smart electricity grids, transportation grid control and infrastructure monitoring. The goal of this project is to design distributed online network protocols that learn the characteristics of such networks and self-optimize to achieve more predictable performance, such as delay guarantees. This is especially important for networks such as smart grid, where end-to-end delay must be predictable. A factor graph is used to model the probability distribution over the allowed network control actions. A novel information theoretic formulation is being investigated, which measures the information sharing required to coordinate network actions, between devices and across the network stack within each device. The solution to this problem will then be obtained by using statistical sampling techniques from machine learning, providing the online algorithm for network control. This algorithm will be distributed, because it is obtained by minimizing the information sharing required. Thus, the project will provide a formal mathematical basis for the probabilistic design of distributed protocols for quasi-static ad hoc networks, utilizing the information theoretic concepts of information, entropy, and side-information to quantify the value of distributed actions. <br\/><br\/>Results from this project will be published and presented in major professional conferences and journals, and will be available to the wider public. The project will support the training of doctoral students in the important field of wireless networks. The theoretical framework obtained will be discussed in courses on statistical engineering methods and information theory. The MAC protocol concepts will be used to augment the PI?s under-graduate experimental set-up based on software radios, so that students of communication theory can obtain hands-on experience with system design.","title":"NETS: Small: Machine Learning Based Algorithms for Quasi-Static Ad Hoc Wireless Networks","awardID":"1218823","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[518488],"PO":["557315"]},"193611":{"abstract":"Multi-pattern matching is the problem of finding whether and where a set of patterns appear in a data stream. An example of such a problem is scanning Internet traffic for malware signature patterns. Important considerations in multi-pattern matching are the amount of memory required to store the patterns and the speed with which the stream can be scanned through. Storage space can be reduced either by compressing the patterns or by approximately 'sketching' them. This project aims to advance this field by seeking ways to enable multi-pattern search with (1) minimum possible space, (2) fastest possible time, and (3) high accuracy. The project combines theoretical advances with practical implementations. Theoretical approaches involve sketching, streaming, hashing and succinct data structures. Practical goals include developing faster hardware-based implementations and cache-aware implementations. <br\/><br\/>Multi-pattern matching is central to applications such as computer virus detection, network intrusion detection and information extraction. It resides at the cross-section of several fields of computer science, including theory, networking, databases and bioinformatics. Recent development of tools in pattern matching such as succinct data structures and streaming algorithms make this an exciting time to advance the state-of-the-art in this field. Several research opportunities for undergraduate students will evolve from this project. Results will be disseminated through publications in conferences and journals.","title":"AF: III: Small: Space-efficient Frameworks for Multi-pattern Matching in Text Streams","awardID":"1218904","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[518519],"PO":["565251"]},"193501":{"abstract":"As the cost of computing and communication resources has plummeted, applications have become data-centric with data products growing explosively in both number and size. Although accessing such data using the compute power necessary for its analysis and processing is cheap and readily available via cloud computing (intuitive, utility-style access to vast resource pools), doing so currently requires significant expertise, experience, and time (for customization, configuration, deployment, etc). This work investigates new models of cloud computing that combine domain-targeted languages with scalable data processing, sharing, and management abstractions within a distributed service platform that \"scales\" programmer productivity. To enable this, this research explores new programming language, runtime, and distributed systems techniques and technologies that integrate the R programming language environment with open source cloud platform-as-a-service (PaaS) in ways that simplify processing massive datasets, sharing datasets across applications and users, and tracking and enforcing data provenance. The PIs' plans for research, outreach, integrated curricula, and open source release of research artifacts have the potential for making cloud computing more accessible to a much wider range of users: The data analytics community who use the R statistical analysis environment to apply their techniques and algorithms to important problems in areas such as biology, chemistry, physics, political science and finance, by enabling them to use cloud resources transparently for their analyses, and to share their scientific data\/results in a way that enables others to reproduce and verify them.","title":"CSR: CC: Small: Collaborative Research: Language and Runtime Support for Large-Scale Data Analytics","awardID":"1218348","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["549800"],"PO":["565255"]},"194722":{"abstract":"The security of our software is critical for consumer confidence, the protection of privacy and valuable intellectual property, and of course national security. Because of our society's increased reliance on software, security breaches can lead to serious personal or corporate losses, and endanger the privacy, liberties, and even the lives of individuals. As threats to software security have become more sophisticated, so too have the techniques and analyses developed to improve it. Symbolic execution has emerged as a fundamental tool for security applications. Its main idea is to run a program using symbolic instead of concrete values: a set of symbols are assigned to the program inputs, and the outputs are expressed as a set of \"verification conditions\", logical formulas over the input symbols. A number of successful security analyses use symbolic execution and similar methods to recast security questions about programs as constraint satisfaction problems in some formal logic. Automatic reasoners for that logic can then be used to solve those problems. In the last few years, solvers based on Satisfiability Modulo Theories (SMT) techniques have become a natural choice in such approaches to security because of their superior performance and automation compared to more traditional theorem provers and their greater generality with respect to ad-hoc tools or propositional satisfiability solvers.<br\/><br\/>This collaborative project brings together experts in security and in SMT to pursue two complementary research goals: (i) harness the full power of SMT solvers to improve current security tools based on symbolic analysis; and (ii) design and develop new techniques to address the needs of anticipated future security applications. Specific activities addressing these goals include: collecting challenge benchmark problems from existing security analyses and developing targeted SMT optimizations for these benchmarks; developing appropriate security abstractions in the SMT language used to express security verification conditions; developing logical theories and algorithms for reasoning about character strings in such verification conditions; exposing a general framework for extending the verification condition language; and developing techniques for computing symbolic solution sets for SMT constraints. These activities are expected to (i) significantly increase the flexibility, performance, and reasoning capabilities of SMT solvers in support of security applications; (ii) improve the performance and scalability of current security analyses by leveraging the reasoning power of SMT solvers; and (iii) provide a foundation for new, more powerful, and more expressive security analyses. Overall, this project will help create more scalable and expressive security applications which could have a considerable impact on society as they enable the production of software much more resistant to security attacks.","title":"TWC: Medium: Collaborative: Breaking the Satisfiability Modulo Theories (SMT) Bottleneck in Symbolic Security Analysis","awardID":"1228768","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["550906"],"PO":["565264"]},"194843":{"abstract":"Proposal #:12- 29236 Collaborative Proposal #: 12-29250<br\/>PI(s): Valavanis, Kimon P.; Gao,David Wenzhong; Mahoor,Mohammad;Rutherford,Matthew J;Yi,Yun-Bo<br\/> and Collab PI(s): Boussalis, Helen R.; Guillaume, Darrell; Wu, Chivey <br\/>Institution:University of Denver & and Collab Institution: California State-LA University<br\/>Title: MRI: Collaborative: Dev. of an Integrated, Intelligent, Autonomous, Unmanned, Mobile Sensor<br\/><br\/>Project Proposed:<br\/>This project focuses on the development of an integrated, intelligent, autonomous unmanned mobile sensor will enable research into the foundations of the next generation of autonomous Unmanned Aerial Systems (UAS). The objective of this proposal is to develop an unmanned helicopter (about 150 kg weight) along with a mobile landing platform for refueling purposes. The aircraft would be able to operate with both electric and fuel. The instrument will be composed of two tightly coupled components, a<br\/>(i) Novel light-weight unmanned helicopter (<150 Kg), and,<br\/>(ii) General purpose landing platform that will also serve as a refueling\/recharging station and data relay\/repository. <br\/>This composition of the instrument is expected to pave the way for the next generation of multi-purpose\/cost-effective UAS into civilian and public domain applications. The proposed integrated two component instrument development is not considered as an extension of existing technology. It will enable heterogeneous networked unmanned systems operating in unison in traditional\/extreme environment. The following specific research projects will be enabled through the instrument: <br\/>- Fault-Tolerant and Emergency Landing Navigation and Control Systems<br\/>- RADAR-based Sense-and-Avoid System<br\/>- Prognosis and Structural Health Monitoring of UAVs<br\/>- Networked Unmanned Systems (NUS)<br\/>- Integration: Software Reliability and Security<br\/>- Unmanned Helicopters for Civilian\/Public and Industrial Applications<br\/>The University of Denver (DU) and California State University Los Angeles (CalStU-LA), a predominantly minority-serving institution, collaborate in the project. <br\/><br\/>Broader Impacts: <br\/>The impact should be felt both regionally and nationally. At the national level, the instrument should initiate transformative advances in the computational algorithms proposed. The results will be made available to the broader research community in the form of open-source codes. Simulations made possible by these algorithms will have broad national and societal impact ranging from climate change scenarios to wind power generation to plant biotechnology and improved animal breeding.<br\/>At the institutional and regional levels, DU faculty\/students will collaborate with CalStU-LA faculty\/students to enhance the ethnic and gender diversity of the student population, especially recruiting minority students. Project goal include increasing the educational\/training opportunities for underrepresented students, and the number of graduates in STEM fields.","title":"MRI Collaborative: Development of an Intelligent, Autonomous, Unmanned, Mobile Sensor","awardID":"1229236","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[522051,522052,"523825","522995",522055],"PO":["557609"]},"193633":{"abstract":"The PI's research explores fundamental relationships between physical systems and the efficiency of algorithms, looking at applications in Economics, Nanotechnology, Computing and Physics that can benefit from this joint lens. For instance, the Schelling model of segregation was developed in the economics community in 1971. In this model, residents within a community assess their personal comfort with the racial distribution in their local neighborhood and they are more inclined to move if they are dissatisfied. Schelling showed that even if every member of the community is satisfied with having half of their neighbors be of the opposite race, even small preference for one's own race leads to global segregation. Thus, micromotives can bring about macrobehavior without any centralized influence. The PI will explore variants of this model for 2-dimensional models using insights from computing and physics.<br\/><br\/>The PI will also consider natural stochastic processes occurring in the context of self-organizing lists and nanotechnology. The first is a fundamental question about biased permutations arising from list update algorithms for minimizing total search costs. The problem can be modeled as a question about permutations under nearest-neighbor transpositions in which items are biased to be put in the correct order. The second is a nanotechnology problem concerning growth processes arising in the context of tile-based self-assembly, where tiles are constructed from DNA. The rates of convergence of these two sampling algorithms are closely related, and the PI has developed new approaches to try to better understand their convergence properties.<br\/><br\/>Last, the award addresses fundamental questions at the interface of computing and physics. Determining the mixing time of Markov chains is often the vital step in proving the efficiency of many approximation algorithms based on random sampling. One of the richest sources for sampling problems is statistical physics, where the state space of the Markov chain represents the states of a physical system and sampling lends insight into the thermodynamic properties of the model. By exploring parallels between phase transitions in both fields, the PI will address fundamental questions about physical systems while searching for better approaches to sampling.","title":"AF: Markov Chain Algorithms for Problems from Computer Science, Statistical Physics and Economics","awardID":"1219020","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[518569],"PO":["565157"]},"193523":{"abstract":"Current magnetic recording technology is fast approaching its theoretical limit of 1 terabit per square inch (1 Tb\/in^2), and unless new technology is developed that can deliver areal densities of up to 10Tb\/in^2, the annual increases in hard-disk drive capacity will taper rapidly. Several candidate technologies are currently being developed that will extend the areal densities up to 4Tb\/in^2, but only two that can possibly extend it all the way to 10Tb\/in^2, namely energy assisted recording on bit-patterned media and two-dimensional magnetic recording. Bit-patterned media requires extreme nano-lithography and imprinting techniques, which are prohibitively expensive, and very tight specifications on the planarization of the disk surface. Two-dimensional magnetic recording, on the other hand, uses conventional heads and media, but requires the development of new two-dimensional signal processing and coding techniques suitable for the magnetic recording channel. <br\/><br\/>This research program aims at providing an in-depth understanding of two-dimensional shingled magnetic recording through: 1) development of realistic channel models at the magnetic grain level; 2) development of techniques to analyze the statistical properties of such models; 3) development of two-dimensional intersymbol interference channel detectors with limited per-symbol complexity; 4) development of a novel and transformative approach to the design of capacity-approaching codes based on fundamental algebraic properties of cyclic codes; and 5) determination of the maximum areal recording density that can be achieved in practice. This research program will help answer the fundamental question of whether it is possible to approach the ultimate theoretical limit of one user bit per magnetic grain using shingled writing.<br\/><br\/>The broader goal of this research program is to help determine the feasibility of hard-disk drives with areal densities of up to 10Tb\/in^2 using shingled writing. Its successful completion would establish two-dimensional magnetic recording as the technology of choice for the next generation of magnetic storage devices and potentially shape future research in this field. The significance of achieving such a high recording density is that one could store up to ten times as much data on a drive of the same size as current ones, thus fostering a multi-billion dollar economic impact on the storage industry. In addition, the methods devised for detection and coding for channels with two-dimensional intersymbol interference have a wider application to new two-dimensional transmission and storage systems as they become available, for instance multi-aperture free-space optical communication systems and holographic data storage systems.","title":"CIF: Small: Two-Dimensional Channel Modeling, Detection and Coding for Shingled Magnetic Recording","awardID":"1218452","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["89283"],"PO":["564924"]},"193644":{"abstract":"This project aims to improve tool support for software debugging, by providing automatic assistance in the identification of root causes of a software failure using static and dynamic program analysis techniques. A flexible diagnosis framework first identifies candidate root causes of a failure and then uses a broad, open-ended series of diagnosic \"filters\" to narrow down the most likely root causes. A key innovation is that the system automatically generates \"passing\" and \"failing\" inputs for diagnosis that are close to the original failing input, making it less likely that root causes are missed. The work develops two approaches for this difficult step, based on concolic testing and on string rewriting using the application's input grammar, and investigates various types of program properties (\"likely invariants\") for effective localization of various classes of bugs. Candidates are then winnowed using novel filters based on existing and new program analyses to pinpoint root causes with few false positives.<br\/><br\/>This research will significantly increase programmer productivity by reducing manual debugging effort and improve reliability and security by reducing the time to fix critical software failures. A fully-automated diagnosis tool based on the widely-used LLVM compiler will be publicly distributed for developers to use. It will also be used for teaching debugging techniques and program analysis techniques in university classes.","title":"CSR: Small: Automated Software Fault Localization via Static and Dynamic Analysis","awardID":"1219080","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["542046"],"PO":["564778"]},"193413":{"abstract":"The increasingly common multi-core\/many-core CPU architectures<br\/>are effective for accelerating programs\u00e2?? execution only when<br\/>sufficient parallelism is maintained. For data-intensive<br\/>programs the increased parallelism can severely compromise I\/O<br\/>efficiency: when a sequential program is parallelized, not only<br\/>computations, but also the I\/O operations associated with them, can<br\/>be distributed among multiple processes. Because the execution<br\/>order of the processes is usually determined by the scheduler at<br\/>runtime, the relative progress of processes is nondeterministic<br\/>and the order in which the processes issue their I\/O requests is<br\/>accordingly nondeterministic. It is this I\/O nondeterminism that<br\/>can substantially compromise I\/O efficiency, and thus program<br\/>performance, by negating the advantages of parallel execution.<br\/><br\/>To address this problem the PI proposes a facility built either<br\/>in the operating system kernel or in the runtime to streamline<br\/>the service of I\/O requests from different processes of a<br\/>parallel program. The major distinction from conventional<br\/>techniques for improving I\/O performance is in the coordination<br\/>of I\/O request issuance, via I\/O-aware process scheduling, to<br\/>improve the locality of these requests for I\/O-intensive<br\/>multithreaded and MPI programs.<br\/><br\/>If successful, the proposed research would introduce a disruptive<br\/>technique for data-centric computing to effectively relieve the<br\/>I\/O bottleneck. This project also provides abundant research<br\/>training opportunities for students, especially under-represented<br\/>minority students in the southeast Michigan area, to help relieve<br\/>the shortage of IT professionals with expertise in parallel<br\/>computing and storage systems.","title":"CSR: Small: Adaptively Applying Data-Driven Execution Mode to Remove I\/O Bottleneck for Data-Intensive Computing","awardID":"1217948","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[518050],"PO":["565255"]},"193534":{"abstract":"Solid-state storage technologies, such as flash, phase-change memory<br\/>and memristors promise large-capacity storage at speeds much faster<br\/>than disk. To date, mainstream use of these technologies has been as a<br\/>replacement for disks, storing a disk-oriented file system. However,<br\/>solid-state storage is and will remain far more expensive than<br\/>disks. Thus, it will often be used as a cache or special-purpose<br\/>store, and not as the main repository of data.<br\/><br\/>This proposal develops new interfaces to solid-state storage that<br\/>leverage its new features, such as access via ordinary memory<br\/>instructions, and its role in large software systems as a middle layer<br\/>between memory and disk. It focuses on two forms of solid-state<br\/>storage: flash memory, common in solid-state drives and mobile<br\/>devices, and forthcoming storage-class memory, which compared to flash<br\/>promises lower latency, better endurance, and access as memory rather<br\/>than as a device.<br\/><br\/>This research addresses important concerns about using solid-state<br\/>storage: how best to use the capabilities of these devices to improve<br\/>specific applications or use cases, such as caching; how to provide<br\/>access to internal management capabilities of solid-state storage<br\/>devices, such as address translation and garbage collection, to<br\/>applications; how to remove software layers between an application and<br\/>storage to reduce latency; and how to provide reliable storage while<br\/>removing many of the layers that currently provide reliability.","title":"CSR: Small: Advancing Operating System Interfaces to Solid-State Storage","awardID":"1218485","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["559530"],"PO":["565255"]},"193303":{"abstract":"This award explores connections between the computational complexity of approximate counting problems and phase transitions in Statistical Physics models. Recent work implies that the computational complexity of approximately counting weighted independent sets in general graphs undergoes a phase transition that coincides with a classical Statistical Physics phase transition on trees. PI will explore whether such connections hold in other settings, for example, the well-studied Ising model.<br\/><br\/>Another main theme in this research are improved techniques for Markov Chain Monte Carlo (MCMC) methods, which are often used in algorithms for randomly sampling from and approximately counting the size of large sets of combinatorial objects. This research has applications in a variety of fields which rely on MCMC algorithms, including Statistical Physics and Bayesian inference of phylogeny in Evolutionary Biology.","title":"AF: Small: Phase Transitions in Approximate Counting Problems","awardID":"1217458","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[517800],"PO":["565157"]},"193666":{"abstract":"Traditionally, feedback has been mainly used in communication systems for retransmission and for channel prediction. Several recent results in network information theory have identified a new role for feedback: exploiting side information to mitigate interference. Due to the broadcast nature of communication media, information intended for one user is often received by other users. Feedback can be used to exploit this side information to improve the efficiency of future transmissions. The proposed work builds upon these results to come up with a theory unifying the existing isolated results as well as broadening to more scenarios of interest. It will also identify specific problems to solve for realizing this new role of feedback in practice. The goal is to close the gap between feedback research in information theory and the design of feedback mechanisms in practice.","title":"CIF: Small: Exploiting Side Information: a New Role of Feedback","awardID":"1219188","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["523728"],"PO":["564924"]},"191488":{"abstract":"This project investigates how education and training methods from traditional work settings can be applied to paid online crowdsourcing. The focus is on how methods such as scaffolding, examples, critique, and apprenticeship affect worker performance, learning, task perseverance, and satisfaction. The project will produce guidelines for a more sustainable crowdsourcing infrastructure where employers can embed relevant domain knowledge into online tasks, and workers can learn key principles and then train less experienced members. The research focuses on worker-centered training strategies in the domain of visual design, which will yield knowledge about effective design principles and instructional methods for visual design. <br\/><br\/>Broader impacts: The project will contribute to increase the availability of online work. It will expand the capabilities and skills of crowd workers, thereby allowing online work to become a more viable part of the American economy. The project will also lead to novel methods for organizations to achieve complex visual design work. More generally, the project will lead to new knowledge about how to train crowds to perform a complex activity and produce practical guidelines to help requesters write tasks and manage the crowd. Finally, the project will provide interdisciplinary training for graduate and undergraduate students in socio-computational system design, HCI concepts, educational theory, and evaluation methodologies. All course materials will be available online for reuse and adaptation. Undergraduate researcher training will focus on supporting underrepresented student groups.","title":"SoCS: Collaborative Research: Strategies for Crowdsourcing Complex Design Work","awardID":"1208382","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["517579"],"PO":["565342"]},"196823":{"abstract":"The University of Delaware proposes Partner4CS, a project to design and evaluate a comprehensive set of professional development opportunities for middle and high school computer science teachers. Delaware, like many other states, does not have teacher certification in computer science, CSTA chapters, or a defined educational path that would prepare computer science teachers. Partner4CS aims to circumvent these problems. The project brings an interdisciplinary team -- including university faculty and undergraduates from the computer science, math education, and educational research disciplines -- that has strong engineering outreach and evaluation credentials. The team will develop (1) a 3-track summer professional development institute bringing together G6-12 teachers and high school students for skills development, teaching pedagogy, and community building; (2) an online learning environment that provides teachers with instant access to pedagogical and curricular support and means to communicate regularly with other teachers and university faculty; (3) a new college service learning 1-credit course weekly alternating undergraduate service to teachers in the classroom with college classroom sessions for planning and reflection; and (4) quarterly Saturday morning teacher workshops for G6-12 teachers and students to continue the summer professional development throughout the academic year. Carefully mentored undergraduates will assist in these programs, in turn gaining from interdisciplinary collaboration, teaching and lesson planning, and the opportunity to experience first-hand the potential impact of their computing expertise in helping others. Their service may also contribute to an improvement in the participation of underrepresented students in computing at the both the college and at the high school levels. Partner4CS will build on the CS PIs' experience in partnering computer science undergraduates in service learning with middle school teachers and on the Education PIs' established partnerships with regional schools for education student teaching experiences. It will leverage both the university's math education major requirement of taking computer science, and the timing of the University of Delaware replacing its current CS0 course by CS Principles in Fall 2012.","title":"CS 10K: Developing and Supporting Computer Science Teachers Via Strategic Partnering","awardID":"1240905","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}}],"PIcoPI":[527984,527985,527986,527987,527988],"PO":["561855"]},"192104":{"abstract":"This project will design new models of social participation and volunteerism through mobile device platforms, with a focus on citizen science. Micro-volunteerism is a newly emerging design territory for volunteering on the order of seconds or minutes. This research will develop a flexible new framework for citizen science based mobile tools to study this novel and largely unexplored social model of citizen participation and volunteerism. Through a series of research studies and design interventions, it will explore challenges and opportunities for leveraging this crowd sourced just-in-time volunteering social participation framework. <br\/><br\/>These efforts contribute toward a series of open research themes in the field of citizen science such as: a subscription based model for campaigns, flexible sensor and data collection techniques that adapt to context, diverse sensing strategies, models for participatory sensing and participatory analysis, and citizen data debate mechanisms. Also studied will be the effect of novel contribution models, badges and rewards, narrative and storytelling, and other methods for improving participation, contribution, motivation, and usage. The research is designed to allow citizens to easily develop and deploy citizen science based mobile collaborative campaigns, often leveraging low-cost sensing and ubiquitous technologies to facilitate real, positive environmental change. <br\/><br\/>The everyday world can become a living laboratory where citizens play a new and active role in facilitating scientific research aimed at exposing the dynamic interactions between people and the natural ecosystems and improving overall human health and well being. This research departs from typical sampling and collection techniques, and hypothesizes that while traditional scientific methods and models play a vital role in understanding the complex dynamics of our world, everyday non-expert citizens with sensor equipped mobile phones have the potential to expand the model of how scientific research is conducted. This approach also stands counter to traditional \"smart computing\" strategies, and instead develops a vocabulary of technologies and experiences to promote human curiosity that serves to scaffold individuals and communities towards a new understanding of our world. Citizen science is also positioned to synergize a new cooperative and collaborative approach to problem solving across a variety of expert practitioners such as computer scientists, engineers, social scientists, atmospheric chemists, environmental health organizations, urban planners, local and national governments. Successful citizen science projects can achieve positive societal change and produce a more participatory and transparent democracy with improved public understanding of our environment and urban ecology.","title":"SoCS: Towards Micro-Volunteerism: From Citizen Sensor to Citizen Participant","awardID":"1211047","effectiveDate":"2012-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":[514849],"PO":["564456"]},"193677":{"abstract":"Contrary to some depictions in popular media, humans are still far better than any computer program at understanding the visual world around them. If we understood how the visual system does this, perhaps better artificial vision systems could be built. The goal of this project is to understand how the brain represents the visual world and why. Following a mantra famously credited to Richard Feynman -- What I cannot create, I do not understand -- this project's approach is to create a computer system that learns from natural input (images, videos), assuming that the visual system operates with the goal of efficiently representing the world. These representations will then be compared to measurements of visual neurons. The long term goal is to understand the functional roles of the early visual processing layers in the human visual pathway.<br\/><br\/>The model is based on the efficient coding hypothesis, in which the early visual pathway serves to capture the statistical structure of its visual inputs by efficiently coding visual information in its outputs. Most computational models following this hypothesis have focused on modeling only one or two visual layers. In this project, Cottrell's group proposes a hierarchical information processing model, which concurs with the efficient coding hypothesis, yet provides the most complete description so far of the early visual processing layers. In this model, the visual inputs are first compressed to reduce noise using Sparse Principal Components Analysis (SPCA), then the data dimensions are expanded to capture the statistical structure of the visual inputs using overcomplete Sparse Coding. A nonlinear activation function then formats the outputs of this layer for the next layer up, and the whole process is repeated. Preliminary work shows that the resulting hierarchical model can learn visual features exhibiting the receptive field properties of neurons in the early visual pathway, including retinal ganglion cells, LGN, V1 simple and complex cells, and V2 cells.","title":"RI: Small: A Hierarchical Approach to Unsupervised Feature Discovery","awardID":"1219252","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["539251"],"PO":["564318"]},"191499":{"abstract":"Robots cannot currently grasp objects or perform other contact tasks in unstructured environments with speed or reliability. This project is developing techniques for accurate real-time perception in support of contact tasks. In the proposed method, sensor data tracks the continuous motions of manipulated objects, while models of the objects are simultaneously updated. Particle filtering, a kind of Monte-Carlo simulation, ensures consistency of this tracking and updating.<br\/><br\/>The strongest impact of this work will be in robotic grasping and manipulation. Because of the synthesis of modeling and probabilistic inference, further impacts can be expected, for example in real-time haptics for telepresence.","title":"NRI-Small: Collaborative Research: A Dynamic Bayesian Approach to Real-Time Estimation and Filtering in Grasp Acquisition and Other Contact Tasks","awardID":"1208463","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":["550584"],"PO":["549626"]},"193204":{"abstract":"This research draws upon techniques from large-scale optimization to develop new decoding algorithms for error-correcting codes. Initial results yield a scalable decoding algorithm for linear programming decoding that runs as fast as state-of-the-art decoders, has a simple schedule, robust convergence guarantees, and achieves better empirical performance than standard decoding algorithms when the signal-to-noise ratio is high. The decoding algorithm will have a transformative effect on the types of codes used in high-reliability applications including storage, optical networks, and microprocessor architectures. <br\/><br\/>This project will develop further results, analyzing in detail algorithmic behavior in the \"error floor regime\" where the signal-to-noise ratio is high. It will examine the algorithmic robustness to the specifics of hardware implementation, and investigate other applications in coding such as high-density, non-binary, and rank-metric codes. The PIs will extend the algorithmic methods to applications beyond decoding error-correcting codes, investigating large-scale data processing applications in graphical models and statistical estimation. The research thrusts of the project are well suited for incorporation into the PIs' courses in digital communication, optimization, and information processing for \"big data\" problems more broadly.","title":"CIF: Small: Decoding Error-Correcting Codes using Large-Scale Decomposition Methods","awardID":"1217058","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[517551,"564275"],"PO":["564924"]},"193457":{"abstract":"Occlusion contour (OC) is well known to play important roles in many computer vision tasks. Unlike regular photographs, an OC image removes the effects of illumination, texture, and appearance while preserving important depth edges and silhouette. This project develops a comprehensive framework for acquiring, processing, and utilizing OCs in visual inference tasks. On the sensor front, the research team develops a new Occlusion Contour Camera or OC-Cam. The new OC-Cam extends the multi-flash camera by coupling an array of controllable infrared (IR) LEDs and a visible-IR camera pair. On the algorithm and application fronts, the research team systematically develops OC-assisted visual inference algorithms. For recognition, the acquired OCs are used as a feature filter to improve category-level object recognition. For tracking, the PIs apply OCs to enhance target representation by filtering out the background and texture edges. Furthermore, the research team investigates the previously under-explored problems of OC-assisted image summarization and privacy protection.<br\/><br\/>This project can cast deep impact on broad areas of computer vision, artificial intelligence, criminal justices, and robotics, both in research and education. Due to the importance of OCs in human vision, the results can produce a testbed for the study of visual psychology. Furthermore, the OC-Cam is expected to serve as conceptual inspiration for constructing the next-generation surveillance systems. Finally, the captured OC datasets and relevant tools are made available to other researchers, to provide a platform for validating new OC-based computer vision algorithms.","title":"RI: Small: Collaborative Research: Contour-Assisted Visual Inference: Systems, Algorithms, and Applications","awardID":"1218156","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["562889"],"PO":["564316"]},"193226":{"abstract":"This project will develop a theoretical and practical framework for understanding and supporting processes of interpersonal attention management in virtual organizations of geographically distributed individuals. Research on virtual organizations (VOs) - aggregations of individuals, facilities and resources that span geographic and institutional boundaries - is critical because VOs are an increasingly common work structure. They enable interaction between individuals who might not otherwise work together, the sharing of scarce resources, and allow novel ways of solving problems. Despite these advantages, members of VOs often cannot work together as effectively as those who are collocated. One reason for this is the difficulty of opportunistic, informal interactions in VOs. These interactions are critical to troubleshooting and coordination, as when co-workers ask quick questions or respond to others' requests, exchange information about the task or environment, or make spur-of-the-moment decisions. <br\/><br\/>While many virtual organizations provide basic communication tools such as instant messaging or video conferencing, members often cannot use these effectively because the tools lack support for the subtlety and nuance of managing one's availability and attention to others. As a result, many people only sporadically attend to messages from collaborators, or may abandon technologies altogether. One problem limiting research progress in this area is that prior work has not considered attention management as a form of joint action in which both parties act in response to each other. This research addresses this problem by developing a theoretical and practical framework for understanding the joint and adaptive nature of attention management. Through a combination of field and laboratory efforts, this work addresses three issues: (1) What information do people seek, and what are they willing to share as they jointly convey attention in today's VOs and distributed collaborations? (2) How does the relationship between gathering and display impact people's task performance, social relationships with others, their use of awareness information, and their attitudes toward privacy and sharing? (3) How do we integrate asynchronous and synchronous attention behaviors? <br\/><br\/>This work builds on research in the area of interpersonal awareness and fostering interaction in geographically distributed groups. It makes several contributions: (1) developing and testing a joint action framework for attention management in VOs, (2) examining joint attention management in synchronous and asynchronous activities, and (3) developing novel tools using next-generation technologies to facilitate analysis of attention management, such as eye and gesture tracking. <br\/><br\/>This work will improve our ability to support more natural and effective collaboration in virtual organizations, which have been identified as critical to national competitiveness and can improve interaction with aging, disabled and otherwise isolated individuals. Computer-supported cooperative work and other forms of computer-mediated communication can benefit. Results will be incorporated into classroom learning activities, and work will be carried out by students from multiple behavioral and technical disciplines, thus drawing a broader population of students to the science and engineering disciplines.","title":"HCC: Small: A Joint Action Approach to Understanding and Supporting Interpersonal Attention In Virtual Organizations","awardID":"1217143","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[517608],"PO":["564456"]},"193347":{"abstract":"While numerous studies have focused on the design of novel controllers and devices to enhance the user experience of teleoperated and virtual environments, our general understanding of what makes a haptic interface acceptable to human operators is limited. The addition of haptic feedback to a computer-mediated task, such as training to perform a surgical procedure in a virtual environment or teleoperating a robot to dispose of explosive ordnance, has been hypothesized to improve the speed, accuracy, and precision of task performance. However, the benefits of haptic feedback have been insufficient to motivate inclusion of haptics in many mission-critical systems. Recent publications in the haptics literature have shown confusing results regarding the role of haptic feedback, such as haptic teleoperators that have high user acceptance and realism ratings but do not have any effect on user performance, as well as haptic teleoperators that are disliked by users yet lead to significant improvements in performance. The PI's goal in this project is to identify the salient parameters of haptic systems leading to haptic realism and haptic utility, their trade-offs, and - hopefully - their complementary features that lead to haptic systems that are realistic and useful, and therefore acceptable to human operators in high-risk scenarios. She plans to approach this problem by examining manipulation and exploration with bilateral teleoperators, where haptic feedback consists of vibrotactile and kinesthetic feedback mediated by a tool. System parameters of interest include feedback gain and frequency content, device mechanical properties, and time delay. For each parameter, the PI will examine its effect on realism and utility, specifically: how users subjectively rate realism and their own performance, and objective measures and theoretical predictions of user perception and performance. In addition, she will survey user acceptance and measure affect, and compare these to measures of realism and utility. Based on these results, she will design and test haptic feedback systems that should maximize user acceptance. This framework will allow her to answer relevant questions such as: What is the spectrum of cost-benefit ratios in bilateral teleoperation, considering the role of device performance in defining the limits of haptic realism and utility? How does the level of risk in a task affect user acceptance of haptic interfaces? Can we design \"haptic cartoons\" analogous to medical illustrations, which are not completely realistic but display the most important haptic features in order to maximize task performance? And is there a haptic \"uncanny valley\" in which slightly unrealistic haptic feedback is particularly disturbing to operators?<br\/><br\/>Broader Impacts: Effective haptic feedback systems will improve human health and well being through applications such as surgery and explosive ordnance disposal. This project will provide the field of computer-mediated haptics with a theoretical and experimental framework to describe the effects of system design choices on user acceptance of tool-based haptic teleoperators. The framework will likely apply to other forms of haptic display (such as sensory substitution and spatially distributed tactile feedback) and in other haptic feedback scenarios (e.g., medical training and the transfer of learning in simulation to real-world tasks). Project outcomes will be disseminated through software and data made publicly available on the PI's laboratory website, a conference workshop, and a new course on haptic design. Outreach programs, public lab tours, and mentoring of female and minority graduate students, undergraduates, and high school students will broaden participation of underrepresented groups in engineering.","title":"HCC: Small: Haptic Realism versus Haptic Utility","awardID":"1217635","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["520895"],"PO":["565227"]},"194678":{"abstract":"This project aims at developing efficient methods for protecting the privacy of computations on outsourced data in distributed settings. The project addresses the design of an outsourced storage framework where the access pattern observed by the storage server gives no information about the actual data accessed by the client and cannot be correlated with external events. For example, the server cannot determine whether a certain item was previously accessed by the client or whether a certain algorithm is being executed. This property provides a high level of privacy protection that goes far beyond standard data encryption. The project also deals with advanced methods for verifying the correctness of outsourced computations, focusing on keyword searches and graph algorithms. The educational component of the project includes a curricular development effort for introductory computer security courses.<br\/><br\/>The project has applications to a broad range of web services widely used by business and consumers. Privacy-preserving access for outsourced data is relevant to web-based email and office applications. Also, it is especially important for the management of proprietary business data, medical data, and other sensitive personal data.","title":"TWC: Medium: Collaborative: Privacy-Preserving Distributed Storage and Computation","awardID":"1228598","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["560092"],"PO":["562974"]},"193358":{"abstract":"This project will develop methods for using historical understanding of technology to assess potential consequences of sociotechnical change and to inspire new design practices. Information technology (IT) builds on a longer history of technology tied to significant cultural shifts, commonly conceptualized as technological innovations driving societal progress. This research critically analyzes the idea of sociotechnical progress by asking: How is it conceptualized? What practices, values, and stakeholders become marginalized in the pursuit of progress, what are its consequences, and how can currently marginalized factors inspire new forms of design? It uses these questions to evaluate roles that IT has played in progress, and to envision and design for new roles it could play.<br\/><br\/>This project answers these questions through three case studies that look at societies on the global margin which have seized on technological progress as a means for bettering their circumstances. The case studies look at (1) a past attempt to rapidly transform from a subsistence, fishing-based to an industrialized economy in rural Newfoundland; (2) the consequences of a similar transformation in present Iceland, where pervasive adoption of information technology has transformed the small-boat fishing industry; and (3) debates over possible futures arising from the sudden and pervasive adoption of mobile phone technology in Jamaica. These novel case studies provide a new lens through which to understand the values embodied in information technology, its cultural impact, and their implications for practices in the field of human-computer interaction.<br\/><br\/>Methodologically, this work builds on design ethnography to demonstrate how historical methods can enrich the ability of work in human-computer interaction to address the broader cultural impacts of technology. By analyzing how the consequences of modernization compare with hopes invested in technology as a tool for progress, the project will provide evidence to support a more rigorous debate about the impact of information technologies. By using this analysis to generate new design insights, the project supports design practices that may improve the implications of technology, especially as productivity tools and means for advancing economic development.","title":"HCC: Small: Values of Information Technology for Progress: Three Case Studies","awardID":"1217685","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[517929],"PO":["564456"]},"193479":{"abstract":"The widespread practice of open source development is changing the IT industry in significant ways. Open source, these days, is a strategy that companies consider as part of their product's marketability. In Science and Engineering, open source has an established track record, and having the source code available to everyone these days is as important as having the data supporting scientific claims available, since Science and Engineering rely more and more on software for substantiating claims. Unfortunately, undocumented source code is as difficult to understand as raw, undocumented data; having it available without being able to understand it is not of much benefit. Open source projects, in particular, are notorious for their lack of documentation, since the developers often don't have the resources to produce artifacts beyond the code, so \"the code is the documentation.\" This is a pervasive problem that impacts Science the most, as it increasingly relies on software that is produced under slim budgets without margin for documentation efforts.<br\/><br\/>This project seeks to automatically recover high-level knowledge from software artifacts in order to make software components understandable in the absence of documentation. Recovering high-level knowledge from software artifacts has been a long-sought goal of software engineering research. The achievements so far have been limited. The approach taken here is to use machine learning techniques. This approach may finally start to produce usable solutions to this elusive problem. In pursuing the goal, this project unveils important knowledge and tools related to open source projects. First, it unveils knowledge about which and what kind of relations among source code artifacts correlate with the architecture recovery process. Second, it will produce a catalog of unsupervised learning algorithms tailored for software component identification. This will be publicly available for others to use and study. Third, it will produce a benchmark of software architectures of projects from various domains. Fourth, it will produce a catalog describing the artifacts and the learning technique which best recovered their architecture. Finally, it will produce reusable implementations of (i) several component identification algorithms; and (ii) structural, behavioral, and domain feature extraction. This project combines all this knowledge and tools in a plugin for Eclipse that supports automatic recovery of software architecture.","title":"SHF: Small: Automatic Software Architecture Recovery: A Machine Learning Approach","awardID":"1218228","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[518206],"PO":["564388"]},"193248":{"abstract":"Embedded computer systems have become essential to many aspects of our lives. Cheaper, smaller, faster, more sophisticated, and more energy-efficient embedded devices spur ever new applications. However, the growing complexity and shift to multicores make programming and debugging these systems difficult. Traditional debugging is time consuming and may interfere with program execution, causing some bugs to become irreproducible and making it unusable in real-time environments. Moreover, tracing a processor?s internal state during execution is only feasible for short program segments and requires large on-chip buffers or wide trace ports, either of which increases system cost and limits scalability. This project is developing the next generation of trace compression methods and infrastructure to make continuous, real-time, unobtrusive, and cost-effective program, data, and bus tracing possible in embedded systems. The approach relies on on-chip hardware to record the processor state and corresponding software modules in the debugger. The novel insight is that a sequence of trace records can be translated, without loss of information, into a much shorter sequence of miss events using small hardware structures. The few remaining miss events are then further compressed using highly-effective yet simple-to-implement encoding schemes, yielding heretofore unseen compression ratios.<br\/><br\/>The new tracing and debugging infrastructure can help programmers find difficult and intermittent software bugs faster, thus improving productivity. For example, reducing debugging time by just one percent amounts to hundreds of millions of dollars annually in saved salaries, with a concomitant reduction in software cost and time to market. Moreover, higher quality software may eliminate errors in medical, automotive, or mission-critical devices and thus save lives.","title":"CSR: Small: Collaborative Research: Real-Time Unobtrusive Tracing in Multicore Embedded Systems","awardID":"1217231","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[517663],"PO":["565255"]},"198814":{"abstract":"Most modern microprocessors support some form of vector operations that allow the same operation to be applied to small vectors of arguments simultaneously. Studies have shown that use of these instructions can improve the performance of many scientific codes by a factor of 2 or more. Unfortunately, the state of the art in autovectorization falls far short of this goal, only achieving improvements of 20-30% on the same codes.<br\/><br\/>While studies have shown that current autovectorizing compilers do not identify all of the opportunities for vectorization, little is known about why they fail to do so. Specifically, the project will focus on identifying weaknesses in compiler analyses that cause failures to vectorize. The goal of this research is to identify a list of causes that are responsible for the vast majority of these failures. This research will make it possible to develop better compiler analysis algorithms that will result in better autovectorizing compilers. The performance benefits of such compilers will improve the performance of applications ranging from multimedia software to scientific computing.","title":"EAGER: A Study of the Limitations of Program Analysis for Autovectorization","awardID":"1251312","effectiveDate":"2012-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[533380],"PO":["564588"]},"193017":{"abstract":"The first goal of the project is to develop new domain decomposition algorithms and software for the numerical solution of some highly nonlinear, coupled systems of partial differential equations arising from multi-physics applications. For simple problems, implicit methods are relatively easy to develop from a given explicit or semi-implicit method, but for some multi-physics problems it is quite difficult to develop a fully implicit method that allows a high performance implementation. Most of the existing techniques are non-smooth and therefore difficult to solve with Newton type solver. In the project, some discretization techniques will be developed that involve high order non-smooth discretization for capturing the domain information, and low order locally smooth discretization for building the Jacobian system of the Newton iterations. The low order discretization serves as a nonlinear preconditioner that speeds up the convergence, but doesn't change the accuracy of the solution. The second goal of the project is to develop an efficient implementation of the proposed linear and nonlinear preconditioning approaches on high performance computers with a large number of processors. <br\/><br\/>Relatively mature technologies including algorithms and software are available for solving many types of single physics problems, but for coupled multi-physics problems, robust and scalable techniques are badly needed, especially for large scale parallel computers with accelerators. The proposed algorithms and software will have a great impact on several important application areas, such as the simulation of global atmospheric flows and the bio-fluids, and will also have substantial influence on other areas of computational sciences where large linear and nonlinear equations need to be solved. To broaden the impact of the research, the software will be made fully compatible with the widely used PETSc package. The research is a rich area in opportunities for both graduate and undergraduate students interested in high performance computing and general Computational Science and Engineering.","title":"AF: Small: Fully Implicit Methods for Partial Differential Equations and Software for Hybrid Architecture","awardID":"1216314","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[517075],"PO":["565251"]},"193028":{"abstract":"This research will develop a detailed understanding of interactions between copyright law, social norms, and user behavior in online communities where people create and share content. Recent work has found that the following five things are typically different: (1) what the law says; (2) what people think the law says; (3) what people think is ethical; (4) community norms; and (5) what people actually do. How can we better understand users, how they engage with copyrighted content online, and how they interact with one another in environments of creative sharing? To fully answer these questions, it is necessary to address all five dimensions, and their complex interactions. This research takes up the task of understanding how these dimensions function within different online communities, how community norms evolve, and what lessons can be derived for online community management and design.<br\/><br\/>The Internet is a rich medium for a vast spectrum of creative activity. People make original art, write stories, make videos, and share them with others online. The raw material for this wealth of creativity is a combination of original ideas and existing content, including the remix of copyrighted material created by corporations or other Internet users. As a result, while the nuances of copyright law were once something that largely mattered only to commercial producers of content, technology has changed all of this. With both copying and wide dissemination made orders of magnitude easier thanks to digital content and the Internet, copyright is now something that touches the average computer user on almost a daily basis. This is particularly true for the large number of online amateur content creators. However, just because the law is more relevant to more people does not mean it is more easily understandable.<br\/><br\/>The same confusions that have always existed in applications of the law have been exacerbated by technological advances. Social norms that form within these communities of creators do not necessarily track exactly to the law, but represent shared understandings and constructions, as well as ethical intuitions. These norms interact in intricate ways with other sources of order in online communities - legal rules, site policies, and technology-imposed control - and only together provide a complete picture of user behavior.<br\/><br\/>This study will gather data from three sources: (1) current online community policies; (2) public conversations about intellectual property occurring on current online sites and archives from older communities; and (3) interviews with creators of online creative content. The analysis will focus on teasing out the norms that exist within different communities, how they have evolved, and how they interact with the law as written and as enacted by community policies.<br\/><br\/>The results of this research will better inform online community design, and more broadly contribute to our fundamental understanding of how social norms operate in complex sociotechnical systems. It will provide evidence-based guidance for online community designers, and for policy makers tasked with helping the law adapt effectively to new technologies. Broader educational impacts of this research include the training of two graduate students in this interdisciplinary field of study. Additionally, this research will enrich the curriculum for the required undergraduate class CS 4001 \"Computers, Society, and Professionalism.\"","title":"HCC: Small: Copyright and Online Communities: An Empirical Study of Social Norms and User Conceptions","awardID":"1216347","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[517101],"PO":["564456"]},"194007":{"abstract":"Silicon physically unclonable function (PUF) is a supplemental circuit embedded in an IC which generates signatures unique to its native IC. This signature could be used for authentication, protection of data and secure communication. PUFs rely on the presence of uncontrollable variations in the fabrication process causing the circuit parameters to exhibit randomness. Current approaches for PUF design have mostly investigated circuit and architectural aspects. PUF quality is severely marred by a lack of understanding of exactly how fabrication process variations impact the PUF responses. Much of the existing work assumes the fabrication process to be a black box. This results in several opportunities being unutilized. This research investigates fundamentally different approaches to PUF enhancements. It leverages quantified models for fabrication randomness that have been developed in Design for Manufacturability related research endeavors. This research looks into mask, circuit and layout level techniques along with their interdependence.<br\/><br\/>This work enables improved silicon PUFs thereby increasing the possibility of their adoption. Our approaches would be useful for both semiconductor manufacturing companies and fab-less design houses. On an education front, PhD students shall be involved in the core aspect of this work while undergraduates shall be used for data collection, analysis and test-bed development. Lastly, this project plans to enhance infrastructure for research and education by making available all the artifacts produced by this research in public domain. Further outreach efforts such as tutorials, panel discussions, etc. shall also be organized.","title":"TWC: Small: Physically Unclonable Function (PUF) Enhancements Via Lithography and Design Partnership","awardID":"1223233","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["541967"],"PO":["565264"]},"197527":{"abstract":"This project will result in a novel system called SOCRATES that will help transform social media research for scholars working in diverse fields by building a community of researchers and practitioners around various issues of data-intensive research. Social media services such as Twitter and Facebook, used by millions of people worldwide, expose vast amounts of data about people's beliefs, ideas, opinions, behaviors, and activities. At the same time, the sheer scale and volume of the data make them extremely difficult for scholars to study effectively. SOCRATES will address this issue by incorporating a set of socio-computational tools that will allow researchers from multiple fields to collect large-scale social media data; explore and visualize the resulting content items, and analyze the collected content. A community- and human-centered approach to developing the new system will ensure that SOCRATES matches researchers' work practices and mental models, is easy to use, and produces outcomes that significantly contribute to the researchers' goals, especially in solving multi-disciplinary problems. Importantly, the SOCRATES system will employ a social-computational approach--crowdsourcing--to handle some of the challenges of social media research. Thus, the project will take advantage of the intelligence of both computers and people to study online social activities. SOCRATES proposes to use the labor of humans to assist in the collection of data (e.g., by refining and filtering information collected by an automatic crawler); to help explore the data and generate insights (e.g., by allowing the public to view and comment on visualizations of the collected data); and to analyze and annotate the data (e.g., by creating a controlled environment where coders can annotate content items with high reliability). As a result, SOCRATES will provide a first-of-its-kind, end-to-end environment where social media can be studied effectively, with high validity, and at immense scale.","title":"Collaborative Research: BCC-SBE: Building Communities for Transforming Social Media Research with SOCRATES: SOcial and CRowdsourced AcTivities Extraction System","awardID":"1244704","effectiveDate":"2012-09-15","expirationDate":"2015-02-28","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"8068","name":"Data Infrastructure"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}}],"PIcoPI":[529949,529950],"PO":["564343"]},"190730":{"abstract":"Emotion is the complex psycho-physiological experience of an individual's state of mind. It affects every aspect of rational thinking, learning, decision making, and psychomotor ability. Emotion modeling and recognition is playing an increasingly important role in many research areas, including human computer interaction, robotics, artificial intelligence, and advanced technologies for education and learning. Current emotion-related research, however, is impeded by a lack of a large spontaneous emotion data corpus. With few exceptions, emotion databases are limited in terms of size, sensor modalities, labeling, and elicitation methods. Most rely on posed emotions, which may bear little resemblance to what occurs in the contexts wherein the emotions are really triggered. In this project the PIs will address these limitations by developing a multimodal and multidimensional corpus of dynamic spontaneous emotion and facial expression data, with labels and feature derivatives, from approximately 200 subjects of different ethnicities and ages, using sensors of different modalities. To these ends, they will acquire a 6-camera wide-range 3D dynamic imaging system to capture ultra high-resolution facial geometric data and video texture data, which will allow them to examine the fine structure change as well as the precise time course for spontaneous expressions. Video data will be accompanied by other sensor modalities, including thermal, audio and physiological sensors. An IR thermal camera will allow real time recording of facial temperature, while an audio sensor will record the voices of both subject and experimenter. The physiological sensor will measure skin conductivity and related physiological signals. Tools and methods to facilitate and simplify use of the dataset will be provided. The entire dataset, including metadata and associated software, will be stored in a public depository and made available for research in computer vision, affective computing, human computer interaction, and related fields.<br\/><br\/>Intellectual Merit <br\/>This research will involve construction of a corpus of spontaneous multi-dimensional and multimodal emotion and facial expression data, which is significantly larger than any that currently exist. To elicit natural and spontaneous emotions from subjects, the PIs will employ five approaches using physical experience, film clips, cold pressor, relived memories tasks, and interview formats. The database will employ sensors of different modalities including high resolution 2D\/3D video cameras, infrared thermal cameras, audio sensors, and physiological sensors. The video data will be labeled according to a number of categories, including AU labeling and emotion labeling from self-report and perceptual judgments of na\u00efve observers. Comprehensive emotion labeling will include dimensional approaches (e.g., valence, arousal), discrete emotions (e.g., joy, anger, smile controls), anatomic methods (e.g., FACS), and paralinguistic signaling (e.g., back-channeling). Additional features will be derived from the raw data, including 2D\/3D facial feature points, head pose, and audio parameters.<br\/><br\/>Broader Impact <br\/>Project outcomes will immediately benefit researchers in computer vision and emotion modeling and recognition, because the database will allow them to train and validate their facial expression and emotion recognition algorithms. The new corpus will facilitate the study of multimodal fusion from audio, video, geometric, thermal, and physical responses. It will contribute to the development of a comprehensive understanding of mechanisms involving human behavior, and will allow enhancements to human computer interaction (e.g., through emotion-sensitive and socially intelligent interfaces), robotics, artificial intelligence, and cognitive science. The work will likely also significantly impact research in diverse other fields such as psychology, biometrics, medicine\/life science, law-enforcement, education, entrainment, and social science.","title":"CI-ADDO-EN: Collaborative Research: 3D Dynamic Multimodal Spontaneous Emotion Corpus for Automated Facial Behavior and Emotion Analysis","awardID":"1205195","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[511335],"PO":["565227"]},"191500":{"abstract":"Robots cannot currently grasp objects or perform other contact tasks in unstructured environments with speed or reliability. This project is developing techniques for accurate real-time perception in support of contact tasks. In the proposed method, sensor data tracks the continuous motions of manipulated objects, while models of the objects are simultaneously updated. Particle filtering, a kind of Monte-Carlo simulation, ensures consistency of this tracking and updating.<br\/><br\/>The strongest impact of this work will be in robotic grasping and manipulation. Because of the synthesis of modeling and probabilistic inference, further impacts can be expected, for example in real-time haptics for telepresence.","title":"NRI-Small: Collaborative Research: A Dynamic Bayesian Approach to Real-Time Estimation and Filtering in Grasp Acquisition and Other Contact Tasks","awardID":"1208468","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":["522222","534411"],"PO":["549626"]},"192952":{"abstract":"The main objective of the project is to develop and study new incentive and reimbursement mechanisms within the context of the delivery of medical care. The project takes a game-theoretic perspective, with the main players being the government, health plans, healthcare providers, and patients. Some of the design goals of the mechanisms are to motivate the parties involved to improve healthcare quality while controlling costs. Among others, the study will try to extend the algorithmic game theory framework to address the unique challenges that occur in the context of healthcare. A key goal of the study is understanding the extent to which utilizing electronically available medical records may enable new mechanisms in the context of healthcare. In particular, the project studies potential advantages of high quality risk-adjustment schemes that are empowered by the application of machine learning to medical data.<br\/><br\/>In recent years, much of the focus in the US public policy debate has been given to problems surrounding providing and sustaining healthcare services. One of the key problems the US healthcare system faces is that of aligning incentives among the various stakeholders - the government, health plans, care providers, and patients - to ensure favorable outcomes and efficient resource utilization. The study will use tools from algorithms and game theory to develop new alignment strategies. In particular, the study will look at ways in which the collection and data-mining of electronic health records may be used to provide better incentives for the stakeholders, and lead to better overall care at lower cost.","title":"ICES: Small: Collaborative Research: Data-driven mechanisms in healthcare","awardID":"1215990","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":[516903],"PO":["565251"]},"191511":{"abstract":"The objective of this research is to develop a generic robotic vision architecture that is both biologically plausible and jointly optimal, in a decision theoretic sense, for attention, object tracking, object recognition, and action recognition, in both static and dynamic environments. The research is motivated by the observation that all these problems are solved by biological vision with very homogeneous neural computations. The approach is to exploit a mapping of accepted computational models of visual cortex into the elementary computations of statistical learning and inference in order to derive unified algorithms for all tasks. <br\/><br\/>Intellectual merit: the proposed unification of vision tasks is novel and of paramount importance for robotics, since it is computationally infeasible for a robot to implement a large set of disjoint vision algorithms. It will also exploit task synergies, producing algorithms that leverage the solution of one task to improve performance on another. This will likely enable overall better performance of vision systems. Finally, the project will produce novel insights on the structure of the visual world, and how it can be leveraged by robotic vision, by introducing new models for natural image statistics. <br\/><br\/>Broader impacts: The research has applicability in manufacturing, intelligent systems, health care, homeland security, etc. The expected theoretical insights are likely to be of wide application in statistics (models of feature dependence), neuroscience (models of neural computation), and computer vision (synergistic models). Educationally, the project provides an exciting opportunity for the involvement of undergraduates in research.","title":"NRI-Small: A Biologically Plausible Architecture for Robotic Vision","awardID":"1208522","effectiveDate":"2012-09-01","expirationDate":"2017-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":[513306],"PO":["563109"]},"192963":{"abstract":"An individual's preferences can be complicated. <br\/>The project investigates whether people's preferences do, in fact, conform to the CP-net (conditional preference network) formalism, how such preferences can be combined according to different voting methods, and how vulnerable those methods are to manipulation or \"strategic voting.\" Finally, the very large corpus of preference data from the Netflix Challenge is used to build statistical models of the efficiency of manipulation algorithms and to compare the performance of different consensus methods.<br\/><br\/>Laboratory experiments will check whether people exhibit preferences that can be modeled by CP-nets. The project extends ideas from aggregation in Bayesian networks (models of conditional probabilities) to aggregation in CP-nets (models of conditional preferences).<br\/><br\/>The team investigates how statistical inference from noisy data relates to or interacts with strategic manipulability and bribery. The project extends behavioral social choice and computational social choice on voting systems, and the manipulation thereof, from preferences expressed as ratings, rankings, or subsets to preferences expressed as CP-nets.<br\/><br\/>The team investigates the performance of voting methods and the efficiency of manipulation schemes on real preference data from the Netflix challenge data set. These data, namely hundreds of thousands of (slightly perturbed) personal rankings of movies, were released several years ago for data-mining purposes. One can extract individual \"elections\" based on the rankings of a small set of movies, evaluate and compare various aggregation methods and empirically characterize voting scenarios that are especially susceptible or especially resilient to strategic manipulation.<br\/><br\/>Among the broader impacts of the research, beyond the integration and cross-fertilization of several distinct research areas spanning several scientific disciplines, are the development of more adequate individual and collective decision making tools, that will help individuals, groups, organizations, and society to improve decision making.","title":"ICES: Small: Collaborative Proposal: Robust Preference Aggregation","awardID":"1216016","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":[516926],"PO":["565251"]},"200817":{"abstract":"This funding establishes a new CISE Research Experiences for Undergraduates<br\/>(REU) site at Utah State University. The project, called<br\/>Bug Wars, exposes students to research on software testing and AI<br\/>planning through both competition and collaboration. This project will<br\/>create new knowledge about user-session-based testing, model-based<br\/>testing with AI planning, and the combination of these two techniques<br\/>as applied to web applications. A novel feature of this REU is that<br\/>it encourages both competition and collaboration. The students initially<br\/>split into two teams that strive to find the most faults in web application<br\/>systems under test. One team collects, reduces, and prioritizes<br\/>user-session-based test suites. A second team uses machine learning to<br\/>build models of the software and AI planning to generate test suites.<br\/>Students compete to show the merits of their approach on the same systems<br\/>by considering the sizes and fault detection effectiveness of their<br\/>test suites. The students then critically discuss their work and propose<br\/>combining the different approaches to further improve effectiveness. <br\/><br\/>The broader impacts of this research are that twenty-four students over a<br\/>three-year period have the opportunity to participate in a supportive<br\/>environment that encourages them to pursue graduate studies in Computer<br\/>Science. The students are better prepared for graduate school as they gain<br\/>basic research skills, including the formulation of research questions,<br\/>design of experiments, critical evaluation, and written and oral<br\/>communication.","title":"REU Site: Bug Wars: A Collaborative Software Testing Research Experience for Undergraduates","awardID":"1262126","effectiveDate":"2012-09-01","expirationDate":"2015-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1139","name":"RSCH EXPER FOR UNDERGRAD SITES"}}],"PIcoPI":[538414],"PO":["564588"]},"192974":{"abstract":"This project investigates how exogenous shocks that take place in one network affect the structure and evolution of other networks. The objective of the project is to gain a better understanding of the interaction between social and physical networks at critical junctures, allowing both assessment of the conditions of failure and rehabilitation of systems that fail because they are connected to other systems that fail. The main focus is on three types of interrelations between pairs of networks: 1) Overlapping networks: two or more networks that share nodes and\/or edges. 2) Complementary networks: two or more networks that perform partially or fully complementary functions (such as e-commerce and shipping networks). 3) Competitive networks: networks in which the flow of goods, information, or energy in one is inversely correlated to the flow of similar items in the other (such as airline and rail transportation).<br\/><br\/>The intellectual merit of the project rests in explaining the effect of shocks on the structure of interacting social and physical networks. It will allow new insights into the cross-network effects of shocks as a function of both the structure of individual networks and the type of relationships between pairs of networks.<br\/><br\/>The broader impacts of the project include the development of methods and computerized infrastructure for predicting the impact of a future shock in one network on other networks, potentially providing decision makers with insights into structuring network ties in a way that will optimize the effects of a shock in one network. Finally, this project offers graduate student training and experiencing in theory development, designing mathematical and agent-based models, and empirical evaluation of theoretical models.","title":"ICES:Small: The Effects of Shocks on Interacting Social and Physical Networks","awardID":"1216048","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":[516957,"542083",516959,"547089"],"PO":["565251"]},"194921":{"abstract":"Proposal #: 12-29561<br\/>PI(s): Dubey, Rajiv; Diamond, David M; Quillen, William; Reed, Kyle; Sarkar, Sudeep<br\/>Institution: University of South Florida<br\/>Title: MRI\/Acq.: CAREN: Virtual Reality System for Collaborative Research in Assistive & Rehabilitation Technologies<br\/><br\/>Project Proposed:<br\/>This project, acquiring an instrument referred to as CAREN (Computer Assisted Rehabilitation ENvironment), aims to greatly facilitate ongoing interdisciplinary and inter- and intra-institutional research to analyze human mobility and function and to improve the quality of life of individuals with disabilities and older adults by increasing their independence and community reintegration. The instrument, a turnkey customizable 3D virtual reality system with applications in complementary research and training experience in the broad areas of rehabilitation engineering and science, also includes a cylindrical screen projection system, 12-camera real-time motion-capture system, a six degree-of-freedom motion base and a control software suite. The team includes about 20 PIs from various departments at the institution, which currently lacks a shared virtual reality simulation facility for large collaborative projects. The instrumentation, to be used for fundamental research in various disciplines, analysis and creation of innovative technology solutions that can be rapidly evaluated, tested, prototyped and commercialized, is expected to dramatically reduce the need for costly physical simulations and allow complex testing not otherwise possible. The following research projects will be supported by CAREN:<br\/>- Fundamental research: measure effects of sensory inputs (e.g., visual, auditory, vestibular, tactile);<br\/>- Early diagnosis related research: quantify behavioral indicators for early detection of disorders;<br\/>- Applied rehabilitation research: provide real-time feedback to the user, thus allowing rapid correction of therapeutic movements;<br\/>- Sports medicine research: optimize training techniques for peak performance and injury prevention; and<br\/>- Research on rehabilitation transfer to daily life: model environments that allow more real-life training for enhancing laboratory or clinic based rehabilitation.<br\/><br\/>Broader Impacts:<br\/>The impact should be felt both regionally and nationally. At the national level, the proposed system could have great implications for improving the quality of life of individuals with disabilities and older adults. At the local level, the VR equipment will be integrated into a number of courses and will engage K-12 students. It is expected that the engagement of students through the REU program can greatly impact undergraduate research. There is a substantial industrial partnership and potential for technology transfer.","title":"MRI: Acquisition of a CAREN Virtual Reality System for Collaborative Research in Assistive and Rehabilitation Technologies","awardID":"1229561","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[522399,522400,522401,"550586",522403],"PO":["557609"]},"180522":{"abstract":"This project develops methods to provide citizens information about technologies that obstruct, restrict, or tamper with their access to information. Internet users need an objective, independent, third-party service that helps them determine whether their Internet service provider or government is restricting access to content, specific protocols, or otherwise degrading service. Towards this goal, we are (1) monitoring attempts to block or manipulate Internet content and communications; and (2) evaluating various censorship circumvention mechanisms in real-world deployments}. The project develops a large-scale measurement and monitoring service that measures network reachability and performance from a variety of access networks to various Internet services; infers whether ISPs or governments are restricting or otherwise throttling access to various applications and services; and detects attempts to tamper with information presented to users. The project also studyies the policy ramifications of making information about censorship and information tampering available to Internet users. It will provide up-to-date information about both the extent of censorship and information tampering in countries around the world and technologies countries are using to implement censorship and thwart censorship circumvention tools. Discoveries are disseminated through real-time portals and through regular written reports and academic publications.","title":"TC: Large: Collaborative Research: Facilitating Free and Open Access to Information on the Internet","awardID":"1111723","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["535009","543138","561756","549758"],"PO":["565327"]},"194701":{"abstract":"Access control schemes are traditionally compared in terms of raw expressive power (i.e., the policies they can encode and how those policies can be changed); however, such comparisons ignore the needs of the application within which a scheme will be deployed. For some applications, the most expressive scheme may be overly complex and not necessarily the best fit. To this end, this project investigates the suitability analysis problem: Given a system's access control workload, a set of candidate access control schemes, and a set of application-specific cost metrics, which scheme best meets the needs of the system?<br\/><br\/>The goal is to create a suitability-analysis framework that is sufficiently rigorous to be useful to researchers and theoreticians, while remaining accessible to security practitioners. Such a framework will help formalize an access control scheme's application-specific strengths and limitations, enable researchers to precisely describe the scenarios for which a scheme is best suited, allow assessment of the novelty and utility of proposed schemes, and help analysts diagnose shortcomings in existing systems. In particular, the project will develop (1) an application-specific, workload-based framework for analyzing the suitability of access control schemes that is sufficiently rich to compare logical, extensional, and hybrid schemes in both sequential and concurrent systems; (2) a cost analysis component that quantifies a scheme's suitability using custom metrics; and (3) tools that automate a range of suitability analysis tasks. A real-world security workload, PKI-based authentication and authorization on the web, will be used to evaluate the results.","title":"TWC: Medium: Collaborative: Foundations of Application-Sensitive Access Control Evaluation","awardID":"1228668","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["524617"],"PO":["562974"]},"193502":{"abstract":"One of the most computationally challenging tasks in Numerical Linear <br\/>Algebra (NLA) is the estimation of the trace or the determinant of functions <br\/>of matrices. The computational difficulty arises for very large matrices <br\/>where the computation of the entire spectrum is infeasible. Traditionally, <br\/>this problem is approached through stochastic techniques, such as Monte <br\/>Carlo, where each step involves the solution of a linear system of equations. <br\/>Deterministic techniques could provide approximations much faster but <br\/>introduce bias in the result. This research will employ a combination of <br\/>these techniques. Deterministic techniques involve novel uses of <br\/>traditional NLA tools such as low rank approximations, deflation, and <br\/>preconditioners, not only for speeding the solution of linear systems but also <br\/>for reducing the variance of the stochastic process. The team plans to use Hadamard <br\/>vectors, which are popular in coding theory, with an ordering induced by <br\/>hierarchical graph-coloring, to produce a deterministic sequence of sampling <br\/>vectors for Monte Carlo that exploits the structure of the matrix.<br\/><br\/>Although most of these techniques address the general NLA problem, the <br\/>motivating application is lattice quantum chromodynamics (LQCD). The goal <br\/>of LQCD is to calculate the properties, structure, and interactions of hadrons,<br\/>the basic constituents of matter. Computation of observables in LQCD entails <br\/>averaging of correlation functions over an ensemble of gauge fields. <br\/>These correlation functions often require the trace of the inverse of a large <br\/>sparse matrix, or the ratio of determinants of two such matrices. <br\/><br\/>It is increasingly clear that there is an opportunity for real gains by <br\/>harnessing the synergy between randomized and deterministic techniques.<br\/>Based on such an approach, this research will advance the current <br\/>state-of-the-art in NLA, while transforming some of the standard computational <br\/>practices in LQCD. It will also be useful in other disciplines, as the <br\/>problem is common in many statistical applications, in data mining, <br\/>in uncertainty quantification, as well as in quantum physics applications <br\/>such as quantum Monte Carlo.","title":"AF: Small: Algorithms for computing aggregate functions of matrices with applications to Lattice QCD","awardID":"1218349","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[518256,518257],"PO":["565251"]},"193513":{"abstract":"Compressed sensing (CS) is a rapidly advancing area of signal processing and statistics that has the potential to radically change the way that analog signals are transformed into digital signals. The main idea is to acquire a sparse signal from a very small number of measurements using a specialized sampling and reconstruction process. Since one promising application of CS is medical imaging, improvements in CS systems are also expected to advance real-world healthcare applications. In this project, the investigators will study the fundamental connection between error-correcting codes (ECC) and CS and leverage recent advances in ECC to design improved CS measurement and reconstruction systems.<br\/><br\/>In particular, the connection between linear-programming (LP) decoding of binary linear codes and LP reconstruction will be used to develop a non-asymptotic theory for the design and analysis of CS algorithms and measurement matrices. The first part of the project will focus on novel relaxations of the CS reconstruction problem that allow non-convex regularization and iterative solution. The second part of the project will focus on applying the theory of pseudo-codewords, which was originally developed to understand iterative and LP decoding of binary linear codes, to achieve a non-asymptotic analysis of iterative reconstruction algorithms for CS. The third part of the project will focus on exploiting additional signal structure (i.e., beyond sparsity) that exists in high-contrast imaging applications such as angiograms.","title":"CIF: Small: Collaborative Research: Design and Analysis of Novel Compressed Sensing Algorithms via Connections with Coding Theory","awardID":"1218398","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["551056"],"PO":["564898"]},"193634":{"abstract":"The growth of the Internet has led to a dramatic increase in the rate at which information is generated and delivered. This is especially true for the news cycle which has become instantaneous and often resulting in social networks, most notably Twitter, being the medium of choice to deliver late breaking news. This is usually in the form of links to more details which include news articles and multimedia data (news photos and videos). One problem lies in identifying reliable news gatherers which is done by noting if they are the first to report on a topic in contrast to being a re-poster and their frequency. Other issues in providing access to news content involve making the news automatically indexable (instead of by human tagging) both by content (regardless of the language of creation and the nature of the media) and by the location of the content (i.e., geotagging) rather than the location or affiliation of its creator. In the case of location, the challenge lies in devising language-independent geotagging techniques. Machine learning based methods are investigated and are expected to work better than rule-based methods due to a reduced reliance on language-specific rules and a greater reliance on examples. Access to the images is facilitated by indexing them by the words associated with the news articles containing them. This indexing technique is meant to be used as a filter for finding similar or near-duplicate images where the similarity is based on image features. The access by location is facilitated by the use of a map query interface. This is important as it corresponds to enabling the use of spatial synonyms thereby permitting a wider range of queries to be posed. A novel aspect of the research is the incorporation of non-English content which is facilitated by the use of computerized translation services which will be evaluated on their ability to capture the content on the basis of clustering similar articles in different languages rather than on the basis of factors such as proper grammar, etc. <br\/><br\/>In today's rapidly changing world, the tools that are developed in this project will make this information more accessible as users are enabled to focus on a geographical area of interest as well as have access to content in their own language. This is of utility to a number of organizations and attempts will be made to collaborate with potential users on tailoring the tools for their needs. In addition, the project will provide research experience to undergraduate and graduate students who will be involved in developing some of the components. These tools are also a step in the growth of the nascent field of computational journalism. The project web site (http:\/\/www.cs.umd.edu\/~hjs\/geomultimedia.html ) will provide access to results of this and related research.","title":"III: Small: Issues in the Management of GeoMultimedia Data","awardID":"1219023","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":["551003"],"PO":["563751"]},"193403":{"abstract":"Grasping and manipulation of deformable objects presents a host of new research challenges that are much more demanding than for rigid objects. A particular challenge is to fully understand the physics of deformation and to model deformable objects in a way that can be used by real robotic systems in the presence of noise and uncertainty and with real-time constraints. This project will use offline simulation to predict states of deformable objects modeled as thin-shells (i.e. cloth, fabric, clothing) that can then be recognized by a robotic vision\/grasping system to pick up and manipulate these objects. The Intellectual Merit includes a significant step forward in the synthesis of state-of-the-art numerical computation of plasto-elastica with a database-driven manipulation approach to allow robots to manipulate deformable objects. This includes fabric simulation technology that provides the requisite level of accuracy at speeds amenable to online computation parallel to the robotic grasping task. <br\/><br\/>The Broader Impacts of this research include 1) creation of an open source, extensible, 3-D database of deformable objects for dissemination to the robotics and graphics communities, 2) extending the range of working environments for the emerging field of personal robotic assistants, and 3) developing and educating a new class of scientists who bridge the fields of computer graphics, computational mechanics, and robotics.","title":"RI: Small: Dexterous Manipulation Using Predictive Thin-Shell Modeling","awardID":"1217904","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[518026,"554341"],"PO":["564069"]},"193524":{"abstract":"Inverse problems like parameter estimation, data assimilation, optimal<br\/>engineering design, and optimal control of large scale systems governed by<br\/>partial differential equations, are of considerable importance in many<br\/>fields including atmospheric science and oceanography, aerospace<br\/>engineering, and fluid and structural mechanics.<br\/><br\/>State-of-the-art solvers for large scale partial differential equations<br\/>adaptively refine the time step and the mesh, and adjust the computational<br\/>pattern according to the features of the solution. Adaptivity is necessary<br\/>to control the numerical errors introduced by temporal and spatial<br\/>discretizations and to preserve the qualitative features of the solution<br\/>(e.g., avoid the formation of spurious wiggles). In contrast, most inverse<br\/>problems to date have been solved using non-adaptive methods (e.g., fixed<br\/>grids and timesteps).<br\/><br\/>This project develops a fully discrete framework for solving inverse<br\/>problems in the context of adaptive models. The framework fills the gap<br\/>between the state-of-the-art adaptive methods used in (forward)<br\/>simulations and the computational tools currently available for the<br\/>solution of inverse problems. The specific research objectives are to<br\/>develop discrete algorithms for inverse problems with models that employ<br\/>refinement of the spatial discretization, and adaptive time stepping, to<br\/>guarantee that the discrete inversion process leads to convergent<br\/>numerical approximations, and to control the accuracy of the inverse<br\/>solution.<br\/><br\/>The results of this work are general algorithms and methodologies that<br\/>will advance the field of inverse problems by developing the capability to<br\/>adapt time steps, grid sizes, and computational patterns, such as to<br\/>control the quality and accuracy of the inverse solutions. These results<br\/>have the potential to impact any mature<br\/>field which relies on adaptive simulations, such as data assimilation in<br\/>atmospheric sciences, oceanography, and environmental sciences; optimal<br\/>control of flows, and optimal engineering design.<br\/><br\/>The algorithmic and software tools developed during this research will be<br\/>largely disseminated through specialized journals and conferences. This<br\/>project provides an excellent opportunity for training graduate students in<br\/>the areas of inverse problems and adaptive computations.","title":"A Fully Discrete Framework for the Adaptive Solution of Inverse Problems","awardID":"1218454","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[518306],"PO":["565251"]},"193645":{"abstract":"The use of sophisticated digital systems to control complex physical components in real-time has grown at a rapid pace. Examples include automobile adaptive braking, industrial robotic assembly, medical pacemakers, autonomous vehicular travel, remote surgery, physical manipulation of nano-structures, and space exploration. Since all these applications interact directly with the physical world and often have humans in the loop, their physical safety must be ensured. The correctness of these safety-critical systems depends not only on the actions they generate, but also on the time at which these actions occur. This project develops response time analysis techniques and scheduling algorithms for embedded control systems implemented as functional reactive programs (FRP's), which are mathematical functions. The controller may consist of a single control component or a network of distributed control components, each running on single or multi-core processors. The response time of the embedded controller has a direct impact on the safety of the entire physical system, but accurate response time analysis of FRP's remains a largely unexplored problem. While there are limited domain-specific studies that provide basic schedulability analysis using approximate bounds on the response time of the transactional model used in implementing functional reactive systems, they do not provide the exact timing characterization needed to guarantee satisfaction of the timing constraints imposed on the execution of the embedded controller. Thus this work develops a framework for accurate response time analysis, scheduling, and thermal-aware\/power-conserving methods for these FRP-implemented controllers to improve their performance and enhance their safety.<br\/><br\/>This project evaluates the impact of this framework on physical system safety and performance using two applications that will require integrating the results of all the research activities: automotive systems and avionics. Determining actual response times of embedded controllers implemented as FRP's will be a technical milestone. Verifiably showing how these scheduling techniques enhance physical system safety and performance will be another. By improving the safety and performance of embedded control systems while reducing the cost of their implementation in domains such as aerospace, medicine, communication, automotive, nano-fabrication, industrial processing, and space exploration, the project has broad societal impact. This project educates diverse undergraduate and graduate students to perform research in a top-tier urban university whose graduates often join local energy-related\/high-tech industries, NASA's Johnson Space Center, and the world-renowned Texas Medical Center. Novel techniques discovered will be incorporated into the undergraduate and graduate courses in embedded\/real-time systems and operating systems. Project results will be included in the next edition of the PI's popular textbook titled \"Real-Time Systems: Scheduling, Analysis, and Verification\" (Wiley) and in a new textbook titled \"Embedded Programming.\" The planned research activities will generate a variety of research papers and hardware\/software tools addressing the aspects of the project. Implemented tools will be readily available for download.","title":"SHF: Small: Real-Time Scheduling and Analysis of Functional Reactive Systems","awardID":"1219082","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":[518598],"PO":["564588"]},"193414":{"abstract":"Novel hardware technologies and application requirements have recently triggered a flurry of research and development into new data management systems. These systems challenge the hegemony of ossified, legacy database systems which lack the agility to adapt to these new constraints. But features pioneered by legacy systems (e.g., declarative query processing) are still desirable, and therefore, much work is being devoted to designing components that provide these features in new systems.<br\/><br\/>The goal of this project is to support research and development of (query) optimizers in data management systems. Optimizers, which translate declarative descriptions of data (queries) into executable plans, are inherently complex but nonetheless, there are no software engineering tools dedicated to their development. Therefore this project aims to design and build DEVEL-OP: a dedicated DEVELopment Environment for OPtimizers consisting of the following suites of tools:<br\/><br\/> 1) Component Generators, which use declarative specifications of components to produce executable code. Developers can use generators to rapidly prototype alternative versions of components encompassing different optimization approaches,<br\/><br\/> 2) Profiling Tools, which help developers identify bugs or performance bottlenecks in generated components, and<br\/><br\/> 3) Component Benchmarks, which enable the evaluation of optimization approaches (as manifested in generated components) in terms of their effectiveness and robustness in contributing to optimization as a whole.<br\/><br\/>DEVEL-OP provides a sandbox where optimizers can be quickly prototyped, refined and compared with minimal effort. Therefore, its impact will be in applying software engineering methodologies to the inherently difficult and complex development process for this key component of data management systems.","title":"III: Small: A Development Environment for Query Optimizer Engineering","awardID":"1217952","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[518052,"534198"],"PO":["563727"]},"194745":{"abstract":"This project investigates the feasibility of secure, robust, and usable gesture-based authentication as an alternative to traditional alphanumeric passwords and biometrics. It is motivated by the rapid increase in authentication-related security breaches and by the emergence of new human-computer interfaces. While the breaches have demonstrated the seriousness of the issue, two emerging types of gesture-based interfaces, multi-touch (smartphones, tablets) and camera-based (Kinect), offer a unique opportunity for robust solution.<br\/><br\/>The benefit of gesture-based authentication over a purely-biometric one lies in the fact that it combines involuntary biometric features (e.g., hand shape), that are irrevocable, with user-controlled voluntary characteristics that can be easily changed. Three research thrusts are being pursued: 1) gesture recognition algorithms (search for robust gesture features, their compact representation, and reliable classification algorithms), 2) human factors (study of uniqueness, repeatability, ergonomics, device dependence of gestures, and gesture complexity) and 3) security considerations (evaluation of authentication performance under a range of performance measures and different threat models). <br\/><br\/>A successful completion of this research will catalyze the development and adoption of next-generation authentication methods that are critically needed at the personal, institutional, and governmental levels. As the price paid (time, money, and resources) to repair a security breach can be astounding, this project will have substantial societal impact by increasing the sense of security and reducing breach-related costs. At educational level, this project is involved in middle and high school outreach at Boston University as well as the annual cybsersecurity competition CSAW at NYU-Poly.","title":"TWC: Medium: Collaborative: Towards Secure, Robust, and Usable Gesture-Based Authentication","awardID":"1228869","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[521649,521650],"PO":["565327"]},"193535":{"abstract":"In an era of information overload and big data, there is a pressing need to analyze, protect, prioritize and utilize data. Much of this data is inherently relational; thus, it is crucial to understand the benefits, challenges and potential hazards of exploiting the relational properties. Integrating, cleaning, and linking relational data requires matching and resolving references in the data. At the same time, matching and linking pose significant privacy risks. The proposed work develops a theoretical understanding of entity resolution in network data with the goal of developing tools and methods which can tell us how easy or difficult it will be to resolve data in different settings. Making use of the theory, new entity resolution algorithms will be developed with accuracy guarantees and for scaling entity resolution to large-scale data sources. These research results will enable more informed data sharing and usage decisions by individuals, industry, and government. Accurate analysis of network data is of utmost importance to science, medicine and national security. Whether studying socioeconomic trends, integrating data from large microarrays, analyzing organized crime or terrorist networks, or mining financial data for corporate misconduct, accurate network data, and its associated statistics, are crucial. At the same time, understanding how entity resolution effects privacy guarantees, and educating the public about the impact of releasing identifying information, is equally important.","title":"III: Small: A Theoretical Framework for Practical Entity Resolution in Network Data","awardID":"1218488","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[518332],"PO":["563727"]},"192446":{"abstract":"This project will develop and evaluate methods by which large numbers of humans, together with computers, can advance the field of synthetic biology by assembling a corpus of creative designs of molecular machines built from DNA segments as well as other molecular structures. Specifically, it will develop a massively-distributed DNA machine construction game that will enable human worldwide collective creativity to be applied to problems ranging from the design of novel self-organizing materials to smart therapeutics that can sense and respond to their environment. The innovative approach is to cast problems of constructing molecular nano-machines with specific functions as a collaborative machine design game governed by the rules of DNA strand interactions. <br\/><br\/>This approach points to a new paradigm for future science, in which a large group of people together with computers work on difficult creative problems, finding solutions that could not be found by computers alone, or by people alone, or without the massive participation of users. If successful, this approach could change science profoundly, with wide-ranging impact on many disciplines including nanotechnology, biochemistry, medicine, and even social and economic behavior analysis. Although the project specifically focuses on games that use DNA strands as principal building blocks of nano-machines, the potential set of applications is large, and encompasses three of the most significant problems facing humanity today. <br\/><br\/>The primary goal of the computer game is to develop and focus collective creativity towards a design space of machines governed by DNA molecular mechanisms. It is currently not known whether this form of sophisticated scientific design creativity can be developed rapidly with non-experts. It is also unknown whether this developed creativity can exceed the current capabilities of the scientific community. This project aims to answer a number of fundamental questions: How does one develop computer games to maximize targeted human design creativity? What are the guiding principles of successful molecular design games? How do we generalize game-development principles to the widest possible range of synthetic biology problems? How can we develop a collective creative design process that outperforms any individual creativity? How do we learn from the way people play the game, and distill their strategies towards stronger automated approaches? <br\/><br\/>The successful outcomes of this project can have a wide ranging impact on health and medicine. One such problem is the design of diagnostic devices and imaging technologies. The game players will work to develop DNA sensors and circuits that can autonomously analyze and interpret the information encoded in a set of molecular disease markers. This approach will enable new devices for multi-analyte testing in low resource settings and will lead to novel medical imaging technologies. Another challenge is design of novel targeted therapeutics, in this case novel RNA-based therapeutics that can autonomously sense and analyze their environment and activate a therapeutic response only where required. A third problem is design of novel materials. This project will develop DNA nanostructures with the potential for the massively parallel self-assembly materials with desired electronic, optical, or chemical properties. These materials will find applications in areas from artificial photosynthesis to biofuels production. <br\/><br\/>This effort will have positive broader impacts for informal science education. The game will reach out to people of all demographic profiles in hope of educating everyone about key molecular research challenges, empowering them to solve important scientific problems, and engaging them in research and science in general. Hopefully, the best scores in these games turn into seminal discoveries with deep impact on people's lives. Also, undergraduates will be involved directly in game development, and a course centered around prototyping of molecular games will be offered. Furthermore, the research team will work with education scientists to develop a new curriculum about DNA and how nature uses molecular mechanisms to achieve function. The curriculum will be anchored around the DNA Machine game and will be piloted in US high schools.","title":"HCC: Large: Collaborative Research: DNA Machine Builder: Creative molecular-machine design through mass-scale crowdsourcing","awardID":"1212940","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[515752,"549568","549589"],"PO":["564456"]},"193304":{"abstract":"This award funds research to develop faster and better algorithms for handling data, and specifically geometric data. With the massive amount of data in the world nowadays, standard algorithms fall short. The PI and his students investigate ways to improve geometric search for nearest neighbor, clustering, data-compression, and similarity search between curves, especially for massive amount of data. Such algorithms are widely used in the real world to handle navigation tasks, pattern recognition, signature identification, etc.<br\/><br\/>The algorithms and insights obtained from the technical work will benefit Computer Science and related disciplines where geometric algorithms are widely used. The PI hopes to broaden the scope of Computer Science (and Computational Geometry) by introducing new techniques, that would lead to faster and better algorithms. A complementary goal is also to introduce Computer Science techniques into other fields.<br\/><br\/>The award will support and train two or more PhD students in Computer Science at UIUC. The PI is committed to popularizing ideas and techniques that will be investigated by giving courses, publishing the research, and using less convectional new tools to disseminate the research such as blogs, social media, and online videos.","title":"AF: Small: Efficient Proximity and Similarity Search in Computational Geometry","awardID":"1217462","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[517802],"PO":["565157"]},"193667":{"abstract":"This work aims to obtain an empirical understanding of the collaborative behaviors in patient-provider handoffs and to explore opportunities for designing technologies that support and enhance these practices. Handoffs, also called handovers, occur when workers exchange information necessary for their tasks, and when responsibility for an operation shifts from one person to another. Handoffs are often considered as the most error-prone activities in collaborative work, especially for time-critical tasks under continuous operation, such as in software design, 24\/7 services areas, and healthcare practices. In healthcare, this project's area of study, repeated handoffs occur between patients and their health providers, with information being transferred from patients or caregivers to healthcare professionals, and conversely from professionals back to patients. The challenges involved in patient-provider collaboration make it a uniquely situated area to study.<br\/><br\/>This research uses ethnographic methods to investigate patient-provider handoffs in three different patient care settings: an emergency department, an inpatient ward, and an outpatient clinic. It aims to study the entire spectrum of activities related to handoffs, including pre-visit, medical visit, and post-visit information work performed by patients and clinicians. In addition, based on the empirical insights obtained through the ethnographic study, an information media prototype will be used to solicit feedback and further insights on designing information systems to mediate patient-provider collaboration.<br\/><br\/>The research will provide both empirical and conceptual insights into understanding the mechanisms, challenges and behavioral patterns of team collaboration involving consumers and professionals. The findings will benefit the design and the adoption of information systems for health practices, and will reduce information and communication errors in the handoff process. In the long run, this study will also positively impact larger populations of patients through the wide dissemination of the findings and through improving the design of the future information media for patient-provider handoffs.","title":"HCC: Small: Patient-Provider Handoff: Collaboration Challenges and Technology Design","awardID":"1219197","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[518647],"PO":["564456"]},"191489":{"abstract":"This project, developing a systematic methodology for the design of multi-fingered robotic hands and grasping devices for a desired kinematic task, represents a novel formalization of the kinematic synthesis of articulated systems as a tree structure. The kinematic task is to be defined as positions and higher motion derivatives of the fingers, with accelerations related to the contact geometry at the fingertips for grasping actions. This research team aims to develop multi-fingered grasping devices for human-robot and anthropomorphic tasks, however the method will be a general tool for the design of any kind of multiple-finger grasping device.<br\/><br\/>This research has a number of broader impacts affecting both the academic community and society at large. First, the project will directly result in a design tool for multi-fingered robotic hands to enable the automatic transformation from task specifications to design alternatives ? an important development in its own right. This design tool will increase the ability of industry to design high performance, cost-effective multi-fingered robotic hands and other end effectors. This directly impacts manufacturing by speeding the development of end-of-arm tooling, with secondary benefits to the cost and quality of the final product. This will assist the U.S. to maintain its leadership and encourage the creation of high-quality jobs. The proposed curriculum additions resulting from this project will produce competent engineers for industry with a greater ability of approaching and solving design problems.","title":"NRI-Small: Collaborative Research: A Design Methodology for Multi-fingered Robotic Hands with Second-order Kinematic Constraints","awardID":"1208385","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[513250],"PO":["564069"]},"194767":{"abstract":"Secure Computation is a powerful concept from cryptography that enables collaboration in the absence of trust. Despite its great potential for solving practical problems in collaborative situations, it has not yet been widely adopted in practice. Indeed, until recently there were few practical implementations of secure computation protocols, and even recent implementations were forced to restrict themselves to weak forms of security for the sake of efficiency. This is because the dominant paradigm for achieving strong security, since the invention of the first such protocols, has relied on zero-knowledge proofs, and yields protocols that are too inefficient even for simple computations.<br\/><br\/>We are developing radically different new architectures for efficient secure computation protocols that bypass the need for such zero-knowledge proofs. Our architectures are based on a novel principled approach to developing new secure computation protocols, with consequences to the theory and practice of modern cryptography. Our research will identify new (partial) security properties inherent in simple protocols, and study how such properties can add up to strong security guarantees through carefully developed methods for composing protocols.<br\/><br\/>Secure multiparty computation is an idea whose time has come, as evidenced by the several projects around the world engaged in translating the theoretical results to practical implementations, and the number of research projects outside cryptography that seek to exploit it. Widespread availability and deployment of secure computation protocols has the potential to be a disruptive technology, enabling new avenues of cooperation in areas with sensitive information. Apart from the technological impact, we strive to bring the advances in cryptography to a broader computer science audience, by integrating our research into graduate and undergraduate education, and outreach efforts.","title":"TWC: Medium: Collaborative Research: Transformative New Approaches to Efficient Secure Computation","awardID":"1228984","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[521734],"PO":["565239"]},"193557":{"abstract":"In some combinatorial optimization problems, the resulting solution<br\/>may violate some constraints provided the cost of finding the solution<br\/>is significantly reduced. Such problems are called soft constraints<br\/>problems. In hard constraints problems, an acceptable solution cannot<br\/>violate any of the constraints. Hard constraints versions of many<br\/>problems have resisted satisfactory solutions as compared to the<br\/>corresponding problems with soft constraints. The goal of<br\/>this project is to study combinatorial optimization problems with hard<br\/>capacity constraints. <br\/><br\/>The PIs will be focusing on hard capacity versions of network design<br\/>and facility location problems. These problems have applications in<br\/>networking and resource allocation and are among the central problems<br\/>in combinatorial optimization. As it has happened often in the past,<br\/>the PIs believe that techniques developed for solving these problems<br\/>will have broader impact in solving other combinatorial problems. <br\/><br\/>Training and fostering undergraduate as well as high school students<br\/>is a major emphasis of the broader impact of the proposed project.<br\/>The PIs' prior work with undergraduates have led to very good career<br\/>opportunities for many of them. The PIs will continue working with<br\/>students at Rutgers-Camden, fostering their raw talent and helping<br\/>them discover their own potential. The PIs will also continue working<br\/>with high school students, giving them exposure to theoretical<br\/>computer science and working on research with some of them.","title":"AF: Small: RUI: Network design and facility location problems","awardID":"1218620","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":[518386,518387],"PO":["565251"]},"193678":{"abstract":"This project develops incremental language processing techniques to enable spoken dialogue systems to communicate in a way that is more highly interactive, more efficient, and more human-like. Most previous dialogue systems have employed a strict turn-taking regime in which one person speaks at a time, no attempt is made to understand or respond to speech until the speaker finishes speaking, and the overall latency in system responses is high in comparison to human-human conversation. This results in systems that are unable to provide a range of rapid and overlapping responses that human interlocutors frequently use to achieve an efficient and successful communication process, including back-channels, interruptions, collaborative completions, clarifications, and other rapid responses. This project is a computational and empirical investigation into how a system's assessment of its own incremental understanding of ongoing user speech can guide its strategic decisions to initiate such rapid and overlapping responses. The feature representations and response policies that can implement this decision-making are studied in the context of two fast-paced interactive dialogue games. These games are carefully chosen to support objective evaluation of incremental response strategies and fun gameplay that facilitates large-scale data collection.<br\/><br\/>The resulting computational models may improve the conversational skills of a range of dialogue systems, including not only game-oriented systems but also practical applications such as intelligent tutoring and training systems, information access systems, and entertainment applications. A second product of this project is an annotated corpus of human-human and human-system dialogue data for use by other researchers. A third product is the incorporation of relevant software into a publicly distributed toolkit for building dialogue systems, supporting further research and education.","title":"RI: Small: Incremental Speech Processing for Rapid Dialogue","awardID":"1219253","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["560564",518675,518676],"PO":["565215"]},"193326":{"abstract":"In many physical and engineering applications one needs to solve ``ill-posed'' or ``ill-conditioned'' computational problems, i.e. problems such that a small perturbation of the input substantially changes the output. The objective of the project is to tackle the following ill-posed or ill-conditioned problems:<br\/><br\/>1. Solution of consistent overdetermined systems of polynomial equations, i.e. systems with more equations than unknowns. The coefficients of the input polynomials may be given only with limited accuracy due to measurement or rounding errors, thus the actual input system may be inconsistent. Such ill-posed problems arise for example in geometric modeling, robotics, or computer vision. <br\/><br\/>2. Decomposition of symmetric tensors which have low rank, or equivalently, decomposition of homogeneous polynomials into minimal sums of powers of linear forms. Again, small perturbations of the entries of the tensor will increase the rank to the ``generic rank'', so the structure of the decomposition changes, thus the problem is ill-posed. Low rank tensors have been utilized in numerous application areas where two-dimensional matrix representation of data was not sufficient for obtaining satisfying data analysis, including image and signal processing, algebraic complexity theory, higher order statistics, etc. <br\/><br\/>3. Solution of polynomial systems of equations which have root multiplicities. Small perturbations of the coefficients will create clusters of roots, completely changing the root structure, so these systems are ill-posed. Furthermore, roots of systems near ones with multiple roots are very sensitive to coefficient perturbations, thus they are ill-conditioned. These systems pose significant difficulties for global numerical solvers, and the distance from such degenerate systems is closely related to the computational complexity of such solvers. <br\/><br\/>Although distant in appearance, these problems will be tackled using very similar techniques: convert them into well-conditioned optimization problems based on the underlying geometry that made these problems ill-posed, analyze output sensitivity under perturbations of the input, and apply relaxation techniques to improve efficiency. This project builds on the PI's and her collaborators' previous results, further advancing the understanding of how these different symbolic-numeric techniques relate to each other, and finding a unified platform which enhance their efficiency and robustness.","title":"AF: Small: Relaxation Techniques in Symbolic-Numeric Computation","awardID":"1217557","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[517853],"PO":["565157"]},"192116":{"abstract":"The goal of this project is to develop a next-generation socio-computational citizen science platform that combines the efforts of human classifiers with those of computational systems to maximize the efficiency with which human attention can be used. Dealing with the flood of digital data that confronts researchers is the fundamental challenge of twenty-first century research. New techniques, tools and strategies for dealing with massive data sets, whether they consist of vast numbers of base-pair DNA sequences or terabytes of data from all-sky astronomical surveys, present an opportunity to establish a new paradigm of scientific discovery, but the task is not easy. In many areas of research, the relentless growth of data sets has led to the adoption of increasingly automated and unsupervised methods of classification. In many cases, this has led to degradation in classification quality, with machine learning and computer vision unable to replicate the successes of human pattern recognition. The growth of citizen science on the web has provided a temporary solution to this problem, demonstrating that it is possible to recruit hundreds of thousands of volunteers to make an authentic contribution to results, boosting human analysis through the collective wisdom of a crowd of classifiers. However, human classifiers alone will not be able to cope with expected flood of data from future scientific instruments. <br\/><br\/>This research will be carried out by a partnership between computer and social scientists, addressing research problems both in automated data analysis and social science through systems implementation, alongside field research and experiments with project participants. The intellectual merit of this project lies in its contribution to advancing knowledge and understanding in multiple domains of science. First, the work will contribute to developing new methods of computational data analysis, initially with analysis of astronomical images, and later extending to additional fields. Second, the project includes social science research to test and apply theories of human motivation and learning in an online context, which can then be applied to a broad range of social-computational problems. By mixing human and computational elements, the planned system has the potential to transform the application of citizen science and its approach to data analysis. <br\/><br\/>This project will advance science while promoting teaching, training and learning. One of the most significant broader impacts for its citizen science activities is enabling a community of hundreds of thousands of volunteers to participate in research, a powerful and rapidly developing form of informal science education. By choosing the relatively generic topic of image classification, beginning with astronomy but not limited to that field of science, the techniques developed under this grant will be of significant value to future investigations in similar research areas, thus enhancing the infrastructure for research and education.","title":"SoCS: Collaborative Research: Focusing Attention to Improve the Performance of Citizen Science Systems: Beautiful Images and Perceptive Observers","awardID":"1211094","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":[514880,514881],"PO":["565215"]},"193216":{"abstract":"The purpose of this project is to shed light on two important questions in science education and cyberlearning: (1) How can we study and support the ways in which students learn to use simulation and data analysis technologies as tools of scientific discourse? (2) What is the pedagogical potential of such an approach? The project explores the feasibility of a novel web-based modeling environment, SiMSAM, that will allow students in grades 5-8 to easily produce dynamic Stop-Action Motion animations that illustrate scientific events using everyday materials (e.g., construction paper, cotton balls, drawing, etc.) with which they are already familiar; analogous computer simulations using a novel visual interface that allows them to import and \"give instructions\" to images from their original animations; collect, analyze, and graph data generated by their simulations; and share, trade, and test their creations. Students use SiMSAM to explore kinetic molecular phenomena by completing activities that invite them to represent \"unseen\" events involving air pressure, sound propagation, and evaporation. Analysis focuses on new forms of learning afforded by the tool (especially the adoption of simulation and data analysis as tools of scientific discourse) and identifying potential shifts in students' reasoning about causal mechanism in the modeled phenomena, their adoption of kinetic molecular theory as a conceptual model, and their understanding of the nature of scientific models in STEM disciplines. The project integrates contemporary learning theory regarding the value of students' productive resources for reasoning about scientific and mathematical topics, model-based approaches in science and mathematics education, and the importance of computational simulation as a pedagogical and professional tool.<br\/><br\/>This project will prototype new technologies that will allow middle-school students to learn science through scientific modeling, an approach with potential for promoting deep understanding of the mechanisms underlying phenomena in the world. The software, called SimSAM, allows students to create animations and simulations of phenomena related to molecular kinetics - an important content area across grades K-16. The technology uses cross-platform, web-based technologies that do not require a special device or download and will thus be easily usable in schools without the need to download specialized software applications. The project's products will include curriculum materials for promoting learning the particle theory of matter and software that can eventually become a robust toolkit for students to engage with a wide variety of dynamic scientific phenomena across the science curriculum.","title":"EXP: SiMSAM: Bridging Student, Scientific, and Mathematical Models with Expressive Technologies","awardID":"1217100","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":["562842",517584],"PO":["562669"]},"193458":{"abstract":"This project is focused on developing new speech processing techniques which will transform access to large asynchronous multi-channel and diverse collections of multimedia materials. In particular, the algorithms developed are being employed to create a novel multi-source and multi-scale event reconstruction system that brings together the massive archives of the Apollo lunar missions, to create experiential interaction with historical materials. Specific research advancements are focused on state of the art acoustic environment analysis, speech recognition including keyword spotting, speaker identification under adverse conditions, multimodal content alignment, and automated linking for events and entities from spoken content. Specifically, the research is developing: (i) new techniques for noise- and channel-robust acoustic processing, exploiting missing-features concepts with novel feature extraction and compensation techniques, (ii) a new articulatory framework for speech recognition for robustness to variations in speech production, (iii) environmental \"sniffing\" techniques to automatically characterize acoustic environments to improve robustness, and (iv) automatic detection of novel task-specific audio-events. Since the data is asynchronous, unique speech analytics techniques are being formulated to address the large number of \"local loop\" intercom circuits in the NASA Mission Control Center, audio recorded onboard the two Apollo spacecrafts during specific mission events, and space-to-ground radio circuits. The specific speech, language, and knowledge extraction advancements will be integrated into a new automated evaluation model that reflects specific challenges encountered in the event reconstruction task. This platform will be deployed and evaluated by actual users from the Science and Engineering Education Center (SEEC) of the University of Texas at Dallas. <br\/><br\/>Integration of robust speech processing algorithms with event reconstruction systems will have a direct and immediate impact on education, society, and government organizations. Working with NASA's Apollo mission data allows for the development of speech technology for challenging audio that contains severe communication channel artifacts, cross-talk\/static\/tones, and low signal-to-noise ratios. The software being developed in this project will be made available to any non-profit organization for use in audio\/video search (download with training modules). Students working on senior design teams will also develop a Contact Science station to be deployed in Dallas, TX and overseen by the University of Texas in Dallas Science and Engineering Education Center to illustrate and assess student use of the advancements. As a lasting legacy for this project, this project team includes eminent historians of human space flight, who will explore opportunities to deploy this event reconstruction system in a museum setting where it can support both scholarship and public engagement, and we will make the system itself available on an open-source basis to support other researchers.","title":"RI: Small: Collaborative Research: 'Houston, We Have a Solution': Novel Speech Processing Advancements for Analysis of Large Asynchronous Multi-Channel Audio Corpora","awardID":"1218159","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["543582"],"PO":["565215"]},"193579":{"abstract":"Pseudorandomness and randomness extraction are motivated by the amazing utility of randomness in computing. When simulating complex phenomena, such as the weather or the economy, it is standard to include random components. Computer security is impossible without randomness. In practice, however, it is expensive to get truly random numbers, if it is possible at all. What can we do with a small amount of high-quality randomness, or a large amount of low-quality randomness? Pseudorandom generators are designed to attack the first question, and randomness extractors the second. The PI proposes to strengthen constructions of these fundamental objects.<br\/><br\/>Not only will this help advance computer science, but it could enable progress in other fields of science which use randomized simulations. Moreover, constructions of such pseudorandom objects often have unexpected applications. For example, the PI recently showed how related pseudorandom objects -- ``expander graphs\" -- can be used to construct financial derivatives that cannot be significantly manipulated. A more common application area is cryptography, the mathematical foundation of computer security.","title":"AF:Small:Pseudorandomness and Randomness Extraction","awardID":"1218723","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[518438],"PO":["565157"]},"193469":{"abstract":"Complex systems, such as living cells and the Internet, involve interactions and associations between large numbers of individual components. Specific examples include interactions between proteins in biological cells and connections between users in communication networks. Developing theory and methods to model and analyze large-scale networked systems is a grand challenge for the 21st century. For instance, new mathematical methods will lead to better models of biological systems and thus improvements in disease prevention. Measuring the signals of such systems is a crucial step in developing good models, and a major hurdle is that it is often impractical or impossible to measure all variables in large systems. This project addresses the hurdle by developing adaptive methods that automatically adjust the measurement process by using information gleaned from previously collected data in order to focus and optimize the gathering of new information. Ultimately, these methods will dramatically accelerate the pace of discovery in science and engineering.<br\/><br\/>The main theme of the project is an investigation of the role of adaptive measurement, sensing and experimentation in large complex systems of many variables. Adaptive methods are sequential procedures that optimize the selection of the next measurements or experiments based on previously gathered data. The research involves the development of a general theory for adaptive measurement that is applicable to various domains of engineering and science. The main goals are to mathematically characterize and quantify the advantages of adaptive measurements relative to non-adaptive methods and to design optimal adaptive measurement procedures. The investigation also explores the potential of adaptive methods by studying specific problems and applications in biology, national security, and human-computer interaction.","title":"CIF: Small: Adaptive Information: Sequential Sensing and Active Learning Theory, Methods and Applications","awardID":"1218189","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"L564","name":"National Security Agency"}}],"PIcoPI":[518179],"PO":["564898"]},"193029":{"abstract":"The most important task for scientific computing is to plan the way forward from the current era of multicore microprocessors implemented in deeply submicron CMOS. This has to be done in such a way that performance improvements are guaranteed. Otherwise the escalating costs of fabrication at the nanometer scale will not be sustainable. Heterogeneous multiple core microprocessors face several major problems, not the least of which is codified in Amdahl?s Law, which shows that even relatively small amounts of serial or low-parallelism code can limit the gains that are possible. It is clear that the ultimate way to circumvent this dilemma is to greatly accelerate the serial code using a high clock rate unit (HCRU) core using a ?beyond-CMOS? device approach. Past research suggests that clock rates of 20-30 GHz are possible for many key components using BiCMOS, but 3D technology is needed to mitigate memory wall problems. This research explores a brand new 90nm IBM SiGe HBT (300GHz fT) BiCMOS process to accomplish this goal while trading excess speed for 4X lower power. The strategy will be to redesign certain critical components of a computer in this new process to verify that the same high speed is obtained at a lower power. The second thrust of the project is to verify by high-level simulation that the execution of serial code at a high clock rate will in fact result in the expected improvement in performance. This is to be conducted using the Wind River SIMICS simulation package.","title":"CSR: Small: Simulation of Multicore Processors with One (or More) Fast Core(s) Using Wind River SIMICS","awardID":"1216352","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[517103],"PO":["565255"]},"198628":{"abstract":"Modern smartphones are notorious for consuming energy far too quickly, especially for access to the Internet through wireless radios.<br\/>Although certain advances have been made on the hardware side such as better batteries, this research is focused on improving energy management software to make better use of existing batteries.<br\/>Considering that the frequency of use of these radios is spurred by the popularity of smartphone applications, the wide availability of applications, for instance the Android Market has over 500,000 registered applications, shows that the need to save smartphone radio energy is highly relevant and urgent today.<br\/><br\/>Different from existing research, this high-risk high-reward research takes a network traffic aware approach to save smartphone radio energy. The main intellectual merits include: (1) Solutions for determining low priority delay tolerant smartphone applications without assistant from application developers. (2) Solutions for determining delay tolerant traffic periods within high priority real-time smartphone applications. (3) Solutions for tracking low priority delay tolerant applications, and delay tolerant traffic periods in high priority real-time applications through the system to optimize radio energy efficiency.<br\/><br\/>This research will extend smartphone battery lifetime with the potential to benefit over one billion smartphone users worldwide. User experience of smartphone usage will be enhanced. Industry smartphone practice will also be improved. This research will be integrated into three courses, and also benefit research of female graduate students and undergraduate students. Special distribution efforts are also planned to increase the number of women and girls in computing.","title":"CSR: EAGER: Network Traffic Aware Smartphone Energy Savings","awardID":"1250180","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["545346"],"PO":["565255"]},"190841":{"abstract":"Linguistic code switching (LCS) is the practice of switching back and forth between the shared languages of bilingual or multilingual speakers. This phenomenon is particularly prevalent in geographic regions with linguistic boundaries or where there are large immigrant groups. Various levels of language (phonological, morphological, syntactic, semantic and discourse-pragmatic) may be implicated in LCS in different language pairs and\/or genres. Computational algorithms trained for a single language quickly break down when the input includes LCS. A major barrier to research on LCS in computational linguistics (CL) has been the lack of large, accurately annotated corpora of LCS data. In this project, a large repository of LCS data is collected and a large annotation infrastructure is developed. It is consistently annotated in different modalities (speech and text), at various levels of linguistic granularity, and across different language pairs reflecting different linguistic typologies (Standard Arabic and Dialectal Arabic, Arabic-English, Spanish-English, Chinese-English, Hindi-English). The focus of the effort is on intra-sentential LCS.<br\/><br\/>This infrastructure and unified large LCS data resource is eagerly awaited by the CL research community, since annotated LCS data provides a natural test-bed for adaptive learning algorithms and the handling of diverse data sources, as well as a framework for genuine multilingual processing. It will also be of benefit to sociolinguistic and theoretical linguistic researchers, and provide a platform for collaborative interdisciplinary research. Finally, research on LCS helps overcome biases against multilingual speakers by demonstrating the creativity of such speakers in exploiting their verbal repertoires. Such a result is particularly important for K-12 education and testing policies in the USA with its diverse immigrant population.","title":"CI-ADDO-NEW: Collaborative Research: A Repository for Annotating Multilingual Code Switched Data","awardID":"1205556","effectiveDate":"2012-09-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[511614,"560340"],"PO":["565215"]},"191523":{"abstract":"In order for robots to collaborate efficiently and effectively with humans, the human perception of their movement must be considered in motion creation. Because a human collaborator will interpret the movements of a robot (even subconsciously), robot motion synthesis algorithms that do not consider the human observer may create motions that are perceived incorrectly, interpreted negatively (e.g. as being angry or threatening), or at least miss out on the opportunity to use this subtle communication channel effectively. The key idea of this project is to develop an understanding of human perception of movement that can be applied to the development of robot trajectory planning and control algorithms. The team will use human subjects experiments to understand and evaluate the interpretation of movements and apply these findings in robotics and motion synthesis. The research plan interleaves empirical studies of how people interpret motions, algorithm development to create methods that generate robot motions in a controllable manner, and contextualized deployments that allow the PIs to evaluate the success of the methods. The success of the project will provide a deeper understanding of how people interpret movements, new algorithms for synthesizing robot movements, and demonstrations of the potential applications of collaborative robots.<br\/><br\/>Broader Impact: Perceptually inspired robot motion synthesis algorithms will enable robots to collaborate more effectively with people. It will enable more communicative robots that can serve as teachers and guides; more approachable and acceptable robots that can work in domestic situations such as elder care; more cooperative robots that can work as assistants to workers; and easier to instruct robots that can be trained by non-experts. This project will enhance the education and outreach efforts of hte PIs by connecting empirical human studies to the technical challenges of robot trajectory planning.","title":"NRI-Small: Perceptually Inspired Dynamics for Robot Arm Motion","awardID":"1208632","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":["555023","520932","531411"],"PO":["564069"]},"194702":{"abstract":"One of the keys to scientific progress is the sharing of research data. When the data contain information about human subjects, the incentives not to share data are stronger. The biggest concern is privacy - specific information about individuals must be protected at all times. Recent advances in mathematical notions of privacy have raised the hope that the data can be properly sanitized and distributed to other research groups without revealing information about any individual. In order to make this effort worthwhile, the sanitized data must be useful for statistical analysis. This project addresses the research challenges in making the sanitized data useful. The first part of the project deals with the design of algorithms that produce useful sanitized data subject to privacy constraints. The second part of the project deals with the development of tools for the statistical analysis of sanitized data. Existing statistical routines are not designed for the types of complex noise patterns that are found in sanitized data; their naive use will often result in missed discoveries or false claims of statistical significance. The target application for this project is a social science dataset with geographic characteristics. The intellectual merit of this proposal is the development of a utility theory for algorithms that sanitize data and statistical tools for their analysis. The broader impact is the improved ability of research groups to share useful, but privacy-preserving, research data.","title":"TWC SBES: Medium: Utility for Private Data Sharing in Social Science","awardID":"1228669","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[521518,521519,521520],"PO":["559060"]},"194823":{"abstract":"Proposal #: 12-29176<br\/>PI(s): Parker, Lynn E.<br\/> Arel, Itamar; Corbetta, Daniela; MAcLennan, Bruce J.; Reynolds, Gregory D.<br\/>Institution: University of Tennessee - Knoxville<br\/>Title: MRI\/Acq.: Infant\/Robot Grasp Learning Instrumentation<br\/>Project Proposed:<br\/>This project, acquiring equipment to create an instrument for social robot learning from human infant studies, aims to transform the development of human-interactive robots by applying fundamental scientific paradigms from developmental psychology studies in infants to new ways of designing autonomous robots. Specifically, the research utilizes data from human infant perceptual-motor learning studies in reaching and grasping to build comprehensive models of human sensorimotor control that achieve embodied learning like that exhibited by infants. These models will then be instantiated in a robotic setting to create a machine that can autonomously acquire shared object manipulation skills through bottom-up and top-down processes mimicking human infant learning. The equipment will facilitate multiple research thrusts within the grand scope of understanding and improving human-robot interaction. The thrusts include: <br\/>- Study of biologically-plausible visual attention mechanisms, <br\/>- Adaptive visually-guided motor skills, and <br\/>- Inference of human state. <br\/>Infant visual search patterns, from which models of perception will be developed, will be acquired via the eye tracking system. The robotic arm system will serve as a platform for extensive studies on perceptual motor skills. The instrumentation should enable the following outcomes: <br\/>- Yield robotic systems able to learn to physically interact with humans through shared object manipulation. These systems will learn skills that allow handling of previously unseen objects.<br\/>- Facilitate human-robot interaction, especially regarding manipulation, grasping, and handling capabilities, as well as eye-tracking, to better study the role of vision in infant grasp and reach learning. <br\/>- Contribute significantly to the integration of two bodies of research ? psychology and engineering ? coupled through the computational models built. These computational models will provide a two-way exchange of ideas between psychology and engineering, <br\/>- Lead both to the design of new experiments in psychology and to new mechanisms for interactive robots. <br\/>These systems will learn skills that allow handling of previously unseen objects. Facilitating robot interaction will permit to better study the role of vision in infant grasp and reach learning. These computational models will provide a two-way exchange of ideas between psychology and engineering leading to the design of new experiments in psychology and to new mechanisms for interactive robots.<br\/>Broader Impacts<br\/>The instrument, initially used by 7 faculty in 3 departments across 2 colleges, will offer new opportunities for cross-disciplinary training in the fields of cognitive psychology, developmental cognitive neuroscience, computer science, computer engineering, electrical engineering, and mechanical engineering, for both graduate and undergraduate students. The enabled research is also expected to offer significant practical societal impact, as many potential applications of human-robot interaction involve the exchange of objects (e.g., an assistive robot picking up a dropped TV remote control for a disabled person, a delivery robot handing a package to a human, or a therapeutic robot handing a toy to an autistic child). The work may have implications for addressing developmental problems in children, emanating from the increased understanding of the perceptual and motor learning processes in infants. Moreover, the instrumentation provides experiental and cross-disciplinary opportunities that buttress classroom theory, thus providing a positive impact to education, students, faculty, K-12 teachers, museums, etc.","title":"MRI: Acquisition of Infant\/Robot Grasp Learning Instrumentation","awardID":"1229176","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[521958,521959,521960,521961,521962],"PO":["557609"]},"193613":{"abstract":"ABSTRACT<br\/><br\/>CIF: Small: Fast In Vivo Optical Imaging in the Heavily and Weakly Scattering Regimes<br\/><br\/>Kevin Webb, Purdue University<br\/><br\/><br\/>Optical imaging is important in medicine because it provides unique information about human health and an avenue for inexpensive and portable instruments for laboratory, clinical and home use. Within a deep-tissue optical diffusion tomography framework, it becomes possible to determine chemical and molecular information for blood chemistry monitoring and understanding diseases. The research on faster and more accurate deep-tissue imaging is a critical step in facilitating more widespread use of optics in medical research and for treatment. Another important challenge for in vivo optical imaging is access to the regime within a few millimeters of the skin, with application to skin cancer, for example. This research involves the development of a method that describes optical tissue properties on this near-surface length scale and hence provides a basis for imaging. Collectively, this work will be important in applications like the early detection of cancer, intra-operative imaging to ensure all tumor nodules are removed during surgery, and blood chemistry monitoring.<br\/><br\/>More specifically, various optical diffusion tomography modalities describing scatter and absorption, fluorescence, and fluorescence resonance energy transfer parameters are being developed. The approach avoids a background scattering emulsion, in which the subject is placed, by use of a laser body scan to define the geometry and an unstructured mesh forward model based on the diffusion equation. In this work, a multigrid method coupled to the unstructured mesh permits fast and accurate imaging. In the weakly scattering regime, an imaging method based on the Bethe-Salpeter equation that uses a rigorous field correlation over space and frequency is being developed.","title":"CIF: Small: Fast In Vivo Optical Imaging in the Heavily and Weakly Scattering Regimes","awardID":"1218909","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[518523],"PO":["564898"]},"194713":{"abstract":"Access control schemes are traditionally compared in terms of raw expressive power (i.e., the policies they can encode and how those policies can be changed); however, such comparisons ignore the needs of the application within which a scheme will be deployed. For some applications, the most expressive scheme may be overly complex and not necessarily the best fit. To this end, this project investigates the suitability analysis problem: Given a system's access control workload, a set of candidate access control schemes, and a set of application-specific cost metrics, which scheme best meets the needs of the system?<br\/><br\/>The goal is to create a suitability-analysis framework that is sufficiently rigorous to be useful to researchers and theoreticians, while remaining accessible to security practitioners. Such a framework will help formalize an access control scheme's application-specific strengths and limitations, enable researchers to precisely describe the scenarios for which a scheme is best suited, allow assessment of the novelty and utility of proposed schemes, and help analysts diagnose shortcomings in existing systems. In particular, the project will develop (1) an application-specific, workload-based framework for analyzing the suitability of access control schemes that is sufficiently rich to compare logical, extensional, and hybrid schemes in both sequential and concurrent systems; (2) a cost analysis component that quantifies a scheme's suitability using custom metrics; and (3) tools that automate a range of suitability analysis tasks. A real-world security workload, PKI-based authentication and authorization on the web, will be used to evaluate the results.","title":"TWC: Medium: Collaborative: Foundations of Application-Sensitive Access Control Evaluation","awardID":"1228697","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["534206"],"PO":["562974"]},"193503":{"abstract":"Program analysis provides solid foundations for a broad range of applications, such as detecting security vulnerabilities, localizing program faults, proving program correctness, and optimizing performance. A pervasive and critical challenge in program analysis is to handle library functions and system calls, which provide an essential execution environment for a program and would be ideal to be co-analyzed with the program itself. Despite its importance, achieving program-environment co-analysis in practice is challenging. First, the difficulty to acquire the source code of some environmental functions precludes source code based analysis. Moreover, even if source code is available, the code base is often prohibitively large and complex, making analysis difficult. Existing solutions are to provide program analysis with either manually-constructed models, which do not scale, or imprecise models, which are overly conservative.<br\/><br\/>In this project, the goal is to apply program synthesis technique to construct models for environmental functions from their binary implementation and a set of initial inputs. The models are essentially programs that provide the same functionality of the functions being modeled, yet substantially simplified. Such programs can be included as part of the application, enabling program-environment co-analysis. The proposed technique will lead to an automated solution that will offload the onus of manually crafting models from program analysis developers' shoulders. Moreover, it will demonstrate the feasibility of precise program-environment co-analysis through applications.","title":"SHF: CSR: Small: Collaborative Research: Automated Model Synthesis of Library and System Functions for Program-Environment Co-Analysis","awardID":"1218358","effectiveDate":"2012-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["550532"],"PO":["564388"]},"193624":{"abstract":"Researchers and decision makers in diverse fields such as <br\/>fraud detection, genome sequencing, and datacenter<br\/>management need to process many terabytes of data every day. <br\/>Many fields are turning to MapReduce systems to process such <br\/>growing datasets. Consequently, the relatively young MapReduce<br\/>ecosystem has to support complex workloads that include <br\/>declarative queries for report generation, MapReduce <br\/>programs for machine learning tasks, and large job workflows.<br\/>Furthermore, elastic and pay-as-you-go cloud platforms pose novel <br\/>challenges and opportunities for MapReduce workload management.<br\/><br\/>This project is building the Hadoop AutoAdmin system for <br\/>automating MapReduce workload management. To the PI's knowledge, <br\/>Hadoop AutoAdmin is the first system to address this challenging <br\/>problem that will become increasingly important as a broad class <br\/>of users adopt MapReduce. Hadoop AutoAdmin has three research <br\/>thrusts. The first thrust is to understand and characterize the <br\/>behavior of MapReduce workloads based on a comprehensive empirical <br\/>study involving workloads and data from multiple application domains <br\/>as well as different cluster configurations on the cloud. The second <br\/>thrust is to develop an easy-to-use and efficient warehouse to <br\/>store, retrieve, and visualize the diverse forms of workload <br\/>monitoring data. The models and insights from these activities will <br\/>drive the third thrust of developing end-to-end algorithms for <br\/>workload management.<br\/><br\/>This project can have significant impact in areas of national <br\/>importance like security and healthcare that are inundated with <br\/>data. Hadoop AutoAdmin will improve worker productivity, system <br\/>utilization, and cost-effectiveness of cloud platforms. The <br\/>technical contributions will be disseminated broadly and the <br\/>system released publicly.","title":"III: Small: MapReduce Workload Management","awardID":"1218981","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550820"],"PO":["565255"]},"193514":{"abstract":"The increasing importance of ?big data?, i.e., the usage of computer systems to store and analyze large data sets, is changing the face of both science and industry. Underlying big-data analyses are big-data storage systems, including the popular Hadoop File System (HDFS). The WiS3C project seeks to re-examine the core foundations of storage systems such as HDFS, specifically by developing new specialized storage techniques to improve both the reliability and performance of these systems. The project specifically targets novel modifications in crash consistency (i.e. how storage systems keep data safe despite power loss), end-to-end data integrity (i.e., how storage systems ensure data does not become corrupt), and caching and layout (i.e., how storage systems make access to data fast); the sum of these changes will result in a new era of more robust and high-performance big-data analysis. The project will also improve the educational pipeline by connecting more undergraduates with research and attracting more women into the Ph.D. program.","title":"CSR: Small:The Wisconsin Specialized Support for Storage Clouds (WiS3C) Project","awardID":"1218405","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550389","550390"],"PO":["565255"]},"193635":{"abstract":"In the multicore era, a major programming task is to make existing sequential programs parallel. One approach to parallelizing an existing sequential program is to rewrite it from scratch. However, the most common way is to parallelize a program incrementally, by changing the existing code. Each small step can be seen as a behavior-preserving transformation, i.e., a refactoring. While refactoring is more economical than rewriting, it is still tedious because it requires changing many lines of code, and it is error-prone and non-trivial because programmers need to ensure non-interference of parallel operations.<br\/><br\/>This project aims to significantly enrich educational resources and programmers' toolset for refactoring sequential programs for parallelism and improving the performance of already parallel programs. The PIs plan to pursue research activities in three areas:<br\/>(1) mining refactorings by studying the evolution of widely used open-source programs; (2) automating refactorings for parallelism that programmers frequently use; and (3) suggesting refactorings that offer several candidate programs with different trade-offs in terms of performance or thread-safety. This project has the potential to revolutionize how programmers parallelize software, to educate them about successful parallelization techniques, and to significantly reduce the cost and increase the quality of their code.","title":"SHF: Small: Interactive Refactoring for Multicore Parallelism","awardID":"1219027","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":[518573,518574],"PO":["564388"]},"192425":{"abstract":"The network properties underlying the circuit operations of the brain are still basically unknown. There is no complex brain in which the overall activity patterns have been observed in real time. This project will chart the major patterns of information flow in a small, complex brain, and analyze its functional network architecture. Treating the network in a totally unbiased way, it will generate data from artificial stimulation of brain circuits aimed at surveying the paths of information flow, without regard to why the brain is doing anything or what the output is. The task will be carried out in an unusual collaboration between experimental and computational neuroscientists and network theorists to chart information flow through the complex, but relatively small, brain of the fruit fly Drosophila and then to analyze the principles of network function that it reveals. The rationale for focusing on the fruit fly brain is that it is small enough to be possible to monitor its activity completely, but also complex enough (150,000 nerve cells) to offer solutions to the major problems of complex brain networks. In addition, the entire wiring pattern of its nerve cell connections is well under way and will soon be completed. The goal of this project is to characterize the network from the perspective of its underlying function and architecture, which not may not be identical with its actual physical layout. With the data in hand, a search will be conducted for the engineering the design principles embodied in the brain's networks. From these findings, a general theory of information flow in the brain will be formulated, based on the first broad-based, whole network analysis.<br\/><br\/>Intellectual Merit: The project aims at mining biological systems for principles and strategies that can be applied to problems in computing and engineering. At the same time, it tackles a major problem in neuroscience in a technically feasible fashion. The challenge to understanding the overall strategy used by the brain is the fact that, in its operations, the whole is greater than the sum of the parts. This feature, known as an \"emergent\" property, arises from the timing and patterns of signaling activity of many thousands of nerve cells. If one had access to that data, and could correlate the activity with the pattern of nerve cell connections brain, it would be possible to formulate a theoretical basis for large-scale neuronal coding. Understanding this process, in turn, holds substantial promise for applications in computing and engineering.<br\/><br\/>Broader Impact: <br\/>Educational Impact: In addition to providing the opportunity for training of graduate students, postdoctoral fellows, and undergraduates, a knowledge of the fundamental strategies of information processing in the brain would allow us to design educational strategies that take maximum advantage of that understanding. <br\/><br\/>Technological Impact: The principles and theoretical formulation that will emerge from this project also have the potential for providing novel strategies for computer network design and traffic flow of signals, and for engineering strategies that involve networks and information flow. The experiments outlined for this project constitute a new approach to the question of whether there are fundamental underlying principles of brain network operation which, if discerned, would have wide-ranging implications for applications such as the design and implementation of artificial networks constructed for computing, engineered devices, and communications. In addition, properties such as adaptability, versatility, and robustness are keenly sought in these areas, and efforts are aimed at being able to capture the ability of gene networks to carry them out.","title":"CIF: BCSP: Large: Connectivity and Information Flow in a Complex Brain","awardID":"1212778","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"7712","name":"ORGANIZATION"}}],"PIcoPI":[515695],"PO":["565223"]},"193404":{"abstract":"This project aims to study an array of important computational geometry problems in several applied areas such as medicine, biology, biomedical imaging, and data mining, and to develop new algorithmic solutions for these problems in biomedical applications. In addition, the project also seeks to investigate a set of fundamental theoretical geometric problems and to forge new geometric computing techniques.<br\/><br\/>Emerging biomedical imaging technologies and modalities have been revolutionizing the field of disease diagnosis and prognosis, pushing a paradigm shift in diagnosis and prognosis study and practice from qualitative to quantitative and from tissue\/structure level to molecular\/cellular level. Molecular\/cellular imaging holds the promise of transforming modern diagnosis and prognosis, and offers numerous advantages over the traditional practice. This project will apply geometric computing techniques and data mining methods to develop new algorithms for vital cell identification and analysis problems in microscopy images, such as computing and analyzing the architectural structures of dendritic cells and other types of cells in multi-spectral microscopy images of tumor-draining lymph nodes for prognosis of breast cancer, and detecting and classifying cells in histology images of joint tissue for diagnosis of rheumatoid arthritis and other autoimmune diseases. Radiation therapy\/surgery is a major modality for modern cancer treatment. This project will design new algorithms for an intriguing type of geometric motion planning problems that seek a set of paths to cover target tumor regions under special constraints and criteria. These problems arise in dynamic Gamma Knife radiosurgery and are at the core of a novel radiosurgery approach for breast cancer treatment. Besides, the project will develop new algorithmic techniques for solving a number of theoretical problems that are among the most fundamental tasks in computational geometry, such as computing optimal paths, visibility, Voronoi diagrams, geodesic diameters and centers, geometric clustering, and shape approximation. The research plan of the project includes a crucial component of algorithm implementation, experimentation, evaluation, software development, and practical applications. This research will integrate and enhance the power of computer algorithms and modern biomedicine to solve critical applied and theoretical problems in computational geometry and biomedical applications, and help improve the quality of life in today's society.","title":"AF: Small: Applied and Theoretical Algorithm Problems in Computational Geometry","awardID":"1217906","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[518029],"PO":["565157"]},"194735":{"abstract":"The operating system (OS) exercises complete control over applications, thus a compromise of the OS compromises every application. Software developers have little recourse to improve security in the face of system compromise---they cannot defend against OS vulnerabilities, nor can they reasonably substitute a secure version of the millions of lines of code that constitute a modern OS.<br\/><br\/>Rather than require applications to blindly trust OS interactions, this project investigates a system architecture that enables trusted applications to efficiently verify OS interactions with the help of a small, trusted hypervisor. Most verification work is performed within the C language runtime, minimizing changes to legacy code and shielding developers from increased programming complexity.<br\/>The prototype system, called InkTag,improves upon prior work in several key areas: it provides more efficient techniques to verify system call results, implements usable access control for resources managed by an untrusted OS, and introduces hardware and software techniques to further reduce the size of the trusted computing base.<br\/><br\/>Cloud computing provides energy and economic efficiencies, but suffers from the inability to give meaningful security guarantees to hosted applications. This project demonstrates that system security is possible without trusting the OS---a large part of the hosted infrastructure. This project is also developing new materials for undergraduate and graduate curricula that combine core knowledge of systems with an understanding of how systems provide security properties, equipping future computer professionals with a better understanding of what security guarantees a system can meaningfully provide.","title":"TWC: Medium: Collaborative: Trustworthy Programs Without A Trustworthy Operating System","awardID":"1228839","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[521618],"PO":["565327"]},"193646":{"abstract":"This research will study ways to ease the production and<br\/>use of high-performance matrix algebra software. Matrix algebra<br\/>calculations constitute the most time-consuming part of simulations<br\/>in diverse fields, and lowering the runtimes of those computations<br\/>can have a significant impact on overall application performance. The<br\/>process of converting matrix algebra from algorithm to high-quality<br\/>implementation is, however, a complex one. At each step, the code<br\/>developer is confronted with a myriad of possibilities, many requiring<br\/>expertise in numerical computation, mathematical software, compilers,<br\/>and computer architecture. In response to these difficulties, the PIs<br\/>have developed a prototype taxonomy implementation entitled Lighthouse,<br\/>which is a guide to the linear system solver routines from the software<br\/>package LAPACK. It is the first framework that combines a matrix algebra<br\/>software ontology with code generation and tuning capabilities. Its<br\/>interface is designed for users across a spectrum of disciplines, career<br\/>levels, and programming experience.<br\/><br\/>The PIs will dramatically extend the Lighthouse framework in a number of new directions. <br\/>First, they will construct a general taxonomy of software that can be used to build<br\/>highly-optimized mathematical applications. The taxonomy will initially<br\/>provide an organized ontology of software components for high-performance<br\/>matrix algebra and later other numerical software from a variety of<br\/>problem domains. It will serve as a guide to practitioners seeking<br\/>to learn what is available for their mathematical programming tasks,<br\/>how to use it, and how the various parts fit together. Second, the PIs<br\/>will apply a combination of source code analysis and machine learning<br\/>techniques to fully automate the generation of parameterized models that,<br\/>given representative inputs and a simple architecture description, can be<br\/>evaluated to identify methods from various libraries that best reflect<br\/>the user's resource and performance requirements. This automation is<br\/>critical for ensuring that the taxonomy is comprehensive enough to be<br\/>useful and that it accurately reflects the features and performance<br\/>of the latest versions of numerical libraries. Finally, the PIs will<br\/>advance the state-of-the-art in tuning tools by improving some of the<br\/>tools included in the taxonomy, broadening their ranges of functionality<br\/>in terms of problem domains and languages. This project will produce<br\/>the following impacts: greater performance by applications, enabling<br\/>both more discovery with available computing resources and greater<br\/>productivity of application programmers; greater understanding of the<br\/>interaction between architecture and algorithms; and an educational tool<br\/>for future computational scientists.","title":"SHF: Small: Collaborative Research: Lighthouse: Resource-Aware Advisor for High-Performance Linear Algebra","awardID":"1219089","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[518600],"PO":["565264"]},"193426":{"abstract":"With wireless sensor networks deployed in hostile environments, there is a need for cryptographic protection to enable secure communications services. Unfortunately, many approaches developed for general networking environments do not take into account the unique features of such wireless networks. Starting with the original scheme of Eschenauer and Gligor, random key predistribution schemes have been proposed to address this challenge. Much of the work on these schemes has been carried out under the full visibility assumption whereby sensor nodes are all within communication range of each other. However, the question remains whether randomized key predistribution schemes can indeed deliver the needed security guarantees under wireless communication constraints. To explore how this partial visibility affects two basic issues, namely secure connectivity and resiliency, we study random graph models which are obtained by intersecting two random graphs, namely a communication graph (to model the communications constraints of the wireless medium) and a cryptographic graph (to capture the given predistribution scheme). Our goal is to better understand performance trade-offs and to develop guidelines for dimensioning available cryptographic, communication and computing resources. <br\/><br\/>Intersecting two (or more) random graphs constitutes a modular approach for building graph models of greater complexity. Generally speaking, the structural properties of the random graph obtained by such intersection operations are determined by those of the intersecting random graphs. Since some of the component random graphs have been studied in the literature, existing results can be leveraged, and this makes the modeling paradigm quite appealing for dealing with the multi-dimensional applications encountered in wireless networking (and other areas). Technically, many of the questions of interest are asymptotic in nature (with the numbers of nodes becoming large). The project aims to make contributions on three fronts: (i) Advance the study of random graphs in new directions through probabilistic techniques; (ii) Develop a better understanding of new classes of random graphs which thus far seem to have received little attention in the literature; and (iii) Enhance one's understanding of security issues in some large-scale wireless networking environments.<br\/><br\/>Such issues are inherent to the many critical infrastructures which are monitored by wireless sensor networks, and random key predistribution techniques have a role to play in making these environments more secure. Some of these ideas are likely to be of use in less challenged wireless environments as well.","title":"CIF: Small: Random key predistribution in wireless sensor networks -- The impact of partial visibility","awardID":"1217997","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[518081],"PO":["564924"]},"193668":{"abstract":"The ability to accurately model such complex phenomena as the natural scene statistics inherent in stacks of photographs or movies, or the collective behavior of hundreds of simultaneously recorded neurons in the cerebral cortex, would be transformative for our understanding of the natural world and of human thought. The insights gained would not only enhance our understanding of the brain and the sensory stimuli it can process, but they would confer practical advantages as well -- leading to improvements in automated speech recognition and meaningful analysis of real-time video, for example. The various data needed for these studies is coming online at a rapid pace, but these large and complex data sets defy traditional modeling and analysis techniques. Unfortunately, the complexity and size of many recently acquired corpora in biology, physics, and engineering domains render them incapable of being fit by powerful mathematical models unless they are constrained by strong and unjustified assumptions about the data. This, coupled with the general difficulty of developing general purpose machine learning algorithms has driven most contemporary scientists and engineers to focus on algorithms tailored to narrow problem spaces rather than tackling the more general machine learning problem. Fortunately, some researchers have continued to push for general learning algorithms with capabilities more similar to human intelligence, but they have typically had to rely on ad hoc assumptions or uncontrolled approximations in order to make progress on this daunting problem. This proposal is to further develop a recently introduced machine learning technique, called Minimum Probability Flow learning, so that it is capable of fitting exceedingly general parametric models to much larger data sets than has ever been possible before. In addition, this proposal is to develop novel, complimentary methods for sampling efficiently from a model distribution once the parameters have been fit to data, so that the models can be understood and meaningfully compared with one another. These techniques will be used to study the statistical structure of natural scenes by fitting a new and powerful mathematical model to a database consisting of a large number of photographs. The program proposed here is highly interdisciplinary, drawing ideas and approaches from physics, engineering, computer science, and systems neuroscience.","title":"RI: Small: Efficient Learning Algorithms for Modeling Natural Data","awardID":"1219199","effectiveDate":"2012-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["539958"],"PO":["564318"]},"192106":{"abstract":"This project seeks to discover new knowledge required to support geodeliberation in community geospatial decision-making contexts. Geodeliberation refers to democratic deliberation (within local communities) on complex and controversial geographically-defined problems and involves the use of geographical information and online, asynchronous deliberative technologies. This research addresses two key knowledge gaps. One is the lack of understanding about human information and interaction behavior while engaging online asynchronous geodeliberation, and the methodological challenges of supporting community-scale deliberation of complex geospatial problems over sustained engagements. A more formidable gap is between the desirable level of public involvement and the practical level of participation that can be supported by the current social-technical solutions. To address these gaps, the research applies an ethnographically-guided participatory research approach to: (1) identify opportunities and barriers in using geodeliberation to empower communities; and (2) investigate visual-computational methods to enable human participation and facilitation of geodeliberation processes. <br\/><br\/>This research will contribute to the foundations of a science of geodeliberation, including both an understanding of key processes and a set of design techniques for social and visual-computational support of geodeliberation. It will focus on issue-related narratives about personal experiences, sensemaking with respect to synthesizing disparate geo-planning views and issues, and the development of public judgment and common ground for mutual understanding and collective action. These research activities are integrated around a prototype - GeoDeliberator. The approach will incorporate methods from three domains: cognitively-motivated design of visual representations and interfaces; models of deliberative discourse and decision-making in communities; and active facilitation of large-scale geodeliberation towards better coherence and effectiveness.<br\/><br\/>The research addresses broader impacts of three kinds. First, this project will demonstrate the potential of using information technology to improve civic engagement in community-level. Second, the design research investigation of socio-technical support for geodeliberation will provide a concrete model for local governments across the nation. Third, this project will prepare a generation of undergraduate and graduate students with consciousness and career potentials in applying social-technical solutions in the practice of democratic decision-making.","title":"SoCS: Geodeliberation: Enabling Democratic Decision-Making in Local Communities Through Place-Based Deliberative Dialogues","awardID":"1211059","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":[514854,"549541"],"PO":["564456"]},"194768":{"abstract":"Internet miscreants cooperate for profit in identity theft, denial of service, etc. \u00a0Meanwhile, defending organizations act separately and treat Internet information security (infosec) as a cost to be minimized. Customers could choose more wisely among competing Internet firms if they knew which had good or bad security, and such fame or shame would cause firms to improve security to retain and attract customers.<br\/><br\/>To verify such a policy of peer influence, this project uses a readily available stand-in for organizational infosec: outbound spam (unsolicited bulk email). \u00a0Other security problems may not cause outbound spam, and this project makes no claims to solve all problems. \u00a0However, just as a sneeze indicates disease, spam indicates poor infosec that could be exploited for even worse purposes (theft, denial of service, blackmail, etc.), and no organization wants to be seen to have such problems.<br\/><br\/>The project ranks similar organizations in SpamRankings.net, using daily data from multiple anti-spam blocklists, aggregating it from IP addresses into routing blocks (Autonomous Systems), and categorizing their owners by geography and type (hosting, medical, ISP, etc.). \u00a0Field experiments, including the relative effects of different publicity strategies, seek to determine whether publishing information on a symptom of infosec (outbound spam) causes firms to improve that symptom.<br\/><br\/>Positive experimental results will serve as stepping stones to policy recommendations of legislative mandates of timely and publicly accessible incident disclosure to enable more third-party peer rankings for further infosec improvement. \u00a0Minimal enforcement could thus catalyze significant improvements in Internet usability, profitability, and national security.","title":"TWC: Medium: Reputation as Public Policy for Internet Security","awardID":"1228990","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[521736,521737],"PO":["565327"]},"193679":{"abstract":"Many applications generate data that can be modeled as graphs: Biological networks, social networks, ecological networks and food-webs, among others. Traditional graph theory and most current research in graph modeling, querying, and mining concentrates on problems where the graph structure is inherently static and does not change with time. But networks in the real world are dynamic in nature with a wide range of temporal changes. While the topology of networks such as social networks and transportation networks undergoes gradual change (or evolution), the content (information flow, annotations) changes more rapidly. <br\/><br\/>Against this background, this project aims to develop a set of scalable querying and mining tools for dynamic graphs by integrating techniques from databases, data mining, and algorithms. The first research thrust examines inherent properties for characterizing dynamic graphs, specifically the dynamic reachability structure of nodes. It also investigates high-fidelity methods for generating dynamic graphs based on these properties. The second research thrust aims to develop summarization techniques for dynamic graph structures. These techniques can be used to compress large graph datasets, to make predictions about future values, and to query information cascades under partial observation. The third research thrust aims to develop techniques for mining significant dynamic subgraphs under different constraints of connectivity such as fixed subgraph structure, connected subgraphs, and smooth subgraphs. The goal is here to find anomalous patterns in dynamic graph datasets using a statistical characterization of background behavior. The final research thrust reconsiders the first three research thrusts from the point of view of content and topic models in order to understand the relationship between content of a message and its flow in a network. The developed methods will be evaluated using a number of real-world data sets including email datasets such as Enron, re-tweeting activity data sets on Twitter, Facebook wall posts, and transportation networks. <br\/><br\/>An important result of this work is a theoretically well-founded and empirically verifiable framework for modeling, querying and mining of dynamic graphs. Aspects of dynamic behavior in which both the structure of networks and their content (information flow, annotations, etc.) change will be considered. The study of such dynamic networks and how information flows through them is essential to developing a theory of dynamic networks and their evolution. This work helps answer questions such as power-law applies to dynamic behavior, whether content of a message can predict its flow and vice versa, whether anomalies in a dynamic network can be mined effectively by building either an empirical summary or a generative model. Robust open source tools based on the developed algorithms will be released for research, academic and non-profit endeavors. The research is expected to yield new techniques in graph algorithms, graph databases, and graph mining, and realize a collection of tools that can be used by scientists, and ultimately lead to a theory for dynamic graphs. <br\/><br\/>Broader Impacts: The proposed project will integrate research and education by introducing the results of the project into a graduate seminar, and a graduate course on information management. The project will support a postdoctoral researcher and train graduate students. The project offers enhanced opportunities for research-based training of graduate and undergraduate students, including members of under-represented groups e.g., females in Computer Science at the University of California at Santa Barbara. For high school students, the CNSI Apprentice Research Program at UCSB brings in high school students every summer. The open source implementations of algorithms resulting from this work will be freely disseminated to the community.","title":"III: Small: Modeling, Querying and Mining of Dynamic Graphs","awardID":"1219254","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["536697"],"PO":["565136"]},"193448":{"abstract":"Preventable errors in healthcare are a leading cause of patient injury and death. Despite considerable effort and the expenditure of billions of dollars, computerization has yet to improve the efficacy or safety of healthcare. To this problem, the PIs bring a novel insight: a prescription is a program. That is, they hypothesize that prescription writing is a long lost sibling of software engineering, using many computer programming constructs but without the benefit of the extensive conceptual framework provided by Computer Science. This project will test this hypothesis by exploiting software engineering and programming languages know?how to create a highly?intuitive, domain specific language for building and executing prescriptions. The PIs will then build and validate a \"patient oriented prescription\" to manage the care of patients with Gestational Diabetes Mellitus (GDM), a disease affecting 600,000 women annually.<br\/><br\/>Limitations of current GDM management include low patient adherence, modest efficacy of interventions, time?burden for clinicians, and cost. Using extensive archives of rich data from real patients, including diet, activity, glucose readings, and insulin use, the PIs will perform pure computer-based simulations that will help them determine how their POP-GDM program will respond to real-world data. They will also perform simulations with real clinicians, actor patients, and simulated inputs from smartphones, glucometers, and accelerometers in our state of the art medical simulation facility. The PIs expect this work to generate multiple new insights regarding the building and maintenance of multi-stage programs, the development of new kinds of analyses of programs, and the discovery of new general methods for developing high-reliability software that facilitates collaboration between machines and humans.","title":"SHF: Small: Collaborative Research: Designing a Patient-Oriented Prescription Language: An Executable Medical Algorithm for Gestational Diabetes Mellitus","awardID":"1218103","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[518130],"PO":["564588"]},"193569":{"abstract":"Now that computer technology appears to have reached the limit of Dennard scaling (increasing clock rates), software must become more parallel, to scale with hardware that provides more instead of faster cores. However, writing correct, scalable shared-memory concurrent programs is notoriously difficult. Transactional memory (TM) offers potential improvements over conventional shared-memory systems in programmability, reliability, and scalability. However, it has not lived up to its initial promise, primarily because no one has shown how to make it practical. Hardware manufacturers are reluctant to build hardware TM (HTM) into already-complex cache and memory subsystems, and software TM (STM) suffers from poor performance and weak semantics. This project seeks to advance the state of the art dramatically by investigating new research directions for making STM truly practical, by achieving high performance with strong semantics. The project tackles STM's key cost in existing work -- detecting and handling conflicting accesses -- using a novel mechanism that avoids synchronization at non-conflicting accesses.<br\/><br\/>Direct beneficial impacts of making widely available practical STM support include the ability to produce more reliable and scalable software systems, leading to advances in software for safety- and mission-critical systems. Widespread use of STM can help spur commercial development of hardware support for hybrid hardware-software TM, which requires practical STM support. The investigator's engagement with industrial researchers provides an avenue to enhance dissemination. Public distribution of STM implementations produced by this project provides a basis for further research and development. Several educational and outreach activities, including course projects, enhanced core course material, interactive presentations for a summer bridge program targeting minority undergraduate engineering majors, and recruiting events for prospective minority graduate students, aim to train a diverse group of programmers and researchers in developing future reliable, scalable software systems.","title":"CSR: Small: Making Software Transactional Memory More than a Research Toy","awardID":"1218695","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["534400"],"PO":["564778"]},"193217":{"abstract":"The performance of computers has improved tremendously in the past four decades, which has enabled innumerable applications that have major roles in our daily lives. However, without dramatic innovations in improving performance and power efficiency of computing, the continued semiconductor device scaling alone will fail to provide computing capabilities needed for future applications. One of the main performance bottlenecks of traditional computing systems has been the high cost of communications between central processing unit (CPU) and graphics processing unit (GPU). The on-chip integration of CPU and GPU dramatically reduces the cost of communications, but it also worsens power, thermal, and bandwidth issues for chip design. Nonetheless, it also allows new approaches to be explored that previously were not practical. Given the potential and challenges of on-chip integrated CPU+GPU processors, this project undertakes a multidisciplinary effort to improve performance and power efficiency of computers. Specifically, the project aims to (i) develop runtime algorithms for scheduling workload and memory accesses under power, thermal, bandwidth constraints; (ii) explore micoarchitectures for improving memory system performance under bandwidth constraints; and (iii) optimize heterogeneous technology choices for integrated CPU+GPU processors. <br\/><br\/>This project is expected to have significant impact on the technology, circuit, architecture, and runtime system communities, and it is leading to state-of-the-art research infrastructure. The project also contributes state-of-the art workforce training. The outcomes of this project benefit economic growth through technology advances that will provide increased computing capability at a lower cost.","title":"CNS: CSR: Small: Runtime System, Architecture, and Technology Codesign Approach for Heterogeneous Many-Core Processors and Clusters","awardID":"1217102","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[517586],"PO":["565255"]},"193459":{"abstract":"The objective of this project is to develop a better understanding of the relationships between the design features of tangible user interfaces (TUIs), the gestures used when thinking about creative tasks, and creative problem solving. There is an increasing interest in developing tangible user interfaces to digital environments that has resulted in a large number of graspable interactive devices. This project seeks correlations between tangible computing and cognition, and more specifically, with creative cognition, and then uses that correlation to impact the design of environments for tangible interaction. One hallmark of creative problem solving is the ability to solve a problem by recognizing its similarity to another already solved problem, particularly if the problems appear dissimilar on the surface, but share an underlying structure. The act of recognizing that two superficially different problems are analogous requires a key creative step, which can be characterized as making a mental leap. TUIs may facilitate a mental leap in creative problem solving by enhancing perception and therefore cognition of spatial or structural similarities. <br\/><br\/>The intellectual merit of the project, arising from the synthesis of the results of the observation and design sessions are: a methodology for studying children's activities while they use TUIs that has two parts: observation and design; a reusable coding scheme for observation data that is based on research in tangible computing, gesture and thought, and creativity; and design principles for tangible devices. <br\/><br\/>Broader impacts: The results of this project can be used to develop motivating learning technology for children and adults that encourage learning in non-traditional ways. The project will also have an impact on public and professional understanding of the role of tangible computing in education through an association with the University of Maryland HCILab activities and their association with pubic radio. The proposed project has benefits to society more broadly by focusing on the importance of creativity in education and learning, which leads to a more innovative and competitive society.","title":"HCC: Small: Designing Tangible Computing for Creativity","awardID":"1218160","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[518152,518153,"554479"],"PO":["564456"]},"198937":{"abstract":"Smart wireless devices are increasingly becoming the preferred method for accessing physical locations, bank accounts, and other valuable resources. However, their use for authentications comes with increased security considerations, since they can be stolen and are vulnerable to different types of software attacks. The objective of the research is to develop a new type of pervasive authentication for smart wireless networked systems based on macroscopic human behavior. The key hypothesis is that the regularity in a person's behavior can be used to uniquely identify her, as well as to substitute static passwords with one-time authentication challenges pertaining to her past behavior. To this end, this project will focus in three integrated components: (1) methodologies for behavioral data collection and authentication, spanning from physical layer fingerprinting techniques to privacy-preserving authentication protocols; (2) algorithms for discovering and modeling the regularity in a user's behavior to pervasively authenticate her; and (3) methods for generating one-time authentication challenges based on the user's preferences, schedules and routines. The expected result of the research is a radically new paradigm in authentication that will eliminate the risks associated with smart wireless devices, and can also find application in other domains such as online authentication. The research outcomes and parts of the developed authentication framework will be disseminated to the widest audience possible, including application developers, through the project?s website. The educational component of the project includes integration of the research agenda with curriculum development, and outreach activities that engage high-school students and underrepresented communities in computer science and engineering.","title":"EAGER: Human Behavior Based Authentication for Smart Wireless Networked Systems","awardID":"1251962","effectiveDate":"2012-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["560478",533706],"PO":["565303"]},"199828":{"abstract":"This PI team asks (i) how to use the affordances of modular robotics for distributing work among individuals in a student groups to promote both better engagement and better learning among those learning algebra and (ii) what can be learned more generally from this effort about orchestrating and supporting learning when learners have available to them technology that supports distributed group work. One PI, a mechanical engineer, brings a novel modular robotics platform to this collaboration, one that has many affordances for supporting algebra learning, is quite engaging and has been found to draw in students who otherwise might not become excited about math learning, and that has affordances for supporting distributed cognition and hence suggests some new ways of promoting and supporting collaborative learning. The second PI, a learning scientist and mathematics education researcher, brings expertise in math learning and a nuanced understanding of the ways distributed cognition can be leveraged to promote collaborative math learning. It is possible that there are aspects of collaborative learning that are uniquely afforded by the robotics materials of the first PI and the kinds of project-solving challenges that can be built up around them. And there may be new kinds of collaborative behaviors that arise from use of such manipulatives that suggests new avenues for promoting learning. This EAGER project supports first steps in creating synergy between these two approaches and in making these intriguing ideas about promoting collaboration and math learning concrete. The technological innovation in this project is in learning how to use manipulatives with affordances for supporting distributed cognition to promote collaboration and how to effectively integrate use of such manipulates with use of software designed for collaborative math problem solving. The research is directed at shedding light on how to take advantage of manipulatives that can support distributed cognition and hence collaborative learning, and discovering some of the new kinds of collaborative behaviors that might arise from activities with such manipulatives and how to take advantage of those (or alleviate them) in promoting learning.<br\/><br\/><br\/>The educational goals being addressed are both broader participation goals and learning goals, the idea being that \"play\" with engaging robots in the context of learning algebra and other disciplines will draw students in to the subject area at the same time it better promotes their learning. Algebra, in particular, is a gateway to more advanced STEM, and drawing more of the population into STEM careers requires drawing more of them into algebra learning and helping more of the population learn algebra well. The potential broader impacts are particularly strong with respect to gender and diversity. This project represents work in its early states on an untested but potentially transformative idea and is likely to catalyze rapid and innovative advances in the use of modular robotics and other computational manipulatives to broaden participation in STEM disciplines and promote deeper learning in those same disciplines.","title":"EAGER: Collaborative Mathematics Learning with Robots","awardID":"1256780","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":[535738,535739],"PO":["562669"]},"192910":{"abstract":"Private and widely dispersed information across individuals is pervasive aspect of economic environments. In financial markets, traders possess different information about the value of an asset; in labor markets, employees and employers have different information about the cost of a job. In the interaction of the individual agents, the nature of the private information held by the individuals influences the outcome of the entire economy. In particular, the structure of the interaction - the form of the network - determines the aggregate outcome. Yet from the point of view of an observer, be it as an analyst or a regulator or a legislator, the precise nature of the private information and network structure of the agents is rarely known.<br\/><br\/>The current research develops a method to analyze the behavior and the welfare in an economic environment, online as well as offline, independent of the structure of the private information and network structure of the agents. Concurrently, the investigators will analyze the extent to which the structure of the economic environments (payoffs, preferences) can be identified from the empirical data without knowledge of the exact information and network structure. The methods have epistemic and computational advantages over earlier approaches. The investigators will identify bounds on the statistical moments of the equilibrium distribution. Conversely, the statistical description of the equilibrium outcome allows the investigators to give precise bounds on how much can be learned from the data when the nature of the private information is unknown.<br\/><br\/>This new approach to networks with private information offers techniques to analyze the welfare implications of economic rules and institutions by providing bounds that are independent of the knowledge of the information and network structure. The method allows the investigators to assess the implications of different policies and regulations regarding information disclosure, trading restrictions, and reserve requirements that are independent of the specific information held by the economic agents.","title":"ICES: Small: Collaborative Research: Interaction, Information and Identification","awardID":"1215808","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"1320","name":"ECONOMICS"}}],"PIcoPI":[516801],"PO":["565251"]},"190853":{"abstract":"Computing increasingly permeates daily lives, yet few appreciate the growing presence of Parallel and Distributed Computing (PDC) in common computing activities; e.g., modern laptops' processors contain multiple cores and special-purpose devices such as graphics processors (GPUs). With increasing availability of powerful PDC technology, familiarity with single-processor computers and sequential computing no longer constitutes computer literacy. Technological developments point to the need for a broad-based skill set in PDC at all levels of higher education in disciplines such as Computer Science, Computer Engineering, and the related computational disciplines. The rapid changes in technology challenge educators to decide what to teach and how to teach it. Students and employers face similar challenges in characterizing \"basic\" expertise in computing. The PIs are addressing these challenges via a project devoted to creating and sustaining curricular and educational infrastructure to facilitate the teaching of PDC topics in undergraduate computer-related curricula. The goal is for every graduating student to become skilled in PDC technology, hence be prepared to enter tomorrow's workforce.<br\/><br\/>The project embodies multiple synergistic activities that develop: flexible PDC curricula for a spectrum of academic programs and institutions; mechanisms that help individuals maintain currency; instructional materials for PDC-related topics; experience-based guidelines for injecting PDC into curricula. A signature activity is competitions for early adopters of PDC curricula (winners receive seed funds, equipment donations from industry) and workshops and training sessions to foster awareness and adoption of PDC curricula. Feedback from early adopters and coordination with the ACM\/IEEE 2013 CS Curriculum Taskforce steers future development of both the PDC curricular guidelines and of strategies for deploying PDC material within computing curricula at a larger scale.<br\/><br\/>This project is supported by CISE, OCI, and EHR\/DUE.","title":"Collaborative Research: CI-ADDO-NEW: Parallel and Distributed Computing Curriculum Development and Educational Resources","awardID":"1205592","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["559445"],"PO":["564588"]},"192954":{"abstract":"Many auctions used in practice are extremely simple, but do not satisfy the usual standards of mechanism design. These auctions are referred to as \"auction games. \" The Internet provides an environment running millions of auctions, an environment where simplicity is more important than ever before. The \"ideal\" of mechanism design is the single item Vickrey auction (second price auction), selling a single item to the highest bidder at the second highest price. This auction has all the desired features combining simplicity with efficiency: the auction has simple and intuitive rules; it has simple bidding strategies, as truthfully reporting the agent's value as the bid is dominant strategy; and it leads to efficient allocation. A main theme in mechanism design has been designing such truthful and efficient auctions in settings other than the single item auction. Unfortunately, truthfulness and efficiency often come at a price: the resulting mechanisms can be too complex for many environments.<br\/><br\/>The goal of this project is to develop tools to understand outcomes of auction games, such as Ad-Auctions (a multi-billion-dollar game played by Internet service providers and advertisers), and to quantify the expected efficiency and revenue. The Principal Investigator will investigate this goal under various models of the information structure of the game, as well as under various assumptions on the rationality of the agents.<br\/><br\/>The broader impact of the proposal is in developing the basic tools needed to understand many natural auctions, such as the auctions typically being used in practice. Such understanding will lead to simple and intuitive auctions in different environments that result in good quality outcomes.","title":"ICES: Small: Auction Games","awardID":"1215994","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":[516907],"PO":["565251"]},"193966":{"abstract":"Perimeter security and air gap approaches to preventing malware disruption of industrial and infrastructure processes are challenged by the complexity of modern control systems incorporating networked heterogeneous and software-updatable components such as personal computers and programmable logic controllers. Global supply chains and proprietary third-party hardware components, tools, and software limit the reach of static design verification techniques. As a consequence, attacks such as Stuxnet have demonstrated that these systems can be surreptitiously compromised. We are developing a run-time method for process control violation prediction to enhance system resilience against configuration attacks on embedded controllers. This approach copes with either malicious or unintentional errors in any software layer of any programmable component. The run-time system includes a second instance of the active controller connected to a model of the plant, giving a short-term projection of future controller actions and process state. To maintain convergence with the physical system, the model's state is periodically synchronized with the plant's state. The predictor is combined with run-time guards implemented in a configurable hardware-anchored root-of-trust to quickly detect when the projected process state violates specifications. Aberrant event- or time-triggered controller behavior is anticipated before it affects the physical process, allowing preemptive switchover to a minimal and static stability-preserving controller. A productive model-based design flow is being extended to synthesize the active and backup controllers, prediction module, and specification guards into a single commercially-available chip. The root-of-trust can be formally verified due to its hardware implementation and independence.","title":"TWC: Small: Run-Time Prediction and Preemption of Stuxnet-Like Attacks in Embedded Process Controllers","awardID":"1222656","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[519432,519433],"PO":["565327"]},"194824":{"abstract":"Proposal #: 12-29178<br\/>PI(s): Cappelleri, David; Backburn, Mark; Mordohai, Philippos; Valdevit, Antonio; Zavlanos, Michael M.<br\/>Institution: Stevens Institute of Technology<br\/>Title: MRI\/Acq.: Large Volume, High Resolution Motion Capture System for an Interdisciplinary Research Facility<br\/><br\/>Project Proposed:<br\/><br\/>This project, acquiring a Vicon Motion Capture System, aims to support a wide range of technologies and systems including unmanned vehicles, embedded robotics, sensing, perception and visualization, and collaborative, cooperative, networked robotics. Adding critical capability to researchers, the instrumentation is expected to impact research projects in the following areas: <br\/>- Micro aerial vehicles, Active Heterogeneous Sensor Teams, 3D Range Data Generation and Reconstruction, <br\/>- Control of Mobile Robot Networks, Biomechanics, Human-Robot collaboration, Concept Engineering, and Concept of Operations Development<br\/><br\/>Since the institution has initiated a wide range of interdisciplinary high-risk, high payoff technologies and systems, the instrumentation fosters a multidisciplinary research-intensive learning environment. Utilizing highly responsive instrumentation to capture the nuances that can be missed by lesser systems, this work should advance the area of motion capture to the next generation. The instrumentation is also expected to greatly accelerate research progress in the multiple areas addressed. <br\/><br\/>Broader Impacts: <br\/><br\/>The system impacts research projects in many emerging robotics, controls, and scientific areas of national and societal importance. The instrumentation supports a training environment and educational initiatives that contribute to increase the number of undergraduate and graduate students to the system and the research projects that leverage its capabilities. Enabled research will be incorporated into classes and outreach programs. This acquisition fosters further the integration of research and education.","title":"MRI: Acquisition of a Large Volume, High Resolution Motion Capture System for an Interdisciplinary Research Facility","awardID":"1229178","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["564068","541930",521966,"551285",521968],"PO":["557609"]},"193614":{"abstract":"Derivatives are required in numerous contexts in computational science and engineering, including in algorithms for nonlinear optimization and nonlinear differential equations. This project targets the current state-of-the-art technology for computing derivatives, Automatic Differentiation (AD), and its adaptation to multi-core architectures. Algorithms and software from this effort will be useful to the high-performance computing and computational science and engineering communities. Advances in AD technology will directly contribute to improved methods for uncertainty quantification and sensitivity analysis, both of which play crucial roles in high-fidelity predictive computer simulations for scientific applications of national interest. Modules based on parts of this project will be included in suitable graduate courses. As part of this project, the Principle Investigators will visit and give seminars describing this research at a four-year undergraduate college in Indiana to motivate students to pursue graduate studies in science and engineering.<br\/><br\/>Automatic (or Algorithmic) Differentiation (AD) is a modern technology of growing importance for evaluating derivatives accurately and efficiently, but it generates a number of combinatorial problems for which efficient algorithms remain to be found. Multi-core computing platforms, by bringing substantial computing power to the desktop, are well positioned to accelerate innovation and discovery in science and engineering, as long as they are furnished with suitable enabling algorithms and software. Focusing on general-purpose combinatorial abstractions, this project seeks to accelerate progress on both fundamental AD algorithms and those needed to enable derivative computation on multi-core platforms. The specific goals are to: (1) Develop graph-based, symmetry-exploiting models and algorithms for efficient computation of Hessians via AD, (2) Develop combinatorial algorithms to support efficient computation of large, sparse Jacobian and Hessian matrices using AD on multi-core architectures, and (3) Develop combinatorial algorithms for concurrency discovery in irregular computations on multi-core architectures.<br\/><br\/>Many of the targeted combinatorial problems are NP-hard to solve optimally, and fast algorithms that yield near-optimal solutions will be emphasized. To ensure that the algorithms would run correctly, reliably and in a scalable manner on the rapidly evolving multi-core platforms, careful attention will be paid to programming models, algorithm and data structure design, and memory management. Suitable large-scale nonlinear optimization problems will be used to guide the algorithm development effort and as a vehicle for demonstrating impact.","title":"AF:Small: Combinatorial Algorithms to Enable Derivative Computations on Multicore Architectures","awardID":"1218916","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[518525,518526],"PO":["565251"]},"194714":{"abstract":"This research is focused on the creation of new techniques and algorithms to support comprehensive analysis of Android applications. We have developed formally grounded techniques for extracting accurate models of smartphone applications from installation images. The recovery formalization is based on TyDe, a typed meta-representation of Dalvik bytecode (the code structure used by the Android smartphone operating system). In developing TyDe, we are formalizing the TyDe type inferencing, ill-formed bytecode structure management, and creating a generalized Dalvik-to-Java retargeting logic based on bytecode \"instruction templates\". <br\/><br\/>TyDe and the models they represent are being used to perform deep analysis of application structure to infer potential application behaviors that may harm users, their data, or the cellular or Internet infrastructure. In particular, these analyses support whole program analysis, reflection, and smartphone specific data flow analysis. Such analyses provide a means for evaluating an applications adherence to best security practices or organizational requirements by inspecting permission structures, component interfaces, and source code and library origins for signals of malicious behavior. The analysis techniques are being evaluated on a large corpus of real-world applications extracted from real application markets. <br\/><br\/>In the broadest view, this work is providing new avenues for researchers, industry, and consumers to assess potential dangers presented by applications retrieved from smartphone application markets, an advancing the state of the art in application program analysis.","title":"TWC: Medium: Collaborative: Extending Smart-Phone Application Analysis","awardID":"1228700","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[521556],"PO":["564223"]},"193625":{"abstract":"There has been an explosion in our ability to sense and record the world around us. This has led to new discoveries and allowed us to consider new paradigms in nearly every walk of life. While the promise of these developments is significant, the explosion of sensing has also created substantial challenges. These challenges include high-dimensionality of observations and the associated ``curse of dimensionality'', non-trivial relationships between the observations and the latent variables we care about, poor understanding of models, and lack of sufficient training data from which to learn these models. Motivated by such problems, this research studies an approach which we term ``sensing-aware inferencing'' that leverages knowledge about the underlying structure of the sensing process for data-driven inferencing. Such problems are at the frontier of statistical signal processing and advance this frontier by contributing to signal processing theory and practice.<br\/><br\/>This research involves both analysis of the fundamental limits to the performance of, as well as the development of new methods for, decision making and inference from high-dimensional data when the data are related to latent variables through a underlying sensing structure. The methods being developed explicitly acknowledge and account for the underlying sensing process in a unified and optimal way. Research is being advanced along two major thrusts: 1) theoretical investigation of the fundamental limits of classification performance as dimension grows faster than available training data under various states of sensing knowledge, 2) development of methods for inference in high-dimensional problems exploiting sensing structure in a unified way. Throughout, the samples available for such learning are severely limited relative to the dimensionality of the observations.","title":"CIF: Small: Sensing-Aware Decision Making for High-Dimensional Signals","awardID":"1218992","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[518549,"553668","521650"],"PO":["564898"]},"194725":{"abstract":"The goal of our work is to (a) capture people's expectations and surprises in using mobile apps in a scalable manner, and to (b) summarize these perceptions in a simple format to help people make better trust decisions. Our main idea is analyzing privacy in the form of people's expectations about what an app will and won't do, focusing on where an app breaks people's expectations. We are building an App Scanner that combines automated scanning techniques with crowdsourcing. Automated scanning captures the behavior of an app, while crowdsourcing is used to interpret how expected and acceptable this behavior is. This information is used as the basis for building a better privacy summary for apps. We have organized an interdisciplinary team with expertise in mobile computing, computer security, systems, and human-computer interaction.<br\/><br\/>Success in this work will include results in: (a) the design and implementation of an App Scanner that combines automated techniques with crowdsourcing techniques for analyzing and interpreting privacy-related behaviors of mobile apps; (b) a series of evaluations of this app scanner, showing effectiveness, accuracy, and scalability; (c) the design and evaluation of better privacy summaries, which prioritize and highlight the most unexpected behaviors of an app; and (d) demonstration of a new conceptualization of privacy, namely privacy as expectations. Success will also help end-users, corporate and government employees manage their privacy better than can be done today.","title":"TWC: Medium: Collaborative: Capturing People's Expectations of Privacy with Mobile Apps by Combining Automated Scanning and Crowdsourcing Techniques","awardID":"1228777","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[521585],"PO":["565327"]},"193515":{"abstract":"Diffractive masks and algorithms for light field capture<br\/>PIs: Ramesh Raskar, MIT Media Lab Alyosha Molnar, Cornell ECE<br\/><br\/>Advanced imaging and display technology requires integrated, low cost systems able to efficiently capture and characterize light from 3-D scenes. In particular, a 3-D scene can be described by the collection of light rays it generates, called the light field. This research combines concepts from mask-based light-field imaging with angle sensitive pixels (ASPs). While mask-based light-field capture is much better understood mathematically, and masks are cheaper to manufacture and more easily modified on-the-fly, diffractive ASPs provide smaller, denser light field sensors, and provide naturally compressible outputs. This project combines the physics and signal processing of these approaches to enable optical imaging systems that capture more information than normal cameras while reducing the system's complexity. This work broadly impacts diverse applications spanning consumer imaging and displays, machine vision and automation, scientific\/medical imaging and displays, robotic surgery, surveillance and remote sensing.<br\/><br\/>3-D images and video can be captured by measuring the combined spatial and angular distribution of light (the light field). This research combines two techniques for light-field capture: mask-based light-field imaging and diffractive angle sensitive pixels (ASPs). A critical element of this work is the development of a mathematical framework that maps between conventional geometric light fields and the diffractive optics upon which ASPs rely. A second element is constructing hybrid systems based on this mathematics, leveraging diffractive effects in mask design, and combining masks with ASPs in single light-field cameras. This work also combines formalisms in existing light field methods with knowledge about real 3-D scene statistics to develop optimal (in the sense of usability and compressibility) basis sets for sampling and encoding the light-field. All of these aspects combine to reduce the size, cost and complexity of light field cameras, while simultaneously enhancing their capabilities.","title":"CGV: Small: Collaborative Research: Diffractive masks and algorithms for light field capture","awardID":"1218409","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["531753"],"PO":["565227"]},"191458":{"abstract":"The research objective of this award is to integrate polymer and piezoelectric micro-structures to create robust, sub-centimeter terrestrial micro-robots, and to use a combination of modeling and experimentation to evaluate leg dynamics of such robots. Specifically, high-aspect ratio parylene flexural mechanisms will be integrated with thin-film lead-zirconate-titanate (PZT) actuators in complex, multi-degree-of-freedom micro-robotic leg joints. Experimental measurements of parylene structure response to integrated thin-film PZT actuation or external bulk PZT ceramic or load cell actuation will be used to characterize parylene stiffness and damping characteristics at varying strain rates, relative to high-strain rate piezoelectric actuation. Adhesion between bulk-micromachined silicon trench surfaces and PZT\/metal stack layers will also be evaluated. Measured parylene properties will then be incorporated into existing micro-robotic foot-terrain models developed by the PI and students to produce simulation models of PZT-polymer robots that can be validated against experimental robot prototypes.<br\/><br\/>Successful completion of this work would dramatically improve the ability of walking millimeter-scale micro-robots to move over uneven terrain, thus increasing the range of possible interactions between human operators and engineered or natural systems. The target user community for millimeter-scale autonomous robots includes disaster response teams, infrastructure maintenance and monitoring workers, and national security organizations. The framework to be deployed would be a technique to embed piezoelectric microactuators in resilient micro-robotic appendages, producing sample walking micro-robot platforms. Results from this research would be coupled into both undergraduate and graduate curriculum and secondary school education. The latter effort will consist of interactive hands-on and web-based projects developed by the PI for use in science education for the local Ypsilanti, Michigan school district and the broader community of interested citizens.","title":"NRI-Small: Robust, highly-mobile MEMS micro-robots based on integration of piezoelectric and polymer materials","awardID":"1208233","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":["555574"],"PO":["563744"]},"193405":{"abstract":"Systems of autonomous vehicles under cooperative control provide versatile platforms for a variety of tasks including environmental monitoring, search and rescue, intelligent transportation, and cooperative surveillance or attack. Performing these tasks requires control or optimization of the system's formation while maintaining network connectivity. Such systems are also potential targets for attack, and so techniques to secure the communications and control processes are important. In this project, techniques from computer networks are coupled with controls techniques to reconfigure the physical formation of a system of autonomous vehicles while maintaining network connectivity by \"routing\" vehicles through the formation to new positions. This approach is an enabling technology that also allows the network formation to be optimized to increase the efficiency of networked communication. New approaches to securing communication signals are coupled with the ability to transform the physical formation of the system to provide new approaches to achieving communication that is secure against eavesdroppers and robust to hostile jamming. The results of this project will be new algorithms, protocols, and controls techniques for formation control of systems of autonomous vehicles that are more flexible, efficient, and secure than the techniques currently available. These results will be widely applicable to future sensing\/monitoring, homeland security, and defense operations involving autonomous systems of ground, air, surface, and underwater vehicles.","title":"NeTS: Small: Network Connectivity and Security for Cooperative Autonomous Vehicles","awardID":"1217908","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[518031,"561494"],"PO":["557315"]},"194736":{"abstract":"This project investigates the feasibility of secure, robust, and usable gesture-based authentication as an alternative to traditional alphanumeric passwords and biometrics. It is motivated by the rapid increase in authentication-related security breaches and by the emergence of new human-computer interfaces. While the breaches have demonstrated the seriousness of the issue, two emerging types of gesture-based interfaces, multi-touch (smartphones, tablets) and camera-based (Kinect), offer a unique opportunity for robust solution.<br\/><br\/>The benefit of gesture-based authentication over a purely-biometric one lies in the fact that it combines involuntary biometric features (e.g., hand shape), that are irrevocable, with user-controlled voluntary characteristics that can be easily changed. Three research thrusts are being pursued: 1) gesture recognition algorithms (search for robust gesture features, their compact representation, and reliable classification algorithms), 2) human factors (study of uniqueness, repeatability, ergonomics, device dependence of gestures, and gesture complexity) and 3) security considerations (evaluation of authentication performance under a range of performance measures and different threat models). <br\/><br\/>A successful completion of this research will catalyze the development and adoption of next-generation authentication methods that are critically needed at the personal, institutional, and governmental levels. As the price paid (time, money, and resources) to repair a security breach can be astounding, this project will have substantial societal impact by increasing the sense of security and reducing breach-related costs. At educational level, this project is involved in middle and high school outreach at Boston University as well as the annual cybsersecurity competition CSAW at NYU-Poly.","title":"TWC: Medium: Collaborative: Towards Secure, Robust, and Usable Gesture-Based Authentication","awardID":"1228842","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["559652","565224"],"PO":["565327"]},"193526":{"abstract":"Traditionally, cryptographic algorithms and protocols are geared towards protecting against attacks that interact with the designed algorithms via well specified interfaces (such as I\/O and communication). However, the increasingly sophisticated ways in which computing devices are currently used completely shatter the traditional boundaries between the attacker and the \"private internals\" of the cryptographic algorithm under attack. Algorithms are run over small and exposed machines that leak information on their internal state; they are transported to other, potentially adversarial machines which may inspect all the internal state and also misreport the result; their code is exposed and subject to adversarial tinkering.<br\/><br\/>This project is aimed at developing new algorithmic and analytical techniques for dealing with this new reality. This includes cryptographic algorithms and protocols that are resilient to leakage from and tampering with the internal states of the host machines, program obfuscation techniques, and techniques for verifying computation done on untrusted machines. A basic premise of this project is that new analytical techniques, that no longer treat the adversary as black-box, are essential. Consequently, special effort is dedicated to developing such techniques.<br\/><br\/>The project tackles a set of problems that are central to the security of modern computer systems and consequently also to the well-being and stability of modern society. But even disregarding practical applicability, the tackled problems lie at the heart of our understanding of the notion of computation, the interplay between code and data, and the ability to algorithmically \"understand\" arbitrary code.","title":"AF: Small: New Directions in Cryptography: Non-Black-Box Techniques against Non-Black-Box Attacks","awardID":"1218461","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["562062"],"PO":["565157"]},"193647":{"abstract":"Objective of this research is to develop an easy to apply and high quality asynchronous design flow for modern VLSI chips based on the NULL Convention Logic (NCL) asynchronization approach with proper Computer Aided Design tool support. The design flow will focus on simultaneously optimizing power, performance and area of the circuit at the logic, circuit and layout levels. New optimization techniques targeting asynchronous design will be derived and implemented into the tools. The proposed work will address an important aspect (power) in attempts to overcome Moore's law slowdown in semiconductor circuit design, manufacturing with potentially large impact to industry.<br\/><br\/>The results will be integrated into graduate courses and\/or senior electives in university curricula. The proposal is from an EPSCoR state, and PI will in addition recruit students from the University of Puerto Rico, which is yet another EPSCoR state. The tools developed as part of this project will be made available in the public domain. The PI has a very strong past record of developing CAD tools and making them available to the community. Overall the project exemplifies NSF commitment to the integration of research and education.","title":"SHF: Small: Enabling Techniques for Asynchronizing Synchronous Design","awardID":"1219100","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[518602],"PO":["562984"]},"193658":{"abstract":"This research will study ways to ease the production and<br\/>use of high-performance matrix algebra software. Matrix algebra<br\/>calculations constitute the most time-consuming part of simulations<br\/>in diverse fields, and lowering the runtimes of those computations<br\/>can have a significant impact on overall application performance. The<br\/>process of converting matrix algebra from algorithm to high-quality<br\/>implementation is, however, a complex one. At each step, the code<br\/>developer is confronted with a myriad of possibilities, many requiring<br\/>expertise in numerical computation, mathematical software, compilers,<br\/>and computer architecture. In response to these difficulties, the PIs<br\/>have developed a prototype taxonomy implementation entitled Lighthouse,<br\/>which is a guide to the linear system solver routines from the software<br\/>package LAPACK. It is the first framework that combines a matrix algebra<br\/>software ontology with code generation and tuning capabilities. Its<br\/>interface is designed for users across a spectrum of disciplines, career<br\/>levels, and programming experience.<br\/><br\/>The PIs will dramatically extend the<br\/>Lighthouse framework in a number of new directions. First, they will<br\/>construct a general taxonomy of software that can be used to build<br\/>highly-optimized mathematical applications. The taxonomy will initially<br\/>provide an organized ontology of software components for high-performance<br\/>matrix algebra and later other numerical software from a variety of<br\/>problem domains. It will serve as a guide to practitioners seeking<br\/>to learn what is available for their mathematical programming tasks,<br\/>how to use it, and how the various parts fit together. Second, the PIs<br\/>will apply a combination of source code analysis and machine learning<br\/>techniques to fully automate the generation of parameterized models that,<br\/>given representative inputs and a simple architecture description, can be<br\/>evaluated to identify methods from various libraries that best reflect<br\/>the user's resource and performance requirements. This automation is<br\/>critical for ensuring that the taxonomy is comprehensive enough to be<br\/>useful and that it accurately reflects the features and performance<br\/>of the latest versions of numerical libraries. Finally, the PIs will<br\/>advance the state-of-the-art in tuning tools by improving some of the<br\/>tools included in the taxonomy, broadening their ranges of functionality<br\/>in terms of problem domains and languages. This project will produce<br\/>the following impacts: greater performance by applications, enabling<br\/>both more discovery with available computing resources and greater<br\/>productivity of application programmers; greater understanding of the<br\/>interaction between architecture and algorithms; and an educational tool<br\/>for future computational scientists.","title":"SHF: Small: Collaborative Research: Lighthouse: Resource-Aware Advisor for High-Performance Linear Algebra","awardID":"1219150","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["551055","521548"],"PO":["366560"]},"193306":{"abstract":"The growth of social media data in size and variety accelerates rapidly as more people use social media such as Facebook, Twitter, LinkedIn, among others. It is a massive \"treasure trove\" interesting to researchers and practitioners of different disciplines, and a great source for data mining. However, attribute-value data in classic data mining differs from social media data besides both are large-scale. Social media data are noisy, incomplete, comprised of multiple sources, and form multi-modal and and multi-attributed networks. Furthermore, such data are not independent and identically distributed (i.i.d.). These unique properties present new challenges for mining social media data. <br\/><br\/>This project investigates a novel approaches to feature selection in linked data in general and social media data in particular. Specifically, it seeks to exploit link information in supervised as well as unsupervised feature selection for social media data. Because social media data are drawn from multiple noisy, partial, or redundant sources, the proposed approach to feature selection seeks to select relevant sources and use them together to guide linked feature selection in multi-modal, multi-attributed social media.<br\/><br\/>The project lies at the confluence of feature selection, social media analysis, and data mining. The project offers an opportunity to engage students who are adept users of social media in developing computational tools that can harness the power of social media. Some broader impacts of this research include integration of social media analytics into undergraduate and graduate courses as well as student research projects; enhanced research-based training opportunities for students from under-represented groups; and powerful social media analytics tools for understanding collective behavior in social media, employing social media for crisis response and disaster relief, and studying social and political movements. The results of the project (including publications, software, etc.) will be made available through the project web site: http:\/\/www.public.asu.edu\/~huanliu\/projects\/NSF12","title":"III: Small: Transforming Feature Selection to Harness the Power of Social Media","awardID":"1217466","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[517806],"PO":["565136"]},"194758":{"abstract":"The goal of this project is to provide secure and robust communications in underwater sensor networks (UWSNs). Specifically, the project is investigating denial of service attacks and their countermeasures in such networks.<br\/><br\/>There has been a growing interest in developing underwater acoustic sensor networks in recent years, aiming for breakthroughs in aquatic environment monitoring for scientific exploration, commercial exploitation and coastline protection. The unique properties of underwater environments result in two major differences between UWSNs and land-based sensor networks: the communication method and sensor node mobility. Because radio frequency (RF) signals attenuate quickly in water, communications in UWSNs normally use acoustic channels, which feature long latencies, low bandwidth, high error rates, and high energy consumption. The mobility of sensor nodes leads to dynamic network topology.<br\/><br\/>Since underwater sensor nodes are deployed in the field and communicate through acoustic channels that can be accessed easily by adversaries, they are vulnerable to various attacks. This project investigates denial-of-service (DoS) attacks and countermeasures in underwater networks. <br\/><br\/>The project has three research thrusts.<br\/><br\/>1. DoS attacks and countermeasures at the physical and link layers. <br\/><br\/>2. DoS attacks and countermeasures at the network layer. <br\/><br\/>3. System integration and field testings. The outcomes of the project, including both attacks and countermeasures, will be thoroughly evaluated in simulation, lake, and ocean testbeds.<br\/><br\/>This project will lead to more robust communications in underwater networks, and thus advance the development and use of such networks. <br\/><br\/>Beyond the research significance, this project impacts education on three fronts. First, it will support graduate students in their advanced research in the fields of security, communication, networking, and computer engineering. Second, it will motivate undergraduates, especially women and other under-represented groups, to participate in advanced research in computing and engineering. Third, this project will promote multi-disciplinary collaboration.","title":"TWC: Medium: DoS Attacks and Countermeasures in Underwater Wireless Networks","awardID":"1228936","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["546033","526410","550179"],"PO":["549626"]},"193669":{"abstract":"Brain computer interfaces (BCIs) translate basic mental commands into computer-mediated actions. BCIs allow the user to bypass the peripheral motor system and to interact with the world directly via brain activity. These systems are being developed to aid users with motor deficits stemming from neurodegenerative disease, injury, or even environmental restrictions which make movement difficult or impossible. One popular class of EEG-driven BCI systems is based on imagined movement. In these systems the user interacts with a computer through motor imagery such as the imagination of hand vs. tongue movement. But the ability of users to control such a BCI is very variable, and all the factors involved are not fully understood. For example, EEG signals can change drastically from offline training to online use. Unfortunately, drift in EEG can lead to loss of control of the BCI, which leads to user frustration and further drift of EEG signals from their training baselines.<br\/><br\/>The PI's goal in this project is to create a more robust BCI system by specifically addressing loss of control and system drift. Her hypothesis is that explicitly training on a signal that incorporates a user's satisfaction and, more importantly, dissatisfaction with the current performance may result in a more natural interface, and thereby lead to a reduction in loss of control and improved system usability and performance. The research will be carried out in three stages. First, active and passive EEG signals of dissatisfaction and satisfaction will be analyzed in a simulated online setting. Next, a real-time online system that recognizes dissatisfaction vs. satisfaction to control 1-D cursor movement will be constructed and system performance compared to that of a standard left\/right motor imagery system. Finally, the best working parts of the dissatisfaction\/satisfaction system will be integrated with the more standard left\/right system, to create a better hybrid system. The (dis)satisfaction signals will be based on actively controlled motor imagery signals, interpreted emotion, and detection of error-like signals.<br\/><br\/>Broader Impacts: This project has the potential to vastly improve the robustness of EEG-based BCI systems, by responding to natural signals of satisfaction and dissatisfaction, by being resistant to drift, and by naturally taking advantage of frustration which is a common cause of loss of control. By training the BCI to recognize frustration the PI expects to turn this typically negative trait into a positive. The project will support and train an under-represented minority graduate student and a post-doc in this important interdisciplinary area, and it will create projects for under-represented REU participants as well as for high school students through the PI's partnerships with the NSF Temporal Dynamics of Learning Center (TDLC, where she is a member of the faculty governing and admissions committee for the REU program) and the Preuss School (a charter school for low income students with no college educated parent). All software written for EEG signal processing and analysis, as well as data from the experiments, will be made available as add-ons to EEGLAB which is distributed by co-PI Makeig.","title":"HCC: Small: Towards more natural and interactive brain-computer interfaces","awardID":"1219200","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[518651,"520809"],"PO":["565227"]},"193317":{"abstract":"It is natural that events of interest in observed scenes manifest themselves across multiple sensing modalities - vision, hearing, smell, etc. The remarkable perceptions of audio-video signals by natural systems, such as humans, also points to superiority of inferences drawn across modalities. It, therefore, seems natural to enhance performance of automated systems by using joint, cross-modal statistical inferences. However, the detection, organization, and understanding of cues and events in real-world scenarios are difficult tasks. This project seeks to develop a pattern-theoretic framework for achieving these goals. The main research items are: (1) development of mathematical quantities to represent audio and visual events and their spatiotemporal relations, (2) use domain-specific ontologies to impose semantic structure and to incorporate prior knowledge, and (3) derive algorithms for Bayesian inferences using efficient adaptations of Markov Chain Monte Carlo sampling. <br\/><br\/>The use of pattern theory allows bridging of gaps between raw signals and high-level, domain-dependent semantics, and helps discovers large groups of audio-visual events likely to represent the same underlying event. This effort combines ideas from perceptual organization in computer vision, computational analysis of auditory signals, pattern theory, and prior developments in ontological structures. The methods developed here are applicable to many scenarios that deploy audio and video sensors, including problems of audio annotations of videos, speaker tracking in teleconferencing, and separation of multiple objects in remote surveillance. Broader impact activities involve the development of teaching modules, innovation and entrepreneurial training of the students, and communication of the findings to the community.","title":"RI: Small: Collaborative Research: Ontology based Perceptual Organization of Audio-Video Events using Pattern Theory","awardID":"1217515","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["550508"],"PO":["564316"]},"193438":{"abstract":"The goal of this research project is to transform the way that data visualizations are designed and created to enable more effective, creative, and accessible ways of communicating scientific information using computer graphics. The project enables artists, scientists, engineers, and others to rapidly design, generate, and iteratively refine visualizations of today's most complex datasets. The approach combines novel computational tools that enhance sketching, analogical reasoning, and other creative human design tasks with underlying scientific data and 3D displays. The results include new tools, algorithms, and guidelines, which are evaluated experimentally through challenging applications to biomedical engineering, such as visualizing multidimensional imaging and modeling data to understand interactions between proposed new medical devices and human tissues. These results are significant because they lead to new understandings of how computation and human creativity can be most effectively combined in general, and specifically, how they can be combined to help scientists visualize and understand complex multidimensional data. <br\/><br\/>The broader impacts of the work lie in educational efforts integrated with the experimental research and broad applications of the new methods developed. Students from local art and design colleges are educated in scientific methods, opening up new career paths in the sciences for these visual experts. Hands-on educational research demonstrations are conducted in the local community. Through specific applications, the work yields insights that can improve and accelerate science, engineering, and healthcare. Project results, including new curriculum developed, open source software, videos, publications, and demos, will be disseminated on the project web site (http:\/\/ivlab.cs.umn.edu\/visualization-by-sketching).","title":"CGV: Small: Visualization by Sketching, Analogy, and Computational Creativity","awardID":"1218058","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["533320","565145"],"PO":["563751"]},"193328":{"abstract":"The goal of this research project is to help people make sense of large graphs, ranging from social networks to network traffic. The approach consists of combining two complementary fields that have historically had little interaction -- data mining and human-computer interaction -- to develop interactive algorithms and interfaces that help users gain insights from graphs with hundreds of thousands of nodes and edges. The goal of the project is to develop mixed-initative machine learning, visualization, and interaction techniques in which computers do what they are best at (sifting through huge volumes of data and spotting outliers) while humans do what they are best at (recognizing patterns, testing hypotheses, and inducing schemas). This research addresses two classes of tasks: first, attention routing -- using machine learning to direct an analyst's attention to interesting nodes or subgraphs that do not conform to normal behavior. Second, sensemaking -- helping analysts build in-depth representations and mental models of a specific areas or aspects of a graph. Evaluation of the tools will involve both controlled laboratory studies as well as long-term field deployments.<br\/><br\/>As large graphs appear in many settings -- national security, intrusion detection, business intelligence (recommendation systems, fraud detection), biology (gene regulation), and academia (scientific literature) -- the potential benefits of new tools for making sense of graphs is far reaching. Project results, including open-source software and annotated data sets, will be disseminated via the project web site (http:\/\/kittur.org\/large_graphs.html) and incorporated into educational activities.","title":"CGV: Small: Making Sense out of Large Graphs - Bridging HCI with Data Mining","awardID":"1217559","effectiveDate":"2012-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[517858,"548220"],"PO":["563751"]},"193449":{"abstract":"Hybrid systems are a mathematical framework that has been widely used to model engineering and natural systems whose dynamics have both continuous and discrete aspects. Applications range from modern \"fly-by-wire\" airplanes to cellular biology. A controller for a hybrid system observes the execution of the system and issues input signals and\/or trigger events in the hybrid system so as to meet the system's goals and safety requirements. An outstanding problem is that for complex hybrid systems existing methods for controller synthesis require exceedingly large computational resources.<br\/><br\/>This project seeks to address the high computational demands of constructing controllers for hybrid systems in a new way. The novelty of the approach lies in using human-centered computing (crowdsourcing), while ensuring that the obtained controller is correct. The expected outcomes of this project are mathematical theory and algorithms that will enable the idea above for a wide range of problems, including those involving nonlinear systems and random events. These results are further implemented in simulator computer games, which will be deployed online. The amount of computing resource that can be potentially be harvested through crowdsourcing is very high. Earlier crowdsourcing applications such as reCAPTCHA, FoldIt, and Wikipedia have recorded billions of hours of effort by their human contributors. Beyond solving the controller synthesis problem, the outcomes of this project can lead to new ways to tap into this resource for solving new problems.<br\/><br\/>The broader impacts of this project include improvements in the safety of a wide range of engineered systems. The project also has an educational outreach program involving K-12 students and educators in cutting edge multidisciplinary research. Uniquely, the gaming theme is an ideal vehicle to engage pre-college students in science and engineering.","title":"CSR: Small: Human-Centered Synthesis of Provably Correct Controllers for Hybrid Systems","awardID":"1218109","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[518132],"PO":["564778"]},"193218":{"abstract":"This project explores perception-driven models of human audio-visual emotion using statistical analyses, data-driven computational modeling, and implicit sensing. Emotion underlies and modulates human communication. It is used in the diagnosis of many mental health conditions and is tracked in therapeutic interventions. Research in emotion perception seeks to identify models that describe the felt sense of 'typical' emotion expression -- i.e., an observer\/evaluator's attribution of the emotional state of the speaker. This felt sense is a function of the methods through which individuals integrate the presented multi-modal emotional information. However, the nature of the interaction of the multi-modal cues is still an open question. This project will investigate multi-modal cue integration by studying how emotional inconsistency affects human perceptual judgment. In pursuit of this goal, the research objectives of this proposal are (1) to identify and validate primary and secondary audio-visual cues responsible for emotion perception, (2) to create a data-driven model to automatically predict the emotion perception of an evaluator, and (3) to predict evaluator state using implicit physiological and body gesture cues. <br\/><br\/>The first research objective addresses the open question of how distal cues, the encoding of a speaker's communicative goals, interact and result in the felt sense of specific emotion states. Novel techniques will be used to identify emotionally salient distal cues using emotionally consistent and inconsistent audio-visual information. This identification has implications in the design of emotion classification algorithms and the emotional behavior of affective agents. The second research thrust addresses the open question of how human-centered models (rather than data-driven models) can be designed for use in emotion classification tasks. The project will investigate the efficacy of novel dynamic structures to model emotionally inconsistent information. These new structures will provide insights into the development of human-centered emotion classification inspired by the emotion perception process, rather than solely on data fluctuations. The third research objective addresses the open question regarding the effect of audio-visual emotion evaluation tasks on the evaluator's internal state. We will assess evaluator inattention in the context of emotional evaluation tasks. Models that can accurately predict evaluator inattention have applications in long-term human-computer and human-robot interaction platforms. The insights gained from this project will facilitate the design of emotion-focused algorithms that replicate the process by which humans interpret and integrate emotional audiovisual signals. It will also aid in the creation of emotional interfaces for health informatics applications, which will lead to more specifically targeted interventions and treatments for many mental health conditions including schizophrenia, depression, and autism.","title":"RI: Small: Collaborative Research: Exploring Audiovisual Emotion Perception using Data-Driven Computational Modeling","awardID":"1217104","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["563326"],"PO":["564318"]},"193339":{"abstract":"To provide responsive services to end-users, cloud platforms are designed for low latency. Each layer of the stack, including local storage, distributed file systems, the communication layer, and coordination services, operates with a few milliseconds latency on average. However, a typical user request flows through dozens of services. As a result, the latency tail is as important to responsiveness as average latency: if 1 in 100 RPC requests experiences 50ms latency, then as the complexity of servicing an individual user request grows, so do does the likelihood that the latency of the user's request will be \"dragged down\" by an outlier.<br\/><br\/>We are exploring techniques for constructing data center services that provide low latency tails. Hard drives can introduce high latency when seeking, whereas SSDs provide uniform access times even for random workloads. Distributed storage systems like GFS or BigTable provide good average latency, but at scale, \"rare\" events like tablet splitting become common. We are designing techniques to reduce the latency impact of these rare events and that exploit redundancy to provide a fast path even if they occur. OSs and transport protocols are another source of latency noise; we are applying techniques from soft real-time systems and QoS-oriented networks to condition these layers as well. By bringing down tail latency, we will also make protocols that provide strong data consistency more practical.<br\/><br\/>As part of our work, we are incorporating these topics into the undergraduate and graduate curriculum, including a graduate course on operating systems.","title":"CSR: Small: Bringing Predictable Low Latency and Strong Consistency to Data Center Services","awardID":"1217597","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["532591"],"PO":["565255"]},"193108":{"abstract":"The goal of this project is to consider classical optimization problems, originally stated in the context of abstract graph theory and combinatorial optimization, whose hardness as well as approximation factors have been studied extensively, and investigate them in a geometric context, that is, when the input consists of geometric objects. While considerable progress has been made on the analysis of such problems in the abstract setting, their geometric variants have received much less attention. These problems include minimum coverage of a given area, stabbing a set of geometric objects, geometric packing, and obtaining largest sets of mutually intersecting geometric objects. For each of these problems, new ideas will be explored, which aim to combine tools from computational and combinatorial geometry with traditional algorithmic tools from theoretical computer science. Specifically, this work exploits techniques such as linear programming relaxation and local search, commonly used in operation research, combinatorial optimization, and algorithm theory, with tools from computational and combinatorial geometry such as geometric arrangements, Epsilon-nets, Helly-type properties, and others.<br\/><br\/>This award will help to develop a new set of tools that will not only be exploited in computational and combinatorial geometry, but will extend to other (perhaps, more applied) disciplines, such as networking, computer graphics, geographic information systems, learning and others, as they often pose problems of geometric nature. In particular, each of the problems to be investigated in this project has applications to these areas, and hence their importance is not only theoretical but also practical. <br\/><br\/>The project will support and train one postdoctoral researcher in Computer Science at NYU. The PI will disseminate the research to the scientific community through conference and journal publications, teaching courses, as well as presenting her works in departmental seminars, and collaboration with researchers from various disciplines.","title":"AF: Small: Geometric Optimization via Combinatorial Geometry","awardID":"1216689","effectiveDate":"2012-09-15","expirationDate":"2014-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[517305,"518072"],"PO":["565157"]},"192702":{"abstract":"Enterprise and campus networks are often large with many having hundreds of routers and thousands of switches which interconnect tens of thousands of hosts and servers. The IP network for an enterprise is not only charged with delivering IP packets but also blocking packets based on security and policy considerations. The set of packets that can travel from one node to another node (reachability set) is controlled by router configurations and by packet filters that guard the outgoing and incoming interfaces of routers and switches. The ability to compute reachability sets is valuable not only for troubleshooting reachability problems but also for debugging and redesigning access control lists (ACLs) in case of link\/router failures or before new links\/routers are deployed. At present, there is no method fast enough for online computation of reachability sets for large dynamic networks. This project will leverage a novel idea for very fast computation of reachability sets as the basis for developing a theoretical foundation for both transforming network design and configuration into a science and for developing software tools for monitoring, diagnosing, and configuring of large dynamic networks. <br\/><br\/>The objectives and activities in the project include the following: (i) Design and implementation of algorithms fast enough to compute reachability sets and answer an online reachability query in milliseconds; (ii) design and implementation of methods and algorithms to update reachability sets of large networks with dynamic changes in topology, packet filters, and forwarding tables at a frequency of once every few seconds; (iii) analysis of ?atomic packet sets? computed from configuration files of operational networks for knowledge discovery and identifying network reachability structure; (iv) design and implementation of a network-wide reachability policy language such that automated tools can be used to check that a network configuration satisfies stated policies; (v) investigation of a top-down design approach for configuring new networks with software tools used by network designers to generate packet filters from network-wide reachability policies, with ACLs generated automatically to implement the packet filters.<br\/><br\/>Broader Impact:<br\/>The results of this project will contribute towards a scientific foundation for network design and management and the creation of a top-down design approach for configuring networks, which are key aspects of building more secure and reliable networks. It will also educate undergraduate and graduate students on new concepts, formal analysis methods, and software tools for network design and configuration. In particular, the results of this project will be incorporated into the undergraduate and graduate classes being taught by the principal investigator at the University of Texas at Austin. The investigators will actively seek out involvement by high school, undergraduate, and graduate students, especially students from under-represented minorities. The software tools to be created from the project?s research findings will be made available to other researchers under a license of the Free Software Foundation.","title":"NeTS: Small: An Efficient Reachability Analysis Method for Large Dynamic Networks and Its Applications","awardID":"1214239","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[516340],"PO":["564993"]},"191525":{"abstract":"New rehabilitation therapies for patients with incomplete lower spinal cord injuries (SCI) will be developed using the Treadport, a robotic treadmill that provides a realistic walking experience in a safe and flexible virtual environment. The Treadport overcomes limitations of current rehabilitation treadmills, which are too dissimilar from everyday walking and therefore limit a patient's recovery. We will seek to improve a patient's walking speed and effort, resistance to falling by strengthening and training a patient to unexpected perturbations, and arm swing coordination which is critical for normal walking. The intellectual merit is the body-weight assisted robotic treadmill training, and arm swing assistance using a light-weight exoskeleton. The robotic treadmill will provide monitored assistance and virtual reality training scenarios not currently possible.<br\/><br\/>The broader impact is the development of new technology and scientific understanding that will improve the lives of SCI patients so that they have the most mobility possible given their injuries. The proposed research combines the disciplines of robotics, biomechanics, and physical therapy, and requires interdisciplinary training. The socially positive nature of this project is expected to be especially attractive to underrepresented populations in engineering and computer science, particularly women and people with disabilities.<br\/><br\/>This proposal addresses the co-worker theme of the National Robotics Initiative, particularly rehabilitation, orthotics and prosthetics.","title":"NRI-Small: Robotic Treadmill Therapy for Lower Spinal Cord Injuries","awardID":"1208637","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":[513354,513355],"PO":["548925"]},"190799":{"abstract":"Computing increasingly permeates daily lives, yet few appreciate the growing presence of Parallel and Distributed Computing (PDC) in common computing activities; e.g., modern laptops' processors contain multiple cores and special-purpose devices such as graphics processors (GPUs). With increasing availability of powerful PDC technology, familiarity with single-processor computers and sequential computing no longer constitutes computer literacy. Technological developments point to the need for a broad-based skill set in PDC at all levels of higher education in disciplines such as Computer Science, Computer Engineering, and the related computational disciplines. The rapid changes in technology challenge educators to decide what to teach and how to teach it. Students and employers face similar challenges in characterizing \"basic\" expertise in computing. The PIs are addressing these challenges via a project devoted to creating and sustaining curricular and educational infrastructure to facilitate the teaching of PDC topics in undergraduate computer-related curricula. The goal is for every graduating student to become skilled in PDC technology, hence be prepared to enter tomorrow's workforce.<br\/><br\/>The project embodies multiple synergistic activities that develop: flexible PDC curricula for a spectrum of academic programs and institutions; mechanisms that help individuals maintain currency; instructional materials for PDC-related topics; experience-based guidelines for injecting PDC into curricula. A signature activity is competitions for early adopters of PDC curricula (winners receive seed funds, equipment donations from industry) and workshops and training sessions to foster awareness and adoption of PDC curricula. Feedback from early adopters and coordination with the ACM\/IEEE 2013 CS Curriculum Taskforce steers future development of both the PDC curricular guidelines and of strategies for deploying PDC material within computing curricula at a larger scale.<br\/><br\/>This project is supported by CISE, OCI, and EHR\/DUE.","title":"Collaborative Research: CI-ADDO-NEW: Parallel and Distributed Computing Curriculum Development and Educational Resources","awardID":"1205437","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["518069"],"PO":["564588"]},"180525":{"abstract":"This project develops methods to provide citizens information about technologies that obstruct, restrict, or tamper with their access to information. Internet users need an objective, independent, third-party service that helps them determine whether their Internet service provider or government is restricting access to content, specific protocols, or otherwise degrading service. Towards this goal, we are (1) monitoring attempts to block or manipulate Internet content and communications; and (2) evaluating various censorship circumvention mechanisms in real-world deployments}. The project develops a large-scale measurement and monitoring service that measures network reachability and performance from a variety of access networks to various Internet services; infers whether ISPs or governments are restricting or otherwise throttling access to various applications and services; and detects attempts to tamper with information presented to users. The project also studyies the policy ramifications of making information about censorship and information tampering available to Internet users. It will provide up-to-date information about both the extent of censorship and information tampering in countries around the world and technologies countries are using to implement censorship and thwart censorship circumvention tools. Discoveries are disseminated through real-time portals and through regular written reports and academic publications.","title":"TC: Large: Collaborative Research: Facilitating Free and Open Access to Information on the Internet","awardID":"1111734","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["533300"],"PO":["565327"]},"193615":{"abstract":"Given the importance of interpreting data, educators have made the teaching of graph concepts a core component of primary and secondary mathematics education. Unfortunately, the visual nature of a typical number line or graph presents a major disability for those with visual impairment. In current practice in the United States, blind students learn graphs with tactile graphics, which often represent a graph using raised dots (similar to Braille) embossed on paper. Tactile graphics are useful and have their place, but are increasingly marginal for two reasons. First, most visually impaired students now are in \"mainstream\" classes with their sighted peers. Mainstreaming can be beneficial in many ways, but makes it less convenient to provide alternative formats to the student; furthermore, teachers and other students will typically be unable to read Braille. Second, many classrooms are using computers for learning mathematics and graphs. Tactile graphics are generally not compatible with computers, and the very few current tools that are compatible are rudimentary or extremely expensive.<br\/><br\/>On a standard desktop computer, a natural alternative to visuals is audio. The use of auditory displays for mathematical data and graphs is not a new concept, however much still needs to be done in order to make these auditory graphs useful in the school curriculum. In this project, the PI seeks to address this need by exploring the upcoming Common Core Standards for the teaching of graphs in middle school classrooms and establishing a software system to allow visually impaired and sighted middle school students to author and explore graphs using sound. The software system will go through an ecological validation process based on the identified goals and operations of the Common Core Standards, and will include optimal auditory display designs based on the PI's findings from planned auditory graph perception experiments in multiple data sets and conveying concepts such as uncertainty.<br\/><br\/>Broader Impacts: This project opens a whole new field within assistive technology, making software-based accommodations possible and effective in the classroom. Students with vision loss stand to directly gain increased access to STEM materials from project outcomes; a solid STEM education will increase employability, which in turn will positively impact general income levels and quality of life for the members of this community. More broadly, however, it is clear that nearly all persons will benefit from appropriately designed and validated multimodal information displays. Thus, the background scientific knowledge that will be gained from this research will have foundational utility not only in this field but in many other disciplines as well, while the advances in curriculum-driven auditory graphing tools should lead to all manner of new uses for the technology in the field of education, HCI and beyond.","title":"HCC: Small: Multimodal Technology Tools for Universal Access to STEM Education under the Common Core Curriculum","awardID":"1218920","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["529975"],"PO":["565227"]},"194946":{"abstract":"Proposal #: 12-29700<br\/>PI(s): Dantu, Ram; Tam, David N<br\/>Institution: University of North Texas <br\/>Title: MRI\/Dev.: CloudCar: A Diverse Distributed Instrument for Vehicles in the Cloud<br\/>Project Proposed:<br\/>This project, developing an instrument referred to as CloudCar, aims to build a cloud-based infrastructure to monitor and collect data about drivers, vehicles, and road conditions. The type of data to be collected includes driver's biometrics (eyeball tracking, heart rate, blood pressure, and EEG brain wave analysis), sensory data from the vehicle, traffic data, and sensed data about road condition. The collected data is analyzed in the cloud and used to enable a wide spectrum of applications, including assessing drivers' behavior and ability to drive, the \"health\" of the vehicle, dissemination of information about road conditions to prevent accidents and road congestion, and vehicular crash detection and notification. <br\/><br\/>The basic equipment requested includes cloud servers, software and tuning tools, the OBD-II and CAN software\/hardware, a number of 14-channel EEG equipment for the alpha, beta, and gamma wave analysis during driving, EEG headbands, and mobile devices. AvaCars will be developed to allow researchers and application developers to access information about virtual cars. This work extends current infrastructure to include the cloud for real-time monitoring and feedback. A successful integration of the cloud into the system has great potential to enhance the accuracy and reliability of the system. <br\/><br\/>The proposal raises multiple research questions and establishes research directions that can be pursued to address these questions when the proposed infrastructure is made available. The following research activities will be pursued: <br\/>- Design of a portal with AvaCar of a vehicle and road conditions with all the timeline of events;<br\/>- Measurements of driver attention and vehicle condition using mobile phones, OBDII, and CAN bus;<br\/>- Measurements of the driver distraction using EEG-based headband;<br\/>- Design of an infrastructure for near real-time notifications and alerts to drivers in an area;<br\/>- Real-time guidance to the driver for optimal fuel consumption, energy-efficient localization, and speed tracking; <br\/>- Proactive prediction of drivers? behavior during accidents, hazards, and construction; and,<br\/>- Performance analysis, sensitivity analysis, and calibration for V2C2V.<br\/>Broader Impacts: <br\/>The proposed instrument can greatly impact the capability to assess and\/or improve the driving performance of people with disabilities, senior citizens, teen drivers, physiotherapists, and proper physical exercises. Overall, the project contributes to personal and road safety, optimized fuel consumption, and energy-efficient localization. The project incorporates the use of the infrastructure in the curricula of the different institutions involved. Course content, focused on cloud computing and vehicular communications, will be developed and tailored to computer science, electrical engineering, mechanical engineering, and cognitive science programs at participating departments. The research team will build on their existing outreach and educational programs to attract diverse undergraduate and graduate students and involve them in the MRI project.","title":"MRI: CloudCar: Development of a Diverse Distributed Instrument for Vehicles in the Cloud","awardID":"1229700","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[522520,"528479"],"PO":["557609"]},"193978":{"abstract":"This project will investigate, prototype and evaluate CloudFence, a proposed framework that allows users to independently audit the treatment of their private data by third-party online services, through the intervention of the cloud provides hosting said services. Specifically, the PI will investigate, novel techniques for conducting fine-grained tracking of ``information of interest'' (as defined by the user of the cloud service, in a flexible, context-sensitive manner) toward (a) providing increased transparency to end users of the handling of their information by the cloud, and (b) enabling the periodic (or even continuous) auditing of said handling, either by the user or an agent acting on her behalf. <br\/><br\/>The underlying hypothesis is that it is possible to create a general-purpose, application-agnostic information tracking mechanism across the cloud that can operate on both legacy and newly developed applications, such that users can leverage their trust on the infrastructure provider without imposing unreasonable constraints on said provider (e.g., not requiring manual inspection of applications). <br\/><br\/>The project will take a systems approach, aiming to demonstrate the feasibility, effectiveness, and limitations of CloudFence by applying it to real problems encountered in managing the cloud computing infrastructure of the PI's department; a significant part of the effort will go toward system evaluation. Tangible results of the effort include (a) a new architectural framework for information auditing in a cloud environment, (b) software prototypes demonstrating the concepts, (c) conference and journal publications and reports, and (d) a network security lab focusing on cloud and web security.","title":"TWC: Small: Auditing PII in the Cloud with CloudFence","awardID":"1222748","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["549898","564223"],"PO":["366560"]},"194715":{"abstract":"For nearly 40 years, the United States has faced a critical problem: increasing demand for energy has outstripped the ability of the systems and markets that supply power. Today, a variety of promising new technologies offer a solution to this problem. Clean, renewable power generation, such as solar and wind are increasingly available. Hybrid and plug-in electric vehicles offer greater energy efficiency in transportation. The power grid that manages the generation, transmission and distribution of electric power, however, was designed and constructed in the 1960?s and is ill-suited to handle these emerging energy technologies. Operating the electrical grid using power sources with random and uncertain availability, like solar and wind, requires new sensing and control methods. Widespread use of plug-in\/hybrid electric vehicles (PHEV) will not only require far greater power capacity, but will also radically change the peak usage profile, with large evening demand that cannot be shifted. To address this problem, our current power grid must be upgraded with a control system that uses the full power of modern sensor and computing technology to increase efficiency. This new power grid, with an integrated, modern IT control plane is commonly referred to as the Smart Grid, which uses distributed control, customer integration and market based control mechanisms. <br\/><br\/>It is critical to build security features into this Smart Grid from the beginning to ensure fairness, to provide warnings of misuse, to provide control algorithms that minimize damage from malicious behavior, and most importantly, to provide robustness and high-availability of power delivery even in the presence of bad-faith actors. This project develops methods to achieve security in power and market delivery. This entails a study of economic market models with stability as one objective but also in consideration of new sources of power and usage, both on the producer and the consumer sides. To achieve security, the following techniques are used synergistically: vulnerability discovery by formal analysis; on-line monitoring, anomaly and specification-based intrusion detection; and recovery and reconstitution by feedback control. Unique to this project, it is emphasized that the security enhancements take place at both the market level and the system level, requiring separate state-estimation models. These seemingly disparate domains are unified through mapping functions among the states of the respective models. By integrating the two control models, future Smart Grids can detect and respond to activity, either malicious or caused by natural disturbances, that threaten either level; the unification of the models permits the investigation of attacks that possibly impact both levels. Results of this work would lead to a secure and reliable Smart Grid architecture that is robust in the face of attacks on both the power delivery and market control systems. The inherent cross-disciplinary nature of the research will educate future researchers to be conversant in both cyber-security and associated economic issues, through co-advising between the departments of Computer Science and Economics at both UC Davis and Pennsylvania State University and through course modules developed under this work, again involving both campuses. Results will be transitioned to partnership with PG&E, SMUD, the West Davis Village, and other utilities in California, Pennsylvania, and Connecticut.","title":"TWC: Medium: Collaborative: Towards Securing Coupled Financial and Power Systems in the Next Generation Smart Grid","awardID":"1228717","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["556038","562302"],"PO":["565264"]},"193505":{"abstract":"This project takes a comprehensive look at inter-domain traffic engineering, and how it can be done efficiently through cooperation as well as competition between Internet Service Providers (ISPs), and at different timescales. Using network flow decomposition and separate convex optimization techniques, the project seeks to design distributed inter-domain traffic engineering solutions that, along with effective intra-domain traffic engineering, converge to optimal traffic flows in the entire Internet. The project also involves modeling of traffic engineering - under competitive pricing of inter-domain forwarding by ISPs - as a two-timescale pricing-forwarding game, and the study of existence, computability, and efficiency of the equilibrium. The project explores dynamics and convergence of distributed pricing updates by ISPs, and compare different pricing strategies and models like point-to-destination pricing vs. point-to-anywhere pricing, linear vs. non-linear pricing, and cascaded vs. non-cascaded pricing.<br\/><br\/>The project considers inter-ISP interactions and decision-making at multiple timescales that involve traffic forwarding (fast timescale) and pricing updates (slow timescale), where decision-making on a slower timescale may depend on that at a faster timescale. Furthermore, the project considers both cooperative and competitive approaches through which the Internet as a whole (and not individual ISP networks or Autonomous Systems) can be utilized efficiently. The models and approaches considered take into account the control and operational structure of the Internet that consists of multiple providers seeking to maximize their individual benefits, and accordingly considers the relevant issues like competitive efficiency. Using these models, the project seeks to develop competitive pricing-forwarding solutions that can converge to efficient and stable traffic flows in the entire network (Internet.<br\/><br\/>Broader impact: The issues that the project investigates are timely, and fundamental to the efficient operation and economic viability of the Internet in the long run. Solutions that the project is developing will improve the overall use of the Internet bandwidth resources through optimal\/near-optimal traffic cross-provider engineering in the Internet. Pricing strategies developed and investigated in this project will improve the Internet's economic efficiency and viability through inter-ISP competition. For providers, this would imply more efficient and flexible management of their available resources, better investment in infrastructure, and higher revenue overall. For end-users, it would imply better service at lower cost. Research results will be used in advanced graduate coursework on network optimization and algorithmic game theory. The PIs will also enhance the research and educational experience of undergraduate students, by supervising undergraduate research projects.","title":"NeTS: Small: Inter-Domain Traffic Engineering though ISP Cooperation and Competition","awardID":"1218374","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[518263,"531799"],"PO":["564993"]},"194836":{"abstract":"Proposal #: 12-29213<br\/>PI(s): Cao, Yu; Kizza, Joseph M; Li, Ming; Tanis, Craig;<br\/>Institution: University of Tennessee Chattanooga<br\/>Title: MRI: Acquisition of HPC-B: A High Performance Computational Infrastructure for Biomedical Informatics Research<br\/>Project Proposed:<br\/>This project, from an EPSCoR state and a non-PhD granting institution, acquiring a high performance computational infrastructure to be located at U. of Tennessee, Chattanooga (UTC), aims to support, as a shared facility, five research projects involving ten investigators and 18 students (9 UG, 6 MSc and 3PhD). The proposed projects explore three requirements for a viable, productive and usable health information technology. The project addresses the need to<br\/>- Retrieve relevant information from biomedical data, with accuracy and security; <br\/>- Analyze the data; and <br\/>- Disseminate and share the data. <br\/>Biomedical records hold enormous amounts of multimodal data. Thus, the research efforts described focus on actions needed to make this data available (complete, secure, and reliable). <br\/>The proposed research questions are organized into three main thrust areas: How to<br\/>- Discover clinically and biomedically important knowledge from complex biomedical multimedia data; <br\/>- Evaluate and improve the quality and safety of health care by analyzing the large amount of clinical data; and<br\/>- Facilitate the biomedical information collection, management, exchange, and analysis with large-scale network computing platforms and telemedicine systems. <br\/>The computational infrastructure is expected to serve as an essential shared research instrument, allowing researchers to analyze, design, develop, test, and deploy large-scale and distributed computer algorithms to address a variety of computationally-intensive and data-intensive biomedical informatics research challenges.<br\/>Broader Impacts: <br\/>Due to a large potential number of users, its convincing educational plan, outreach plan, as well as expected scientific discoveries in a very important area for every society: health care, this work exhibits potential for strong broader impacts. The programs to enrich broader impact aspects will not only be felt locally, but also internationally, and help to ensure that the country maintains leadership and innovation within the addressed research domains.","title":"MRI: Acquisition of HPC-B: A High Performance Computational Infrastructure for Biomedical Informatics Research","awardID":"1229213","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["196924","543501","549913","549913",522032],"PO":["557609"]},"193626":{"abstract":"Program analysis provides solid foundations for a broad range of applications, such as detecting security vulnerabilities, localizing program faults, proving program correctness, and optimizing performance. A pervasive and critical challenge in program analysis is to handle library functions and system calls, which provide an essential execution environment for a program and would be ideal to be co-analyzed with the program itself. Despite its importance, achieving program-environment co-analysis in practice is challenging. First, the difficulty to acquire the source code of some environmental functions precludes source code based analysis. Moreover, even if source code is available, the code base is often prohibitively large and complex, making analysis difficult. Existing solutions are to provide program analysis with either manually-constructed models, which do not scale, or imprecise models, which are overly conservative.<br\/><br\/>In this project, the goal is to apply program synthesis technique to construct models for environmental functions from their binary implementation and a set of initial inputs. The models are essentially programs that provide the same functionality of the functions being modeled, yet substantially simplified. Such programs can be included as part of the application, enabling program-environment co-analysis. The proposed technique will lead to an automated solution that will offload the onus of manually crafting models from program analysis developers' shoulders. Moreover, it will demonstrate the feasibility of precise program-environment co-analysis through applications.","title":"SHF: CSR: Small: Collaborative Research: Automated Model Synthesis of Library and System Functions for Program-Environment Co-Analysis","awardID":"1218993","effectiveDate":"2012-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["550848"],"PO":["564388"]},"191448":{"abstract":"This Project will support the web-based data sharing of high-resolution, high-quality, whole mouse brain data obtained from an innovative 3D microscopy technology called Knife-Edge Scanning Microscopy (KESM). Furthermore, the data from KESM will be linked to other existing, complementary data sets such as the Allen Brain Atlas containing extensive gene expression data, effectively multiplying the utility of the resource for neuroscientists studying the brain by relating structural data (microstructure) to functional data (gene expression).<br\/><br\/>The central goal of this project is to devise a web-based data dissemination framework to link and to deliver massive amounts of mouse brain data (up to 2 terabytes per brain) to the neuroscience research community in an easily accessible form. To this end, the research team will design and develop a light-weight, web-based 3D visualization and annotation framework so that the KESM data can be viewed, annotated, and analyzed at multiple resolutions (imagine Google Maps in full 3D). The project is expected to result in a unique resource that provides an unprecedented look into the wiring of the entire mouse brain in the context of large-scale gene expression data. Such a resource can help scientists begin to unravel the intricate functions of the brain, and in the long term enable the construction of intelligent artifacts based on such an understanding. <br\/><br\/>The project will involve graduate and undergraduate researchers, and a simplified version of the resource will be created to kindle interest and fascination for brain science in K12 students and in the general public. The framework developed in this project is expected to have broader application in geology, meteorology, and even in astronomy where huge amounts of 3D data are gathered routinely yet the access limited due to the massiveness and 3D nature of the data. All data and software resulting from this project will be released in the public domain, available in full at http:\/\/kesm.org.","title":"CRCNS: Data Sharing: Open Web Atlas for High-Resolution 3D Mouse Brain Data","awardID":"1208174","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"7275","name":"CROSS-EF ACTIVITIES"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"7714","name":"MODULATION"}}],"PIcoPI":["535313","535314","535315"],"PO":["565284"]},"194726":{"abstract":"Proposal #: 12-28778<br\/>PI(s): Matthias K Gobbert; Erill, Ivan; Olano, Thomas M; Sparling, Lynn; Thorpe, Ian<br\/>Institution: University of Maryland Baltimore County<br\/>Title: MRI\/Acq.: Hybrid CPU\/GPU Nodes for the Interdisciplinary UMBC High Performance Computing Facility <br\/>Project Proposed:<br\/><br\/>This project, acquiring an instrument based on advanced GPU\/CPU computers with 360 TB high-performance storage and high-speed communication links, aims to enhance the current UMBC High Performance Computing Facility. The instrument enables research in emerging data-intensive high-performance computing topics. This multi-disciplinary and collaborative project involves faculty and students from biology, chemistry, computer science and engineering, electrical engineering, environmental systems, mathematics, physics, and statistics. <br\/>The following current, as well as new research projects, benefit immediately from the availability of the enhanced high-performance computing instrument:<br\/>- Parallel Algorithms for Numerical Simulations of Partial Differential Equations; <br\/>- Application of GPU Processing to Atmospheric Chemistry and Dynamics Modeling;<br\/>- Atmospheric Remote Sensing; etc.<br\/><br\/>Broader Impacts:<br\/><br\/>Research and educational initiatives should be highly impacted by the research enabled through the instrument. The research team, including female faculty members, has interactions with the Women in Science and Engineering (WISE) organization and the Center for Women in Technology (CWIT). Undergraduate students will be involved in the UMBC REU site on high performance computing. Furthermore, the instrumentation should contribute to attract students from under-represented groups into sciences. Presented are plans and initiatives to do so.","title":"MRI: Acquisition of Hybrid CPU\/GPU Nodes for the Interdisciplinary UMBC High Performance Computing Facility","awardID":"1228778","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[521587,521588,521589,521590,521591],"PO":["557609"]},"193516":{"abstract":"Diffractive masks and algorithms for light field capture<br\/>PIs: Ramesh Raskar, MIT Media Lab Alyosha Molnar, Cornell ECE<br\/><br\/>Advanced imaging and display technology requires integrated, low cost systems able to efficiently capture and characterize light from 3-D scenes. In particular, a 3-D scene can be described by the collection of light rays it generates, called the light field. This research combines concepts from mask-based light-field imaging with angle sensitive pixels (ASPs). While mask-based light-field capture is much better understood mathematically, and masks are cheaper to manufacture and more easily modified on-the-fly, diffractive ASPs provide smaller, denser light field sensors, and provide naturally compressible outputs. This project combines the physics and signal processing of these approaches to enable optical imaging systems that capture more information than normal cameras while reducing the system's complexity. This work broadly impacts diverse applications spanning consumer imaging and displays, machine vision and automation, scientific\/medical imaging and displays, robotic surgery, surveillance and remote sensing.<br\/><br\/>3-D images and video can be captured by measuring the combined spatial and angular distribution of light (the light field). This research combines two techniques for light-field capture: mask-based light-field imaging and diffractive angle sensitive pixels (ASPs). A critical element of this work is the development of a mathematical framework that maps between conventional geometric light fields and the diffractive optics upon which ASPs rely. A second element is constructing hybrid systems based on this mathematics, leveraging diffractive effects in mask design, and combining masks with ASPs in single light-field cameras. This work also combines formalisms in existing light field methods with knowledge about real 3-D scene statistics to develop optimal (in the sense of usability and compressibility) basis sets for sampling and encoding the light-field. All of these aspects combine to reduce the size, cost and complexity of light field cameras, while simultaneously enhancing their capabilities.","title":"CGV: Small: Collaborative Research: Diffractive masks and algorithms for light field capture","awardID":"1218411","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["532050"],"PO":["565227"]},"194847":{"abstract":"Proposal #: 12- 29236 Collaborative Proposal #: 12-29250<br\/>PI(s): Valavanis, Kimon P.; Gao,David Wenzhong; Mahoor,Mohammad;Rutherford,Matthew J;Yi,Yun-Bo and Collab PI(s): Boussalis, Helen R.;Guillaume, Darrell; Wu, Chivey<br\/>Institution: University of Denver and Collab Institution: California State-LA University<br\/>Title: MRI: Collaborative: Dev. of an Integrated, Intelligent, Autonomous, Unmanned, Mobile Sensor<br\/><br\/>Project Proposed:<br\/><br\/>This project focuses on the development of an integrated, intelligent, autonomous unmanned mobile sensor will enable research into the foundations of the next generation of autonomous Unmanned Aerial Systems (UAS). The objective of this proposal is to develop an unmanned helicopter (about 150 kg weight) along with a mobile landing platform for refueling purposes. The aircraft would be able to operate with both electric and fuel. The instrument will be composed of two tightly coupled components, a<br\/>(i) Novel light-weight unmanned helicopter (<150 Kg), and,<br\/>(ii) General purpose landing platform that will also serve as a refueling\/recharging station and data relay\/repository. <br\/>This composition of the instrument is expected to pave the way for the next generation of multi-purpose\/cost-effective UAS into civilian and public domain applications. The proposed integrated two component instrument development is not considered as an extension of existing technology. It will enable heterogeneous networked unmanned systems operating in unison in traditional\/extreme environment. The following specific research projects will be enabled through the instrument: <br\/>- Fault-Tolerant and Emergency Landing Navigation and Control Systems<br\/>- RADAR-based Sense-and-Avoid System<br\/>- Prognosis and Structural Health Monitoring of UAVs<br\/>- Networked Unmanned Systems (NUS)<br\/>- Integration: Software Reliability and Security<br\/>- Unmanned Helicopters for Civilian\/Public and Industrial Applications<br\/><br\/>The University of Denver (DU) and California State University Los Angeles (CalStU-LA), a predominantly minority-serving institution, collaborate in the project. <br\/><br\/>Broader Impacts: <br\/><br\/>The impact should be felt both regionally and nationally. At the national level, the instrument should initiate transformative advances in the computational algorithms proposed. The results will be made available to the broader research community in the form of open-source codes. Simulations made possible by these algorithms will have broad national and societal impact ranging from climate change scenarios to wind power generation to plant biotechnology and improved animal breeding.<br\/><br\/>At the institutional and regional levels, DU faculty\/students will collaborate with CalStU-LA faculty\/students to enhance the ethnic and gender diversity of the student population, especially recruiting minority students. Project goal include increasing the educational\/training opportunities for underrepresented students, and the number of graduates in STEM fields.","title":"MRI Collaborative: Development of an Intelligent, Autonomous, Unmanned, Mobile Sensor","awardID":"1229250","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[522070,522071,522072],"PO":["557609"]},"194737":{"abstract":"The operating system (OS) exercises complete control over applications, thus a compromise of the OS compromises every application. Software developers have little recourse to improve security in the face of system compromise---they cannot defend against OS vulnerabilities, nor can they reasonably substitute a secure version of the millions of lines of code that constitute a modern OS.<br\/><br\/>Rather than require applications to blindly trust OS interactions, this project investigates a system architecture that enables trusted applications to efficiently verify OS interactions with the help of a small, trusted hypervisor. Most verification work is performed within the C language runtime, minimizing changes to legacy code and shielding developers from increased programming complexity.<br\/>The prototype system, called InkTag,improves upon prior work in several key areas: it provides more efficient techniques to verify system call results, implements usable access control for resources managed by an untrusted OS, and introduces hardware and software techniques to further reduce the size of the trusted computing base.<br\/><br\/>Cloud computing provides energy and economic efficiencies, but suffers from the inability to give meaningful security guarantees to hosted applications. This project demonstrates that system security is possible without trusting the OS---a large part of the hosted infrastructure. This project is also developing new materials for undergraduate and graduate curricula that combine core knowledge of systems with an understanding of how systems provide security properties, equipping future computer professionals with a better understanding of what security guarantees a system can meaningfully provide.","title":"TWC: Medium: Collaborative: Trustworthy Programs Without A Trustworthy Operating System","awardID":"1228843","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["555324"],"PO":["565327"]},"193648":{"abstract":"Multiple-input multiple-output (MIMO) technology provides a means of boosting network capacity without requiring additional spectrum by exploiting spatially multiplexing, interference suppression, and spatial diversity. It has received widespread attention over the past decade from both industry and academic researchers, now forming a key component of nearly all emerging wireless standards. Despite the huge promise and considerable attention, a rigorous algorithm-theoretic framework for maximizing network capacity in multihop wireless MIMO networks is missing in the state of the art. This project establishes both the computational hardness and approximation hardness of maximizing network capacity in multihop wireless MIMO networks, and develops practical approximation algorithms with provably good performance. A polyhedral approach is taken by the project to construct various polynomial approximate capacity subregions of multihop wireless MIMO networks. These approximate capacity subregions not only are the algorithmic foundation of maximizing network capacity in multihop wireless MIMO networks, but also serve as a basis for interesting future projects on cross-layer design and optimizations in multihop wireless MIMO networks. They are also of independent interest to the theoretical computer science community and communications community at large. This project provides scholarships to graduate students and offers research topics for strong dissertation works on multihop wireless networks. The outcome of this project will not only be disseminated to the professional researchers through journals and conference proceedings, but also be integrated into the lecture notes targeted for senior undergraduate students and graduate students.","title":"NeTS: Small: Collaborative Research: Maximizing Network Capacity in Multihop Wireless MIMO Networks","awardID":"1219109","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[518604],"PO":["565303"]},"193538":{"abstract":"Humans are constantly making judgments about the world based on material appearance (e.g. is something old or new, clean or dirty, soft or hard?). A material appearance editor is an essential feature in any software system for generating synthetic photorealistic images. Increasingly the applications that rely on photorealistic imagery -- design, historical reconstruction, training, and entertainment -- depend on renderings of high visual quality. Ultimately human perception determines what is required for high visual fidelity. However, very little work has been done modeling human perception of materials in a form that can be applied to computer graphics rendering systems. In this project, the researchers are conducting a series of physical and psychophysical experiments with the goal of developing a material appearance model that is applicable to computer graphics. The focus is a class of materials with clear economic impact -- materials used in architectural design. This work holds promise of a strong impact on architectural-design and material manufacture by providing high-quality visualization of architectural materials. It will accelerate developing architectural materials by allowing researchers to simulate material appearance with physical accuracy as well as perceptual fidelity. Additionally, the psychophysical experiments will provide new insights into human vision.<br\/><br\/>The goal of this work is to produce a material appearance model that informs the efficient modeling, measurement and representation of materials for visual simulation. The results obtained in the process of developing this model include:<br\/>- an apparatus particularly suited to measuring architectural material appearance properties.<br\/>- psychophysical measures of the perception of materials accounting for directional, scale, and surround effects that are typical of architectural applications.<br\/>- simplified material models, based on applying psychophysical measures to physical data.<br\/>- experimental results verifying the visual accuracy of simplified material models.<br\/>- a common database for both physical and psychophysical measures of material appearance for architectural applications.","title":"CGV: Small: High-Fidelity Representation of Architectural Material Appearance","awardID":"1218515","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["541919","548698"],"PO":["565227"]},"193307":{"abstract":"Embedded computer systems have become essential to many aspects of our lives. Cheaper, smaller, faster, more sophisticated, and more energy-efficient embedded devices spur ever new applications. However, the growing complexity and shift to multicores make programming and debugging these systems difficult. Traditional debugging is time consuming and may interfere with program execution, causing some bugs to become irreproducible and making it unusable in real-time environments. Moreover, tracing a processor?s internal state during execution is only feasible for short program segments and requires large on-chip buffers or wide trace ports, either of which increases system cost and limits scalability. This project is developing the next generation of trace compression methods and infrastructure to make continuous, real-time, unobtrusive, and cost-effective program, data, and bus tracing possible in embedded systems. The approach relies on on-chip hardware to record the processor state and corresponding software modules in the debugger. The novel insight is that a sequence of trace records can be translated, without loss of information, into a much shorter sequence of miss events using small hardware structures. The few remaining miss events are then further compressed using highly-effective yet simple-to-implement encoding schemes, yielding heretofore unseen compression ratios.<br\/><br\/>The new tracing and debugging infrastructure can help programmers find difficult and intermittent software bugs faster, thus improving productivity. For example, reducing debugging time by just one percent amounts to hundreds of millions of dollars annually in saved salaries, with a concomitant reduction in software cost and time to market. Moreover, higher quality software may eliminate errors in medical, automotive, or mission-critical devices and thus save lives.","title":"CSR: Small: Collaborative Research: Real-Time and Unobtrusive Tracing in Multicore Embedded Systems","awardID":"1217470","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[517808],"PO":["565255"]},"193428":{"abstract":"The fast-advancing modern nonvolatile memory technology includes flash memory and phase-change memory as the two most notable representatives. It is critical to create new schemes and architectures to improve their energy efficiency as well as their write speed, reliability and memory longevity. New schemes should fully utilize the unique properties of the memory technologies, including cell programming models, error models and endurance models. The key is to control cell states more flexibly and robustly by closely coupling novel coding schemes with the physics of these memory technologies.<br\/><br\/>In this project, a novel green storage technology will be developed based on coding theory for nonvolatile memory. The focus will be on flash memory and phase-change memory that share many common features. A new scheme for representing data using relative cell levels will be studied; it optimizes the energy efficiency for both writing and error correction. A novel variable-level cell technology will be developed to maximize storage capacity. New error-correcting codes will be designed to correct memory-specific errors. In addition, new processing techniques will be developed to balance the power consumption at peak and non-peak times. <br\/><br\/>The new designs will be integrated to form a comprehensive solution, and their performance will be analyzed thoroughly. The results will contribute to providing a new platform for high-performance ubiquitous computing based on nonvolatile memories.","title":"CIF: Small: Collaborative Research: Coding for Green Storage Technologies in Nonvolatile Memories","awardID":"1218005","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["549584"],"PO":["564924"]},"194759":{"abstract":"Unauthorized online behavior motivated by social, political, economic and cultural (SPEC) conflicts is increasing. However, research dealing with cyber-attacks has tended to be reactive and to focus on defense, instead of proactive and focused on the root psychological and social causes of such attacks. Despite considerable evidence that trust and distrust impact rule-following behaviors and obedience to the law, little research investigates the role of distrust in promoting unauthorized online behaviors. Critically, trust\/distrust research in other areas suggests the cyber-attacks might be reduced through interventions aimed at forms of distrust. Thus, advancing knowledge about distrust in general and in this specific domain is important both for social science and cybersecurity. <br\/><br\/>The present project will answer questions about whether different types of distrust have different effects on willingness to engage in or provide support for cyber-attacks, and will investigate the effectiveness of sociotechnical interventions designed to reduce unauthorized online behaviors. The central hypothesis is that relationships between distrust and unauthorized online behaviors (or support of such behaviors) depend on the specific bases of distrust, and require different remedies. The project will achieve its aims by the development of vignettes that systematically vary conditions likely to foster trust or distrust and motivation for unauthorized online behaviors. The effects of the variables manipulated in the vignettes will be tested in other groups of students using online experiments and simulation (role-playing) activities. The project will also develop and test an online deliberative space that can both take advantage of the research findings and provide an environment for theory-testing. Specifically, the online prototype will be able to manipulate key trust\/distrust-relevant features of the deliberative space while measuring and tracking participant online behaviors, providing data that can then be subject to data mining procedures in order to find important patterns of behavior related to trust and distrust.<br\/><br\/>The intellectual merit of the current research is that it uses distrust as an organizing construct to understand individual behaviors and attitudes toward security in cyberspace and innovatively uses science communication as the specific application domain to investigate cybersecurity. By examining the antecedents and consequences of distrust, and by integrating a variety of research approaches, this research will both (a) advance theoretical models of trust and distrust generally, and (b) enhance the prevention of cyber-attacks specifically by providing insights that contribute to the design of institutions and interventions perceived as legitimate and obedience-worthy even in the context of culturally divisive issues. <br\/><br\/>The broader impacts of the proposed activities are that the research findings will contribute to the creation of online spaces for public engagement that encourage optimal behavior and reduce destructive and ethically questionable behaviors (e.g., cyber-attacks, hacktivism). The platform developed for our research will be widely applicable to studying problems in other domains, and can be used to further research, as well as in applied educational and policy contexts. Through this project, hundreds of undergraduate and graduate students will be exposed to topics beyond their discipline including cybersecurity, climate change and public deliberative engagement. Finally, by educating students about online deliberation, pros and cons of argumentative discourse, public engagement and policy making, we are training future scientists to be leaders and world citizens.","title":"SBES: Medium: Investigating the Role of Distrust in Unauthorized Online Activities Using an Integrated Sociotechnical Approach","awardID":"1228937","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[521702,521703,"526198",521705,521706],"PO":["559060"]},"193318":{"abstract":"Improving the usage of communication spectrum resources is critical to future wireless systems. The OSTARA project focuses on the development of RF photonic techniques that support the ability to simultaneously transmit and receive in wireless devices. The effort involves a mix of theoretical development (specifically investigating potential improvements in capacity), as well as systems validation efforts involving building an opto-cancellation circuit capable of cancelling out co-site interference associated with simultaneous transmission and reception. . Specifically, the theoretical component of the effort will involve using ray-tracing to understand the role of cancelation of multipath components on communication rate, as well as an investigation into the impact of idealized cancellation on network capacity using graph coloring. The systems component of the effort will involve developing photonic circuits that subtract off the transmitted signal from the receiver chain, as well as potential multipath images of the transmitted signal. Validation will involve field testing the opto-canceller by setting up test scenarios on the ORBIT testbed at WINLAB.<br\/><br\/>Broader Impact: The proposed research will improve the spectrum utilization of future wireless systems, an issue of critical national importance. Additionally, the project will educate students and post-doctoral fellows in the inter-disciplinary area of RF-photonics as applied to advanced radio systems.","title":"NeTS: Small: Collaborative Research: OSTARA: An Optically-based Simultaneous Transmit And Receive Architecture for Enhancing Wireless Communications","awardID":"1217517","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["531726"],"PO":["564993"]},"194649":{"abstract":"This project aims at developing efficient methods for protecting the privacy of computations on outsourced data in distributed settings. The project addresses the design of an outsourced storage framework where the access pattern observed by the storage server gives no information about the actual data accessed by the client and cannot be correlated with external events. For example, the server cannot determine whether a certain item was previously accessed by the client or whether a certain algorithm is being executed. This property provides a high level of privacy protection that goes far beyond standard data encryption. The project also deals with advanced methods for verifying the correctness of outsourced computations, focusing on keyword searches and graph algorithms. The educational component of the project includes a curricular development effort for introductory computer security courses.<br\/><br\/>The project has applications to a broad range of web services widely used by business and consumers. Privacy-preserving access for outsourced data is relevant to web-based email and office applications. Also, it is especially important for the management of proprietary business data, medical data, and other sensitive personal data.","title":"TWC: Medium: Collaborative: Privacy-Preserving Distributed Storage and Computation","awardID":"1228485","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[521367],"PO":["562974"]},"192956":{"abstract":"Multiterminal (MT) video coding considers the problem of separate compression and joint decompression of multiple correlated video sources. Driven by a host of emerging applications (e.g., in network communications, distributed video sensor networks and camera arrays, and distributed inference), MT video coding has become a very active area of research in the past ten years.<br\/><br\/>This research addresses both the theory of MT source coding and practice of MT video coding, with the aim of using the theory to guide practice. It involves: 1) identifying new classes of problems of quadratic Gaussian MT source coding with tight sum-rate bound or giving sufficient conditions for sum-rate tightness; 2) taking an approximation approach when sum-rate tightness cannot be proved; 3) performing MT source code constructions based on Slepian-Wolf coded quantization for random coding and hybrid random-structured coding; and 4) spearheading the practical application of MT video coding for camera arrays and distributed video sensor networks, with focus on depth camera assisted MT video coding.","title":"CIF: Small: Multiterminal Video Coding: From Theory to Practice","awardID":"1216001","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[516912],"PO":["564898"]},"192967":{"abstract":"How do institutions organize to perform the many functions that they seek to perform, such as education, health, infrastructure, market regulation, or policing? How do they interact internally and with other organizations in the society at large to execute these functions and gain feedback on their performance, and what are the implications of these patterns of activity and connectivity? This project proposes that institutions are complex systems that self-organize so as to provide a range of essential products, services, rules, and regulations for the economy and society. It will use the growing presence of institutions on the Internet to gather and analyze the first comprehensive, objective dataset on the functions institutions perform and the connectivity of individual institutions with each other and with different parts of society. <br\/><br\/>The project will develop novel methods for community discovery, graph mining, and analytical web crawling to transform the information in the websites of U.S. institutions, and the linkages of these websites with each other and with societal organizations, into a pilot dataset on the activity and connectivity of institutions in the United States. These data will then be used to investigate the nature and evolution of the activity and connectivity of U.S. institutions, and their implications for public policy, relations with business and society, and economic productivity and performance. The project will open new avenues for analysis of variation in the activity and connectivity of institutions, including a range of new indicators of institutional linkages and connectivity, as well as new techniques for web crawling, data mining, and data analysis of complex networks. The project will also form the basis for new techniques and collaborations between computer scientists and economists.","title":"ICES: Small: Using Web Crawling and Complex Network Analysis to Understand Institutional Activity and Connectivity","awardID":"1216028","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":["516935",516935,"516937",516937],"PO":["565251"]},"190789":{"abstract":"Prosody is a critical component of spoken communication. Loosely defined, prosody is ?how words are spoken?, as opposed to ?what words are said?. Prosody is typically defined to include pitch, intensity, and timing -- and systematic variation in these parameters can reinforce or augment a speaker?s intended meaning. Prosody provides important information at every linguistic level, disambiguating syntax, augmenting semantics and pragmatic information, e.g. by conveying information about phrasal grouping and phrase-level prominence. Emotions and other speaker-state information are also communicated through a speaker?s prosody. <br\/><br\/>Although this aspect of speech is important, it remains under-investigated. A major limiting factor is the lack of large sample of prosodically labeled speech. Prosody researchers at CUNY, Columbia and MIT are developing Reciprosody, a web source of prosodically annotated data and tools for analysis. Reciprosody makes critical resources for the study and teaching of prosody available to a growing and diverse population of researchers, students, and technologists. This website hosts data in any language, annotated under any prosody standard. The only restriction for hosting data in the repository is that it must be made freely available for academic and educational activities. <br\/><br\/>Reciprosody is not merely a passive repository, but an active resource for researchers and educators to communicate with each other on a regular basis. This enables the resource to be a center not only for annotated data, but information and support related to ongoing prosody research.","title":"Collaborative Research: CI-P: Reciprosody - A Repository for Prosodically Annotated Material","awardID":"1205402","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[511474],"PO":["565215"]},"194804":{"abstract":"Proposal #: 12-29108<br\/>PI(s): Holland-Minkley, Amanda<br\/>Institution: Washington and Jefferson College<br\/>Title: MRI\/Acq.: Acquisition of Eye Tracking System<br\/>Project Proposed:<br\/>This project from an undergraduate-serving institution, acquiring an Eye Tracking system, aims to add quantitative measures of changes in problem-solving techniques to more traditional outcomes-based assessments of student learning. The eye tracking system enables pursuing further work and greater quantitative analysis in design and usability research focused on issues such as the effect of the interface design of security-focused software on the secure behaviors and awareness of security features of the software users.<br\/>Current work at the institution focuses on the particular application of these methods in an introductory programming course. The Information Technology Leadership (ITL) faculty have broaden their research to encompass more mobile computing that has contributed in developing a collaboration with Biology faculty. In turn, this collaboration has given rise to a mobile application used when collecting ecological data in the field. A beta version, now under assessment, has been created and deployed where the eye tracking methods will be used to confirm that mobile technologies enable not only more accurate data collection, but better learning and retention on the part of the student researchers in the field.<br\/>Broader Impacts: <br\/>This solely undergraduate institution core mission focuses on research involving significant undergraduate collaboration. In particular, the ITL Department is committed to enabling its majors to take part in significant research projects that allow them to act as true collaborators and not simply as coders or lab technicians. Thus, with an existing history of engaging undergraduates in design and usability research, a modern eye tracking system will strengthen the program making it accessible to more students. The system will play a role in classroom activities, labs, and independent projects. Students should gain fluency with the tool and with appropriate methods for using it in regular coursework. A service management course will be required for all seniors to partner with local non-profits to provide technical consulting or development. The system provides a platform for continued interdisciplinary research, including ongoing work in Biology and potential projects that involve Political Science, Gender and Women?s Studies, Sociology, and Psychology.","title":"MRI: Acquisition of Eye Tracking System","awardID":"1229108","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[521864],"PO":["557609"]},"194925":{"abstract":"Proposal #: 12-29566<br\/>PI(s): Lynch, Kevin M; Argall, Brenna; Colgate, J. Edward; Murphey, Todd D; Wu, Ying<br\/>Institution: Northwestern University<br\/>Title: MRI\/Dev.: Bimanual Robotic Manipulation and Sensory Workspace <br\/><br\/>Project Proposed:<br\/>This project, developing an instrument consisting of robot arms\/arms and vision-related equipment, aims to advance research in dexterous dynamic robot manipulation. The major components of the system are a two-arm manipulation system consisting of two 7-DOF WAM arms and three-finger hands with tactile and force-torque sensors; a sensory workspace consisting of high-speed vision for object tracking and color-depth cameras for lower-speed color imaging and occupancy maps; and a user command and control workstation, all integrated using software running under the Robot Operating System (ROS). The instrument enables research in various areas, such as manipulation, haptics, learning-by-demonstration, gesture recognition, rehabilitation, prosthetics, and novel sensing modalities (e.g., active electrosense).<br\/><br\/>Broader Impacts:<br\/>The area of human-robot interaction should gain much from this instrument. An active area of research, dual-arm manipulation is extremely relevant in the context of manufacturing, which constitutes an important and urgent national concern. In terms of outreach and the involvement of under-represented groups, the team?s track record is evidenced by institutional programs, like summer research opportunities and partnerships to Girl Scout troops and local science museums. This project aims to place PhD students involved in the project as interns at Barrett Technologies, thus providing opportunities to closely collaborate with the robot arm\/hand designer. Such collaboration transcends the traditional vendor-buyer relationship to possibly co-design and co-publish material and software components.","title":"MRI: Equipment Development: Bimanual Robotic Manipulation and Sensory Workspace","awardID":"1229566","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["553637",522422,"555644","541976","182691"],"PO":["557609"]},"194705":{"abstract":"The project explores the influence that offline cues and stimuli, indicating the presence of other human beings in the physical world, and often processed unconsciously by our brains, can have over security and privacy behavior in cyberspace. <br\/><br\/>The project is predicated around an evolutionary conjecture: Human beings have evolved to detect and react to threats in their physical environment, and have developed perceptual systems selected to assess these ?physical? stimuli for current, material risks. In cyberspace, the same stimuli often are absent, subdued, or intentionally manipulated by third parties. Hence, security and privacy concerns that would normally be activated in the offline world are restrained, and defense behaviors are hampered.<br\/><br\/>While it is impossible to test such conjecture directly, indirect evidence compatible with the conjecture can be obtained by investigating the impact that external stimuli in the physical world have on security and privacy behavior in cyberspace. The proposed research consists in a stream of human subjects controlled experiments investigating such impact of various sets of stimuli or cues. <br\/><br\/>This significance of this research is two-fold. First, it attempts to advance the scientific understanding of what makes security and privacy decision making in cyberspace uniquely different from, and sometimes more difficult than security and privacy in the physical world. Second, by investigating a factor that may significantly disrupt user behavior in cyberspace, the research findings could inspire the construction of systems that induce more secure behavior.","title":"TWC SBES: Medium: Collaborative: Evolutionary Approaches to Privacy and Information Security","awardID":"1228684","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["561930"],"PO":["565327"]},"193616":{"abstract":"Malware, especially botnets, have become the main source of most attacks and malicious activities on Internet. Bots communicate with each other and Command & Control servers to coordinate their malicious activities. This project is developing new techniques and tools to detect malicious activities and botnets through analyzing their communication channels. This project plans to investigate mechanisms for detecting these communication channels through several novel mechanisms: (i) through a graph analysis of social contacts, (ii) analyzing graph properties of communication to decipher Peer to peer communication properties of bots and (iii) machine learning based approaches to analyzing network traffic. The automation required to propagate malicious contents and malware will result in different behavior than human behavior in these communication channels. We expect the generated names, content, the time of contacts and communication, the social graph structures to be sufficiently different to enable us to develop techniques for detection of malicious entities. Our work focuses on developing robust techniques that are hard to evade or limit the botnet functions when they try to evade the detection mechanisms. Developed analysis tools will help in detecting botnets in networks and malicious entities in social networks. Educational impact will include training graduate and undergraduate students with valuable research skills while advancing the state of the art in network security and traffic analysis, contributing to the technology workforce. We will publish our results and enable technology transfer to industry.","title":"NETS: Small: Exploiting Social Communication Channels Against Cyber Criminals","awardID":"1218929","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["550709","548314"],"PO":["565327"]},"194716":{"abstract":"In this research controlled economics experiments are used to test the predictions of economic theories that hypothesize effective cybersecurity tradeoffs within an organization depends on both worker incentives and the structure of job duties. In these experiments a team of economists and cybersecurity experts are working together to design virtual world experiments that measure the impact of different incentive arrangements and job design on operational cybersecurity risks. This is particularly interesting in computer intensive environments where the mix of competing tasks include easily monitored tasks with easily verified impact on organizational goals, such as tasks performed by application programming teams, and tasks that have a more ambiguous impact on organizational performance such as tasks associated with cybersecurity practices. In the former case high powered incentives often compete against the relatively low powered incentives associated resulting in the inefficient management of cybersecurity risks. The goal of this research is to better understand how management practice interacts with available cybersecurity technologies and cybersecurity threats to enable better risk management strategies within organizations. Such research provides evidence based findings that will make organizations more aware of their cybersecurity\/operational-efficiency tradeoffs and thus allow them to improve their organizational practices and consequently their risk management strategies against cybersecurity threats.","title":"SBES: Medium: Economic Incentives and Organizations for a Trustworthy Cyberspace","awardID":"1228719","effectiveDate":"2012-09-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[521561,"552989"],"PO":["550223"]},"193748":{"abstract":"Personal healthcare systems based on wearable\/implantable medical devices are being increasingly deployed for a variety of diagnostic, monitoring, and therapeutic applications. A consequence of the increased functional complexity, software programmability, and wireless network connectivity of such devices is that they are now vulnerable to security attacks that have plagued general-purpose computing systems. Recent demonstration of security attacks on commercially deployed systems has raised medical device security concerns significantly. Unfortunately, medical devices come with extreme size\/power constraints and unique usage models, making it infeasible to simply borrow conventional security solutions.<br\/><br\/>This research focuses on developing a non-intrusive medical security monitor that snoops on all wireless communication to\/from medical devices and uses multi-layered anomaly detection to identify potentially malicious transactions. While formal methods have been previously used to check for implementation flaws, they are not geared towards verifying the safety behavior of the medical device software in its interactions with the real world, which can expose logical flaws as well. The work investigates these interactions by transforming properties specified at the real-world interfaces (sensors and actuators) into program properties against which the medical device software can be verified. The findings will be disseminated through conferences and journals. The hardware and software developed will be placed in the public domain, and disseminated to the industry. The knowledge developed will be integrated into various courses. Undergraduates will be encouraged to perform independent research on this topic. Fellowships and outreach programs will be leveraged to encourage participation of female and minority students.","title":"TWC: Small: Collaborative Research: Enhancing the Safety and Trustworthiness of Medical Devices","awardID":"1219570","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["550002"],"PO":["565327"]},"194727":{"abstract":"Deep packet inspection (DPI) is a crucial tool for protecting networks from emerging and sophisticated attacks. However, it is becoming increasingly difficult to implement DPI effectively due to the rising need for more complex analysis, combined with the relentless growth in the volume of network traffic that these systems must inspect. To address this challenge, future DPI technologies must exploit the power of emerging highly concurrent multi- and many-core platforms. Unfortunately, however, current DPI systems severely limit their use of parallelism by either resorting to coarse-grained load-balancing or restricting their analysis to very simple, hard-coded detectors.<br\/><br\/>In order to fully exploit parallel hardware platforms, in this project we develop a comprehensive approach that introduces parallelism across all stages of the complex DPI pipeline. We investigate application-independent scheduling strategies that take existing DPI analyses and automatically parallelize their processing. We do so by mapping them into a domain-specific intermediary representation that abstracts from specifics of the underlying hardware architecture while providing low-level consistency guarantees. Conceptually, the project's goal is to virtualize and abstract parallelism as a fundamental primitive, just like how virtual memory abstracts away physical memory size limitations from programmers.","title":"TWC: Phase: Medium: Collaborative Proposal: Understanding and Exploiting Parallelism in Deep Packet Inspection on Concurrent Architectures","awardID":"1228782","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[521593,521594],"PO":["565327"]},"194738":{"abstract":"The Wireless Philadelphia Network (WPN) is a metropolitan?area network (MAN) consisting of thousands of Tropos 5210 wireless mesh routers distributed across the entire city of Philadelphia and connected by a fiber backbone. This project is employing this network as a testbed to investigate three diverse security challenges facing any large-scale wireless network servicing a heterogeneous population. The first challenge is in efficient network anomaly detection algorithms, and the proposed solution is to investigate the efficacy of both compressive sampling and distributed source coding based approaches in reducing the amount of data that must be transmitted to the anomaly detector. The second challenge is physical layer security in wireless networks, and the proposed solution is to use physical layer based encryption algorithms and user authentication. The third challenge is anomaly detection at the application layer, in particular for web servers, and the proposed solution is to develop software sensors on the hardware, operating system, virtual machine, and application server, and develop rules for identifying possible anomalies using these metrics. Besides the intellectual merit of these challenges, the project has several broader impacts. First, low-income residents gain Internet access through integration with the Freedom Rings Partnership. Second, students participate in community service based engineering design projects. Finally, curricular enhancements and the recruitment of women and minority graduate students improve the educational and diversity missions at our university.","title":"TTP: Medium: Securing the Wireless Philadelphia Network","awardID":"1228847","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[521625,"533237","533238","563559"],"PO":["564246"]},"193528":{"abstract":"The goal of this project is to support the development of big-data analytics and facilitate the deployment of such applications over the different execution environments encountered in the life-cycle of big-data software. The project achieves its goal by (i) designing and implementating a Scalable Analytics Language (SAL) that supports the definition of advanced analytics through user-defined aggregate functions; (ii) developing a compiler for SAL that optimizes parallel MapReduce-oriented executions over distributed systems containing many nodes, and (iii) developing an early accurate result library (EARL) that enhances (ii) with the ability of providing approximate results based on sampling of the data. Using EARL, the analyst can avoid the slow response and long set up-time of MapReduce applications by simply specifying a target accuracy, with no modification of the original program required. The final delivery of the project is a SAL compiler that optimizes parallel execution of continuous analytical queries on massive data streams, by supporting the synoptic and load-shedding primitives needed to achieve quasi real-time response in this environment. These research results are expected to have great impacts in several areas, including domain science, digital government and e-commerce. The project supports Ph.D. students pursuing research on big-data analytics and their management. Publications, technical reports, software, and experimental data from this research will be disseminated via the project web site (http:\/\/yellowstone.cs.ucla.edu\/nsf-projects\/nsf1218471.html).","title":"III: Small: Scalable Analytics for Data Bases and Data Streams--a Unified Approach","awardID":"1218471","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["542091"],"PO":["563727"]},"193649":{"abstract":"A central goal of research in artificial intelligence, operations research, and related fields is the development of algorithmic approaches to decision making under uncertainty. This project considers influence diagrams, a widely-used graphical model for representing and solving problems of sequential decision-making under imperfect information. Influence diagrams were originally developed to provide a more compact representation of a decision problem than is provided by a decision tree, which suffers from an exponential explosion in the number of its branches as a function of the number of variables in the model. Although influence diagrams provide a compact problem representation, standard algorithms for solving influence diagrams do not represent the solution to a decision problem in a similarly compact form. This project addresses this limitation by introducing a more compact graphical representation of decision strategies that improves the scalability of algorithms for solving influence diagrams, makes it easier for a human user to understand the recommended decision strategy, and allows a principled approach to approximation. In addition, the project develops a new approach to solving influence diagrams based on branch-and-bound search, including an incremental approach to probabilistic inference.<br\/><br\/>The algorithms and software tools developed from this project will improve the scalability and utility of influence diagrams as an approach to automated decision making under uncertainty. These contributions will have a broad impact in the many disciplines in which influence diagrams are applied, including medical decision analysis and support, therapy plan selection, user modeling, information retrieval, climate change analysis, and many others.","title":"RI: Small: A New Approach to Influence Diagram Evaluation","awardID":"1219114","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["39192"],"PO":["562760"]},"193539":{"abstract":"Mobile computing is sweeping the world. Recent studies are pointing to the permanent storage in mobile computing platforms being a weak link. Due to considerations of power and physical footprint, flash has been the storage technology of choice hitherto in mobile platforms. Flash and other newer storage technologies, such as PCM and STT-RAM, have their own idiosyncrasies both from the point of view of architecting them and integrating them in the operating system. In this project, we focus on the system software and hardware issues, in an integrated fashion, in the construction of high-performance storage architecture for mobile platforms. We will analyze the source of storage-related performance bottlenecks on mobile platforms at different levels of the software stack using a combination of measurement, simulation, and real implementation on existing and emerging mobile platforms. We will propose solutions both at the system software and architecture levels for advancing the state-of-the-art in storage for mobile platforms, and conduct detailed quantitative evaluation of our solutions. This project with its focus on advancing the state-of-the-art in mobile storage technology can have unexpected economic and societal impact. We intend to make the research artifacts from this project (traces, workloads, and software) available to the broader research community through open source efforts. Despite technological advances, system software has lagged significantly behind the hardware in delivering the expected performance. The vision behind this project is an attempt to bridge this gap for the storage side of the system software stack through an integrated hardware\/software approach.","title":"CSR: Small: Storage Architecture for the Next Generation of Smart Mobile Platforms","awardID":"1218520","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["564690","550473"],"PO":["565255"]},"193308":{"abstract":"Mobile Music Touch (MMT), developed in prior work by the PI and his colleagues, is a lightweight, wireless tactile music instruction system consisting of fingerless gloves and a Bluetooth-enabled mobile phone. Piano passages to be learned are loaded into the mobile phone and played repeatedly in the user's earpiece while s\/he performs other tasks. As each note of the song plays, a vibrator on the appropriate finger in the gloves activates, indicating which finger is used to play the note. MMT users showed significant improvement in their ability to reproduce simple piano melodies, even though they were actively engaged in a reading comprehension task during practice. The PI terms this effect Passive Tactile Learning (PTL). He also has initial evidence for a related effect, Passive Tactile Rehabilitation (PTR), where tactile stimulation of the hand correlates to improvements in dexterity and sensation for people with tetraplegia resulting from incomplete spinal cord injury. In this project, the PI will explore PTL\/PTR effects in a variety of applications, develop procedural and device design guidelines to best elicit these effects, and illustrate methods and metrics that are sensitive to detecting these effects.<br\/><br\/>Using MMT, he will compare users' learning of piano melodies while being distracted by a math-intensive test in four conditions: vibration stimulation with accompanying audio, vibration alone, audio alone, and no stimulation. This study will quantify the PTL effect and establish if vibration alone is sufficient to cause a learning effect. In an effort to broaden the applicability of the method, he will study the use of PTL to aid in learning stenographic typing and dance steps. To explore the possibility of PTR, he will run a 12-18 person controlled study with participants with tetraplegia due to partial spinal cord injury. This \"in-the-wild\" PTL\/PTR study will compare active practice on a piano with active practice augmented with MMT. Participants will wear the glove during their everyday lives for at least 2 hours a day. The PI will compare learning rates as well as changes in participants' scores on standard sensation and dexterity tests. And he will also conduct a wearability study on MMT for persons with spinal cord injury to better accommodate their needs.<br\/><br\/>Broader Impacts: Establishing guidelines for the use and effectiveness of PTL and PTR will enable others to apply the concepts in different domains, e.g., learning sign language or manual procedures such as a pre-flight checklist or training users of prosthetic limbs in how to trigger different actions in their limb. Beyond partial spinal cord injury, PTR might also be exploited for recovery from damage from stroke or lesions due to Multiple Sclerosis.<br\/><br\/>The PI maintains an aggressive outreach program. Beyond professional publication of results in both the Human Computer Interaction and Rehabilitation literature, he will leverage his contacts to present the work in mainstream press and media (e.g., CNN), as well as more niche communities such as the Georgia Radio Relay Service. One of his focuses is exposing children in Georgia area schools for the deaf to his research, as there is a distinct need for encouraging deaf children in STEM areas. This effort will also be part of the undergraduate \"Device Thread\" in Georgia Tech's College of Computing, which exposes undergraduates to the rigors of designing computing for situations with physical device limitations, such as mobile phones, wearable devices, and robotics. Graduates and undergraduates in these classes will help investigate and fabricate new PTL\/PTR devices. Finally, the PI intends to use this effort in his Computing4Good campaign, which inspires students to think of computing as a means for enabling social change.","title":"HCC: Small: Passive Tactile Learning and Rehabilitation Using Wearable Computers","awardID":"1217473","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[517810],"PO":["565227"]},"199919":{"abstract":"Traditional, dynamic scenes are captured as video frames sampled at regular space-time grids. For many computer vision tasks, however, this uniform sampling may be either inefficient (e.g., low light, high-speed motion) or unnecessary (e.g., motion\/change\/event detection). This project explores non-uniform, adaptive sampling schemes that exploit the underlying structures of space-time volumes (e.g., sparsity, temporal coherence, statistical priors). These sampling schemes are implemented with novel programmable pixel-wised coded exposure and aperture in cameras. The captured information-rich coded projections of space-time volumes are used for video reconstruction or directly as features for motion\/event detection. In addition to higher efficiency in imaging and higher signal-to-noise ratio in reconstructed results, the method also provides benefits in data security and privacy protection for video surveillance because decoding the captured images requires the knowledge of coded patterns and dictionaries. <br\/><br\/>This research has many applications in surveillance, machine vision inspection, and high-speed imaging. The developed technology is being tested in transportation imaging for traffic monitoring and accident detection. A database of high-speed videos of traffic scenes and events is being captured and plan to be released online when it is finished. In addition to videos, the technical approach can also be applicable to other high-dimensional signals such as light fields or light transport matrices.","title":"EAGER: Smart Space-Time Sampling for Recovering and Recognizing Dynamic Scenes","awardID":"1257163","effectiveDate":"2012-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[535962,535963],"PO":["564316"]},"192913":{"abstract":"Private and widely dispersed information across individuals is pervasive aspect of economic environments. In financial markets, traders possess different information about the value of an asset; In labor markets, employees and employers have different information about the cost of a job. In the interaction of the individual agents, the nature of the private information held by the individuals, influences the outcome of the entire economy. In particular, the structure of the interaction, the form of the network, determines the aggregate outcome. Yet, from the point of view of an observer, be it as an analyst or a regulator or a legislator, the precise nature of the private information and network structure of the agents is rarely known.<br\/><br\/>The current research develops a method to analyze the behavior and the welfare in an economic environment, online as well as offline, independent of the structure of the private information and network structure of the agents. Concurrently, the PIs analyze the extent to which the structure of the economic environments (payoffs, preferences) can be identified from the empirical data without knowledge of the exact information and network structure. The methods have epistemic and computational advantages over earlier approaches. The PIs identify bounds on the statistical moments of the equilibrium distribution. Conversely, the statistical description of the equilibrium outcome allows the PIs to give precise bounds on how much can be learned from the data when the nature of the private information is unknown.<br\/><br\/>This new approach to networks with private information offers techniques to analyze the welfare implications of economic rules and institutions by providing bounds that are independent of the knowledge of the information and network structure. The method allows the PIs to assess the implication of different policies and regulations regarding information disclosure, trading restrictions, reserve requirements, that are independent of the specific information held by the economic agents.","title":"ICES: Small: Collaborative Research: Interaction, Information and Identification","awardID":"1215814","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"1320","name":"ECONOMICS"}}],"PIcoPI":[516807],"PO":["565251"]},"193914":{"abstract":"The objective of this project is to extend the concept of crowdsourcing in citizen science to the interaction design of the organization as well as to data collection. Distributed technologies offer new opportunities for conducting scientific research on a larger scale than ever before by enabling distributed collaboration. Virtual organizations that use distributed technologies in scientific organizations have primarily focused on how dedicated, professional scientists collaborate and communicate. More recently a rapidly increasing number of citizen science virtual organizations are being formed. Citizen scientists participate in scientific endeavors and typically lack formal credentials, do not hold professional positions in scientific institutions, and bring diversity of knowledge and expertise to projects and challenges. They participate in scientific endeavors related to their personal scientific interests and create new challenges for the design of virtual organizations. <br\/><br\/>In terms of intellectual merit, the project will make three specific contributions: a new interaction design for collecting biodiversity data within a nature park, a model for crowdsourcing the design of an social computing approach to citizen science, and an analysis of the impact of crowdsourcing the design on motivating participation in collecting biodiversity data. Interactive tabletop computers will be placed in two nature parks so that the design of the citizen science environment can be embedded in a park experience and engage the public in understanding more about their parks, in data collection, and develop a personal commitment to environmental sustainability issues. <br\/><br\/>In terms of broader impacts, the project provides three types of impact: research training by including graduate students, broad public dissemination to enhance scientific understanding of biodiversity, and benefits to society through association with the Aspen Center for Environmental Studies (ACES) and Encyclopedia of Life (EOL).","title":"VOSS: Crowdsourcing interaction design for citizen science virtual organizations","awardID":"1221513","effectiveDate":"2012-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7642","name":"VIRTUAL ORGANIZATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["527291","554479",519276],"PO":["565342"]},"193925":{"abstract":"This project will build and validate a typology of collaboration types associated with cyberinfrastructure (CI) use in the conduct of science. The research focuses on documents and documenting practices as important windows into the socio-technical arrangements of scientific teams. A large number of virtual scientific collaborations will be studied and compared using a mix of text mining, social network analysis and qualitative methods. The research will result in: (1) a detailed compendium regarding what document infrastructures scientists build to support their virtual organizing and documenting practices and (2) specific design principles for the distributed, social and technical aspects of scientific work. The findings will have implications for better design and management of virtual scientific teams and for CI to support scientific endeavors.","title":"VOSS: Documents and the Doing of Science: Studying Cyberinfrastructures in Use","awardID":"1221945","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7642","name":"VIRTUAL ORGANIZATIONS"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"8031","name":"Science of Organizations"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["561666",519313],"PO":["565255"]},"191505":{"abstract":"The goal of this project is to develop a cooperative underwater robotic network for underwater discovery and rescue. With technological advancements, human involvement in underwater activities has increased. Vulnerable oceanic engineering systems, however, can have drastically negative environmental and economic consequences. The oil spill in the Gulf of Mexico in 2010 was a case in point for the impact of underwater infrastructure has on marine ecosystem and local economy. Compared to manned systems, underwater robots, also called autonomous underwater vehicles (AUVs), have inherent advantages by eliminating the need of life support systems and potential risk of human life. Further, an AUV network (with a swam of AUVs) can offer more benefits in efficiency and cost in underwater exploration, discovery and rescue. In this project, innovative algorithms, methods and techniques in autonomous underwater vehicle (AUV) design, cooperative control and underwater acoustic communication networks are proposed to ensure the AUV network's performance in highly uncertain environments. Deliverables for this project include key enabling technologies for the AUV networks and the demonstration of a network including several prototype AUVs.<br\/><br\/>A high performance, energy efficient and autonomous AUV network is significant to science, economy and society. It will have significant impact to underwater infrastructure inspection, wildlife and habitat monitoring, and search and rescue missions. It can also be leveraged for oceanography data collection and water pathway monitoring. Beyond the research significance, this project has important impact on education and outreach by supporting undergraduates, women and other under-represented groups, as well as promoting multi-disciplinary collaboration across departments, campuses, and institutions.","title":"NRI-Small: Cooperative Underwater Robotic Networks for Discovery & Rescue","awardID":"1208499","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1632","name":"CONTROL SYSTEMS"}}],"PIcoPI":[513290,"526410",513292],"PO":["563744"]},"192957":{"abstract":"Modern marketplaces, enabled by recent advances in information<br\/>technology, are becoming ever more complex, dynamic and<br\/>interconnected. Customers are increasingly more informed about the<br\/>choices available to them and are thus able to make better decisions.<br\/>For firms, this presents both opportunities and challenges. On the<br\/>positive side, the firm has a bigger than ever array of tools at its<br\/>disposal that enable it to better sell to its customers. Such tools<br\/>are both computational (pricing algorithms, customer targeting data,<br\/>social networking information) and economical (dynamic mechanisms) in<br\/>nature. The challenging aspect for the firm is that modern technology<br\/>also allows consumers to easily learn the opinions of fellow customers<br\/>and to be strategic in their decision-making. Having such strategic<br\/>and networked customers is not necessarily a net negative for the<br\/>firm, but it certainly makes the firm's problem of how to sell its<br\/>products a more complex one.<br\/><br\/>This project aims to develop a framework for understanding how to<br\/>sell goods in markets that are fundamentally dynamic and<br\/>interconnected. The project will research what mechanisms are revenue-optimal<br\/>(or near-optimal, while being simple and computationally tractable) in<br\/>dynamic settings where customers can learn from each other. The PIs will<br\/>study the effect of network learning on the firm's behavior and<br\/>whether it forces the firm to share some of the costs associated with<br\/>consumer learning. The project will also focus on how the social<br\/>networkstructure affects the optimal mechanism and will try to<br\/>understand whether such network learning effects lead to lower (or<br\/>higher) revenue for the firm and aggregate consumer welfare.<br\/><br\/>Fundamental research in the dynamics of networked markets provides<br\/>deeper knowledge to a broad audience that includes firms, consumer<br\/>groups and regulators. Curriculum development at the interface of<br\/>operations research, information systems and computer science will<br\/>benefit from this research experience.","title":"ICES: Small: Collaborative Research: Selling to Networked Markets","awardID":"1216004","effectiveDate":"2012-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":[516914],"PO":["565251"]},"193507":{"abstract":"Complex network theory has proved to be a versatile framework to represent and analyze relational data in many disciplines including the social sciences, biology and information systems. One particular application that has benefited from these developments is cognitive neuroscience. Contemporary neuroimaging techniques provide neural recordings with increasing spatial and temporal resolution yielding rich multichannel datasets that can be exploited for detailed description of functional connectivity patterns in the brain. Recent research provides evidence that neural integration across various spatial and temporal scales plays an important role in a wide range of cognitive and executive processes as well as in the manifestation of neural diseases and psychopathologies. The current characterizations of functional brain networks are limited to global and static measures that quantify average activity across subjects, brain regions and time. This research addresses this problem by developing a signal processing framework to study the time-varying nature of the functional brain networks based on multichannel electroencephalogram (EEG) data for a better understanding of cognitive control. <br\/><br\/>This research develops three major approaches to study the dynamic nature of functional connectivity in the brain. First, time-varying measures of synchrony along with statistical hypothesis testing are implemented to construct sparse weighted graphs across time and frequency. Second, hierarchical multiple subject clustering algorithms are developed with information theoretic criteria to identify time-varying community structure. Third, a statistical signal processing framework is developed to summarize dynamic network activity with a few representative networks and to identify transient and stationary activity. Finally, this research is applied to the study of cognitive control for identifying the pathways that control cognition and perception, and in understanding the basic network causes of psychopathologies.","title":"CIF:Small: A Signal Processing Approach to the Analysis of Time-Varying Functional Networks of the Brain","awardID":"1218377","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[518268],"PO":["564898"]},"194607":{"abstract":"Proposal #: 12-28312<br\/>PI(s): Apon, Amy W.<br\/> Gemmill, Jill; Ligon, Walter B.; Smith, Melissa C.; Stuart, Steven J.<br\/>Institution: Clemson University<br\/>Title: MRI\/Acq.: High Performance Computing Instrument for Collaborative Data-Enabled Science<br\/>Project Proposed:<br\/>This project, acquiring a high performance computing (HPC) for collaborative data-enabled science, aims to enable fundamental and applied research in areas of experimental HPC, including scalable file systems, accelerator technologies, middleware architectures, and cluster scheduling policies. The instrument will be used as a production resource to support several compelling science applications in materials and biomolecular modeling, bioinformatics (and others) and will contribute a significant new component of the institution?s well established and managed Palmetto cluster while providing critically needed file storage, and accelerator systems not currently available. Supported projects include:<br\/>- Scalable file system implementation,<br\/>- Exploiting and analyzing concurrency in heterogeneous computing environments,<br\/>- High performance cluster modeling, analysis, and characterization,<br\/>- File replication and consistency maintenance,<br\/>- Cloud architecture,<br\/>- Properties of advanced materials and biomolecular systems,<br\/>- Molecular dynamic simulation studies of poly-dots, new light-emitting nanoparticles,<br\/>- Biomolecular evolution,<br\/>- Optimizing catalysts for direct chemical remediation from water,<br\/>- Protein-surface interactions,<br\/>- Map\/Reduce framework for next generation sequencing data assembly,<br\/>- Searching for identification of significantly conserved protein blocks,<br\/>- Digital manufacturing,<br\/>- Statistical inference in nonparametrics models of production,<br\/>- Analysis of the structures of hospital and banking industries,<br\/>- Multiple scatter rendering,<br\/>- Digital scholarship, and<br\/>- Applications of computing to the geosciences.<br\/>Regular planned input from the scientific team is expected to facilitate the development of policies for use of the instrument as a test bed for experimental high performance computing systems research as well as a shared production resource for scientific applications.<br\/>Broader Impacts: <br\/>The instrument serves as a tool for the collaborative team that includes more than 20 faculty from 4 institutions, and more than 250 graduate and undergraduate students. The system will also be utilized by the already established ?Desktop to Teragrid? program that reaches more than a dozen universities across South Carolina, an EPSCoR state, and with regional partners. The proposal team includes 6 women senior personnel. The institution has outreach, education, and training activities, and has engaged SC?s only public HBCU, South Carolina State University, as well as other minority institutions within the region. Development of interdisciplinary curricula will support computational and data-enabled science and engineering.","title":"MRI: Acquisition of High Performance Computing Instrument for Collaborative Data-Enabled Science","awardID":"1228312","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}}],"PIcoPI":[521239,"540643",521241,521242,521243],"PO":["557609"]},"194728":{"abstract":"Deep packet inspection (DPI) is a crucial tool for protecting networks from emerging and sophisticated attacks. However, it is becoming increasingly difficult to implement DPI effectively due to the rising need for more complex analysis, combined with the relentless growth in the volume of network traffic that these systems must inspect. To address this challenge, future DPI technologies must exploit the power of emerging highly concurrent multi- and many-core platforms. Unfortunately, however, current DPI systems severely limit their use of parallelism by either resorting to coarse-grained load-balancing or restricting their analysis to very simple, hard-coded detectors.<br\/><br\/>In order to fully exploit parallel hardware platforms, in this project we develop a comprehensive approach that introduces parallelism across all stages of the complex DPI pipeline. We investigate application-independent scheduling strategies that take existing DPI analyses and automatically parallelize their processing. We do so by mapping them into a domain-specific intermediary representation that abstracts from specifics of the underlying hardware architecture while providing low-level consistency guarantees. Conceptually, the project's goal is to virtualize and abstract parallelism as a fundamental primitive, just like how virtual memory abstracts away physical memory size limitations from programmers.","title":"TWC: Phase: Medium: Collaborative Proposal: Understanding and Exploiting Parallelism in Deep Packet Inspection on Concurrent Architectures","awardID":"1228792","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["562329"],"PO":["565327"]},"193639":{"abstract":"In modern automotive and avionics applications, the use of multiple sensors and especially real-time imaging sensors creates unprecedented workloads. From a computational perspective, multicore architectures have become mainstream; however, as a multicore chip is expected to process increasing volumes of data in real-time, the memory hierarchy becomes the bottleneck resource. In the worst case, task execution times can grow linearly with the number of cores in the system. This research aims at laying foundations for a modern memory-centric real-time scheduling theory that can effectively co-schedule the use of the memory hierarchy, the cores, and the on-chip network, including the I\/O channels. According to the vision of Memory-Centric Scheduling, when the memory hierarchy is the system bottleneck, memory accesses should be scheduled to achieve high memory utilization. Performance of a real-time multicore system should be measured in terms of schedulable memory utilization rather than just core utilization. Ideally, the real-time constraints should be met as long as total memory utilization of all real-time applications (across all the cores contending for shared memory) is below 100%.<br\/><br\/>The potential economic and social benefits of this research are significant since the developed theory will greatly increase the temporal predictability of embedded multicore software systems in general, while in particular reducing cost and time required to achieve the necessary safety certification of next generation avionic multicore computing architectures. As the new scheduling theory is being developed, key elements will be incorporated into graduate classes in real-time computing and then migrated to senior undergraduate classes.","title":"CSR: Small: Memory-Centric Real-Time Scheduling for Multicore Embedded Systems","awardID":"1219064","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["553686","542023"],"PO":["564778"]},"193419":{"abstract":"Modern data centers hosting popular Internet services face significant and multi-facet challenges in performance and power control. The challenges are mainly due to complex interaction of highly dynamic and heterogeneous workloads in complex virtualized computing systems. In this research project, the investigators take an organized approach to autonomic performance and power control on virtualized servers. The project designs and develops automated, agile and scalable techniques for server parameter tuning, virtual machine capacity planning, non-invasive energy-efficient performance isolation, and elastic power-aware resource provisioning. The deliverables are innovative and practical approaches and mechanisms that provide performance assurance of applications, maximize effective system throughput of data centers with resources and power budget, mitigate performance interference among heterogeneous applications, and achieve performance and power targets with flexible tradeoffs while assuring control accuracy and system stability. The research methodology integrates strengths of reinforcement learning, fast online learning neural networks, fuzzy logic control, model predictive controls and distributed and coordinated control. The project broadens impact by developing a testbed in a university prototype data center to demonstrate the orchestration of developed approaches and mechanisms for autonomous management of virtualized computing systems, middleware, and services. The project engages women, US citizens, full-time and part-time graduate and undergraduate students in computer system research. The success will guide autonomous resource management for sustainable computing in next-generation data centers. The research data is deposited at a dedicated website at the host institution and research results are disseminated to the public as published technical reports.","title":"CSR: Small: Autonomous Performance and Power Control on Virtualized Servers","awardID":"1217979","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550728"],"PO":["565255"]},"190868":{"abstract":"Computing increasingly permeates daily lives, yet few appreciate the growing presence of Parallel and Distributed Computing (PDC) in common computing activities; e.g., modern laptops' processors contain multiple cores and special-purpose devices such as graphics processors (GPUs). With increasing availability of powerful PDC technology, familiarity with single-processor computers and sequential computing no longer constitutes computer literacy. Technological developments point to the need for a broad-based skill set in PDC at all levels of higher education in disciplines such as Computer Science, Computer Engineering, and the related computational disciplines. The rapid changes in technology challenge educators to decide what to teach and how to teach it. Students and employers face similar challenges in characterizing \"basic\" expertise in computing. The PIs are addressing these challenges via a project devoted to creating and sustaining curricular and educational infrastructure to facilitate the teaching of PDC topics in undergraduate computer-related curricula. The goal is for every graduating student to become skilled in PDC technology, hence be prepared to enter tomorrow's workforce.<br\/><br\/>The project embodies multiple synergistic activities that develop: flexible PDC curricula for a spectrum of academic programs and institutions; mechanisms that help individuals maintain currency; instructional materials for PDC-related topics; experience-based guidelines for injecting PDC into curricula. A signature activity is competitions for early adopters of PDC curricula (winners receive seed funds, equipment donations from industry) and workshops and training sessions to foster awareness and adoption of PDC curricula. Feedback from early adopters and coordination with the ACM\/IEEE 2013 CS Curriculum Taskforce steers future development of both the PDC curricular guidelines and of strategies for deploying PDC material within computing curricula at a larger scale.<br\/><br\/>This project is supported by CISE, OCI, and EHR\/DUE.","title":"Collaborative Research: CI-ADDO-NEW: Parallel and Distributed Computing Curriculum Development and Educational Resources","awardID":"1205650","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"L122","name":"National Security Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"7511","name":"TUES-Type 2 Project"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7477","name":"CI-TEAM"}}],"PIcoPI":["526127"],"PO":["565136"]},"192958":{"abstract":"Mechanism design studies the problem of designing interactions that yield socially, politically, and economically desirable outcomes when the agents participating in the interaction are self-interested. While agents' interests are typically captured by preferences over material outcomes such as money and consumption goods, this is often insufficient for real-world interactions. For example, many of today's social and economic interactions take place online, and records of the interactions are archived, maintained, and often spread to others. In such interactions agents are motivated not only by the resulting material outcomes, but possibly also by concerns about what and how much of their private information is revealed in the course of the interaction. Agents may, for example, prefer one outcome to another when their private information is revealed, but may prefer the latter outcome to the former if no information is revealed. They may value privacy, and wish to prevent the leakage of their private information. Alternatively, they may wish to credibly disclose their private information as a signal to others. This project develops a model of information-sensitive agents that captures these kinds of preferences, and examines the problem of designing ineractions for such agents.<br\/><br\/>Some of the questions addressed in this project are: Do the mechanisms that exist in the current theoretical literature and in practice still \"work\" when agents have information-sensitive preferences? Is it possible to design mechanisms that are robust to various levels of information-sensitivity of the agents? Are there mechanisms that have additional desirable properties, such as the preservation of privacy or the credible disclosure of information?<br\/><br\/>The broader impacts of this project are twofold. First, a prevalent form of information-sensitivity is a predilection for privacy, one of the most debated issues in electronic commerce. Since this project examines the strategic implications of privacy, it has the potential to contribute valuable insights to this heated debate. Second, information-sensitivity is particularly relevant when agents participate in numerous mechanisms, in which case the leakage of information from one mechanism to another becomes a critical consideration. By explicitly including concerns for information leakage, this project facilitates the design and analysis of economic mechanisms that are both more robust and more modular.","title":"ICES: SMALL: Mechanism Design with Information-Sensitive Agents","awardID":"1216006","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"1320","name":"ECONOMICS"}}],"PIcoPI":[516916],"PO":["565251"]},"194707":{"abstract":"The ubiquity of computing technology and the Internet have created an age of big data that has the potential to greatly enhance the efficiency of our societies and the well-being of all people. The trend comes with problems that threaten to prevent or undermine the benefits. An immediate concern is how to fuse, integrate and analyze data while respecting privacy, security and usage concerns. A second issue is allowing data to remain distributed, enabling its owners to maintain and control quality as well as to enforce security and privacy policies. A final underlying challenge is helping to produce sound and useful results by assuring that systems understand the meaning of the data being integrated and analyzing access and usage policies. For some domains, like health informatics and clinical research, solving these problems will have a significant impact on society.<br\/><br\/>This project explores an approach to solving these problems by developing a policy-compliant integration system for linked healthcare data. The system models data, schemas and policies using open Web standards such as Semantic Web languages, federates queries to independent Linked Data stores based on content, provides policy enforcement by modifying incompliant queries, and uses formal methods to guarantee correctness of key components.<br\/><br\/>This project provides new approaches to solving one of the most significant problems our society faces in the 21st century: benefiting from the integration of distributed linked data while respecting security, privacy, and usage requirements. The prototype tools and systems are incorporated into our educational activities and made available to others via appropriate open source licenses.","title":"TWC: Medium: Collaborative Proposal: Policy Compliant Integration of Linked Data","awardID":"1228687","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["551967",521533],"PO":["549626"]},"194828":{"abstract":"Proposal #: 12-29185<br\/>PI(s): Silva, Claudio; Freire, Juliana; Iacono, John; Suel, Torsten; Vo, Huy<br\/>Institution: Polytechnic University of New York<br\/>Title: MRI\/Acq.: Prototyping Next-Generation Algorithms for Large-scale Visualization, Data Processing and Analysis<br\/>Project Proposed:<br\/><br\/>This project, acquiring an instrument for prototyping the next-generation algorithms for large-scale visualization, data processing and analysis, facilitates the development and evaluation of next-generation algorithms and systems that leverage different hardware configurations. It consists of computational resources in the form of an SGI UV 1000 machine with 384 cores and four Tesla M2070 GPUs, and a small cluster composed of 32 nodes (384 cores total), each with two Tesla M2070 GPUs; and disk resources in the form of solid-state storage cards and an Isilon Storage Cluster. The instrumentation supports projects in various domains. The computer science projects include <br\/>- Dataflow architectures, <br\/>- Theoretical models of computation, <br\/>- Web search, <br\/>- Visualization, and <br\/>- Data mining; <br\/>While the application area research projects (undertaken with external collaborators) relate to<br\/>- Wildfire simulation, <br\/>- Bird migration simulation, and <br\/>- Climate science. <br\/><br\/>Broader Impacts: <br\/>The team plans to release the software developed as part of this project as open source, which carries potential for significant broader impact. The involvement of graduate and undergraduate students in the project provides mentoring opportunities.","title":"MRI: Acquisition of an Infrastructure for Prototyping Next-Generation Algorithms for Large-Scale Visualization, Data Processing and Analysis","awardID":"1229185","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[521988,521989,"550499",521991,521992],"PO":["557609"]},"193618":{"abstract":"This project will advance the scientific state of the art in social service robots by introducing a novel approach for performing, composing, and correcting tasks using spatial language, and for handling the challenges of long-term interaction with people. The team of investigators will leverage prior work on CoBot service robots as a scientific platform. CoBots can transport objects, deliver messages, escort people and go to places, continuously executing these tasks over multiple weeks in a multi-floor building. The team will collaborate to research, develop, and evaluate algorithms for learning, composing, and correcting the execution of tasks via natural language. The proposed research will enable any person to train the robot; we will use the CoBot robots to perform evaluation and testing of our proposed algorithms.<br\/><br\/>The vision of a continuously operating robot in a real-world environment that can update its behavior in response to human instruction will have a broad impact on the way students, faculty and visitors interact with and view the usefulness of robots. Some examples include: (1) Customizable intelligent robots will give people the creative power to simply and intuitively update robot behavior, making the system broadly accessible to non-experts. (2) Outreach to the community will transform the view that robots are static unchangeable systems by creating an awareness towards robots co-inhabiting our environment. We will invite children of different age groups and people from different cultures to interact with our co-robot through language-based instruction. (3) Synergistic activities across multiple research groups have and will continue to be explored and encouraged (e.g., continuous environmental measurement and monitoring).","title":"RI: Small: Natural Language-Based Human Instruction for Task Embedded Robots","awardID":"1218932","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[518535],"PO":["564069"]},"193508":{"abstract":"Fundamental problems in network design have served as benchmarks for the development of new techniques and evaluating their effectiveness in combinatorial optimization. This proposal will investigate a class of connectivity problems including the traveling salesperson problem and its closely related variants such as the bridge connectivity augmentation problem, two-edge-connected subgraph problem and vertex connectivity network design problems, in order to design improved approximation algorithms by advancing current techniques and developing new methods. The proposal also develops new theoretical models for network design problems from practice that incorporate sub-additive demands in information aggregation, and that integrate inventory storage and vehicle routing costs in logistics planning. <br\/><br\/>Due to the ubiquity of their applications, and the fundamental nature of their theory, network design problems are important both in practice and theory. New methods developed can be incorporated into practical heuristic approaches for solving prototypically hard optimization problems of real-life scale that arise in a host of applications from communications to logistics networks. The theoretical analysis developed will improve the mathematically provable quality of fast heuristic solutions for this important class of computational optimization problems.","title":"AF: Small: Approximation Algorithms for Network Design","awardID":"1218382","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["561985"],"PO":["565251"]},"195829":{"abstract":"This collaborative research award provides funding for the development of new and stronger techniques for the solution of optimization problems with complementarity constraints to global optimality. Complementarity problems are pervasive in business, engineering, and economics, since complementarity conditions arise in optimality conditions for nonlinear programs and in models of equilibria. Algorithms for complementarity problems have until recently focused on feasibility problems by employing local optimization techniques. This project focuses on the development of convex relaxations for these problems, with the goal of incorporating them into branch-and-bound algorithms for global optimization. The research is aimed at deriving procedures that (i) exploit the combinatorial and disjunctive structure of complementarity constraints, (ii) focus on relaxations with a provable guarantee of strength, and (iii) target problems in which some of the constraints (besides complementarities) are nonlinear. The benefits of relaxation techniques will be studied relative to mature implementations of global optimization algorithms.<br\/><br\/>If successful, the new relaxations developed with this research, along with factorable decomposition and separation techniques, will advance the state of the art in the global optimization of complementarity programs, bringing many practically relevant problems within the range of tractability. Because complementarity constraints arise in equilibrium analyses of supply and demand, adversarial relationships between strategically interacting entities, traffic equilibria, and in the analyses of multistage optimization problems, this research could lead to improved efficiencies in various sectors of the economy. Further, since bilevel programs have numerous applications in defense planning, including interdiction and protection of critical infrastructure, this research could impact positively various areas of national defense. From an educational perspective, related material will be incorporated into undergraduate and graduate education and doctoral students will be trained in relevant technologies including integer programming and global optimization. In addition, a website will be designed to disseminate prototype implementations and problem data sets.","title":"Collaborative Research: Novel Tighter Relaxations for Complementarity Constraints with Applications to Nonlinear and Bilevel Programming","awardID":"1235236","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"5514","name":"OPERATIONS RESEARCH"}}],"PIcoPI":[524913],"PO":["565139"]},"193409":{"abstract":"Two distinct milestones of any software development lifecycle are requirements gathering and acceptance testing, where a software product is verified against its requirements. Yet this verification is one of the most difficult tasks, since it involves bridging an abstraction gap between high-level descriptions of requirements and their low-level implementations in the source code. Determining how different requirements are covered by acceptance tests is very hard, since it means tracing each acceptance test to specific requirements. Many companies and organizations do not have or cannot invest significant resources into recovering links among requirements, acceptance tests and other artifacts. As a result, software development is not as efficient as it could be, lacking controls to steer the overall testing and bug-fixing effort, and involving extra work peripheral to the core tasks. The end result is a situation in which it is unclear how well software is tested and how much confidence stakeholders can have in it.<br\/><br\/>We are addressing this fundamental problem by defining and developing a new, integrated model for recovering traceability links using execution artifacts, diverse models, and requirements. We develop techniques for automatically generating additional test cases that execute untested code to recover additional traceability links and verify existing ones. To ensure that our approach is effective, we will perform rigorous case studies in real industrial scenarios to evaluate the model, techniques, and methodologies. As a result, the state-of-the-practice in software development will be improved that faces difficulties in ensuing that software products are tested fully with respect to their requirements. Among the broader impacts the project includes developing educational course content, involving underrepresented categories of students, producing software tools under open source licenses, and collaborating with industry to transfer technology.","title":"III: Small: Collaborative Research: Linking Evolving Software Requirements and Acceptance Tests","awardID":"1217928","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["564387"],"PO":["564388"]},"190803":{"abstract":"Prosody is a critical component of spoken communication. Loosely defined, prosody is ?how words are spoken?, as opposed to ?what words are said?. Prosody is typically defined to include pitch, intensity, and timing -- and systematic variation in these parameters can reinforce or augment a speaker?s intended meaning. Prosody provides important information at every linguistic level, disambiguating syntax, augmenting semantics and pragmatic information, e.g. by conveying information about phrasal grouping and phrase-level prominence. Emotions and other speaker-state information are also communicated through a speaker?s prosody.<br\/><br\/>Although this aspect of speech is important, it remains under-investigated. A major limiting factor is the lack of large sample of prosodically labeled speech. Prosody researchers at CUNY, Columbia and MIT are developing Reciprosody, a web source of prosodically annotated data and tools for analysis. Reciprosody makes critical resources for the study and teaching of prosody available to a growing and diverse population of researchers, students, and technologists. This website hosts data in any language, annotated under any prosody standard. The only restriction for hosting data in the repository is that it must be made freely available for academic and educational activities. <br\/><br\/>Reciprosody is not merely a passive repository, but an active resource for researchers and educators to communicate with each other on a regular basis. This enables the resource to be a center not only for annotated data, but information and support related to ongoing prosody research.","title":"RUI: Collaborative Research: CI-P: Reciprosody - A Repository for Prosodically Annotated Material","awardID":"1205445","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[511507],"PO":["565215"]},"191507":{"abstract":"The goal of this project is to create a transformative robotic technology that utilizes Magnetic Resonance Imaging (MRI) systems to power, control and image robots under the guidance and control of a clinician. Specifically, the research effort will be organized around three tasks: (1) creation of design principles for MRI-powered actuators, (2) development of motion planning and control algorithms for MRI-powered robots, and (3) design of MRI pulse sequences for closed-loop motor control. This tether-less robot technology addresses the needs for small, low cost medical robots identified in the Roadmap for US Robotics and can be exploited for robots ranging in size from centimeters down to fractions of a millimeter. At the centimeter scale, it could be used for robots designed to crawl inside body cavities to perform interventions and also for robotic prosthetic implants. At the millimeter and sub-millimeter scale, groups of MRI-powered robots can swim inside fluid-filled regions of the body to perform targeted therapies, such as drug and cell delivery, or to assemble as a sensor network. Two testbeds at these different scales will be used to evaluate and demonstrate the technology.<br\/><br\/>This research addresses a largely unexplored frontier in medical robotics that could revolutionize the standard of care for many serious medical conditions currently associated with both high mortality rates and high societal costs. The location of the PI's lab inside a teaching hospital provides a unique environment to integrate the research and education of the engineering and medical disciplines. To promote an understanding of engineering and medicine along with the value of learning and research to low income and minority school students, the project team will partner with local educational organizations. Furthermore, the project technology will consist of algorithms and software that can be utilized by researchers and educators throughout the country to provide fundamentally new capabilities to existing multi-million dollar equipment. The ultra-minimally invasive medical robots developed using this technology can potentially provide substantial societal benefits in terms of reduced trauma, precise image-based control and lower cost.","title":"NRI-Small: Core Technologies for MRI-powered Robots","awardID":"1208509","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":[513297],"PO":["548925"]},"194917":{"abstract":"Proposal #: 12-29553<br\/>PI(s): Crowley, Patrick; Turner, Jonathan S<br\/>Institution: Washington University<br\/>Title: MRI\/Dev.: A Testbed for Overlay Network Research and Education<br\/><br\/>Project Proposed:<br\/><br\/>This project, developing an instrument for experiments used in a controllable, high-performance and experimental overlay network research and education, enables researchers to experiment with overlay network algorithms, protocols (peer-to-peer, novel Internet architectures) and understand workloads in great details including cost coming from routers, switches and servers in a safe manner. Building upon and leveraging an existing Internet-accessible community resource, the Open Network Lab (ONL, www.onl.wustl.edu), it adds high performance components that can be configured and extended to support a wide range of controlled and repeatable experimental computer networking projects. Through the integration of additional switches and servers and the addition of platform-level server virtualization, this instrument extends the function of ONL by expanding the available physical resources in ONL by a factor of two and, via server virtualization, expanding the effective virtual resources by a factor of approximately eight. The enabled research ranges from future Internet architectures, overlay networks, to peer-to-peer systems. <br\/><br\/>Broader Impacts: <br\/><br\/>The proposed instrument can greatly impact the research in future Internet. The instrument is likely to have significant broader impact on undergraduate and graduate education, as well as contribute in attracting more students to careers in science and engineering, thus increasing their participation.","title":"MRI: Development of a Testbed for Overlay Network Research and Education","awardID":"1229553","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[522381,522382],"PO":["557609"]},"193619":{"abstract":"One of the fundamental problems in statistical data analysis is to learn the relationship between the samples of a dependent variable (e.g., the malignancy of a tumor) and the samples of predictor variables (e.g., the expression data of genes). This problem was relatively easy in the data-starved world of yesteryears. Our inability to observe too many variables meant that a single sample had dimensions in the tens or hundreds. Times have changed. We now live in a data-rich world. DNA microarrays, for example, can provide us with the expression data for hundreds of thousands of genes (predictors) per tissue sample. This is just one of the countless examples in modern statistics where a single sample comprises thousands or billions of predictors, while there are only hundreds or thousands of samples available for analysis. Computational and analytical tools developed in the 20th century, however, were not designed to work in such high-dimensional settings. The challenge then is developing new sets of computationally efficient methods that analyze the high-dimensional data in an optimal manner.<br\/><br\/>This research addresses the challenge of high-dimensional data analysis within the context of linear models by developing low-complexity inference methods based on marginal correlations of predictors with the response variable. One of the distinguishing features of this research is its emphasis on mathematical characterization of the performance of developed methods in the most general of terms. This is accomplished by drawing connections with the literature on finite frame theory. Because of the fairly general nature of this research, it significantly advances the state-of-the-art in inference problems arising in myriad areas, such as genomics, tumor classification, network monitoring and computer tomography. In addition, the frame-theoretic focus of this research lays the foundations for future cross-fertilization of ideas between statistical inference and frame theory.","title":"CIF: III: Small: High-Dimensional Linear Models? Bring 'Em On!","awardID":"1218942","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[518537],"PO":["564898"]},"190804":{"abstract":"Prosody is a critical component of spoken communication. Loosely defined, prosody is ?how words are spoken?, as opposed to ?what words are said?. Prosody is typically defined to include pitch, intensity, and timing -- and systematic variation in these parameters can reinforce or augment a speaker?s intended meaning. Prosody provides important information at every linguistic level, disambiguating syntax, augmenting semantics and pragmatic information, e.g. by conveying information about phrasal grouping and phrase-level prominence. Emotions and other speaker-state information are also communicated through a speaker?s prosody. <br\/><br\/>Although this aspect of speech is important, it remains under-investigated. A major limiting factor is the lack of large sample of prosodically labeled speech. Prosody researchers at CUNY, Columbia and MIT are developing Reciprosody, a web source of prosodically annotated data and tools for analysis. Reciprosody makes critical resources for the study and teaching of prosody available to a growing and diverse population of researchers, students, and technologists. This website hosts data in any language, annotated under any prosody standard. The only restriction for hosting data in the repository is that it must be made freely available for academic and educational activities. <br\/><br\/>Reciprosody is not merely a passive repository, but an active resource for researchers and educators to communicate with each other on a regular basis. This enables the resource to be a center not only for annotated data, but information and support related to ongoing prosody research.","title":"Collaborative Research: CI-P: Reciprosody - A Repository for Prosodically Annotated Material","awardID":"1205450","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["511614"],"PO":["565215"]},"190815":{"abstract":"Linguistic code switching (LCS) is the practice of switching back and forth between the shared languages of bilingual or multilingual speakers. This phenomenon is particularly prevalent in geographic regions with linguistic boundaries or where there are large immigrant groups. Various levels of language (phonological, morphological, syntactic, semantic and discourse-pragmatic) may be implicated in LCS in different language pairs and\/or genres. Computational algorithms trained for a single language quickly break down when the input includes LCS. A major barrier to research on LCS in computational linguistics (CL) has been the lack of large, accurately annotated corpora of LCS data. In this project, a large repository of LCS data is collected and a large annotation infrastructure is developed. It is consistently annotated in different modalities (speech and text), at various levels of linguistic granularity, and across different language pairs reflecting different linguistic typologies (Standard Arabic and Dialectal Arabic, Arabic-English, Spanish-English, Chinese-English, Hindi-English). The focus of the effort is on intra-sentential LCS.<br\/><br\/>This infrastructure and unified large LCS data resource is eagerly awaited by the CL research community, since annotated LCS data provides a natural test-bed for adaptive learning algorithms and the handling of diverse data sources, as well as a framework for genuine multilingual processing. It will also be of benefit to sociolinguistic and theoretical linguistic researchers, and provide a platform for collaborative interdisciplinary research. Finally, research on LCS helps overcome biases against multilingual speakers by demonstrating the creativity of such speakers in exploiting their verbal repertoires. Such a result is particularly important for K-12 education and testing policies in the USA with its diverse immigrant population.","title":"CI-ADDO-NEW: Collaborative Research: A Repository for Annotating Multilingual Code Switched Data","awardID":"1205475","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["562856"],"PO":["565215"]},"193906":{"abstract":"A major advantage of virtual organizations (VOs) is flexible membership and participation. In many VOs, members are able to join and leave at will, and can change whom they collaborate with at any point in time. This flexibility can be a source of increased effectiveness as VO structures are more readily able to adapt to contingencies and VO leadership can evolve over the course of a VO's lifecycle. <br\/>This project examines the relationship between structural fluidity, VO leadership, and VO performance. The investigators will examine the log data generated by the technical systems used for coordination and information sharing in four different types of VOs (software engineering, disaster relief, online learning, and public discourse communities), will interview VO participants, and will measure VO performance in context-specific ways. The project will: (1) develop tools to measure organizational fluidity and make that fluidity visible to VO participants; (2) examine the relationship between organizational performance, the fluidity of group membership and fluidity of leadership in virtual organizations. The techniques pioneered in this proposal will increase understanding of how to use technical system log data to more quickly identify the most effective social structures and leadership strategies in VOs. The results and tools developed in the course of the project will have practical value for those seeking to improve VO performance for science, industry and government organizations that increasingly rely on virtual organizations for their success. A number of undergraduate and graduate students will participate in the project, furthering their training and education in interdisciplinary research.","title":"VOSS: Toward a Context Adaptive Theory of the Relationship Between Structural Fluidity and Virtual Organization Performance","awardID":"1221254","effectiveDate":"2012-09-01","expirationDate":"2014-03-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7642","name":"VIRTUAL ORGANIZATIONS"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"8031","name":"Science of Organizations"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":[519253,"565341"],"PO":["565342"]},"192949":{"abstract":"An individual's preferences can be complicated. The project investigates whether people's preferences do, in fact, conform to the CP-net (conditional preference network) formalism, how such preferences can be combined according to different voting methods, and how vulnerable those methods are to manipulation or \"strategic voting.\" Finally, the very large corpus of preference data from the Netflix Challenge is used to build statistical models of the efficiency of manipulation algorithms and to compare the performance of different consensus methods.<br\/><br\/>Laboratory experiments will check whether people exhibit preferences that can be modeled by CP-nets. The project extends ideas from aggregation in Bayesian networks (models of conditional probabilities) to aggregation in CP-nets (models of conditional preferences).<br\/><br\/>The team investigates how statistical inference from noisy data relates to or interacts with strategic manipulability and bribery. The project extends behavioral social choice and computational social choice on voting systems, and the manipulation thereof, from preferences expressed as ratings, rankings, or subsets to preferences expressed as CP-nets.<br\/><br\/>The team investigates the performance of voting methods and the efficiency of manipulation schemes on real preference data from the Netflix challenge data set. These data, namely hundreds of thousands of (slightly perturbed) personal rankings of movies, were released several years ago for data-mining purposes. One can extract individual \"elections\" based on the rankings of a small set of movies, evaluate and compare various aggregation methods and empirically characterize voting scenarios that are especially susceptible or especially resilient to strategic manipulation.<br\/><br\/>Among the broader impacts of the research, beyond the integration and cross-fertilization of several distinct research areas spanning several scientific disciplines, are the development of more adequate individual and collective decision making tools, that will help individuals, groups, organizations, and society to improve decision making.","title":"ICES: Small: Collaborative Research: Robust Preference Aggregation","awardID":"1215985","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7932","name":"COMPUT GAME THEORY & ECON"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":[516895],"PO":["565251"]},"193609":{"abstract":"Supervised machine learning is a critical component of software systems in a wide variety of applications. Although models induced via supervised learning algorithms often provide state-of-the-art accuracy, they are not applied as widely as they could be because they require labeled training instances, which are often expensive to acquire. One promising approach to addressing this limitation is to employ active learning algorithms. These methods are able to make queries in which they choose which instances are labeled and added to the training set. The goal of this project is to develop a new class of algorithms for active learning that broadens the applicability of this approach to more complex, realistic settings. Specifically, we will develop methods that (i) address complex learning tasks such as biological network reconstruction and event extraction from natural language, (ii) assemble batches of queries when it is cost effective to do so, (iii) are able to employ a variety of query types, and (iv) reason about the costs incurred for various queries.<br\/><br\/>Machine learning represents an important methodology for inferring models that can make useful predictions in scientific, educational, health-care, business and consumer applications. The methods to be developed in this project will provide substantial benefits to machine-learning applications in such problem domains by reducing the cost required to obtain enough data to learn accurate models. Moreover, because this project is connected to specific collaborations with biologists, it is likely to have a direct impact on the ability of scientists to design, conduct and interpret experiments investigating networks of complex relationships such as host-virus interactions. The project will also play a role in training undergraduate and graduate students in interdisciplinary research, and in recruiting undergraduate students from under-represented minority groups into scientific careers.","title":"RI: Small: Active Learning with Rich Query Types on Networks and Trees","awardID":"1218880","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[518513],"PO":["562760"]},"190805":{"abstract":"Among the developments that are pushing the boundary of computer science and engineering research, these stand out: the emergence of Big Data as a reality, pushing the need for scalable data analytics (e.g., data mining), the proliferation of wireless and cellular networks, and the deployment of large scale cyber-physical systems. Every year, petabytes of new data are collected and stored by companies and organizations, prompting the need for scalable data mining to make sense of the data that has been collected. Further, the proliferation of wireless and cellular networks has enabled the advent of mobile and nomadic computing. This proliferation has also given rise to many new challenges. <br\/><br\/>This new computing research infrastructure enables research into cross-layer protocols for cognitive radio networks, wireless security energy management techniques for mobile devices, designing security for cyber-physical systems, malware detection and prevention for mobile devices, design of deeply embedded systems for monitoring water distribution infrastructure, new tools to perform scalable Time Series analysis, tools to perform Bayesian inference in critical data mining problems, and to perform Metagenome annotation and comparison. It supports undergraduate and graduate courses on these topics. Software developed under this program and supporting data will be made available to the research community, strengthening efforts for technology transfer.","title":"II-NEW: An Experimental Infrastructure for Cross-Domain Research in Wireless Computing, Cybersecurity and Data Mining","awardID":"1205453","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[511511,511512,511513,"542388"],"PO":["565239"]},"204182":{"abstract":"The objective of the research is to develop an innovative spin-transfer torque random access memory (STT-RAM) based memory hierarchy to meet the demands of modern embedded systems for low-power, fast-speed and high-density on-chip data storage. <br\/>Three integrated components are included in our research to address the major technical concerns in STT-RAM designs: (1) Application-driven STT-RAM cell design and optimization to target different embedded system specifications. (2) Thermal resilient adaptive STT-RAM memory hierarchy to tolerate the temperature instability of STT-RAM incurred by ambient temperature and self-heating. (3) Probabilistic STT-RAM design methodology to improve the run-time stability and\/or the performance. <br\/><br\/>This research provides a comprehensive design package for efficiently integrating STT-RAM into modern embedded system designs and offers unparalleled performance and power advantages. The system architects and the circuit designers can be well bridged and educated by the research innovations. The developed techniques can be directly transferred to industry applications under the close collaborations with several industry partners, and directly impact the future embedded systems. The activities in the collaboration also include the tutorials in the major conferences on the technical aspects of the projects and new course development. <br\/><br\/>The educational components of this project will introduce the students to the implementation and optimization techniques of embedded systems and train the students? problem solving ability by leveraging challenge based instruction technique.","title":"CAREER: STT-RAM based Memory Hierarchy and Management in Embedded Systems","awardID":"1311706","effectiveDate":"2012-09-01","expirationDate":"2017-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["107868"],"PO":["565255"]},"207130":{"abstract":"The project brings together an interdisciplinary team of researchers from Johns Hopkins University, Carnegie Mellon University, and the University of Chicago to develop methods, theory and algorithms for discovering hidden structure from complex scientific datasets, without making strong a priori assumptions. The outcomes include practical models and provably correct algorithms that can help scientists to conduct sophisticated data analysis. The application areas include genomics, cognitive neuroscience, climate science, astrophysics, and language processing.<br\/><br\/>The project has five aims: (i) Nonparametric structure learning in high dimensions: In a standard structure learning problem, observations of a random vector X are available and the goal is to estimate the structure of the distribution of X. When the dimension is large, nonparametric structure learning becomes challenging. The project develops new methods and establishes theoretical guarantees for this problem; (ii) Nonparametric conditional structure learning: In many applications, it is of interest to estimate the structure of a high-dimensional random vector X conditional on another random vector Z . Nonparametric methods for estimating the structure of X given Z are being developed, building on recent approaches to graph-valued and manifold-valued regression developed by the investigators; (iii) Regularization parameter selection: Most structure learning algorithms have at least one tuning parameter that controls the bias-variance tradeoff. Classical methods for selecting tuning parameters are not suitable for complex nonparametric structure learning problems. The project explores stability-based approaches for regularization selection; (iv) Parallel and online nonparametric learning: Handling large-scale data is a bottleneck of many nonparametric methods. The project develops parallel and online techniques to extend nonparametric learning algorithms to large scale problems; (v) Minimax theory for nonparametric structure learning problems: Minimax theory characterizes the performance limits for learning algorithms. Few theoretical results are known for complex, high-dimensional nonparametric structure learning. The project develops new minimax theory in this setting. The results of this project will be disseminated through publications in scientific journals and major conferences, and free dissemination of software that implements the nonparametric structure learning algorithms resulting from this research.<br\/><br\/>The broader impacts of the project include: Creation of powerful data analysis techniques and software to a wide range of scientists and engineers to analyze and understand more complex scientific data; Increased collaboration and interdisciplinary interactions between researchers at multiple institutions (Johns Hopkins University, Carnegie Mellon University, and the University of Chicago); and Broad dissemination of the results of this research in different scientific communities. Additional information about the project can be found at: http:\/\/www.cs.jhu.edu\/~hanliu\/nsf116730.html.","title":"III: Small: Nonparametric Structure Learning for Complex Scientific Datasets","awardID":"1332109","effectiveDate":"2012-09-01","expirationDate":"2015-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["496977"],"PO":["565136"]},"208682":{"abstract":"Project proposes a petaflop-scalable computational infrastructure for the direct simulation of particulate flows, in particular the simulation of spatio-temporal dynamics of platelet aggregation. Better understanding of microcirculation of blood and platelet rheology will impact clinical needs in thrombosis risk assessment, anti-coagulation therapy, and stroke research. The proposed method comprises two algorithmic components: (1) integral equation solvers for Stokesian flows with dynamic interfaces; and (2) scalable fast multipole algorithms. Why do we need petaflop-scale computing power to tackle this problem? One microliter of blood contains millions of red blood cells(RBCs) and a few hundred thousand platelets. Discretizations with O(100 points\/cell and O(1000) time steps result in more than a trillion space-time unknowns. Solving problems of such size will require 50K-core machines. Computational tools that achieve such scalability, will enable direct numerical simulation of several microliters of blood, once million-core computing platforms are available.","title":"Collaborative Research: Petascale Algorithms for Particulate Flows","awardID":"1341290","effectiveDate":"2012-09-01","expirationDate":"2013-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7583","name":"ITR-HECURA"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"7691","name":"PetaApps"}}],"PIcoPI":[559409],"PO":["565247"]},"190819":{"abstract":"Computing increasingly permeates daily lives, yet few appreciate the growing presence of Parallel and Distributed Computing (PDC) in common computing activities; e.g., modern laptops' processors contain multiple cores and special-purpose devices such as graphics processors (GPUs). With increasing availability of powerful PDC technology, familiarity with single-processor computers and sequential computing no longer constitutes computer literacy. Technological developments point to the need for a broad-based skill set in PDC at all levels of higher education in disciplines such as Computer Science, Computer Engineering, and the related computational disciplines. The rapid changes in technology challenge educators to decide what to teach and how to teach it. Students and employers face similar challenges in characterizing \"basic\" expertise in computing. The PIs are addressing these challenges via a project devoted to creating and sustaining curricular and educational infrastructure to facilitate the teaching of PDC topics in undergraduate computer-related curricula. The goal is for every graduating student to become skilled in PDC technology, hence be prepared to enter tomorrow's workforce.<br\/><br\/>The project embodies multiple synergistic activities that develop: flexible PDC curricula for a spectrum of academic programs and institutions; mechanisms that help individuals maintain currency; instructional materials for PDC-related topics; experience-based guidelines for injecting PDC into curricula. A signature activity is competitions for early adopters of PDC curricula (winners receive seed funds, equipment donations from industry) and workshops and training sessions to foster awareness and adoption of PDC curricula. Feedback from early adopters and coordination with the ACM\/IEEE 2013 CS Curriculum Taskforce steers future development of both the PDC curricular guidelines and of strategies for deploying PDC material within computing curricula at a larger scale.<br\/><br\/>This project is supported by CISE, OCI, and EHR\/DUE.","title":"Collaborative Research: CI-ADDO-NEW: Parallel and Distributed Computing Curriculum Development and Educational Resources","awardID":"1205492","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["517880"],"PO":["564588"]},"198190":{"abstract":"This CREATIV award is partially funded by the Networking Technologies and Systems (NeTS) program in the Division of Computer Networks and Systems in the Directorate of Computer & Information Science & Engineering, the Animal Behavior program through the the Divisions of Integrative Organismal Systems and Emerging Frontiers in the Directorate of Biological Sciences, the Office of the Division Director in CISE\/CNS and the Office of the Assistant Director in CISE. Despite many years of research on animal interactions, our information about the details of those interactions, especially in large groups of animals, is limited. Fortunately, today's technology can be used to extend our ability to track the social interactions of animals to a much larger scale. While collaborations between social networking and sensor networking researchers have started in the right direction, current approaches have not provided the depth of proximity and orientation information necessary to take the next logical step and infer social interactions between animals. The main challenge lies in the need to balance the accuracy of information about the animal interactions with the energy consumed by the devices themselves, with the ultimate goal of an effective, long running system. To this end, we have designed Mingle, an adaptive sensor-based systems that tracks social interactions between animals. The novelty of Mingle comes from the observation that such social interactions can be tracked by monitoring the animals' relative orientation and relative distance to each other. By relying on local information, Mingle optimizes energy efficiency by integrating local collaborative sensing with the judicious use of infrastructure-based solutions based on observations about the mobility of the animals. Finally, Mingle integrates real application constraints to ultimately drive energy-efficient data collection.<br\/><br\/>Mingle has the potential to change education, science, and how we view our own society. The ability to see the very detailed social interactions about an entire population of animals will change how we understand and study them. Automating the process of the collection of information about animal, and human, interactions will free behavioral scientists from the collection process while providing data at the level of detail and magnitude never before possible. Moreover, entirely new educational curricula can be designed that engage children in scientific inquiry in fundamentally novel ways. For example, students will have the ability to \"become the animals\", enacting herding and foraging strategies. Additionally, information about the children's own social interactions will change educational research, enabling our understanding of how children learn in a group and through interactions. While we focus on social interactions between animals in this proposal, the results from this research can be taken into the human social networking domain, where many people already carry sensor-rich smartphones, enabling new and exciting social networking applications for interactions between people, exposing social networking information based on actual social interactions, or measuring social interactions to research social behavior and social patterns.","title":"INSPIRE: Mingle: Sensing the Interactions of Animals","awardID":"1248080","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"8078","name":"INSPIRE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"7275","name":"CROSS-EF ACTIVITIES"}}],"PIcoPI":["561785","533275",531879,"552898"],"PO":["557315"]},"189390":{"abstract":"In this collaborative interdisciplinary proposal involving a researcher at the University of Illinois at Chicago (UIC) and one at the Pennsylvania State University (Penn State), the investigators will design and apply novel algorithmic tools to explore several fundamental graph-theoretic problems that have significant applications in biological and social interaction networks. The research problems addressed in the proposal can be broadly classified into graph partitioning type of problems and graph sparsification type of problems. For example, one such problem in the context of social interaction networks is to partition the nodes into so-called \"communities of statistically significant interactions\" to study the behavioral patterns of a group of individuals in a society. The PIs will formulate precise computational problems, study their properties, use novel algorithmic tools to design efficient algorithms, and implement the resulting algorithms to test their accuracy and efficiency. The proposed research will leverage further development of novel combinatorial tools previously developed by the PIs, in addition to developing new techniques, to design efficient algorithms for complex optimization problems. The algorithms developed in the course of this project will be implemented for validation on simulated and real data, and will lead to open-source software for the life science and social science communities.<br\/><br\/>On a broader level, since this proposal deals with fundamental combinatorial optimization problems that arise in diverse scientific fields, the proposed research will have a strong impact on research areas beyond the primary research area, such as in stability analysis of computer networks and in social network visualization. A central component of the proposal is the creation of meaningful educational activities that leverage the proposed interdisciplinary research and build on the PIs' substantial past experience in teaching, mentoring and outreach and on the diverse communities in Chicago . Additionally, the PIs plan to integrate research and education via course and curriculum development, involvement of undergraduates, minorities and under-represented groups, effective dissemination of research, mentoring of undergraduate and graduate students, outreach and community involvement, and promoting diversity in research and educational activities.<br\/><br\/>The outcomes of the project will be made freely available through the following websites of the investigators and their labs: http:\/\/www.cs.uic.edu\/~dasgupta; http:\/\/www.cs.uic.edu\/~dasgupta\/professional\/algo-lab.html; and http:\/\/www.phys.psu.edu\/~ralbert.","title":"III: CCF: Medium: Collaborative Research: Combinatorial Analysis of Biological and Social Networks","awardID":"1161007","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["547502"],"PO":["565136"]},"198180":{"abstract":"This INSPIRE award is partially funded by the Transforming Undergraduate Education in STEM Program in the Division of Undergraduate Education and the Discovery Research K12 Program in the Division of Research on Learning in the Directorate for Education and Human Resources; the Geography and Spatial Sciences Program in the Division of Behavioral and Cognitive Sciences in the Directorate for Social and Behavioral Sciences; and the Cyberlearning program in the Division of Information and Intelligent Systems in the Directorate for Computer & Information Science & Engineering. <br\/><br\/>This is a research program to promote and study effective strategies and habits of mind for understanding complex geospatial data using interactive visualization tools, and to generate and test design strategies for such tools in three contexts: an online data access website, interactive museum exhibit, and social science classrooms. All three research sites will utilize geographic information system (GIS) visualization tools to give learners access to geospatially-referenced historical U. S. Census data for examining changing populations across space and time. These complex data tools are increasingly used in different disciplines and in multiple aspects of everyday life. However, how learners interact with them is still poorly understood. The three research sites will strategically employ multiple, coordinated research methods, including design-experimentation, machine-learning analyses, multimodal interaction analyses, and grounded-theory generation of hypotheses. The outcomes of these empirical studies, coordinated across three contexts, will be used for iterative generation and evaluation of design strategies to promote effective reasoning with complex data for learners in each of these learning environments. This project also will build a coherent, interdisciplinary understanding of representational fluency for complex geospatial data across learning contexts. <br\/><br\/>Intellectual Merit: The merit of this research program derives from its fundamental interdisciplinarity, combining research methods, concepts, and design expertise from Sociology, Computer Science, the Learning Sciences, and GIS design and large-scale implementation, in the service of addressing pressing questions about how people learn with social-scientific data. Because the proposed research does not fit neatly within any single academic discipline, it is an ideal match for the goals of the INSPIRE program. The conceptual and methodological diversity of this project contributes to its potentially transformative nature, as a model for cross-discipline collaboration in transforming status-quo approaches to studying data visualization and the design of learning environments. The collaborating investigators, as active members of multiple research communities and regular contributors to the work of educational practitioners, are uniquely situated to effectively translate empirical research findings into accessible designs and professional development opportunities across multiple communities.<br\/><br\/>Broader Impacts: The proposed project has the potential to have substantial impact due to the exceptional scale of dissemination currently realized by the Social Explorer project and related installations at the New York Science Museum, as well as the diversity of audiences for design-based research conducted in these three contexts (museum, classroom and web-based learning environments). In addition, the core of the research is the archive of historical U. S. Census data, which is central to research practices across social science disciplines, as well as popular news media, and is also highly relevant to people's understandings of our society.","title":"INSPIRE: Studying and Promoting Quantitative and Spatial Reasoning with Complex Visual Data Across School, Museum, and Web-Media Contexts","awardID":"1248052","effectiveDate":"2012-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"8078","name":"INSPIRE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"1352","name":"GEOGRAPHY AND SPATIAL SCIENCES"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1100","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"7511","name":"TUES-Type 2 Project"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7645","name":"DISCOVERY RESEARCH K-12"}}],"PIcoPI":[531844,"539435",531846],"PO":["564439"]},"200183":{"abstract":"This award supports travel of eligible graduate students from US institutions of higher learning to the second International workshop on mobile systems, applications, and services for healthcare, (mHealthSys 2012). Grant recipients will be required to attend the workshop and participate in a special session to discuss their experience. Recent advances in technology such as miniaturization of sensing and computing devices, new bio sensing modalities (e.g. respiration, SpO2), increasing use of mobile phone sensors for health care, and wireless integration of wearable sensors with smart phones are accelerating the<br\/>deployment of mobile systems for healthcare. The goal of the grants is to encourage research<br\/>interest and involvement of students who are not well-funded, under-represented, or otherwise<br\/>not likely to be able to attend high-profile conferences in the field. <br\/><br\/>By financially facilitating attendance and generating discussion, the grant will encourage such students to become active in the latest research directions in this important field. The mHealthSys conference will take place in Toronto, Canada, in November 2012. mHealthSys will explore, encourage, and accelerate advances in wearable sensing, mobile phone sensing, algorithms, applications, and services that aim to deliver healthcare in the unconstrained mobile environment of individuals. The mHealthSys 2012 workshop we will bring together a group of international researchers with expertise in mobile systems, sensor systems, and medical informatics to push the state of the art of research at the intersection of mobile systems, sensor systems, and healthcare.","title":"Student Travel Support for mHealthSys 2012","awardID":"1258389","effectiveDate":"2012-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["548311"],"PO":["565303"]},"198160":{"abstract":"This INSPIRE award is partially funded by the Modulation Program in the Divison of Integrative Organismal Systems in the Directorate for Biological Sciences, by the Graphics and Visualization Program in the Division of Information and Intelligent Systems in the Directorate for Computer Information in Science and Engineering, by the Advances in Biological Informatics in the Division of Biological Infrastructure in the Directorate for Biological Sciences, and by the Emerging Frontiers Program in the Directorate for Biological Sciences. <br\/><br\/>This interdisciplinary project will capitalize on a remarkable opportunity driven by new chemical-engineering technology to define the full brainwide activity patterns underlying complex mammalian behaviors. Achieving high-precision control and high-resolution information on a complex system, while maintaining intact a full global perspective on the same system, is especially difficult for neuroscience but extends to the study of all biology. The expected outcome of this work will be to enable biologists around the world to readily observe simultaneous activity of cells in 3D volumes of tissue and in real time. From the perspective of both society-at-large and NSF, the significance of this INSPIRE proposal may be very broad. This information will be crucial for understanding how complex behaviors can be tuned, and how complex biological systems operate, and will lead to development of what will be among the largest datasets in biology. This research program also will integrate new multidisciplinary approaches encompassing bioengineering, genetics, optics, chemical engineering, and computer science, which will capitalize upon and strengthen the rich local and nationwide multidisciplinary training and education environments. Computational tools will address data curation and free online public access to resulting information that will be accessible via the website (www.optogenetics.org), and the technology will be freely transferred to other U.S. academic or government laboratories. This Project meets the challenge of achieving high-resolution information on a complex system, while at the same time maintaining a global and functional perspective on the same system: an approach may be transformative, not only in neuroscience, but also throughout biology.","title":"INSPIRE: Fully-assembled Biology via Light-field Illumination and Intact-tissue Imaging","awardID":"1247950","effectiveDate":"2012-09-01","expirationDate":"2017-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"8078","name":"INSPIRE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"7275","name":"CROSS-EF ACTIVITIES"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"1165","name":"ADVANCES IN BIO INFORMATICS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"7714","name":"MODULATION"}}],"PIcoPI":[531790],"PO":["565284"]},"199381":{"abstract":"Current cellular technologies fail to provide services with data rates that are anywhere close to the speeds available over typical Wireless LANs (WLANs). Large-scale deployments of WLANs have the potential to provide ubiquitous high data rate coverage, but the cost of deployment and management of a large number of WLAN access-points for providing full coverage is prohibitive. On the other hand, scattered deployments of WLAN hotspots are useful but they fail to provide any level of service assurance to mobile users.<br\/><br\/>This project aims at developing the foundations for a system that will provide assured data services over a wide-area to data-intensive applications for mobile users using an economically scalable infrastructure consisting of heterogeneous technologies, and to demonstrate it with a prototype implementation. The project involves the following research objectives: 1) to develop solutions for hotspot deployment that enable the best possible services for mobile users through a limited number of hotspots; and, 2) to design solutions for meeting the needs of delay tolerant applications using dynamic resource control.<br\/><br\/>The proposed research is transformative as it will build the foundations for bringing high-speed data services to mobile users through scattered hotspots and it has the potential to open up new research avenues along the lines of assured but interruptible services. A number of applications covering the entertainment, industrial and commercial sectors will get impacted by this research. Special efforts will be made to recruit women and minority students for this project.","title":"EAGER: WideSpot: Enabling Predictable Wide-Area Coverage over Scattered Hotspots","awardID":"1254525","effectiveDate":"2012-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["542039"],"PO":["565303"]},"197082":{"abstract":"The publications culture of a research community has an impact much broader than simply how research is disseminated. This culture can have substantive impacts on how and why research is conducted. The purpose of the workshop is to bring together key players in this ongoing discussion within the CISE community for a discussion and deliberation, with the aim of analyzing the issues and developing guidelines for the way forward. The participants will represent all stakeholders, from academic researchers to for-profit publishers. A specific focus of the workshop would be to develop consensus around a set of guiding principles. The workshop will make significant progress in exploring the current and alternative publication models for computing research.","title":"Workshop on the Publication Culture in Computing Research","awardID":"1242205","effectiveDate":"2012-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["209556","565263"],"PO":["565264"]},"189591":{"abstract":"This research project explores ways to solve optimization problems where the targets of optimization are programs containing general-purpose control and data constructs. Such optimization questions arise often in the everyday practice of software engineering. While it may seem that standard optimization packages could solve these problems, it is often not so. White-box optimization approaches like linear programming are ruled out here because they only permit very restricted classes of objective functions. Black-box optimization techniques like gradient descent and Nelder-Mead search are applicable in principle, but they work well only in relatively smooth search spaces, and due to arbitrarily nested branches and loops, even simple programs can have highly irregular, ill-conditioned behavior.<br\/><br\/>The central insight guiding this project is that program analysis techniques from the field of formal reasoning about programs can work together with blackbox optimization toolkits, and make it possible to solve many more problems of the above sort than are currently possible. Ultimately, the project will produce a unified system for optimizing programs that can leverage flexible combinations of optimization techniques and program analysis strategies. As numerous real-world problems faced in the development of everyday software are optimization problems, this system will offer a new range of capabilities to the end programmer. In addition, the research will foster synergy between two different research areas customarily housed in different academic departments.","title":"SHF: Medium: Collaborative Research: Marrying Program Analysis and Numerical Search","awardID":"1162076","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["541024","551025"],"PO":["565264"]},"189481":{"abstract":"Most scientific and engineering disciplines today have enormous opportunities for creation of knowledge from massive quantities of data available to them. But the lack of appropriate algorithms and analysis tools for processing, organizing, and querying this data deluge makes this task extremely challenging. A large portion of the data being acquired today has a geometric character, and even non-geometric data are often best analyzed by embedding them in a multi-dimensional feature space and exploiting the geometry of that space. This data is invariably full of noise, inaccuracies, outliers, is often incomplete and approximate, yet most of the existing geometric algorithms are unable to cope with any data uncertainty in relating their output to their input. <br\/><br\/>The project aims to fill this void by investigating uncertainty-aware geometric computing, with an express goal of designing algorithmic techniques and foundations that will help extract ``knowledge'' from large quantities of geometric data in the presence of various non-idealities and uncertainties. It focuses on a number of fundamental geometric problems, all dealing with uncertain data. A unified set of models will be developed for modeling uncertainty that can deal with multiple uncertainty types, and attention will be paid to handling noise\/outliers in heterogeneous and dynamic data. Algorithms will be investigated for understanding how input uncertainty carries over to output uncertainty (e.g. by associating a confidence level or likelihood with each output, or computing certain statistics of the output) and how the input uncertainty impacts the quality of the output (e.g. by defining and computing the stability of the output in terms of the input uncertainty). Since exact solutions are likely to be computationally infeasible, the emphasis will be on simple, efficient approximation techniques (e.g. computing a compact, approximate distribution of geometric\/topological structures such as Delaunay triangulations and their subcomplexes of uncertain data). <br\/><br\/>A key ingredient of the award is to address a variety of computational issues that arise in the presence of uncertainty using a few key problems, and to develop a core set of techniques that illuminate algorithmic design under uncertainty not only on these key problems but that can also be transferred to other geometric problems, as needed. This research touches upon many topics in theoretical computer science and applied mathematics including discrete and computational geometry, discrete and continuous optimization, estimation theory, and machine learning. This study will strengthen connections of computational geometry with a variety of disciplines, including machine learning, probabilistic databases, statistics, and GIS. Since so many problems require geometric data analysis, the project has the potential of enhancing the capability of various government, commercial, and civic units to make informed decisions that impact the society at large.","title":"AF: Medium: Collaborative Research: Uncertainty Aware Geometric Computing","awardID":"1161480","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["521232"],"PO":["565157"]},"199194":{"abstract":"This project develops and validates a novel technique for establishing acoustic communication links among nodes in an underwater setup. Basically, acoustic links have limited bandwidth and suffers from slow and multi-path signal propagation. These issues make underwater communication a challenge and motivate the use of directional antennas to establish line-of-sight (LOS) paths between communicating nodes. However, the node mobility while serving an application or due to water current will break LOS links and thus hinders effective communication among nodes. To overcome this challenge, the team develops a novel surface-based reflection (SBR) scheme that allows nodes to utilize reflected acoustic links from the water surface or bottom as non-line-of-sight (NLOS) communication links. A prototype modem is to be developed to utilize a multimodal directional transducer for validating the feasibility of establishing NLOS communication when using the SBR scheme. The prototype design could be leveraged for networking protocols such as node discovery, localization, medium access control and routing. The end result is an efficient directional acoustic communication platform that mitigates the effects of multipath propagation while fully utilizing the available spatial spectrum.<br\/><br\/>This project will boost the effectiveness of many civil and scientific applications. Examples of these applications include search-and-rescue, coastal patrol, oceanographic data collection, environmental monitoring, assisted navigation, and security surveillance. The project will also help enrich the undergraduate and graduate curricula in sensor networks, robotics, and embedded and distributed systems while providing outreach opportunities to demonstrate the prototype to local middle and high schools in order to stimulate interest in this technology among the next generations of scientists and engineers.","title":"EAGER: Prototype Validation of Surface-Reflected Acoustic Communication Links in Underwater Environments","awardID":"1253414","effectiveDate":"2012-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[534304],"PO":["565303"]},"198491":{"abstract":"This grant provides travel support for students wishing to attend the 2012 Operating Systems Design and Implementation (OSDI) conference, which is to be held in Hollywood, California, from October 8-10, 2012. The organizing committee expects that more than 500 people attend the OSDI 2012 conference, with at least 100 student attendees.","title":"Student Travel Support for the 10th USENIX Symposium on Operating Systems Design and Implementation (OSDI 2012)","awardID":"1249332","effectiveDate":"2012-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[532591],"PO":["565255"]},"187172":{"abstract":"Recent studies estimate that a majority of Internet traffic is digital content distribution, whose dominant component is applications that require tight time deadlines, such as content streaming and realtime services. Excessive costs of always-available server-based content distribution networks (CDNs), and a lack of service guarantees in low-cost peer-to-peer (P2P) networks have led the pursuit of agile hybrids of both systems that seek to leverage the best of each. <br\/><br\/>Such a hybrid requires coordination across peers, across information, and across shared resources available to the peers, which form the three research thrusts of this project. The first objective of this project is the development of a systematic analytical framework to achieve this coordination, using ideas drawn from game theory, learning and stochastic networks. The aim is to capture the fundamental properties of large-scale content distribution systems using analytical models, and bind together applications such as file sharing, streaming, cloud-based services, and device-to-device wireless networks by employing this framework. The second is to generate prescriptions for ensuring economic viability by using revelations on the value of the system to participating agents. Finally, the basic analytical methodology developed will be applicable generally beyond the core problem of content distribution. The analytical insights will be validated via a smart-phone-based server-assisted P2P content streaming network. <br\/><br\/>Broader Impact: The project is supported by an education and outreach agenda that aims at familiarizing students with analytical results developed and how best to apply them in a real-world setting. A core component is a semester-long course for seniors and first-year grads in which classroom teaching is complemented by research experience through app development at the AM-Droiders smart-phone laboratory. Outreach includes demonstrations and illustrative projects at a yearly week-long summer camp for high school students, as well as tele-seminars in which students from multiple universities (including Prairie View A&M, an HBCU) can participate interactively. The project is further enhanced by strong collaborations with industry.","title":"CAREER: Beyond Akamai and BitTorrent: Information and Decision Dynamics in Content Distribution Networks","awardID":"1149458","effectiveDate":"2012-09-01","expirationDate":"2017-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["525195"],"PO":["565090"]},"187194":{"abstract":"Continual advances in wireless communication technology offer additional protections against interference and jamming, but these same advances unfortunately also enable stronger attacks. Observant attackers can achieve significant gains by incorporating knowledge of the network under attack, and jammers can consider various metrics, including attack impact, energy efficiency, and stealth. Moreover, attackers can continually adapt parameters and behaviors to compensate for system dynamics, thwart detection, and save valuable resources. Robust wireless communication protocols that can survive such adaptive attacks require new techniques for near-real-time defensive adaptation, allowing the defenders to similarly modify their parameters in response to perceived attack impacts.<br\/><br\/>This project will involve the three primary tasks of identifying and modeling advanced inference-based jamming attacks, developing novel cross-layer network defenses to mitigate jamming attacks using similar adapatation techniques, and characterizing system-level behaviors that emerge from the interactions between multiple adapting parties. Contributions of the project will expand the existing body of knowledge in wireless network security by developing novel probabilistic, game theoretic, and control system theoretic models to better understand efficient and stealthy jamming attacks and provide a basis for future robust protocol design. Application areas in which the project work will be included are mobile commerce using NFC, home networking, medical information management, smart grid communication, and disaster response.","title":"CAREER: Inference-Based Adaptation Techniques for Next Generation Jamming and Anti-Jamming Capabilities","awardID":"1149582","effectiveDate":"2012-09-01","expirationDate":"2017-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["523922"],"PO":["565264"]},"193091":{"abstract":"The preponderance of language design and program analysis efforts in the study of multicore systems has implicitly assumed the presence of an underlying coherent memory that ensures global visibility of updates performed on processor-local caches. Because all threads witness a consistent view of data, concurrency bugs manifest purely as a consequence of unintended non-determinism introduced by scheduler-driven thread interleavings and inadequate synchronization. As new architectural advances lead to multicore or manycore platforms supporting hundreds of (potentially heterogenous) cores, automatically enforcing memory coherence becomes an increasingly complex and expensive proposition. Indeed, new architectural designs are likely to sacrifice local coherence guarantees in exchange for a simple commodity-based scalable design, equipped with a limited degree of global shared memory. Applications that target such platforms must be carefully written not to make assumptions about the consistency of the contents of memory locations accessed and modified locally. In the absence of coherence, new techniques are needed to recover the abstraction benefits that are now lost; these issues become exacerbated at scale. The broader impacts of the proposal have obvious positive interaction with industry efforts to promote multicore and manycore processor platforms.<br\/><br\/>This project will consider novel ways to map consistency models expressed in the context of high-level managed languages onto non-coherent architectural platforms. In doing so, it will consider new programming models, abstractions, analyses, and implementations to enable (a) avoidance of coherency enforcement whenever possible, (b) reduction of coherency demands based on application logic, (c) specification of complex consistency requirements that can be used to inform the implementation of specialized software-based coherence protocols, and (d) integration of language-level memory models with weakly-coherent architectures. The project will subsume formal, rigorous development of different abstractions, analyses, and implementations that enable the automatic construction of new protocol families that express complex aggregates of communication and computation actions with sensible consistency semantics even when executed on non-coherent platforms.","title":"SHF: Small: Programming with Non-Coherent Memory","awardID":"1216613","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["549798","558390"],"PO":["564588"]},"198030":{"abstract":"The project supports participation of graduate students enrolled in PhD programs at US universities in the 10th International Semantic Web Conference (ISWC 202) to be held in Boston, MA, US. Specifically, the project supports travel to the conference for those who might not otherwise be able to attend for financial reasons, and participation in a doctoral consortium that provides for one-on-one interactions and mentoring for the students from the world's leading semantic web researchers. Students benefit from exposure to state-of-the-art semantic web research, opportunities to attend tutorials on emerging research topics. Collectively, these activities help integrate graduate students into the established semantic web research community and provides a natural avenue for integration of research and education.","title":"Travel Fellowships for Students from U.S. Universities to Attend ISWC 2012","awardID":"1247325","effectiveDate":"2012-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[531452],"PO":["565136"]},"189582":{"abstract":"Comparison is an essential part of data analysis and, therefore, of many visualization tasks. While the published literature provides a wealth of visualization tools for looking at individual objects (graphs, volumes, time series, gene sequences, molecular motions, etc.), there has to date been less consideration of support for comparison. The PIs argue that comparison tasks are best supported by tools explicitly designed for that purpose. The problem is that visual comparison becomes more challenging as the number of objects, their size, and the complexity of the objects and\/or of the relationships among them increases. The difficulty is further compounded by our rapidly growing ability to collect and generate data. In prior work the PIs have developed some encouraging initial examples of comparison tools, but these are specialized successes that offer little guidance for future endeavors. Addressing a wider range of comparison problems at greater scale with our present limited understanding thus largely remains an art that requires considerable effort. The PIs' goal in this project is to move towards a science of visual comparison. By studying visual comparison as a general problem, they will establish a domain-independent foundation for the field that facilitates the design of future tools which allow the creation of more effective and scalable comparisons. To these ends the team will pursue three interconnected research threads. They will define theories that are grounded upon principles of visual cognition. They will explore case studies (derived from real problems suggested by domain collaborators) that challenge and extend these theories, provide examples for empirical study, and suggest or use general concepts. And they will identify common tasks, designs, and strategies that enable development of generalized techniques, guidelines, and software components. This approach uniquely combines empirical studies, design explorations, and software development to take the field of visual comparisons to a new level that is both rooted in theory yet viable in practice. <br\/><br\/>Broader Impacts: Because visual comparison plays a key role in diverse domains (including essentially all of the sciences, engineering, and medicine), the potential benefits from an improved science of visual comparison tools are far reaching. To ensure maximum applicability for project outcomes, the PIs are directly collaborating with physical, biological, social, educational, and medical scientists, as well as with engineers and scholars in the humanities. The project will generate visualization tools, software components, and resources for visualization development by others. Visual comparison will serve as a mechanism to expose students at all levels to issues in data understanding. This project will also provide training for visualization specialists, engage non-technical students in visualization, and explore the role of visualization in public outreach efforts.","title":"CGV: Medium: Collaborative Research: Visualizing Comparisons","awardID":"1162037","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["531411"],"PO":["565227"]},"199064":{"abstract":"There is widespread agreement that scientists should receive training in ethics. But little is known about how to achieve and how to assess the desired outcome of helping scientists and engineers to make good ethical decisions. How is it possible to connect ethics education in science to ethical decision making by scientists? In this exploratory research, the PI will address that question. In particular, he will develop a prototype virtue ethics game with the goal of providing proof of concept for the idea that playing such a game will improve ethical decision making. If successful, this will represent a transformative approach to graduate ethics education in two respects. First, in terms of method, despite promising developments in the gamification of pedagogy more generally, few attempts have been made to teach ethics through games. Second, in terms of theory, the PI's approach emphasizes the cultivation of virtues and judgment rather than the delivery of content and rules. Given the limitations of the EAGER funding mechanism, the PI will narrow his focus in two ways. First, rather than attempt development of an electronic game, he will focus on an iterative process of developing and piloting the game concept, mechanics, rules, and pedagogical goals. Second, rather than attempt to demonstrate that game play produces more ethical scientists, he will aim to show that playing the virtue ethics game increases a player's confidence in his or her own ability to make ethical decisions and his or her reputation among fellow players as a trusted member of the scientific community. These preliminary steps will position the PI for submission of a later EESE proposal to validate, scale-up, and digitize the game.<br\/><br\/>The premise of the game will be to simulate the NSF research proposal review process. By adopting various roles (proposer, reviewer, and program officer), students will be immersed in situations that call for ethical decision making. Rather than instructing students in \"the right thing to do\" and then testing whether they know \"the right thing to do,\" this project will place students in situations in which they must decide what to do. Thus, the gaming environment will serve as a training ground for developing the practical skills necessary for sound ethical decision making. The PI argues that this environment is more true to the ambiguous, dynamic, and complex situations faced by scientists than any pre-packaged, static, and unidirectional content. The PI's team incorporates expertise from the Center for the Study of Interdisciplinarity (CSID), the Center for Learning Enhancement, Assessment, and Redesign (CLEAR), the Department of Philosophy and Religion Studies, and the Toulouse Graduate School at the University of North Texas (UNT).<br\/><br\/>Broader Impacts: This project has great potential to contribute to a specific, desired societal outcome: the improvement of ethical decision making in scientists. The America COMPETES Act requires that students who receive funding from NSF receive instruction in Responsible Conduct of Research (RCR), and the National Academies have recommended that acquiring the skills necessary for ethical decision making is the most important aspect of RCR instruction. Project outcomes will be disseminated broadly, including contributions to the Ethics CORE (Collaborative Online Resource Environment) Digital Library and to Ethics of Science, Technology, and Engineering, the second edition of the widely acclaimed Encyclopedia of Science, Technology, and Ethics.","title":"EAGER: Prototyping a Virtue Ethics Game","awardID":"1252692","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7787","name":"EESE"}}],"PIcoPI":["557986","557983","557987"],"PO":["565227"]},"201473":{"abstract":"There are billions of new digital documents created around the world every day. Examples include emails, blog posts, legal documents, and news articles. To enable effective information management, many of these documents are processed by information retrieval systems, such as desktop search tools or Web search engines. Most existing technologies represent documents digitally. To a computer, these representations are nothing more than a sequence of bits, completely devoid of any explicit meaning. Since most modern search engines utilize such basic representations, they often fail to properly account for the meaning of the words found in the documents, thereby diminishing the quality of their results. Despite the importance of this fundamental problem, there have been surprisingly few attempts to build, and subsequently search, document representations that encode the deeply rich meaning of text, especially for data sets that contain millions or billions of text documents.<br\/><br\/>This research investigates how to automatically construct, index, and search next-generation super-enriched document representations. The approach relies on the careful integration of traditional text representations with natural language processing-based sources (e.g., named entities, synonyms, and paraphrases), rich knowledge sources (e.g., Wikipedia and Freebase), contextual sources, and other value-added sources of content. Constructing such representations for large document collections requires computationally intensive batch processing to mine, aggregate, and join data across disparate sources. To overcome these challenges, a scalable, massively distributed cloud computing solution is adopted. The resulting enriched document representations can be effectively applied to a wide variety of information retrieval, natural language processing, and data mining tasks.","title":"EAGER: Constructing, Indexing, and Searching Super-Enriched Document Representations in the Cloud","awardID":"1265301","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"K155","name":"National Security Agency"}}],"PIcoPI":["543277"],"PO":["565136"]},"206951":{"abstract":"The objective of this research is to help increase speed, quality, and productivity of shape handling in practice. Geometric shapes are at the core of a wide range of cutting-edge technological sectors including computer vision, computer aided design (CAD), robotics, bioinformatics, computational biology, medical imaging, geographical information systems (GIS), and drug design, in which a multitude of tasks for manipulating and handling geometric shapes have to be performed efficiently and reliably.<br\/><br\/>This research is based on two research tracks: (i) shape handling applications and (ii) shape handling theory. The investigator will continue to foster interdisciplinary communication, contribute more theoretical soundness to applied problems, and pursue a stronger theoretical foundation which can be the basis for a wider range of applications. Specifically, this research involves several applied projects including, but not limited to, computational proteomics, computational neuroscience, and spatiotemporal traffic databases. Semi-automatic algorithms will be combined with theoretical expertise in order to pave the road for high-throughput processing in areas with very noisy data. Theoretical projects include matching and distance measure problems for curves and surfaces, multi-curve matching, initiation of a general study of geodesic distance measures in which distances are measured using shortest paths on a surface, and shape simplification. Lower bounds will be investigated in order to gain better insight into the structure of the problems, and application-friendly algorithms such as output-sensitive algorithms and approximation algorithms will be devised in order to better cope with outliers and noisy inputs.","title":"CAREER: Application and Theory of Geometric Shape Handling","awardID":"1331009","effectiveDate":"2012-09-01","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["558984"],"PO":["565157"]},"204531":{"abstract":"A fundamental challenge in life sciences is the characterization of genetic factors that underlie phenotypic differences. Thanks to the advanced sequencing technologies, an enormous amount of genetic variants have been identified and cataloged. Such data hold great potential to understand how genes affect phenotypes and contribute to the susceptibility to environmental stimulus. However, the existing computational methods for analyzing and interpreting the high-throughput genetic data are still in their infancy. The objective of this project is to systematically investigate the computational and statistical principles in modeling and discovering genetic basis of complex phenotypes. The proposed research provides answers to the following fundamental questions in genetic association study: (1) How to effectively and efficiently assess statistical significance of the findings? (2) How to account for the relatedness between samples in genetic association study? (3) How to accurately capture possible interactions between multiple genetic factors and their joint contribution to phenotypic variation? In particular, the team will develop a multi-layer indexing structure for robust and scalable multiple testing correction, a general phylogenetic tree based framework to account for local population structure, and an ensemble learning approach for studying joint effect of multiple genetic factors.<br\/><br\/>The research provides a computational framework for large scale genotype-phenotype association study. The outcome includes novel methods for addressing sample relatedness, capturing confounding factors, and controlling multiple testing errors which are widely applicable for many common data mining tasks including frequent pattern mining, multitask learning, and ensemble learning among others. Collectively, the theoretic framework and algorithms will provide the research community much better tools to dissect complex relationships between genotypes and phenotypes, and gain deeper understanding of the roles of environmental stimuli.<br\/><br\/>The proposed research directly involves applications in large scale genome-wide association study. Additional applications exist for biologists in their study of gene-gene interactions, metabolic pathways and protein-protein interaction networks. Beyond the applications proposed here, the algorithms can find wide applications in other areas of biology as well as other scientific disciplines. The methods will be evaluated thoroughly by both simulation and real data collected from yeast, mouse, and human. Early versions of the applications will be made available to the biological community through a web-based server to evaluate efficacy of the methods and to apply them to a broader set of problems.<br\/><br\/>The research findings and methods will be integrated into graduate and undergraduate instruction. The team already offer classes in computational biology and data-mining where the proposed tools will aid students in comprehending abstract concepts and data relations. They will also continue their commitment to supporting multidisciplinary educational experiences, and service to the research community, as well and proving research opportunities for undergraduate students.","title":"III: Medium: Collaborative Research: Toward Robust and Scalable Discovering of Significant Associations in Massive Genetic Data","awardID":"1313606","effectiveDate":"2012-09-19","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["234536"],"PO":["565136"]},"194060":{"abstract":"JavaScript has transformed the way in which software systems are developed, deployed and extended. It is now used to build complex, security sensitive applications for communications, retail, and banking, and is even a primary building block of web browsers themselves. Unfortunately, the advent of JavaScript has also opened the door to new classes of security vulnerabilities, as applications manipulate security critical client information like browsing history, passwords, bank account numbers, social security numbers and so on. Worse, the absence of language-level isolation mechanisms makes it hard to establish confidentiality and integrity of key software components.<br\/><br\/>We believe that the key to making the web more secure is to develop a practical, precise and expressive type system for JavaScript and to use it as a foundation for developing security policies, analyses and enforcement mechanisms for JavaScript browser extensions and applications. Thus, we propose to develop a type system for JavaScript that is expressive enough to support JavaScript's dynamic idioms, practical enough to require minimal programmer intervention and hence, be capable of highly automated analysis of large code bases, and easily extensible enough to allow developers to specify and enforce different kinds of fine-grained security policies.<br\/><br\/>Our research will lead to the following contributions: End Users will be able to freely run extensions, plugins and rich browser applications from trusted sites, without having to suffer the plagues of code-injection, information exfiltration or the unpalatable cures of fully dynamic enforcement whose overhead can render sites unusable. Developers will be able to fully enjoy the fruits of static verification, in a familiar package: namely types. Types will allow developers to specify at the right granularity, the permissions required for some functionality, and will prevent the inadvertent vulnerabilities that are introduced by overprovisioning, or under-sanitization of data. Curators that aggregate third party applications (e.g. ``app stores\" for various mobile platforms) will be able to use type-based certificates to quickly vet applications, thereby determining if an application is safe to host without compromising the reputation of the platform.","title":"TWC: Small: New Foundations for Secure JavaScript","awardID":"1223850","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["529115"],"PO":["564388"]},"195182":{"abstract":"The NSF Sustainable Energy pathways (SEP) Program, under the umbrella of the NSF Science, Engineering and Education for Sustainability (SEES) initiative, will support the research program of Profs. Burcin Becerik-Gerber of the Department of Civil and Environmental Engineering, Wendy Wood of the Department of Psychology, David Gerber of the Department of Architecture, and Milind Tambe of the Department of Computer Science at the University of Southern California (USC). The multi-disciplinary team of investigators will develop an energy-aware, cyber-physical multi agent framework of buildings, humans, and intelligent software agents for sustainable energy management, taking a collective, energy literacy approach to influencing building occupants, operators, designers, and engineers. The investigators will first assess behavior and preferences of building occupants, evaluate building design\/system specifications, and identify building operational policies. They will then build a multi-agent model to integrate these different systems. Building on fundamental research in agents' autonomy and teamwork, the multi-agent framework will facilitate negotiations between occupants and building devices. The agents will provide feedback to the occupants and control building devices to conserve energy. Based on this integrated model, feedback about occupant energy use to building designers will be provided to shape early-stage design decisions that have the longest lasting impact on building's lifecycle footprint. The central focus is designing a multi-component model of energy consumption in office buildings in order to identify and test the optimal points of change in energy systems. Specifically, the research predicts that energy use could be optimized and occupant comfort could be maximized in an integrated way by changing occupant behavior, design\/system specifications, and building operators' policies via an agent-based system. The research will be validated in an office building, where occupants lack the individual financial incentives for energy consumption. The system will be tested both in professional and student designer studios to validate the impact of the model in energy aware design decisions. The research differentiates itself by treating occupant preferences and behavior not only as input data but also as controllable variables in a broader energy system; it then harnesses a complex multiagent system to control these variables for energy savings. It also extends energy literacy into the arena of design and engineering by providing human behavior input in early design stages, as well as into the arena of building operations by dynamically controlling buildings based on human behavior and preferences.<br\/><br\/>With respect to the increasing energy needs of our country and world, this research has far-reaching impact on environmental conservation, pollution, and the economy. The primary impact of this research is identifying the key factors that create significant energy savings for buildings, resulting in monetary savings and environmental protection. The results will be disseminated through and contribute to multiple conference talks and publications. A game, in which students will compete to save the most energy, will be developed with the aim of teaching how to conserve energy in daily life. Energy-focused workshop lessons will be developed and delivered to minority-majority K-12 schools in USC's neighborhood and other children and their families. In addition, the research team will partner in research with the computer science department of California State University, Dominguez Hills, a minority majority institution.<br\/><br\/>The proposed interdisciplinary research challenges the ways that building engineers and designers, computer scientists, and behavioral scientists look at the pressing challenges of energy-efficient buildings. The research will integrate design with outside data sources and bring behavioral science to design, which in turn will trigger a design-method evolution for sustainable buildings. Through dynamic data collection, spatiotemporal information about energy use, and data on human comfort, the research will improve system optimization and adaptation through the use of intelligent software agents. The project will educate building occupants about their energy consumption and the ways that they can make concrete behavioral changes to achieve greater energy efficiency. The research brings to the problem of energy literacy an interdisciplinary approach in which cyber tools are manifested in physical space.","title":"SEP: Creating An Energy Literate Society Of Humans, Buildings, And Agents For Sustainable Energy Management","awardID":"1231001","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"8026","name":"Sustainable Energy Pathways"}}],"PIcoPI":[523205,"563122",523207,523208],"PO":["565303"]},"198471":{"abstract":"This project develops a new approach to protecting information from interception by adversaries in wireless communication networks, with a particular focus on the scenario where an eavesdropper obtains a higher-quality version of the transmitted signal than the desired recipient. The standard method of providing protection in such a situation is to encrypt the information so that it is beyond the eavesdropper's computational capabilities to decrypt the message; this approach has met with longstanding critiques, including the lack of a fundamental proof establishing the difficulty of the problem presented to the adversary. An approach to everlasting security initiated in this project exploits the non-commutativity of certain nonlinear operators: different orderings of the same two nonlinear systems applied to the same input signal can produce different outputs. This property is exploited for security in wireless communication links by employing a short-term cryptographic key to force the eavesdropper's signal to be subjected to nonlinear operations in the reverse order of that of the signal at the desired recipient. The appropriate design of the nonlinear systems yields differences in the signals at the desired recipient and eavesdropper that can be exploited for everlasting secrecy - even when the ephemeral cryptographic key is revealed to or broken by the eavesdropper immediately after transmission. The development of this approach under applicable system constraints and a comparison of the obtained security performance to current approaches form the technical core of this project. <br\/><br\/>By establishing a new approach that expands the system conditions under which everlasting security is obtained, a new avenue of research opens in this critical area of wireless security. In particular, a security approach that exploits characteristics of the eavesdropper's receiver rather than assumptions of noise or loss on the propagation channel will provide an extra layer of security that has not been exploited in current systems. Also, integral to the project is the involvement of undergraduate and graduate students, and a research experience for high school teachers will draw technical ideas from the project. These activities provide workforce development in a critical area by providing a compelling application and further broaden the impact of the project.","title":"CIF: EAGER: Everlasting Security in Disadvantaged Wireless Environments","awardID":"1249275","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["545656"],"PO":["564924"]},"198240":{"abstract":"This research project will develop a theoretical and computational framework to understand and enable the socio-technical dynamics shaping the assembly of teams in distributed global contexts. The main barrier to understanding and explaining the role of human centered computing in team assembly is finding a suitable research environment where (1) geographically distributed individuals from potentially different cultures are assembling in teams of varying sizes to accomplish a variety of tasks over varying durations; (2) their actions, interactions and transactions are captured with precise time-stamps; and (3) their outcomes would be recorded with well-defined metrics. Massively multiplayer online role-playing games offer a research environment that meets all of these requirements. EVE Online, a massively multiplayer online role-playing game, offers a potentially suitable research opportunity to study the assembly of teams and ecosystems of teams. It is notable for allowing as many as tens of thousands of people to interact simultaneously on a single server cluster, from around the world, through a well-developed economic system and serious long-term coalitions, in a more flexible action framework than many other popular games possess. <br\/><br\/>This high-risk high-payoff project will explore the feasibility of using data from EVE Online to identify the socio-technical and cultural mechanisms that explain the assembly of teams more generally. If successful, the study will serve as a model for larger scale studies that, in addition to identifying the assembly mechanisms also assess the impact of these mechanisms on the performance of global teams. The most important and complex decisions in society are made in teams. And yet, assembling effective teams is a daunting task. While there is an awareness of how team collaborations can spearhead socio-economic change, we still have sparse sociotechnical knowledge of how globally distributed cross-cultural teams and systems of teams are assembled. This project seeks to address this limitation. First, the proposed research offers the promise to launch a new generation of theorizing and research on the assembly mechanisms of teams and ecosystem of teams. The empirical data that will be used to develop and test these theories will be a high risk effort but with potential for unprecedented scale, size, and completeness. Second, the research will arguably be the first effort in the field of social networks to develop hypergraph techniques to study assembly of teams and ecosystems of teams. <br\/><br\/>The knowledge and tools developed in this research will allow practitioners to cultivate more effectively the emergence and performance of ad hoc teams in business, science and gaming. It will also provide other scientific disciplines with new computational statistical modeling methodologies and tools to model hypergraphs.","title":"EAGER: Collaborative Research: Some Assembly Required: Understanding the Emergence of Teams and Ecosystems of Teams","awardID":"1248269","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[532009],"PO":["564456"]},"196062":{"abstract":"Adverse drug reactions (ADR) (undesired or excessive responses drugs) have been linked with significant morbidity and mortality, and account for as much as 5% of all admissions. A drug-drug interaction (DDI) is a type of ADR involving two or more drugs. Reports suggest that 50% percent of the drugs withdrawn in the U.S. by the Food and Drug Administration (FDA) from 1999 to 2003 were linked with significant DDIs. The ADR profile of a given drug is rarely complete at the time the drug is approved by FDA. Hence, after a drug has been in use by the general population (with significant diversity in race, gender, age, lifestyle), often previously unidentified DDIs are discovered. To complicate matters, certain populations of patients, e.g., psychiatric patients, are often concurrently treated with multiple medications. The potential interactions between multiple drugs are neither well understood nor completely characterized. Voluntary reporting, the basic mechanism used by the FDA to monitor new drugs, suffers from underreporting, delayed reporting, uneven quality of reports, and even lack of reports of rare DDIs.<br\/><br\/>Against this background, this collaborative project aims to explore the feasibility of a novel computational approach to the problem of drug-drug interaction surveillance. It seeks to develop new methods for predicting molecular level interactions between drugs from data gleaned from online sources and digital social media. The project aims to test the hypothesis that such online data, in combination with with data from traditional drug related databases can be used to reliably predict potential DDIs much sooner than possible using current methods. The effectiveness of the approach is assessed through verification of predictions against future reports. <br\/><br\/>If successful, the project could lead to effective, proactive computational approaches to drug interaction surveillance, with benefits to federal, local and public health agencies, drug companies, clinical practitioners, the patients, and the public at large. Early detection of adverse DDIs could lead to improved patient care, and significant reduction in healthcare costs and lawsuits involving DDIs. The project offers enhanced opportunities for collaboration among investigators with expertise in computational and health sciences. It also offers research-based training opportunities to students at West Virgina University and the University of Virginia. Results of the research will be freely disseminated to the broader academic and research community.","title":"EAGER: Collaborative Research: Computational Public Drug Surveillance","awardID":"1236970","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[525543],"PO":["565136"]},"198130":{"abstract":"Spectrum efficiency refers to the information rate that can be transmitted over a given bandwidth in a specific communication system. It is a measure of how efficiently a limited frequency spectrum is utilized. In this project, innovative spectrum efficient waveform designs are studied towards narrower mainlobe and lower sidelobe in spectrum. It has been recognized that judicious use of properly designed waveforms, coupled with advanced receiver strategies, is fundamental to fully utilizing the capacity of the electromagnetic spectrum. This project seeks innovative approaches on nested and co-prime samplers for spectrum efficiency, and subsequently applies it to wireless networks. Different waveforms designs and diversities are studied based on nested and co-prime samplers. Co-prime samplers are used for Multi-Input Multi-Output communication system. In the application to spectrum efficient wireless networks, nodes exchange information over a common wireless channel. Under different traffic scenarios and different constraints, e.g., bandwidth and signal to noise and interference ratio, the amount of data exchanged among these nodes may vary. A key question then is how the throughput capacity of wireless network improves with the new waveform design schemes and different network setup and how it grows with the number of nodes in the network. This project seeks to help reach the nation's broadband goals and the larger objective of alleviating growing pressure on limited spectrum resources. This project will attract minority and woman students to participate in the project.","title":"Collaborative Research: Spectrum Efficient Waveform Design with Application to Wireless Networks","awardID":"1247848","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7976","name":"EARS"}}],"PIcoPI":[531713],"PO":["557315"]},"198031":{"abstract":"A study of software code has revealed a surprising result: that software code may be just as (if not more) \"natural\" as natural language itself (e.g., English) in that code is highly predictable and repetitive; statistical natural language techniques may be applied quite competently for some software engineering tasks. For example, N-grams may be quite effective at suggestion and completion tasks in code. The evidence supports further exploration of the applicability of statistical NLP techniques and tools to software development activities and processes. The project explores the feasibility of establishing a scientific basis and tools for a variety of code-level software engineering functions -- including natural language summarization, code retrieval, software question answering, automated code completion, and assistive tools for disabled developers to support software engineering, forming not only a new and important domain for further research in NLP, but also a totally new approach to software development.","title":"EAGER: Exploiting the \"Naturalness\" of Software","awardID":"1247328","effectiveDate":"2012-09-01","expirationDate":"2014-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[531454],"PO":["564388"]},"199483":{"abstract":"Recently we have seen the emergence new challenges to cyber security in which adversaries seek, not to simply to deny service, steal data, or utilize resources, but rather to use the network to distort information to influence opinion, thought, or action. Such Internet information manipulation is challenging in that the scale of the Internet makes it easier to influence large numbers of users, that the anonymity on the Internet makes attribution and identity hard, and that the control of information flow is distributed and highly automated allowing for easy modification of personalization and filtering algorithms.<br\/><br\/>This research project proposes to study information manipulation on the Internet. Specifically, it seeks to provide evidence of manipulation and demonstrate the serious nature of the problem. The project has three parts: (1) Constructing a corpus of documented cases of Internet information manipulation, (2) An identification of various players in Internet information flow and their relationships to each other, and (3) An empirical analysis of the scope of the information flow between these players. More broadly, the work will provide data to inform techniques, and methods that with enhance a truly interdisciplinary set of fields, from the social and political sciences, to networking and distributed systems, security, information retrieval, and data mining.","title":"EAGER: Understanding the Scope and Impact of Internet Information Manipulation","awardID":"1255153","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["553725",534889],"PO":["565264"]},"198284":{"abstract":"Porting scientific codes to new high-performance platforms is a time consuming and error-prone process. The research funded by this EAGER award will make scientific codes more portable by raising the level of abstraction. The Principal Investigators will develop a domain-specific language embedded in C++ for solving partial differential equations. They will evaluate the effectiveness of their approach by applying their language to the problem of reacting flow simulations, which is a problem that is important for modeling zero-emission power plants.<br\/><br\/>Computation is an increasingly important tool for scientists, but scientists must hand-tune their code for each new machine to take advantage of the latest high-performance hardware. This research represents a new approach to implementing scientific codes on high-performance machines. The approach allows domain experts to write code at a high level of abstraction while gaining portability across parallel platforms. This research has the potential to improve the productivity of computational scientists by transforming the way that scientific codes are developed.","title":"SHF: EAGER: Platform-Agnostic Supercomputing from Scientific Metaprogramming","awardID":"1248464","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":["556612","564587","556614"],"PO":["564588"]},"199384":{"abstract":"The PIs are developing and testing a prototype visualization lab designed to help middle schoolers understand why the moon appears to have phases when observed from Earth. The work is being done through a partnership between (i) astronomers who have developed the WorldWide Telescope Universe Information System (WWT) and the World Wide Telescope Ambassadors program as a way of bringing the big data and visualization capabilities of astronomers to children and schools and (ii) learning scientists on the WISE team who have a long history of using what is known about how people learn to develop technology-rich middle school science curriculum. Astronomy data and tools for visualization developed by the WWT team is being integrated into WISE's technological infrastructure, which, for curriculum developers, scaffolds the development of curriculum that promotes learning, and for learners, makes available tools and resources for collaboratively making sense of what they are experiencing. Data is being collected that will show the potential of bringing these two projects together for promoting astronomy learning.<br\/><br\/>The WorldWide Telescope computer program, with 9 million downloads, and the WISE environment, funded by NSF since 1998, are both freely available and held up as examples showing the promise of cyberlearning approaches. This project holds the potential to demonstrate the power of formally combining two modern technologies, one developed in industry and the other with public funds, to enhance online learning and educational research. The approaches developed under this EAGER grant will offer an example for future private\/public partnerships and a model for engaging students and promoting learning through access to the big data and tools of scientists, and it will result in free software for the public to use in learning about moon phases and catalyze a long-term partnership with potential for dramatically impacting the ways middle schoolers and high schoolers are exposed to and learn about astronomy and how astronomers do science.","title":"EAGER: A Prototype WorldWide Telescope Visualization Lab Designed in the Web-based Inquiry Science Environment","awardID":"1254535","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":[534685,534686],"PO":["562669"]},"198185":{"abstract":"With software becoming more and more complex, ensuring its total correctness, in the absence of full formal and rigorous specifications, has become a highly nontrivial task. Lightweight program analysis techniques which go beyond type checking and detect semantic bugs are thus becoming increasing relevant. This is especially so given that bugs such as buffer overflows can be exploited to cause havoc, bringing organizations to a stand-still and causing considerable financial loss. <br\/><br\/>This project will explore geometric heuristics for quantifier elimination to automatically derive a restricted class of invariant properties of programs, with the goal of developing scalable highly efficient algorithms for program analysis. Particular attention will be paid to properties expressed using numerical relational constraints on program variables; industrial experience suggests that automatically deriving such properties from unannotated and unspecified programs is extremely useful in finding bugs in industrial software. Recent advances made in satisfiability modulo theories (SMT) solvers and automated reasoning techniques as well as already built tools for quantifier elimination will be exploited to achieve this. This project will build a repertoire of techniques to be used in tools analyzing programs including optimizing compilers, debuggers, and verifiers as well as those for identifying security violations in computer networks.","title":"Generating Octagonal Invariants using Quantifier Elimination Heuristics","awardID":"1248069","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[531861],"PO":["565264"]},"199043":{"abstract":"The grant funds travel to a meeting of Software Engineering (SE) and Artificial Intelligence (AI) researchers to promote synergies between the two fields. Advances in several AI areas, such as data mining, natural language understanding and constraint solving, have become ready for application in many domains, including SE. SE as an area for AI -- automating the activities of programmers -- is still a long-term vision for AI. SE goals, such as component-based, evolvable software containing valid world models and correct code, are important to AI as they are to other fields. The workshop will explore synergies between the fields and serve as a planning meeting for future interactions.","title":"Planning Future Directions in SE & AI","awardID":"1252557","effectiveDate":"2012-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["541880"],"PO":["564388"]},"199098":{"abstract":"This project addresses three main challenges in large scale 3D modeling from photocollections: 1) efficient and complete data linkage, 2) Inference and modeling of scene and user dynamics, and 3) development of data adaptive algorithms. These challenges are tackled within the framework of data association and exploitation. The benefits of such an approach are two fold. First, through enhanced data association, the approach increases the scope of 3D models due to more complete data linkage. Second, through the development of algorithms that are not only robust against (and mitigate) input data variability, but also explicitly designed to exploit this diversity and data richness, the approach increases fidelity of 3D models. The specific data association tasks of this project include: location recognition, view planning for 3D reconstruction, online learning for feature matching, and modeling under scene symmetries. The specific data exploitation tasks of this project include: model update and archiving, native resolution modeling, high resolution dynamic texture estimation, and exploring and leveraging user behavior. <br\/><br\/>This work enables the broad deployment of applications where fully automated scene modeling expands from determining structure properties to encompass the modeling of observable behavioral patterns both in the scene and in the user controlled image capture process. The developed technologies have a wide range of applications, from virtual tourism, to cultural heritage preservation, to disaster response.","title":"EAGER: Data Association and Exploitation for Large Scale 3D Modeling from Visual Imagery","awardID":"1252921","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"L582","name":"National Security Agency"}}],"PIcoPI":["562634","562635"],"PO":["564316"]},"202871":{"abstract":"As the number of cores in high performance computing (HPC) systems continues to grow, the mean-time-to-failure (MTTF) for large HPC systems is becoming shorter than the execution time of many HPC applications. Fault tolerance is becoming one of the critical techniques for the effective use of large HPC systems.<br\/><br\/>This project develops highly efficient algorithmic fault tolerance techniques for selected linear algebra computations to tolerate both fail-stop and fail-continue failures. <br\/>Fail-stop failures, where the failed computation crashes, are often tolerated by checkpoint. This project removes checkpoint from fault tolerance for selected linear algebra computations so that neither checkpoint nor rollback is necessary for the protection of these computations. Fail-continue failures, where the corrupted computation continues to make progress but the computation results cannot be trusted any more, are usually tolerated offline by checking the computation results after the computation finishes. This project designs novel online fault tolerance techniques to detect fail-continue failures in the middle of the computation so that better efficiency can be achieved by stopping the corrupted computations in the middle of the computation in a timely manner.","title":"SHF: Small: FTLA: Fault Tolerant Linear Algebra Software for Massively Parallel Architectures","awardID":"1305622","effectiveDate":"2012-09-01","expirationDate":"2015-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["543712"],"PO":["565272"]},"194050":{"abstract":"Many recent security attacks are financially motivated. Understanding how attackers monetize their activities is critical to combine technological, legal, and economic intervention to render certain classes of attacks unprofitable, and disincentivize miscreants from considering them.<br\/><br\/>Manipulation of social network and web search-engine results to promote illicit businesses is increasingly common. Rather than the product of isolated attackers, search-engine manipulation relies on collaboration between many distinct actors, ranging from individuals installing malware on end-systems, to miscreants funneling traffic in exchange for commissions on sales.<br\/><br\/>This project aims to quantitatively model the economic interactions between the actors behind search-engine manipulation, and to infer which intervention policies could raise the cost of carrying out these attacks. <br\/><br\/>We develop novel measurement methodologies to collect large amounts of field data, cross-reference our measurements with data from industry partners, and gather forensic evidence on compromised hosts that are unknowingly participating in attacks. This leads us to quantify various operational parameters (e.g., common malware families, common infrastructure components...), and use them to build economic models of search-engine manipulation attacks. <br\/><br\/>Project outcomes include (1) identifying salient features that denote relationships between different entities participating in search-engine manipulation campaigns, (2) describing possible relationships between different types of illicit online trades, and (3) discovering points of failure in the attackers' infrastructure, that the defenders can try to exploit. More generally, this study will further refine our understanding of online crime economics, which will not only be useful to security researchers, but also to economists and criminologists.","title":"TWC: SBES: Small: Modeling the Economics of Search-Engine Manipulation","awardID":"1223762","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[519675,"560203"],"PO":["565327"]},"194072":{"abstract":"There are very few publicly available network traces that contain application-level data, because of the enormous privacy risk that sharing such data creates. Application-level data is rich with personal and private information, such as human names, social security numbers, etc. that criminals can monetize. Yet such data is necessary for realistic testing of research products, and for understanding trends in the domain of networking and network applications.<br\/><br\/>This project develops a publicly accessible, diverse and fresh archive of content-rich network data, contributed by volunteer users, called Critter-at-home. Users join the Critter overlay whenever online, offering their data to interested researchers. Privacy of data contributors is protected by several means. First, contributors may opt to host their own data on their machines, thus retaining full control over it. Second, we process contributed data to modify all personal and private information (PPI) and we encrypt it. Third, no human apart from the contributor ever accesses the raw, PPI-sanitized, data. Instead, researchers query the data via our Critter-at-home framework, and they receive aggregate statistics (counts, distributions, etc.) of the traffic features they query for. Four, all contact with a contributor is at her discretion and is done through an anonymous network, where contributor identities are hidden.<br\/><br\/>The archive this project creates will greatly advance security research by providing necessary data for its validation and for data mining. This archive will further be valuable to a broader networking e.g., for realistic traffic generation, as ground truth in traffic classification, and for many other purposes.","title":"TWC: Small: Critter@home: Content-Rich Traffic Trace Repository from Real-Time, Anonymous, User Contributions","awardID":"1224035","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"1668","name":"FED CYBER SERV: SCHLAR FOR SER"}}],"PIcoPI":["550312"],"PO":["565327"]},"198670":{"abstract":"The big question being addressed in this project is, \"How can technology support the teaching and learning of mathematical argumentation?\" This EAGER proposal focuses on the first steps in moving towards the vision of helping youngsters learn mathematical\/algebraic argumentation. The project has two complementary goals: to better define the technological tools needed to support elementary students learning about proof and argumentation and to understand better how elementary school students learn to make and defend mathematical claims when such tools are available. The PIs envision and are developing an animation tool to be implemented on tablet computers (so each child has his\/her own electronic notebook) that provides infrastructure for sharing and refining arguments in small groups and across the class and for promoting concrete math discussions. A big challenge is providing the right tools for expression; for sharing to happen, learners need to first be able to express their understanding, and much research shows that a concrete \"written\" (sharable) expression of understanding provides better foundations for promoting concrete discussion than do expressions of understanding that are simply verbal. The particular advance in expression that is being made in this project is providing tools for dynamic representations; that is, they are able to animate what happens when mathematical operations are carried out. These concrete expressions of understanding can then be played back, paused, and so on. Students create animations by drawing, erasing, duplicating, moving, and grouping objects. They can edit each others' animations, and the teacher will also be able to create animations for students to view and edit. They record and save their oral explanations along with the animations and play them back together, thus making their verbal descriptions concrete, examinable, and sharable. <br\/><br\/>The ability to prepare and present a mathematical argument is a key component of the mathematical competence students need to achieve in upper elementary school (grades 3 through 5). Many students struggle with the subject matter and therefore struggle as well with making mathematical arguments. The PIs envision a computational tool set that young students will use to construct and share mathematical arguments, in the service of learning to be competent algebraic reasoners. In this EAGER project, they focus on first steps in developing that tool set and on investigating how young learners make and defend mathematical arguments when they have such tools available. This project represents work in its early states on an untested but potentially transformative idea and is likely to catalyze rapid and innovative advances in helping young learners become mathematical reasoners.","title":"EAGER: Collaborative Research: Technology to Support Mathematical Argumentation","awardID":"1250362","effectiveDate":"2012-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":["551487"],"PO":["562669"]},"198560":{"abstract":"In recent years, there has been an explosive growth in mobile applications, most of which need to serve global audiences. Cloud computing provides unique opportunities for the application service providers to manage and optimize application delivery over geographically distributed computing resources. The PIs of this project are developing an open application delivery network platform which will allow Internet Service Providers (ISPs) to offer load balancing, fault tolerance, and numerous other application delivery services to the application service providers. <br\/><br\/>The PIs also plan to augment the flow abstraction layer of Software Defined Networks to add adequate support for application-level flows using several other recent innovations such as cross-layer communication, ID\/Locator split, MPLS-like label switching. The claims will be validated through a proof-of-concept implementation of a use-case scenario designed over a prototype switch implementation. <br\/><br\/>A goal of the proposed design is to be evolutionary in the sense that it can coexist and is backward compatible with the current Internet and can be deployed incrementally now with a small number of new devices. The in-going research is designed to transform application delivery over the Internet. It would make significant contributions towards developing a set of generic architectural primitives that may be used for developing application specific networks on shared network infrastructure.","title":"Collaborative Research: Eager: An Application Delivery Platform for Mobile Apps on Global Clouds","awardID":"1249681","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[532762],"PO":["565255"]},"197141":{"abstract":"The integration of gene annotations and omics (e.g., genomics, proteomics, metabolomics) data can provide important insights into noisy and incomplete biological data. Such data is often also on a scale presents computational challenges to many traditional algorithms. This project exploits Foretell, a local search algorithm originally created to accelerate solvers on large constraint satisfaction problems. Here Foretell is used to detect complex relationships among genes in context-specific protein-protein interaction (PPI) networks, with guidance from human experts. This is a novel, and potentially transformative, approach to provide new insights into the molecular and cellular mechanisms of fundamental biological processes. This flexible, innovative project is ideal for noisy, incomplete genomic data. It uses repeated local search guided by empirical biological knowledge to explore large weighted graphs under human direction. It provides users with meaningful feedback to reformulate their search for complex relationships among genes in context-specific PPI networks, and to devise new weight schemes to find them. Expected outcomes include a knowledge base of recurring clusters in Saccharomyces cerevisiae and the weight schemes used to detect them, a more flexible algorithm that detects and tabulates cluster features and provides meaningful feedback to the user, and a tool whose output suggests additional biological experiments. This project addresses, both in its design and its implementation, important questions in the discovery and application of computational approaches to biological networks.<br\/><br\/>Knowledge derived from this project will be broadly applicable and well promulgated through publication and through a web site. The resultant knowledge base will support other researchers? detection of combinations of interacting genes and the interpretation of their results. While it advances discovery and understanding, this project will support interdisciplinary collaboration, disseminate its results broadly, and promote research by students in a predominantly female, minority-serving institution.","title":"EAGER: Cluster Detection in Graphs for Noisy, Incomplete Biological Data","awardID":"1242451","effectiveDate":"2012-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[528942,528943],"PO":["565136"]},"189661":{"abstract":"This project defines meaningful notions of confidence in prediction, designs procedures for computing such notions, and applies these procedures to core machine learning tasks such as active learning, crowd-sourced learning, and tracking. In many applications it is helpful to have classifiers that output, together with each prediction, a rating of the confidence that the prediction is in fact correct. Existing literature either provides various ad-hoc ways for computing such ratings which typically lack a rigorous mathematical footing, or provides mathematically consistent methods (in the Bayesian framework) for computing confidence ratings under very strong assumptions that are unlikely to hold in practice. The research team investigates methods of computing measures of confidence that are mathematically rigorous while making minimal assumptions on the way data is generated, and use these measures to further develop solutions to core machine learning tasks.<br\/><br\/>Defining and computing mathematically sound measures of confidence lies at the heart of machine learning, pattern recognition and uncertainty in AI. Confidence-rated prediction, active learning, and tracking are fundamental tasks of machine learning and statistics that arise repeatedly in large-scale problems; this project will develop rigorous solutions to these problems. The algorithms developed in this work are tested and used in the Automatic Cameraman project, an interactive, audio-visual installation in the UCSD Computer Science department. The interactive Automatic Cameraman system are used an educational tool to be extended in many different directions, by teams of students at a variety of skill levels.","title":"RI: Medium: Quantifying and utilizing confidence in machine learning","awardID":"1162581","effectiveDate":"2012-09-01","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["534486",508515,"525613"],"PO":["562760"]},"198263":{"abstract":"Location Based Service (LBS) is one of the most popular types of applications in mobile networks. As the name suggests, the success of an LBS application depends on two pipelined procedures: localization and information transmission. In other words, an LBS application cannot start until all the mobile users have obtained their positions. The localization time of current methods is too long to support time-critical applications based on mobile networks, where users continually change their positions. This project envisions a radically new alternative to the intuitive pipelined procedures approach, where the LBS application can start before all the users? positions become available.<br\/><br\/>The intellectual merit lies in the concept of mobile essential localization, which is expected to significantly reduce both (i) localization time and (ii) energy consumption, while enhancing the location privacy and guaranteeing the success of LBS applications. The proposal entails high-risk as it is applied to real-time environments, which are highly unpredictable and dynamic. If successful, this novel paradigm could motivate scientific investigations aimed at a plethora of time-critical mobile network applications. One can expect high-reward in terms of applicability to areas of strategic interest including social and vehicular networks, and performance enhancements of such applications.<br\/><br\/>The broader impact of this project is reflected in several aspects: (i) The outcomes of this NSF project will have societal impact on facilitating the spread of mobile network usage; (ii) The new approaches may be adopted by US-based industry in their future designs and protocols for enhancing the location based service availability and its integrity; (iii) This EAGER projects investigates the time critical localization challenge from an interdisciplinary perspective combining Computer Science, Theoretical Computing, Electronic Engineering, and Communications; (iv) The resulting software codes will be disseminated to the public under open source license; and (v) New interdisciplinary graduate curriculum will be offered to students in MA\/OH including minorities and underrepresented groups. Demos will be offered to Toledo Public School students.","title":"EAGER: Collaborative Research: Time Critical Localization in Mobile Networks","awardID":"1248380","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["554394","253923"],"PO":["565303"]},"198384":{"abstract":"Discrete optimization finds widespread use in almost all areas of human endeavor ranging from science to technology to business, and encompassing diverse applications such as chip design, power system design, robotics, bioinformatics, transportation, financial computing and industrial engineering. However, currently there is no general discrete optimization solver that can solve hard problems near-optimally in tractable runtimes (fast to moderate runtimes). To rectify this, this project will explore developing novel and efficient techniques for solving the class of 0\/1 integer linear programming (ILP) problems that can be used to model a wide range of discrete optimization problems (DOPs). The approach used for this purpose is a solution technique termed discretized network flow (DNF), in which classical network flow (that solves a class of continuous linear programming problems), is constrained by special discrete requirements on the flow to yield valid solutions to 0\/1 ILPs.<br\/><br\/>A successful completion of this project will yield algorithms and a software tool for solving large 0\/1 ILP problems near-optimally and much faster than current techniques. This will represent a significant advance in the state-of-the-art of such solvers, and can be used to solve large DOPs more accurately and faster in many application areas ranging from genomics to chip design to robotics. This can help in answering fundamental issues in these application areas that have not been attempted so far, and also lead to better products and services in these areas. For example, in the area of chip design, the use of our solver can lead to much lower power and higher quality chips (e.g., with good performance and reliability) than are possible with current CAD tools, and thereby result in better and greener electronic products in several consumer and commercial application areas.","title":"An Effective and Time-efficient Approach to Solving Linear Discrete Optimization Problems using Discretized Network Flow","awardID":"1248945","effectiveDate":"2012-09-15","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[532322],"PO":["565251"]},"198164":{"abstract":"This INSPIRE award is partially funded by the Perception, Action, and Cognition Program and the Social Psychology Program in the Division of Behavioral and Cognitive Sciences in the Directorate for Social, Behavioral and Economic Sciences, and the Human-Centered Computing Program in the Division of Information and Intelligent Systems in the Directorate for Computer and Information Science and Engineering. <br\/><br\/>The notion of collective wisdom - that many interacting individuals can produce better ideas, insights, solutions and decisions than a single individual can produce - is a foundational principle for many institutions of modern societies, including elections, parliaments, governing boards, free markets and the free press. Until recently, such collective wisdom could only be harnessed through massive unstructured mechanisms such as elections and markets, or through highly structured and interactive but smaller-scale mechanisms such as legislatures, committees, boards and panels. With the advent of the Internet, the World-Wide Web and social network technology, the paradigm has changed. It is now possible for large numbers of diverse, geographically distant individuals to interact in structured ways and at almost no cost. This has opened up vast possibilities for innovation and creativity, but these possibilities are still largely unrealized. A major reason for this is the lack of a systematic scientific understanding of collective innovation in human networks. The current project addresses this through a combination of methods from several disciplines, bringing together a unique group of researchers with expertise in social psychology, cognitive science, computer science, engineering and network theory.<br\/><br\/>The fundamental principle underlying the research is that an understanding of natural human innovation requires a coordinated combination of laboratory and field studies and that neither is sufficient on its own. Field studies of innovative human networks (communities of research scholars and engineers) will be used to identify natural patterns of innovation through data mining and intelligent analysis methods. Laboratory experiments will then verify and validate these patterns under controlled conditions. Thus, through a combination of large-scale fieldwork and careful experiments, the investigators will develop better metrics for measuring innovation and discover ways to help groups and individuals be more innovative. Most importantly, this project will clarify how the connectivity of individuals in a network acts to boost or suppress innovation, leading to recommendations for making human networks from corporations to social networks more innovative.<br\/><br\/>Recent studies suggest that the rate of innovation must increase exponentially to sustain a growing and urbanizing global society. While the proposed research will focus on specific areas, the methods it generates will inform organizations and governments broadly in developing policies conducive to innovation. In today's fast-moving, highly competitive world, such policies are likely to be a major determinant of scientific, technological and geopolitical leadership.","title":"INSPIRE: The Hunting of the Spark: A Systematic Study of Natural Creativity in Human Networks","awardID":"1247971","effectiveDate":"2012-09-15","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"1332","name":"SOCIAL PSYCHOLOGY"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"7252","name":"PERCEPTION, ACTION & COGNITION"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"8078","name":"INSPIRE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[531801],"PO":["563458"]},"189485":{"abstract":"Most scientific and engineering disciplines today have enormous opportunities for creation of knowledge from massive quantities of data available to them. But the lack of appropriate algorithms and analysis tools for processing, organizing, and querying this data deluge makes this task extremely challenging. A large portion of the data being acquired today has a geometric character, and even non-geometric data are often best analyzed by embedding them in a multi-dimensional feature space and exploiting the geometry of that space. This data is invariably full of noise, inaccuracies, outliers, is often incomplete and approximate, yet most of the existing geometric algorithms are unable to cope with any data uncertainty in relating their output to their input. <br\/><br\/>The project aims to fill this void by investigating uncertainty-aware geometric computing, with an express goal of designing algorithmic techniques and foundations that will help extract ``knowledge'' from large quantities of geometric data in the presence of various non-idealities and uncertainties. It focuses on a number of fundamental geometric problems, all dealing with uncertain data. A unified set of models will be developed for modeling uncertainty that can deal with multiple uncertainty types, and attention will be paid to handling noise\/outliers in heterogeneous and dynamic data. Algorithms will be investigated for understanding how input uncertainty carries over to output uncertainty (e.g. by associating a confidence level or likelihood with each output, or computing certain statistics of the output) and how the input uncertainty impacts the quality of the output (e.g. by defining and computing the stability of the output in terms of the input uncertainty). Since exact solutions are likely to be computationally infeasible, the emphasis will be on simple, efficient approximation techniques (e.g. computing a compact, approximate distribution of geometric\/topological structures such as Delaunay triangulations and their subcomplexes of uncertain data). <br\/><br\/>A key ingredient of the award is to address a variety of computational issues that arise in the presence of uncertainty using a few key problems, and to develop a core set of techniques that illuminate algorithmic design under uncertainty not only on these key problems but that can also be transferred to other geometric problems, as needed. This research touches upon many topics in theoretical computer science and applied mathematics including discrete and computational geometry, discrete and continuous optimization, estimation theory, and machine learning. This study will strengthen connections of computational geometry with a variety of disciplines, including machine learning, probabilistic databases, statistics, and GIS. Since so many problems require geometric data analysis, the project has the potential of enhancing the capability of various government, commercial, and civic units to make informed decisions that impact the society at large.","title":"AF: Medium: Collaborative Research: Uncertainty Aware Geometric Computing","awardID":"1161495","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["536698"],"PO":["565157"]},"189386":{"abstract":"In this collaborative interdisciplinary proposal involving a researcher at the University of Illinois at Chicago (UIC) and one at the Pennsylvania State University (Penn State), the investigators will design and apply novel algorithmic tools to explore several fundamental graph-theoretic problems that have significant applications in biological and social interaction networks. The research problems addressed in the proposal can be broadly classified into graph partitioning type of problems and graph sparsification type of problems. For example, one such problem in the context of social interaction networks is to partition the nodes into so-called \"communities of statistically significant interactions\" to study the behavioral patterns of a group of individuals in a society. The PIs will formulate precise computational problems, study their properties, use novel algorithmic tools to design efficient algorithms, and implement the resulting algorithms to test their accuracy and efficiency. The proposed research will leverage further development of novel combinatorial tools previously developed by the PIs, in addition to developing new techniques, to design efficient algorithms for complex optimization problems. The algorithms developed in the course of this project will be implemented for validation on simulated and real data, and will lead to open-source software for the life science and social science communities.<br\/><br\/>On a broader level, since this proposal deals with fundamental combinatorial optimization problems that arise in diverse scientific fields, the proposed research will have a strong impact on research areas beyond the primary research area, such as in stability analysis of computer networks and in social network visualization. A central component of the proposal is the creation of meaningful educational activities that leverage the proposed interdisciplinary research and build on the PIs' substantial past experience in teaching, mentoring and outreach and on the diverse communities in Chicago . Additionally, the PIs plan to integrate research and education via course and curriculum development, involvement of undergraduates, minorities and under-represented groups, effective dissemination of research, mentoring of undergraduate and graduate students, outreach and community involvement, and promoting diversity in research and educational activities.<br\/><br\/>The outcomes of the project will be made freely available through the following websites of the investigators and their labs: http:\/\/www.cs.uic.edu\/~dasgupta; http:\/\/www.cs.uic.edu\/~dasgupta\/professional\/algo-lab.html; and http:\/\/www.phys.psu.edu\/~ralbert.","title":"III: CCF: Medium: Collaborative Research: Combinatorial Analysis of Biological and Social Networks","awardID":"1160995","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["516991"],"PO":["565136"]},"193280":{"abstract":"The massive hardware scale, labyrinthine software complexity, and tangled external interactions of networked systems conspire to undermine reliability: Scale increases the frequency of failures while interconnectedness exacerbates their consequences by turning local mishaps into global disasters. This project will establish new system support toward recoverable network applications on two foundations. In an individual machine, fast, simple application recovery can be greatly eased if the application state on the persistent storage is kept always consistent. Over a networked system, the fault-tolerance and global consistency can be better supported and reasoned if application components commit local state before emitting any output to others. The time is right for this effort, because emerging Flash-based solid-state disks (SSDs) promise to dramatically reduce the cost of required persistent state management. Research will proceed along three fronts: First, the project will design and implement a new operating system mechanism (fast synchronous logging without double writes) for failure-atomic, synchronous I\/O on SSDs. Second, for broad applicability, this project will present the programmers with simple extensions of familiar POSIX interfaces. Third, to achieve efficiency and fairness, research will develop a new I\/O resource manager that combines the classic fair queuing scheduling with SSD-oriented anticipatory I\/O. Fast, simple failure recovery mechanisms developed in this project will enable high reliability for a broad range of networked applications that are critical to today's digital economy and society. This project will also involve industry collaboration, curriculum enhancement, and student training.","title":"CSR: Small: System Support for SSD-Backed Recoverable Network Applications","awardID":"1217372","effectiveDate":"2012-09-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550397"],"PO":["565255"]},"193291":{"abstract":"The ubiquitousness of massive data sets presents<br\/>great challenges. The difficulty of dealing with massive data<br\/>sets is especially formidable when attempting to<br\/>solve computational problems in which both the inputs<br\/>and the outputs to the computation are large.<br\/>In such a situation, it would be useful if one could find<br\/>faster ways of computing just the portion of the output that is required<br\/>by the user.<br\/><br\/>This project aims to study \"local computation algorithms\",<br\/>namely algorithms that quickly compute only the portions of the<br\/>output that are required by the user,<br\/>without performing the full computation.<br\/>In particular, local computation algorithms<br\/>view only a miniscule portion of the input.<br\/>The PI considers a broad based approach, studying the application of<br\/>local computation algorithms to a range of problems and<br\/>settings within algorithm design.<br\/>The focus of this research is on the question of when local computations<br\/>can be done in time that is sub-linear in the size of the input and output.<br\/>The proposed research will develop techniques for constructing<br\/>such algorithms and for understanding when such algorithms are<br\/>not possible.<br\/><br\/>The project will leverage known results from sub-linear time<br\/>algorithms, which for the most part have focused on the somewhat<br\/>different setting of computational<br\/>problems in which the inputs are large but the outputs are small.<br\/>In addition, the project will investigate well-studied<br\/>classes of algorithmic techniques and focus on modifying them for<br\/>use in this new setting. Such classes include algorithmic techniques<br\/>first developed for parallel and distributed algorithms, as well as the<br\/>extensively used greedy method.<br\/>Problems from combinatorial optimization, graph theory and compressibility<br\/>of strings will be studied.","title":"AF: Small: Local Computation Algorithms","awardID":"1217423","effectiveDate":"2012-09-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[517766],"PO":["565251"]}}