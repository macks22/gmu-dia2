{"62925":{"abstract":"The research described here addresses information security issues for embedded processors and constrained environments. Embedded processors are found in a vast array of existing and emerging technologies, including mobile phones, personal digital assistants, smart cards, and remote-controlled utility network devices and are distinguished from typical (but far less prevalent) PC-level microprocessors in their relatively low power consumption and inherent limitations on memory and speed.<br\/><br\/>It is predicted that the number of applications with embedded microprocessors which will be connected to our telephone and computer networks will increase dramatically over the next few years. For instance, it is anticipated that within the next few years, 50% of all Internet end-devices will have to operate in constrained environments. At the same time, these networks are enabling remote access to, and manipulation of, sensitive resources of all sorts, including bank records, medical information, alarm system, and industrial machinery.<br\/><br\/>The need is clear for long-term planning and directed research in the area of cryptographic security for these devices. The challenges represented here require the attention of experts from a variety of disciplines, from engineering to computer science to mathematics. Both fundamental and immediate problems face hardware designers, software engineers, and theoretical crypytographers alike.<br\/><br\/>We propose a three-pronged approach in an effort to contribute solutions to these problems. The long-term ambition of such research is to bring cryptographic security solutions to the market which are low-cost, highly scalable, and suitable for constrained environments. This project places particular focus on implementation of public-key algorithms in embedded devices and is divided into three modules as follow:<br\/><br\/>Development of power-efficient and scalable cryptographic hardware for pervasive computing.<br\/><br\/>Investigation of emerging public-key schemes which appear promising for implementation in constrained environments.<br\/><br\/>Evaluation of combinatorial structures for public-key schemes in hardware and on embedded processors.<br\/><br\/>This three-pronged approach combines a long view, cutting across disciplines, as well as a variety of very promising short-term objectives which assure practical relevance and payoff.","title":"ITR:SI Implementing Public-Key Cryptosystems for Secure Information Infrastructure","awardID":"0112889","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["564461","549951","550273"],"PO":["7594"]},"60868":{"abstract":"0103933<br\/>Ramanujam, Jagannathan<br\/>Louisiana State University & Agricultural and Mechanical College<br\/><br\/>CISE Postdoctoral Associates in Experimental Computer Science: CISE Postdoctoral Research and Training in Advanced Compiler Optimization<br\/><br\/>Modern processors extensively use memory hierarchies with multiple levels of caches in order to cope with the widening gap between processor and memory speeds. As a result, the performance of programs depend critically on their memory access characteristics and how these are matched to the memory hierarchy of the processors. While several compiler transformations have been proposed towards enhancing locality, even for programs with regular memory access patterns such as those in dense linear algebra computations, the best compiler-optimized codes do not match the performance of library implementations.<br\/><br\/>One goal of this research is to train a postdoctoral research associate in the area of developing compiler transformations (either data or computation or a combination of the two) to handle a larger class of programming constructs than perfect nests and regular memory accesses. Initially, the associate will build on data shackling, which has been recently proposed as a data-centric approach to the problem of optimizing locality. To accomplish this goal, the associate will be trained to design an optimization strategy that will integrate data shackling (a data-centric approach) and tiling (a control-centric approach), and implement it in a compiler and evaluate its effectiveness. The associate will:<br\/><br\/>1) Study a large collection of applications with both regular and irregular memory access patterns, including scientific computing codes and multimedia applications,<br\/><br\/>2) Design heuristics for improving the effectiveness and applicability of data shackling, develop methods to integrate data shackling and tiling, and implement these in a compiler, and<br\/><br\/>3) Perform extensive experimental evaluation of the techniques on several benchmarking applications.","title":"CISE Postdoctoral Research and Training in Advanced Compiler Optimizations (Operating Systems and Compilers Program\/CCR\/CISE)","awardID":"0103933","effectiveDate":"2001-09-01","expirationDate":"2005-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":["557461"],"PO":["564318"]},"62936":{"abstract":"This project will develop a new generation of numerical simulation systems using advanced parallel computers, mathematical models, and real-time data. Modern sensor technology and the Internet have made it possible to monitor closely the performance of structures such as highway bridges. However, there are often limits on the possible number of embedded sensors, and accurate prediction the overall structural performance therefore requires other technologies, such as computer modeling, at the same time. This project will merge the two technologies, creating a computer modeling system that incorporates the live data in the numerical simulation.<br\/><br\/>Using measured data as an integrated part of a numerical simulation is a challenging research project. Because data collected by the sensors must be moved continuously into the numerical simulation, the traditional paradigm of reading control parameters at the start of the computation is not possible. Instead, this project will use the ALICE memory snooper from Argonne National Laboratory to allow the constant interruption introduced by the transmission of the measured data. This will in turn allow a parallel computer to exchange information with remote sites without going through slow disk I\/O. To fully integrate the sensor data with the computation, the project will develop new numerical schemes based on classical multigrid methods, but using the measured data to build the coarse space. The measured data will also be used as a basis for calibrating and validating the parameters in the mathematical model.<br\/><br\/>The new simulation system will be used in a high cycle fatigue test of bridge decks, which will be conducted in the Structures Laboratory at the University of Colorado at Boulder. Field tests will also be scheduled on new bridges to be constructed with a variety of installed sensors. These tests are part of ongoing projects sponsored by other agencies. The synergy of these projects will help develop and validate the proposed simulation system.","title":"ITR\/AP: A Live-Data Simulation with Application to Bridge Performance","awardID":"0112930","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["517075","398834"],"PO":["565272"]},"60769":{"abstract":"EIA-0103645<br\/>Laxmikant V. Kale<br\/>University of Illinois<br\/><br\/>Performance Modeling and Programming Environments for PetaFlop Computers and the Blue Gene Machine<br\/><br\/>The objective of the proposal is to develop performance simulation capabilities to allow system level analysis and prediction of performance of the next generation complex PetaFlop machines that include multiple levels of memory hierarchy and interconnects. The performance simulator that will be developed will be used to test parallel data structures and algorithms implemented in programming environments used in these machines, as well as frameworks to enable the development of applications for these machine classes. A number of important applications will be used to test and validate the CS technology advances.","title":"NGS: Performance Modeling and Programming Environments for PetaFlop Computers and the Blue Gene Machine","awardID":"0103645","effectiveDate":"2001-09-15","expirationDate":"2006-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["533380","558488","551063","517379"],"PO":["301532"]},"61319":{"abstract":"With communication link speed exceeding terabit per second, packet processing at the routing processors is becoming the main bottleneck in network services. The workload for these processors is very different compared to the general-purpose processors.<br\/><br\/>The two-year project develops necessary benchmark and simulation environment to analyze the impact of new architectural ideas, such as instruction-level parallelism, branch prediction, speculative execution, lock-up free caches and multiprocessing, on the performance of Internet router architectures. First, it creates suitable workload by developing a set of communication benchmark programs that normally execute on high-performance routers. These programs are executed on commercially available processors and their performance is compared with other standard benchmark applications.<br\/><br\/>The main contribution of the project lies in development of an execution-driven simulator for the router, where these communication programs are compiled and executed. The simulator incorporates the network processor, line cards, and the backbone crossbar switch. The input data to the simulator is obtained from real Internet traces, such as NLANR and UCB. By incorporating new ideas in instruction-set design, memory subsystem, packet scheduling, and multiprocessing into the simulator, architectures for the next-generation Internet routers are developed and tested in this project.","title":"High-Performance Internet Router Architectures","awardID":"0105676","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["516924"],"PO":["180163"]},"64828":{"abstract":"We are poised at the threshold of an information rich world with devices and services able to deliver that information to nearly anyone, at any place, and at any time. Humans have evolved social mechanisms for smoothly and flexibly managing interpersonal communications; however, current computational and communications devices are, almost without exception, utterly unaware of the social and attentional state of the user. They know little or nothing of the personal, social, and task situations in which they are used, and they do little or nothing to account for, and minimize, the human costs they induce. In this project, the PI and his team will explore situationally appropriate interfaces that retrieve, generate, and deliver information in a manner that is sensitive to the situation of the user. These interfaces will allow for communication and information systems that maneuver, rather than blunder, through the social world. To accomplish this ambitious goal, the team will pursue a three-part research plan. First, they will use behavioral theory and research to model social mechanisms for managing interpersonal communications. The comparatively unexploited research we will draw on examines the affordances of situations and consistent patterns of human nonverbal social behavior within situations. Second, they will extract key situational and user behavior data from these models via input from new sensing technologies, using noninvasive (e.g., vision-based) sensing technology to provide information about situations and users. Third, leveraging knowledge from sensory, perceptual, and cognitive psychology, as well as from the fields of visual and interaction design, the team will create displays and interaction designs that are far more situationally appropriate than today's interfaces. To address the substantial challenges that this breadth of work presents, the PI has assembled a strong multidisciplinary team that brings expertise from computer science, social, sensory, perceptual, and cognitive psychology, and the field of design.","title":"ITR\/SY: Situationally Appropriate Interaction","awardID":"0121560","effectiveDate":"2001-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7496","name":"COLLABORATIVE SYSTEMS"}}],"PIcoPI":["518043","564316","526576","457024"],"PO":["564456"]},"60802":{"abstract":"EIA-0103742<br\/>Lawrence Rauchwerger<br\/>Texas Engineering Experiment Station<br\/><br\/>NGS: Collaborative Research: SmartApps: An Application Centric Approach to High Performance Computing<br\/><br\/>The objective of this proposal is to develop new methods that allows runtime performance optimization by an enhanced monitoring, resource modeling, evaluation and remapping of the application at runtime, depending on runtime resources and application performance. The specific approaches to be pursued include application algorithm adaptation, run-time software optimization, system configuration selection and tuning reconfigurable OS services.","title":"NGS: Collaborative Research: SmartApps: An Application Centric Approach to High Performance Computing","awardID":"0103742","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["561154","496841"],"PO":["301532"]},"62926":{"abstract":"An application running in a distributed computing environment such as the Computational Grid must adapt to the available hardware and software resources. This requires information about the properties of Grid resources such as hosts, network switches, links and paths, software libraries and systems, user and organization rights, software services, event channels and dictionaries, and more. The information needed for an application to run, the values of the information (how fast the information changes) and the freshness of the information (how fast updates must be pushed to the application) can vary dramatically. These attributes place significant demands on the resource information service, demands that are arising with increasing prevalence in the general area of directory services as well. The Grid Forum, an international standards body for world-wide Grid computing, is developing standards for representing and querying this information. There is much that is excellent about these evolving standards, but there are many forms of highly desirable queries that will be difficult or expensive to perform in these systems. In particular, dynamic information will require very high update rates not supported by LDAP-based implementations.<br\/><br\/>This project will address these concerns through a proposed (and tentatively named) Grid Resource Information Service (GRIS), a unified relational approach to grid information services. The research will start with the full ACID (Atomicity\/Consistency\/Isolation\/Durability) functionality of a relational database system and \"build down\" to a practical resource information system that still provides most of the benefits of the RDBMS. Such a system will provide a single highly flexible query model and language for all types of Grid resource information, no matter how dynamic. The research will culminate in an extensible implementation based on commodity database systems and the SQL language, including \"canned queries\" for non-SQL users. The project will evaluate the new system and techniques using logged updates and queries from an existing Grid information service, and comparing results with a hierarchical system such as Globus MDS2. To facilitate comparisons, the project will produce a set of benchmark queries from discussions with users, tool developers, and Grid Forum members, and will quantify the limits of these queries.","title":"ITR\/SY Collaborative Research: A Unified Relational Approach to Grid Information Services","awardID":"0112891","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["540138"],"PO":["565272"]},"60748":{"abstract":"EIA-0103582<br\/>Rudolf Eigenmann<br\/>Purdue Research Foundation<br\/><br\/>NGS: Collaborative Research: An OpenMP Environment for Wide-Area Network Computing<br\/><br\/>The objective of this proposal is to develop a new programming system that will close the gap that exists between programming SMPs and networked computer clusters, by using the emerging standard (OpenMP) for SMPs and develop compiler and runtime support that will enable using OpenMP on distributed platforms with optimized performance. The proposed programming system will make it possible to program the Grid and networked computer systems using OpenMP, the emerging standard for shared-memory programming. The PI expects to attain high efficiency in the execution of OpenMP programs for collection of Grid-connected computers. Through static and dynamic compiler techniques, we expect to harness the complexity and load fluctuations of the target environment.","title":"NGS: Collaborative Research: An OpenMP Environment for Wide-Area Network Computing","awardID":"0103582","effectiveDate":"2001-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["558595"],"PO":["301532"]},"62937":{"abstract":"EIA-0112934<br\/>Ting Chen<br\/>University of Southern California<br\/> <br\/>Title: ITR\/AP(BIO): Algorithmic Study in Computational Proteomics<br\/><br\/>The main focus of this project is on developing computer algorithms and programs to support a technology called High Performance Liquid Chromatography (HPLC)-Tandem Mass Spectrometry (MS-MS), a very powerful tool for high-throughput protein identification. This technology generates mass patterns for peptides, and relies on fast and accurate computer algorithms to map mass patterns to peptide sequences. This project aims at designing algorithms for multiple proteomic applications.<br\/><br\/> This project addresses four fundamental computational problem areas in Proteomics: (1) the problem of peptide identification (2) the problem of de novo peptide sequencing, which aims to sequence peptides directly from tandem mass spectra without database search, (3) the problem of identifying protein cross-linking sites, which looks for a pair of cross-linked peptide sequences optimally correlated to a tandem mass spectrum, and (4) the problem of peptide mass fingerprinting, which aims to identify proteins by their masses of enzyme-digested peptide mass patterns. Novel and efficient algorithms are being designed to solve these problems.","title":"ITR\/AP(BIO): Algorithmic Study in Computational Proteomics","awardID":"0112934","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["464484"],"PO":["565136"]},"60759":{"abstract":"EIA-0103610<br\/>David Padua<br\/>Univ. of Illinois<br\/><br\/>NGS: Collaborative Research: An OpenMP Environment for Wide-Area Network Computing<br\/><br\/>The objective of this proposal is to develop a new programming system that will close the gap that exists between programming SMPs and networked computer clusters, by using the emerging standard (OpenMP) for SMPs and develop compiler and runtime support that will enable using OpenMP on distributed platforms with optimized performance. The proposed programming system will make it possible to program the Grid and networked computer systems using OpenMP, the emerging standard for shared-memory programming. The PI expects to attain high efficiency in the execution of OpenMP programs for collection of Grid-connected computers. Through static and dynamic compiler techniques, we expect to harness the complexity and load fluctuations of the target environment.","title":"NGS: Collaborative Research: An OpenMp Environment for Wide-Area Networked Computing","awardID":"0103610","effectiveDate":"2001-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["533380","485665"],"PO":["301532"]},"62827":{"abstract":"This project will develop tools that make it possible to retrieve naturally occurring sentences from the World Wide Web on the basis of lexical content and syntactic structure, providing linguists with an immediate, easily accessible source of raw linguistic data. The PIs will investigate specific linguistic hypotheses at the lexical semantics\/syntax interface as an illustrative application of these tools. At a high level, the planned work constitutes an important step toward a new paradigm for linguistic research. Rather than relying entirely on introspective data generated by the linguist who is trying to (dis)prove a particular hypothesis, Web-enabled linguistics research will draw on the methodology and the tools developed by the PIs to supply naturally occurring data on which theories can rest. With regard to specific linguistic questions, the goal is to provide an explanation of the rules and constraints that govern three transitivity alternations (Middle, Unaccusative, Unspecified Object Deletion), and the PIs expect data made available by their tools to shed light on the \"grey\" area between competence and performance, that is, the linguistic behavior that seems to fall outside of rule-governed behavior. Although naturally occurring data are not accorded great emphasis in generative syntax, the use of text corpora has a tradition in the greater linguistic enterprise. An explosive new phenomenon in the world of naturally occurring text, the World Wide Web is an essentially untapped resource that embodies the rich and dynamic nature of language, presenting a data resource of unparalleled size and diversity","title":"Collaborative Proposal: Using the Web as a Corpus for Empirical Linguistic Research","awardID":"0112429","effectiveDate":"2001-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["511536"],"PO":["246649"]},"64818":{"abstract":"Electronic markets are emerging as a primary medium of trade in business-to-business, business-to-consumer, and consumer-to-consumer settings. In order to design viable electronic marketplaces, a host of novel interrelated game-theoretic and computational issues must be<br\/>addressed. With a team of interdisciplinary researchers from multiple institutions, this project will develop a unified theory of games and computing to guide and facilitate the growth of such markets. Specific research directions of the project include the following: (1) Market designs will be generalized to incorporate combinatorial bidding, multi-attribute preferences, multi-stage mechanisms, continuous mechanisms, and multi-unit sale; (2) New algorithms for clearing, quoting, incentive-compatible pricing as well as new incentive-compatible tractable mechanisms will be designed with particular emphasis on online and incremental updating of market states; (3) Bounded rationality of the agents will be investigated under a wide spectrum of models of computations, equilibrium concepts of game theory, and trade-offs between centers and agents; and (4) Novel approaches to relaxing the classic common prior assumption will be explored in order to develop practically useful models for ecommerce. The successful completion of this project will make significant contributions to both theory and practice in the areas of electronic commerce, multi-agent systems, algorithms, computational complexity theory, and game theory.","title":"ITR\/PE+SY: Collaborative Research: Foundations of Electronic Marketplaces: Game Theory, Algorithms and Systems","awardID":"0121541","effectiveDate":"2001-09-15","expirationDate":"2008-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["560217",167381],"PO":["564456"]},"64829":{"abstract":"Electronic markets are emerging as a primary medium of trade in business-to-business, business-to-consumer, and consumer-to-consumer settings. In order to design viable electronic marketplaces, a host of novel interrelated game-theoretic and computational issues must be<br\/>addressed. With a team of interdisciplinary researchers from multiple institutions, this project will develop a unified theory of games and computing to guide and facilitate the growth of such markets. Specific research directions of the project include the following: (1) Market designs will be generalized to incorporate combinatorial bidding, multi-attribute preferences, multi-stage mechanisms, continuous mechanisms, and multi-unit sale; (2) New algorithms for clearing, quoting, incentive-compatible pricing as well as new incentive-compatible tractable mechanisms will be designed with particular emphasis on online and incremental updating of market states; (3) Bounded rationality of the agents will be investigated under a wide spectrum of models of computations, equilibrium concepts of game theory, and trade-offs between centers and agents; and (4) Novel approaches to relaxing the classic common prior assumption will be explored in order to develop practically useful models for ecommerce. The successful completion of this project will make significant contributions to both theory and practice in the areas of electronic commerce, multi-agent systems, algorithms, computational complexity theory, and game theory.","title":"ITR\/PE+SY: Collaborative Research: Foundations of Electronic Marketplaces: Game Theory, Algorithms and Systems","awardID":"0121562","effectiveDate":"2001-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":["536698"],"PO":["564456"]},"62904":{"abstract":"EIA-0112742<br\/>Schimpf, Paul<br\/>Washington State University<br\/><br\/>ITR\/Comp Bio: Computational Tools for Inverse Electromagnetic Problems<br\/><br\/>The principal investigator previously developed an adaptive algorithm for solving the Poisson problem in complex three-dimensional domains. This algorithm found immediate application<br\/>in modeling the electric field produced by surgically implanted defibrillators as a guide to electrode placement for the cardiologist, where the algorithm reduced solution times from 3 hours to less than 10 minutes.<br\/><br\/>A logical next step is the pursuit of more demanding applications, such as those with an inverse problem formulation. The inverse problem seeks to identify volume energy sources on the basis<br\/>of electric field measurements on the surface or magnetic field measurements outside of the modeled domain. In general, there is no unique solution unless some a-priori knowledge of the<br\/>sources is exploited. Inverse problems can be formulated for many applications with domains<br\/>governed by partial differential equations. They are computationally intensive because many forward computations are typically required for a solution to the inverse problem.<br\/><br\/>The primary aim of this work is to develop an efficient and practical inverse algorithm based on a hierarchical spatial decomposition of the domain, integrate it with the existing forward algorithm, and disseminate it to researchers with a need to solve such problems. Cardiology and neurology are examples of two fields that can benefit from the availability of such tools. In clinical applications, these tools can prove invaluable in the diagnosis and treatment of disease. In research applications, these tools can improve our knowledge of the fundamental behavior of the system.","title":"ITR\/Comp Bio: Computational Tools for Inverse Electromagnetic Problems","awardID":"0112742","effectiveDate":"2001-09-01","expirationDate":"2006-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["290509"],"PO":["521045"]},"60726":{"abstract":"Divisions of Chemistry, Molecular and Cellular Biosciences, Chemical Transport Systems, Computer-Communications Research, and Experimental and Integrated Activities support this multidivisional award to University of Illinois Urbana-Champaign. This Nanoscale Interdisciplinary Research Team (NIRT) award is part of the Nanoscale Science and Engineering program. Under this project, an interdisciplinary team with Joseph Lyding as the principal investigator will develop protein-based logic chips that interfaces between biochemical reactions and conventional microfabricated silicon-based electronics such as metal-oxide semiconductor (MOSFETs) taking advantage of biocomplexity and electronic speed. These protein interfaced MOSFETs will help to create atomically accurate protein arrays to function as cellular nonlinear\/neural network, and this in turn will help to over come the 100 nm limit in miniaturization of the present transistor technology. Industrial collaborations and outreach programs in the K-12 system will be part of the project. <br\/><br\/>Under the award, ordered and atomically accurate protein arrays that interfaces between biochemical reactions and conventional microfabricated silicon-based electronics will be developed. Strong industrial collaboration will help in the industrial development and technology transfer of this science. In addition, the research program will provide multidisciplinary education and training opportunities in materials chemistry, protein chemistry and electronics to students from K-12 to post doctoral candidates.","title":"Protein Logic","awardID":"0103447","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1674","name":"NANOSCALE: INTRDISCPL RESRCH T"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1708","name":"QuBIC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"1415","name":"PARTICULATE &MULTIPHASE PROCES"}}],"PIcoPI":["544556","162978","243624","366168","535303"],"PO":["543629"]},"60507":{"abstract":"EIA-0102280<br\/>Dey, Tamal K.<br\/>Ohio State University<br\/><br\/>CISE Postdoctoral Associates in Experimental Computer Science: Sampling Based Geometric Modeling<br\/><br\/>Many application domains ranging from engineering to medicine require the computer modeling of physical objects. Laser range scanners and other modern scanning devices are capable of sampling large numbers of points on the surface of a physical object. Computing a model of an object, often referred to as surface reconstruction, has received wide attention in recent years. In the proposed postdoctoral training and research project, the problem of how to perform surface reconstruction of a physical object from a set of sampled points will be further studied. Specifically, a postdoctoral associate will focus on extending the cocone algorithm to handle large, noisy, and undersampled sets of data points. The associate's research will contribute to building a software library that provides the reconstruction functionality needed to meet the widespread demands of a range of users across disciplines.","title":"Postdoctoral: Sampling Based Geometric Modeling","awardID":"0102280","effectiveDate":"2001-09-01","expirationDate":"2003-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":["549998"],"PO":["564181"]},"60749":{"abstract":"EIA-0103583<br\/>Anand Sivasubramaniam<br\/>Pennsylvania State University<br\/><br\/>NGS: Powerful Software for Power Constrained Systems<br\/><br\/>The objective of this proposal is to develop new monitoring and simulation tools for resource monitoring at runtime, and compiler assisted optimization to enable execution under energy evaluation and optimization conditions. The proposal will implement these methods into an integrated framework to evaluate optimizations at the application, compiler and operating system levels. This project will specifically focus on a spatial database application called PocketGIS, an important mobile application, to explore these issues.","title":"NGS: POWERful Software for Power Constrained Systems","awardID":"0103583","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["507752","542015","542016","549542"],"PO":["301532"]},"62938":{"abstract":"The aim of this project is to put new and cutting-edge computational applications in the hands of high school students in after-school club settings in underserved communities. These tools will allow the students to build tangible and ubiquitous computing applications that will find genuine utility in the communities that surround the schools. For the first half of the project, we will be planning with our partner schools and making connections in the adjacent communities. We will also be crafting the initial technology platforms for the students. The final phase of the project will entail high school students working jointly with researchers to build community-centered applications. New insights will be gained on how to develop toolkits for young designers and, for the young designers, how to design and evaluate computational applications. This work will also suggest new ways to engage underserved communities in building and using the nation's information infrastructure.","title":"\"ITR\/PE: Bridging the Digital Divide with Tangible and Ubiquitous Computing\"","awardID":"0112937","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["315258","552897","326088"],"PO":["495796"]},"62949":{"abstract":"The objective of this project is to capture physical properties of real world phenomenon by analyzing photographs and video. The problem of capturing motion of objects has emerged as a major research area in the fields of computer vision and computer graphics with a wide range of possible applications. This project will attempt to devise new computer vision techniques for capturing and modeling the dynamics and physical characteristics of a number of differing objects in different contexts. If successful, the new techniques will enable more accurate 3D motion estimation from a single video stream and other limited sensor data. Finally, the project will explore potentially valuable application areas for these research products.","title":"ITR\/AP(CISE): Capturing and Modeling Physics from Images","awardID":"0113007","effectiveDate":"2001-09-15","expirationDate":"2005-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["549589","533242"],"PO":["564456"]},"64709":{"abstract":"EIA-0121141<br\/>Requicha, Aristides<br\/>University of Southern California<br\/><br\/>ITR\/SI+AP: Active Sensor Networks with Applications in Marine Microorganism Monitoring<br\/><br\/><br\/><br\/><br\/><br\/>The proposed research combines networking, distributed robotics, nanorobotics, and microbiology in an effort to develop and apply technology for the in-situ, real-time monitoring of microbial populations in aquatic environments, such as the ocean or water supply systems. The application context provides feedback from experiments with realistic systems, and this feedback is essential to the progress of the Information Technology (IT) research proposed here. This project addresses two key challenges for IT during this decade: moving from virtual to physical applications, and moving from macro to micro and nano.<br\/><br\/>The IT focus is on the study of Physically-Coupled Scalable Information Infrastructures (PCSIIs), which effectively \"embed the internet\". The sensors and actuators in the proposed PCSII must have small physical dimensions, comparable to those of the microorganisms to be monitored. They must be deployed in very large numbers to achieve the unprecedented spatial and temporal resolution necessary to investigate the causal relationships between environmental conditions and microorganisms. Control and coordination of a multitude of such devices of limited and heterogeneous capabilities raise major challenges for networking, distributed coordination and distributed algorithms. Sensing for detection and identification of microorganisms is another challenge, which will be tackled by using nanorobotic Scanning Probe Microscope technology.","title":"ITR\/SI+AP: Active Sensor Networks with Applications in Marine Microorganism Monitoring","awardID":"0121141","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"1360","name":"HUMAN RESOURCES DEVELOPMENT"}}],"PIcoPI":["187175","495864","560926","558935","560335"],"PO":["565223"]},"80615":{"abstract":"","title":"On Providing Quality-of-Service Control for Core-Based Multicast Routing","awardID":"0296206","effectiveDate":"2001-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["342042"],"PO":["234222"]},"80549":{"abstract":"","title":"CAREER: Commonality in Multiagent Systems: Protocols and Languages","awardID":"0296140","effectiveDate":"2001-09-01","expirationDate":"2003-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["338092"],"PO":["565227"]},"62905":{"abstract":"The goal of this project is to develop an interactive geometric approach to creating, editing, transforming, and computing with models of spatially distributed physical phenomena. The funded effort will involve fleshing out sound theoretical foundations, developing appropriate data structures and algorithms, as well as implementing a prototype system for interactive physical modeling. At the heart of the proposal is a novel use of tools from algebraic topology and geometric algebra to describe, classify, and unify physical phenomena. The prototype system will allow users to create models of physical phenomena through an interactive geometric interface designed in terms of familiar and intuitive control elements. The created models may be interactively transformed, modified, combined, visualized, and instantiated. <br\/><br\/>The successful outcome of the proposed research should have broad technological, economic, educational, and social impact. The physics editor will allow users to create, visualize, test, and experiment with new models of physical phenomena quickly and effortlessly. It could greatly enhance the ability to efficiently create and modify scientific software that is modular, reusable, and consistent across the disciplinary boundaries. Engineers may discover a practical tool that will allow them to communicate with computer-aided design systems in a visual intuitive language that does not require deep mathematical knowledge and unifies a multitude of theories and special cases. And perhaps most importantly, the proposed research could open doors of computational sciences to college and high school students and others who may have been discouraged or intimidated by traditional methods of mathematical physics and scientific computing.","title":"ITR\/AP: Interactive Spatial Physics: Computational Foundations and Systems","awardID":"0112758","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["560677"],"PO":["381214"]},"63819":{"abstract":"EIA-0116573<br\/>Alexander A. Sawchuk<br\/>University of Southern California<br\/><br\/>MRI: Acquisition of Equipment for Remote Multichannel Media Immersion<br\/><br\/>This is a proposal for equipment acquisition under the Major Research Instrumentation (MRI) program to support research and student training in immersive technology. Immersive technology is the creation of the aural and visual ambience of a virtual space in which individuals can experience remote events or communicate naturally with others located remotely.","title":"MRI: Acquisition of Equipment for Remote Multichannel Media Immersion (RMMI)","awardID":"0116573","effectiveDate":"2001-09-01","expirationDate":"2004-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["293075"],"PO":["241298"]},"61905":{"abstract":"Abstract<br\/><br\/>Acevedo<br\/>0108563<br\/><br\/>Detailed ecological data have been used to develop computer models of forest stands that have been applied to solve resource management issues. Increasingly, however, there is a need to answer questions that are relevant for larger areas, for example the impact of changing land use and of removing forest cover on habitat and water quality. This project will contribute to the methodology for scaling forest simulators into models of vegetation cover change in order to help answer those broad scale questions. Specifically, Dr. Acevedo and colleagues will develop methods to calculate the uncertainty associated with translating the model to larger areas, to scale the effect of neighboring vegetation patches, and to determine general mathematical functions of how those changes vary across a large landscape. The investigators will engage students in research as well as international collaboration with a team that is interdisciplinary and includes modelers, a mathematician, a computer scientist","title":"QEIB: Uncertainty Analysis, Spatial Interaction and Response Functions in Scaling-up Models of Forest Ecosystems","awardID":"0108563","effectiveDate":"2001-09-15","expirationDate":"2006-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"1181","name":"ECOSYSTEM STUDIES"}}],"PIcoPI":[159102,"547799","448584"],"PO":["269559"]},"62929":{"abstract":"The U.S. medical system faces an impending crisis: how to provide for the medical needs of a rapidly aging population. This project will investigate new technologies for \"just-in-time\" preventative health education in the home. Prior work on using computer telephony to deliver health education and counseling to people in their homes will be extended to mobile computing devices. Algorithms will be investigated that passively and actively collect data from healthy users of mobile computing devices and use that data to identify patterns of everyday activity using probabilistic models. The activity of each person will be used to present preventative health information and counseling at \"teachable moments\" -- the times when that information is most likely to impact the user's health-related decision making. A prototype system for elderly individuals interested in improving their exercise level and diet will be collaboratively developed by technologists and medical professionals. A participatory design process will be used to ensure the devices are easy to use, even for those who are not computer literate. The prototype system will be evaluated in a small focus group study.","title":"ITR\/PE: Using context-recognition for preventative medicine in the home","awardID":"0112900","effectiveDate":"2001-09-15","expirationDate":"2004-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["335579",161576,"487172",161578],"PO":["495796"]},"60806":{"abstract":"EIA-0103756<br\/>Vikram S. Adve<br\/>University of Illinois-Urbana<br\/><br\/>The goal of this project is to develop the tools needed for performance-directed integrated design and control of complex applications running on distributed computational systems. Its target computational systems are complex, incorporating the difficult heterogeneity, latency, and adaptive properties of computational grids. Its target applications are at the cutting edge of computational science: very large, complex applications with adaptive characteristics that do not allow their optimal system configurations or computational requirements to be estimated prior to run time. Each application will be viewed as a composition of components, with a formal, high fidelity model of performance to be designed for each component. The approach is to use model-based adaptive run-time control, based on these composed performance models, to control the execution of the application to meet specified performance goals. The control strategy will make real-time changes to parameters that modify the behavior of both application and computational platform.","title":"NGS: Collaborative Research: Performance Driven Adaptive Software Design and Control","awardID":"0103756","effectiveDate":"2001-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["542046"],"PO":["301532"]},"62919":{"abstract":"PROPOSAL NO.: 0112849<br\/>PRINCIPAL INVESTIGATOR: Arge, Lars<br\/>INSTITUTION NAME: Duke University<br\/>TITLE: ITR\/SY(CISE): Cache-Oblivious Data Structures<br\/><br\/>As the memory system in modern computers grows more complex, it is becoming increasingly important to design algorithms that are sensitive to the structure of the memory. One of the essential features of modern memory systems is that they are made up of a hierarchy of several levels of cache, main memory, and disk. While traditional theoretical memory models have assumed a \"flat\" memory with uniform access time, the access times of different levels of memory can vary by several orders of magnitude in current machines. For example, level-one cache is often around 100 times faster than main memory, while main memory is around<br\/>1,000,000 times faster than disks. In order to amortize the large access time of memory levels far away from the processor, memory systems often transfer data between memory levels in large blocks. Thus it is becoming increasingly important to obtain high data locality in memory access patterns.<br\/><br\/>This project will focus on the challenging problems encountered when trying to maintain data locality in irregular and dynamic problems, where by definition the data flow is continually changing and unpredictable, making it difficult to organize data locality a priori. In particular, cache-oblivious dynamic data structures will be developed-such data structures can in turn be used to develop cache-efficient algorithms. Only very recently was the first (and only) such dynamic cache-oblivious data structure developed. This structure is a cache-oblivious<br\/>version of a search tree. The ambitious goal of this project is to develop cache-oblivious structures for other fundamental problems. In the process general techniques for designing cache-oblivious data structures will be developed. Data structures with applications in a variety of application areas will be considered, but there will be a particular focus on geometric structures. Such structures often have important applications in e.g. spatial databases and geographic information systems (GIS). The project is high-risk because almost nothing is known about dynamic cache-oblivious data structures, but it has the potential to revolutionize the area of<br\/>cache- and I\/O-efficient computation and to make a tremendous practical impact. Ultimately this research could lead to a standard library of cache-oblivious data structures. Such platform-independent data structures would enable programmers to easily develop a wide variety of applications that obtain high performance on all modern memory hierarchies.","title":"ITR\/SY(CISE): Cache-Oblivious Data Structures","awardID":"0112849","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["172543"],"PO":["499399"]},"56080":{"abstract":"Considerable work has been done in devising mechanisms for providing service guarantees within a network. These schemes can be broadly classified into two categories, schemes that require maintaining state for each flow and schemes that do not require maintaining state for each flow withing the network. Integrated services architecture and differentiated services architecture and differentiated services architecture are prime examples of such approaches. Both the approaches have their advantages and proponents. This proposal aims to investigate approaches that fall in between two extremes, where a network switch may be able to maintain state for a fixed number of flows (possibly less than the number of flows it serves). This proposal looks at the services that can be provided by a limited amount of state.<br\/> The proposal plans to pursue the general direction of investigating new approaches for providing QOS with a limited amount of state. Our initial work has identified the following guiding principles:<br\/>*The provided service needs to be flexible i.e., should be able to work with any amount of state (relative to the number of flows). <br\/>*The provided service needs to be scalable i.e., increased amount of state should improve QOS.<br\/>*The provided service needs to be additive i.e., as more network components employ it, QOS should be improved.<br\/>The proposal plans to investigate mechanisms that can provide the following QOS:<br\/>*Identify and limit the resource consumptions of non-responsive flows.<br\/>*Provide fair sharing of bandwidth.<br\/>*Provide bandwidth allocations to different flows.<br\/> As a first step, we propose to employ Sampling and Caching in addition to queue and buffer management techniques at a router to enhance the QoS. The proposed mechanism uses caching to deal with the limited amount of state and uses sampling to select flows for which individual state is maintained. Our preliminary results show that sampling and caching can be effectively used for containing non-responsive flows and fair sharing of bandwidth.<br\/> The proposal plancs to study the effectiveness and feasibility of employing partial state in currently defined architectures such as IntServ and DiffServ. The proposal also plans to study if partial state can be used to provide delay and jitter service.<br\/> Besides studying mechanisms, the proposal also plans to do both trace-driven and statistical analysis of usefulness of partial state. Available network traces will be used to study the impact of state on the amount of work to be done at a network element and the QOS impact of such mechanisms. We also plan to analyze partial state with well understood models of network traffic to see if we can make qualitative conclusions about the impact of partial state.","title":"'QOS Enhancement with Partial State'","awardID":"0087372","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["550709"],"PO":["565090"]},"60809":{"abstract":"EIA: 0103764<br\/>Rajive Bagrodia<br\/>University of California-Los Angeles<br\/><br\/>The goal of this project is to develop the tools needed for performance-directed integrated design and control of complex applications running on distributed computational systems. Its target computational systems are complex, incorporating the difficult heterogeneity, latency, and adaptive properties of computational grids. Its target applications are at the cutting edge of computational science: very large, complex applications with adaptive characteristics that do not allow their optimal system configurations or computational requirements to be estimated prior to run time. Each application will be viewed as a composition of components, with a formal, high fidelity model of performance to be designed for each component. The approach is to use model-based adaptive run-time control, based on these composed performance models, to control the execution of the application to meet specified performance goals. The control strategy will make real-time changes to parameters that modify the behavior of both application and computational platform.","title":"NGS: Collaborative Research: Performance Driven Adaptive Software Design and Control","awardID":"0103764","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["231158"],"PO":["301532"]},"59271":{"abstract":"The increased chip complexity causes that average interconnect lengths increase and proportionally<br\/>larger and larger fraction of chip's area is occupied by interconnects. This proposal addresses several is-sues<br\/>related to interconnects in submicron technologies.<br\/><br\/>We will concentrate on simultaneous switching cross-talk noise effects in RC interconnects. Our goal<br\/>here is to develop efficient, easy to compute and accurate bounds on delay in the presence of crosstalk and<br\/>to characterize and prevent propagating crosstalk signals. Besides correcting the crosstalk caused prob-lems<br\/>we will also develop methodologies of circuit optimization in the presence of crosstalk. We will develop<br\/>gate sizing tool, buffer insertion, spacing and net reordering which will consider both cross-talk and delay.<br\/>At the same time we will explore regularity at the Boolean level to achieve layouts with mostly local<br\/>interconnects. The ultimate goal is to develop logic synthesis methodology which would produce highly reg-ular layout structures without large area penalty. We propose to continue our work on wave steered design methodology and we will develop tools for logic synthesis and physical design of such circuits.","title":"Performance Driven Layout and Logic Synthesis","awardID":"0098069","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["550832"],"PO":["562984"]},"59095":{"abstract":"With the increasing amount and complexity of today's data, there is an urgent need to accelerate the development of knowledge discovery and concept learning methods for mining large databases. Furthermore, much of this data is structural in nature, or is composed of entities and relationships between those entities. Hence, there exists a need to develop scalable methods for discovering new knowledge in structural databases. The main objective of this project is to investigate and implement new methods for performing knowledge discovery and concept learning on structural databases represented as graphs. This work builds upon existing methods for graph-based knowledge discovery implemented in the Subdue structural discovery system. The graph-based discovery algorithm is extended to perform structural concept learning and structural, hierarchical conceptual clustering. To achieve greater scalability, database management techniques are integrated into the graph-based discovery and learning processes. One targeted application is the use of Subdue as the core of a structural Web seach engine. Domain experts provide guidance and feedback on applications to molecular biology, geology, telecommunications, and software engineering. Achievement of the above objectives impacts the ability to automatically extract useful knowledge from the ever-increasing amount of data. By disseminating the Subdue discovery algorithm, databases, and discovered results over the Internet, scientists in all areas benefit from similar analyses of their own databases. Through integration of our research ideas into classes taught at UTA and into student research, this project impacts education at UTA and at other universities.","title":"Graph-Based Data Mining","awardID":"0097517","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["553596","547675","550149"],"PO":["563751"]},"59481":{"abstract":"Abstract:<br\/><br\/>0098643<br\/><br\/>Collaboration-Oriented Aspects<br\/><br\/>PI: Karl Lieberherr<br\/>co-PI: David Lorenz<br\/><br\/>The goal of AOP (Aspect-Oriented Programming) is to turn a tangled and scattered implementation of a crosscutting concern into an aspect, i.e. a well-modularized <br\/>implementation of the concern. The goal of the proposed research is to design and implement a collaboration-based language for aspect-oriented programming that supports reusable aspects. The potential impact of the proposed research is to improve the development and maintenance of complex software. <br\/><br\/>The design and implementation of the new language will be evaluated in two diverse domains: telecommunication applications in collaboration with BBN and banking applications in collaborations with UBS. The success of the project will be measured based on the ease of evolution of the applications that will be built<br\/>with our language. It is expected that the tangling control offered by AOP<br\/>and the loose coupling between class graphs and path sets offered by <br\/>adaptive programming will lead to more flexible software that is easier to evolve.","title":"Collaboration-Oriented Aspects","awardID":"0098643","effectiveDate":"2001-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":[152774,"540016"],"PO":["564388"]},"59492":{"abstract":"The project addresses the issues of vision tracking, in particular the consecutive use of hypotheses generated by tracking methods to yield better results in tracking. The proposed approach is likely to be expendable to various tasks, such as finding clothed people in images. Overall the approach promises a powerful technique for building an accurate self-initializing tracker.","title":"Finding and Tracking People from the Bottom Up","awardID":"0098682","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["457204"],"PO":["317663"]},"59294":{"abstract":"In order to maintain the spectacular rates of growth in the semiconductor industry over the past three decades, it will be necessary in the future to move away from the most traditional ways of building VLSI circuits. This research will explore problems in this domain. The main thrust of the research is related to providing design automation support for circuits using silicon on insulator (SOI) technology, although some aspects of the work will have applicability to the widely used bulk CMOS technology. This research will develop SOI-specific synthesis techniques, as well as optimization techniques that enable the designer to exploit technologies such as dual threshold voltages. Issues related to related to physical design will also be considered.","title":"Design Automation Techniques for SOI and High-Performance Bulk CMOS Designs","awardID":"0098117","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["508418"],"PO":["562984"]},"66291":{"abstract":"EIA-0127857<br\/>Mary K. Vernon<br\/>University of Wisconsin<br\/><br\/>The goal of this project is to develop the tools needed for performance-directed integrated design and control of complex applications running on distributed computational systems. Its target computational systems are complex, incorporating the difficult heterogeneity, latency, and adaptive properties of computational grids. Its target applications are at the cutting edge of computational science: very large, complex applications with adaptive characteristics that do not allow their optimal system configurations or computational requirements to be estimated prior to run time. Each application will be viewed as a composition of components, with a formal, high fidelity model of performance to be designed for each component. The approach is to use model-based adaptive run-time control, based on these composed performance models, to control the execution of the application to meet specified performance goals. The control strategy will make real-time changes to parameters that modify the behavior of both application and computational platform.","title":"Collaborative Research: Performance-Driven Adaptive Software Design and Control","awardID":"0127857","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["517079","410040"],"PO":["301532"]},"58261":{"abstract":"The scalability of the Internet hinges on our ability to tame the unpredictability associated with its open architecture. This project investigates the development of basic control strategies for reducing traffic burstiness and improving network utilization. Such strategies can be applied through Traffic Managers (TMs)-special network elements strategically placed in the Internet (e.g., in front of clients\/servers or at exchange\/peering points between administrative domains). We believe that the incorporation of such control functionalities will be key to the ability of the network infrastructure to sustain its own growth and to nurture the Quality-of-Service (QoS) needs of emerging applications.<br\/><br\/>Although there have been some recent advances in building network elements capable of wire-speed processing, there is a need for fundamental research into the basic QoS control capabilities that these TMs should implement. This set of capabilities have to be identified and implemented in a programmable, scalable architecture that allows for the easy and effective composition of services. Such a flexible architecture is highly desirable as the Internet continues to evolve and users demand new kinds of service for their applications. <br\/><br\/>TMs should be capable of quickly inspecting and classifying packets as they go by (e.g., marking packets into precedence classes), and should control the transmission of these packets (e.g., through pacing, scheduling, or selective dropping) to ensure desirable properties (e.g., satisfaction of jitter requirements, compliance with TCP friendliness, or improved fairness across flows).<br\/><br\/>In this proposal, we will address the design of dynamic dos control programmable TMs. We focus on basic capabilities that could be employed at different levels of the control architecture. These capabilities include differentiated, aggregate and proxy controls. The following are examples of how such control strategies would be employed by TMs.<br\/><br\/>Differentiated Control enables TMs to route flow aggregates with divergent characteristics on separate communication paths. Unlike traditional routing, our routing metrics will respect bursitis measures, such as self-similarity and traffic correlation:<br\/><br\/>Aggregate Control enables TMs to use congestion control mechanisms for collections of flows that share the same bottleneck. Unlike traditional congestion control, \"Congestion-equivalent\" flows are identified based on measures of relationship (such as cross-correlation and cross-covariance) and managed as a set; <br\/><br\/>Proxy Control enables TMs to filter out variability (e.g., loss, delay jitter) at shorter time-scales. Such a functionality is crucial for improving the stability and effectiveness of control mechanisms that operate over longer time-scales (e.g., end-to-end). Unlike traditional a-hoc proxy approaches, our approach will take into account the length and characteristics of the control loops that get formed between the TM and the end-systems.<br\/><br\/>Our design will be based on mathematical foundations from control theory and wavelet analysis. These methods enable thorough analysis and control of system dynamics at different time-scales and an understanding of the complex interactions among them. Specifically, functionality's at different levels of a TM architecture will be developed based integrated control-theoretic models. These models will account for \"nested\" control loops that are driven by system characteristics, which are identified using wavelet analysis of passive measurements. TMs that are designed in such and integrated fashion, could increase flow throughput, reduce flow jitter and response time, and improve the stability, utilization, and scalability of the network.<br\/><br\/>We plan to implement our dos controls in a tested deployed in a controlled local setting as well as over the Internet. Our implementations will be based on emerging technologies, such as Diffserv and MPLS, and will be stressed by bandwidth-and QoS-demanding applications. Our testbed will provide a programming interface to softservices, in which capabilities can be turned on or off and control parameters can be dynamically adjusted. To this end, we have secured the support of industrial research laboratories and start-up companies-namely Lucent's Bell Labs, Cisco Systems, Nortel Networks, and Quarry Technologies. Specifically, we intend to use Lucent's Network Element for Programmable Packet Injection (NEPPI). NEPPI provides an ideal foundation upon which to implement the control policies we propose to develop. This project is a collaborative efforts between Boston University (Is: Ibrahim Matta, Azer Bestavros, and Mark Crovella) with expertize in characterization, measurements and control of Internet traffic, and University of Arizona (PI: Marwan Krunz) with expertize in traffic modeling, multimedia and wireless QoS.","title":"Collaborative Research: A Control Theoretic Approach to the Design of Internet Traffic Managers","awardID":"0095626","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["540507"],"PO":["292741"]},"59251":{"abstract":"Approximation algorithms are efficient algorithms for combinatorial<br\/>optimization problems that deliver solutions which are guaranteed to<br\/>be within a certain factor of the optimum. This area of theoretical<br\/>computer science has seen a tremendous growth in the last decade for<br\/>various reasons. First, several important techniques for designing<br\/>such approximation algorithms have been discovered, including the use<br\/>of convex optimization techniques and more specifically semidefinite<br\/>programming. Also, major advances in complexity theory have lead to<br\/>strong non-approximability results, sometimes even showing that for<br\/>certain problems trivial approximation algorithms give the best<br\/>guarantee one could hope for (unless P=NP).<br\/><br\/>In this project, which is a continuation of the PI prior CAREER award,<br\/>the emphasis is both on the design of general techniques for deriving<br\/>approximation algorithms and also on obtaining improved approximation<br\/>algorithms for several classical hard optimization problems. The<br\/>problems to be considered include routing problems, the traveling<br\/>salesman problem, the Steiner tree problem, the sparsest cut problem,<br\/>and scheduling problems.","title":"Design of Improved Approximation Algorithms for Combinatorial Optimization Problems","awardID":"0098018","effectiveDate":"2001-09-01","expirationDate":"2005-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["485468"],"PO":["279077"]},"64080":{"abstract":"Although Internet traffic is routinely quite heavy, there has usually been more than enough storage,<br\/>processing and bandwidth capacity to provide acceptable performance. However, it is well known that, more<br\/>and more frequently, demands for network resources are mushrooming locally into hotspots or data storms,<br\/>and in such cases the affected web sites and subnetworks founder almost completely, creating revenue<br\/>losses and client dissatisfaction on a large scale. We propose a novel collaborative technology to alleviate<br\/>the effects of these hotspots, a technology that we will apply by designing and prototyping a Hotspot Rescue<br\/>Service (HRS). This work will build on the past research of the PI's in networking, operating systems, and<br\/>distributed caching.<br\/> A key premise on which the technology is founded lies in the observation that existing Internet band-width<br\/>resources are sufficient to deal effectively with hotspots. In other words, rescues of heavily-overloaded<br\/>sites can be assembled from underutilized resources lying elsewhere. It follows that there is no inherent need<br\/>for resources held in reserve uniquely for this purpose, i.e., there is no need for over-provisioned, under-utilized resources such as distributed caches to protect against hotspots. We propose instead a paradigm shift in which efficient mechanisms that we provide will enable communities of participating sites to share their resources to suppress hotspots. The service in action will be transparent, in part self-regulating and will take the form of automated traffic redirection to sites with available bandwidth.<br\/> The proposed Columbia HRS will be proactive as well as reactive. We will amass hotspot data that<br\/>will be modeled and analyzed with the aim of designing hotspot daemons or plugins, software devices for<br\/>monitoring traffic behavior and signalling incipient hotspots via hotspot watches and advisories, along with<br\/>relevant statistics. We will implement two complementary approaches to the technology, a server-based<br\/>approach and a client-based, peer-to-peer (P2P) approach.<br\/> In the server-based approach, servers monitor their own loads, the loads of a small set of servers that<br\/>they would service in the event that the other server overloads, and, via probes between servers, network<br\/>conditions. When a server or network component is identified as going into possible overload, the system<br\/>activates a replication mechanism to duplicate the hot content. Clients can then retrieve the content from<br\/>the server sites acting as replicas, alleviating the load on the original overloaded resource.<br\/> In the P2P approach, clients install a plugin into their browser that communicates with similar plugins<br\/>installed on other clients' browsers, as well as with a distributed directory service. Clients cache their recent downloads, and, through the plugin, inform the directory service of the objects that are cached. The directory service can then identify the most popular content, as well as cached locations and notify additional clients of these alternative locations for download. By using client machines to store and deliver the hot content and if requests for the given content can be redirected to the client machines, the hotspot at the server can be eliminated. In this way, hotspot response becomes self-organizing and self-regulatory.<br\/> There are several issues that need to be addressed as we develop this rescue service. First, we will use<br\/>experimentation and analysis of collected data (including data sets obtained via a company partnerships)<br\/>to develop models of causes and effects of network hotspot activity. Next, we will analytically evaluate<br\/>the effect on server and network load that techniques such as caching, redirecting, and migrating have<br\/>upon hotspots within the network. Last, we will implement and evaluate prototype systems to validate<br\/>their effectiveness, either upon simulated hotspot activity within a testbed, or if possible, on actual hotspots<br\/>through agreements with content providers.<br\/> Development of the HRS will provide research opportunities to multiple students at Columbia, and<br\/>its deployment will improve web performance of objects served from academic institutions and non-profit<br\/>companies whose content is to date not hosted by commerical third-party content delivery companies.","title":"The Columbia Hot Spot Rescue Service","awardID":"0117738","effectiveDate":"2001-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["451494","493395","508477","522280"],"PO":["7594"]},"56051":{"abstract":"Broadband satellite systems have an important role to play in the delivery of multimedia applications.<br\/>In this proposal we concentrate on GEO (geo-synchronous) based satellite networks. GEO based systems<br\/>deliver continuous services to a specific region with a single satellite. They play an ever-increasing role in<br\/>the public and private Internets, due mostly to their large geographic coverage, inherent broadcast<br\/>capabilities and fast deployment. They are attractive to support data, audio and video streaming; bulk data<br\/>transfer such as software updates or dissemination of Web caches; and applications involving limited<br\/>interactivity such as distance learning. They are also attractive to provide broadband access to users who are<br\/>either beyond the reach of the terrestrial network, or have particular needs for broadcast\/multicast<br\/>applications or fast deployment.<br\/> We will focus in this proposal on Next Generation Satellite Networks that comprise one (or more) GEO<br\/>satellite with some form of onboard processing (OBP). Two of the essential issues regarding broadband<br\/>satellite network are 1) end-to-end resource management, and 2) network availability.<br\/> Resource management is key to deliver acceptable Quality of Service (QoS) to services while providing<br\/>adequate efficiency. It is central to any satellite system, be it a bent pipe or an onboard processing (OBP)<br\/>satellite system. Indeed, in order to offer flexibility and efficiency to bursty applications, the capacity of the<br\/>multiple access uplink has to be managed using some bandwidth on demand (BoD) scheme.<br\/> We define network availability as the ability for the network to offer some level of services to some<br\/>applications even during degraded periods. Most of the next generation systems will be using the Ka band,<br\/>which is known for its very difficult transmission characteristics. Many solutions involving variable rate<br\/>coding, power control, and\/or variable modulation have been proposed to make this band friendly to<br\/>broadband applications. This proposal will not study directly those layer 1\/2 mechanisms but rather study<br\/>how their use affects BoD and more generally end-to-end resource management.<br\/> Hence the final objective of our proposal is to design and evaluate end-to-end resource management<br\/>for the Next Generation of Satellite Networks that interworks efficiently with the range of solutions<br\/>proposed by the air-interface designer to improve the availability of the transmission. In particular, we<br\/>want to understand the trade-off in terms of efficiency and system complexity.<br\/> To achieve this ultimate objective, we will study:<br\/>1. Static end-to-end resource management for large GEO OBP systems. The term static refers to the<br\/>fact that the coding and modulation are fixed. The focus here will be to develop and evaluate<br\/>mechanisms that are scalable, robust, flexible and protect the OBP (i.e., the switch in the sky). We<br\/>will build upon our extensive previous work in the domain where we developed scalable, robust,<br\/>flexible end-to-end resource management for large GEO bent pipe systems.<br\/>2. Network availability. One of the main concerns of satellite network designers is to offer an<br\/>\"appropriate\" level of service to the users in spite of the difficult characteristics of the frequency<br\/>band. However it is not very clear what is meant by \"an appropriate level of service\" since it may<br\/>vary from a user to another or from an application to another. Most of the studies have focussed on<br\/>link availability without taking into account the networking and applications aspects. We believe<br\/>that coordinating the lower layers with the upper layers will give us a flexible and cost-efficient<br\/>solution allowing the system to deliver different levels of network availability to the users<br\/>depending on their need and their willingness to pay. Hence network availability can be seen as a<br\/>QoS requirement and should be defined and studied that way.<br\/>3. Designing end-to-end resource management for a system comprising layer 1\/2 mechanisms to<br\/>dynamically improve the uplink availability so as to offer flexible and cost efficient services to the<br\/>users. We need to propose solutions and to evaluate them to ensure that the increase in complexity<br\/>is worthwhile in terms of efficiency. We will also propose and study some dynamic pricing schemes<br\/>integrated with the BoD so as to allow the users to indicate their willingness to pay for capacity in a<br\/>context where the total available capacity is variable due to link impairment.","title":"Resource Management for Broadband Satellite Networks","awardID":"0087266","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["231101"],"PO":["565090"]},"59351":{"abstract":"This research proposes a new generation of Field Programmable Gate Arrays (FPGAs) based upon a self-timed design methodology known as Phased Logic. One of the principle attractions of FPGAs is that they<br\/>give users a streamlined methodology for implementing large gate-count digital designs that are specified in a Hardware Description Language (HDL) such as Verilog. FPGAs shield designers from the time-consuming<br\/>physical design details that Application Specific Integrated Circuit (ASICs) designers must face and offer a flexible implementation substrate with a quicker time to market. However, design complexity is increasing significantly for both FPGA designers and users due to timing issues related to global clock distribution over larger arrays operating at higher frequencies. Spending more design effort on reaching timing closure can increase time to market and threatens to undermine one of the key benefits of FPGAs for its users.<br\/><br\/>Phased Logic (PL) is a self-timed, delay-insensitive methodology that allows automatic mapping of clocked netlists to netlists of PL gates. Preliminary work has indicated that PL gates based upon a four input<br\/>LookUp-Table (LUT4) can implement designs that are competitive with clocked approaches in both power and performance. This research investigates new FPGA architectures using both LUT4-based gates and<br\/>traditional product-term-based gates. PL offers a general capability for data dependent computing; synthesis techniques that take advantage of this for general logic are investigated. Extensions for supporting these new architectures and PL gate designs are made to the current mapping tool that transforms clocked designs to PL designs. Tradeoffs that sacrifice some delay insensitivity for extra performance are studied.","title":"Self-Timed FPGA Systems","awardID":"0098272","effectiveDate":"2001-09-01","expirationDate":"2004-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["393581","425804","485742"],"PO":["562984"]},"59274":{"abstract":"James Aspnes<br\/>\"Fault-Tolerant Distributed Resource Location\"<br\/><br\/>Resource location is a fundamental problem in distributed computing.<br\/>Examples include such basic tasks as translating URLs into machine<br\/>addresses, mapping telephone numbers to individual telephones, and<br\/>searching for documents on the Web. Typical current solutions involve<br\/>maintaining centralized directories that become bottlenecks that<br\/>impair speed and reliability; such solutions are also unsuited to<br\/>peer-to-peer systems where individual machines come and go freely. The<br\/>research examines how to distribute directory information<br\/>holographically throughout the network, so that the costs of searches<br\/>are spread evenly, no specialized server machines are needed, and<br\/>resources can still be found even if a large fraction of the machines<br\/>leave the system.<br\/><br\/>The main technique is the construction of random graphs whose nodes<br\/>(representing resources and machines) are assigned coordinates in some<br\/>space based on their keys. Searching for a resource involves moving a<br\/>token from some initial node to adjacent nodes closer to the target<br\/>until the target is reached. Core components of the project are the<br\/>design of graph structures that provide the correct mix of<br\/>short-distance and long-distance edges for fast searching and the<br\/>design of local mechanisms for building and repairing such structures<br\/>quickly without central coordination.","title":"Fault-Tolerant Distributed Resource Location","awardID":"0098078","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["409429"],"PO":["543507"]},"59054":{"abstract":"The goal of this interdisciplinary research is to analyze the vast amounts of MEMS sensor data using datamining techniques to discover relationships among actions at MEMS actuators and their impact on the system state. These relationships (captured in the form of rules) are then used to build a feedback loop for aircraft control. The input-output relationships for most systems (e.g., the delta wing aircraft) are highly non-linear. Traditional datamining approaches discard much important information from the datasets and cannot provide sufficient transfer function information, which makes them unsuitable for system control. This project develops a scalable multivariate datamining technique that discovers full sensor-actuator relationships and predictive models under a wide range of conditions (dynamic, temporal, spatial, etc.). The research includes collecting data for dynamic system behavior, extending the datamining algorithms for summarizing temporal rules, developing the rule selection strategy for actuation schema, and developing wind tunnel experiments to validate the approach. This work has the potential to advance the state-of-the-art in data mining substantially, as this problem has many features (real time feedback, spatio-temporal nature) that are not commonly found in other applications. The success of data mining techniques is expected to advance the MEMS sensor and actuation technology in system monitoring and control and in other engineering problems.","title":"Control of Systems with MEMS Sensors and Actuators via Data Mining Techniques","awardID":"0097438","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1639","name":"SENSORS AND SENSING SYSTEMS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0709","name":"Division of BIOENGINEERING & ENVIRON SYSTE","abbr":"BES"},"pgm":{"id":"1443","name":"FLUID DYNAMICS"}}],"PIcoPI":["218209","455101"],"PO":["563751"]},"66380":{"abstract":"An application running in a distributed computing environment such as the Computational Grid must adapt to the available hardware and software resources. This requires information about the properties of Grid resources such as hosts, network switches, links and paths, software libraries and systems, user and organization rights, software services, event channels and dictionaries, and more. The information needed for an application to run, the values of the information (how fast the information changes) and the freshness of the information (how fast updates must be pushed to the application) can vary dramatically. These attributes place significant demands on the resource information service, demands that are arising with increasing prevalence in the general area of directory services as well. The Grid Forum, an international standards body for world-wide Grid computing, is developing standards for representing and querying this information. There is much that is excellent about these evolving standards, but there are many forms of highly desirable queries that will be difficult or expensive to perform in these systems. In particular, dynamic information will require very high update rates not supported by LDAP-based implementations.<br\/><br\/>This project will address these concerns through a proposed (and tentatively named) Grid Resource Information Service (GRIS), a unified relational approach to grid information services. The research will start with the full ACID (Atomicity\/Consistency\/Isolation\/Durability) functionality of a relational database system and \"build down\" to a practical resource information system that still provides most of the benefits of the RDBMS. Such a system will provide a single highly flexible query model and language for all types of Grid resource information, no matter how dynamic. The research will culminate in an extensible implementation based on commodity database systems and the SQL language, including \"canned queries\" for non-SQL users. The project will evaluate the new system and techniques using logged updates and queries from an existing Grid information service, and comparing results with a hierarchical system such as Globus MDS2. To facilitate comparisons, the project will produce a set of benchmark queries from discussions with users, tool developers, and Grid Forum members, and will quantify the limits of these queries.","title":"ITR\/SY Collaborative Research: A Unified Relational Approach to Grid Information Services","awardID":"0128390","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["565242"],"PO":["565272"]},"67052":{"abstract":"EIA-0131691<br\/>Flikkema, Paul <br\/>Northern Arizona University<br\/><br\/>BDEI: Reconfigurable Wireless Sensor Networks for Dense Spatio-Temporal Environmental Monitoring<br\/><br\/>Summary<br\/><br\/>Improving understanding of ecosystem processes requires the acquisition of multi-component<br\/>environmental time series at high spatial resolution. Current environmental sensing systems typically rely on stand alone data loggers or wired sensor arrays. Research and resource management that depend on such<br\/>systems are currently limited by initial cost and\/or the effort required to acquire the data. The nexus of this project is to integrate cutting-edge, low-cost circuit and system technology into a wireless environmental sensing network based on an evolvable architecture that will meet an immediate and critical need: to dramatically improve coverage and spatial density while greatly reducing the total cost. This first-generation network will also serve as an experimental testbed for fundamental research in wireless sensor networking that targets the unique characteristics of environmental monitoring applications. This research includes distributed, adaptive source coding of spatio-temporally correlated vector processes, multi-hop protocols with inter-layer interaction, and coded macrodiversity for energy-constrained multi-hop networks.<br\/><br\/>Since this project brings together wireless networking and ecosystems and microclimate researchers, it also provides an opportunity to initiate the development of a new interdisciplinary program of study: Ecosystem Sciences and Informatics. This program will educate a new generation of students who can develop and use technology for ecosystem monitoring and modeling.","title":"Biodiversity and Ecosystem Informatics - BDEI - Reconfigurable Wireless Sensor Networks for Dense Spatio-Temporal Environmental Monitoring","awardID":"0131691","effectiveDate":"2001-09-15","expirationDate":"2003-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["498157","538000",173848],"PO":["371077"]},"59341":{"abstract":"Computational geometry covers a wide range of applications, such as motion planning and computer graphics, <br\/>and its contribution to their solution involves the use of sophisticated techniques drawn from many branches of mathematics and computer science. The investigators extensively study many basic and applied problems in the area, including motion planning, Voronoi diagrams, combinatorial and algebraic analysis of arrangements of curves and algebraic surfaces, graph drawing, randomized algorithms, and geometric optimization.<br\/><br\/>A major portion of this research involves the study of arrangements of curves and surfaces. The significant progress made by the PI's on these problems during the past 15 years has opened up many new challenging research directions, including:<br\/>Combinatorial and algorithmic problems related to substructures (lower envelopes, single cells, zones, levels, vertical decompositions) in arrangements of surfaces in higher dimensions. Related algorithms in real algebraic geometry for computing connected components, stratifications, the dimension and other<br\/>topological parameters of real semi-algebraic sets. Graph drawing and other algorithmic, combinatorial, and topological problems involving planar arrangements of segments or curves. Applications of these results to numerous areas, including motion planning in robotics, rendering and modeling problems in computer graphics, generalized Voronoi diagrams and geometric optimization problems, including problems in metrology and facility location. <br\/><br\/>An important feature of this research is the cross-fertilization between basic research in computational and combinatorial geometry and various application areas. Another theme is the strong connection between the combinatorial analysis of arrangements and the design of efficient algorithms for constructing and utilizing these structures. The efficiency of the algorithms often crucially depends on the size of the structure to be computed, and most of the work is devoted to bounding this quantity.","title":"Studies of Geometric Arrangements and their Algorithmic Applications","awardID":"0098246","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["381203","381204","381205"],"PO":["321058"]},"59253":{"abstract":"CCR-0098024<br\/>Empirical Validation of Information Theory-Based Software Metrics<br\/><br\/>Edward B. Allen, P.I, and Rayford B. Vaughn, co-P.I.<br\/><br\/>Empirical Validation of Information Theory-Based Software Metrics is a<br\/>research project of Mississippi State University that is empirically<br\/>validating the usefulness of a new generation of software metrics, based<br\/>on information theory.<br\/><br\/>Software engineers employ a wide variety of diagrams during development<br\/>of software. Because many abstractions of software are represented by<br\/>graphs, metrics of graph attributes have the potential for wide<br\/>application. Information theory is an alternative to counting, focusing<br\/>on the amount of information in an attribute. The contribution of this<br\/>project to the state of the art is empirical evidence that information<br\/>theory-based software metrics of size, length, complexity, coupling and<br\/>cohesion can be useful timely predictors of software quality, and that<br\/>they have advantages over counting-based metrics.<br\/><br\/>Case studies in collaboration with industrial and government software<br\/>development organizations are providing a meaningful evaluation by<br\/>examining a variety of real-world software systems large enough to be<br\/>comparable to other industry projects. Collaborators include EDS Inc.,<br\/>Ericsson Inc., and MPI Software Technology Inc. Results will be<br\/>disseminated throught the Center for Empirically Based Software<br\/>Engineering (CeBASE). The empirical evidence generated by this project<br\/>is aimed to facilitate a new level of cost-effective improvement to<br\/>software quality.","title":"Empirical Validation of Information Theory-Based Software Metrics","awardID":"0098024","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["528453","557830"],"PO":["564388"]},"59198":{"abstract":"The goal of this project is to understand and improve upon the ways in which people manage information for re-access and re-use. The project focuses on information found on the Word Wide Web and consists of three phases. In Phase 1, the current situation is assessed to determine the nature and severity of problems in managing Web information for re-use and to determine the effectiveness of supporting tools. Participants are first observed in their workplaces as they use the Web to research a work-relevant topic. In a follow-on session, participants try to return to each in a collection of web sites they have previously visited and found useful. Special attention is given to the choice of tools, their success or failure and to the overall time required to reach a site. In Phase 2, practices of re-use and supporting tools, current and potential, are modeled using Phase 1 data. In Phase 3, a select number of tools and practices of re-use are prototyped and evaluated as guided by the modeling of Phase 2. Results of this project will be improved tools and practices to help manage Web information for personal use and re-use. The project will also provide a framework for the assessment of various tools and practices, current and potential. Possible applications extend beyond the Web to other information types including email, the files of a personal computer and even the printed documents in an individual's office. The results will be disseminated through scholarly publications and through the Internet.","title":"Keeping Found Things Found On the Web: How Do Users Get Back to Relevant Web Pages?","awardID":"0097855","effectiveDate":"2001-09-01","expirationDate":"2006-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["523483","467745","376063"],"PO":["563751"]},"64291":{"abstract":"This project extends peer-to-peer communication networks to better support formation of virtual communities in wide area computer networks. Virtual communities bring together individuals with similar interests, but the difficulty of forming them and sustaining critical mass discourages communities that serve small populations or compete with existing communities. Large-scale peer-to-peer networks offer the possibility of self-organizing communities, in which nodes recognize and create relatively stable connections to other nodes with similar interests. The solution includes nodes that learn about their network neighborhoods, nodes that offer partial (and competing) directory services, new methods of routing messages efficiently in peer-to-peer networks, more accurate methods of making resource selection decisions in environments containing many resources, and a utility-theoretic model for decision-making by individual nodes that incorporate multiple task requirements (e.g., cost, accuracy, and reliability). The scientific results will be more robust and efficient peer-to-peer networks, new techniques for forming virtual communities, and a better understanding of how complex peer-to-peer networks work. A software simulator will enable CS, MIS, and Business students to study virtual communities, for example testing hypotheses about why marketplaces fail or policies that encourage community formation. The basic science can be used to build search tools that explicitly consider tens of thousands of databases, software that supports dynamic creation of virtual communities within organizational intranets in response to unforeseen developments (e.g., the DoD), and wireless networks in which devices work whenever they are in range of another device.","title":"Peer-to-Peer Networks for Self-Organizing Virtual Communities","awardID":"0118767","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":[165715,"541869",165717],"PO":["469867"]},"66370":{"abstract":"This workshop will address the new research and education challenges posed by the advent of embedded computing as a discipline. Workshop participants include embedded system experts from both academia and industry. The workshop report includes: 1) a statement of pressing research problems posed in embedded computing; 2) recommendations about important research areas relating to embedded computing; and 3) viewpoints on how the discipline of embedded computing fits in with existing computing disciplines and specialties.","title":"Workshop on Challenges in Embedded Computing","awardID":"0128345","effectiveDate":"2001-09-01","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["431683"],"PO":["187585"]},"64071":{"abstract":"Making it Easier to Interact with Technology through Handheld Personal<br\/>Universal Controllers<br\/><br\/><br\/><br\/>This is a standard award. In this project the PI will investigate how a hand-held computer exploiting wireless communications technologies can be used as a Personal Universal Controller (PUC) to control all kinds of home, office and factory equipment. When users point their PUC at a light switch, at a photocopier in an office, at a machine tool in a factory, at a VCR at home, at a piece of test equipment in the field, or at almost any other kind of device, the device will send to the hand-held a description of its control parameters. The PUC will use this information to create an appropriate control panel, taking into account the properties of the controls that are needed, the properties of the hand-held (the display type and input techniques available), and the properties of the user (what language is preferred, whether left or right handed, how big the buttons should be based on whether the user prefers using a finger or a stylus). The user can then control the device using the PUC. The device will not need to dedicate much processing power, hardware, or cost to the user interface, since it will only need to contain a description of its capabilities and storage for the current settings, along with hardware for wireless communication. PUC programs will use intelligent \"model-based\" techniques to create useful and appropriate interfaces that are customized for each user. The PI's preliminary research suggests that an interface on a hand-held can be significantly better than the interface supplied by the manufacturer, so the PUC should enable people to make more effective use of their equipment, as well as making it practical to add intelligence to a broader range of appliances. The PUC can also facilitate access for people with disabilities, since the interfaces will be customized to the individual's preferences and needs. But this research will have benefits beyond just remote control devices for appliances, in that it will help further the cause of separating the user interface from the application code, which has been a basic goal of user interface software research from the beginning.","title":"Making it Easier to Interact with Technology Through Handheld Personal Universal Controllers","awardID":"0117658","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}}],"PIcoPI":["548127"],"PO":["565227"]},"65050":{"abstract":"EIA- 0122600<br\/>Panchanathan, Sethuraman<br\/>Arizona State University<br\/><br\/>Educational Innovation: A Concentration Track in Embedded Systems<br\/><br\/>This project presents a novel structure for a concentration track in embedded systems. The new curriculum combines important aspects of content, synthesized from the latest research in academia, with industry research aspects channeled through a capstone project (implemented as internships in industry). The curriculum spans a spectrum of activities related to the design and delivery of educational and research efforts and is characterized by three main innovative components namely; a new industry-university collaborative model for integrating basic and applied research, creation and delivery of state-of-the-art course content and appropriate laboratories, delivery of a capstone project through internships. The embedded systems curriculum emphasizes fundamental issues such as the balance between hardware and software and the respective trade-offs in building embedded systems. Practical design experience is fostered through the courses, laboratory experiments, and capstone projects that expose the students to the state-of-the-art design methodologies. In addition, internships, funded by industry, expose the students to work on applied projects mentored by the industrial supervisors and faculty fellows.","title":"EI: A Concentration Track in Embedded Systems","awardID":"0122600","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}}],"PIcoPI":["171437","477210","528940","425207",168153],"PO":["551712"]},"56174":{"abstract":"Today the World Wide Web is the foundation of e-commerce (including, e-advertisement, e-banking, etc.) Unfortunately, the World Wide Web does not offer good support for anonymity (called \"privacy\" in the popular press). While in a mechanical society window shoppers do not need to identify themselves, they implicitly or explicitly do so (to a certain extend) when using the World Wide Web. \"Privacy\" concerns may limit the growth and the use of the internet.<br\/><br\/>The state of the art techniques to guarantee anonymity only provide weak security, or are too expensive to be used, or are completely impractical. Moreover, some protocols have been broken. The goals are:<br\/><br\/>1. to revisit and to (crypt) analyze existing protocols,<br\/>2. to study more efficient protocols to achieve robust anonymous communication,<br\/>3. to develop protocols to guarantee anonymity even when insiders are trying to break the anonymity, or trying to disrupt the anonymous communication,<br\/>4. to address the user-friendly aspect of cookies, without endangering the anonymity of the communication,<br\/>5. to enhance very secure (called unconditionally secure) protocols for anonymous communication,<br\/>6. to study limited anonymity.","title":"Anonymity: Securing User Privacy on the Internet","awardID":"0087641","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["218583","561926"],"PO":["565090"]},"67075":{"abstract":"EIA-0131801<br\/>Doruska, Paul <br\/>University of Arkansas<br\/><br\/>BDEI: Quantifying Forest Ground Flora Biomass and Diversity Using Close-Range Remote Sensing.<br\/><br\/>Summary<br\/><br\/><br\/>Researchers propose the use of close-range remote sensing to estimate biomass per<br\/>unit area and species diversity of forest ground flora. Ground flora biomass and diversity<br\/>information is useful when describing forested ecosystems, gauging results in scientific<br\/>experiments and determining the need for herbicide application to reduce unwanted<br\/>competition in forest crops. Scientists will use both color and color infrared digital<br\/>imagery to study forest ground flora biomass and species diversity of pine stands in<br\/>southeastern Arkansas and mixed pine-hardwood stands in the Ouachita Mountains in<br\/>central Arkansas.<br\/><br\/>Airborne and\/or space-borne imagery have been used to estimate forest overstory<br\/>biomass. However, such platforms cannot be used to estimate biomass of forest ground<br\/>flora species because (a.) spatial resolution is too coarse for the required level of detail,<br\/>and (b.) the presence of the overstory canopy can hinder use of such imagery. The<br\/>objectives of this project are to (1) determine if these metrics can be collected through<br\/>close-range remote sensing, and (2) identify spectral signatures for a number of species<br\/>of forest ground flora.","title":"Biodiversity and Ecosystem Informatics - BDEI -Quantifying Forest Ground Flora Biomass and Diversity Using Close-Range Remote Sensing","awardID":"0131801","effectiveDate":"2001-09-15","expirationDate":"2004-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}}],"PIcoPI":[173901,173902],"PO":["371077"]},"59353":{"abstract":"The basic elements of the storage industry are in the midst of radical change<br\/>with the advent of network-attached storage devices. Storage systems comprised<br\/>of network-attached drives provide many potential advantages over traditional<br\/>storage architectures, but also introduce additional challenges, particularly<br\/>regarding manageability. In this proposal, the WiND project (Wisconsin<br\/>Network Disks) is described, which has the goal of developing the software<br\/>techniques required to build a truly manageable network-attached storage<br\/>system.<br\/><br\/>The key to manageability is adaptation. In traditional systems, such<br\/>adaptation is performed by a human administrator. Future storage systems must<br\/>themselves adapt, and in doing so, reduce the need for manual<br\/>intervention. The WiND system will gracefully and efficiently adapt to changes<br\/>in the environment, reducing the burden of administration and increasing the<br\/>flexibility of storage for an eclectic range of clients. In particular, WiND<br\/>will automatically handle the addition of new heterogeneous disks to the<br\/>system, the failure of existing disks, and changes in client workload. Within<br\/>this proposal, three specific sub-areas of WiND are developed: adaptive data<br\/>layout and access with SToRM, adaptive caching via Clouds, and the underlying<br\/>information substrate.","title":"Robust Adaptive Network-Attached Storage","awardID":"0098274","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["550389","550390"],"PO":["309350"]},"59364":{"abstract":"Society is increasingly dependent on the robustness, reliability, and evolvability of software systems. Better support for software development and maintenance is essential. This research will help developers to be more productive and to create better software.<br\/><br\/>Developers use high-level linguistic structure and semantics to discuss software artifacts with one another; however, they create and modify software artifacts using low-level text editors and compiler-motivated program representations. The goal of this research is to bridge that gap - to raise the linguistic level of developer\/computer interaction. That will be done by augmenting text-based representations with multi-modal interaction, and by supporting semantic and structural search, navigation, and transformation mechanisms.<br\/><br\/>Using the Harmonia language-based framework being developed at Berkeley, the new methods will be applied initially to Java. A form of Java will be created that is more naturally verbalized by human developers. Methods will be devised to (1) translate this form to the same annotated abstract syntax representation used by conventional text-based tools, (2) resolve the ambiguities that the new form allows, (3) analyze program fragments, a necessary component of semantic search and navigation, and (4) accommodate lexical, syntactic, and semantic inconsistencies, sustaining language-based services when the artifacts are incomplete and incorrectly formed.","title":"Language Support for High Level Interaction in Software Development","awardID":"0098314","effectiveDate":"2001-09-01","expirationDate":"2004-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["495935"],"PO":["564388"]},"59265":{"abstract":"Clusters of workstations have become standard system platforms for many scientific, commercial, and educational applications. This research focuses on effective usage of global memory resources to deal with dynamic job demands in large cluster systems. The targeted workloads are data-intensive scientific applications, Internet web accesses, and data processing for commercial databases. The first objective is to develop analytical\/experimental performance models\/tools to quantitatively examine the impact of the technology changes and data-intensive workloads to resource management policies, and to provide resource management guidance. The second objective is to design several memory-centric load sharing schemes by comprehensively considering dynamic job interactions and global cluster system resources. Finally, these schemes will be implemented and tested in a large cluster system. The impact and contributions of the proposed projects will be: (1) providing insights into memory systems performance and understanding potentials of memory-centric load sharing in clusters; (2) providing effective system solutions to adapt rapid changes of technology and workloads in cluster computing; and (3) making low-cost clusters more accessible for both scientists and business users to effectively run their large and demanding applications.","title":"Memory-Centric Resource Management for Data-Intensive Workloads on Clusters","awardID":"0098055","effectiveDate":"2001-09-01","expirationDate":"2006-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["418746","551992"],"PO":["309350"]},"60090":{"abstract":"This project involves three \"working groups\" of researchers meeting at DIMACS, the Center for Discrete Mathematics and Theoretical Computer Science, to address different aspects of massive data analysis problems in different applied contexts. One group is concerned with \"streaming\" data analysis and mining. The group deals with computational and analytical methods relevant to problems that arise when decisions must be made in one, initial scan as data \"stream\" by. The results will have impact on massive data set problems arising from credit card transactions, telephone calling, financial transactions, environmental modeling, and astrophysical experiments. The second group develops and analyzes new models and algorithms for and applications of multidimensional scaling. MDS, a traditional tool of data analysis in marketing, psychology, and other social and behavioral sciences, faces new challenges from the sheer volume of data in today's databases and from a variety of new applications, and the results should be useful in a wide variety of applications in economics, management science, chemistry, and psychology. A third group brings together researchers designing computers to generate scientific conjectures. Specifically, the group deals with conjectures in graph theory and related areas of chemistry that are generated from databases of graph invariants and relations between them and of chemical structures such as of fullerenes. The results should be of wide interest to researchers in graph theory and chemistry but also to researchers dealing with automatic theorem proving and generation. The results of the three working groups will be broadly disseminated to research communities via technical reports, papers, and books in the DIMACS book series.","title":"Working Groups in Data Analysis and Mining","awardID":"0100921","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1333","name":"METHOD, MEASURE & STATS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["264120"],"PO":["563751"]},"63093":{"abstract":"NSF ITR Proposal #0113810<br\/>Compositional Connectors<br\/>David Garlan<br\/><br\/>For systems composed from independently developed parts, specialized forms of<br\/>interaction are often needed to bridge component mismatches or to achieve<br\/>extra-functional properties (e.g., security, reliability), making the design and<br\/>implementation of these interaction mechanisms a critical issue. Unfortunately,<br\/>system developers have few options: they must live with available, but often<br\/>inadequate, generic support for interaction (such as RPC), or they must<br\/>handcraft specialized mechanisms at great cost.<br\/><br\/>This research investigates a new approach whereby interaction mechanisms are<br\/>constructed compositionally. Specifically, basic connectors (such as RPC or<br\/>data streams) can be augmented with selected adaptations or enhancements to<br\/>produce a more complex connector that meets the system requirements. This<br\/>work will investigate the hypothesis that (a) there exists a collection of<br\/>general-purpose transformations that can be applied to connectors to produce<br\/>increasingly rich forms of interaction, and (b) tools can be built to automate<br\/>the application of these transformations to existing interaction mechanisms.<br\/>If successful, this research will reduce the cost of component integration by<br\/>partially automating the production of complex interaction mechanisms, improve<br\/>the quality of systems by making it simple to add security and dependability<br\/>features, and develop new foundations for specifying and reasoning about complex<br\/>interaction mechanisms.","title":"ITR\/SY(CISE): Compositional Connectors","awardID":"0113810","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["485947"],"PO":["564388"]},"55086":{"abstract":"The goal of this research project is to improve our understanding of how humans behave in information-seeking digital environments such as the Web. The approach consists of using massively large Web logs to infer patterns of behavior. New probabilistic models for modeling human behavior on the Web are under investigation including Markov and switching models, mixture models, and Bayesian hierarchical models. Adaptive statistical techniques form the basis for building up individual user models in an online fashion, automatically learning both the dynamic time-dependent patterns of a user as well as text-vector representations of their interests. Test data sets from large commercial Web sites are being used to develop, validate, and test the models. Data are anonymized to protect individual privacy. The statistical user models are in turn being used to develop two primary software tools. The first tool allows an analyst to explore, cluster, predict, and visualize Web logs with millions of entries, allowing an understanding of dynamic patterns of access and behavior in a manner that is not currently available in research or commercial tools. The second tool, WebMARS, uses adaptive user-models to enhance information retrieval algorithms by interpreting search queries in a personalized manner. More generally, the results from this project will provide tools and techniques to enable a better scientific understanding of modes of human behavior across a broad range of digital environments, with potential applications in wireless information appliances, medical informatics, scientific exploration of massive data sets, and so forth.","title":"Data Mining of Digital Behaviour","awardID":"0083489","effectiveDate":"2001-09-15","expirationDate":"2010-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"H228","name":"CIA"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T472","name":"CIA-KNOWLEDGE DISC & DISSEM PR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"T029","name":"CIA-KDD WORKING GROUP"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"T159","name":"ARMY-MMSD"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V513","name":"CIA-KDD WORKING GROUP"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"V145","name":"CIA-KNOWLEDGE DISCOVERY & DISS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"W525","name":"CIA-GRANT EXTENSIONS FOR KNOWL"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"1269","name":"STATISTICS"}}],"PIcoPI":["515756","550872"],"PO":["565136"]},"64271":{"abstract":"Fostering Peripheral Information Awareness through Personalized Expressive Art<br\/><br\/><br\/>This is a standard award. In today's information-rich society, people who are busy and deeply engaged in work or other activities often are unable to maintain awareness of peripheral, but useful, information such as weather, traffic, and financial news. In this project the PI will explore the concept of Information Art, the process of promoting awareness of peripheral information through personalized, expressive art. This new form of information access and presentation system combines elements of both ambient displays and information visualizations. Information Art allows people to identify information of interest and then to design a customized, aesthetically-pleasing representation of that information. The primary goal of the project is to explore techniques for calmly communicating information without interrupting a person's concentration and without robbing space from his\/her desktop displays. As people gain access to more and more information, it is crucial to develop techniques and tools that aid them in managing and utilizing that information. Many computer technologies only seem to exacerbate the situation, however, by contributing more (often unwanted) information. This project will create techniques and tools that will empower people to choose information of interest to them, and to represent and communicate this information in a manner that is personally meaningful and pleasing. An even broader impact of the project will be to explore the space of new, pervasive information displays and understand their place in future work and home environments.","title":"Fostering Peripheral Information Awareness through Personalized, Expressive Art","awardID":"0118685","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}}],"PIcoPI":["550876"],"PO":["565227"]},"64282":{"abstract":"The project focuses on perception issues, with the goal of achieving a flexible and consistent representation of large scale man-made environments that can be acquired via visual sensing. The work will enhance the autonomy of robotic agents and their interactions with humans, or used to help humans with impaired vision.","title":"Visually Guided Agents","awardID":"0118732","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["553609"],"PO":["317663"]},"63072":{"abstract":"EIA- 0113679<br\/> Black, Michael<br\/>Brown University<br\/><br\/>ITR\/SY: The Computer Science of Biologically-Embedded Systems<br\/><br\/>Biologically-embedded systems that directly couple artificial computational devices with neural systems are emerging as a new area of information technology research. The physical structure and adaptability of the human brain make these biologically-embedded systems quite different from computational systems typically studied in Computer Science.<br\/><br\/>Fundamentally, biologically-embedded systems must make inferences about the behavior of a biological system based on measurements of neural activity that are indirect, ambiguous, and uncertain. Moreover these systems must adapt to short- and long-term changes in neural activity of the brain. These problems are addressed by a multi-disciplinary team in the context of developing a robot arm that is controlled by simultaneous recordings from neurons in the motor cortex of awake behaving monkeys. The goal is to probabilistically model the behavior of these neurons as a function of arm motion and then reconstruct continuous arm trajectories based on the neural activity. To do so, the project will exploit mathematical and computational techniques from computer vision, image processing, and machine learning.<br\/><br\/>This work will enhance scientific knowledge about how to design and build new types of hybrid human\/computer systems, will explore new devices to assist the severely disabled, will address the information technology questions raised by these biologically-embedded systems, and will contribute to the understanding of neural coding.","title":"ITR\/Comp Bio: The Computer Science of Biologically Embedded Systems","awardID":"0113679","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["511983","498150","422017"],"PO":["565223"]},"64293":{"abstract":"The design of efficient wireless communication systems relies on a<br\/>deep understanding of the basic characteristics of the underlying<br\/>channel. The most fundamental and unique characteristic of wireless<br\/>channels is the random time-variation of the channel strengths, a<br\/>phenomenon known as fading. Communication over fading channels has<br\/>been a topic of study since the 60's. A very different view of the<br\/>problem, however, emerges from recent research. The traditional view<br\/>of fading is that it is a source of unreliability that has to be<br\/>compensated for by various diversity techniques. The modern view is<br\/>much more<br\/>powerful and considers fading as a source of randomization from nature<br\/>that can be exploited to get very significant capacity boost.<br\/><br\/>The research project addresses several key problems within this<br\/>modern paradigm. They will be centered around two areas: 1)<br\/>opportunistic communication : the dynamic rate and power allocation<br\/>over the dimensions of time, frequency, antennas and users<br\/>so that transmission is done when and where the channel is strong;<br\/>2) multi-antenna communication: the use of multiple transmit and<br\/>receive antennas to increase the number of degrees of freedom available<br\/>for communication in richly scattered fading environments. The issues<br\/>studied are focused on how the random fading can be exploited even in<br\/>the face of<br\/>channel uncertainty, and the interplay between the modern and<br\/>traditional views of channel fading.","title":"Communication over Wireless Fading Channels: A Modern View","awardID":"0118784","effectiveDate":"2001-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["523728"],"PO":["348215"]},"56120":{"abstract":"Toward building large-scale switches, the current industry focus is on increasing packet handling<br\/>capacities of switch fabrics from Gb\/s to Tb\/s. Although an increase in packet handling<br\/>capacities and line card data rates requires a corresponding increase in call handling capacities of<br\/>switches, this problem has received little attention. This is because most of the work on scalability<br\/>of packet switch fabrics has targeted connectionless internet protocol (IP) routers, while call handling<br\/>arises only in connection-oriented networks. However, in the last few years, resource reservation<br\/>to support Quality-of-Service (QoS) guaranteed flows has gained attention. Internet<br\/>Engineering Task Force (IETF) is addressing this issue by augmenting IP routers with connection-oriented<br\/>capabilities.<br\/> In a connection-oriented network, the signaling protocol that is used to set up and release connections<br\/>impacts its call handling capacity. Signaling messages can be complex with many parameters<br\/>and timers and the state information associated with calls can become unwieldy.<br\/>Consequently, signaling protocols have traditionally been implemented in software. QoS control<br\/>solutions are being developed and evaluated based on the premise that call handling capacities do<br\/>not scale with the packet handling capacities of switch fabrics. This assumption regarding call<br\/>handling capacities has also relegated circuit-switched networks, including high-speed Wave-length<br\/>Division Multiplexed networks, to just serve as wires. This proposal challenges this basic<br\/>assumption by demonstrating call handling capacities in the order of millions of calls\/sec. Changing<br\/>this basic assumption regarding call handling capacities would indeed have a far-reaching<br\/>impact on both QoS control mechanisms for packet-switched networks, and on the use of emerging<br\/>high-speed circuit-switched networks for challenging new applications.<br\/> Our solution approach is to implement signaling protocols in reconfigurable Field Programmable<br\/>Gate Array (FPGA) hardware. FPGAs can be reprogrammed as signaling protocols evolve<br\/>while significantly improving the call handling capacities relative to software implementation. To<br\/>manage complexity, we propose to implement the basic and frequently-used operations of the protocol<br\/>in hardware, and relegate the complex and infrequently-used operations to software. In contrast<br\/>to stateless protocols, signaling protocols maintain state information for each call. To<br\/>manage associated memory requirements, we propose to maintain only the essential state information<br\/>for each call in hardware. In this project we propose to (i) implement a typical signaling<br\/>protocol in FPGAs, (ii) design a switch controller board using the signaling protocol FPGAs, and<br\/>(iii) quantify measures of the implementation to demonstrate achievable call handling capacities.","title":"Towards enabling a 2-3 orders of magnitude improvement in call handling capacities of switches","awardID":"0087487","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["550604","550604","564799","564799"],"PO":["565090"]},"57693":{"abstract":"Computational geometry arose out of the need for many<br\/>science and engineering applications of geometric computing.<br\/>Over the last two decades, the field has emerged as a rich,<br\/>mature, and mathematically rigorous discipline. However,<br\/>despite its impressive achievements well-received in the<br\/>theoretical computer science community, computational<br\/>geometry has had limited impact in the practical areas of<br\/>geometric computing. As advocated by the recent<br\/>Computational Geometry Task Force Report, it is important to<br\/>reorient the field towards providing more practical<br\/>solutions to the specific needs of the applications that use<br\/>geometric computing, and towards focusing on new<br\/>\"bottleneck\" problems of identifiably important practical<br\/>areas. In this proposed career plan, we intend to develop<br\/>our research career toward this goal, by working on the full<br\/>computational pipelines of some important real-world<br\/>applications of geo-metric computing, including air traffic<br\/>management (conflict prediction), graphics and scientific<br\/>visualization (I\/O-efficient isosurface extraction, I\/O-<br\/>efficient direct volume rendering, external-memory view-<br\/>dependent surface simplification), and manufacturing<br\/>(maximum scatter traveling salesperson problem (TSP)). An<br\/>important aspect of the work is to examine the full<br\/>computational pipelines of the practical applications to<br\/>identify and formulate critical tasks into new algorithmic<br\/>questions, extend computational geometry methodologies to<br\/>devise novel solutions, and finally implement and integrate<br\/>the developed algorithms into the pipelines to evaluate<br\/>their practical ef-fectiveness in the original real-life<br\/>applications. Key components of the plan are the expected<br\/>rich interactions between theory and practice, and the aim<br\/>of designing simple, easy-to-implement geometric algorithms<br\/>that are efficient both practically and theoretically. In<br\/>the long term, we expect to be able to have real impact on<br\/>these important practical areas of geometric computing, and<br\/>at the same time enrich the knowledge body of the field of<br\/>computational geometry. The proposed educational plan<br\/>includes introduction of new courses, involvement of both<br\/>graduate and undergraduate students in the proposed research<br\/>projects, participation in an outreach program, and further<br\/>development of a research laboratory.","title":"CAREER: Theory and Practice of Applied Geometric Computing","awardID":"0093373","effectiveDate":"2001-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["292992"],"PO":["565157"]},"59333":{"abstract":"Proposal #0098219<br\/>Eva K. Lee<br\/>GA Tech Res Corp -GIT<br\/><br\/>The field of mixed integer programming (MIP) involves a fascinating and lively blend of theoretical analysis, algorithm and software development, and scientific computing. Over the past thirty years, real applications have provided invaluable insight and motivation for advancing the frontiers of this evolving discipline. In particular, the MIP modeling paradigm and the associated algorithmic branch-and-bound, branch-and-cut, and branch-and-price solution strategies have been applied extremely successfully to a broad range of industrial applications, from scheduling and process planning applications, to VLSI and telecommunication network design. Integral to these successful applications of MIP were close collaborations between optimization researchers and the domain experts in each application area. In each case, much research was devoted to developing a superior model (versus simply a correct formulation, as the solution process depends heavily on the underlying structure of the formulated model) and effective computational strategies for the specific application at hand. Beyond this active research came the technological transfer of computational advances into commercial software (e.g., CPLEX, XPRESS), enabling the integration of these advances into the decision support systems used daily by practitioners.<br\/><br\/>The primary focus of this research is to explore applications of mixed integer programming strategies to radio-therapy treatment planning optimization. The initial focus will be radiosurgery treatment planning. Radiosurgery involves small field, stereotactic external beam irradiation to the brain. It has evolved over the past decade into a common method for treating and controlling certain central nervous system lesions such as arteriovenous malformations, metastatic lesions, acoustic neuromas, pituitary tumors, malignant gliomas and other intracranial tumors. Although radiosurgery provides an excellent potential for effectively curing these disorders, the complexities and functional dependencies both within and between brain structures means that the procedure is inherently high-risk and can bring about severe complications. Hence, accuracy and precision are of paramount importance in both the planning and execution of stereotactic radiosurgery.","title":"Mixed Integer Programming Applied to Radiation Treatment Planning Optimization","awardID":"0098219","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["496947"],"PO":["321058"]},"57034":{"abstract":"Visual processing in the mammalian brain is not done simply with several parallel channels leading to higher areas. We now know that visual input pathways diverge into multiple processing streams, with feedback at all levels in each stream and crosstalk between streams. The visual cortex can be seen in this view at a dynamic system of interconnected areas interacting flexibly in different combinations at different stages of processing. This renewal project builds on technological advances and analytical tools for with high spatial, temporal and frequency resolution, developed from prior support. These comprehensive advances make it possible to monitor multi-area functional interdependency patterns that arise in the cortex, and to measure and analyze how one cortical area can affect others. The novel approach in the current project is to examine the mesoscopic scale of functional brain organization, offering a complementary level between the microscopic recording of single cell activity in a local area or layer, and the macroscopic derivation of images from whole brains using scanning technologies such as PET and fMRI. <br\/> Results will have an impact by providing new insights into the dynamics of functional interdependency in the visual cortex, and going beyond visual neuroscience to make available digital signal processing tools potentially useful for a handling large-scale neural systems in a range of cognitive studies, and potentially leading to designing better complex artificial neural networks. This project also provides excellent cross-disciplinary training opportunities for students.","title":"Large-Scale Distributed Cortical Networks in Vision","awardID":"0090717","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"1162","name":"COMPUTATIONAL NEUROSCIENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"5500","name":"NEURAL SYSTEMS CLUSTER"}}],"PIcoPI":["483285","562346"],"PO":["322092"]},"63062":{"abstract":". This project will develop tools that make it possible to retrieve naturally occurring sentences from the World Wide Web on the basis of lexical content and syntactic structure, providing linguists with an immediate, easily accessible source of raw linguistic data. The PIs will investigate specific linguistic hypotheses at the lexical semantics\/syntax interface as an illustrative application of these tools. At a high level, the planned work constitutes an important step toward a new paradigm for linguistic research. Rather than relying entirely on introspective data generated by the linguist who is trying to (dis)prove a particular hypothesis, Web-enabled linguistics research will draw on the methodology and the tools developed by the PIs to supply naturally occurring data on which theories can rest. With regard to specific linguistic questions, the goal is to provide an explanation of the rules and constraints that govern three transitivity alternations (Middle, Unaccusative, Unspecified Object Deletion), and the PIs expect data made available by their tools to shed light on the \"grey\" area between competence and performance, that is, the linguistic behavior that seems to fall outside of rule-governed behavior. Although naturally occurring data are not accorded great emphasis in generative syntax, the use of text corpora has a tradition in the greater linguistic enterprise. An explosive new phenomenon in the world of naturally occurring text, the World Wide Web is an essentially untapped resource that embodies the rich and dynamic nature of language, presenting a data resource of unparalleled size and diversity.","title":"Collaborative Proposal-Using the Web as a Corpus for Empirical Linguistic Research","awardID":"0113641","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["334102","514912"],"PO":["246649"]},"67330":{"abstract":"This proposal is for a Digital Society and Technologies Program workshop on \"Global Issues in the Social and Economic Impacts of IT\" to be conducted jointly with the European Commission's Information Society Technology program in conjunction with their research conference \"e2001: e-Business and e-Work\" to be held in Venice, Italy, October 17-19. The proposed workshop will be held on October 16, in advance of the conference. The workshop will explore a research agenda regarding the global social and economic impacts of IT and the possibilities for international cooperation in gathering multi-country data and conducting research. The workshop will discuss research issues related to 1) the global diffusion of IT production and use, the globalization of e-commerce (including mobile e-commerce), the new ways of working and collaboration, and the influence of national environments and government policies on IT diffusion and impact. A report will be produced indicating the results from the workshop.","title":"US\/NSF and European Commission\/IST Workshop on Global Issues in the Social and Economic Impacts of IT to be held October 16-19, 2001, in Venice, Italy","awardID":"0132911","effectiveDate":"2001-09-15","expirationDate":"2005-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["426259"],"PO":["495796"]},"57540":{"abstract":"The research objective of this proposal is to design, implement, and evaluate a scalable and adaptive network service platform.<br\/> Supporting sophisticated new applications, such as multi-party conferencing and streaming media transmission, over the Internet poses serious technical challenges for the underlying infrastructure. However, adding some processing inside the network enables new network-based services that substantially improves the end-to-end performance of these applications. The continual exponential decrease in the cost of processing makes network services viable, while the increases in application complexity makes it necessary. Link capacities, however, have been increasing at rates even faster than increases in processing capacity, and current network service platforms are incapable of sustaining non-trivial service to multiple flows at line speeds.<br\/> In this proposal, the researcher outlines research whose goal is to develop and evaluate adaptive processing techniques to scale the number of flows supported by network service platforms. Adaptive techniques control degradation in service quality when aggregate demand exceeds available resources, and can be applied within a single node or across multiple cooperating nodes. The research focuses on the development of general adaptation techniques that are applicable across a wide range of node architectures and applications. The proposed work is grouped into three major thrusts: design of the adaptation mechanisms themselves and underlying control and resource management mechanisms and interfaces required to adapt processing on-line; development of a single- and multi-node policy framework to trigger adaptation; and the development of an analytic model of adaptive network processing that will allow on-line evaluations of possible adaptations. The researcher will evaluate these techniques using a combination of analysis, simulation, and experimentation with a number of example services and policies implemented over the Odyssey network service platform. The success of the Internet derives from the spectrum of applications it supports. As a new generation of Internet applications emerge, a pivotal challenge is to design a scalable and flexible network service platform that can sustain processing for multiple end-applications at high speeds; otherwise, end-to-end performance will be limited by the processing constraints imposed by the network. This research explicitly addresses the issues of network processing scalability by using adaptive techniques. By reducing, and in some cases eliminating, network processing bottlenecks, the work will enable new classes of applications to be supported on a large scale over the Internet.<br\/> The educational objective is to design a set of core networking courses that introduce students to current developments in the field while emphasizing the fundamental concepts and to train students to understand how large networks, complex programs, and realistic systems can be built by composing relatively small, simple, and modular components.<br\/> The core networking curriculum consists of an undergraduate, a graduate, and a research course. The undergraduate course teaches the basics of networking with an emphasis on the fundamentals. Students learn by building substantial parts of different network layers, and by experimenting with real-world applications with which they are already familiar. The aim of the graduate course is to understand core network protocols in detail, to appreciate the philosophy behind the current Internet protocols, and to introduce students to new research ideas in networking. The goal of the research course is to try to bridge the gap between theory and implementation: understand the overheads incurred in implementing complex protocols and devise mechanisms to mitigate their effects.<br\/> The unparalleled success of the Internet has made it essential that every CS student understand the basics of networking. This curriculum will fill this need for general CS students and will motivate students interested networking to pursue further research in the field.","title":"CAREER: Adaptive Network Processing","awardID":"0092806","effectiveDate":"2001-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["548322"],"PO":["565090"]},"55362":{"abstract":"Data mining is one of the very promising information technologies today. We are concentrating our research into two new topics in data mining. First, instead of optimizing construction of a complete data mining model, parts of the model are incrementally constructed as guided by user feedback in order to reduce the long construction times of data mining models. The methods enable interactive response times, and this research is expected to result in a paradigm shift away from batch-oriented mining to interactive data mining. Second, data mining has traditionally been performed over static datasets, and mining algorithms could afford to read the input data several times. This traditional approach is referred to as offline data mining. This research addresses the online mining of high-speed data streams. The goal is to develop data mining systems that never stop working, incorporate new records immediately as they arrive, and update current and construct new models continuously. This new approach is referred to as online data mining. Anticipated applications include the discovery of patterns in network data, click-stream data, text data, and\/or biological databases.","title":"Interactive and Online Data Mining","awardID":"0084762","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["448955"],"PO":["563751"]},"65042":{"abstract":"The computational GRID vision is that everyone at a desktop machine could eventually have the power of a supercomputer at his or her fingertips. The GRID takes its name from the electrical utility analogy. <br\/><br\/>GRID computing holds the promise of transforming the Internet, now used for communication, mainly e- mail and instant messaging, while the Web is an information retrieval system, enabling computer users to have access to text, images and music. Grid computing builds on the result of previous and ongoing research in networking, distributed computing, seamless computing, meta computing, web technologies, and other related topics. <br\/><br\/>In this proposal, the National Virtual Observatory, the Sloan Digital Sky Survey, the Laser Interferometer Gravitational-Wave Observatory (LIGO) and the Large Hadron Collider experiments, all well-presented science projects (two of which have support via NSF Major Research Equipment funds) have data needs appropriate for GRID based technologies and are depending on such technologies for the successful operations of their experiments. The experiments will serve as test beds for GRID concepts.","title":"ITR\/AP: An International Virtual-Data Grid Laboratory for Data Intensive Science","awardID":"0122557","effectiveDate":"2001-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"1221","name":"ELEMENTARY PARTICLE ACCEL USER"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"1688","name":"ITR LARGE GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7369","name":"INTERNATIONAL RES NET CONNECT"}}],"PIcoPI":["538211","530692","559256","531440","554547"],"PO":["397635"]},"67110":{"abstract":"EIA-0131937<br\/>Henebry, Geoffrey<br\/>University of Nebraska - Lincoln<br\/><br\/>BDEI: Spatio-temporal models of Biogeophysical Fields for Ecological Forecasting:<br\/>A Cross-Disciplinary Incubation Activity <br\/><br\/>Summary<br\/><br\/><br\/><br\/>We are now in an era of intensive earth observation: orbital platforms generate myriad remote sensing<br\/>datastreams across a range of spatial, temporal, spectral, and radiometric resolutions. The number and<br\/>variety of \"eyes in the skies\" are scheduled to increase significantly over the next few years. This<br\/>veritable data deluge necessitates new ways of thinking about transforming remote sensing data into<br\/>information about ecological patterns and processes. These datastreams hold the promise for<br\/>environmental decision support. Yet, there is a critical need for theories and tools that will enable efficient<br\/>and reliable characterization of spatio-temporal patterns contained in image time series. We think that<br\/>such tools must be based on ecological expectations of land surface dynamics, analogous to<br\/>climatological expectations. Ecological expectations would summarize across specific regions the typical<br\/>temporal development of spatial pattern in biogeophysical fields. We have a robust principal method for<br\/>extracting ecological expectations from remote sensing datastreams: projecting image time series into<br\/>pattern metric spaces. To make ecological forecasting an operational possibility, we need the capability<br\/>to establish and to update complex spatio-temporal baselines that will enable prediction of the usual and<br\/>identification, quantification, and assessment of the unusual. A recent NASA workshop on Earth Science<br\/>data mining identified anomaly detection as a key characteristic of scientific data mining; yet, there are<br\/>relatively few examples of spatio-temporal data mining of biogeophysical data. Our approach is spatio-temporal datamining that is informed by relevant domain expertise. Representation of the spatio-temporal<br\/>entities and fields in databases must support sophisticated spatio-temporal queries: a capability that does<br\/>not currently exist.","title":"Biodiversity and Ecosystem Informatics - BDEI - Spatio-temporal Models of Biogeophysical Fields for Ecological Forecasting: A Cross-Disciplinary Incubation Activity","awardID":"0131937","effectiveDate":"2001-09-01","expirationDate":"2004-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["214520","475693","518814"],"PO":["371077"]},"67000":{"abstract":"EIA-0131354<br\/>Andrew Lumsdaine<br\/>University of Notre Dame<br\/><br\/>Next Generation Software: Open Compilation for Self-Optimizing Generic Components<br\/><br\/>This proposal is to advance the state-of-the-art in high-performance software specifically related tot he design and compilation of high-performance scientific libraries. This work will address two of the most important issues-code complexity and performance optimization-by applying and extending two emerging programming paradigm: generic programming and concept-based optimization. The vehicle for this work will be development of an integrated framework consisting of open compilation and generic library technologies. By simultaneously developing the compilation technologies and the library technologies-and by providing mechanism to couple the two together-the whole will be greater than the sum of its parts","title":"NGS: Open Compilation for Self-Optimizing Generic Components","awardID":"0131354","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["562709"],"PO":["301532"]},"57573":{"abstract":"The goal of this project is to develop a large-scale parallel data mining system (PDMS), which can manipulate very large scientific databases. The research pursues an application-oriented approach with input from three scientific domains: bioinformatics (protein structure prediction), astronomy (rare object identification) and materials informatics (\"virtual\" material design). There are two conflicting objectives that must be satisfied: genericity and specificity. The PDMS toolkit must be generic in that it can support a range of common data mining tasks such as associations, sequences, classification and clustering, yet to be usable it must support specificity or domain-specific customization. The PDMS system is based on a novel three-tiered architecture consisting of a front-end interface and query tool, a middle layer of common high-level mining algorithms, and a back-end system consisting of a core set of data mining \"primitive operations\", tightly integrated with a database system, and delivering peak parallel or distributed performance. The application-oriented approach produces excellent opportunities to advance inter-disciplinary educational efforts, and encourages the cross-fertilization of ideas and algorithms across these areas. New courses will be offered on the design of large scale data mining systems as well as applications of data mining in scientific domains. The results of this project will aid research in developing more generic data mining tools that are able to leverage high performance parallel and distributed techniques in all the phases of the knowledge discovery process, and in developing customized tools for important scientific applications like bioinformatics, astronomy and materials science.","title":"CAREER: Application-Oriented Large-Scale Parallel Data Mining","awardID":"0092978","effectiveDate":"2001-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["541893"],"PO":["563751"]},"48631":{"abstract":"Proposal: CMS-9987871<br\/>PI: James Garrett<br\/>Institution: Carnegie Mellon University<br\/>Date: April 20, 2001<br\/><br\/>ABSTRACT CMS-9987871 \" A Knowledge Discovery Framework for Civil Infrastructure Contexts\" PI: Garrett, James, Carnegie Mellon University; Christos Faloutsos, Carnegie Mellon University; and Sue McNeil, University of Illinois at Chicago.<br\/><br\/>The primary objective of this research is to specialize the abstract CRISP-DM (Cross-Industry Standard Process for Data Mining) process model being developed within the Knowledge Discovery in Databases (KDD) community, into a framework for use in civil infrastructure problem domains. With the recent accumulation of domain data, civil infrastructrue researchers have turned to data-intensive techniques to aid their understanding of deterioration mechanisms and usage patterns. During roughly the same time period, researchers in the machine learning, database, and statistical communities began to develop a set of new tools and techniques, known as CRISP-DM, to analyze very large databases. This framework will assist civil infrastructure researchers in systematically applying the CRISP-DM process for their data analysis needs. Such a framework will become vital for civil infrastructure researchers as they begin to analyze the enormous amounts of infrastructure data they have collected. The research team will identify the analyze preliminary case studies in civil infrastructure using the CRISP-DM process. Case studies will be chosen based on the uniqueness of their KDD problem characteristics. Special attention will be paid to those case studies that present challenging issues in data quality and data preparation, the most time-consuming and difficult stages of the process as well as the least-studied. The research team will classify civil infrastructure data analysis needs in terms of CRISP-DM process characteristics. All phases of the process will be addressed, but the data understanding (including data quality), data preparation, and modeling phases will be treated in-depth. The research team will then develop a more specific framework for applying the CRISP-DM process to civil infrastructure analysis needs. The research team will also identify and conduct case studies with which to validate the framework. Finally, the development and deployment of a web-based course and a web repository based on this research will be completed during the final year.","title":"A Knowledge Discovery Framework for Civil Infrastructure Contexts","awardID":"9987871","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1631","name":"CIVIL INFRASTRUCTURE SYSTEMS"}}],"PIcoPI":["147905","548220","493225"],"PO":[124471]},"59301":{"abstract":"Proposal #0098133<br\/>Ye, Qiang<br\/>U of Kentucky <br\/><br\/>This project will develop preconditioned Krylov subspace methods with analysis for computing a few eigenvalues of a large generalized eigenvalue problem Ax = lambda Bx, and study their robust implementations with a long term goal to develop a specialized package for public distributions. The<br\/>resulting algorithms should inherit desirable characteristics of the existing Krylov subspace methods, but<br\/>extend their capability for efficient preconditioning. The feasibility of this objective has been demonstrated by a preliminary study that led to an algorithm of this type for computing the smallest eigenvalue of a symmetric definite problem. In this project, this preliminary work will be strengthened and its idea further developed and generalized to produce algorithms that are capable of delivering extreme as well as interior eigenvalues for symmetric as well as nonsymmetric problems alike.<br\/><br\/>This project builds upon the PI's research expertise and contributions over the past decade, to significantly advance the state-of-the-art of numerical methods for large matrix eigenvalue problems. Unifying several existing ideas and concepts and bringing new approaches, the resulting methods would be an ideal topics for classroom learning and thesis research. Moreover, the preliminary study indicates that they would be well suited for black-box implementations and thus have the potential to reach a broader application community.","title":"Preconditioned Krylov Subspace Algorithms for Computing Eigenvalues of Large Matrices","awardID":"0098133","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["550008"],"PO":["321058"]},"59257":{"abstract":"Proposal #0098034<br\/>Van Hoeij, Mark<br\/>Florida State University<br\/><br\/>This award will devise new methods for solving linear differential equations and for integration of algebraic functions, including implementations. The significance is that differential equations are used in physics, engineering, mathematics and many other sciences. Several computer algebra softwares have solvers that apply various methods to search for closed-form solutions of differential equations. This project will lead to new methods, so that more equations can be solved. Implementations will be written as well and distributed via the web so that researchers who use a computer to solve differential equations can easily benefit from the results. Algorithms for solving non-linear differential equations will benefit indirectly because such algorithms often reduce problems to linear differential equations. The second topic in this award consists of improving the performance of the algorithm for integration of algebraic functions. This is necessary because the the existing method is not efficient enough to handle large inputs.","title":"Algorithms for Linear Differential Equations and Algebraic Functions.","awardID":"0098034","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["550445"],"PO":["321058"]},"64790":{"abstract":"Embedded systems, such as controllers in automotive, medical, and avionic systems, consist of a collection of interacting software modules reacting to and controlling an analog environment. Engineering disciplines such as control theory focus on continuous dynamics, and offer foundations for designing robust control laws for ensuring optimal performance of dynamical systems. Computing disciplines such as software engineering focus on discrete programs, and offer structured ways of implementing complex control and analysis tools for validating distributed software. For networked embedded devices with multiple modes of operation, the combination of the complexity in both discrete and continuous aspects leads to fundamental problems that are not yet well understood, and this makes the programming of reliable embedded systems a particularly challenging task. A systematic approach to designing embedded devices requires combining tools from control theory and modern software engineering, and the emerging theory of hybrid systems---systems with tightly integrated discrete and continuous dynamics, has the potential to provide the foundation. Despite the great appeal of hybrid systems as a model, the applicability of the state-of-the-art analysis and design techniques for hybrid systems has been limited to examples of small size due to complexity. This ITR research aims to develop foundations and tools for automatic abstraction and hierarchical decomposition as a means of simplification and scalability. <br\/><br\/>To facilitate high-level design of embedded software, modeling concepts such as hierarchy, modularity, reuse, compositionality, and object-orientation, are explored to develop a theory of hierarchical hybrid systems with an accompanying a compositional calculus of refinement. This will be the basis for behavioral interfaces and descriptions of components at different levels of abstractions. For rigorously specifying and evaluating design alternatives and correctness requirements, automated techniques such as model checking are very effective. To apply these techniques for formal analysis of hybrid systems, this research is developing automated schemes for constructing abstractions of hybrid models. The technical directions being pursued include model checking algorithms that exploit hierarchy, algorithms for extracting finite-state approximations using predicate abstraction, counter-example guided refinement of abstractions, property-preserving bisimulation-based reductions of continuous differential equations, and assume-guarantee reasoning. The results of this research are being integrated in software tools for modeling and analysis of hybrid systems. The benefits of the techniques for developing embedded systems with higher assurance for safety and reliability are evaluated in an experimental testbed of multiple, autonomous, mobile robots.","title":"ITR\/SY: Formal Design and Analysis of Hybrid Systems","awardID":"0121431","effectiveDate":"2001-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["497082","526896"],"PO":["561889"]},"66880":{"abstract":"EIA-0130858 <br\/>Camillo Taylor<br\/>University of Pennsylvania<br\/><br\/>The idea of deploying teams of small, inexpensive robotic agents to accomplish various sensing, manipulation and communication tasks is one that has gained increasing currency over the last few years. This project will involve three interrelated research thrusts that investigate various aspects of this paradigm. The first thrust deals with the problems associated with coordinating the motion of teams of robots. Some of the questions that are addressed by this effort include the problem of controlling the motion of robots moving in formation and coordinating the action of robots engaged in cooperative manipulation of an object. The second thrust focuses on the issues associated with combining the information obtained from distributed robots to form a coherent model of the environment. The third area of research concerns the problems associated with designing and analyzing networking strategies that are appropriate for use with distributed teams of robotic agents. Since the platforms are mobile, many of the traditional networking strategies, which were designed with fixed infrastructure in mind, are not applicable. As part of this proposal we intend to investigate questions concerning the appropriateness of various wireless networking technologies such as IEEE 802.11b and Bluetooth. This proposal requests funding to purchase the equipment required to develop a fleet of networked robots that would serve as a shared testbed for our research efforts.","title":"CISE Research Resources: Coordination, Control and Communications Strategies for Teams of Mobile Robots","awardID":"0130858","effectiveDate":"2001-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["553286","456808","517945"],"PO":["557609"]},"65340":{"abstract":"A major trend in distributed computing is toward environments consisting of numerous wearable, handheld and embedded devices. Rapid growth in inexpensive, short range, and low-power wireless communications and hardware, are now enabling experimentation with ubiquitous computing environments. In order for ubiquitous environments to work well, it is essential that devices be able to detect their current context, that they must be aware of relationships between the users and the devices, and handle ad-hoc groups and their communications.<br\/><br\/>The proposal plans to take an integrated hardware and software approach to developing essential services to support a wide variety of distributed applications in heterogeneous environments. The services include investigation of:<br\/>situation-aware inter-object communications<br\/>group management service to establish device communities<br\/>feasibility of using cellular automata computational model to design a scalable dissemination service<br\/>a service that will use the concept of context-sensitivity to perform trade-offs between transparent and QoS assisted adaptations.<br\/>The proposal will develop a Reconfigurable and Context-Sensitive Middleware, which will be open-source, open-schematic and open standard middleware based on top of Bluetooth standards.","title":"Adaptive Middleware Services for Situation-Aware Communication in Ubiquitous Computing Environments","awardID":"0123980","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4089","name":"NETWORK CENTRIC MIDDLEWARE SVC"}}],"PIcoPI":["487903","535238"],"PO":["7594"]},"64284":{"abstract":"Force feedback devices, or haptic interfaces, have the potential to increase the qualityof human-computer interaction by adding the sense of touch. However, there are still few practical force feedback applications, due in large part to the stringent computational requirements of haptic rendering. In order to maintain a high fidelity system, haptic update rates must be as high as 1000 Hz, rather than the 30 Hz updates for graphical displays. This is especially challenging for 6-degree of freedom (DOF) haptic devices which are used to display forces and torques for arbitrary pairs of objects. This requires accurate contact determination and contact force and torque computation of all collision points in less than a millisecond.<br\/><br\/>This project focuses on three aspects of high fidelity haptic display or ''virtual touch''. The first goal includes developing new geometric and physically-based algorithms that can improve the state of the art by more than an order of magnitude, in addition to the expected improvements in processor speed and computing power over that time. This will be based on hybrid spatial data structures, simplification hierarchies, multi-resolution representations, bounded error approximations, and massively parallel rasterization hardware. The second goal is to pursue applications that can benefit significantly from the use of high-fidelity 6-DOF haptic displays. This includes virtual prototyping of nano-structures, haptic visualization of biological interaction between molecules, maintenance analysis and interactive modeling and painting. The third goal is the evaluation of 6-DOF haptic rendering systems as a tool for human-computer interface. This will be done in collaboration with Boeing, Sandia Labs, and Sensable Technologies. If successful, the proposed research will provide enabling algorithms and a prototype software system for designing a high-fidelity virtual touch system.","title":"VISUALIZATION: High Fidelity Virtual Touch: Algorithms, Applications and Evaluation","awardID":"0118743","effectiveDate":"2001-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}}],"PIcoPI":["543535","559716"],"PO":["565272"]},"57640":{"abstract":"Increased connectivity to information networks and the widespread availability of high bandwidth links are expected to result in much increased interest in digital image and video applications providing very high quality and advanced processing and compression options. This research is geared toward addressing this need by providing more accurate representations, modeling, processing and compression for digital images and video. The main objective is the development of localized, multiresolutional models and the design of related estimation, optimization, and processing strategies. The developed techniques are specifically targeted at digital images and video depicting natural scenes, which are characterized by localized singularities separating regions of uniform smoothness\/texture in the camera plane. Statistical multiresolutional models for the singularities combined with global optimization techniques constitute the foundations of the research track. The developed techniques are utilized in a variety of applications including compression, estimation of missing data, noise removal, segmentation and resolution enhancement. The results of this research are expected to have an impact in a variety of areas, such as wireless communications and multimedia applications over the Internet. Modern engineering education involves many courses that assume students are familiar with detailed technical background material. The educational component of this is geared toward addressing significant variations in student background by allowing the students to enhance their learning experience at their own pace. Educational objectives include the development of computerized, multimedia assisted course material, including problems and example solutions with rich annotations. Extensions of this material to distance learners, including outreach to broader communities of learners over information networks, are expected.","title":"CAREER: Models and Representations for Digital Images and Video","awardID":"0093179","effectiveDate":"2001-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":[148214],"PO":["433760"]},"64174":{"abstract":"The project focuses on general purpose trajectory design algorithms for high dimensional, highly nonlinear systems evolving in complex environments. The goal is to solve the currently intractable problem of trajectory generation and optimization for high-fidelity models of various types of autonomous vehicles, using an approach that combines methods from differential geometry, nonlinear control theory, robot motion planning, randomized algorithms, and mathematical programming.","title":"Algorithmic and Differential-Geometric Trajectory Design","awardID":"0118146","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["553248","495278"],"PO":["234178"]},"57651":{"abstract":"Over the next few years, large high resolution displays and immersive displays will enable and popularize new kinds of interactive applications that will drive a vast increase in the demand for computational and communications resources. These demands will be met by using increasingly wider area distributed computing environments such as computational grids. Unfortunately, there is a mismatch between the aperiodic soft real-time requirements of these distributed interactive applications and the shared, unreserved, highly dynamic and competitive environments they will run in. To achieve responsiveness these applications will have to adapt their behavior to the vagaries of their execution environments.<br\/> A number of adaptation mechanisms have been developed or proposed, but there is comparatively little work on how to control these mechanisms to achieve soft real-time constraints. The goal of this project is to develop a control system that can competently advise an application as to how to make use of its adaptation mechanisms to achieve such constraints. The approach is to apply rigorous statistical prediction techniques to predict both how the application's resource demands will vary over time and how the environment's resource availability will vary over time. Such predictions, which are computed on demand at run-time, can then be used by the application or other user-level middleware services to choose an appropriate mapping for the application's tasks with which they can meet their constraints with high probability.<br\/> The contributions of this project will include a statistical characterization of the dynamic behavior and predictability of the demand for CPU and network resources in distributed interactive applications, a statistical characterization of the dyunamic behavior and predictability of the availability of these resources in distributed computing environments, practical tools for predicting resource demand and availability online and providing application-level performance predictions and adaptation advice to distributed interactive applications, and courses that will introduce graduate students and undergraduates to statistical prediction techniques and data analysis within the context of computer systems research and practice. The project will also produce at least two Ph.D. dissertations.<br\/> This project will build on the researcher's earlier work, which has shown , for a simplified problem, namely scheduling compute-bound real-time tasks using time series predictions of host load, that the approach described in this proposal can work and can lead to the kinds of contributions described above. In addition to producing scientific results, software artifacts, and educating students, the researcher believes that the path shown here will develop his reputation as the authority on prediction-based services for distributed interactive applications within the high performance distributed computing community.","title":"Career: A Prediction-based Approach to Responsive Distributed Interactive Applications","awardID":"0093221","effectiveDate":"2001-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["540138"],"PO":["565090"]},"58993":{"abstract":"Current systems that generate spatial sound for computer-based<br\/>applications employ Head-Related Transfer functions (HRTFs) and<br\/>simple models of room reflections to provide the acoustic localization<br\/>cues. However, the abilities of these systems to generate well-controlled<br\/>spatial sound streams are quite limited. Although it is possible to position<br\/>virtual sound sources to the left or right rather accurately, front\/back <br\/>confusion is common, localization in elevation is problematic, and localization<br\/>in range is unreliable.<br\/><br\/>This proposal describes a comprehensive program of research directed at solving<br\/>the major problems that are the cause of these limitations. These problems<br\/>are identified as (a) a mismatch between the HRTF used by the system and<br\/>the listener's actual HRTF, (b) a failure to provide the correct dynamic cues<br\/>that occur when the listener moves relative to the source, (c) a mismatch between <br\/>synthesized room reflections and the listener's experience or expectations, and<br\/>(d) a failure to render the correct spectral cues for familiar sounds,<br\/>such as human speech.","title":"Customized Spatial Sound for Human\/Computer Interaction","awardID":"0097256","effectiveDate":"2001-09-15","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}}],"PIcoPI":[151489,151490],"PO":["565227"]},"65296":{"abstract":"The proposal is a collaborative proposal involving University of Pittsburgh & Case Western Reserve University. The proposal plans to explore fundamental questions and associated middleware development issues to support broadcast and multicast data dissemination. When many people try to access the same information (for example, news sites during the Election), servers are often overwhelmed resulting in long delays. If an effective multicast capability existed across the Internet, a single server could have served all the requests, saving both computer power as well as reducing the amount of overall Internet traffic. <br\/><br\/> The approach will highlight gaps in the state-of-the-art and will research and explore new techniques and algorithms. The objectives include<br\/>1. transparently provide applications with data management services such as caching, scheduling and consistency maintenance, <br\/>2. improve internet functionality, performance, and cost-effectiveness, and<br\/>3. reduce the application development time while improving performance and reliability.<br\/><br\/>The proposal plans to make the information and developed software available to","title":"Collaborative Research: Middleware Support for Multicast Data Dissemination","awardID":"0123705","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4089","name":"NETWORK CENTRIC MIDDLEWARE SVC"}}],"PIcoPI":["534213","532922"],"PO":["7594"]},"66286":{"abstract":"The objective of this Small Grant for Exploratory Research (SGER) project is to establish a unifying taxonomy of features selection. Feature selection is used in used in various applications, including pattern recognition, machine learning, datamining or decision making, to choose the most appropriate subset of features among the available ones for the task. It can be viewed as an optimization problem of exponential time complexity along several dimensions. Many feature selection algorithms have been developed and deployed in real-world applications. However, there exists a distinct gap between what theory suggests and what practice reveals, and the proliferation of feature selection algorithms makes it very difficult to fully understand the various feature selection techniques and construct a general methodology for feature selection. It is time-critical that these issues are addressed and a unifying taxonomy is developed, to facilitate new research, development and tools in feature selection. This project explores the first step toward dealing with these issues. The task of establishing a unifying taxonomy for feature selection is accomplished in two steps: (1) defining a common platform to consider representative algorithms on the equal footing; and (2) building a unifying taxonomy to discover how the algorithms complement each other and what is missing. The approach includes collection of representative data and algorithms and conducting comparative experiments to determine the characteristics of the feature selection algorithms, their performance on different data and tasks. The expected results of this project include a contemporary survey, a unifying taxonomy of feature selection algorithms, and some potential solutions to the automatic selection problem -- being able to automatically choose the most suitable feature selection algorithm with given the problem conditions. The progress and updates of the project, and the resulting survey and unifying taxonomy will be available online.","title":"SGER: Toward a Unifying Taxonomy for Feature Selection","awardID":"0127815","effectiveDate":"2001-09-15","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["517806"],"PO":["563751"]},"57597":{"abstract":"This research develops efficient cryptographic tools which offer provable security guarantees. Such tools rectify the widely-recognized deficiency associated with extant provably-secure cryptosystems: their prohibitive computing demands. Indeed, despite the highly amplified security offered by provably-secure systems, efficiency considerations have prevented their widespread adoption; as a result, tools in common use typically involve ad-hoc methods designed with speed, rather than security, as their first priority. This re-search resolves this difficulty, constructing cryptographic tools (like encryption engines, digital signature schemes, and pseudo-random generators) which can simultaneously boast provable security guarantees and competitive efficiency. This program is undertaken in concert with an educational initiative which develops security and general information technology course material at the University of Connecticut. Security in provably-secure constructions is generally accumulated by repeated application of some underlying cryptographic primitive (a one-way function, for example). For a fixed underlying primitive, the computing time required to \"generate enough security\" to, say, encrypt a long message, depends essentially<br\/>on (i.) the quantity of security which can be quickly extracted from a single application of the underlying primitive, and (ii.) the total quantity of security necessary for the encryption process. This research ad-dresses both of these issues, developing provably-secure frameworks for cryptography which fully exploit the security capacity of underlying primitives and utilize this distilled security in the most effective manner.<br\/>Issue (i.) is addressed by the development of quantitative bounds for the security capacity of one-way functions and bounds on the computational complexity of extracting security from general one-way functions. Issue (ii.) is addressed by the development of a new family of cryptographic primitives, balancing provable security and competitive efficiency. For encryption, a focal point of the research, this is attained by coupling strong (information-theoretic) pseudo-random constructions with semantically secure encryption machinery. Such methods have direct applicability to encryption, cryptographically strong hashing, and pseudo","title":"CAREER: Efficient Cryptography with Provable Security Guarantees","awardID":"0093065","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["486281"],"PO":["499399"]},"59302":{"abstract":"Proposal #0098140<br\/>Duke University<br\/>Liu, Qing Huo<br\/><br\/>In this interdisciplinary project, we propose to develop fast algorithms for electromagnetic and elastic wave scattering in layered media. The impetus for such a joint effort is the ever increasing demand for efficient and accurate numerical simulation tools for electronic packaging and geophysical exploration where wave phenomenon plays an important role for design, evaluation, prediction and production. In both applications, there is a pressing need for fast solution techniques for full wave equations in layered media, namely, Maxwell's equations for electronic packaging and both electromagnetic and elastic wave equations for geophysical exploration. As the numerical issues involved in the solution of both wave equations share many common features, a concerted effort to develop fast algorithms for wave scattering in layered media will have a significant impact in both areas.<br\/><br\/>In a high-speed electronic package, interconnects are one of the determining factors for the speed performance of the system. Such a high order effect is not easily captured in either equations or tables, rendering conventional timing driven layout techniques inaccurate and obsolete. One must fully characterize<br\/>the interconnect structures to ensure on-chip signal integrity and to achieve the expected high-speed system performance. Therefore, there is a strong need for faster and more accurate full-wave electromagnetic analysis tools to extract parasitic parameters such as resistance, capacitance, and inductance.<br\/><br\/>On the other hand, in geophysical exploration for oil and gas, electromagnetic and acoustic sensors are widely used to probe complex geologic structures. The goal of electromagnetic and acoustic subsurface sensing is to infer from these measurements the electromagnetic and mechanical properties of the formation,<br\/>and to combine with other, such as nuclear, measurements to determine the petrophysical characteristics of the reservoir. The interpretation of these easurements, however, remains a challenging problem because of the complicated interaction of waves with the complex geologic structures and wellbore. The interpretation and processing of these measurements depend on fast and accurate forward and inverse solutions of lectromagnetic and acoustic waves in large-scale, highly heterogeneous media.<br\/><br\/>The main emphasis of this proposal is on numerical algorithm development relevant to direct problems for electromagnetic and elastic waves propagation in layered media. A frequency domain integral equation formulation will be used. Major tasks include fast calculation of dyadic Green's functions for general<br\/>layered media; fast matrix-vector multiplication and robust preconditioner for matrix solver; construction and study of high order basis functions for large targets; application of the obtained numerical algorithms in electronic packaging and geophysical exploration.<br\/><br\/>Both PI's have extensive experience in the proposed application areas---parameter extraction for VLSI and RF component design (Cai) and geophysical subsurface sensing and electronic packaging (Liu). The<br\/>collaborated research will greatly benefit the electronics and oil exploration industry, and our research and educational programs in electrical engineering and applied mathematics and scientific computation.","title":"Fast Algorithms for Wave Scattering in Layered Media for Electronic Packaging and Geophysical Exploration","awardID":"0098140","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["542982","478385"],"PO":["321058"]},"59203":{"abstract":"This award is to continue an REU site program at the Geophysical Institute of the University of Alaska. Building on success since 1987, this program will give further research opportunities to undergraduates majoring in the physical sciences. The program objective is to acquaint undergraduates with life and work at a research institute. The objective is achieved by providing summer educational work opportunities in which undergraduates become interns participating in the research activities at the Institute. Research topics concentrate on space physics and aeronomy, but also extend to atmospheric science, and in a minor way to solid state physics and laser physics. Students are assigned to conduct research with individual principal investigators who direct their work and serve as mentors during their internship. A common program of weekly lectures and field trips is designed to expose interns to fields of research beyond the scope of their project. Through their close relationships with their mentors, contacts with graduate students, attendance at seminars, lectures, and thesis defenses, and participation in field trips, the interns gain a first hand perspective on life and work as a research scientist.","title":"REU Site: Summer Research Experience for Undergraduates in the Geosciences","awardID":"0097871","effectiveDate":"2001-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T377","name":"DIA-MASINT CONSORTIUM PROJECT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T489","name":"DIA-MASINT CONSORTIUM PROJECT"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0602","name":"Division of DIV ATMOSPHERIC & GEOSPACE SCI","abbr":"AGS"},"pgm":{"id":"1522","name":"PHYSICAL METEOROLOGY"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0602","name":"Division of DIV ATMOSPHERIC & GEOSPACE SCI","abbr":"AGS"},"pgm":{"id":"1525","name":"PHYSICAL & DYNAMIC METEOROLOGY"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0602","name":"Division of DIV ATMOSPHERIC & GEOSPACE SCI","abbr":"AGS"},"pgm":{"id":"5750","name":"MAGNETOSPHERIC PHYSICS"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0602","name":"Division of DIV ATMOSPHERIC & GEOSPACE SCI","abbr":"AGS"},"pgm":{"id":"X808","name":"OFFICE OF NAVAL RESEARCH-"}}],"PIcoPI":["529481","454014","387218"],"PO":["476703"]},"59258":{"abstract":"0098037<br\/>Automated Analysis of Probabilistic Open Systems<br\/>S. Purushothaman Iyer<br\/>W. Rance Cleaveland (Co-PI)<br\/><br\/>Concurrent systems such as network protocols and net-centric programs<br\/>are difficult to build and debug because of the potential they exhibit<br\/>for unintended process interactions. The development of net-based<br\/>applications which have to contend with probabilistic guarantees from<br\/>lower-levels is even more difficult as they need to be functionally<br\/>correct and also satisfy reliability\/performance constraints. This<br\/>project will investigate how formal methods can be extended to address<br\/>both logical correctness and reliability\/performance constraints.<br\/><br\/>The current project will explore semantic theories of systems that<br\/>have both non-determinism and probabilistic choice. In particular,<br\/>notions of equality and approximate equality of system behaviors will<br\/>be investigated. Furthermore, the effect of these notions on<br\/>compositional reasoning will also be studied.<br\/><br\/>The second topic of the proposed work will be a thorough comparison of<br\/>the semantic theories developed in this project against traditional<br\/>approaches to dealing with non-determinism and probabilistic choice.<br\/><br\/>Finally, practical algorithms for process minimization and for<br\/>checking equality (and approximate equality) of processes will be<br\/>designed and implemented in the Concurrency Workbench of New Century.<br\/>Case studies, to evaluate the proposed theories, will also be<br\/>constructed and studied.","title":"Automated Analysis of Probabilistic Open Systems","awardID":"0098037","effectiveDate":"2001-09-15","expirationDate":"2005-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["78952","417615"],"PO":["564388"]},"60182":{"abstract":"EIA-0101242<br\/>James Griffioen<br\/>University of Kentucky<br\/><br\/>CISE Research Infrastructure: The Metaverse: A Laboratory for Digital Media Networks<br\/><br\/>The primary goal of our research is to investigate and develop new techniques to support networked, collaborative, visually immersive environments and applications. The objective is to design visually compelling collaborative spaces (where people interact with computer simulations and each other) that are inexpensive, extensible, automatically configurable, adaptable, and scalable. The work involves an interdisciplinary team of researchers exploring system-level issues including visualization, network communication, and computer vision, with others studying application-level issues such as scientific (CFD) visualization, presentation of new-media\/art, and the educational <br\/>efficacy and impact of the technology.<br\/><br\/>The requested infrastructure will be used to create three physically separate, networked visualization laboratories supported by two new technical staff. Each visualization environment will have a distinct configuration and objective. The CORE (COllaborative Rendering Environment) will explore compelling collaborative immersive spaces, while the VIDE (Visually Immersive Display Environment) investigates stereo visualization. Unlike the CORE and VIDE, where users are immersed in pixels, the DOME (Digital Object Media Environment) will be a head-tracked ``outside looking in'' configuration. The environments will demonstrate the versatility of the underlying base technology by using the same techniques to support multiple application domains. A fourth environment will be deployed at the University of Puerto Rico.","title":"CISE Research Infrastructure: The Metaverse: A Laboratory for Digital Media Networks","awardID":"0101242","effectiveDate":"2001-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["530999","483390","494196",154569,"359059"],"PO":["539087"]},"61271":{"abstract":"This research is concerned with the development, analysis <br\/>and empirical evaluation of algorithms for information <br\/>retrieval and data mining, primarily using spectral analysis. <br\/>A partial list of the fundamental questions<br\/>being addressed are: How should data be stored,<br\/>organized and processed so as to allow the most effective retrieval of<br\/>information? How can ``important'' structure and ``meaningful''<br\/>patterns be found within a large data-set? How and when can this<br\/>hidden structure be used to facilitate determination of missing data<br\/>or to ``clean'' data that is imprecise or partially incorrect?<br\/>What are appropriate models for data generation, and how can<br\/>these models be used to improve the design of data mining algorithms?<br\/><br\/>The researchers are studying applications that have already <br\/>received a great deal of attention and on which<br\/>empirical success has been achieved, including object<br\/>clustering and web site ranking. In addition, they are designing <br\/>and analyzing algorithms, and developing and analyzing models <br\/>for newer data mining problems, including collaborative filtering, <br\/>topic distillation, spam detection and prevention, and hierarchical<br\/>clustering. Matrix perturbation theory is the foundation for the <br\/>development of theoretical results. The researchers are also studying<br\/>new techniques for speeding up the computation of the SVD.<br\/>The theoretical research is being complemented by<br\/>experimental evaluation on real data sets.","title":"Spectral Analysis for Data Mining","awardID":"0105406","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["450784"],"PO":["279077"]},"66881":{"abstract":"0130861 <br\/>Srinivas Aluru<br\/>Iowa Stae University<br\/><br\/>CISE Research Resources: Acquisition of a Cluster for Experimental Parallel Computing Research in Scientific Computing and Computational Biology<br\/><br\/>This project provides funding to Department of Electrical and Computer Engineering at Iowa State University for acquisition of a cluster of 64 Pentium workstations connected by a high-speed network. The cluster will be used as a distributed memory parallel computer and will be dedicated to support research in parallel computing, bioinformatics and computational biology, and scientific computing. More specifically, the equipment will be used for research in: parallel algorithms and software for gene identification, parallel algorithms and software for electromagnetic scattering analysis, scalable parallelization of tree-based data structures, and integrated software visualization environments for program correctness, validation and optimization. Experimental studies will be conducted to evaluate the performance of the parallel algorithms developed and the knowledge gained from such studies will be used to derive efficient, scalable, parallel implementations. Acquisition of the instrumentation will enable researchers to develop, demonstrate and disseminate comprehensive software systems that are capable of solving large-scale scientific applications of current relevance.","title":"CISE Research Resources: Acquisition of a cluster for experimental parallel computing research in scientific computing and computational biology","awardID":"0130861","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["182948","438098","565135","526244","532976"],"PO":["557609"]},"63130":{"abstract":"The proposed research is aimed at designing and developing new resources for information and knowledge management in a heterogeneous distributed environment for law enforcement. Important problem areas to be addressed are: system scalability, group-based monitoring of dynamically changing data, analyzing group behavior in search and notification, and incremental searching, among others<br\/>The technical approach will be implemented in an agent-based framework and empirical studies will be performed to evaluate the proposed prototype in two law enforcement agencies.","title":"ITR\/IM(IDM): Developing A Collaborative Information and Knowledge Management Infrastructure","awardID":"0114011","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["548216","387279"],"PO":["433760"]},"66892":{"abstract":"EIA-0130887 <br\/>Enrico Pontelli<br\/>New Mexico State University<br\/><br\/>The Laboratory for Logic, Databases, and Advanced Programming (LLDAP) plans to acquire modern computing equipment to create an infrastructure for parallel and distributed computing and for software development for autonomous agents. The equipment requested consists of four Pentium III shared memory machines (with four CPUs each) to provide shared memory programming support. The four machines will be connected using fast gigabit Ethernet, creating the testbed for experimenting with distributed memory programming. The Project will also involve the acquisition of a set<br\/>of five autonomous robots. The equipment will be used to support research in three inter-related projects: (1) The goal of the first project is to pursue the development of technology to support exploitation of different forms of parallelism from traditional logic programming and from constraint programming languages, (2) The second project develops technology for the creation of planners capable of dealing with incomplete knowledge, dynamic domains, and sensing actions, (3) The goal of the third project is to develop technology to promote accessibility of Web documents in the context of Web-based course-ware engineering.","title":"CISE Research Resources: Parallel Logic and Constraint Programming, with Applications to Planning and Web Accessibility","awardID":"0130887","effectiveDate":"2001-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["482838","561141","435957","385617"],"PO":["557609"]},"66661":{"abstract":"EIA-0129731<br\/>Robert R. Birge<br\/>Syracuse University<br\/><br\/>Title: Optimized Bacteriorhodopsin Proteins for Photonic and HolographicMemory Storage<br\/><br\/>The protein bacteriorhodopsin is being optimized for bioelectronic and photonic applications through site directed mutagenesis, random mutagenesis and directed evolution. The native protein has many characteristics that make it a nearly optimal photonic material, but further optimization is necessary to achieve competitive performance in computer applications. The goal is to generate protein variants that are optimized for holographic associative memories and large scale volumetric memories. The former memory system is based on Fourier-transform holography, and the protein will be optimized for thermal stability, quantum efficiency and holographic efficiency. <br\/><br\/>The large scale volumetric memory is based on a branching reaction out of the main photocycle. The protein is being optimized for this application by increasing thermal stability, branching efficiency and long-term stability of the branched photoproduct. Genetic engineering is the best method for achieving all three goals simultaneously, and directed evolution is being studied as one possible method of rapidly achieving these goals simultaneously. This is a collaborative project involving researchers at the W. M. Keck Center for Molecular Electronics at Syracuse University and molecular biologists at the University of Connecticut.","title":"Bio-QuBIC: Optimized Bacteriorhodopsin Proteins for Photonic and Holographic Memory Storage","awardID":"0129731","effectiveDate":"2001-09-15","expirationDate":"2004-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}}],"PIcoPI":["380924","259496","315512"],"PO":["565223"]},"66793":{"abstract":"This DARPA\/NSF workshop will take place on September 29-30, 2001, on the campus of the California Polytechnic State University, San Louis Obispo, CA. The workshop will provide a forum for roboticists, human- computer interaction experts, psychologists, sociologists, cognitive scientists, and communication experts, to examine the state of the art in the area of human-robot interaction. About 60 participants will be invited from the academic community, industry, and government.","title":"DARPA\/NSF Study on Human-Robot Interaction will be held September 29 - 30, 2001 in San Luis Obispo, California","awardID":"0130511","effectiveDate":"2001-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":[173143],"PO":["234178"]},"63042":{"abstract":"0113539 Kaner Florida Institute of Technology<br\/>\"Improving the Education of Software Testers\"<br\/><br\/>This is a project that lays the groundwork for significant improvements in the quality of academic and commercial courses in software testing. This is new ground since the skills used in the field are not well identified and there are few collections of exercises or drills designed to help polish those skills. Software testing is an important area of work within information technology, but it has been largely ignored within the educational community. As a result, the software industry faces a shortage of appropriately educated people to do this work. This project develops foundational material for teaching introductory and advanced classes on software testing, including: a collection of examples of software errors (posted on a web site, well-described, with screen shots, and suitable for use in class), identification and descriptions of specific skills involved in software testing (published at conferences and in articles that are available on the web), sample exercises for students (for use as course assignments or for self-paced study) and a smaller separate collection for teachers (for possible use in exams), free software versions of classroom-level versions of useful testing tools (a \"classroom version\" is intended to teach the concept of that kind of tool, and to handle tasks that are as complex as the student might run into as an undergraduate), research (and reports on the results of the research) on the usefulness of Whittaker's software fault model as an organizing structure for presenting a wide range of key testing techniques in class, extension of Kaner & Bach's characterizations of testing styles\/strategies, bringing together research and practitioner literature into a structure useful for presenting a wide range of key testing strategies in class, and workshops (and an email discussion group) on the teaching of software testing. The core societal benefit of this work lies in its high potential for improvement of software testing and through that, software quality.","title":"ITR\/SY+PE: Improving the Education of Software Testers","awardID":"0113539","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}}],"PIcoPI":["340480"],"PO":["551712"]},"64164":{"abstract":"This RUI project is devoted to studies concerning the implementation, visualization, and analysis of Probabilistic Road Maps (PRMs). The PRM has been actively studied in recent years, and is increasingly seen as an important, if not the best, tool for certain robotic motion planning problems. New probabilistic roadmap heuristics will be developed and experimentally verified. To study the underlying problem and to verify developed strategies, supporting visualization software will be developed. This work will provide a research experience for up to nine undergrads at a place, which is primarily a teaching university.","title":"RUI: Motion Planning: Probabilistic Roadmap Methods and Visualization Strategies","awardID":"0118097","effectiveDate":"2001-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":[165391],"PO":["317663"]},"57410":{"abstract":"Exponentially increasing multimedia information content has become a problem at the<br\/>heart of modern communication networks. This is a paradigm shift from traditional com-<br\/>munication networks, where the primary function is information transmission, and where<br\/>quality of service improvements are attainable through better dimensioning of bandwidth<br\/>and switching resources. However, in networks where information storage plays a central<br\/>role, major improvements in quality of service can not be successful without the help of<br\/>caching, prefetching and\/or mirroring of information. It can be argued that even if an<br\/>unlimited amount of free bandwidth were available, the concentration of information on a<br\/>small number of servers would cause server overloads, resulting in unacceptable download<br\/>latencies.<br\/> This general problem has created the explosion of research studies that are to be found<br\/>in the network systems engineering literature on Web caching. Although this work has<br\/>contributed important engineering solutions, much of it is ad hoc and informal. Indeed, in<br\/>the large literature on caching research, it is rare to find papers dealing with mathematical<br\/>foundations, especially those underpinning stochastic models. Also, one rarely finds proofs in<br\/>a rigorous setting of nontrivial stochastic or average-case properties of caching structures and<br\/>algorithms. It is our thesis here that more systematic approaches are needed. This proposal<br\/>describes a project to meet this need; more generally, we outline a systematic treatment<br\/>that focuses on fundamental design issues, one that, in dealing with these issues, integrates<br\/>experimentation, analysis and statistical measurements.<br\/> Network cache design objectives are reductions in access latency, traffic congestion, and<br\/>server loads. These objectives can be attained only through a thoughtful design that ad-<br\/>dresses many important and challenging research topics. Some of the fundamental questions<br\/>that remain without definitive answers include: dynamic caching and caching with expiration<br\/>times; design and analysis of easily implemented heuristic algorithms; impact of locality in<br\/>request sequences on caching performance; caching and prefetching in low bandwidth access<br\/>environments, with a special emphasis on wireless Web accesses; cache allocation and sizing<br\/>problems; and Web-graph performance modeling. Extending the knowledge base and deep-<br\/>ening our insight into these and several other equally fundamental caching system design<br\/>problems is the main theme of this proposal. The ultimate goal is to utilize this improved<br\/>knowledge base to develop an experimental testbed for achieving practically feasible and<br\/>efficient network caching systems.<br\/> The inherent complexity of the research topics identified here, and the network caching<br\/>problem as a whole, necessarily call into play all available research tools. Thus, methodologi-<br\/>cally, the scope of the proposed research ranges from mathematical modeling and analysis to<br\/>statistical measurements and experimentation. The impact of our results, by their interdis-<br\/>ciplinary nature, will not just be limited to designing multimedia network caching systems,<br\/>but will potentially lead to improved problem solving techniques in related fields of computer<br\/>algorithms, software engineering, probability theory, and operations research.","title":"Network Caching for Efficient Multimedia Content Delivery","awardID":"0092113","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["451494","493395"],"PO":["565090"]},"58983":{"abstract":"This research involves the mitigation of multipath interferences<br\/>in a frequency-selective fading channel. As broadband digital wireless<br\/>communications is more demanded than ever, such as wireless image\/video<br\/>web browsing and wireless data transmission, the technical challenges<br\/>are exponentially increasing. One of such challenges is that, when the<br\/>bandwidth of a channel becomes wider, there are more severe multipaths<br\/>in a wireless system. This implies that the multipath interference<br\/>mitigation becomes more important than ever.<br\/><br\/>Modulated coding (MC), a convolutional coding defined on the complex<br\/>field, has been recently proposed by the PI to optimally mitigate<br\/>intersymbol interferences (ISI) when the ISI channel is known at both<br\/>the transmitter and the receiver. The advantage of MC is that, since<br\/>the arithmetic operations of both MC and ISI are over the complex field,<br\/>they can be naturally combined together, which provides the convenience<br\/>of the optimal MC study for a given ISI channel. Since the encoding<br\/>simplicity of the MC, it is also convenient for further adding a<br\/>conventional error correction coding (ECC) before the MC. It has been<br\/>shown that the combined MC and turbo coding of an ISI channel may<br\/>outperform the AWGN channel capacity at low SNR. As an example, for the<br\/>two tap ISI channel [0.7071,0.7071], the bit error rate is 0.00001 at the<br\/>code rate 1\/4 and the SNR E_b\/N_0=-1.15 dB, which is above the AWGN<br\/>channel capacity. The disadvantage of the previous MC study is that the<br\/>transmitter needs to know the ISI channel, which although may be possible<br\/>for some applications, such as storage channels and wireline channels,<br\/>may not be practical for some other applications, such as wireless<br\/>channels. The aim of this proposal is to optimally design and update MC<br\/>without the full knowledge of the ISI\/multipath channel at the<br\/>transmitter with applications, in particular, in wireless communication<br\/>systems. Due to the simple structure of MC, the MC update at the<br\/>transmitter is possible, which is unlike the existing coding schemes.","title":"Modulated Coding For Frequency-Selective Multipath Channels","awardID":"0097240","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["438661"],"PO":["348215"]},"56211":{"abstract":"We are currently witnessing an incredible transformation in the way we access information and<br\/>computing power. With small handheld devices such as personal digital assistants, cellular phones,<br\/>and palmtop computers, users are taking their computers with them more often than not. Fur-<br\/>thermore, with the developments in wireless technologies, users are beginning to slowly move away<br\/>from their dependence on wired access to their information. While this trend is building significant<br\/>momentum, the types of information that are accessed through these devices is still severely lim-<br\/>ited by the wireless media. Given the bottle-necks associated with today's power-limited portable<br\/>devices, the limitation due to channel conditions has not yet been felt by the user; however the<br\/>strain on the underlying wireless network will only get worse.<br\/> The goal of the proposed research is the construction of high performance algorithms for tetherless<br\/>access which consider overall system goals through joint optimization across multiple layers. The<br\/>objective will be to solve problems which connect the physical layer to the application layer. In the<br\/>past, a classical approach to wireless communication system design was undertaken { a modular<br\/>approach loosely based on the Open Systems Interconnection reference stack model. For wired<br\/>communication networks, such a separation of activities led to functioning systems offering solid<br\/>performance. However, the deleterious effects of the wireless communications channel force the<br\/>investigation of all possible methods to improve performance. Thus, to provide the desired fidelity<br\/>and to transport high-data rate information over the wireless medium, joint optimization across<br\/>multiple communication layers will be necessary. To focus the research, wireless transport of video<br\/>via Direct Sequence Code-Division Multiple-Access (DS-CDMA) will be considered.<br\/> In this project, we propose the research and development of video streaming algorithms that are<br\/>more suited for wireless transmission using DS-CDMA as an access methodology. There are several<br\/>reasons why this project is necessary. First, current research onmulti-rate detection and estimation<br\/>algorithms at the physical layer are not tailored for specific application layer data. Second, many of<br\/>the video transmission schemes over wireless networks have assumed fixed bit-error rates that are<br\/>introduced by the wireless transmission. In CDMA systems, the bit-error rate is highly dependent<br\/>on the channel and the number of active users, both of these processes are time-varying; however,<br\/>this variability in bit-error rates has not been fully addressed at the application layer. Third, the<br\/>elasticity ofvideo can be exploited to design efficient algorithms which can take advantage of the<br\/>shape of video streams as well as time-varying channel conditions to offer desired quality-of-service.<br\/> This research project has three principle goals:<br\/><br\/>Investigation of efficient multi-rate detection and estimation algorithms for wireless physical<br\/>media transmission.<br\/><br\/>Investigation of video streaming techniques for wireless networks that use underlying network<br\/>condition feedback to dynamically adjust the forward error correction used to protect the<br\/>video data.<br\/><br\/>Investigation of the integration of physical layer media characteristics and higher-level video<br\/>applications to provide the highest quality-of- service to applications.","title":"Efficient Integration and QoS Management of Video over Wireless Networks","awardID":"0087761","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["515828","518376"],"PO":["565090"]},"58324":{"abstract":"The scalability of the Internet hinges on our ability to tame the unpredictability associated with its open architecture. This project investigates the development of basic control strategies for reducing traffic burstiness and improving network utilization. Such strategies can be applied through Traffic Managers (TMs)-special network elements strategically placed in the Internet (e.g., in front of clients\/servers or at exchange\/peering points between administrative domains). We believe that the incorporation of such control functionalities will be key to the ability of the network infrastructure to sustain its own growth and to nurture the Quality-of-Service (QoS) needs of emerging applications.<br\/><br\/>Although there have been some recent advances in building network elements capable of wire-speed processing, there is a need for fundamental research into the basic QoS control capabilities that these TMs should implement. This set of capabilities have to be identified and implemented in a programmable, scalable architecture that allows for the easy and effective composition of services. Such a flexible architecture is highly desirable as the Internet continues to evolve and users demand new kinds of service for their applications. <br\/><br\/>TMs should be capable of quickly inspecting and classifying packets as they go by (e.g., marking packets into precedence classes), and should control the transmission of these packets (e.g., through pacing, scheduling, or selective dropping) to ensure desirable properties (e.g., satisfaction of jitter requirements, compliance with TCP friendliness, or improved fairness across flows).<br\/><br\/>In this proposal, we will address the design of dynamic dos control programmable TMs. We focus on basic capabilities that could be employed at different levels of the control architecture. These capabilities include differentiated, aggregate and proxy controls. The following are examples of how such control strategies would be employed by TMs.<br\/><br\/>Differentiated Control enables TMs to route flow aggregates with divergent characteristics on separate communication paths. Unlike traditional routing, our routing metrics will respect bursitis measures, such as self-similarity and traffic correlation:<br\/><br\/>Aggregate Control enables TMs to use congestion control mechanisms for collections of flows that share the same bottleneck. Unlike traditional congestion control, \"Congestion-equivalent\" flows are identified based on measures of relationship (such as cross-correlation and cross-covariance) and managed as a set; <br\/><br\/>Proxy Control enables TMs to filter out variability (e.g., loss, delay jitter) at shorter time-scales. Such a functionality is crucial for improving the stability and effectiveness of control mechanisms that operate over longer time-scales (e.g., end-to-end). Unlike traditional a-hoc proxy approaches, our approach will take into account the length and characteristics of the control loops that get formed between the TM and the end-systems.<br\/><br\/>Our design will be based on mathematical foundations from control theory and wavelet analysis. These methods enable thorough analysis and control of system dynamics at different time-scales and an understanding of the complex interactions among them. Specifically, functionality's at different levels of a TM architecture will be developed based integrated control-theoretic models. These models will account for \"nested\" control loops that are driven by system characteristics, which are identified using wavelet analysis of passive measurements. TMs that are designed in such and integrated fashion, could increase flow throughput, reduce flow jitter and response time, and improve the stability, utilization, and scalability of the network.<br\/><br\/>We plan to implement our dos controls in a tested deployed in a controlled local setting as well as over the Internet. Our implementations will be based on emerging technologies, such as Diffserv and MPLS, and will be stressed by bandwidth-and QoS-demanding applications. Our testbed will provide a programming interface to softservices, in which capabilities can be turned on or off and control parameters can be dynamically adjusted. To this end, we have secured the support of industrial research laboratories and start-up companies-namely Lucent's Bell Labs, Cisco Systems, Nortel Networks, and Quarry Technologies. Specifically, we intend to use Lucent's Network Element for Programmable Packet Injection (NEPPI). NEPPI provides an ideal foundation upon which to implement the control policies we propose to develop. This project is a collaborative efforts between Boston University (Is: Ibrahim Matta, Azer Bestavros, and Mark Crovella) with expertize in characterization, measurements and control of Internet traffic, and University of Arizona (PI: Marwan Krunz) with expertize in traffic modeling, multimedia and wireless QoS.","title":"Collaborative Research: A Control Theoretic Approach to the Design of Internet Traffic Managers","awardID":"0095988","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["562061","486062","438360"],"PO":["292741"]},"57235":{"abstract":"EIA-0091526<br\/>Robert Carlitz<br\/>Information Renaissance<br\/><br\/>Digital Government: The Rulemaking Universe<br\/><br\/>This award will support planning for a larger project in the area of Federal on-line rulemaking, an important part of the Federal regulatory process during which the Internet and the Web will serve to support the consultative dialog between interested parties and agencies developing or modifying rules. Several Federal Agencies are potential partners in the larger project, including the Environmental Protection Agency, the Department of Transportation, and the National Marine Fisheries Services.","title":"Digital Government: The Rulemaking Universe","awardID":"0091526","effectiveDate":"2001-09-15","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}}],"PIcoPI":[147254],"PO":["371077"]},"56025":{"abstract":"Providing reliable multimedia communications in mobile multihop wireless networks is a formidable<br\/>challenge. Communication networks in which all users are potentially mobile and untethered to any fixed<br\/>wireline infrastructure arise in a variety of contexts. The mobile users of the system desire reliable<br\/>communications, including real-time voice and video, notwithstanding the lack of a fixed infrastructure. That<br\/>is, the disconnection probability should be low and certain quality of service (QoS) guarantees should be<br\/>provided: for many applications, the information exchanged should have low delay, low jitter and a low loss<br\/>rate.<br\/> In a fully distributed wireless network, there is no fixed (wired) backbone that can be exploited to<br\/>centralize some of the network management and routing functions. In order to provide the desired functionality, the mobile terminals must be organized into a network that has some hierarchical organization or reliable structure that is maintained (at least to some degree) under varying network connectivities. This structure should, if possible, be maintained in a distributed fashion, without reliance on a centralized controller.<br\/> Our approach to solving the ad hoc network problem is to use an embedded hierarchical structure, with<br\/>physically different networks at the various levels. Recently, we have proposed the employment of a mobile<br\/>backbone to support guaranteed QoS (as well as best effort) applications for mobile networks. Certain mobile<br\/>terminals are assigned to effectively serve as mobile base stations, and these selected users (\"backbone nodes\") together with their interconnecting communication links constitute the mobile backbone. The backbone network consists of a mesh topology with point-to-point links used to interconnect neighboring backbone nodes. The mobile backbone, which has a functionality analogous to a fixed backbone in a cellular network, is then exploited to make the routing, access control, scheduling and congestion control problems tractable. Such mobile backbone networks can also be exploited to supplement an employed ad hoc mobile network that lacks a transport backbone, and is thus not able to readily provide QoS guarantees to multimedia applications.<br\/> This research proposes a new approach to synthesizing communication backbones for mobile wireless<br\/>networks. The backbone will satisfy user-specified accessibility and connectivity requirements and will support guaranteed QoS objectives. The mobile backbone construction algorithm will incorporate terminal positional information and a distance metric in order to discern geographical sections of the network with high concentrations of users. Pattern recognition based techniques will be developed and employed for the first time in the context of telecommunications networks in order to discern compact sections of the network, and to choose representative backbone nodes for these compact sections. This approach provides a new means of decomposing a global network into smaller simpler subnetworks, on each of which a backbone construction<br\/>algorithm can then be run.<br\/> Once the network has been divided into subnetworks (termed itclustersln), a backbone is then constructed<br\/>for each separate cluster. These separate intra-cluster backbones are then linked together to form a composite global backbone network with the desired functionality.<br\/> New graph-theoretic algorithms will be developed to synthesize the separate intra-cluster backbones.<br\/>These methodologies will incorporate deterministic and probabilistic relaxations of the backbones accessibility features. Investigations will also include preprocessing of the input graph that models the communications network and subgraph removal techniques to determine optimal topologies that can be exploited for backbone synthesis. Robust algorithms will be developed that ihlook aheadlp to possible future graph scenarios (based on terminal movement) and choose the best backbone for the ensemble.<br\/> The global backbone construction algorithms will be simplified by decoupling the inter-cluster backbone<br\/>connectivity requirements from the intra-cluster connectivity requirements. A mobile backbone will be<br\/>designed with a single user-specified inter-cluster connectivity requirement, but may have different user-<br\/>specified intra-cluster connectivity requirements for each cluster. The inter-cluster backbone will be<br\/>constructed using graph-theoretic techniques wherein each cluster is treated as a single node a supernode.<br\/>The mobile backbone construction algorithms will be analyzed and evaluated to optimize methods of<br\/>backbone reconstitution under failures caused by nodal movement, environmental variations and loading<br\/>fluctuations. Extensive analyses and simulations will be performed to evaluate the performance of the<br\/>proposed backbone construction protocol under several scenarios that corr","title":"Mobile Backbone Networks","awardID":"0087148","effectiveDate":"2001-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[143788],"PO":["565090"]},"59314":{"abstract":"Regression testing is an important, but expensive part of modern<br\/>software development practices. Central hypotheses of the project are that several key issues have not been adequately considered in current research and that these issues can be exploited, singly and in<br\/>combination, to control the regression testing process. If true, then<br\/>successful research will lead to cheaper, faster, more predictable and<br\/>more effective regression testing processes, thereby saving a great<br\/>deal of time and money throughout the industry. Consequently, the project conducts the following experiments:<br\/> 1. Compare different RTS techniques and to explain how features of their inputs affect their performance.<br\/> 2. Measure how different application policies (rules that trigger regression testing) affect RTS performance.<br\/> 3. Develop and evaluate, using the information from experiments 1 and 2, data-driven (based on each test case's prior performance)<br\/>techniques for prioritizing test case execution, for determining the<br\/>order in which changes are integrated, and for pruning and optimizing<br\/>the original test suites.<br\/> 4. Explore whether and how these techniques can be combined and what effect that has, and<br\/> 5. Validate these models, techniques, and heuristics in an on-line, long-term study of a large software system.","title":"Empirical Investigations of Large-Scale Regression Testing","awardID":"0098158","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["485900"],"PO":["564388"]},"59358":{"abstract":"Practical Persistent Data Structures<br\/><br\/>The legal phrase \"status quo ante\" refers to reverting to a previous<br\/>state of affairs. The same concept frequently arises in computer<br\/>science. For example, most word processors include an \"undo\" feature that<br\/>nullifies the most recent changes and returns the document to its previous<br\/>state. Unfortunately, most current methods of organizing data do not<br\/>support the ability to revert to previous states, or at least do not do<br\/>so efficiently. This research involves designing and evaluating practical<br\/>techniques for supporting such an ability.<br\/><br\/>Technically, a data structure is called \"persistent\" if updating the data<br\/>structure creates a new version without destroying the old version. After<br\/>the update the two versions co-exist, and future operations can refer to<br\/>either or both. Persistent data structures are sometimes called immutable.<br\/>Persistent data structures have applications in computational geometry,<br\/>transaction processing, editing, functional programming, compilers, and<br\/>many other areas. In addition, persistent data structures have several<br\/>important non-algorithmic benefits, including elimination of certain<br\/>families of bugs, increased security, and decreased need for synchronization<br\/>among multiple processors. The objectives of this project include - inventing<br\/>new persistent data structures, with an emphasis on practicality rather than<br\/>merely theoretical efficiency, - extracting from these new data structures new<br\/>design and analysis techniques suitable for a persistent environment, and -<br\/>experimentally evaluating the practical efficiency of competing persistent<br\/>data structures.","title":"Practical Persistent Data Structures","awardID":"0098288","effectiveDate":"2001-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":[152454],"PO":["499399"]},"57059":{"abstract":"EIA-0090832<br\/>Alan Borning<br\/>University of Washington<br\/><br\/>TITLE: Software Architectures for Microsimulation of Urban Development, Transportation and Environmental Impact<br\/><br\/>Patterns of land use and available transportation systems play critical role in determining the economic vitality, livability, and sustainability of urban areas. Transportation interacts strongly with land use; different kinds of transportation systems induce different patterns of land use, while at the same time, different kinds of land use induce demands for different kinds of transportation systems. Both land use and transportation have substantial environmental effects, in particular on emissions, resource consumption and open space. Government policies and investments affect patterns of land use and transportation in many complex and sometimes unintended ways.<br\/><br\/>This proposal will develop a fully disaggregated Microsimulation system for modeling urban development and government investments and policies related to transportation, land use and environment. Technical support can play a critical role in fostering informed civic deliberation and debate on these issues by allowing urban planners and stakeholders to be able to consider different scenarios-packages of possible policies and investments-and then, based on these alternatives, model the effects of these scenarios on patterns of urban growth and redevelopment, of transportation usage, and resource consumption, over periods of twenty or more years. This proposal will concentrate on two related computer science areas; the software engineering issues that arise in the design and construction of such a large, complex model, and the human computer interaction issues that arise in using it.<br\/><br\/>A set of government partnerships is an integral part of this research. At the federal level, there are commitments from the Federal Highway Administration and the Federal Transit Administration (both units in the Department of Transportation), and at the local level, from the Puget Sound Regional Council, the governmental organization charged with land use and transportation planning.","title":"Digital Government: Software Architectures for Microsimulation of Urban Development, Transportation, and Environmental Impact","awardID":"0090832","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}}],"PIcoPI":["438603","450771","440155"],"PO":["371077"]},"59369":{"abstract":"As integrated circuit speed and density increases, more circuits fail due to delay faults -- manufacturing defects that cause the circuit to operate at a speed slower than intended. Such circuits either cannot be used or must be sold at a lower price. The behavior of delay faults is complex, and traditional manufacturing test approaches are increasingly ineffective in detecting them. This research attacks this problem by developing a novel realistic delay fault model. This model is being used to develop powerful techniques for fault simulation, automatic manufacturing test generation, and diagnosis for next-generation integrated circuits. This work is being done in cooperation with U.S. semiconductor manufacturers. These test and diagnosis techniques are being integrated into a state-of-art software system and will be tested on real manufacturing problems.<br\/><br\/>The new realistic delay fault model considers resistive bridges and opens, the impact of process variation on interconnect, device, and defect parameters, and the influence of interconnect parasitics. Fast layout and parasitic extraction algorithms, and model order reduction techniques are being developed to reduce model cost for a given accuracy level. The model is encapsulated in a parameterized static timing analysis engine for use in fault simulation, test generation and diagnosis. A constraint-based fault coverage analysis is used to determine fault coverage over a set of vectors. Together, these techniques can accurately predict fault coverage and achieve very high delay fault coverage for scan-based CMOS logic circuits.","title":"Delay Fault Modeling, Test, and Diagnosis","awardID":"0098329","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["486559","196484"],"PO":["562984"]},"60480":{"abstract":"This project explores the role of balanced information diets in information filtering. Information filtering is an increasingly important response to the problem of information overload. Community-based information filters are particularly beneficial because they can they can strengthen communities and recognize community tastes. The goal of this project is to investigate the benefits that can be realized by having the information filter balance the information presented to the user across the available topics. The project will explore how people forage in information abundance, what interfaces best support balanced information diets, and how much users like balanced information filters. The results will be interfaces to information through which users will receive the right amount of information on each topic, according to their interest in that topic. The information filter will learn which of the disparate sources of information are best for which topics, and present articles from the best sources. The research will also explore the effect of balanced information filtering on communities. The result will be balanced information filters that strengthen communities by ensuring sufficient overlap in information diets among community members.","title":"Reading a Balanced Diet: Foraging in Information Communities","awardID":"0102229","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["483488","550380"],"PO":["563751"]},"64770":{"abstract":"EIA-0121377<br\/>Moret, Bernard M<br\/>University of New Mexico<br\/><br\/>Collaborative Research: ITR\/AP: Reconstructing Complex Evolutionary Histories<br\/><br\/><br\/>Reconstruction of the evolutionary history of a group of organisms has changed the face of biology and is being used increasingly in drug discovery, epidemiology, and genetic engineering. Unfortunately, such reconstructions typically involve solving difficult optimization problems, so that even moderately large datasets can require months to years of computation. In addition, almost all evolutionary reconstructions presently assume that the historical pattern is one of strict divergence that can be represented by a binary tree. This assumption is frequently violated, especially by plants which often hybridize readily and thus produce networks of relationships.<br\/><br\/>This project brings together computer scientists and biologists from two institutions to develop new models and algorithms to address these two problems. Successful completion of this project will have an enormous impact by providing tools for reconstructing phylogenies of large datasets, and the first tools for inferring network models of evolution appropriate to hybridizing speciation. Such network models will alter how biologists think about speciation, while the development of methods for large-scale analyses will strongly benefit medical and pharmaceutical practice. <br\/>Information technology will be advanced in fundamental ways as well, as the project will demonstrate how algorithm design and high-performance algorithm engineering can jointly solve very difficult discrete optimization problems.","title":"Collaborative Research: ITR\/AP Reconstructing Complex Evolutionary Histories","awardID":"0121377","effectiveDate":"2001-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["229244","558497"],"PO":["565136"]},"64891":{"abstract":"This project brings together a diverse array of scholars from around<br\/>the country, including computer scientists, 3D modellers and animators,<br\/>theater practioners, and theater and music historians. The objective is<br\/>to use digital technology to address a problem fundamental to performance<br\/>scholarship and pedagogy: how to represent and communicate the phenomenon<br\/>of live performance using media. This problem becomes especially pressing<br\/>when the objective is to represent a performance tradition from the past.<br\/>Neither a written description nor a filmed recreation is capable of conveying<br\/>the experience of attending a live performance, an experience that encompasses<br\/>not only the way the performance on stage looks and sounds from the perspective<br\/>of spectators in different parts of the theatre, but also spectator's<br\/>perceptions of and interactions with one another.<br\/><br\/>Our proposed solution to this problem is to recreate historical performances<br\/>in a virtual reality environment. The central objective is to simulate<br\/>a feeling of \"liveness\" in this environment: the sensation of being<br\/>surrounded by human activity onstage, in the audience and backstage,<br\/>and the ability to choose where to look at any given time (onstage<br\/>or off) and to move within the environment. With respect to the performers<br\/>themselves, a critical concern is to find a way to bring the nuances<br\/>of great stage performances into the virtual environment. To this end,<br\/>we propose to use motion capture technology to capture real-world performances<br\/>by professional, highly skilled actors, singers, dancers, acrobats<br\/>and musicians.<br\/><br\/>Key to our project is the depth of the proposed collaboration between<br\/>technology, scholarship, pedagogy and art. This project is conceived<br\/>to make a significant contribution to all four domains simultaneously,<br\/>rather than merely using any one in the service of the others. The end<br\/>result will represent an important advance in the design and implementation<br\/>of virtual environments, building on recent successes in creating<br\/>photo-realistic simulations of real 3D environments. The scale of this<br\/>simulation, and in particular the complexity and precision of the character<br\/>animation, pose an important technical challenge: how to integrate the complex<br\/>pre-defined motion capture-generated animations of the onstage performances<br\/>with the autonomous behaviors of characters in the audience and backstage.The<br\/>project also constitute an invaluable work of applied scholarship,<br\/>an unprecedented resource for visualizing past performances and testing<br\/>hypotheses about historical performance practices. It will provide<br\/>an unprecedented resource for students to engage with historical performance<br\/>traditions as performance (and not as literature or film). Finally,<br\/>from an artistic perspective, the Virtual Vaudeville project will test<br\/>the potential of virtual environments to provide truly high-quality<br\/>theater experiences to remote audiences.<br\/>~","title":"ITR\/PE - A Live Performance Simulation System: Virtual Vaudeville","awardID":"0121764","effectiveDate":"2001-09-15","expirationDate":"2006-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":[167668,"207718",167670,167671,167672],"PO":["433760"]},"61261":{"abstract":"Abstract:<br\/>This project is aimed at developing data compression techniques for<br\/>substantially reducing the data memory footprint of memory intensive<br\/>applications. We will study the behavior of a wide range of applications<br\/>to identify characteristics of data held in data structures by these<br\/>programs that can be exploited in carrying out data compression. We<br\/>will develop a suite of data compression transformations that will be<br\/>implemented by the compiler. Our goal is to develop data transformations<br\/>that can be applied to partially compressible data structures, that is,<br\/>data structures in which all the data is not compressible. This approach<br\/>will not only result in transformations that are widely applicable, but<br\/>also lead to techniques for applying them that are efficient. In particular,<br\/>instead of relying on complex compile-time analysis for proving their<br\/>applicability, we will be able to use simple value profiling techniques<br\/>to identify data structures that are mostly compressible and then apply<br\/>the transformations to them. We will develop data compression extensions<br\/>(DCX) to a RISC-style instruction set for efficiently manipulating<br\/>compressed data. In addition, we will also address other low level code<br\/>generation issues, such as impact of transformations on register pressure<br\/>and instruction cache behavior, which can have a significant impact on<br\/>performance.","title":"Data Compression Techniques for Improving Memory Hierarchy Performance","awardID":"0105355","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["549718"],"PO":["565272"]},"60183":{"abstract":"EIA-0101244<br\/>Aidong Zhang<br\/>SUNY at Buffalo<br\/><br\/>MultiStore: A Research Infrastructure for Management, Analysis and Visualization of Large-Scale Multi-dimensional Data Sets<br\/><br\/>This project establishes a research infrastructure (MultiStore) for supporting integrated research in specific targeted areas of Computer Science, including Multimedia, visualization, Geographical Information Systems (GIS) and Bioinformatics. The research objective is to develop computational theories and algorithms for storing, managing, analyzing, querying and visualizing multi-dimensional data sets that are generated from the related fields. The research components include: (1) Data storage and management. We develop approaches to manage large-scale multi-dimensional data sets. Particular research issues include: multi-dimensional data storage, indexing, and clustering. (2) Data visualization. We develop effective graphics and visualization techniques that can help the user in information processing tasks. Particular research topics addressed include graph visualization and detecting clusters in a multidimensional data set through visualization. The visualization tools will be used in biomedical image understanding and analysis. (3) Data analysis and querying. We focus on geographical image understanding, analysis and querying. The particular research issues include geographical metadata\/knowledge extraction, geographical metadata\/knowledge representation and management, and geographical metadata\/knowledge querying. (4) Data mining and bioinformatics. We develop data mining techniques for determination of protein structures and detection of gene expression patterns. Through these research activities, the fundamental understanding and novel techniques will be provided to support the management of various large-scale multi-dimensional data sets.","title":"CISE Research Infrastructure: MultiStore: A Research Infrastructure for Management, Analysis and Visualization of Large-Scale Multidimensional Data Sets","awardID":"0101244","effectiveDate":"2001-09-01","expirationDate":"2008-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["442408","528208","542246","518277",154576],"PO":["550859"]},"61272":{"abstract":"With modern processor architectures, programs can achieve good<br\/>performance only if they possess sufficient data locality to exploit<br\/>on-chip caches. This research focuses on developing and evaluating<br\/>software support for improving locality for advanced scientific<br\/>applications for both sequential and parallel machines. The basic<br\/>premise is that both compile-time analyses and sophisticated run-time<br\/>systems are necessary. Run-time systems are needed because many<br\/>programs are not analyzable statically. Compiler support is crucial<br\/>both for inserting interfaces to the run-time system and for directly<br\/>applying program transformations where possible.<br\/><br\/>This proposal investigates locality optimizations needed for three<br\/>features found in advanced scientific applications (3D arrays,<br\/>irregular accesses, and pointers). It focuses on extending<br\/>locality optimizations to handle cache conflicts between multiple<br\/>data, deep memory hierarchies (multi-level caches and TLBs), hardware<br\/>and software prefetching, nonlinear memory layouts, parallel and<br\/>cluster architectures, and memory performance tools. Locality<br\/>optimizations will be applied to representative programs and<br\/>experimentally evaluated on advanced computer systems.<br\/><br\/>The results of this research should help improve the performance<br\/>of computationally intensive scientific applications. Because<br\/>of trends in computer architectures, lessons learned are also<br\/>likely to be useful for application domains such as image<br\/>processing and high-performance databases.","title":"Compiling for Locality in Advanced Scientific Computations","awardID":"0105411","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":[157565],"PO":["565272"]},"61283":{"abstract":"Modern processors predict the outcome of branch instructions and speculatively fetch instructions on the predicted path. If the prediction is wrong the speculatively fetched instructions are squashed (deleted) and fetch continues on the correct path. Techniques will be investigated that will reduce the number of such squashed instructions. With compiler and hardware assistance instructions that would normally be squashed and later re-fetched are identified and specially handled so they can be retained. Another approach to be investigated is to delay the fetch of instructions that might have to be squashed, in their place fetching instructions that would be executed regardless of branch outcome. A memory access latency hiding technique will also be investigated. It works by retiring a portion of the dynamic instruction stream (that is delayed<br\/>by a cache miss) out of order, if necessary. The techniques will help solve two pervasive problems: the limited speed of integer programs due to branch mispredictions and the reduced performance of certain<br\/>programs due to long memory latency. Branch misprediction penalty is an increasing function of issue width and pipeline depth; as both of these are expected increase the techniques to be developed will have a<br\/>greater relative impact.","title":"Compiler-Inserted Control Independence Information for Latency Hiding and Reduced Branch Cost","awardID":"0105478","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["540194"],"PO":["325495"]},"66860":{"abstract":"EIA-0130798 <br\/>Miroslav Martinovic<br\/>The College of New Jersey<br\/><br\/>CISE Research Resources: Purpose-Driven Natural Language Processing<br\/><br\/>The unifying theme of the three projects (WHAT, QASTIIR, and Hopewell) is the integration of methodologies of computational linguistics with statistical techniques and their cooperative application to question answering and information retrieval systems. QASTIIR (Question Answering System Through Intelligent Information Retrieval) considers where and when techniques of computational linguistics could best improve performance of a hybrid statistical\/linguistic question answering system. WHAT (Web Host Access Tool) addresses client-side personalization of web search queries, exploiting semantics to disambiguate keyword meaning. The Hopewell project automates K-12 curriculum mapping (essentially a digital library of curriculum resources achieved through teacher consensus). NLP\/IR techniques should reduce the need for middle layer expertise to manipulate map databases. All three projects address how to disambiguate logical and set expression queries. QASTIIR takes the most theoretical approach, developing theory through established protocols for testing. The WHAT domain provides a highly ambiguous real-world domain using well established databases. Hopewell project provides a second real-world domain whose semantics are more constrained, but that requires a database design responsive to novice querying. Anticipated outcomes are (1) new theory development in natural language processing, (2) highly private user profile development, (3) application of NLP technology to digital library development and retrieval.","title":"CISE Research Resources: Purpose-Driven Natural Language Processing","awardID":"0130798","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["471780","465435"],"PO":["557609"]},"66750":{"abstract":"EIA-0130331<br\/>James.J. Collins<br\/>Boston University<br\/><br\/>Title: Designer Gene Networks for Biocomputing Applications<br\/><br\/>Many fundamental cellular processes are governed by genetic networks which employ protein-DNA interactions in regulating function. The biochemistry of the feedback loops associated with protein-DNA interactions leads to nonlinear effects, and the tools of nonlinear analysis become invaluable. This project involves the use of techniques from nonlinear dynamics and molecular biology to model, design and construct synthetic gene networks for biocomputing applications. Here biocomputing is defined as representing the ability of cells to make decisions based on external stimuli, and in this context, synthetic gene networks can be viewed as \"controllers\" for living cells. In this project, a rapidly switching genetic toggle switch is being modeled and constructed in bacterial cells. The genetic toggle switch, which is a fundamental unit of biocomputing memory storage, can be flipped between two stable expression states using transient chemical or thermal stimuli. In addition, as part of this project, synthetic gene networks based on more complicated logic gates (i.e., AND and OR gates) are being designed, modeled and constructed in bacterial cells. These circuits can function as sensors of multiple transient signals, and form the basis for general control schemes requiring an \"if\/then\" structure.<br\/><br\/>Synthetic gene networks represent a first step towards logical cellular control, whereby biological processes can be manipulated or monitored at the DNA level. Ultimately, synthetic gene circuits encoded into DNA, might be \"downloaded\" into cells creating, in effect, a \"wet\" nano-robot. These cellular robots could be utilized for a variety of functions, including in vivo biosensing, autonomously synthesizing complex biomaterials, executing programmed cell death, and interfacing with microelectronic circuits by transducing biochemical events to and from the electronics.","title":"Bio-QuBIC: Designer Gene Networks for Biocomputing Applications","awardID":"0130331","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["177383","529556"],"PO":["565223"]},"63120":{"abstract":"The performance of graphic processors is outpacing the performance of general processors, in fact cubing the growth curve. It has been recently shown that some graphics algorithms can be performed in new ways on the graphics processor, using a novel technique known as multipass programming. Multipass programming treats the graphics processor as a SIMD processor acting on a data array stored in the screen's pixels, with each operation applied as an image-processing pass. The proposed research will extend this concept further not only within the graphics community, but also for the scientific computing and general computing communities, by developing a multipass programming language general enough to support both graphical and non-graphical programs. Existing problems of numerical range and precision will be overcome, and the fidelity of the resulting numerical implementations analyzed.<br\/><br\/>Work in multipass algorithms for procedural shading will be continued our, and multipass programming applied to radiosity and physically-based animation. Multipass programming will also be extended to applications outside of computer graphics, including solving linear systems, the finite element method and computational fluid dynamics.<br\/><br\/>If graphics processors continue to grow at the current rate, they will attain a four teraflop performance at the end of the proposed funding period. During this growth period a library of programming techniques and applications that will harness this otherwise untapped source of high-performance computing power will be developed. The result will be richer graphics, more realistic virtual environments, more natural simulated motion, and the ability to perform sophisticated supercomputing simulations on consumer-level personal computers.","title":"ITR\/SY (Revolutionary Computing) Multipass Programming for Personal High-Performance Computing","awardID":"0113968","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["517378"],"PO":["565272"]},"63131":{"abstract":"We propose development of a network layer protocol necessary to increase the utility of acoustic<br\/>communications in the shallow water environment. Increasing attention has been given to collecting data<br\/>from difficult to access coastal waters for diverse activities, to include scientific research, industrial and<br\/>commercial concerns, and military applications. The preponderance of activity has focused on<br\/>developing reliable methods for transmitting the information collected through the difficult time-varying<br\/>shallow water medium. However, current network layer protocols, which are responsible for determining<br\/>traffic routing, do not provide for guaranteed quality of services. Current protocols also may cause<br\/>unnecessary message delays.<br\/>The delivery of traffic in an acoustic network is complicated by the excessive propagation delays<br\/>resulting from the speed of sound in water. The effect of this propagation speed is to cause an acoustic<br\/>network connected by short hops to perform similar to a wire-based network with links between<br\/>neighboring nodes of over 100,000 kilometers. However, the potential benefits and increased potential<br\/>for application developments that stem from the implementation of wireless underwater networks make it<br\/>worthwhile to explore means of mitigating the effects of the propagation delays.<br\/>Central to the problem of route determination for network traffic is the discovery of the networks<br\/>topology from which network nodes extract next-hop information upon which to base traffic forwarding<br\/>decisions. Two principal methods are used for discovering the route information. Proactive routing<br\/>methods pre-compute route data before network traffic is generated, thus when traffic is submitted by<br\/>network applications the appropriate routes are already known. Reactive routing determines the route<br\/>information in response to traffic submissions. This method, referred to as on-demand routing, seeks to<br\/>minimize route discovery traffic by only determining routes necessary to support actual traffic patterns.<br\/>This routing information is cached to increase responsiveness to submitted traffic and adaptability to<br\/>topology changes. Both methods have their merits; however, neither adequately supports resource<br\/>allocations necessary to assure guaranteed levels of service quality.<br\/>We proposed a novel network protocol that provides many of the benefits of proactive routing yet<br\/>retains the adaptability of reactive protocols. Our protocol is based upon a central master node which<br\/>periodically probes the network for active participant nodes. In responding to the probes, the nodes<br\/>provide the master node with sufficient information for the master node to determine all possible data<br\/>paths through the network. From this information the master node makes all routing decisions for the<br\/>network and provides irnext-hoply information to each non-master node, thus reducing the workload on<br\/>non-master nodes. This information also enables the master node to optimize the allocation of traffic to<br\/>network paths providing for active management of delays insuring delay variance and data capacity are<br\/>within the established quality of service commitments.<br\/>Fundamental to this approach is the separation of control traffic from data delivery. This separation<br\/>allows data to be transmitted without first having to wait for traditional handshake mechanisms to provide<br\/>access to the channel. This separation significantly reduces the expected delay to which traffic is<br\/>subjected resulting in potentially higher data throughput.<br\/>Progress in network layer protocols will expand the usefulness of underwater acoustic networks<br\/>beyond applications that are limited to very low data rate traffic and non-time sensitive data types.<br\/>Specific beneficiaries of this research activity include the Deployable Autonomous Distributed System,<br\/>the SeaWeb Technology Demonstrations, the Autonomous Oceanographic Sampling Network, and the<br\/>National Oceanographic partnership Programs Front Resolving Observational Network with Telemetry<br\/>(FRONT) project.","title":"ITR\/SI - A Networking Protocol for Underwater Acoustic Networks","awardID":"0114014","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["491613"],"PO":["7594"]},"65331":{"abstract":"The convergence of telecommunications networks rely heavily on the interconnection of networks and related Quality of Service (QoS). The Internet is evolving into a multi-class service, integrated network, which is trying to support various applications, which require QoS in addition to the traditional best-effort applications. <br\/><br\/>The goal of the proposal is to design, evaluate, develop and test new dynamic Quality of Service and bandwidth management mechanisms and systems that allow secure and scalable dynamic open provisioning for the interconnection of Differentiated services. The proposal will develop a Bandwidth Management Point to manage scalable and secure control, and performs the functions of service assignment, admission control, traffic conditioning and class routing.<br\/><br\/>The Bandwidth Management Point will support intra-domain communications, which is useful for applications within the same domain. It will also support inter-domain applications including policy information such as reservation process, edge-to-edge admission control and peer-to-peer access control. The deliverables include the design, analysis and implementation of software.","title":"MWIR(CISE\/ANIR): A Secure and Scalable Bandwidth Management Platform for Open Market-based Dynamic and Distributed Provisioning DiffServ Interconnection","awardID":"0123939","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4089","name":"NETWORK CENTRIC MIDDLEWARE SVC"}}],"PIcoPI":["530675",169075],"PO":["7594"]},"76353":{"abstract":"This project is concerned with the study of vision as a sensor for engineering systems operating in complex, dynamic and unknown environments. It entails the analysis of measurable properties of images that depend upon controllable parameters such as the geometry and optics of the imaging device. These properties are called \"controllable cues\" and they include, for instance, stereo, motion and accommodation. In the project, the purposeful aspect of vision is emphasized: knowledge and representation of the environment are only functional to the accomplishment of control tasks, as for instance visual-based navigation, docking, manipulation, endoscopic surgery, Human-Machine Interaction. In order to address the issue of modeling and representation, it is necessary to understand how the geometry and the dynamics of the environment are related to the information coming from the imaging sensor. In the long term, these issues will become crucial in the study of complex systems, where low-level information needs to be organized in order to perform effective communication between different levels of a control hierarchy, or between different agents involved in the control structure. The research material will be integrated into an educational plan that spans graduate, undegraduate and pre-college levels. In addition, to emphasize physical intuition, the PI plan to develop an experimental setup on the use of controllable cues, which will be accessible by precollege students through an Internet educational service.","title":"CAREER: Controllable Visual Cues: Analysis and Applications of Images as Sensory Signals in Complex Control Systems","awardID":"0228544","effectiveDate":"2001-09-01","expirationDate":"2004-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["461021"],"PO":["234178"]},"67212":{"abstract":"The e-Print Archive has been a major advance in the dissemination of scientific research. It has effectively transformed the research communication infrastructure of multiple fields of physics and other scientific communities. It has been in operation since 1991 and has recently moved its base from Los Alamos National Labs to Cornell University. It has experienced continuous growth and has become in such general use that the APS and the University of California Digital Library have become mirror sites. Other scientific research areas are utilizing the archiving system as well. The number of submissions are over 20,000 per year and the site processes about 3 million transactions per month. The project has positively influenced the process and progress of scientific research and can be credited with many of the innovations in the electronic transfer and sharing of scientific information. It provides rapid access to current research at both larger and smaller research institutions and allows fuller participation in research by developing countries. It represents research at the leading edge of electronic dissemination of scientific information and continues to provide a service of great value to a number of scientific disciplines. Its continued development will have a strong influence on scientific advances in many disciplines.","title":"E-Print Archive","awardID":"0132355","effectiveDate":"2001-09-01","expirationDate":"2005-02-28","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"9134","name":"PHYSICS EDUC & INTERDISCIP RES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6857","name":"DIGITAL LIBRARIES AND ARCHIVES"}}],"PIcoPI":["531624"],"PO":["445352"]},"59600":{"abstract":"Next generation high-speed networks are expected to support exciting new applications involv-<br\/>ing multi-media traffic, such as video-conferencing, tele-medicine, video-on-demand, and web<br\/>TV, in addition to countless other yet-to-be-conceived network applications. The viability and<br\/>the continuing success of these networks will depend crucially upon their ability to offer high<br\/>performance with regard to latency, delay variation, and bandwidths they can provide to these<br\/>myriad of applications. Customers will demand high-quality multimedia services, and not be<br\/>satisfied with the kind of high-latency, variable delay that is characteristic of the current Inter-<br\/>net. The various performance requirements from the users and the sheer size of these networks<br\/>make it imperative that we properly understand at a fundamental level how to design, engi-<br\/>neer, and control these networks, and develop appropriate methodologies. It is also essential<br\/>that these tools be evaluated in terms of complexity and accuracy using experimentation (i.e.,<br\/>testbed) and simulation.<br\/> To address the challenges described above, we propose to develop an innovative approach<br\/>that harnesses the power of combined measurement and analysis to create design and control<br\/>tools for next generation networks. We plan to elaborate on the approach in the context of:<br\/>performance evaluation (i.e., QoS estimation), and QoS-sensitivity estimation.<br\/> These issues form the foundation required to solve key network design and control problems.<br\/>Building upon our approach|combining analysis with measurements|we will then focus on<br\/>on a variety of problems that have to be addressed in order for networks to support QoS:<br\/> admission control, congestion control,<br\/> QoS-based routing, and<br\/> network design and dimensioning.<br\/>Our proposed solutions to the above problems will be supported and refined by extensive<br\/>empirical studies on our experimental platform. This platform is capable of supporting a<br\/>variety of network technologies and traffic characteristics.<br\/> Our research team has been at the forefront of the development of important results in traffic<br\/>analysis, network design, and control, and is committed to creating the necessary synergy for<br\/>addressing the key problems outlined above. Our team already has a significantly productive<br\/>track record in previous collaborative efforts.<br\/> We are planning to address a set of problems that are critically important for deploying<br\/>next generation networks with the capability of offering high bandwidth and stringent QoS to<br\/>users. Creating a future broadband network that is exible, efficient, robust, and controllable<br\/>is essential to the viability of our economy and to the different communities within it. Hence, if<br\/>our research is successful, it will have a significant impact on the delivery of services necessary<br\/>to meet the diverse needs of education, business, and entertainment.","title":"Design and Control of Next Generation Networks:A Measurement-Analytic Approach","awardID":"0099137","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["487976","548182","231101",153088],"PO":["7594"]},"57686":{"abstract":"The goal of this research project is to develop a new generation of algorithms and systems for mining distributed and heterogeneous data for ubiquitous computing environments. This research involves development of a distributed principal component analysis (PCA), distributed randomized projection techniques, clustering algorithms based on these distributed representation construction techniques, and a distributed decision tree learning technique based on Fourier analysis. This research is integrated with promotion of education in the data mining area through hosting undergraduates, K-12 students and teachers, organizing workshops, maintaining virtual presence, working with under-represented groups in collaboration with the University of Maryland Baltimore County Shriver Center, and the development of research\/instructional laboratories. The results of this project will provide a new generation of data mining algorithms that minimize the cost for maintaining the ubiquitous presence. It will also enhance the awareness among the students at different levels about the importance of data mining education.","title":"CAREER: Ubiquitous Distributed Knowledge Discovery from Heterogeneous Data","awardID":"0093353","effectiveDate":"2001-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6857","name":"DIGITAL LIBRARIES AND ARCHIVES"}}],"PIcoPI":["421169"],"PO":["563751"]},"64099":{"abstract":"This proposal seeks funding for research in the design, implementation, and instrumentation of new<br\/>methods for scalable wide-area on-demand reliable digital (SWORD) streaming. The larger goal of the<br\/>research is to enable new streaming media applications, such as immediate access to a television show<br\/>whenever a client anywhere would like to view it, by devising new practical cost-effective methods for on-demand real-time streaming of very popular streaming media content. The key aspects of the research to<br\/>be undertaken are:<br\/>1. The development of innovative practical new reliable multicast techniques that optimize client stream<br\/>sharing to conserve server and network bandwidth, improve bandwidth cost-sharing, and maximize<br\/>system scalability.<br\/>2. The design of delivery techniques that work over the Internet or over satellite\/cable networks, or any<br\/>combination of these network technologies.<br\/>3. The development of new metrics and models to determine which popular streams or partial streams<br\/>should be cached at regional (or proxy) servers in order to minimize delivery cost for the data.<br\/>4. The development of new network instrumentation facilities for the streaming media delivery protocols<br\/>that enable deep understanding of the impact of network events and conditions on the performance of<br\/>the protocols.<br\/>5. The use of the new on-line network instrumentation facilities to develop new streaming methods that<br\/>optimally adapt to current network conditions.<br\/>6. The development of a novel testbed that allows experimentation with alternative new reliable multicast<br\/>methods as well as alternative algorithms for caching streaming content closer to the clients, uses the<br\/>new instrumentation facilities, and operates seamlessly and transparently in a live environment with<br\/>ordinary clients accessing widely used media servers over large-scale networks such as Internet2 or the<br\/>Internet MBONE.","title":"iSWORD: Instrumented Streaming Research and Testbed","awardID":"0117810","effectiveDate":"2001-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["410040","402290"],"PO":["292741"]},"59315":{"abstract":"CCR-0098162<br\/>Reliable Multithreaded Software<br\/>William Pugh<br\/><br\/>Multithreading is useful for providing responsive software, particularly in the face of user input and network connections with unpredictable latency. Multithreading allows transparent use of shared memory multiprocessors (SMPs) and multithreaded uniprocessors (e.g., Sun's MAJC, Alpha-EV8). Unfortunately, writing reliable multithreaded programs is difficult.<br\/><br\/>This research defines a formal semantics for multithreaded Java, and works to understand the interaction of that semantics with the compiler and run-time system. The results of this effort should be transferable to other languages and systems that incorporate threads (e.g., C# and C++ with Pthreads).<br\/><br\/>The research effort also performs software archaeology on existing multithreaded systems, documenting data races that have already been fixed and using dynamic and static tools to search for other potential data races. The effort studies both large open source efforts (e.g., Linux kernel, FreeBSD kernel, Apache, Tomcat) and smaller systems.<br\/><br\/>Education, both at universities and for professionals, will form an important component of this research effort. This effort will both illuminate which concepts and forms of instruction are most effective, and also generate material that can be widely disseminated and used by others in instruction.","title":"Reliable Multithread Software","awardID":"0098162","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":[152351],"PO":["564388"]},"63990":{"abstract":"EIA-0117255<br\/>Robert E. Hiromoto<br\/>University of Texas - San Antonio<br\/><br\/>Research Experiences in High-Performance Computing and Communications<br\/><br\/>In this project, our goals are to (1) strengthen our ability to attract and retain undergraduate and graduate minority students, (2) increase the numbers of talented undergraduate minority students pursuing graduate education and high-tech industrial careers, (3) enhance the research productivity of the faculty and students, and (4) provide valuable industry experience to these students through industrial internships.<br\/><br\/>We propose to create a dual-mentor partnership program with local industry to enhance the linkage of research and high-tech opportunities for our students. Students selected for this program will participate as NSF student scholars and will be provided financial support in the form of scholarships and research assistantships. Students will be expected to collaborate with a faculty mentor and regional industry research partners.<br\/><br\/>Faculty from the Computer Science Department and the College of Engineering, will provide undergraduate student mentoring, work to develop student skills in problem solving activities, and create student research collaborations with faculty and industry. The research strengths in CS alone include: 1) parallel and distributed computing; 2) compiler technology for internet and parallel computing; 3) computer network protocols; 4) network security; 5) high-speed switching architectures; 6) data mining; and 7) biocomputing.","title":"CISE MII: Research Experience for Minority Students in High-Performance Computing and Communications","awardID":"0117255","effectiveDate":"2001-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7399","name":"CISE MINOR INST INFRA (MII) PR"}}],"PIcoPI":["297663","525789",164962],"PO":["564778"]},"61273":{"abstract":"he models used in inductive inference have their<br\/>roots in the models used by the philosophers of<br\/>science who were discussing the scientific method.<br\/>The goal there, and in prior work in learning theory,<br\/>was to come up with an explanation of the phenomenon<br\/>under consideration.<br\/>However, scientists rarely work directly for the grand goal<br\/>of a complete explanation.<br\/>The more modest goal of finding features and<br\/>facts about the observed data is pursued.<br\/>A variety of types of algorithms that could be construed as<br\/>discovering their final result will be investigated.<br\/>We propose to consider computations that discover rather than compute<br\/>their intended result.<br\/>A logic of discovery will be developed and investigated.<br\/>This study is particularly relevant to contemporary<br\/>science as automated data generation techniques<br\/>produce sufficient volumes of data to<br\/>overwhelm the analysis abilities of humans.<br\/>The goal of our work is to illuminate<br\/>precisely what can and cannot be accomplished<br\/>by automatic data analysis algorithms.<br\/>Such algorithms are used in data mining and<br\/>text analysis for world wide web search engines.","title":"A Computational Theory of Discovery","awardID":"0105413","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["69811","538795","538795"],"PO":["499399"]},"64793":{"abstract":"This research will investigate methods for automatic retrieval and analysis<br\/>of 3D models. It will develop computational representations of 3D shape<br\/>for which indices can be built, similarity queries can be answered<br\/>efficiently, and interesting features can be computed robustly. Next, it will<br\/>build user interfaces which permit untrained users to specify shape-based<br\/>queries. This will include queries specified with text, 3D models, 2D<br\/>sketching, and high-level methods based on constraints and rules. It will<br\/>combine elements of computer graphics, computer vision, and computational<br\/>geometry.<br\/><br\/>Applications of shape-based query methods will include Internet search engines,<br\/>computer-aided design, molecular biology, medicine, and security. In each<br\/>application the researchers will work with domain experts to understand the<br\/>critical elements of the 3D databases and the challenging shape queries for<br\/>which new methods are required. For example, working with molecular biologists<br\/>will help develop query tools for the Protein Data Bank to find macromolecules<br\/>matching a given shape. These methods will aid classification of proteins for<br\/>which only low-resolution electron density maps are available, and aid searches<br\/>for proteins matching a specific binding site.","title":"ITR\/IM:3D Shape-Based Retrieval and Its Applications","awardID":"0121446","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["533355","450650","424207","213809"],"PO":["433760"]},"66861":{"abstract":"EIA-0130799 <br\/>Teresa Dahlberg<br\/>University of North Carolina Charlotte<br\/><br\/>CISE Research Resources: Experimental Testbed for Mobile Network Protocols<br\/><br\/>The overall objective of this project is to experimentally analyze mobile network protocols that support multimedia services. A wireless, mobile multimedia network will be built to add an experimental component to four ongoing research projects at UNC Charlotte. The experimental work will focus on the component of each project that involves development and analysis of mobile network protocols. Experimentation will enable critical analysis of protocol behavior in dynamic environments where real-world entities replace simulation models, especially, network traffic models, wireless channel models, fault and vulnerability models, and power usage models. The testbed will encompass both cellular and ad hoc network architectures with components that include PCs and laptops with IEEE 802.11 radios and FreeBSD operating system. Network nodes to be configured include multimedia nodes that generate variable bit rate streaming audio and video and a security authentication node. The testbed will support individual research activities as well as facilitate synergy among the researchers who possess expertise in the areas of multimedia, security, ad hoc networking, and cellular networking. The outcome of the experimental studies will contribute to the limited body of knowledge of mobile network protocol behavior within highly dynamic environments.","title":"CISE Research Resources: Experimental Testbed for Mobile Network Protocols","awardID":"0130799","effectiveDate":"2001-09-15","expirationDate":"2005-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["464128",173334,"492724","486470"],"PO":["557609"]},"66982":{"abstract":"EIA-0131281<br\/>Bergen, Kathleen<br\/>University of Michigan - Ann Arbor<br\/><br\/><br\/>BDEI: Radar Remote Sensing of Habitat Structure for Biodiversity Informatics<br\/><br\/>Project Summary<br\/><br\/>Mapping for biodiversity informatics requires information on habitat so that known species<br\/>occurrences may be extrapolated to maps of potential species occurrences. That is, given the conversion<br\/>of known specimen locations into maps, how can we best predict where additional individuals or<br\/>populations of that species may occur? In the context of landscape ecology, landscape structure - its<br\/>multi-dimensional components - is a primary basis for habitat preferences of bird species. Vegetation<br\/>spatial composition, heterogeneity, variability, and scale are among the variables contributing to the<br\/>horizontal structure, while vegetation height, layering, and biomass are examples of variables in the<br\/>volumetric dimension. Combined together these variables, and others, describe the real multi-dimensional<br\/>structure of habitat.","title":"Biodiversity & Ecosystem Informatics - BDEI : Radar Remote Sensing of Habitat Structure for Biodiversity Informatics","awardID":"0131281","effectiveDate":"2001-09-15","expirationDate":"2003-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"W100","name":"INTERIOR-NBII JOINT FUND COMPE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"1165","name":"ADVANCES IN BIO INFORMATICS"}}],"PIcoPI":["505325",173681,"353411"],"PO":["371077"]},"61295":{"abstract":"Scalable high-speed routers are necessary to handle rapidly growing traffic in the Internet at the aggregated packet forwarding rates expected to reach terabits per second. This proposal deals with a novel router architecture with good scalability and capable of forwarding hundreds of millions of packets per second, in order to keep up with future transmission technologies. It aims to help advance the state-of-the-art of router design and to enable large networking configurations. The project contains both basic research and experimental systems activities, including the major objectives of (1) developing a fast packet classification subsystem (PCS), (2)pursuing a scalable switching fabric (SSF) for interconnecting line cards,<br\/>(3) assessing the use of a simultaneous multithreading SMT) processor to replace the conventional processor(s) in each forwarding engine, and 4) investigating into effective fault-tolerant schemes for key router components. The first three objectives are related to router scalability and performance,<br\/>whereas the last one is for reliability improvement, which is especially crucial as the router sizes grow. The fast PCS proposed comprises multiple forwarding engines and a novel cache-oriented multistage structure (COMS), which directs packets arriving at line cards to those forwarding engines for table lookups. The COMS caches lookup results at its constituent switching elements to enable fast and concurrent lookups of subsequent packets. Each forwarding engine keeps only partial routing\/filter lookup tables, rather than full ones (as in any other router design). The SSF is based on PI's earlier switching fabric work, with an appropriate set of wrap-around connections and additional logics for hardware multicast support. An initial study on the use of an SMT processor to handle multiple table-lookup processes, with one thread for a process, is encouraging, and its extensive assessment will be conducted in this project. Caching lookup outcomes optimally in COMS will be modeled formally as a graph optimization problem, with its solution being developed. Research results from this project are likely to have material, positive impacts on future router design, advancing networking technologies to facilitate the continuous expansion of the Internet for years to come. They will also enrich the lecturing materials of such courses as computer communications and networks, network computing, and distributed systems.","title":"Architectural Support for Scalable High-Speed Routers","awardID":"0105529","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["409472"],"PO":["325495"]},"63121":{"abstract":"State-of-the-art run-time systems are a poor match to diverse, dynamic distributed applications because they are designed to provide support to a wide variety of applications, without much customization to individual specific requirements. Little or no information flows from the application to the run-time system to allow the latter to fully tailor its services to the application. As a result, the performance is disappointing. To address this problem, this project will pursue application-centric computing, or Smart Applications (SMARTAPPS). The overriding philosophy of SMARTAPPS is \"measure, compare, and adapt if beneficial.\" That is, the application will continually monitor its performance and the available resources to determine if, and by how much, the application could improve its performance by restructuring. Then, if the potential performance benefit outweighs the projected overhead costs, the application will restructure itself and the underlying system accordingly. This process occurs continuously to adapt to the dynamic needs of the application and the availability of system resources. The adaptation can occur at various levels including selection of an algorithmic approach suitable for the current problem, run-time parallelization and other related compiler optimizations, tuning reconfigurable OS services (e.g. scheduling policy), and system configuration (e.g., selecting which computational resources to use). The SMARTAPPS framework provides performance monitoring and modeling components, as well as mechanisms for performing the actual restructuring, to integrate these levels of adaptation.<br\/><br\/>This project will test SMARTAPPS on several important computational science applications and representative platforms throughout the development process. From computational physics, it will study discrete-ordinates codes that simulate subatomic particle transport. From computational biology, it will study a molecular dynamics code and a code that simulates protein folding and ligand binding (also known as drug docking). SMARTAPPS will be developed and run on current distributed, heterogeneous platforms, including the ASCI machines, large NUMA machines, networks of workstations, and, ultimately, the Grid.","title":"ITR\/SY: SmartApps: An Application Centric Approach to Scientific Computing","awardID":"0113971","effectiveDate":"2001-09-01","expirationDate":"2007-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["496841"],"PO":["565272"]},"66883":{"abstract":"EIA-0130864 <br\/>James Cremer<br\/>University of Iowa<br\/><br\/>CISE Research Resources: Instrumentation for a Virtual Environment Laboratory to Study Human Behavior<br\/><br\/>The University of Iowa will purchase equipment supporting multidisciplinary research on the use of virtual environments as a medium for the study of human behavior. The primary components of the equipment include a PC-based, real-time image generation system for use in the existing immersive display environment, and hardware for instrumented bicycle and wheelchair interfaces to the virtual environment. The equipment will replace outdated and unstable equipment currently in use, and greatly improve the computational foundation of the virtual environments laboratory.<br\/><br\/>The supported research has two primary thrusts: (1) a computational component directed at advancing scenario modeling techniques to meet the special needs of experiments for replicable experiences that adapt to subject behavior and (2) an experimental component investigating children's bicycle riding behavior in simulated traffic. Experiments conducted in virtual environments will be compared with experiments conducted in real environments to validate the use of simulators as laboratories for the study of human behavior. The work integrates research on high-fidelity simulation, control of complex behaviors of simulated agents, human factors, and developmental psychology. This research will advance virtual environment technology, experimental methods, and simulator validation, and increase the understanding of a leading cause of childhood injuries.","title":"CISE Research Resources: Instrumentation for a Virtual Environment Laboratory to Study Human Behavior","awardID":"0130864","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["543444","543446","543447"],"PO":["557609"]},"63022":{"abstract":"Internet is undergoing an overhaul unprecedented in size, diversity, and reach, with profound im-<br\/>pact in all aspects of our scientific, social, economic and political life through the integration of<br\/>networks of communication, transportation, entertainment, utilities, and finance. The stability<br\/>and robustness of this vital infrastructure demands a rigorous theory to understand the current<br\/>protocols and evolve them to meet emerging challenges. We propose to develop such a theory for<br\/>TCP congestion control, and use it to drastically improve the stability, robustness and optimality<br\/>of the current protocols.<br\/>A key insight is to view congestion control as a distributed asynchronous computation to maxi-<br\/>mize aggregate source utility over the Internet; different TCP and active queue management (AQM)<br\/>schemes correspond to different utility functions and different algorithms to maximize them.<br\/>Our research hastwo components. First, we will develop a new theoretical model of TCP<br\/>congestion control based on duality in optimization and multivariate robust control. The theory will<br\/>clarify the role of source algorithms, such as Tahoe, Reno and Vegas, and active queue management,<br\/>such as DropTail, RED and REM, in the control of networks and establish performance limits of<br\/>the current protocols; it will explain the effect on stability when delay, topology, capacity, and load<br\/>scale up; and it will provide conditions under which the feedback stability ofTCP\/AQM algorithms<br\/>are invariant to these effects. Indeed, such a theory is already emerging from our recent works.<br\/>Even in its currently preliminary stage, it already provides a fundamental understanding on some<br\/>widely observed performance and fairness behavior of the current protocols, and uncovers new and<br\/>surprising stability problems. For example, it shows that the current protocols become unstable and<br\/>exhibit bifurcation when network capacity increases. Moreover, maintaining stability as capacity<br\/>scales up arbitrarily imposes severe constraints on how sources adjust their rates (TCP) and what<br\/>congestion information is fed back (AQM). The current protocol does not satisfy the condition<br\/>for such stability invariance, and hence may be ill suited for future networks where, pulled by<br\/>application demand and pushed by technological advances, the capacity will be large.<br\/>The second component of our research is the design of practical TCP and AQM protocols<br\/>based on the theory, and the development of prototypes and experiments to demonstrate their<br\/>effectiveness. We will use the theory to identify the sources of instability in the current protocols<br\/>when delay, network size, capacity, and traffic load scale up. We will design both enhancements that<br\/>incrementally evolve the current protocols, and drastically new protocols that have the strongly<br\/>robust stability property promised by theory. As a concrete application of our algorithms, we will<br\/>apply them to improve TCP performance over wireless links, both because they are ubiquitous and<br\/>because they are likely to remain the most important bottlenecks in future networks.","title":"ITR\/SI(CISE):Optimal and Robust TCP Congestion Control","awardID":"0113425","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["490256","564049"],"PO":["292741"]},"64276":{"abstract":"In recent years, low-density parity-check (LDPC) codes have been shown<br\/>to have the power to perform within thousandths of decibels of the<br\/>Shannon channel capacity of memoryless communications channels. This<br\/>project seeks to answer a natural question: how good are these codes<br\/>for transmission over channels with memory? The channels under<br\/>consideration are Markovian memory channels, including both channels<br\/>where the memory is dependent and independent of the transmitted<br\/>symbols. Such channels arise in several applications, such as disk<br\/>drives or other storage media.<br\/><br\/>The analysis and design of LDPC codes has benefited from representing<br\/>these codes as graphs, where the decoding is done by passing messages<br\/>along the graph edges. This graph model allows an analysis using<br\/>martingales that underlies recent advances, including the density<br\/>evolution design technique. The investigators study how to extend<br\/>this graphical modeling approach to channels with memory. More<br\/>specifically, the project is divided into four major tasks: <br\/>designing density evolution algorithms under new channel models;<br\/>evaluating noise tolerance thresholds; engineering codes for short<br\/>block lengths and rapid decoding; and achieving spectral shaping with<br\/>low-density parity-check codes.","title":"Low Density Parity Check Codes for Channels with Memory","awardID":"0118701","effectiveDate":"2001-09-01","expirationDate":"2005-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["492224","560092"],"PO":["348215"]},"63066":{"abstract":"Disk systems have long been a source of performance and management<br\/>problems, and they grow in importance as the years pass. Of particular<br\/>concern are the slow-to-improve mechanical positioning delays. To<br\/>address these problems, storage devices and host systems have abundant<br\/>resources and knowledge. Independently, engineers of both device<br\/>firmware and operating system (OS) software aggressively utilize their<br\/>local knowledge and resources to mitigate disk performance problems.<br\/>The overall goal of this research is to increase the cooperation<br\/>between these two sets of engineers, which will increase the<br\/>end-to-end performance and robustness of computer systems.<br\/><br\/>This research will develop a deep understanding of available device<br\/>and workload information and how it can be collectively exploited.<br\/>Exploiting this understanding in real systems will require more<br\/>expressive interfaces and new cooperative algorithms. Two concrete<br\/>examples to be explored are: (1) device-side specializations, such<br\/>as freeblock scheduling, that have access to system-provided<br\/>information about priority levels and forthcoming demands, and<br\/>(2) OS-side specializations, such as track-aligned extents, that<br\/>have access to device-provided details about physical data layout<br\/>and firmware cache algorithms. In addition, the insights generated<br\/>by this research will assist end-to-end education and thinking in<br\/>storage systems.","title":"ITR\/SY: Blurring the Line between OSes and Storage Devices","awardID":"0113660","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["486331"],"PO":["223414"]},"56301":{"abstract":"A picture is worth a thousand words, and the addition of sound and motion can breathe life into a picture.<br\/>As a result, the use of video in all kinds of multimedia applications has become an important development<br\/>in the 1990s. In particular, Video on demand (VOD) is a core technology for many important applications<br\/>such as digital libraries, distance learning, electronic commerce, entertainment, public information<br\/>systems, etc.<br\/>The simplest video delivery technique employs a dedicated stream for each service request. Obviously,<br\/>this scheme is too expensive and has been shown to have little scalability. To vastly reduce this cost, one<br\/>can leverage multicast technology to allow multiple clients to share a video stream. Unfortunately, today's<br\/>multicast technology was developed in the 80's, and was not optimized for such applications. Missing a<br\/>multicast could mean a long wait until the next multicast. This limitation has recently led to a large body<br\/>of research looking for remedies at the application level.<br\/>Application-level solutions, however, cannot address all the drawbacks, particularly traffic congestion<br\/>caused by too many multicasts. In fact, this proposal is motivated by application-level work done by<br\/>the investigator in his last NSF project (from 1998 to 2000). The achievements of that project, though<br\/>significant, were constrained by the limitation of standard multicast. Minimizing the multicast frequency<br\/>is crucial for any multicast-based applications, particularly those running on a public network such as the<br\/>Internet. Attaining this goal requires a fundamental change in the multicast concept. The investigator<br\/>proposes enabling the multicast tree to deliver the entire video to all the receivers who may subscribe to<br\/>the multicast at different times. This new capability would significantly reduce the number of multicasts<br\/>necessary, and therefore lower the network resource requirements. At first sight, this seems like a mission<br\/>impossible. But on the contrary, this can be achieved by allowing the routers on the multicast tree to<br\/>intercept and cache a video stream passing through. The data can be relayed to subsequent subscribers to<br\/>further extend the multicast tree. In this project, the investigator proposes to develop a suite of techniques<br\/>to make such an environment practical for future-generation large-scale multimedia applications.<br\/>To assess the potential of the proposed idea, the investigator has designed an initial version of his<br\/>Caching Multicast Protocol (CMP). The preliminary study indicates that this approach has the potential<br\/>to revolutionize the way in which multimedia information is disseminated. This scheme is much more<br\/>scalable and less expensive than application-level solutions. The new communication paradigm, however,<br\/>demands new research at the network level. In this project, the investigator proposes to study issues such<br\/>as cache organization, cache replacement policies, multicast routing algorithms, congestion control, client<br\/>and server protocols, etc. In addition, he will implement a prototype, consisting of CMP-capable routers,<br\/>CMP-compliant servers (sources) and CMP-compliant clients (destinations) to examine the practicality of<br\/>the proposed techniques.<br\/>The significance of this project is in advancing multicast technology to enable large-scale deployment<br\/>of multimedia applications. Although many great advances have been made in the field of information<br\/>technology, none have had as great and direct an impact on the daily lives of ordinary citizens as multime-dia<br\/>information systems. As such, the benefits of this research will reach many people in society. In terms<br\/>of education, this project will help to support three doctoral students. The investigator has a good record<br\/>of using NSF projects to train students for teaching careers. After these students graduate, they can help<br\/>to spread the CMP expertise developed from this project to their new institutions. Other graduate students<br\/>taking our advanced databases course can also benefit from this work by experimenting with various new<br\/>multicast applications on the CMP testbed. To reach out to members of communities, materials resulting<br\/>from this research will be disseminated on the investigator's research group website.","title":"A Scaleable Multicast Protocol to Enable Future-Generation Large Scale Multimedia Applications","awardID":"0088026","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["409925"],"PO":["565090"]},"57302":{"abstract":"PROPOSAL NUMBER: CCR-0091719<br\/>TITLE: Dynamic and Randomized Load Distribution for Tree-Structured<br\/> Parallel Computations on Static Interconnection Networks<br\/>PI: Keqin Li<br\/><br\/>This three-year project will investigate the performance of the class<br\/>of random-walk-based algorithms for dynamic tree embedding to support<br\/>tree-structured parallel computations on various static networks.<br\/>The research will be conducted within the framework of the product of four<br\/>spaces, namely, the embedding algorithm space, the tree model space,<br\/>the static network space, and the performance measure space.<br\/>The overall research objective is to thoroughly investigate and understand<br\/>the behavior of randomized tree embedding produced by random-walk-based<br\/>algorithms in static networks to the largest extent.<br\/>The methods include devising embedding algorithms, proposing random<br\/>tree models, developing analytical tools, formulating mathematical equations,<br\/>generating numerical data, observing and proving general properties,<br\/>and simulating dynamic embedding.<br\/>The project is motivated by the fact that there are a wide spectrum of<br\/>tree-structured applications in computer science and engineering<br\/>and the wide availability of distributed memory multicomputers<br\/>with static interconnection networks.<br\/>The significance of the project is reflected by its wide coverage of<br\/>various randomized tree embedding algorithms, a number of deterministic<br\/>and probabilistic tree models, a wide range of static interconnection<br\/>networks, and different performance measures.<br\/>Algorithms and methods obtained from this project will be readily used<br\/>to support dynamic load distribution for tree-structured parallel and<br\/>distributed computing, and will have great impact on various applications<br\/>on a variety of multicomputers and distributed systems.","title":"Dynamic and Randomized Load Distribution for Tree-Structured Parallel Computations on Static Interconnection Networks","awardID":"0091719","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":[147425],"PO":["309350"]},"65046":{"abstract":"Algorithms are the basic procedures by which computers solve problems. With the explosion in the use and connectivity of computers, and in the sizes of the data sets being used, the performance of algorithms is becoming increasingly important. Being able to solve a problem ten times faster, for example, could mean designing a drug next year instead of several years later, or reducing the cost of developing a new space structure by allowing faster and more extensive computer simulations. Over the past 30 years there have been significant advances in the basic theory of algorithms. These advances have led to a \"core knowledge\" concerning algorithms and algorithmic techniques that has now been applied across an amazing diversity of fields and applications---surely more broadly than calculus is now applied. <br\/><br\/>The problem, however, is that there is a large gap between ongoing theoretical research, and the current use of algorithms in applications. It often takes more than ten years for the core ideas in a new algorithm to make it into an application, and ongoing theoretical research often does not properly address the needs of the applications. The purpose of the Center is to bridge this gap so that efficient and effective algorithms can be deployed more rapidly. This will be achieved through (1) a set of Problem Oriented Explorations (PROBEs), (2) developing an extensive set of web resources on algorithms, and (3) educational activities including holding workshops for educating teachers. The PROBEs will bring together algorithm designers and domain experts to rapidly deploy new algorithmic ideas within a specific domain.","title":"ITR\/SY+IM+AP: Center for Applied Algorithms","awardID":"0122581","effectiveDate":"2001-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1688","name":"ITR LARGE GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"V468","name":"NSA-LEMUR LANGUAGE MODEL TOOLK"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"V239","name":"NSF-MAIN & DEV LEMUR LANGUAGE"}}],"PIcoPI":["485891","258340",168133,"561985","548200"],"PO":["499399"]},"57566":{"abstract":"The goal of this research project is to enable the manag. The project addresses four XML data management tasks: XML publishing from relational databases, transport of XML data over the Internet, storage of large amounts of XML data, and stream processing XML data.ement of XML data on the Web to be done efficiently In XML publishing, a declarative mapping is specified from a relational database to XML. The project develops techniques for efficiently translating XML queries on the view back into SQL queries on the relational database. For XML transport, the project creates new compression techniques that exploit patterns and datatypes in a given XML data instance. Today, it is difficult to store XML data in a relational database system, because XML differs radically from the relational model. This project creates new methods for splitting XML data optimally into relations to be managed by a relational database system. Finally, the project develops alight-weight XML query processing method, by providing a set of tools for simple XML transformations that can be combined into pipelines performing complex processing. Several software tools will result from this project, and will be made available in the public domain, with an expected impact both on the research community and on the industry. Parts of this research project will be integrated in the database course being offered at the University of Washington.","title":"CAREER: Efficient Management of Web Data","awardID":"0092955","effectiveDate":"2001-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["531543"],"PO":["469867"]},"68017":{"abstract":"In the late 1980's the field of computational science and engineering emerged as a new discipline, one with a research core that generalized from its many applications and led to the creation os several academic programs at leading unversities. Computational science has since proven itself with many successes, but it has also evolved both in its tools, methodologies, and research challenges and goals. This workshop seeks to re-examine the area, and develop a new consensus on the directions it should be taking. A major goal of the workshop will be a document summarizing the accomplishments of the past decade, and prognosticating the future for scientific computing research.","title":"NSF Workshop on Computational Science","awardID":"0136291","effectiveDate":"2001-09-15","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["283428","496204"],"PO":["179846"]},"60790":{"abstract":"EIA-0103709<br\/>I-Ling Yen<br\/>University of Texas-Dallas<br\/><br\/>The PI's proposed to develop new innovative approaches and techniques to advance the component-based development ( CDB) of complex applications. The proposed effort in developing advanced CBD techniques spans three dimensions: The research will enable such capabilities by enabling ontology-based repository, code pattern based component composition and tool suite for component comprehension and customization. <br\/> <br\/>Technological advances, such as rapidly increasing computing power and network bandwidth, are enabling advanced high-performance distributed applications that can significantly enhance the quality of education, health care, remote monitoring and control, early warning systems, scientific collaborations, and other high-performance distributed applications.","title":"NGS: A Distributed Component Repository for Rapid Synthesis of Adaptive Real-Time Systems","awardID":"0103709","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["526352","456490","364451","492042","551857"],"PO":["301532"]},"59019":{"abstract":"The goal of this research is to develop the necessary methodology for automated recognition of generic object and concept classes (such as buildings, cars, boats, and trees) in digital images in order to substantially improve the process of content-based image retrieval, which has relied mainly on low-level color and texture features for matching queries to database images. The approach has three major aspects: (1) to design new high-level image features including cluster features that group together lower-level features and relationship features that capture spatial relationships among them; (2) to develop a unified representation that can express a large variety of both low- and high-level features in a form that can be used by learning systems; and (3) to automate the development of recognizers for object and concept classes through the use of a hierarchical, multiple classifier methodology. The resulting techniques are being evaluated on several different large image databases, including commercial databases whose images are grouped into broad classes and a ground-truth database that provides a list of the objects in each image. The results of this work will be a new generic object and concept recognition paradigm that can immediately be applied to automated or semi-automated indexing of large image databases. The methodology will help to bridge the gap between the high-level needs of users of image retrieval systems and the low-level features typically extracted from an image. The generic object class recognition algorithms we develop will begin a new era of object recognition research, leaving the geometric domain and entering the conceptual domain.","title":"Object and Concept Recognition for Content-Based Image Retrieval","awardID":"0097329","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["334068"],"PO":["563751"]},"61483":{"abstract":"Proposal number: 0106760<br\/>PI: Stephen Kosslyn<br\/>Institution: Harvard University <br\/>Title: Cognitive Styles and Individual Differences in Imagery <br\/><br\/>Award Abstract<br\/><br\/><br\/>This is a study of cognitive styles (such as the visualizer-verbalizer distinction) people (both students and professionals) use in thinking through and learning science and mathematics (specifically in the topic area of kinematics). The project has two goals: (1) To investigate and revise the traditional verbalizer-visualizer cognitive style dimension, including the possibility that more than these two basic styles exist (such as object and spatial visual styles). This approach is based on findings and methods from cognitive psychology and cognitive neuroscience to conceptualize the nature of cognitive style and its neural underpinnings. (2) To examine the instructional implications of these cognitive styles and their relevance to educational practice. The research will proceed along three lines: behavioral studies, classroom-based studies, and functional magnetic resonance imaging (fMRI). Based on evidence from this research, the investigators will develop theoretically-based guidelines for teaching students to process visually\/spatially and materials which build on the specific strengths of each type of thinker.","title":"ROLE: Cognitive Styles and Individual Differences in Imagery","awardID":"0106760","effectiveDate":"2001-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T821","name":"CIA-HUMAN COGNITION STUDIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"T054","name":"CIA-DECEPTION DETECTION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"T189","name":"CIA-HUMAN COGNITION STUDIES"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"1666","name":"RESEARCH ON LEARNING & EDUCATI"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"V396","name":"CIA-BASIC RES ON IND & GROUP C"}}],"PIcoPI":["248351","248351","158093",158093],"PO":["533965"]},"66851":{"abstract":"EIA-0130768 <br\/>Sudeep Sarkar<br\/>University of South Florida<br\/><br\/>CISE Research Resources: A Compute-Intensive Sensor-Based Environment for Research in Computer Vision and Artificial Intelligence<br\/><br\/>Automated learning of grouping parameters for perceptual organization of complex images, modeling and reconstruction of elastic objects from image sequences, real-time matching of buyers and sellers for E-commerce, and learning models from extremely large databases, all require large data storage and a computing environment that supports exploring extremely large parameter spaces along with the ability to process huge quantities of data. A multiprocessor computing environment with substantial memory and disk storage is requested for high-performance computing associated with these four research projects in the general areas of computer vision and artificial intelligence. The compute server will increase the present capabilities by an order of magnitude.<br\/><br\/>In addition, image acquisition devices, including high-resolution color cameras, digital video cameras, stereo cameras, and laser range scanners are requested for gathering color, motion, and range data. The ability to acquire fast range images and motion sequences will enable the consideration of the problem of integrating motion and range into the perceptual organization process. Also, the ability to acquire fast and high-resolution range, with registered color, will facilitate development of physics-based non-rigid algorithms and models that incorporate true material properties, which have, heretofore, not been possible.","title":"CISE Research Resources: A Compute-Intensive Sensor-Based Environment for Research in Computer Vision and Artificial Intelligence","awardID":"0130768","effectiveDate":"2001-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["549181","353592","522400",173300],"PO":["557609"]},"61285":{"abstract":"This research involves developing new connections between the areas of<br\/>machine learning, on-line algorithms, and optimization, and using<br\/>these connections to address fundamental problems in all<br\/>three areas.<br\/><br\/>In machine learning, one focus of this research is how to best combine<br\/>a small sample of labeled data with a large amount of unlabeled data<br\/>in order to produce high quality predictions. This type of problem<br\/>has become especially important given the explosion of data now<br\/>available over the web. This research is exploring how techniques<br\/>such as network flow and graph cuts from the optimization literature<br\/>can be used to provide a new means of attack, and how to best make a<br\/>number of design choices that arise in this approach. Another basic<br\/>question this work investigates is what kinds of concepts can be<br\/>automatically learned in the presence of highly noisy data, and to<br\/>what extent substantially new types of algorithms may be possible.<br\/>The PI recently gave the first algorithm to learn a class of concepts<br\/>in the presence of noise that is provably not learnable by a wide<br\/>class of techniques known as Statistical Query methods. The current<br\/>research aims to expand on this work and explore the extent to which<br\/>it can be pushed much further. The types of learning problems being<br\/>studied have close connections to problems of decoding random linear<br\/>codes and finding approximate shortest lattice vectors that arise in<br\/>cryptography. Improvements to the learning algorithms should impact<br\/>our understanding of those problems as well.<br\/><br\/>Another major thrust of this research is the use of techniques from<br\/>machine learning to address problems in online algorithms. In<br\/>particular, the highly-developed \"weighted experts\" technology in<br\/>machine learning suggests new approaches for combining multiple online<br\/>algorithms that may simplify a number of longstanding open problems.<br\/>This work is studying the extent to which this connection can provide<br\/>insight into several basic questions, such as dynamic optimality in<br\/>search trees and the weighted caching problem. Finally, this research<br\/>is also studying a number of basic approximability questions, as well<br\/>as exploring new frameworks for the analysis of local search<br\/>techniques.","title":"Machine Learning, On-line Algorithms, and Optimization","awardID":"0105488","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["554195"],"PO":["543507"]},"66862":{"abstract":"EIA-0130800 <br\/>David Luebke<br\/>University of Virginia<br\/><br\/>This project will construct a state-of-art immersive display at the University of Virginia. Specifically, the investigators will build a wide field-of-view tiled display, using passive stereo projection, 6-DOF head tracking, and spatialized audio to create an extremely immersive 3-D audio-visual display environment. This display will benefit and enable three separate research projects in the Computer Science and Psychology departments: gaze-directed rendering, perceptually driven physical simulation and animation, and cognitive design of human-computer interfaces. Tiling multiple projectors will create a display spanning a very wide field of view; two projectors per tile will enable passive stereo display with lightweight polarizing glasses. An audio system, a head tracker, and realistic scanned 3-D environments will enable immersive and convincing virtual worlds. The wide field-of-view will provide an ideal testbed for gaze-directed rendering, which accelerates interactive rendering by exploiting reduced visual acuity (e.g., for peripheral or fast-moving objects), and for perceptually driven physical simulation, which selectively degrades simulation accuracy according to perceptual metrics. The human-computer interface project investigates immersive ambient context to improve human memory. The stereo head-tracked capabilities of the new display will literally add a new dimension to the investigation, enabling full 3-D environmental cues.","title":"CISE Research Resources: A State-of-the-Art Immersive Display for Research in Rendering, Animation and Simulation, and Cognitive Human-Computer Interface Design","awardID":"0130800","effectiveDate":"2001-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["334091","451003","257184"],"PO":["557609"]},"64563":{"abstract":"The focus of the proposed research is on high-speed serial-links, where the goal is to maximize<br\/>data rates between IC chips. As fabrication technology improves, the challenge in next-generation serial-link design is in handling transistor mismatches and on-chip noise, both of which are expected to grow sharply. Consequently, future serial-link architectures must be able to tolerate high-levels of transistor mismatches and on-chip noise. The general approach followed by most researchers is to use advanced circuit techniques to mitigate their adverse effects. In contrast, we propose to use signal processing techniques in addition to circuit techniques to overcome these problems. This integrated design approach motivates<br\/>a new class of high-speed serial-link architecture that is fundamentally more robust to transistor<br\/>mismatches and on-chip noise. The proposed architecture also enjoys many other important<br\/>implementation advantages, making it well suited for future generation high-speed serial-link systems.<br\/><br\/>This research will demonstrate the feasibility and effectiveness of the proposed architecture<br\/>for reception and transmission of broadband signals. We will provide a complete design frame-work based on a clear understanding of various design options and the corresponding trade-offs in performance and implementation complexity. Furthermore, we will demonstrate the feasibility and the advantages of the proposed architecture by realizing it on silicon. Our goal is to achieve faster data rates than the fastest published serial-link system. The concepts and techniques developed in the proposed research are not limited to serial-link systems. They are easily applicable to any high-bandwidth communication systems where the symbol rates exceed the achievable on-chip clock frequency. Some specific examples of such applications are ultra-wideband and high-speed satellite communication systems.","title":"Research for Mixed Signal Electronic Technologies: A Joint Initiative Between NSF and SRC: Design of High-Speed Serial-Links in CMOS","awardID":"0120372","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["545964"],"PO":["562984"]},"61296":{"abstract":"This research involves two applications of graph algorithms; the first<br\/>regards communication in networks, the second involves solving flow<br\/>problems in structured networks. The investigators study algorithms<br\/>for finding paths connecting many communicating parties in a network.<br\/>The goal is that the paths do not overutilize any particular link in<br\/>the network. The second item the investigators will study is<br\/>the famous problem of routing the maximum amount of flow through<br\/>a network. This problem is itself interesting and has numerous<br\/>applications in fields as diverse as transportation and computer vision.<br\/><br\/><br\/>More specifically, the investigaters study low congestion routing in<br\/>networks. This problem is easy in a relaxed fractional setting but<br\/>notoriously difficult in an integral setting. Recent work has<br\/>established relationships between a cut based upper bound and the<br\/>fractional lower bound on this problem. These results will lead to<br\/>better understanding of the integral version of this problem.<br\/>Research on this problem has made use of techniques from linear<br\/>programming, randomized rounding, combinatorial graph theory, as well<br\/>as geometric embeddings of graph metrics. For the maximum flow<br\/>problem, the investigaters study ideas in a recent maximum flow<br\/>algorithm in order to extend them to the minimum cost flow problem.<br\/>The investigators also study the maximum flow problems on planar and<br\/>other restricted classes of graphs.","title":"Network Algorithms: Scheduling and Routing","awardID":"0105533","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["486616"],"PO":["543507"]},"65300":{"abstract":"Efficient and effective change detection and notification is becoming increasingly important for environments such as WWW and distributed heterogeneous systems. Change detection for structured data has been studied extensively. Change detection and notification for unstructured data in the form of html and XML documents is the goal of this project. The objectives of this proposal are to investigate the specification, management, and propagation of changes as requested by a user in a timely manner, and meeting the quality of service requirements. The user is allowed to specify the kind of changes to documents s\/he is interested in, at different levels of granularity. They also specify how they need to be notified (email, mobile host, PDA, etc.) when the requested information becomes available. Quality of service (QoS) information such as timing constraints, aggregated vs. individual changes is part of the user specification. User specifications are translated into a set of rules that are used for extracting documents, monitoring changes, and propagation of relevant information. Special attention is paid to scalability issues, as it is an important aspect of the solution. The ability to selectively monitor and be informed of changes (push) augments the current strategy of pulling information periodically and checking for interesting changes. By disseminating the resulting prototype and the results over the Internet, scientists can benefit from it. Through integration of research into courses taught at UTA and into student research, this project will impact education at UTA and other universities.","title":"Selective Just-In-Time (JIT) Information Propagation in Large Network-Centric Environments","awardID":"0123730","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["553596"],"PO":["563751"]},"63001":{"abstract":"CDMA systems have achieved great commercial success in wireless communications since the first<br\/>IS-95 system was deployed in Seattle in 1994. In fact, most of the future wireless communication<br\/>systems will be using CDMA technology. Yet, as far as reaching the great potential of CDMA in terms<br\/>of higher system capacity, lower bit error rate, and lower packet loss rate, the problem of demodulation in<br\/>the presence of multiple access interference remains as a significant bottleneck for all CDMA systems.<br\/>To solve this multiple access interference problem, researchers and engineers have worked since the early<br\/>1980's on so-called multiuser detectors (MUD). Unfortunately, thus far none of the multiuser detectors<br\/>has been implemented in a real CDMA system, because of the prohibitive complexity of these structures.<br\/> There are two major factors that contribute to this situation. First, CDMA systems must use long<br\/>spreading sequences for several practical reasons, whereas multiuser detectors must use short spreading<br\/>sequences. Second, the complexity of even the simplest multiuser detector is still too great to be<br\/>implemented in the fastest electronics, for all but the smallest of data rates. In this work, we propose to<br\/>address both of these problems in a collaborative effort. The collaboration will be organized so that Dr.<br\/>Qingchong Liu of Oakland University in Rochester, Michigan, will initially focus on the first objective,<br\/>and Dr. David W. Matolak of Ohio University in Athens, Ohio, will initially (and concurrently) focus on<br\/>the second objective. Results will be exchanged frequently, and meetings will be held quarterly. After<br\/>some early progress, our collaboration will grow closer as we combine the work objectives and consider<br\/>system (transmitter and receiver) performance.<br\/> We propose first to extend some recent results obtained for the construction of long spreading<br\/>sequences from short sequences. This can be termed the system objective. These new sequences will<br\/>be appropriate for both conventional CDMA systems and for multiuser detectors. This method was<br\/>invented by one of us and has been implemented in possibly the fastest wireless network running at<br\/>400Mbps in the Spaceway system by Hughes Electronics. It has significantly reduced receiver<br\/>complexity and cost, and gives essentially optimum performance. By measuring sequence correlations at<br\/>multiple levels, the method provides new insights on sequence design and tremendously reduces<br\/>complexity in signal design and detection for broadband wireless communications. This method has the<br\/>potential to help bridge a gap between current CDMA systems and multiuser detectors.<br\/> We also propose to study reduced complexity multiuser receivers from the perspective of reduced<br\/>complexity trellis search techniques, combined with one of the most promising MUD receiver structures,<br\/>in a partitioned manner. This can be termed the receiver objective. The MUD receiver of interest is<br\/>the minimum mean-squared error (MMSE) receiver, which is attractive for its good performance and<br\/>modest complexity. The partitioning approach will aim to share the detection tasks between the MMSE<br\/>front-end and the reduced-complexity trellis processor. These receivers will make use of the new<br\/>spreading sequences specified for use in future 3 rd and 4 th -generation CDMA wireless communication<br\/>system standards, and the multiple level sequences developed in the system objective. The reduced<br\/>complexity trellis search techniques will explore use of the analogous techniques researched for<br\/>equalization, but not fully applied to the problem of CDMA multiuser detection. Our goal for these two<br\/>objectives is to create a fundamental bridge to connect the existing and planned CDMA systems with the<br\/>theoretical multiuser detectors so that the bottleneck of the multiple access interference problem in<br\/>CDMA systems can be surmounted.<br\/> Both objectives of this proposed work will employ analysis, followed by computer simulations.<br\/>Both objectives will also require the assistance of graduate and undergraduate students. The modeling<br\/>work will aim to reconcile theory with practical implementation and thus provide engineering education<br\/>in the best sense: connecting principles and practice. Training students in both system design and<br\/>receiver design for CDMA will also naturally be valuable to the wireless industry. In addition, the<br\/>research will provide material for inclusion in several new graduate courses, and in undergraduate design<br\/>projects, at both universities.","title":"ITR\/SI-COLLABORATIVE RESEARCH: Investigations on CDMA Systems using Multiple Level Sequences and Partitioned Reduced Complexity Multiuser Detection Receivers","awardID":"0113307","effectiveDate":"2001-09-01","expirationDate":"2004-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["492380","533504"],"PO":["250082"]},"64332":{"abstract":"0119053<br\/>Pajarola, Renato<br\/>U of Cal Irvine<br\/><br\/>In recent years a new rendering paradigm based on the reuse of two-dimensional imagery to generate 3D renderings has evolved, called Image Based Rendering (IBR). Based on a set of input images, so called reference views, IBR methods can generate new images from arbitrary view points. One of the main advantages of IBR techniques is that the rendering cost is independent of the scene complexity and bound by the image resolution. The use of IBR techniques thus allows in certain situations to achieve real-time display performance for other-wise non-interactive rendering of complex geometric scenes. The main target applications are interactive rendering of highly complex scenes (virtual reality systems), and rendering on time-budgets (simulations and computer-game like environments).<br\/><br\/>This grant will improve and explore new techniques for interactive rendering applications on the basis of the depth-image warping approach. Our goal is not to restrict computation of reference views to a preprocessing step, but to explore and develop algorithms and data structures that allow the generation and reuse of depth-image reference views dynamically in an interactive visualization environment. Depth-image warping is a powerful approach, and using multiple reference views to limit visibility artifacts it is possible to create new renderings for a wide range of views. However, the user's movements in a virtual environment are unpredictable, and thus reference views have to be generated dynamically to optimize their use. Therefore, from acquiring image based representations for the reference views to rendering from image data everything has to be done dynamically in an interactive visualization framework.","title":"SGER: Real-time Depth-Image Meshing and Warping","awardID":"0119053","effectiveDate":"2001-09-01","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":[165821],"PO":["179846"]},"63012":{"abstract":"A Mobile Ad hoc NETwork (MANET) is a collection of mobile autonomous system of nodes connected<br\/>by wireless links with multi-hop communication and no underlying infrastructure. Research in the field of<br\/>MANET is receiving unprecedented attention due to their profound impact on human life. The most<br\/>important problems in MANET are Routing, Quality of Service, Security, Power management and Traffic<br\/>and Mobility modeling and we plan to address many of these issues.<br\/>In a MANET, when a mobile node has a packet to send, it first consults its route cache to determine<br\/>whether it already has a route to destination, else it initiates route discovery by broadcasting. Once a route<br\/>is established, its continuation and maintenance is of prime concern for efficient communication. A route<br\/>could be broken by mobility and is determined by route error packets. Rather than employing a<br\/>conventional way of global re-flooding for a new route search, we address this by Local Route Repair<br\/>(LLR) approach and achieve re-connectivity with minimum overhead. Further work is needed to extend<br\/>our scheme by increasing the length of patch-up part. We expect this to yield a higher amount of savings<br\/>in terms of routing overhead and delay when unidirectional links are present. We also plan to define an<br\/>analytical framework for different protocols and determine their performance.<br\/>The need for scheduling in a MANET arises primarily due to limited availability of resources. We plan to<br\/>study the impact of packet level scheduling strategies that transmit packets based on a metric derived<br\/>from characteristics of the data being transmitted, like the length of the packets or the length of the route<br\/>being traversed by the packets or even the priority of the packets. We plan to test other routing schemes<br\/>and define and formulate an analytical model for packet queue at each node so that we could determine<br\/>end-to-end delay of different types of packets.<br\/>Effective operation of MANETs is dependent on maintaining appropriate routing information in a<br\/>distributed fashion. Confidentiality of routing information is important so that not only the payload data<br\/>but also the routing message headers carrying, the location information of the mobile nodes can be<br\/>exchanged securely. We have defined an authentication scheme that can prevent the external attacks. We<br\/>minimize substantial overhead by performing mutual authentication using challenge-response mechanism<br\/>along the reply path only when the route reply is received. We plan to propose a distributed intrusion<br\/>detection system to handle them. We will build these systems based on traffic profiles that we would<br\/>obtain after extensive study of the traffic patterns. We are planning to perform a detailed simulation to<br\/>obtain metrics that would help us in differentiating valid and malicious data.<br\/>Wireless sensor networks can be easily deployed without any installation costs or pre-planned<br\/>organization. To increase fault tolerance, thousands of these sensors might be employed. The traditional<br\/>routing protocols defined for wireless ad hoc network do not scale well for sensor networks as they are<br\/>data centric and application-specific unlike traditional networks. Most protocols for sensor network<br\/>collect data periodically from environment. We feel that there exists a need for networks geared towards<br\/>responding immediately to changes in the sensed attributes. Very recently, we have proposed a protocol<br\/>called TEEN for such networks. We are also looking at ways to combine the best features of both<br\/>proactive and reactive protocols to form a hybrid network. We also believe that sensor networks should<br\/>provide the end user with the ability to control the three-way trade-off between energy efficiency,<br\/>accuracy and response time dynamically. In brief, the proposal research will have a long-term impact on<br\/>the robustness and security of MANETs and sensor networks.","title":"ITR\/SI: On Robust and Secure Mobile Ad Hoc and Sensor Networks","awardID":"0113361","effectiveDate":"2001-09-01","expirationDate":"2005-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["402054"],"PO":["223414"]},"65322":{"abstract":"A major trend in day-to-day computing involves moving seamlessly from workstation to wireless handheld devices. A second major trend is continuous collaboration with colleagues. Accommodating and supporting these trends is extremely difficult because of the vastly different platforms and communication networks. <br\/><br\/> The objective of the proposal is to develop and demonstrate a middleware framework for performance-optimized ubiquitous collaboration over heterogeneous networks. It will enable quality-of-service applications and support selective data distribution. The key component of the proposed framework is the collaboration bus, which is a middleware to support group communication in data-centric groupware. The proposed research includes:<br\/>a) algorithms and methods for dynamic monitoring of network capabilities,<br\/>b) data transformation and adaptation policies for adjusting network traffic, and<br\/>c) assessing and controlling the performance impact involving in broadcasting each message.<br\/><br\/>Some of the key elements of the research are the development of Data Adaptation Agents. These agents transform and change the data so that it can be used by different applications and hardware. The proposed research will bring new capabilities for multi-user collaboration within reach.","title":"Collaboration Bus for Environment-Adaptive Groupware","awardID":"0123910","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4089","name":"NETWORK CENTRIC MIDDLEWARE SVC"}}],"PIcoPI":["409115"],"PO":["250082"]},"65333":{"abstract":"The rapid development of wireless communications technologies and their impact on everyday life has greatly increased over the last couple of years. But, the traditional client\/server architecture, where the client relies completely on the server for information, is not useful in the wireless environment, as the server is often not reachable because it is not connected.<br\/><br\/>The proposal focuses on the development of wireless communications technologies and plans to design, develop and implement a \"client\/proxy\/server system\" in which a client-side proxy assumes the role of a local server during the disconnections. <br\/><br\/>Preliminary work shows that the approach has great potential to improve data access, computation and service. The targeted application areas include distance learning, fast mobile Internet as well as 3rd and 4th generation wireless cellular networks.","title":"A Semantic Caching Service for Wireless Network Centric Environments","awardID":"0123950","effectiveDate":"2001-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4089","name":"NETWORK CENTRIC MIDDLEWARE SVC"}}],"PIcoPI":["539039","394642","180288"],"PO":["7594"]},"76102":{"abstract":"Java is a language of growing importance but so far parallelism in Java has been limited to either multi-threading on symmetric multiprocessors (SMP) or distributed computing using Remote Method<br\/>Invocation (RMI). The number and size of Java-based Internet-related applications require more and more parallelism and system scalability. This proposal addresses the problem of designing memory consistency<br\/>protocols for a distributed Java Virtual Machine capable of self-adapting at runtime to different application characteristics. <br\/><br\/>The proposed work is divided into five tasks: (1) the definition of the memory consistency model, (2) the development of consistency protocols, (3) the definition of an analytical performance model on which<br\/>adaptive protocols are based, (4) the development of processor allocation algorithms for load balancing, and (5) the evaluation of the system performance using four classes of applications.<br\/><br\/>A correct distributed Java Virtual Machine specification must be first defined. The correctness issue is especially important for a distributed shared memory Java Virtual Machine due to the incompatibilities between the Sun specification and distributed memory architectures. Preliminary work indicates that Sun's JVM specification is too strong for DSM architectures. A thorough analysis of the JVMS requirements will produce the set of constraints that have to be relaxed from the original Sun's JVMS to allow an efficient distributed implementation. <br\/><br\/>Once a theoretical memory consistency model is established, the next step is to develop consistency protocols. An analytical model is proposed to analyze the application behavior for various protocols. The application profile can be abstracted by the object granularity, temporal locality of accesses, and object access<br\/>patterns. A novelty of the proposed work is the mapping of application parameters into protocol parameters using the analytical model parameters: thread creation time, synchronization time, and execution<br\/>overhead. These parameters can be estimated analytically and measured. The correlation between model parameters and adaptive protocols needs to be investigated. It is necessary to develop heuristics that link<br\/>parameters with the protocols. <br\/><br\/>As part of the preliminary work, a distributed Java Virtual Machine called DISK has been implemented in our network-of-workstations laboratory consisting of sixteen Pentium III computers connected by a<br\/>100 Mbps network. DISK currently supports two memory consistency protocols: an invalidate and an update lazy release consistency protocol. <br\/><br\/>Several Java-specific applications will be investigated to measure and tune the performance of the adaptive protocols developed. Four different classes of applications from the Internet and knowledge <br\/>processing technology will be used as new benchmarks: (1) client-side I\/O intensive applications, (2) server-side I\/O intensive applications, (3) computational intensive applications, and<br\/>(4) computational and I\/O intensive applications.","title":"ITR: Adaptive Protocols for a Distributed Java Virtual Machine","awardID":"0226862","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[198121],"PO":["551992"]},"63034":{"abstract":"This project focuses on the creation of a stochastic representation for the phase-space embeddings of dynamical systems, for application to the task of speech classification and recognition. The research team will develop a general stochastic model for such signal embeddings, test the model through classification simulations, then apply the technique to both isolated and continuous speech recognition. The goal of the research is to discover time-domain analysis techniques using dynamical systems methods that will lead to improved analysis of speech signals and to improvements in speech recognition accuracy. This approach represents the integration of two traditionally distinct research fields: statistical signal processing and chaotic systems. Since signal processing is fundamentally based on linear systems theory and the study of chaos is inherently non-linear, these fields have little or no overlap outside of the fact that both attempt to model the behavior of physical systems. This research integrates these very different viewpoints by applying stochastic analysis and modeling tools from the signal processing field to the problem of analyzing embedded phase spaces obtained from chaotic systems analysis of time-series signals. The results will lead to a significant gain in our fundamental understanding of the characteristics and analysis of speech signals, with potential long-term application to other areas of speech processing such as speech coding and synthesis. The impact of developing these new technologies and applying them to the speech recognition task extends into both the machine learning and signal processing communities; specifically, the development of time-domain characterization methods is directly applicable to many problems of interest in the chaos and non-linear modeling domain, and will demonstrate an ability to concretely measure differences between the phase-space attractors of chaotic systems.","title":"Integration of Stochastic and Dynamical Methods for Speech Technology","awardID":"0113508","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["224279","551035"],"PO":["565215"]},"63199":{"abstract":"This IGERT project will establish a multidisciplinary graduate program in reliability and risk engineering, analysis, and management at Vanderbilt University. Twenty-five faculty participants in this program are drawn from three different schools: Engineering (Civil, Mechanical, Chemical, Electrical Engineering and Computer Science, and Management of Technology), Management, and Arts and Sciences (Mathematics). The research theme consists of three inter-linked areas: (i) large systems reliability and risk, (ii) device- and component-level reliability, and (iii) uncertainty analysis methods. As engineering systems grow in size, complexity and cost, reliability and risk assessment is increasingly dependent on modeling and simulation, rather than on expensive (or impossible) traditional test-based methods. Therefore, the unique features of the research theme are: (i) development of the modeling and simulation-based methodology for reliability and risk assessment, (ii) systematic integration of models and tools across disciplines, and (iii) inclusion of economic, legal, regulatory, and social perspectives in risk assessment and management. The research projects will apply these concepts to infrastructure, environmental, network, mechanical, and electronic systems. The educational goals are to broaden the training with multidisciplinary perspectives, embed information technology, include model integration and high performance computing technologies, and increase the number and diversity of reliability and risk engineers and managers trained in the modeling and simulation methodology. A number of strategies are proposed to achieve these objectives: multidisciplinary coursework and dissertation topics, laboratory rotations, industry and government laboratory internships, seminars, workshops, case studies, training in professional communication and ethics, undergraduate and high school teacher participants, aggressive recruitment (especially among underrepresented groups), and systematic evaluation by industry, government and academia. The program will include strong participation and support from several industries, government agencies and national laboratories, through internships, workshop and seminar participation, educational and research collaboration, and advisory committee. Through these efforts, the graduate program aims to become a self-sustaining center of national and international leadership. The IGERT award will lead to 35 Ph.D.'s over 9 years, fulfilling a critical need of the American industry in this important field. <br\/><br\/>IGERT is an NSF-wide program intended to meet the challenges of educating Ph.D. scientists and engineers with the multidisciplinary backgrounds and the technical, professional, and personal skills needed for the career demands of the future. The program is intended to catalyze a cultural change in graduate education by establishing new, innovative models for graduate education and training in a fertile environment for collaborative research that transcends traditional disciplinary boundaries. In the fourth year of the program, awards are being made to twenty-two institutions for programs that collectively span all areas of science and engineering supported by NSF. The intellectual foci of this specific award reside in the Directorates for Engineering; Social, Behavioral, and Economic Sciences; Computer and Information Science and Engineering; Mathematical and Physical Sciences; and Education and Human Resources.","title":"IGERT: Multidisciplinary Training in Reliability and Risk Engineering, Analysis, and Management","awardID":"0114329","effectiveDate":"2001-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"1360","name":"HUMAN RESOURCES DEVELOPMENT"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1101","name":"Division of GRADUATE EDUCATION","abbr":"DGE"},"pgm":{"id":"1335","name":"IGERT FULL PROPOSALS"}}],"PIcoPI":["328368","196349","553600",162387,"507639"],"PO":["434633"]},"64299":{"abstract":"ABSTRACT<br\/><br\/>The primary problem addressed is the deleterious effect of dynamic<br\/>multipath propagation on high-speed wireless digital communications <br\/>supporting real-time video and multimedia applications. Digital TV (DTV) <br\/>is a target application along with Fourth Generation Cellular Communication <br\/>Systems. Reflections off buildings and other structures cause ghosts <br\/>and other artifacts in the reconstructed video stream. These multipath <br\/>effects can wreak havoc on all functions of the receiver causing<br\/>loss of synchronization and loss of carrier\/timing recovery as well<br\/>as inter-symbol interference. Discrete ghosts are often associated with <br\/>multipath conditions of large, flat surfaces, such as tall steel buildings. <br\/>However, multipath conditions can occur in areas with hills and dense foliage<br\/>where a signal can travel through many paths to the receiver. When the signal<br\/>is bounced back from a moving object, complex ghosts can arise with a <br\/>time-varying nature that is very challenging for the equalizer to overcome.<br\/>To accommodate delay spreads of up to 40 microseconds, current generation <br\/>Digital TV receiver chips employ a Decision Feedback Equalizer (DFE) with <br\/>more than 100 Feed-Forward taps and more than 400 Feed-Back taps. This <br\/>constitutes a large number of taps to adapt implying slow convergence and <br\/>high computational complexity. Future high-speed wireless multimedia <br\/>applications will place even more stressful demands on equalizer performance. <br\/><br\/>The investigator will develop fundamental advances in the area of<br\/>reduced-dimension Decision Feedback Equalizers (DFE's).<br\/>These include methods for dimensionality reduction based on a<br\/>powerful reduced-rank adaptive filtering algorithm referred to <br\/>as the Multi-Stage Nested Wiener Filter (MSNWF). The MSNWF provides<br\/>convergence speeds better than the Recursive Least Squares (RLS) algorithm,<br\/>but at a much reduced computational complexity due to the fact that <br\/>that the MSNWF constrains the overall weight vector to lie <br\/>in a data-adaptive, low-dimensional subspace.<br\/>The MSNWF has been successfully employed to effect a reduced-rank, <br\/>linear equalizer for applications in Third Generation Cellular Communications<br\/>based on both CDMA Technology and the European GSM EDGE System. The<br\/>investigator will also develop other means for dimensionality<br\/>reduction including the use of the channel shortening concept employed in <br\/>OFDM systems to reduce the length of the cyclic prefix, and symbol waveform <br\/>compression achieved through simple linear filtering at the receiver.<br\/>In addition, the investigator will study the use of reduced-dimension DFE's<br\/>for equalization when block space-time coding is employed under frequency <br\/>selective multipath conditions.","title":"Reduced-Dimension Decision Feedback Equalizers for High-Speed Wireless Digital Communications","awardID":"0118842","effectiveDate":"2001-09-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["434205"],"PO":["348215"]},"56214":{"abstract":"The use of multi-beam antenna arrays for transmission and reception allows wireless units to send and<br\/>receive tens of beams in different directions and using multiple frequency bands. If we deploy a large number<br\/>of such multi-beam wireless units over a large area, we obtain a highly connected and high capacity wireless<br\/>network. We call this the All Wireless Network (AWN).<br\/> Analogous to Dense Wavelength Division Multiplexing (DWDM) in All Optical Networks (AON), we<br\/>propose an analogous Frequency Division (FD) and Space Division (SD) technique for All Wireless<br\/>Networks (AWN). Unlike point-to-point connectivity of an AON, we argue that massively parallel number of<br\/>beams with flexibly assigned direction and frequency from wireless multi-beam units can provide unlimited<br\/>connectivity and bandwidth. We rely on spatial parallelism to achieve an extremely high network throughput.<br\/> An AWN can be arranged as a spatially distributed multi-stage circuit switch or a fully connected ring,<br\/>allowing multi-rate and multi-cast capability of a parallel and spatially distributed switch fabric. A single<br\/>multi-beam wireless unit can receive from multiple beams to achieve a Gigabit per second throughput for an<br\/>application. The wireless unit can also serve as relay nodes to switch incoming beams of given direction and<br\/>frequency through a switch fabric onto outgoing beams of different direction and frequency. This is analogous<br\/>to all optical switching for DWDM in an AON, except we have an added dimension of free and continuous<br\/>spatial connectivity, rather than fiber-to-fiber connectivity.<br\/> We shall devise switching and routing theory and techniques for SD\/FD circuit switching over AWN,<br\/>taking into account co-channel and adjacent channel interference and various fading factors. We formulate<br\/>metric for routing that accounts for power consumption, distance covered, and externality induced to other<br\/>routes. We study social optimality versus individual optimality for such routing techniques.<br\/> Using the OPNET software package, we shall implement a simulation of the AWN. The transmitted<br\/>radiation pattern is modeled for each wireless multi-beam unit. We distribute many such units over an area,<br\/>either randomly or using various wireless interconnection network topologies. Propagation barriers are also<br\/>modeled. The graphical simulation provides estimation of power and interference level. Various power control<br\/>and routing protocols will be tested using the simulation software.<br\/> Theoretical and simulation results will be used to design an Internet Circuit (IC) Router. Routing and<br\/>switching algorithms will be made distributed with a multiple -path connection set-up using a link state routing table, or using source initiated connection requests. We plan to implement a simple IC Router for the<br\/>internetworking of wireless multi-beam units for concept demonstration.<br\/> We believe that the proposed AWN architecture shall be low cost, high performance, and highly flexible<br\/>for traffic pattern and link\/node impairments. The high throughput of the AWN will allow high quality<br\/>multimedia applications to be delivered on-demand entirely by wireless communications.","title":"Switching and Routing for All Wireless Multi-Beam Ad-Hoc Networks","awardID":"0087765","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":[144300],"PO":["565090"]},"57545":{"abstract":"EIA-0092839<br\/>Daniel Andresen<br\/>Kansas State University<br\/><br\/>CAREER DESPOT: Enhanced Dynamic Process Management for Beowulf Clusters on the Grid<br\/><br\/>Current systems for managing workload on clusters of workstations, particularly those available for Linuxbased (Beowulf) cluster, are typically based on traditional process-based, coarse-grained parallel and distributed programming. In addition, most systems do not address the need for dynamic process migration based on differing phases of computation. As we have outlined in the proposal, the DESPOT project will first build a sophisticated thread-level resource-monitoring system for computational, and network resources. This information will be used in an intelligent scheduling system to perform adaptive process\/thread migration within the cluster.","title":"CAREER: DESPOT: Enhanced Dynamic Process Management for Beowulf Clusters on the Grid","awardID":"0092839","effectiveDate":"2001-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["559268"],"PO":["301532"]},"65047":{"abstract":"EIA- 0122582<br\/>Raymer, Michael<br\/>Wright State University<br\/><br\/>EI: An Integrated Undergraduate Program in Bioinformatics<br\/><br\/>This project involves the development of an interdisciplinary, integrated undergraduate program in bioinformatics. In particular, the project's goal includes the design of a program of undergraduate study that embodies an interdisciplinary synthesis of the topics in computer science and biology required for graduates to successfully pursue careers in bioinformatics. The project also plans to implement, test, and refine the program of study so that it may be used as a prototype for similar curricula at universities nation-wide. Pedagogy foci are to design, integrate, and test approaches for teaching topics in bioinformatics while providing research experiences for all students in the program. The project is strengthened by the participation of a group of academic, government, and industry bioinformatics researchers and professionals who act as an advisory committee. The emerging science of bioinformatics seeks to develop computational algorithms and techniques for analyzing large biological databases in search of information that can be applied to specific problems in the life sciences. This project addresses the education of professionals with a background in this field and contributes to satisfying a nationally growing workforce need.","title":"EI: Crossing the Interdisciplinary Barrier: An Integrated Undergraduate Program in Bioinformatics","awardID":"0122582","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}}],"PIcoPI":[168137,168138,"478239"],"PO":["551712"]},"64079":{"abstract":"The project addresses an important, and somewhat neglected so far, topic in robotics - long reach robots. Cable-based robotic devices will be explored, covering questions of configuration design, trajectory planning, feedback control, fine motion control, and metrics for intelligent design. Experimental validation will be performed on an eight degrees-of-freedom cable robot built in the PI's laboratory. The PI has adequate access to outside resources critical for the project.","title":"Cable Suspended Robots: Coordination, Control and Configuration Design","awardID":"0117733","effectiveDate":"2001-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1632","name":"CONTROL SYSTEMS"}}],"PIcoPI":["558467",165174],"PO":["335186"]},"56126":{"abstract":"The mobile agent technology offers many novel capabilities for building future generation systems for monitoring and management of large networks. The goal of this research is to investigate and build a system infrastructure using mobile agents for active monitoring of large distributed systems. Mobile agents would be used to perform remote information filtering and control functions, and such distributed and mobile agents could be securely modified to change their monitoring policies and functions. If needed, new agents could be installed at a node to perform functions different from the existing ones. The system would also support use of agent groups for cooperative distributed monitoring and collaborative filtering of monitored information.<br\/><br\/>The proposed infrastructure would provide a set of basic agent types for event monitoring, subscription, and information correlation and filtering. This infrastructure would support experimentation's with different schemes for monitoring, dissemination, and processing of event data. We would develop monitoring functions for different operating system platforms, such as Sun OS, Linux, and Windows NT. We propose to experiment with intrusion detection techniques using this infrastructure. We plan to use logic programming techniques for performing search and correlation operations on event data. The event notification data would be stored in logic databases using Prolog. Mobile agents would be used for performing filtering and correlation functions on data stored in such databases at different nodes.<br\/><br\/>Security and robustness of operations would be an important design requirement for this infrastructure. This system infrastructure would include mechanisms to monitor its own components and perform recovery actions on detecting any failures. We would also develop a security architecture for mobile agents to execute in separate protection domains and at different security levels to minimize the impact of any corrupted or compromised agents.<br\/><br\/>The proposed system would be deployed in the research and instructional computing labs at the University of Minnesota to evaluate the effectiveness of its mechanisms. This system would be implemented using the Ajanta agent programming system. For this purpose, the capabilities of the Ajanta system would be enhanced to support secure agent groups and debugging facilities for large-scale agent based programs. This monitoring infrastructure would be made available to the community for research and education activities.","title":"Mobile Agent-Based Active Monitoring of Computer Networks","awardID":"0087514","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["74434"],"PO":["565090"]},"80591":{"abstract":"","title":"CAREER:Type Systems and Program Analyses for Secure and Reliable Interactive Web Services","awardID":"0296182","effectiveDate":"2001-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["564588"],"PO":["564388"]},"80492":{"abstract":"","title":"ITR: Architectural Level Software Metrics","awardID":"0296082","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[209618,"309212"],"PO":["564388"]},"62991":{"abstract":"The aims of the project are to develop implementation architectures and conceptual foundations for SYNCHRONIZERS -- programs that reconcile copies of replicated data after disconnected updates. More specifically, the project's goals are (1) to develop high-level SPECIFICATIONS for various forms of synchronization, in particular for the domains of file system synchronization and synchronization for more general structured data presented as XML; and (2) to build and distribute IMPLEMENTATIONS embodying these specifications. These activities are tightly connected, and will proceed in parallel throughout the project's lifetime. The results of the research will both be disseminated in the form conference and journal publications and embodied in publically distributed software. The long-term intention is both to advance the conceptual foundations of synchronization tasks (in filesystems, databases, ad hoc network protocols, and cooperative middleware layers) and, by offering clean designs and compelling prototypes, to improve engineering practice in the area. <br\/>http:\/\/www.cis.upenn.edu\/~bcpierce\/unison","title":"ITR\/SY+IM: Principles and Practice of Synchronization","awardID":"0113226","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["563479"],"PO":["563751"]},"60021":{"abstract":"XML is becoming the principal medium for data exchange over the Web, and for information integration in general. Increasing amounts of public and private data are described in XML while more legacy sources (e.g., relational databases) offer public XML views. The feasibility of many applications that have emerged with the growth of XML on the Web requires new and complex query optimization techniques. The goal of this research project is to develop a \"chase & backchase\" optimization method for XML queries. Based on chasing with constraints and incorporating cost-based optimization, the method brings together strategies such as use of indexes, use of materialized views, semantic optimization and join\/scan minimization, allowing optimizations that depend on non-trivial interactions between these strategies. Particular attention is given to the challenges posed by XML document order and by regular path expressions in queries. This project is expected to result in a theoretical foundation and a practical framework for defining and using indexes, materialized views and complex constraints in XML query processing systems. The practical framework will be demonstrated through a publicly available software prototype appropriate for teaching about XML query systems and for supporting related research projects.","title":"XML Query Optimization","awardID":"0100681","effectiveDate":"2001-09-15","expirationDate":"2004-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["541876"],"PO":["563751"]},"61473":{"abstract":"Modern wireless networks use feedback control of transmit power to accommodate changing channel conditions, such as propagation loss, shadowing, multi-user interference, etc. This proposal suggests the utilization of feedforward control of data rate, in addition to the existing power control schemes, in order to more effectively combat these disturbances and, in addition, accommodate channel model uncertainties. These controllers use the bit error frequency, observed in the previous packet, in order to calculate the data rate of the packet to be transmitted next. Our preliminary results indicate that ideally this approach leads to a minimum of 20% throughput improvement, without additional power expenditures, or to a minimum of 30% decrease of transmit power, without decreasing the throughput. In some scenarios, this approach may lead to as much as 300% of throughput improvement or to 600% of power saving. Moreover, the efficacy of this<br\/>approach is independent of whether a single or multi-user environment is considered, and no data rate wars take place.<br\/> The efficacy of feedforward data rate control is mainly due to the following two reasons:<br\/>(a) Unlike feedback power control, which adapts relatively slowly due to a finite step of power increase\/decrease, feedforward data rate control adapts in the span of one packet transmission time. This leads to a more effective rejection of fast disturbances, such as the level of shadowing. The above-mentioned minima of throughput increase and power decrease are due to this fast adaptation capability.<br\/>(b) Unlike feedback power control, which does not adapt to channel uncertainties (e.g., whether the channel is AWGN or Rayleigh), feedforward data rate control does accommodate these effects. The above-mentioned three-fold in-crease of the throughput and six-fold decrease of power are exactly due to this fact.<br\/>The approach to the development of feedforward data rate controllers, considered in this proposal, is based on the following three steps: (i) First, a non-causal and non-realistic but optimal feedforward data rate controller is designed. It is non-causal because it calculates the optimal data rate as a function of bit error probability in the packet yet to be transmitted. It is non-realistic, because it uses the probability of bit error rather than the frequency of this event. It is designed solely in order to derive the least upper bound of the achievable throughput.<br\/>(ii) Next, this controller is causified and made realistic. The causification is achieved by making the data rate of each packet a function of bit error probability in the previous packet. It is made realistic by using the frequency of bit error rather than its probability. Thus, an implementable controller is obtained and its performance is evaluated. It is shown that causification leads to a relatively small decrease of performance for all practical speeds of mobiles. However, using frequencies instead of probabilities may lead to a substantial performance loss. Thus, a certain level of filtering of bit error frequency is necessary.<br\/>(iii) Finally, a filtered version of the above implementable controller is introduced and it is shown that a right level of filtering leads to an efficient performance. At this point, this level of filtering is investigated only experimen-tally (i.e., numerically), and a rigorous method for designing right filters is, along with others, a problem to be addressed in the proposed research.<br\/> Based on the results to-date briefly mentioned above, the main tasks of the proposed research are as follows:<br\/>1. Develop methods for design of implementable feedforward data rate controllers for wireless networks.<br\/>2. Quantify the level of throughput increase and\/or transmit power decrease when this technology is used.<br\/>3. Develop an architecture in which feedforward data rate control can be used in both cellular and ad-hoc environ-ments.<br\/> The impact of the proposed research is in providing wireless network designers with a new method for combating channel disturbances and uncertainties.","title":"Feedforward Control of Data Rate in Wireless Networks","awardID":"0106716","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["507741","398545"],"PO":["565090"]},"64861":{"abstract":"Scientists are now confronted with many very large high-quality data sets. The potential scientific benefits of these data are offset by the laborious process of analyzing them to answer questions and test theories. This project will develop new data mining algorithms in pursuit of the goal of computer assisted discovery. Two key issues in achieving this are computational efficiency and autonomy. If scientists are to focus their energy on understanding, answers must arrive in minutes rather than days, hence the need for efficiency. Autonomy is important both from the data mining and the statistical perspective. Detailed searches for relationships, models, and parameters are too large for humans to undertake manually. New statistical methods will have to autonomously and quickly select models, test their significance, and report the results to search algorithms looking for new discoveries.<br\/><br\/>The National Virtual Observatory (NVO) currently under construction is a model of the future of science. The NVO will assemble petabytes of data from many multi-wavelength sky surveys into a single repository. The new methods to be developed will be implemented in the domain of cosmology, but they will be applicable to all other sciences. <br\/><br\/>The members of this project are computer scientists, physicists and statisticians who have a track record of collaborating closely. Working together they have produced: new algorithmic theory, new statistical theory, and publicly fielded software packages resulting from the theory, while developing new courseware and training students.<br\/><br\/>This proposal involves research and education in the following areas:<br\/><br\/>Nonparametric data analysis. Nonparametric statistical models enable powerful analysis techniques that make minimal assumptions, which is critical for scientific accuracy.<br\/><br\/>Automated discovery. Statistical models can be used directly for discovery. Individual objects are compared to models to identify anomalies and data generated models are compared to theoretical models to refute or confirm hypotheses.<br\/><br\/>Computational methods for fast analysis. The project will build on past successes of getting orders of magnitude speedups on operations such as Expectation Maximization based clustering and n-point correlations to make the new methods fast.<br\/><br\/>Automated simulation parameter searching. Using all of the above methods, a system will be developed that starts with a parameterized simulation and some observational data. The system will search the space of parameters, testing the resulting simulation against the real data using nonparametric methods to determine the best settings.","title":"ITR\/IM: Statistical Data Mining for Cosmology","awardID":"0121671","effectiveDate":"2001-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["559428","473316",167554,"532936","548334","536675"],"PO":["565272"]},"60153":{"abstract":"Constraint databases integrate database and constraint technologies for spatio-temporal database applications including GIS and moving objects. Constraint data models emphasize logical properties while hiding physical representations; they enable general purpose data management capabilities. The project investigates constraint databases in three aspects: algorithms, applications, and foundations. In algorithms, it aims at optimization techniques for constraint database queries. Joins with the intersection predicate are known as spatial joins. Traditional algorithms use heuristics, indexes, and computational geometry techniques to evaluate the join on minimum bounding rectangles of objects as a filter. Recent algorithms allow better approximations for filter, or even perform a direct join on objects. A focus of this project is to study and compare performance of such new algorithms and develop further improvements and models for predicting filter effectiveness in terms of dataset properties and approximations. Moreover, the techniques for intersection join are extended for joins with other topological (e.g., containment, meet), distance, and direction predicates, and to multiway spatial joins. More fundamentally, optimization issues are often related to decision problems of logical properties such as containment, equivalence, and disjointness of transactions (queries\/updates). Abstract machines are a recently developed tool for studying such problems. Transactions are often designed in advance with parameters instantiated at runtime. The abstract machine techniques are extended for studying logical properties of parameterized transactions and related computational complexity issues. In applications aspect, the project uses the constraint approach to develop data models and query languages for moving object databases and study query optimization Constraint databases integrate database and constraint technologies for spatio-temporal database applications including GIS and moving objects. Constraint data models emphasize logical properties while hiding physical representations; they enable general purpose data management capabilities. The project investigates constraint databases in three aspects: algorithms, applications, and foundations. In algorithms, it aims at optimization techniques for constraint database queries. Joins with the intersection predicate are known as spatial joins. Traditional algorithms use heuristics, indexes, and computational geometry techniques to evaluate the join on minimum bounding rectangles of objects as a filter. Recent algorithms allow better approximations for filter, or even perform a direct join on objects. A focus of this project is to compare and characterize performance of such new algorithms and develop further improvements and models for predicting filter effectiveness in terms of dataset properties and approximations. Moreover, the techniques for intersection join are extended for joins with other topological (e.g., containment, meet), distance, and direction predicates, and to multiway spatial joins. More fundamentally, optimization issues are often related to decision problems of logical properties such as containment, equivalence, and disjointness of transactions (queries\/updates). Abstract machines (in automata theory) have been found to be a very useful tool for studying such problems. Transactions are often designed in advance with parameters instantiated at runtime. The project intends to extend these automata-theoretic techniques for studying logical properties of parameterized transactions and related computational complexity issues. In applications aspect, the project applies the constraint approach to develop data models and query languages for moving object databases. The goal is to provide a conceptual framework and optimization techniques for managing and querying moving objects.","title":"Constraint Databases: Optimization Techniques and Applications","awardID":"0101134","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["499391","389215"],"PO":["469867"]},"64762":{"abstract":"EIA-0121345 <br\/>Tanimoto, Steven<br\/>University of Washington<br\/><br\/>ITR\/PE: A Learning Environment for Information Technology Concepts Using Intensive, Unobtrusive Assessment<br\/><br\/><br\/><br\/><br\/><br\/>Although many learning environments have been developed that effectively engage students in assembling computational objects, simulations, or mathematical constructions, for the most part these systems fail to take pedagogical advantage of the wealth of assessment-related data that results from the fact that the students are working on computers. This is due less to the newness of these environments than to the challenges of effectively utilizing the event logs, student writing, and student constructions as evidence of cognitive state, learning preferences, and skills. We propose to integrate and extend two software systems for online education in order to perform a series of experiments that assess the impact of using intensive, unobtrusive assessment tightly integrated with a constructive learning environment upon learning outcomes and efficiencies. The integrated learning environment will be tested primarily with University of Washington freshmen but also with Mercer Island High School seniors, in problem solving and construction activities involving digital image representation and processing, web-based communication, and computer programming. The students' writing, online constructions, online sketches and computer-generated activity logs will be analyzed using a combination of computer-assisted and automated mark-up. The results of mark-up will trigger pedagogical recommendations to instructors, and in some cases, directly to the students. Such interventions may take a variety of forms; for example, a group of students stuck at the point of frustration in solving some problem may benefit by having a key step, performed well by a student in another group, called to their attention. Our objective will be to determine effective methods both for extracting pedagogically useful information from the products and byproducts of online learning and for designing the instruction to enable and benefit from the use of this information.","title":"ITR\/PE: A Learning Environment for Information Technology Concepts Using Intensive, Unobtrusive Assessment","awardID":"0121345","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["65705","539293","308498","308499"],"PO":["564318"]},"51221":{"abstract":"Abstract:<br\/>This proposal centers on research challenges arising from the realization of Pervasive Location-Aware Computing Environments (PLACE). In PLACE, mobile objects are aware of their own locations as well as<br\/>those of surrounding objects. Such an environment enables (i) the navigation of moving objects, (ii) the execution of continuous queries about moving objects, and (iii) services for groups of moving <br\/>objects. The pervasive nature of location-aware objects, the need for timely responses to numerous concurrent continuous queries dependent upon continuously arriving data pose new challenges for scalable query processing.<br\/><br\/>The proposed research investigates query processing, data management, and broadcasting techniques for the efficient execution of continuous queries. The proposed techniques include (i) the use of data filters and indexing techniques to reduce the amount of data the queries need to analyze, and (ii) the development of techniques for executing continuous queries in an environment characterized by differences in bandwidth, communication costs, and computational capabilities of the objects. The proposal includes building a prototype system to validate and evaluate the proposed techniques and solutions.","title":"Query Processing in Pervasive Location Aware Computing Environments","awardID":"0010044","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["486458","470080","425109"],"PO":["565272"]},"63563":{"abstract":"EIA-0115809<br\/>Thomas A. DeFanti<br\/>University of Illinois at Chicago<br\/><br\/>MRI: Development of Instrumentation for AGAVE: the Access Grid Autostereo Virtual Environment <br\/><br\/>This is a proposal for instrumentation development under the Major Research Instrumentation (MRI) program to support research and student training in tele-immersion technologies for a networked, collaborative virtual-reality environment. The focus is on AGAVE, a tiled, high-resolution autostereo display that integrates well with very-high-speed networks.","title":"MRI: Development of Instrumentation for AGAVE: The Access Grid Autostereo Virtual Environment","awardID":"0115809","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["557607","558517",163496,"558518"],"PO":["557609"]},"60186":{"abstract":"EIA-0101247<br\/>David P. Dobkin<br\/>Princeton University<br\/><br\/>CISE Research Infrastructure: CISE Pervasive Computing: Applications and Systems<br\/><br\/>We are entering a new era in computing, the era of ubiquitous computing. In this world, our classrooms, labs, offices, and homes will be filled with a diverse collection of sensor, display and computing devices. Ubiquitous and pervasive displays will revolutionize the way we use computers.<br\/><br\/>In such an environment, the conventional view of the network as providing bit-pipes between clients and servers will no longer be appropriate. Many of the devices available in the environment will have limited computational capabilities and be connected by limited-capacity networks. So, we need an intelligent network that will be implemented by a collection of servers and programmable routers that overlay the physical network substrate.<br\/><br\/>The award is to build a research infrastructure consisting of three components. At the \"edge\" of the system, will be a variety of display technologies and sensors. At the \"core'' of the system, will be an intelligent network using commodity PCs and emerging network processors. Underlying everything will be commodity wired and wireless<br\/>networks to provide connectivity among the edge devices and nodes in the intelligent network. This network will augment the CS Department's current network, which already includes both wired and wireless components.","title":"CISE Research Infrastructure: CISE Pervasive Computing: Applications and Systems","awardID":"0101247","effectiveDate":"2001-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["52508","560046","213809","467986","495323"],"PO":["539087"]},"61275":{"abstract":"The proposed research investigates new methods for symbolic analysis to<br\/>improve various restructuring compiler optimizations. A new algebra on<br\/>functions is investigated to manipulate, simplify, and derive normal forms of<br\/>scalar functions and (generalized) induction variables in multi-dimensional<br\/>loops. The derivation of normal forms for intermediate program constructs<br\/>enables reasoning about the semantics of a program under analysis. This is<br\/>extremely useful to improve various compiler optimizations to effectively deal<br\/>with symbolic expressions in real-world applications. More specifically, the<br\/>proposed research aims to improve symbolic analysis methods such as<br\/>generalized induction variable recognition, linear and non-linear data<br\/>dependence analysis, value range analysis, global value propagation, and<br\/>counting the number of solutions to systems of constraints. The effectiveness<br\/>of parallelizing compilers depends heavily on the accuracy of these methods.<br\/>The research will result in the ability of compilers to more effectively<br\/>handle symbolic expressions and constraints. Current methods are not always<br\/>effective, resulting in considerable performance losses caused by worst-case<br\/>assumptions or when program analysis has to be performed at execution time.","title":"Improving Symbolic Analysis of Restructuring Compilers","awardID":"0105422","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["538628","537233"],"PO":["565272"]},"64311":{"abstract":"Human-Computer Interaction for Direct Brain-Computer Interfaces<br\/><br\/><br\/><br\/><br\/>This is a the first year funding of a 3-year continuing award. Recent developments in medical technology have brought closer the possibility of direct control of a computer by the human brain, e.g. using recordings from electrodes placed on the scalp or a neurotrophic electrode that is implanted in the brain. Although advances in these biometric interface device technologies hold much promise, there are many aspects yet to be researched. For the half-million people with locked-in syndrome (completely paralyzed and unable to speak), and for many others with severe and progressive disabilities such as quadriplegia or ALS, the potential impact of BCI technology are staggering; preliminary results achieved by the PI encourage vigorous pursuit of refinements and improvements in BCI technology. In this project the PI's objectives will be: to establish a theoretical framework for the field of Brain-Computer Interface (BCI) research; to investigate the effectiveness of various user interaction styles for existing brain-computer interface device technologies; and to validate various interaction styles in two quality-of-life application domains, a basic communications application and an environmental control application.","title":"Human Computer Interaction for Direct Brain-Computer Interfaces","awardID":"0118917","effectiveDate":"2001-09-01","expirationDate":"2005-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6846","name":"UNIVERSAL ACCESS"}}],"PIcoPI":[165764,165765,"506686","353970"],"PO":["565227"]},"54994":{"abstract":"The goal of this collaborative research project involving Christos Faloutsos and Ngai Hang Chang at Carnegie Mellon (award 0083148) and Tara Madhyastha at U of Cal Santa Cruz (award 0083130) is to develop and apply statistical and datamining tools to analyze bursty time sequences, with emphasis on I\/O traffic optimization. The interdisciplinary team includes researchers in computer science, computer engineering and statistics, and industry collaborators. The approach has three parts: (1) advanced statistical tools using the ``ARFIMA'' method; (2) wavelets and the related ``80-20 law'' to model disk traffic; and (3) incorporation of these models<br\/>inside the so-called ``Active Disks'', with the goal to build self-tuning, adaptive disk subsystems.<br\/>The results will advance data mining and statistics as well as disk design. An easy-to-use toolkit \"T-REX\" will aid in I\/O and systems design, handling bursty traffic, and better buffering and prefetching. The theory behind the T-REX toolkit will be based on new data mining algorithms and statistical methods that model self-similar time sequences (like web and network traffic,<br\/>in addition to I\/O traffic). The research team has strong ties with database, data mining and disk manufacturing industrial groups, and this will aid in testing the research toolkit and its technology transfer. It can be expected that the T-REX system will significantly aid the design of disk sub-systems with beneficial impact on the storage industry.","title":"COLLABORATIVE RESEARCH: Data Mining Meets I\/O Performance Evaluation: Advanced Statistical Tools for Analyzing Bursty Traffic","awardID":"0083130","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"1269","name":"STATISTICS"}}],"PIcoPI":["555419"],"PO":["563751"]},"67952":{"abstract":"The primary objective of this workshop was to bring together some of the leading experts in complex silicon-level microsystems with key leaders from the molecular devices community to provide some initial thoughts on how to develop future answers to the following questions: <br\/>- How can molecular level interactions driving such systems be expressed in more abstract ways, how can these abstractions be translated into \"primitive\" building blocks, and how should modeling and design tools be built to emphasize such interactions? <br\/>- How does one develop new design strategies for combining such primitive building blocks into larger functional subsystems and then scale into even larger molecular systems, what might some of these design strategies entail, and what might be lifted from our experiences with silicon? <br\/>- What needs to surround a new technology to allow it to scale into complete, designable, complex sys-tems that can communicate with the outside, including legacy technologies such as silicon? <br\/>- What are long term potentials for such technologies, as seen by complex system architects? <br\/>- Where can they help solve bottlenecks that exist in current silicon technology microsystems?<br\/>- Are there new models of computation or system design for which these new technologies are particu-larly well suited?<br\/> <br\/>Given that the bulk of the attendees were primarily architects of computational silicon microsystems, a second objective of the workshop was to re-energize the computer architecture community to develop alter-native or mixed models of computation, new microarchitectural techniques, design tools and approaches for both the new technologies, mixes of old and new, and even port back into silicon. A final objective was to help both the system architecture and the new technology communities begin to develop the dialogs necessary to advance such technologies in a timely manner, and maximize the Government's investments in new programs such as NSF's Molecular Architecture Initiative.","title":"Molecular Architecture Workshop","awardID":"0136041","effectiveDate":"2001-09-01","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["336016"],"PO":["197478"]},"63112":{"abstract":"EIA-0113919<br\/>Klaus Sutner<br\/>Carnegie Mellon University<br\/><br\/>Title: ITR\/IM(EHR) Course Capsules: Persistent, Personalized Courseware<br\/><br\/>This project will design and implement a system that will store, organize, index and make searchable course content, and preserve that content reliably over long periods of time. The specific plans include the systemic use of emerging XML standards to design a course model that supports both content and presentation markup. Course Capsules will not only archive the university generated course materials, but also the creative work of the students. Content markup will allow the Capsules to respond intelligently to requests by a user, and provide each student with a personalized depot of knowledge that remains available even after graduation. For the faculty, Capsules will form a trusted repository of course material and will encourage sharing and reuse. The archive in conjunction with extensive use tracking will provide a sound basis for ongoing review and improvement of curricula.","title":"ITR\/IM(EHR): Course Capsules: Persistent Personalized Courseware","awardID":"0113919","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["424178","311190","491070","226193",162110],"PO":["565223"]},"63123":{"abstract":"This project will develop a framework for studying protein folding that is based on techniques recently developed in the robotics motion planning community. In particular, this work uses Probabilistic Roadmap (PRM) motion planning techniques which have proven to be very successful for problems involving high-dimensional configuration spaces. The key advance that PRMs offer protein science is the ability to efficiently explore large conformational transitions of realistic models of proteins. The work involves research in both protein science and information technology. <br\/><br\/>The project has two main research goals related to protein science. First, PRMs are expected to provide a computational method to predict the folding kinetics of proteins, when the native structure is already known. This makes PRMs ideal for investigating classical problems in protein folding kinetics such as kinetic intermediates, kinetic traps, parallel vs. series folding routes, and general folding mechanism questions related to potential energy landscapes and zippers processes. Second, PRM, used in conjunction with a new ENPOP parameter optimization strategy, has the potential to improve energy models both high-resolution and low-resolution models for predicting biomolecule conformations. <br\/><br\/>The project has two main research goals related to information technology. Both are motivated by the massive computational requirements of the simulations needed to investigate the protein folding questions. First, new strategies and optimization techniques for PRMs will be needed to support the efficient extraction of high quality paths from the roadmaps for problems with hundreds of dof. Second, since PRMs are known to be amenable to parallel implementation, they will utilize high-performance computing. This will include the development and application of an adaptive parallel version of the C++ STL (Standard Templates library) called STAPL. With STAPL, the simulations can be optimized and run on various parallel and distributed systems and yield a performance approaching that of code manually optimized for each platform","title":"ITR\/AP: A Motion Planning Approach for Protein Folding Simulation","awardID":"0113974","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["561154"],"PO":["381214"]},"67853":{"abstract":"We propose to hold a two-day workshop in Tucson, Arizona during fall 2001 on emerging ultra-large<br\/>networks, such as the Internet. Hosted by Arizona Center for Integrative Modeling and Simulation, the<br\/>meeting will bring together some of the world's leading researchers in the networking area to meet with<br\/>counterparts with expertise in modeling and simulation of networks and of systems more generally. The<br\/>workshop will provide these researchers with the task of coming up with the unknowns of ultra-large<br\/>networks and with new directions of research in modeling and simulation that can address these unknowns.<br\/> The Internet is increasing in connectivity, toward 1 billion nodes in 2005 and node capability providing a<br\/>highly interconnected and computationally powerful medium. Such a globally and ubiquitously dispersed<br\/>network will provide a new frontier for new kinds of educational, commerce and entertainment activities.<br\/>However, there are many issues that arise in the emergence of such a large, highly decentralized, collection<br\/>of interaction parts. The increased connectivity and capability creates new complexity and dynamics that<br\/>we are only on the verge of appreciating. Difficulties in dealing with large-scale software systems are well<br\/>documented in a recent report by the National Research Council. Techniques that work for small software<br\/>systems fail markedly when the scale is increased by one million fold. Computer-based modeling and<br\/>simulation (M&S) methodology is required to address these issues since the scale is well beyond what<br\/>analytical tools alone can handle and there is limited ability to do controlled experiments on the always<br\/>on Internet. Traditional M&S approaches have focussed on the micro-level components rather than the<br\/>macro level integration of these components. However, with the advent of ultra-large scale systems such as<br\/>the Internet of the future, it is necessary to develop M&S approaches for understanding the behaviors of<br\/>very large inter-connected networks with very few loci of control and many interacting and varied sources<br\/>of input and services demand.<br\/> The results of this workshop are expected to be a set of specific finding of gaps in our knowledge of the<br\/>behavior of ultra-large networks and how to deal with their design, management, and control. Participants<br\/>may assess whether current approaches can be evolved to deal with the large increases in scale or whether<br\/>different, revolutionary paradigms are required. Participants will address the need for new techniques and<br\/>approaches for building models of ultra-large networks and developing simulation environments for<br\/>studying their behaviors. Suggestions for borrowing points of view form other areas such as complex<br\/>adaptive systems and from basic theory of modeling and simulation will be encouraged. The proceedings<br\/>will be compiled in a form that will provide a useable and significant guide for new NSF funding initiatives<br\/>for future network infrastructure research.","title":"Workshop on Ultra-Large Networks: Challenges and New Research Directions for Modeling and Simulation","awardID":"0135530","effectiveDate":"2001-09-01","expirationDate":"2003-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["524966","547801"],"PO":["234222"]},"66764":{"abstract":"EIA-0130385<br\/>Russell J. Deaton<br\/>University of Arkansas<br\/><br\/>Title: Modeling and Manufacture of Huge DNA Oligonucleotide Libraries for Computation<br\/><br\/>Computing with DNA, with its advantages of massive parallelism and huge information density, promises a number of revolutionary applications, as well as the potential to solve problems beyond the capabilities of conventional computers. A critical barrier, however, is unplanned crosshybridization among oligonucleotides. In order for the computations to be reliable and efficient, and to scale to larger problems, the DNA sequences have to be designed to minimize these unplanned crosshybridizations. Though pairwise hybridization is well modeled and understood, design of such libraries is challenging because of the huge number of pairwise hybridization's, and the conflicting constraints of maximizing the library size while minimizing crosshybridization.Therefore, to overcome these limitations, huge libraries of non-crosshybridizing DNA oligonucleotides are manufactured by in vitro evolution with a PCR-based protocol that selects from a random pool those oligonucleotides that are maximally mismatched. In addition, because enumeration of all pairwise hybridization energetic in a huge library is computationally prohibitive, a statistical approach, which is based upon spin glass physics, is used to model the library. The model is the basis for a set of analysis and design tools for application to the libraries.<br\/><br\/>Because of the fundamental importance of DNA hybridization in DNA computing, the modeling and manufacture of huge libraries of DNA oligonucleotides is producing foundational principles and results for the field. The size of the largest libraries of non-crosshybridizing oligonucleotides is also the limit on the size of feasible computation. The libraries are an enabling resource not only for large-scale DNA computations, but also biotechnology applications, such as reusable, universal DNA microarrays. In addition, the libraries, as well as the software tools, are available for reproduction and use by other researchers in DNA computing and biotechnology.","title":"Bio-QuBIC: NSF QuBIC: Modeling and Manufacture of Huge DNA Oligonucleotide Libraries for Computation","awardID":"0130385","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}}],"PIcoPI":["541916","284570","461485","548478","284572"],"PO":["565223"]},"66885":{"abstract":"EIA-0130869 <br\/>Benjamin Watson<br\/>Northwestern University<br\/><br\/>CISE Research Resources: A Shared Data Cluster for Real Time Interaction With Massive Datasets<br\/><br\/>The research at Northwestern is increasingly concerned with the issues involved in providing interactive and affordable access to massive (terabyte scale) datasets. In particular, they focus on visualization of these datasets using perceptually based computer graphics techniques and display the visualizations using a combination PC CAVE and Active Mural. They also study the issues involved with ubiquitous access to high-resolution spatial datasets from mobile devices, and leverage a powerful wireless network. They focus on prediction-based adaptation and scheduling for distributed interactive applications and are building a compute cluster to support this work.<br\/><br\/>What is missing in the existing shared research infrastructure is a facility to store and serve massive datasets interactively, with low latency and high bandwidth. The researchers will build such a shared data cluster. The data cluster will be very high performance and capacity PC RAIDs interconnected with a multi-GB\/sec SAN. The SAN will connect to their compute cluster, CAVE\/Mural, mobile devices and wired client machines. The combined data and compute clusters will be sufficient to pump 200 MB\/s from disk to the CAVE\/Mural screens. The combination of the data cluster, compute cluster, CAVE\/Mural, local network infrastructure, and desktop and mobile clients will let them study interactivity in the large.","title":"CISE Research Resources: A Shared Data Cluster For Real Time Interaction With Massive Datasets","awardID":"0130869","effectiveDate":"2001-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["540138","423456","326088"],"PO":["557609"]},"77423":{"abstract":"A major obstacle in building robust systems that extract and interpret information, and summarize and answer questions from texts, is the need to identify the entities referred to by pronouns or other referential expressions. This project extends the PI's prior work involving the development of an empirical reference resolution system that relies on several sets of heuristics that correspond to various forms of reference. In particula, the framework will be extended to learn semantic knowledge that supports consistency checks. This enhancement will provide high precision reference resolution and also enhance substantially the recall of <br\/>referential links. The research will be evaluated using referenceannotated texts and the Penn Treebank corpora. The outcome will be a corpus-based method for reference resolution for both pronouns and nominal <br\/>expressions. First, the semantics of all referential noun phrases will be captured. Then, by extending the <br\/>empirical environment with bootstrapping, this reference resolution technique should lead to a <br\/>powerful tool capable of resolving reference correctly in a large variety of texts. Finally, the tool will be <br\/>incorporated both in an information extraction system and in a question\/answering system, to measure its <br\/>contribution to the overall performance of these systems. The proposed research departs from previous approaches to reference resolution, in that it promotes data-driven techniques instead of relying on combinations of linguistic and cognitive aspects of language. The immediate pragmatic outcome indicated by the preliminary results should be a substantial recall enhancement.","title":"CAREER: Reference Resolution for Natural Language Understanding","awardID":"0233177","effectiveDate":"2001-09-01","expirationDate":"2007-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}}],"PIcoPI":[201965],"PO":["565215"]},"64113":{"abstract":"Interactive Multimodal Interfaces: Designing for Human Performance<br\/><br\/><br\/>This is a creativity extension to the PI's continuing award. The PI plans to conduct a study involving mobile testing of her multimodal system. Subjects will be a mixture of adults and 7-to-9-year-old children. The goals include: (1) establishing the full research infrastructure needed to support extensive mobile testing and semi-automated data analysis; (2) documenting mutual disambiguation during mobile testing of a multimodal system, and studying the factors associated with its enhancement; (3) examining the relation between system recognition performance in a mobile environment and users' signal characteristics, ambient noise levels, and signal-to-noise ratio information; and (4) exploring mobile speech signal patterns and system recognition performance in diverse user groups. The study will provide critical information about multimodal interface designs appropriate for supporting robust mobile use in real-world contexts and by varied users, and in particular for creating adaptive multimodal architectures that are capable of monitoring the environment on a command-by-command basis and adapting mode weights intelligently to avoid recognition failure and stabilize system performance. The data collected during the use of the PI's mobile system will assist in identifying a variety of new research issues and interface design challenges that have neither been recognized nor probed by the broader research community","title":"Designing Next-generation Mobile Interfaces for Dynamic Conversational Speech","awardID":"0117868","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"W359","name":"DARPA-NEW DIRECTION IN ADAPTIV"}}],"PIcoPI":["515490","539504"],"PO":["565227"]},"67776":{"abstract":"The workshop will consider both short-term and longer-term issues in processor evaluation. The rationale for considering at least some short-term issues is clear: the simulation crisis is already here. Even the SPEC95 benchmarks cannot be run to completion using cycle-accurate simulation. The SPEC2000 benchmarks are substantially longer. A variety of techniques for reducing simulation time are currently in use, yet there is no agreement on which techniques are most appropriate. Some clearly-invalid evaluation techniques are in use simply because there are no alternatives that offer scientifically-valid results with the necessary turnaround times.<br\/><br\/>We propose to use the following questions as a starting point for discussion.<br\/><br\/>Metrics: What are the proper metrics to use for various architectural studies?<br\/><br\/>Benchmarks: What are the appropriate benchmarks to use for various architectural studies in the next 5 years?<br\/><br\/>Abstractions: How can researchers determine when abstractions that accelerate simulation (but may reduce accuracy) are appropriate and when they are not? How can their accuracy and precision be characterized?<br\/><br\/>Sampling: How\/when\/whether can researchers use mixed-mode simulations that vary between high and low amounts of detail in a single simulation? How can the accuracy of such simulations be verified?<br\/><br\/>Sensitivity: How can researchers structure sensitivity studies to determine when a low-level error will translate into large errors, as opposed to when the low-level error's effect will be masked when aggregated into the full simulation?<br\/><br\/>Validation methods: How can a processor simulation be validated before a similar processor is built?<br\/><br\/>Hardware assists: How can simulations make use of hardware performance counters and other hardware assists for evaluating next-generation processors (which may have different organizations than the systems from which we are obtaining hardware counts)?<br\/><br\/>Portability: Processor models are complex and often closely tied to the simulation infrastructure (e.g., SimpleScalar, ATOM) on which they are developed, and once a model has been validated, it becomes expensive to develop new models. Yet different simulator platforms are best suited for different experiments. How can the portability of processor models best be accomplished?<br\/><br\/>Power: What new simulation questions are raised by the growing interest among architects in power modeling?","title":"International Workshop on Simulation and Evaluation Techniques for Modern Processors","awardID":"0135209","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["489873"],"PO":["180163"]},"63068":{"abstract":"For the next generation Very Large Scale Integration (VLSI) circuits, the signal delay will be dominated by parasitic resistance (R), capacitance (C), and inductance (L) of the interconnect. The ability to extract RCL<br\/>parasitic quickly and accurately is crucial to the design and verification of large VLSI circuits. This project will develop innovative algorithms and software for fast and accurate extraction of RCL parasitic of VLSI<br\/>circuits. The main goal of the project is the design of preconditioned iterative methods for solving the linear systems arising in inductance and capacitance extraction problems. Solvers for the inductance problem will<br\/>use a novel solenoidal basis approach to precondition a reduced system implicitly, leading to rapid convergence of the iterative methods. Fast approximations to the matrix-vector products with dense system matrices<br\/>will be computed using efficient hierarchical methods. <br\/><br\/>Parallelism in the algorithms will be exploited to develop high-performance software that is capable of tackling large problems. Software developed for this project will be portable across a variety of<br\/>parallel architectures. It is anticipated that the code will deliver the performance necessary for parasitic RCL extraction of deep sub-micron VLSI circuits of realistic sizes.","title":"ITR\/AP: Modeling and Simulation of Sub-micron VLSI","awardID":"0113668","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["196484","258835"],"PO":["562984"]},"64289":{"abstract":"As 3D volume data becomes more prevalent from simulations and sensing equipment, and as volume rendering APIs are becoming available in software and hardware implementations, the need to manipulate volume models arises. However, the work on manipulating volume models for analysis and computer graphics applications is sparse. The few methods that are available are computationally expensive and non-intuitive. This project avoids these problems by using volumetric skeletons to control manipulation. The skeleton acts as a ubiquitous data structure for volumes and allows manipulation in a much more intuitive and general manner. The skeleton is computed from the actual volume with a reversible thinning procedure based upon the distance transform. The skeletal points are connected and arranged in a skeleton-tree structure. The key to this process is the reconstruction phase that maps the sampled voxels around the skeleton-tree. The skeleton is an intuitive mechanism for manipulation. For example, a user can deform the skeleton to create the corresponding deformations in the volume. The skeleton-tree allows the user to reshape volumes and create new visualizations. Among other things, this allows culling sections of a volume logically, morphing volumes to simulate changes in a 3D feature over time, detecting collisions for interactive volume-based virtual reality applications, and volume animation and volume graphics (mimicking the standard graphics pipeline with volumes). Because skeletons can be generated hierarchically, they can be used to perform a variety of tasks including volume smoothing and level-of-detail representation.<br\/><br\/>The goal of this project is to extend and fundamentally enhance previous research in volume skeletonization. It will develop a full range of robust skeletal algorithms and interactive tools. The researchers will investigate the exciting new visualization applications of the parameter-based volume skeleton. This should have a wide impact in the visualization and computer graphics communities.","title":"VISUALIZATION:Manipulating Volumes: A New Paradigm for Advanced Volume Visualization","awardID":"0118760","effectiveDate":"2001-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}}],"PIcoPI":["524497"],"PO":["565272"]},"57546":{"abstract":"The combination of device complexity and design diversity point towards<br\/>systems that will be constructed from components that are both inherently and<br\/>observably heterogeneous. What is needed is a new design discipline that<br\/>accounts for inherently erratic component behavior, and facilitates the<br\/>design and implementation of robust and predictable systems. <br\/><br\/>The necessary infrastructure for robust application development is being<br\/>developed within the context of a new system for cluster programming known as<br\/>Ice. Research proceeds along four axes: the creation of fully robust<br\/>data-transfer mechanisms, the exploration of advanced techniques for<br\/>adaptation, new approaches to automation and ease-of-use, and development of<br\/>the theoretical underpinnings of robust systems. <br\/><br\/>The overall goal of this work is to develop a fundamental understanding of how<br\/>to build scalable clustered systems that ``work well'', even when some of the<br\/>underlying components do not. Such truly robust systems are predictable,<br\/>reliable, and available, perform well in spite of fluctuations and failures of<br\/>constituent components, and require no human intervention. One of the main<br\/>advantages of such systems is the reduction of the burden of administration:<br\/>new components are simply added and utilized to their full capacity.","title":"NSF\/CAREER: Robust Data-intensive Cluster Programming","awardID":"0092840","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}}],"PIcoPI":["550389"],"PO":["565272"]},"59614":{"abstract":"Information systems are now mobile, wearable, multimodal, real-time, scalable from workstations to<br\/>desktops to notebooks to palmtops to cellular, collaborative and ubiquitous. Network access is becoming<br\/>increasingly important as a part of the computing infrastructure. Unfortunately, for the near term, un-limited bandwidth, anytime access to a network is not feasible, particularly in large urban environments<br\/>where interference, occlusion and collision are ongoing problems. To alleviate this, we are developing a<br\/>set of context-aware Autonomous Information Retrieval (AIR) pods. These are small, hardened low-cost<br\/>computers that require only electric power. AIR pods have sufficient local storage to hold relatively static<br\/>information and are equipped with two wireless interfaces: one short-range, unlicensed high-speed interface<br\/>such as IEEE 802.11 and one long-range, low-speed interface such as CDPD or other Wide Area Network<br\/>connection which may be intermittent. AIR pods can be either stationary or mobile. Stationary AIR pods<br\/>can be attached to lamp posts and traffic lights, hidden in lighted store signs or in subway stations. Mobile<br\/>AIR pods can be attached to delivery trucks, postal service vehicles, buses, police cruisers, taxis or other<br\/>vehicles that roam city streets. AIR pods are also small enough to be carried in backpacks.<br\/> We propose to develop and implement the prototype hardware and software AIR idea, and explore what<br\/>kinds of infrastructure support are necessary to make these devices a key component of network applications.<br\/>Research issues addressed will be cooperative data sharing, resource scheduling and anticipatory caching,<br\/>message propagation and wide-area resource discovery.<br\/> The proposed mobile networking infrastructure will be tested in a demanding set of context-aware mo-bile research projects. The first project is a wearable augmented reality system that allows outdoor users to tour a campus interactively. A second related project allows indoor users to collaborate with those outside over wireless networks. The third project is a mobile robot sensing system that can autonomously explore the campus and create rich 3D, texture mapped, site models. All of these applications need to interact with host computers through limited network access, and we propose to optimize this interaction over bandwidth, devices, and locality using context-aware wireless networks.","title":"Infrastructure for Context-Aware Wireless Network Applications","awardID":"0099184","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["518026","530199","518545"],"PO":["7594"]},"67116":{"abstract":"EIA-0131958<br\/>Bowker, Geoffrey<br\/>University of California - San Diego<br\/><br\/><br\/><br\/>BDEI: Designing an Infrastructure for Heterogeneity in Ecosystem Data, Collaborators and Organizations<br\/><br\/>Project Summary<br\/><br\/>Biodiversity and ecosystems data are currently being gathered in a large range of formats by a<br\/>constellation of loosely connected private, government and not-for-profit agencies. The normal response<br\/>to this double heterogeneity has been the development and enforcement of metadata (data about data)<br\/>standards; in this response one tries to abstract data away from its organizational context in order to<br\/>render it universally accessible. This project takes the opposite track, and seeks new ways of grounding<br\/>environmental data in its organizational context in such a way that it can both be used more flexibly today<br\/>and so it can retain its value longer. The hypothesis, based on the last 25 years of work in the field of<br\/>Science Studies, is that formal data descriptions must be wrapped in informal descriptions in order to<br\/>be useful. The informal description for short-lived data is provided by face-to-face contact, by<br\/>exchanging graduate students, through conference papers and so forth. It is precisely this layer which is<br\/>lost in highly distributed data collection efforts characteristic of biodiversity and ecosystem informatics; it<br\/>is also this layer which is lost when data is wrapped in formal metadata and saved to disk. The goal of<br\/>this project is to open up a major new field of database inquiry tied precisely to the specific problems of<br\/>the biodiversity and ecosystems communities generated by their need for very long lasting and highly<br\/>distributed data. The project will develop into a larger study of the articulation between metadata and<br\/>narrative modes of wrapping data.","title":"Biodiversity and Ecosystem Informatics - BDEI: Designing an Infrastructure for Heterogeneity of Ecosystem Data, Collaborators and Organizations","awardID":"0131958","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"W100","name":"INTERIOR-NBII JOINT FUND COMPE"}}],"PIcoPI":["532090","259849"],"PO":["371077"]},"68216":{"abstract":"The rapid advancement of networking technologies and increasing use of embedded devices has extended the scope of traditional computational systems to include intelligent control of physical environments. There are many challenges in such embedded hybrid control systems. Traditionally, the programming language community focused on modeling and reasoning about the semantics of interactions between distributed agents, while the real-time computing community focused on how to manage CPU and network communication resources so that real-time tasks can predictably meet their end-to-end timing constraints. <br\/><br\/>This proposed effort integrates the Actor theory with the theory of real-time elastic control. Real time elastic control theory is an innovative approach that integrates the design of a feedback controller with the design of a real-time scheduler. Traditionally, feedback control is a prototypical example of hard real-time applications. This work allows the controller to adapt to unpredictable surges in workload by slowing down its sampling frequencies and adjusting its gains. Such workload surges are unschedulable without the controller adaptation. The word \"elastic\" refers to the dynamic changes of controller deadlines to improve the management of available computing resources. This work broke the barrier between real-time scheduling theory and feedback control theory. By integrating this theory with Actor model, the barriers between programming language and concurrency control theory, real-time scheduling theory, and feedback control theory will be broken. In addition to the usual qualitative properties (such as eventuality) handled by current formalisms for distributed systems, this work will lay the foundation for a unified framework that will allow users to reason about quantitative properties including whether the timing requirements can be met and the physical system under control is stable.","title":"SGER: Integrating Actor Model with Real-Time Elastic Control Theory","awardID":"0137090","effectiveDate":"2001-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["460466","553686"],"PO":["187585"]},"59757":{"abstract":"The project focuses on a system for bringing enhanced tactile sensitivity and dexterity to supervised tele-manipulation. The proposed structure will utilize a combination of tactile, force, audio, and visual feedback channels between a human operator and a slave system consisting of a robot arm manipulator and a multi-fingered hand. The proposed approach builds on upon existing work in grasping and dexterous manipulation, telemanipulation, and tactile sensing. Future applications of this work include, maintenance, repair, exploration, and salvage operation in remote and hazardous environments.","title":"Supervised Dexterous Manipulation with Haptic Feedback","awardID":"0099636","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["508165","378572"],"PO":["335186"]},"61320":{"abstract":"This research investigates core architectural features for secure and private communications and computations over the public Internet and wireless infrastructures. It focuses on what instruction-set architecture (ISA) features general-purpose processors would have, if secure information processing is the default pervasive mode of operation, with non-secure processing the optional mode, rather than vice versa. It proposes ISA features for very fast, flexible, software cryptographic processing, not only for current algorithms but also to enable algorithm designers to create new cryptographic algorithms that are more secure and more efficient. Word-oriented, programmable processors can be radically more effective for cryptographic functions with new instructions for sub-word manipulations, as well as for multi-word arithmetic. Novel bit permutation instructions are proposed for providing superior diffusion capabilities for current and future symmetric key algorithms. Their performance, area and latency tradeoffs, and scalability with superscalar organizations are studied. Very fast table lookup and other ISA features are also studied for algorithms like Rijndael, the recent Advanced Encryption Standard winner, and for public-key algorithms like Elliptic Curve Cryptography. The research also investigates architectural features for secure key management, and other ISA features designed to enhance or enforce system security.","title":"Instruction Set Architecture for Pervasive Security","awardID":"0105677","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["518483"],"PO":["180163"]},"63982":{"abstract":"Adaptive Representations for Genetic Algorithms and Local Search<br\/><br\/><br\/><br\/><br\/>This is the first year funding of a three year continuing award. The PI's recent theoretical results prove there are advantages to reflected Gray codes compared to standard binary encodings when used as a representation for search and parameter optimization problems (e.g., it is possible to use a simple mechanism to escape local optima by adaptively switching between different reflected Gray codes). Preliminary empirical results indicate that using high precision adaptive Gray codes leads to better optimization, and new convergence results have been proven. In this project, a family of high precision adaptive Gray codes will be developed for use with genetic algorithms and local search. The PI will further conduct a broad comparative evaluation of evolutionary algorithms, local search and other heuristic search methods that do not require derivative information. A real-world application will be addressed related to a new generation of much more accurate weather prediction systems. The CloudSat project will in the next few years deploy a satellite-based system for modeling cloud structures, and the search methods developed in this project will be the best and fastest way to solve a key inverse problem which lies at the heart of such models, as a consequence of which they appear to be likely candidates for inclusion in the scheduled 2003 deployment of CloudSat.","title":"Adaptive Representations for Genetic Algorithms and Local Search","awardID":"0117209","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6846","name":"UNIVERSAL ACCESS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":[164944],"PO":["491702"]},"61331":{"abstract":"Critical path prediction is a processor architecture technique that uses <br\/>the past behavior of instructions in the instruction stream to predict which<br\/>fetched instructions will be on the critical path; that is, which <br\/>instructions will have a significant impact on processor performance, and <br\/>which will not. This information can then be used to guide the selective <br\/>application of a variety of processor optimizations.<br\/><br\/>Modern processors remove most artificial constraints on execution<br\/>throughput. Therefore, the bottleneck for many workloads on current <br\/>processors is the true dependences in the code. Chains of dependent <br\/>instructions constrain the overall throughput of the machine, often leaving <br\/>aggressive processor technology highly underutilized. These chains of <br\/>dependent instructions constitute the critical performance path, or <br\/>critical path (CP), though the code.<br\/><br\/>The performance of the processor is thus determined by the speed at<br\/>which it executes the instructions along this critical path. In our<br\/>efforts to get the maximum performance from the processor, it is no<br\/>longer reasonable to treat all instructions the same. If we can know<br\/>which instructions are critical to performance, we can accelerate<br\/>their execution, possibly at the expense of instructions not on the<br\/>critical path.<br\/><br\/>This research will attempt to identify these critical instructions<br\/>dynamically in hardware. We call this critical path prediction. This <br\/>prediction is based on the behavior of previous invocations of the <br\/>instruction in the pipeline. This prediction will enable the processor to <br\/>make better decisions about where to apply certain policies and <br\/>optimizations. A variety of critical path predictors will be examined.<br\/><br\/>In many cases, critical path prediction will enable more effective <br\/>application of other resources or optimizations. Possible applications of <br\/>critical path prediction include guiding value prediction, instruction <br\/>reuse, instruction issue priority, instruction scheduling on a clustered <br\/>architecture, speculation control on a power-constrained processor, <br\/>arbitration between instructions or threads on a multithreaded <br\/>architecture, or to guide the spawning of speculative threads in a <br\/>speculative multithreaded processor.","title":"Critical Path Computing","awardID":"0105743","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["542069","293079"],"PO":["180163"]},"61353":{"abstract":"In all networks that have a broadcast channel as the basis of communication, the medium access control (MAC) protocol serves a vital role, as it directly controls the access to communication resources. As the networks and the traffic they carry both become more heterogeneous the question is how to best adapt to the unknown or changing network conditions. The natural answer provided by most existing protocols is to include some kind of adaptivity in order to dynamically adust their operation to the actual network conditions. Examples of adaptivity include hybrid protocols that periodically recompute slot assignments, adjustment of retransmission probabilities (e.g., backoff mechanisms), as well as many other ad hoc solutions that tend to become unstable under high load. Rather than what amounts to essentially tuning parameters of the protocol \"on the fly,\" we instead propose a new \"meta-MAC\" protocol framework that implements new dimension of adaptivity, on top of existing MAC protocols. Specifically, we propose research on a method, whose roots are in Artificial Intelligence (A1), to systematically and automatically combine a set of existing protocols into a single MAC protocol in a novel way, such that the resulting combined protocol has provable optimality properties. Each protocol in the set may be a good candidate for certain situations. For example, a randomized contention based protocol is good for low loads, due to its low delay, while an allocation based protocol is desirable for high loads, as it avoids the breakdown induced by too many collisions. Then the meta-protocol will automatically find combined decisions that dynamically represent the \"best of the team,\" under the actual network conditions, without having to know in advance which of the conditions will actually occur and how they will change. Thus, rather than tuning parameters in an ad hoc manner, we systematically and automatically optimize the medium access approach itself. The proposed research program intends to fully explore the promising potential of the novel meta-MAC protocol aggregation approach, in which encouraging initial results of the PI and co-PI have already shown the principal feasibility. Specifically, the three main research directions include aggregating more sophisticated MAC protocols (such as IEEE 802.11), dynamically altering the protocol mix to support Quality of Service (QoS) at the MAC layer, and an in-depth study of the correctness, stability, and consistency of meta-MAC protocols. Our proposed meta-MAC optimization runs autonomously without any centralized control or any message exchanges. This makes the meta-MAC approach inherently scalable to arbitrarily large networks. Thus, the meta-MAC approach is ideally suited for the evolving application requirements of today's increasingly heterogeneous networking environments. In addition to the above, we plan to incorporate the general approach into the graduate curriculum in the new Telecommunications Engineering Program at the University of Texas at Dallas, thus enriching the traditional telecommunications curriculum with novel adaptive methodologies that provide intelligent, highly adaptive solutions in large, dynamically changing, heterogrneous networks.","title":"Meta-MAC Protocols: A New Dimension to Adaptation in Medium Access Control","awardID":"0105985","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["451890","521384"],"PO":["565090"]},"64741":{"abstract":"This project is developing and analyzing algorithms to solve problems of communication and data sharing in highly dynamic distributed environments such as found in networks of mobile and embedded devices. The term dynamic here encompasses many types of changes, including changing network topology, processor mobility, changing sets of participating client processes, a wide range of types of processor and network failures, and timing variations. The properties being studied include ordering and reliability guarantees for communication and coherence guarantees for data sharing. The algorithmic results are accompanied by lower bound and impossibility results, which describe inherent limitations on what problems can be solved, and at what cost. This is particulary important in the networks of embedded devices that need to operate subject to the resource constraints such limited battery power, storage capacity, communication bandwidth and computation power. <br\/><br\/>The communication and data-sharing problems to be solved are viewed as high level global services, which span network locations. These services generally provide performance and fault-tolerance guarantees, conditioned on assumptions about the behavior of the environment and of the underlying network substrate. Traditionally, research on distributed services has emphasized specification and correctness, while research on distributed algorithms has emphasized complexity and performance. This project combines and synthesizes these two concerns: It yields algorithms that perform efficiently and degrade gracefully in dynamic distributed systems, and whose correctness, performance, and fault-tolerance guarantees are expressed by precisely-defined global services. Because the setting is so complex, the algorithms are also be very complex, which means that it it is necessary to decompose them into smaller, more manageable pieces. In this project, many of those smaller pieces are being viewed as lower-level, auxiliary global services. These auxiliary services provide lower-level communication and data-sharing capabilities, plus other capabilities such as failure detection, progress detection, consensus, group membership, leader election, reconfiguration, resource allocation, workload distribution, location determination, and routing. This work is being carried out in terms of a mathematical framework based on interacting state machines. The state machines include features to express issues of timing, continuous behavior, and probabilistic behavior. <br\/><br\/>The theoretical work in this project is guided by the requirements of systems that include networks of mobile and embedded devices and examples chosen from several prototype applications, including distributed file management, information collection and dissemination, computer-supported cooperative work, distributed games, and multimedia transmission.","title":"ITR\/SY: Communication and Data Sharing Services for Dynamic Distributed Systems","awardID":"0121277","effectiveDate":"2001-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["517826","451177"],"PO":["561889"]},"61122":{"abstract":"Data compression techniques that are important in modern efficient communication and storage systems are implemented using computer system architectures with multiple processing elements. Computer failure errors reduce the reliability of many parts of the overall system because compression is achieved by<br\/>reducing the residual redundancy common to all forms of data, particularly image representations. Also, the resulting formats are extremely sensitive to errors introduced by the communications or storage medium. This susceptibility to errors has long been known and most international data compression standards include resilience features designed to eliminate or mitigate channel error effects. Error control coding is employed<br\/>in conveying the compressed data. However, there are quite different classes of errors emanating from failures in the computing resources that implement the compressing, transmitting and expanding of the data. The impact of such computational failures can be disastrous to critical data in remote-sensing or medical applications that depend on compressed data. Hence, fault tolerance capabilities need to be considered in system<br\/>architectures realizing the compression systems.<br\/><br\/>The proposed research will introduce fault tolerance design methods in data compression computing architectures so that temporary computer failures are detected, guaranteeing that no corrupted compressed data reaches the intended user without warning or appropriate action. The research will analyze the specialized effects of computer failure errors in supporting system parts and will provide design methodologies to integrate fault tolerance in standard data compression algorithms. Protection levels will<br\/>be verified by computer simulations of the proposed architectural designs. The ultimate goal of this research is to influence optional features in data compression standards that insure fault tolerance capabilities for critical applications.<br\/><br\/>Common aspects of various compression standards will be studied concerning computer failure errors. The work will begin with still image standards and later expand to those for video images where motion is involved. Fast transform algorithms, integral to many standards, are highly susceptible to even a single computational error, and special design techniques are required to avoid overwhelming any protection methods applied to them. Most compression standards rely on lossless coding techniques such as Huffman or<br\/>arithmetic coding. The outputs from these coding steps contain very little redundancy from which failure errors can be detected. The prediction methods for compressing motion data have feedback paths that greatly exacerbate computer-induced errors, and fault tolerance design techniques will need to be developed especially for them. Any fault tolerance design procedures must also be integrated with the limited error control features and resilience capabilities already present for combating communication or storage<br\/>errors, even though they address a totally different class of effects.","title":"Fault Tolerance in System Architectures Implementing the Compression, Transmission and Expansion of Data","awardID":"0104851","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":[157230],"PO":["180163"]},"64400":{"abstract":"Abstract 0119532 Paul Fishwick University of Florida<br\/>Title: An Investigation into Aesthetic Computing Within the Digital Arts and Sciences Curricula<br\/><br\/>This project integrates research in \"aesthetic computing\" directly into a new set of CISE programs, collectively called Digital Arts and Sciences (DAS). The thrust of DAS is to create a student who is endowed with a hybrid-knowledge of computer engineering and the arts. This enables the student to work effectively in production-oriented teams centered on projects involving videos, interactive games, education, scientific and engineering visualization, and software engineering. The research integration is accomplished through the addition of an Aesthetic Computing course and a series of Digital World Production Studio courses. Both Fine Arts as well as CISE students take these courses, and the PIs team-teach the studio course. Aesthetic Computing refers to the use of genres and styles in fine art employed as metaphors for formal and diagrammatically rendered model structures commonly found in computing, such as automata, data flow graphs, data models and the comprehensive Unified Modeling Language (UML). This work builds upon many areas outside of CS such as semiotics, linguistics, analogy, metaphor, and the arts. Ongoing progress in the information and program visualization literature is most related; however, the project's focus is on a stronger arts component that both personalizes and enriches the user's modeling interface. For example, the representation of a finite state machine may be crafted, through metaphor mapping, to a scale or virtual model of a building. The style of the building can be taken from the huge variety of possible genres existing in architecture, without limiting the representation to abstract entities. And, elements of music and story schemata can be simultaneously mapped onto the architecture, further personalizing the interface. The goal of the project is to develop practitioners who understand both the formalisms of visualization and the practical aspects of human communication that deal with aesthetic interpretation.","title":"Educational Innovation: An Investigation into Aesthetic Computing within the Digital Arts and Sciences Curricula","awardID":"0119532","effectiveDate":"2001-09-01","expirationDate":"2006-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}}],"PIcoPI":[166002,"485200",166004],"PO":["551712"]},"67931":{"abstract":"EIA-0135946<br\/>Fortes, Jose A<br\/>University of Florida<br\/><br\/>ITR\/SY: Design and Simulation of Biologically inspired Nanolattice<br\/><br\/><br\/><br\/><br\/><br\/><br\/>This joint project between the University of Florida and Purdue University is pursuing scientific principles for designing and engineering biologically inspired neuromorphic computing architectures using radically new molecular electronic devices and biologically inspired, ultra-dense, self-assembled systems. Examples of applications of these architectures include unprecedently small and inexpensive nanoscale intelligent sensors. The architectures can be used to implement neurocomputing models and are well suited for nanotechnologies, thus accelerating the development of useful nanotechnology by providing clear functional targets for nanodevices.<br\/>The team of investigators includes computer architects, neurocomputing experts and device physicists working in close collaboration along three highly synergistic thrusts. One of the two thrusts is focused on advancing the understanding of biologically-inspired dynamic information processing systems in order to understand the impact of constraints imposed by architectures and technologies on the properties of these systems. Another thrust investigates neurocomputing system architectures that can be engineered within the constraints of nanotechnologies. The third thrust develops a toolbox of novel mechanisms for integration, self-assembly and interconnection of nanoscale devices. <br\/>The architectures are investigated via formal methods and simulation. Internet resources are used to conduct simulation, and to disseminate models, software and other research results. A new course, summer internships and educational materials are being developed to educate students on the key interdisciplinary aspects and results of the project.","title":"ITR\/SY: Design and Simulation of Biologically-inspired Nanolattice","awardID":"0135946","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["540130","438490","492015"],"PO":["565223"]},"63102":{"abstract":"EIA-0113864<br\/>Vincent Aleven<br\/>Carnegie Mellon University<br\/><br\/>ITR\/PE(CISE): Tutoring Explanation and Discovery Learning: Achieving Deep Understanding through Tutorial Dialog<br\/><br\/>This multidisciplinary research project will develop new instructional software, which will be evaluated in actual classrooms. The project will yield research advances in computer science, education, and cognitive psychology. With respect to education, the project will develop and test new methods of instruction, namely, \"tutoring at the explanation level\". These methods aim to achieve deeper student understanding, resulting in better memory (retention) of the acquired knowledge, as well as the ability to apply what was learned to unfamiliar problems (transfer). With respect to computer science, this project will advance the state-of-the-art in intelligent tutoring systems through the incorporation of natural language processing techniques for assessing student explanations and improving them through dialog. With respect to cognitive psychology, this project will create and test cognitive models of how student understanding emerges from an integration of explicit-verbal and implicit-perceptual learning processes.","title":"ITR\/PE(CISE): Tutoring Explanation and Discovery Learning: Achieving Deep Understanding through Tutuorial Dialog","awardID":"0113864","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["533937","550769"],"PO":["565223"]},"61287":{"abstract":"Project Title: Competitive Analysis of Online Algorithms for Computer <br\/>Systems<br\/><br\/>This research focuses on algorithms that work<br\/>with limited information. Each topic is motivated by an application<br\/>in on-line resource allocation in computer systems and is studied<br\/>using theoretical analysis as well as empirical evaluation.<br\/>The first topic is focuses on<br\/>designing protocols for power management.<br\/>The second topic of this research addresses problems<br\/>that arise in scheduling and load balancing for multimedia servers.<br\/>The third topic focuses on the problem of balancing the use of<br\/>bandwidth and storage in caching continuous multi-media objects<br\/>for Web proxy servers.<br\/><br\/><br\/>For the power management topic, the question addressed is when to move<br\/>an idle device to a lower power consumption state so as to<br\/>conserve power usage while minimizing the latency experienced by the<br\/>user. The investigator expands upon previous work on power management by<br\/>introducing the notion of latency and by studying systems with multiple<br\/>levels of power usage. The work on multimedia scheduling and load<br\/>balancing focuses on two problems. The first is scheduling transmission<br\/>of data that must be viewed continuously when clients have large<br\/>buffers that can store data transmitted ahead of time.<br\/>The second problem is to perform load balancing in assigning<br\/>tasks to servers when there are multiple resource requirements<br\/>that need to be balanced. For the topic of caching continuous<br\/>multi-media objects for Web proxy servers, the challenge<br\/>is that continuous data must be transmitted to the client in a<br\/>continuous sequential stream. To support the real time requirements<br\/>of streaming, web caches need to reserve bandwidth as well as space<br\/>for each request for a continuous data object.<br\/>This research investigates algorithms for balancing these<br\/>two resources.","title":"Competitive Analysis of Online Algorithms for Computer Systems","awardID":"0105498","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["409328"],"PO":["499399"]},"66864":{"abstract":"EIA-0130806 <br\/>Jie Wu<br\/>Florida Atlantic University<br\/><br\/>CISE Research Resources: A Low Cost Parallel and Distributed Systems Laboratory<br\/><br\/>The proposed project includes three parallel applications on a Beowulf cluster. The chief advantage of a Beowulf cluster is its superb price\/performance ratio: the proposed cluster will obtain performance in the 3-5 Gigaflop range, for less than one tenth the cost of a comparably powered supercomputer. The low cost parallel and distributed systems laboratory consists of a 16-node Beowulf cluster. Each node is similar to an off-the-shelf PC without a monitor or keyboard. The nodes are networked by 100 Mbit Fast Ethernet lines. Each node will run both Linux and Windows\/NT. <br\/><br\/>Three parallel applications are proposed: (1) A parallel system for ecological modeling, with its focus on minimizing the simulation time of parallelized ecological models. A central component will be porting NOAA's NNT-SMS rectilinear parallel modeling package to the Beowulf architecture, (2) A Java runtime framework on Beowulf clusters for parallel execution of multithreaded processes. A new lottery-based job stealing algorithm will be studied for efficient scheduling of large-scale multithreaded computation. (3) Optimal configuration selection for accuracy enhancement of programmable machines. A genetic algorithm solution will be studied to enhance the accuracy of programmable machines. The success of this project will demonstrate the usefulness of Beowulf clusters as a cost-effective alternative to the supercomputer.","title":"CISE Research Resources: A Low Cost Parallel and Distributed Systems Laboratory","awardID":"0130806","effectiveDate":"2001-09-15","expirationDate":"2006-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["459379","7594",173346],"PO":["557609"]},"63113":{"abstract":"Currently, automatic attacks are a major threat to computer security. For example, the cheapest home PC can try thousands of \"probes\" against a targeted system. A brute-force password (or PIN number) guessing program can generate and try tens of thousands of candidate passwords each second. Or a home PC could attempt to flood a web site with thousands of \"bogus\" requests. <br\/><br\/>While there methods that attempt to stop such attacks they all can be defeated to some degree. We propose a new approach to this security based on technology that can tell the difference between robots and humans. Thus, we can disallow automatic attacks. Our technology allows a new kind of restriction: now systems can insist that only humans have access to their valuable resources and they can disallow robots.<br\/><br\/>The proposed solution to the problem is inspired by Turing's test for artificial intelligence. The fundamental idea of the solution is for a computer system to first ask the author of every transaction to solve a puzzle before accepting or executing the transaction. The content of the puzzle will be based on grand challenge problems in the domains of pattern recognition, visual interpretation, and natural language understanding. These problems have the essential property that people can solve them easily while computers are not likely to solve them in the foreseeable future. A typical puzzle would consist of the computer system sending the agent a bit-mapped image and the agent replying with an ascii string. The image might include a picture and a question and a question about that picture, such as \"Please type the following handwritten word\" or \"Which of the objects in this picture are edible?\" The computer system determines whether the transaction author is a human based on the answer supplied.<br\/><br\/>This puzzle-solving process leads to a new framework for building secure computer systems. In this framework, a human being has to be directly involved (by solving the puzzle and typing in the answer) in the authentication or other processes that are vulnerable to automatic attacks, referred to as Mandatory Human Participation (MHP). Apparently, no automatic attack to the protected process would be possible under this framework.<br\/><br\/>Our proposed research is to build a pilot system that can be used to demonstrate the basic idea of MHP. This will be based mostly on character based methods. We then, plan to carefuly test and measure how well our system performs and how well it is received by users.","title":"ITR\/SY: Mandatory Human Participation: A New Paradigm for Building Secure Systems","awardID":"0113933","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["400310","508256","349186"],"PO":["250082"]},"63124":{"abstract":"The present problems facing society-such as global warming, earthquake preparedness, safety of transport of nuclear waste, and pollutant emission from automobile engines-call for integration of a variety of computer programs, each solving numerical problems in a different discipline. The overriding concern for such complex models is their reliability: predictability, authenticity, and uncertainty. The focus of the present effort is modeling realistic uncertainty in predictions from multi-response, large-scale, nonlinear dynamic models, using a new strategy to attack this problem.<br\/>This work re-examines the concept of a mathematical model associated with complex physical systems, considering experiment and theory to be an integral part of the model and treating uncertain parameters of the model as internal, \"state\" variables. In this way, the uncertainties of the experimental and theoretical foundation are transferred \"directly\" into uncertainties of model predictions. Establishing this direct relationship allows one also to address the reverse problem: to identify which specific data contribute the most to the prediction uncertainty; to determine the required accuracy of an experiment to bring the prediction uncertainty to a given level; or to assess whether a planned experiment will be able to improve the prediction uncertainty.<br\/>This is accomplished by merging convex relaxations from control theory with the technique of solution mapping developed and applied to numerical modeling of chemical kinetics typical of fossil-fuel combustion. The solution mapping technique uses statistical design of computer experiments to replace complex ODE models with surrogate polynomial models. These simpler, though accurate, algebraic models are more suited to numerical optimization. The convex relaxations allow for optimization problems described by a polynomial objective and polynomial constraints (generally nonconvex) to be attacked by convex optimization, namely linear objectives with linear-matrix-inequality constraints. Nearly twenty years of use in robust control has shown these relaxations to be remarkably useful in a wide variety of physically motivated problems and applications.<br\/>In this approach, surrogate models are developed for all responses, both from the training set and from the prediction set. Each surrogate model is expressed as a quadratic form in terms of internal model parameters, developed in a series of direct ODE integrations performed according to a factorial design covering a subspace of parameter uncertainties. The quadratic form of the surrogate response models is then explored by an optimization algorithm. In the initial effort, the problem of propagation of uncertainties in a natural-gas-combustion model is cast in the form amenable for the S-procedure, a method of convex optimization widely used in control theory. <br\/>Even more sophisticated convex relaxations have recently been developed, centering on the observation that determining if a given polynomial is a sum-of-squares (and hence globally nonnegative), can be cast as a convex feasibility problem, and verified in polynomial-time (in the order of the polynomial). This work will investigate such possibilities for exploring novel avenues for numerically economical assessment of realistic error bounds of complex dynamic models.","title":"ITR\/AP: Realistic Uncertainty Bounds for Complex Dynamic Models","awardID":"0113985","effectiveDate":"2001-09-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1407","name":"COMBUSTION, FIRE, & PLASMA SYS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1632","name":"CONTROL SYSTEMS"}}],"PIcoPI":["290244","416996"],"PO":["372125"]},"66765":{"abstract":"EIA-0130388<br\/>Zhenghan Wang<br\/>Indiana University Bloomington<br\/><br\/>Title: Topological Quantum Computation<br\/><br\/>The theory of quantum computation is being constructed from abstract study of topological properties of collective electron systems. One example is the dancing pattern of quasi-particles in fractional Quantum Hall effects. The dancing patterns of quasi-particles are described mathematically by braids. In this context, the Berry phase of the quasi-particles gives rise representations of braids. In mathematical terms, these are modular functors.<br\/><br\/>This project is using insights from modular functors to investigate the possibilities for physical realization of quantum computers. The chief advantage of topological quantum computation is physical error correction. The rich mathematical structure of modular functors is also employed to design new quantum algorithms. Topological Quantum Computation Numerical Laboratory is being established as an intermediate step towards the physical implementation of a real quantum computer based on the principles of modular functors. A lecture and seminar series at Indiana University is organized to training students. This cross-disciplinary project involves topology, condensed matter physics, and computer science.","title":"Quantum-QuBIC: Topological Quantum Computation","awardID":"0130388","effectiveDate":"2001-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}}],"PIcoPI":["482142",173067],"PO":["521045"]},"63014":{"abstract":"Proposal No: 0113371<br\/>ITR\/SY: Combinatorial Optimization Algorithms for Information Access (Fundamental IT Models)<br\/>PI: Eva Tardos<br\/><br\/>The enormous growth in the amount of information online makes it vital<br\/>to automate the job of searching and organizing large data collections<br\/>while maintaining high accuracy. The research will consider two<br\/>seemingly unrelated tasks:<br\/><br\/>. Searching web pages, and<br\/>. Analyzing the content of digital pictures and movies.<br\/><br\/>Despite their obvious great importance, and the large efforts invested,<br\/>the currently available solutions for these tasks are inadequate. The<br\/>proposed research will address a difficult mathematical problem that<br\/>underlies both of these tasks, the classification problem with pair-wise<br\/>constraints. <br\/><br\/><br\/>The traditional classification problems consist of a set of objects to<br\/>be classified, and a set of labels (the classes). Classifying the topics<br\/>of documents on the Web, or individual pixels or regions of an image are<br\/>two examples of this general problem. The proposed research will build<br\/>on the PIs recent successes in applying powerful combinatorial<br\/>optimization techniques to develop algorithms for classification<br\/>problems with pair-wise relationships. Pair-wise constraints can<br\/>significantly enhance classification, by modeling, e.g., the relations<br\/>of physically close objects in an image, or relations implicit in the<br\/>hyperlink structure of the Web. The outcome of this research will be to<br\/>provide powerful new tools for two important tasks in searching and<br\/>organizing large data collections.","title":"ITR\/SY: Combinatorial Optimization Algorithms for Informaion Access (Fundamental IT Models)","awardID":"0113371","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["516907","508240"],"PO":["543507"]},"63135":{"abstract":"This project will work to enable the design, development, and testing of standards for entries in gazetteers and explore the complexity levels of gazetteers required for research in the humanities and history of computing. Gazetteers are structured records about locations and their place names. Digital libraries research is increasingly concerned with the ability to link place names and map locations. Toponym-rich text and maps are lined effectively through the use of gazetteers. Making robust gazetteer information to users and contributors of digital libraries resources is key to achieving communicability among diverse digital resources, as indirect referencing can be employed. These resources can contribute to a variety of scholarly pursuits across a broad range of subject areas.","title":"ITR\/IM - A Multilingual Gazetteer System for Integrating Spatial and Cultural Resources","awardID":"0114019","effectiveDate":"2001-09-01","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["441922"],"PO":["433760"]},"63036":{"abstract":"Proposal No: 0113515<br\/>ITR\/SY: A Flexible Framework for Secure Information Sharing Among Collaborating Organizations<br\/>PI: Jajodia Sushil<br\/><br\/>This proposal seeks to develop a exible framework for secure information <br\/>sharing among collaborating organizations. The approach will be to extend the Flexible <br\/>Authorization Framework (FAF) designed by the PI and his colleagues. FAF is based on an <br\/>authorization specication language that has rule based syntax and sound, non-monotonic logic based <br\/>semantics. The rst goal of this proposal is to enhance FAF to include information ow <br\/>controls, provisional authorizations, delegation of authority, and a rather broad sense of <br\/>revocation capabilities of granted permissions. The second undertaking is to investigate ecient <br\/>implementation of the resulting framework that is based on the best practices of the security <br\/>community. The third goal of this proposal is to investigate the properties of basic constructs <br\/>that are used to compose security policies.<br\/>The main deliverables of this proposal are a reference architecture, <br\/>mathematics and algorithms for security specications of information access and ow, their ecient <br\/>implementation techniques, and an an algebra for policy compositions.","title":"ITR\/SI: A Flexible Framework for Secure Information Sharing Among Collaborating Organizations","awardID":"0113515","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["540637","316739"],"PO":["348215"]},"65236":{"abstract":"The need for more bandwidth and capacity in wireless systems currently is the main culprit for the<br\/>great interest in the development of wireless communications systems operating at millimeter wave<br\/>frequencies and higher. The future needs of broad-band interactive services (1Gb\/s) demand the<br\/>application of optical fiber feed networks for distribution of the radio signals to and from the antennas at<br\/>the various base stations. Fiber-optic technologies have reached the stage where insertions into various<br\/>commercial RF systems are being considered. Today, there are three main steps in the evolution of<br\/>RF\/Photonics systems for wireless communications. The first step has been in the direction of using<br\/>photonics to slowly replace conventional RF components, such as, the coax that is used to interconnect<br\/>the antenna to the electronics. Optical fibers, in contrast to coaxial cable, provide a more ideal medium for<br\/>broadband RF communication systems. The light weight property of fibers, and its immunity from other<br\/>signal interference make them very critical in the development of future RF distribution systems. The<br\/>second, and more challenging step, is in the seamless integration of photonics and RF wireless circuits.<br\/>The challenge in this step is to use photonics and RF circuits as complementary systems and blend them<br\/>together. Finally, the third step is towards the development of optically coupled antennas. In this step the<br\/>aim is to eliminate the need of local oscillators, mixers, amplifiers and a host of other parts by directly<br\/>feeding an antenna through a fiber at millimeter wave frequencies.<br\/> Here, it is proposed that an array of RF modulator\/photodetectors be integrated directly to an array<br\/>of antennas. This new RF\/photonic antenna array system, with the appropriate space-time processing and<br\/>coding, will form a iosmart antennaln that can enhance network coverage, capacity, and quality. It is<br\/>envisioned that a large number of such RF\/Photonic antenna elements could be networked together into a<br\/>star configuration, feeding in and out of a radio hub.<br\/> As a transmitter, the proposed optoelectronic device operates as a photodiode, while as a receiver<br\/>the device operates as an optical modulator. It has already been demonstrated that this dual function of a<br\/>semiconductor electroabsorption modulator and photodiode in the same device for duplex operation, can<br\/>occur, using bias control as a transmit\/receive mode control. For full duplex operation, two<br\/>modulator\/photodiode devices need to be incorporated in the each transceiver element.<br\/> We propose to directly drive a coplanar waveguide (CPW)-fed slot antenna by converting optical<br\/>power into microwave power and vice versa using these RF modulator\/photodetectors. As a transmitter,<br\/>the CPW line is connected to the active surface of the photodetector, from which the microwave power<br\/>propagates to feed the radiating slot. The photodetector is fed via an optical fiber from beneath. When the<br\/>device functions as an optical modulator, the receive function can also be achieved. Preliminary results<br\/>for a single antenna show that a very good bandwidth and radiation patterns can be achieved.<br\/> It should be noted that these elements can be interconnected via the fiber to achieve summation,<br\/>mixing and other signal processing functions, at the antenna site or at a remote site. Some preliminary<br\/>results have been achieved in the area of multiple functionality for the optoelectronic components, such as<br\/>modulation, photodetection, self-biasing and RF frequency mixing. They have shown properties, such as<br\/>high bandwidth and high power, that are desirable for the antenna applications. A main emphasis here is<br\/>to further investigate the material and device designs for the optoelectronic component that can<br\/>incorporate into the smart antenna architecture.<br\/> The proposed approach will have significant impacts on wireless communication systems by<br\/>providing higher system bandwidth capacity and enhancing their reliability. It may lead to a new type of<br\/>long distance, broadband network infrastructure that supports transparent transport of optical signals.<br\/> Our team is formed to provide the expertise in the four key elements for this proposed research.<br\/>Our project will provide a good opportunity to train graduate and undergraduate students in one of the<br\/>most exciting interdisciplinary areas in science (RF, photonics, signal processing and communications).<br\/>The interactions between the researchers at the different institutions will be aided by the close<br\/>collaboration that exists between the members of the group.","title":"Ultra-High-Capacity Optical Communications and Networking: \"Smart RF\/Photonic Antennas\" for Ultra-High Capacity Wireless Communications","awardID":"0123421","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"5345","name":"BIOMEDICAL ENGINEERING"}}],"PIcoPI":["399151","235820","499664"],"PO":["565090"]},"64037":{"abstract":"The long-term objective of this project is to establish effective techniques for \"fingertip haptics\" - the direct fingertip exploration of virtual surfaces. This includes \"direct\" touch of objects as well as distal attribution (touching using an intermediate object such as a pencil or knife). In the course of the work, two novel devices will be built and studied, a tactile-haptic device with \"contrary motion\", and a novel \"tangent plane\" device, to help achieve the tangent position of the operator's finger relative the virtual surface.","title":"Fingertip Haptics: A Novel Direction in Force Feedback Systems","awardID":"0117489","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["541976"],"PO":["335186"]},"57635":{"abstract":"XML has become the prime standard for data exchange on the Web and is increasingly used to represent data currently residing in databases. With this comes the need for a full treatment of integrity constraints for XML such as key, foreign key, functional, inclusion and inverse constraints, which are commonly found in databases to convey an essential part of the semantics of the data. The goal of this project is to develop XML specifications with constraints, to advance understanding of consistency and implication of XML constraints, and to explore applications of constraints in XML data transformations including information preservation, constraint propagation and normalization of XML specifications. In pursuit of this goal, methods for specifying and reasoning about XML constraints are developed, and transformation techniques and tools in the XML context are implemented and evaluated. An important application of these tools and techniques involves the use of constraints in the specification of biomedical data and the conversion of such data to XML. The educational goal aims at the development of a database curriculum at Temple University that integrates data management for semistructured data, XML and traditional databases in a uniform framework of semantic specifications. An important component of this curriculum involves the research and implementation opportunities provided by the project. Results from the project are expected to yield insight into integrity constraints for hierarchically structured data, including but not limited to XML. They will also provide methods, techniques and tools to facilitate semantic specification, data integration and query optimization.","title":"CAREER: Integrity Constraints for XML and Beyond","awardID":"0093168","effectiveDate":"2001-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":[148204],"PO":["563751"]},"67106":{"abstract":"EIA-0131928<br\/>Lane, Meredith <br\/>Academy of Natural Sciences - Philadelphia<br\/><br\/><br\/>BDEI: Overcoming nomenclatural complications while searching in a distributed database environment: One step toward true interoperability.<br\/><br\/>Summary<br\/><br\/>With biological information content growing exponentially on the Web, the average member of the public<br\/>(and for that matter, many scientists) may not be able to access all of the high-quality information actually<br\/>available and\/or that they need because organisms are often known by more than one scientific name (many of which will perhaps be unknown to the user), and different information providers may use different names for the same organism.<br\/><br\/>Important international projects such as the Global Biodiversity Information Facility (see www.gbif.org)<br\/>have identified organism names as the core means for interconnecting databases from different domains<br\/>(e.g., specimen databases with GenBank or ecological databases, etc.) because the organism name is<br\/>highly likely to be the only database field common to both databases. True interoperability among<br\/>databases is required to answer complex biological questions. This goal cannot be reached without a<br\/>mechanism to allow access to all available information on a particular organism.<br\/><br\/>Therefore, a foundation component in the development of the GBIF and associated national efforts<br\/>must be a means to provide a list of all the names that should be searched for a given organism. The need<br\/>for this component of interoperability was clearly recognized by the proposers of GBIF, but to date there<br\/>have been no efforts specifically directed at providing software tools to make it possible. In this project,<br\/>we will implement such a mechanism. It will allow even the most naive Web user to obtain biological<br\/>information without needing to understand the complexities of nomenclature and associated arcana. To do<br\/>this, we will develop a query interface\/portal understandable to any user; a set of standards and protocols for representing search requests (which will be sent as a URL) and result sets (which will be returned as XML using HTTP) that is platform-independent; and a set of platform-specific translators and search routines for retrieving data from participating<br\/>nomenclatural data providers.","title":"Biodiversity and Ecosystem Informatics - BDEI - Overcoming nomenclatural complications while searching in a distributed database environment: One step toward true interoperability","awardID":"0131928","effectiveDate":"2001-09-01","expirationDate":"2003-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["356146","404642"],"PO":["371077"]},"56117":{"abstract":"The purpose of this work is to support the understanding and development of protocols<br\/>that can provide personal privacy over the Internet. While there have been some protocols<br\/>proposed and implemented that hide the IP address of network communicators, there has been<br\/>no systematic study of such protocols, nor have methods of analyzing the anonymity and security<br\/>of those protocols been developed. A thorough understanding of anonymity is important not only<br\/>for the development, analysis, and use of anonymous protocols for personal privacy, but also for<br\/>understanding how network attackers can hide their location and for developing methods to track<br\/>those attackers. Our eventual goal is to develop new techniques and protocols for anonymity,<br\/>including a \\logic of anonymity\" similar to those developed for authentication protocols that<br\/>can be used to describe and analyze anonymous protocols.<br\/>This proposal considers a number of contributions on this research area. Our first contri-<br\/>bution will be to take a more general view of anonymous communication than previous work<br\/>by considering protocols and techniques for hiding the identity of a responder from all other<br\/>parties, and for providing completely anonymous communication in which both the initiator and<br\/>responder are anonymous to each other and all other parties. The former technique is useful<br\/>for anonymous web sites (rather than just anonymous web browsing); the later technique is<br\/>useful for true two-party privacy over the Internet. Our second class of contributions will be to<br\/>consider generalized protocol construction. This extends our past work, which de-coupled the<br\/>forward and reverse paths of anonymous communication, giving rise to a large family of anony-<br\/>mous protocols. We will continue investigation of those protocols, and examine what network<br\/>support is available for anonymous communication and what support might best be provided in<br\/>the future. Our third contribution will be to provide a formalism for anonymous protocols such<br\/>that beliefs regarding entity identities can be reasoned by stating assumptions and deriving log-<br\/>ical conclusions from following steps of defined protocols. Fourth, we will consider the network<br\/>performance of anonymous routing protocols in an in-depth fashion, including not only latency<br\/>and traffic, but also requirements of streaming media applications and traditional TCP-based<br\/>bulk-data transfer applications. Finally, we will consider heretofore ignored security concerns<br\/>of existing protocols, initially considering path analysis attacks and attacks that cause some<br\/>participants to be unfairly accused by third parties. The formalism provided by our proposed<br\/>logic of anonymity will be a foundational component of our security analysis work.<br\/>Collaboration between these our two institutions will allow us to leverage the existing<br\/>strength in networking at the University of Massachusetts and the existing strength in secu-<br\/>rity at Purdue.<br\/>1","title":"Collaborative Research: Anonymous Protocols","awardID":"0087482","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["451830"],"PO":["565090"]},"62960":{"abstract":"This project will use new techniques from computational optimization to design radiation therapy planning for cancer treatment. <br\/><br\/>Radiation therapy applies ionizing radiation to cancerous tissue, damaging the DNA and interfering with the ability of the cancerous cells to grow and divide. This also damages healthy cells, but they are more able to repair the damage and return to normal function. The therapy planning problem is to specify the shapes of the applied radiation beams, times of exposure, etc., to deliver a specified dose to the tumor but not an excessive dose to the surrounding healthy tissue. New medical devices allow much control over the characteristics of the radiation, thus allowing much scope for the therapy planning. However, the full potential of these devices to deliver optimal treatment plans has yet to be realized due to the complexity of the treatment design process. By using advanced modeling techniques, state-of-the-art optimization algorithms, and implementations on parallel computing platforms this project will provide radiation oncologists with important new computational tools for treatment planning. These tools will be flexible enough to adapt to the varying priorities of different planners and different patients and robust enough to give good solutions to the most difficult planning problems. The project involves collaboration between three researchers whose collective expertise encompasses radiation oncology modeling, optimization algorithms, and parallel implementations. It builds on previous collaborations of these researchers on treatment planning and on NSF-funded work on algorithms for solving large optimization problems.<br\/><br\/>The institutions involved in the project are the University of Wisconsin and the University of<br\/>Maryland School of Medicine.","title":"ITR\/API: Collaborative Research: Cancer Treatment Plan Optimization","awardID":"0113051","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["520933","517079"],"PO":["565272"]},"60793":{"abstract":"EIA-0103722<br\/>Thu D. Nguyen<br\/>Rutgers University<br\/><br\/>System and Compiler Support for Component-Based Construction of Scalable Internet Services<br\/><br\/>The principal investigators propose to investigate system and compiler support for an emerging class of Scalable Internet Service (SIS) applications. This proposed work will be motivated by the emergence of the Internet as the global, ubiquitous networking infrastructure, and its accompanying computing model where much of the computing takes place on servers rather than local machines. SIS applications provide a rich set of services such as on-line auctions, stock exchanges, and instant messaging to diverse clients worldwide.","title":"NGS: System and Compiler Support for Component-Based Construction of Scalable Internet Services","awardID":"0103722","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["486839","559843","438877"],"PO":["301532"]},"63730":{"abstract":"EIA-0116295<br\/>Sharon Stansfield<br\/>Ithaca College<br\/><br\/><br\/>MRI: Acquisition of Computing and Peripheral Hardware to Support Collaborative Research and Undergraduate Research Education in Virtual Reality<br\/><br\/>This is a proposal for equipment acquisition under the Major Research Instrumentation (MRI) program to support research and student training in virtual reality. The virtual reality effort will provide a platform for the investigation of human motion planning and the development of computational models to enable high fidelity object manipulation within a virtual environment.","title":"MRI: Acquisition of Computing and Peripheral Hardware to Support Collaborative Research and Undergraduate Research Education in Virtual Reality","awardID":"0116295","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["327312",164113,164114],"PO":["557609"]},"61442":{"abstract":"It is well established that long-range autocorrelation and heavy-tailed inter-packet time distributions are dominant characteristics of modern multimedia high speed network traffic, determining limits to performance and radically influencing policies for management. Incorporating such characteristics in parametric performance models has so far been difficult. This project will center about the development of powerful and efficient models to capture network behavior for varying levels of abstraction while incorporating approximations to long-range dependence and heavy tails. The model does not solely rely on steady state results, but rather on a finite horizon that can be used for online monitoring and early detection of rare events. In particular, this means that time dependent threads can be modeled which are the root cause of such dependency related problems. Decomposability techniques will be used to decrease the granularity if possible and to scale the model to time scales suitable for online analysis and control. The approach will be to extend the successful and innovative model developed for a high-speed network. Highly correlated arrival processes can be viewed as nearly-completely decomposable processes, which in turn impose a nearly-completely decomposable structure on the system as a whole. Each of these nearly decomposed systems can be solved separately and in parallel and their solutions combined to accurately evaluate the performance of the system. Theoretical work must be done to determine error bounds and robust algorithms for solutions in a wide range of applications, to allow flexible approximation of measured correlations, and to broaden the classes of results that can be computed. Additionally, experimental work must be done to exercise models and compare them with published and other artifactual data. Finally, a prototype software package will be developed that demonstrates the viability of placing this tool in the hands of practicing network engineers and equipment designers.","title":"Scalable Performance Models for Large Scale Networks with Correlated Traffic","awardID":"0106640","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":[157976,157977,"270075"],"PO":["565090"]},"64731":{"abstract":"ITR\/\\(PE+SY\\): Responsive Virtual Human Technology Research<br\/><br\/>Responsive virtual human technology (RVHT) is used in diverse fields (computer generated forces, manufacturing, medicine, theater), but not for interaction skills training. Yet interaction skills are usually critical. Specific situations identified where improved interaction skills would be important include: <br\/>Medical practitioners taking patient histories or interacting with children;<br\/>Law officers handling crisis situations involving mental illness, trauma, or violence; and Military officers interviewing refugees or settling stressed civilians.<br\/>This project will address multiple research issues relevant for RVHT to reach the sophistication required for robust interaction skills training. Important questions to be answered include:<br\/> How is behavior modeled under normal conditions (i.e., a calm adult) and derivative conditions (e.g., anger, schizophrenia, pain, and childhood)?<br\/> What expressions, gestures, movement, and other behaviors will users interpret as serene, angry, schizophrenic, pained, or childlike?<br\/>What skills can be acquired, practiced, and validated using RVHT? What is involved in providing a convincing simulation of human interaction where acquired skills transfer to a live environment?<br\/>The research results will expose a range of additional training and educational opportunities, such as interviewing risky behavior and presenting rare, traumatic events. Combinations of RVHT-based training and instructor-led training offer significantly reduced training development and delivery costs, and increased student throughput, while maintaining training effectiveness and consistency.","title":"ITR\/(PE+SY): Responsive Virtual Human Technology Research","awardID":"0121211","effectiveDate":"2001-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["289631",167070],"PO":["564318"]},"64511":{"abstract":"CCR-0120155 <br\/>Karne, Ramesh <br\/>Towson University <br\/>SGER: Application-Oriented Object Architecture<br\/><br\/>ABSTRACT<br\/><br\/>This SGER project studies the feasibility of an application-oriented object architecture (AOA) to revolutionize the way computer systems are built and drastically reduce the problems of obsolescence and reengineering. The proposed 2-layer architecture consists of an application unit (AU) and an application object (AO). The two form a substrate-software pair with all software functionality in the AO: no additional software is needed and the AU is optimized for the particular AO. This architecture is demonstrated by using an existing computer system such as a desktop and a commonly used resume document application, using a simulation environment prototype for the AU. The work is exploratory in nature and intends to lay the groundwork for a more substantial project. The project intends to make significant contributions to computer systems development and redefine the roles of traditional software, hardware, and applications, providing a new foundation for computer systems based on applications instead of environments.","title":"SGER: Application-Oriented Object Architecture","awardID":"0120155","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["240400"],"PO":["564388"]},"66832":{"abstract":"EIA-0130673 <br\/>Xian-He Sun<br\/>Illinois Institute of Technology<br\/><br\/>CISE Research Resources: Acquisition of a Computing Cluster and Access Grid Node for Information Technology Research<br\/><br\/>The Department of Computer Science at the Illinois Institute of Technology (IIT) will purchase an 82 node Linux cluster, an Access Grid node, and several workstations, all of which will be connected via a high-speed network. These computational resources will be dedicated to the support of several on-going research projects in the area of information technology. Such projects include the development of a process migration environment for heterogeneous distributed computing, design and implementation of scalable information systems, scalable distributed simulation in support of complex systems management, and scalable parallel numerical algorithms and simulations. These projects require significant computing power and high-performance networks. Such resources are not currently available within the university. The acquisition of these resources through the NSF CISE Instrumentation program is critical to the success of these research projects, and to the development of a strong computer science program at IIT. Additionally, the requested equipment will offer an excellent platform upon which students can learn about and experience state-of-the-art research via course work and term projects.","title":"CISE Research Resources: Acquisition of a Computing Cluster and Access Grid Node for Information Technology Research","awardID":"0130673","effectiveDate":"2001-09-15","expirationDate":"2004-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["494506","517717","557489","560175","344399"],"PO":["557609"]},"64412":{"abstract":"Pruning Techniques for More Expressive Planning<br\/><br\/><br\/><br\/>This is the first year funding of a two year continuing award. Solving more expressive planning problems is important because many practical problems fall in this category. It is important to be able to control search in the synthesis of these plans. This project involves development of various pruning techniques for more expressive planning. These are based on identifying various flaws in partial plans and the costs of resolving them. An efficient conjunctive planner and an efficient disjunctive planner will be modified to handle universal quantifiers, functions, metric time and continuous variables. These planners will use pruning techniques developed in this project. The results of the project will improve understanding of efficient synthesis of plans in more expressive domains like NASA's Deep Space One mission.","title":"Pruning Techniques for More Expressive Planning","awardID":"0119630","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":[166040],"PO":["491702"]},"64533":{"abstract":"Recent developments in mixed-signal systems, especially those integrating computing and<br\/>communication in a system-on-a-chip, have focused on the goal to communicate information via wireless devices and networks. While digital system design to process baseband information is moving into the low gigahertz (GHz) frequency range, the mixed-signal transceivers have to operate in the ISM bands (2.5 GHz up to 5.8 GHz) with even higher frequencies in the near future to satisfy bandwidth demands. Analog design advances have produced several transceiver designs up to 5 GHz, using CMOS, BiCMOS, and other technologies. To reduce noise, these designs tend to separate the transmitter and receiver, and so far, have provided only a single physical link (one transmitter and one receiver) in a wireless device. In the design area, this proposal addresses the creation and verification of scalable systematic design methods to integrate two or more physical links on one single chip to provide more bandwidth and flexibility in communication applications. A methodology to incorporate multi-links is scalable in the sense that more links can be added by application demands. To create this methodology, we propose the following design approaches:<br\/><br\/>1. Noise cancellation techniques and circuits to deal with digital switching noise.<br\/><br\/>2. Noise cancellation techniques and circuits to deal with RF noise interference between different transceiver links and circuits.<br\/><br\/>These circuits will be validated using case studies from industry with whom we have had close<br\/>collaborations: Texas Instruments, Motorola, and National Semiconductors, who will provide<br\/>advanced fabrication technologies and simulation models for this study.<br\/>The designs will be fully tested and the development of scalable test methods is the second focus of this proposal. Mixed-signal test advances, despite intense activities, have been rather slow, especially in high-frequency (GHz) test. We propose to investigate the following approaches and distill the results into a test methodology that can be scaled with respect to operating frequencies and process advances:<br\/><br\/>1. End-to-end digital test methods using one transmit link and one receive link on the same chip<br\/>to verify correct information transmission.<br\/><br\/>2. Designs of on-chip delay and phase measurement circuits, operating at the same frequency as<br\/>the transceivers.<br\/><br\/>3. Interface between ATE and on-chip test circuits to use test resources efficiently.<br\/>During the validation of these test methodologies, we will need access to advance test equipment for comparison purposes, and these equipment will be provided by our collaborator at Teradyne (Tualatin, OR) and Wavecrest (San Jose, CA).<br\/><br\/>Another level of integration involves the curriculum - research aspects of the proposed work,<br\/>which is being implemented in our current curriculum revision. Dissemination approaches re-used the distance learning methods and assessment supported by NSF, FIPSE, and our own<br\/>university. The proposal will deliver fundamental methodologies and techniques, and train the<br\/>first-generation system architects in high-frequency mixed-signal design and test.","title":"Research for Mixed Signal Electronic Technologies: A Joint Initiative Between NSF and SRC: Scalable Design and Test Methods for Single-Chip Multi-Link Radio-Frequency Transceivers","awardID":"0120255","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":[166463,"431529"],"PO":["562984"]},"60188":{"abstract":"0101254<br\/>Scott A. Hauk<br\/>University of Washington<br\/><br\/>CISE Research Infrastructure: An Infrastructure for Integrated Systems Education and Innovation <br\/><br\/>The research contained in this proposal represents a wide-ranging investigation into the future of single-chip systems. We will seek to develop a design methodology that can provide the benefits of multiple different resource types for numerous design domains. To support the design of such cutting-edge silicon systems, we will develop innovative techniques to handle numerous design issues. These will include investigations into the following critical issues in chip design: Development of techniques for integrating RF and Analog components into future 1V SoC designs. Creation of high-performance, power efficient digital logic families for supporting the stringent requirements of these systems. Investigation into reconfigurable subsystems for SoC designs, providing post-fabrication customization for support of multi-protocol and multi-algorithm systems. Integrated testing methodologies for complex, heterogeneous systems that can provide complete system test. Complete simulation and design methodologies that can handle complete system integration, architectural exploration, and validation. In addition to the development of new approaches to future chip design, we will also develop innovative techniques for educating future chip designers. By providing an integrated curriculum in VLSI\/CAD, embedded systems, and complex system design, we will help create system architects capable of harnessing these radically new design techniques and opportunities. We will also seek to increase the opportunities in chip design for new constituents, especially under-represented groups to help increase the pipeline of new designers","title":"CISE Research Infrastructure: An Infrastructure for Integrated Systems Education and Innovation","awardID":"0101254","effectiveDate":"2001-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["166463","323356","485670","431529","485671"],"PO":["539087"]},"66876":{"abstract":"EIA-0130847 <br\/>Gopal Gupta<br\/>University of Texas Dallas<br\/><br\/>CISE Research Resources: Resources for Research in Scalable Parallel Computing and Networking Simulation<br\/><br\/>The PIs seek to acquire a network of six 4-cpu multiprocessors and a data storage system connected with 100 Mbit\/s Ethernet. This equipment will be used for building scalable parallel and distributed systems for tabled logic programming (LP), for computational geometry projects, as well as for quantitatively studying mobile ad-hoc networks (MANETs). The logic programming project seeks to combine dynamic reordering of alternatives with stack-splitting for realizing or-parallel tabled LP systems on distributed networks of SMPs. The computational geometry projects are related to research on design and implementation of scalable parallel and distributed algorithms for the weighted regions optimal trajectory problem, with applications in surgery planning, geographic information systems, and radiation therapy. The parallel implementations will be carried out on the network of SMPs. The MANET project will conduct a quantitative evaluation of unidirectional wireless links in MANETs: the impact of interference and battery life on the occurrence of unidirectional links, and MAC sub-layer issues for such links. Routing protocols designed to use both bidirectional and unidirectional links will be evaluated via simulations. The network of multiprocessors and the data storage system will be used, respectively, for conducting large simulations and for storing large simulation data.","title":"CISE Research Resources: Resources for Research in Scalable Parallel Computing and Networking Simulation","awardID":"0130847","effectiveDate":"2001-09-15","expirationDate":"2006-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["490760","462892","558126"],"PO":["557609"]},"63125":{"abstract":"The project addresses the problem of human interaction - in this case mechanical interaction - with virtual environments. Considered are locomotion interface energy-extractive devices that allow natural walking through virtual terrain. The goal is to produce a sense of immersion in the virtual world by realistic integration of walking with vision and sound, and by realistic energy expenditure in moving about. For example, the system will be expected to realistically recreate the fact that walking uphill is harder than downhill. Additional degrees of freedom will be explored to investigate a more generalized pattern of terrain walking.","title":"ITR\/SY(IIS): Advanced Mechanical Displays for Locomotion Interfaces","awardID":"0113996","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["513354"],"PO":["335186"]},"63136":{"abstract":"The goal of this research project is to develop new techniques to handle uncertainty in object-oriented dynamic databases. The approach consists of developing a new data model and associated algebra; developing query optimization techniques for inexact queries; and development of indexing methods to support probabilistic uncertainty in dynamic databases. This research effort develops new theory, tools and technology to support various types of probabilistic uncertainty in object-oriented dynamic databases. The experimental research is linked to spatial databases with applications in the field of Geographic Information Systems. By adding support for uncertainty in database management systems, this research project will substantially increase the power and flexibility of database management in a broad class of business, social, scientific and engineering endeavors where uncertainty is measured and used. <br\/>http:\/\/www.vislab.ucr.edu\/intro.html","title":"ITR\/IM: Handling Uncertainty in Spatial Databases","awardID":"0114036","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["553703","553704"],"PO":["469867"]},"63026":{"abstract":"EIA-0113443<br\/>Winfree, Erik<br\/>California Institute of Technology<br\/><br\/>Title: Biomolecular Computing by DNA\/Enzyme Systems<br\/><br\/>Dr. Erik Winfree and Dr. Hideo Mabuchi are working together to develop techniques and instruments for high-precision quantitative analysis of the DNA molecular devices. These are being designed, characterized and optimized to investigate issues such as robustness and error-tolerance of these DNA molecular devices. The technical objectives being achieved in this project are: development of spFRET instrument capable of counting individual photons from single molecules; characterization of conformal states, kinetics, and thermodynamics of DNA switches; characterization of the activities of two enzymes, RNAP and RNase, on the DNA switches; development of stochastic models of in vitro transcriptional circuits; and investigation of robust algorithms and error-control for transcriptional circuits.<br\/><br\/>Through this project, the PIs are establishing a set of experimental systems and techniques for exploring computation by biological molecules. This will provide fundamental knowledge and principles for nanoscale computation, such as models of computation, molecular algorithms, physical limits, sources of error and error correction strategies. Thus the aim is to leverage the advanced control over biochemical systems to begin establishing a broader foundation for reliable molecular computing.","title":"ITR\/SY(CISE): Biomolecular Computing by DNA\/Enzyme Systems","awardID":"0113443","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["544518","558957"],"PO":["565223"]},"64258":{"abstract":"The research considers the impact of improved Information Technology (IT) on the structure of organizations. Recent empirical work suggests that as IT improves, the organizations using it may find it advantageous to enlarge the scope of individual or departmental decision-making (i.e., to decentralize) and at the same time to make the organization's final actions more sensitive to the information gathered by all departments (i.e., to coordinate). The research will study formal models to determine the assumptions under which these claims indeed hold up. That will require precise specification of the organization's actions, goals, and information-processing activities and precise assumptions about the self-interested behavior of the organization's members when the organization decentralizes. In the main class of models, the relevant IT is the ability to search large databases. To choose appropriate actions, the organization has to track its changing external environment. Each member of the organization specializes in some aspect of the environment, and improved database-search capability allows the member to learn more about that aspect for a given search cost. Search cost will be measured in several alternative ways. The results of the research should be useful in suggesting new hypotheses and methods for future empirical work on the impact of IT at the level of organizations.","title":"Information Technology and the Structure of Organizations:Formal Theory as a Guide for Empirical Research","awardID":"0118600","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":[165632],"PO":["564456"]},"57504":{"abstract":"One of the primary, and often the most important, goals of any computer system is good performance. So it is for communication networks-throughput is the primary evaluator and impetus for new network research and development. In this proposal, we identify a new paradigm for thinking about distributed algorithms that exploits a shift in the engineering environment, the availability of high-precision globally synchronous clocks with cheap hardware. Many research projects are investigating the limits of precision and uses of precise time for traditional, e.g., operating system, algorithms. We propose to build on this research, focusing on improved performance of application-level algorithms and targeting distributed, real-time databases support for e-commerce applications. The career development plan outlined in this proposal focuses on the principal investigator's efforts to integrate core research and educational objectives. The research project addresses a number of important issues in the discovery and analysis of precise time-based algorithms for distributed, real-time systems. The ultimate goal of the proposed work is and estimate of the benefit of precise globally synchronous time for a wide variety of applications. The objective is to not only develop and analyze new time based network protocols, but to characterize the impact of globally synchronous time on distributed algorithms in general. to achieve this, we introduce the concept of a timed stream and propose to investigate how to best implement and use timed streams to achieve high performance distributed, real-time applications. The educational component is closely related to the research plan. Students at the undergraduate and graduate level, as well as industrial participants, will use the software produced and data gathered during the research activities detailed in this proposal. The tools (e.g., new Web server technology) will serve as a research engine to collect performance data for the purpose of performance-based analysis of distributed algorithms. The education plan also includes development of e-commerce curriculum and courses, integrating the proposed research at all levels, and using the basic scientific principles of the research, as well as the PI's enthusiasm, to encourage young (K-12) scientists.","title":"CAREER: Timed Streams: Infrastructure, Applications, and Algorithms","awardID":"0092669","effectiveDate":"2001-09-15","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":[147932],"PO":["194325"]},"59946":{"abstract":"Aggregate computation is expensive, especially when time-varying attributes are involved in it. The task of computing aggregates becomes more challenging for spatial and spatio-temporal databases, as the spatial and temporal extent over which the aggregate value holds must be computed. For example, multi-attribute images are often the result of a query in the Earth Observing System (EOS) environments, which retrieves all of the measurements incident on the pixels that satisfy the spatio-temporal bounds of the query. Each pixel of multi-attribute images has several values associated with it. This project develops a suite of techniques for computing spatio-temporal aggregates. While there has been significant work done in temporal aggregation, little is known about how to evaluate spatial aggregates. The existing temporal aggregation and spatial join algorithms are generalized to create efficient algorithms for computing spatial aggregates, and then further generalized these algorithms to accommodate spatio-temporal aggregates. In addition, scalable techniques will be developed by parallelizing the aggregation algorithms on a shared-nothing architecture. The project team includes a hydrologists at the United States Geological Survey on the USGS Death Valley Regional Flow System (DVRFS) Project, which is investigating ground-water flow in the Nevada Test Site, proposed as a repository for high-level nuclear waste. The results from this research has a direct impact on many large-scale spatio-temporal database applications such as EOS, cadastral databases, atmospheric databases and hydrologic databases.","title":"Spatial and Spatio-Temporal Aggregation","awardID":"0100436","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["560601","392322"],"PO":["469867"]},"59748":{"abstract":"The proposed work addresses a computational model for periodic pattern perception based on the mathematical theory of crystallographic groups. The model to be built will have a capability of isolating underlying periodic patterns in images. Results of the work are likely to enrich methods of image processing of symmetric structures. Other applications include pattern indexing (textile, psychology), image reproduction\/compression, gait analysis, among others.","title":"A Computational Model for Periodic Pattern Perception Based on Crystollagraphic Groups","awardID":"0099597","effectiveDate":"2001-09-01","expirationDate":"2006-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7339","name":"COMPUTER VISION"}}],"PIcoPI":["531866"],"PO":["317663"]},"60761":{"abstract":"EIA-0103625<br\/>James H. Aylor<br\/>University of Virginia <br\/><br\/>NGS Performance Modeling of Complex Hardware\/Software Systems through Mixed Level Modeling<br\/><br\/>This project will develop a revolutionary new capability by providing a unified design framework for complex, high performance computer systems. This framework includes a performance modeling environment that will be integrated into a mixed level hardware\/software design environment through the use of standard Hardware Description Languages (HDLs) and supporting design tools. This framework will allow the modeling of hardware and software systems at a high level to enable rapid design space exploration and system performance analysis. The framework will provide the capability to refine these high level designs in a step-wise manner into models with more design detail and, ultimately into an implementation. This step-wise refinement capability allows areas of the design that are determined to be \"high risk\" in terms of performance to be refined to a more detailed level where the effects on system performance of assumptions and design can be realized.","title":"NGS: Performance Modeling of Complex Hardware\/Software Systems Through Mixed Level Modeling","awardID":"0103625","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["328586"],"PO":["301532"]},"59309":{"abstract":"Proposal #0098151<br\/>Mount, David<br\/>U of Maryland, College Park<br\/><br\/>The vitality of computational geometry depends heavily on its relevance to real-world problems and applications. This field has made significant contributions to these areas, but continued success requires an understanding of the constraints and structure present in the problems that arise in typical applications. Traditional worst-case asymptotic analysis is often too blunt a tool for establishing the efficiency of geometric algorithms, since geometric data sets often contain simplifying structure, which worst-case efficient algorithms may ignore. Another reason is that worst-case analyses may lead designers to concentrate on difficult data configurations that arise only rarely in practice. As a result, many designers of geometric software do not look to computational geometry as a relevant source of algorithms, and instead rely on heuristics of unproven performance.<br\/><br\/>The goal of this research is counter this perception by developing ad implementing algorithms and data structures for geometric problems that are both efficient in practice and whose efficiency is formally provable. Our approach in achieving practical efficiency is through a sensitivity to presence of simplifying structure. For most algorithms this structure may be present in the input. For data structures this structure is present in the distribution of the queries. Our goal is to design and analyze algorithms and data structures that are most efficient when this simplifying structure is present. In the absence of this structure, these algorithms would ideally degrade to the best worst-case algorithms. This approach will be applied to geometric problems in information retrieval (multidimensional nearest neighbor searching and point location) pattern recognition, robust statistics, and in clustering.","title":"Structure-Sensitive Geometric Algorithms and Data Structures","awardID":"0098151","effectiveDate":"2001-09-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["486206"],"PO":["321058"]},"62972":{"abstract":"Project Abstract<br\/>Proposal #0113131<br\/>Antsaklis, Panos<br\/>U of Notre Dame<br\/><br\/>The goals of this project are to develop algorithms and prototype software for the verification and supervision of hybrid embedded control systems; also for the identification of hybrid system models. This project is developing supervisory processors to supervise and control in real time the operation of large number of control processors interacting with the outside world. The control processors interact with the physical world while the supervisory processors are responsible for monitoring and maintaining the health of the<br\/>distributed control system in a highly autonomous and fault-tolerant manner. The innovative characteristics of this project are as follows: 1) the development and application of novel discrete event supervisory methods to supervise hybrid embedded systems; 2) the development and application of novel approaches to the verification and supervision of hybrid, piece-wise linear systems; 3) the development of theory and algorithms to extend these results to a class of nonlinear hybrid systems; and, 4) the development of novel<br\/>model identification methodologies and algorithms for hybrid systems. The project's approach will improve the ability of hybrid embedded control systems to deal with high complexity, undecidability and nonlinearity.","title":"ITR\/SY (CISE): Verification and Supervisory Control of Hybrid Embedded Systems","awardID":"0113131","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["460500","526924",161696],"PO":["561889"]},"63830":{"abstract":"EIA-0116616<br\/>Roger W. Webster<br\/>Millersville University<br\/><br\/><br\/>MRI: Development of Haptic Instrumentation and Software for Computer Science Research and Training Using Surgical Simulation as the Application<br\/><br\/>This is a proposal for instrumentation development under the Major Research Instrumentation (MRI) program to support research and student training in the area of haptic human-computer interaction using surgical simulation as the application. The design and development of haptic surgical instruments which attach to a commercially available device will enable users to practice virtual surgery and will enhance the human-computer interface in realistic simulation applications.","title":"MRI: Development of Haptic Instrumentation and Software for Computer Science Research and Training Using Surgical Simulation as the Application","awardID":"0116616","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["319643",164495,164496],"PO":["557609"]},"62884":{"abstract":"Networked information technology has led to unprecedented opportunities for exchanging information in a population of participants whose interests and needs vary over time. In particular, this project concerns populations of consumers looking for information products, and producers who possess products that others might be seeking. Substantial research has gone into studying how producers and consumers can settle the terms of a transaction for a particular good. However, there are many possible variations and combinations of information products and their prices that can be offered. A critical and poorly understood problem is how parties should position themselves in this vast information product and price space to differentiate themselves from competitors and attract those with whom they should transact. To address this problem, the investigators will use economic analysis and computer simulation to study how producers of information goods can learn to position themselves based on criteria such as price schedules and information content, and can adapt to changing consumer tastes where consumers might be making strategic buying decisions to affect producer positioning. This project will extend economic theory to account for these concerns, and create computational agents that can make adaptive, strategic decisions about product positioning.","title":"ITR\/PE+AP Strategic Positioning in Information Product Space","awardID":"0112669","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["438665","361939"],"PO":["495796"]},"61333":{"abstract":"Computer architecture research is based on experimental evaluation of application behavior.<br\/>One critical issue in the architecture of high-end enterprise servers is the design of the memory<br\/>hierarchy, which must be designed to support current and future data-intensive applications.<br\/><br\/>Few evaluations of the memory behavior of large commercial applications exist, especially in the<br\/>public domain. The research proposed here is based on a collaboration between IBM and USC to<br\/>take advantage of the IBM Watson Server Performance Laboratory to explore the memory<br\/>behavior of high-end commercial applications.<br\/><br\/>More specifically, it is proposed to use the IBM MemorIES board to collect bus activity<br\/>traces from a modern server machine running large, finely tuned OLTP, DSS and Web workloads.<br\/>Because of the sheer size of the traces, samples of transaction records will be collected only <br\/>in selected time intervals.<br\/><br\/>Besides obtaining traces, the goal of this project is to characterize the memory<br\/>behavior of these applications, to evaluate alternative memory hierarchies for future<br\/>high-end commercial servers, and to explore new multiprocessor architectures for<br\/>commercial systems. <br\/><br\/>The experimental environment provided by the IBM Watson Server Performance Laboratory<br\/>cost millions of dollars and years of effort to setup. This proposed research will leverage these<br\/>efforts. It is a unique opportunity to collect and disseminate traces and experimental data<br\/>which would be practically impossible to obtain under any reasonable research budget.","title":"Trace-Driven Evaluations of the Memory Behavior of Large Commercial Applications","awardID":"0105761","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["518643"],"PO":["325495"]},"60365":{"abstract":"CCR-0101833<br\/>Mili<br\/>Univ of Texas - Dallas<br\/>SGER: Using NLP Tools for Requirements Visualization<br\/><br\/>ABSTRACT<br\/><br\/>Creating, understanding, and formalizing requirements are major hurdles in system development. Inherent ambiguity in natural language makes requirements documents difficult to interpret and maintain, while formal specification methods are unacceptable to many stakeholders. This project intends to demonstrate the feasibility of using natural language processing (NLP) tools to analyze informal descriptions of software requirements for the purpose of generating semi-formal and formal descriptions, analyzing them, and automatically maintaining interdependencies between textual, graphical, and formal representations. The chosen NLP tool is the Ergo parser of Bralich and Bickerton, one that is capable of full analysis of English grammar and syntax and of engaging in question\/answer and statement\/response repartee in real time. The project explores a variety of grammatical and writing styles to establish guidelines for useful documents; analyzes synonymous English styles to establish dependency grids; and creates and integrates interfaces with other program functions.","title":"SGER: Using NLP tools for Requirements Visualization","awardID":"0101833","effectiveDate":"2001-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":[155198],"PO":["564388"]},"64842":{"abstract":"The PI will design and build human-computer interfaces that improve human memory, which he terms infocockpits. The basic approach is to take well-understood psychology principles and apply them to the design of information displays, in particular the fact that human beings are adept at remembering information based on its location relative to their body and on the place where they were when they learned it. The implementations will use two basic strategies: multiple spatial displays surrounding the user, to engage human memory for location; and ambient context displays (both visual and auditory), to engage human memory for place. This work leverages prior collaborative efforts by the PI and Co-PI in virtual reality. The project relates to, and represents a new paradigm for, the retention of information instead of its manipulation. Although the PIs postulate just two fundamental design principles, the design space is very large. The basic research apparatus - the infocockpit - will be a computer system with a number of traditional display monitors arrayed relative to the user's body. These display screens are then placed in a room where images can be projected onto the walls. This projected imagery, plus ambient 3D surround sound, creates a distinctive place in which information is viewed. The PI will systematically vary the configuration, and will run controlled experiments, in which users access information and then later are tested for their ability to recall it, to examine the benefits of: multiple monitors arrayed around the user vs. a single monitor; the addition of projected background context; stationary vs. animated background contexts; having the context semantically related to the accessed information; having ambient and\/or localized sound as part of the context; and using hierarchical places to avoid having confusions between many different contexts. The PI will partner with the Virginia Center for Digital History which will employ the new design principles to build and provide content for infocockpit systems for teaching American history; this will allow the PI to observe how the new techniques work in a real world educational application developed by others. A preliminary study conducted by the PI has found a 63% increase in users' memory capabilities; moreover, functional brain imaging assessment of the participants from this study and found that experience in the infocockpit resulted in brain activations in areas associated with spatial representation, working memory, and visualization. Thus, the question is no longer whether this approach can improve the user's ability to remember information; the question is by how much.","title":"ITR\/SY: Augmented Cognition: Combining Human and Digital Memory","awardID":"0121629","effectiveDate":"2001-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"X900","name":"DARPA-AUGMENTED COGNITION PROG"}}],"PIcoPI":["233332","334091"],"PO":["564456"]},"61344":{"abstract":"We propose to develop an architecture and theoretical underpinnings for providing absolute delay<br\/>guarantees for HTTP traffic. HTTP traffic constitutes an overwhelming majority of all Internet<br\/>traffic today. Both network load and user-perceived end-to-end response time of web requests<br\/>depend not only on network conditions but also on the performance of web proxy caches around<br\/>major network backbones. For example, in an HTTP-dominated network, increasing the total<br\/>amount of cached data may increase hit ratio and subsequently decrease both network load and<br\/>network delay. Hence, an architecture for end-to-end web traffic delay guarantees should explicitly<br\/>consider the effect of caching. It is the joint consideration of caching and network performance that<br\/>separates our work from prior efforts on delay guarantees. Essentially, the joint problem considers<br\/>data placement (replication) as a dimension to manipulate for affecting traffic delays. The approach<br\/>is cost-effective since data storage is cheaper than network bandwidth.<br\/> The first contribution of this project is to develop a scheme for network load control that relies<br\/>on adaptive data prefetching. The architecture can be thought of as replacing admission control<br\/>at the network boundary. In an HTTP context, while admission control would prevent a client's<br\/>request from entering the network, data prefetching would bring the information to the client's<br\/>side before it is requested, hence de ecting the request away from the backbone. While prefetching<br\/>itself introduces traffic, the performance gain comes from the fact that, unlike serving live requests,<br\/>prefetching can occur at a lower priority in the background without jeopardizing user-perceived<br\/>network performance. Hence, prefetching removes time constraints from a big chunk of HTTP<br\/>traffic which can now be served at a lower priority. Consequently, the remaining (live) HTTP<br\/>traffic will receive better service from the network.<br\/> The second main contribution of the project is a theoretical derivation of the relationship<br\/>between network resource utilization and the satisfaction of end-to-end deadlines. Specifically, we<br\/>prove that keeping network resource utilization due to live web traffic below a given threshold<br\/>ensures that all ow deadlines are met. We call this threshold, the overcommitment threshold .<br\/>This result allows us to associate deadlines with live web traffic and ensure their satisfaction simply<br\/>by performing utilization control. The result obviates maintaining per- ow state in the network for<br\/>the purposes of satisfying absolute delay guarantees.<br\/> Merging the aforementioned contributions together, we propose to use our adaptive prefetching<br\/>scheme to keep the amount of live web traffic below the overcommitment threshold. Hence, we<br\/>ensure the satisfaction of absolute delay guarantees while requiring neither admission control on the<br\/>network boundary nor per- ow state in routers. The architecture calls only for service differentiation<br\/>in the network to separate live real-time web traffic from background prefetching traffic which may<br\/>receive lower priority. The project will use the PI's existing evaluation testbed for implementing<br\/>and evaluating architectural prototypes.","title":"A Framework for Utilization-Based Absolute Delay Guarantees Using Adaptive Prefetching","awardID":"0105873","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["553633"],"PO":["565090"]},"64864":{"abstract":"Electronic markets are emerging as a primary medium of trade in business-to-business, business-to-consumer, and consumer-to-consumer settings. In order to design viable electronic marketplaces, a host of novel interrelated game-theoretic and computational issues must be<br\/>addressed. With a team of interdisciplinary researchers from multiple institutions, this project will develop a unified theory of games and computing to guide and facilitate the growth of such markets. Specific research directions of the project include the following: (1) Market designs will be generalized to incorporate combinatorial bidding, multi-attribute preferences, multi-stage mechanisms, continuous mechanisms, and multi-unit sale; (2) New algorithms for clearing, quoting, incentive-compatible pricing as well as new incentive-compatible tractable mechanisms will be designed with particular emphasis on online and incremental updating of market states; (3) Bounded rationality of the agents will be investigated under a wide spectrum of models of computations, equilibrium concepts of game theory, and trade-offs between centers and agents; and (4) Novel approaches to relaxing the classic common prior assumption will be explored in order to develop practically useful models for ecommerce. The successful completion of this project will make significant contributions to both theory and practice in the areas of electronic commerce, multi-agent systems, algorithms, computational complexity theory, and game theory.","title":"ITR\/PE+SY: Collaborative Research: Foundations of Electronic Marketplaces: Game Theory, Algorithms and Systems","awardID":"0121678","effectiveDate":"2001-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["561267"],"PO":["564456"]},"66811":{"abstract":"EIA-0130599 <br\/>James Krogmeier<br\/>Purdue University<br\/><br\/>CISE Research Resources: Instrumentation for Communications Research in Wireless Ad-Hoc Networking<br\/><br\/>The Schools of ECE and Civil Engineering at Purdue University will purchase radio frequency test equipment (a network analyzer, an air-interface measurement tool, and radio frequency channel emulators), workstations, Bluetooth Developer's Kits, laptops, and supporting electronic and interface supplies to enhance the capabilities of the Wireless Communications Research Laboratory and the Harold L. Michael Traffic Operations Laboratory in the area of experimental wireless communications research and intelligent transportation systems. <br\/><br\/>Four research projects will be directly enhanced by the availability of the above resources: 1) Wireless ad-hoc networking for dedicated short range communications applications in intelligent transportation systems, 2) Reduced complexity receivers for continuous phase modulations, 3) Reduced-dimension decision feedback equalizers for high-speed wireless communications, and 4) Embedded signal processing for intelligent transportation systems.<br\/><br\/>The communications research involved in the projects above is focused on synchronization, channel estimation and equalization, and low complexity receivers for both linear and non-linear modulations. End-to-end network performance is also considered, as is the design of simplified protocols for use in ad-hoc networking. The signal processing research is largely experimental involving the integration of different intelligent transportation subsystems including communications and embedded signal processing for traffic signal control and weigh-in-motion.","title":"CISE Research Resources: Instrumentation for Communications Research in Wireless Ad-Hoc Networking","awardID":"0130599","effectiveDate":"2001-09-15","expirationDate":"2005-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["434205","385370","548182","286927"],"PO":["557609"]},"64534":{"abstract":"EIA-0120256<br\/>Herbert Schorr<br\/>University of Southern California<br\/><br\/>SGER: Digital Government: Fedstats Secure Collaborative Environment<br\/><br\/>This grant will support preliminary explorations of the needs of statistical researchers and Federal statistical agencies to collaborate at a distance, using the Internet, over potentially confidential information. Issues such as security, privacy and authenticated data arise, particularly when some of the collaborators are connected from behind Federal agency firewalls Data analysis, visualization, Internet-based teleconferencing and other collaboration tools will be explored, as will the applicability of new Internet protocols.","title":"Digital Government: FedStats Secure Collaborative Environment (FSCE)","awardID":"0120256","effectiveDate":"2001-09-15","expirationDate":"2002-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}}],"PIcoPI":["200680","427568","335768"],"PO":["371077"]},"61025":{"abstract":"Preliminary work by the PIs has shown that application-level information can be exploited to greatly reduce the amount of redundancy required to deal with transient failures, which are by far the most common type of failure. For example, in a radar target-tracking application, our approach required only 15% redundancy to provide complete fault-tolerance against transient faults. Another use of ALFT is in providing a temporary patch in the event of a permanent processor failure, allowing the system more time to execute a recovery algorithm.<br\/><br\/>ALFT is orthogonal to other approaches to fault-tolerance, so that it can be used either by itself or in combination with them. For example, a designer might use ALFT to guard against transients, and make a small amount of hardware redundancy available, in the form of line-replaceable spares, to deal with permanent failures.<br\/><br\/>The objective of this project is to develop Application-Level Fault Tolerance strategies and investigate their<br\/>effectiveness for various classes of real-time applications. The main focus will be to generalize our approach to include as many different types of applications as possible, develop the most suitable strategy for each application type and evaluate the efficiency of the developed scheme.","title":"Incorporating Fault Tolerance at the Application Level","awardID":"0104482","effectiveDate":"2001-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["553614","553615"],"PO":["180163"]},"64303":{"abstract":"In recent years, Turbo coding has emerged as a powerful forward error control coding paradigm. Although still new, the success of Turbo coding is witnessed by its widespread use in a variety of applications, including deep space communication, satellite communication, and digital cellular communication. <br\/>The key behind this success is the elegant iterative decoder that approaches theoretical limits with <br\/>reasonable implementation complexity. More recently, the iterative decoder structure was abstracted and <br\/>generalized to what is now known as the Turbo Principle. Because of its remarkable performance, it is expected that the Turbo Principle will have an enormous impact on virtually all aspects of digital <br\/>communication systems. The main goal of this research is to explore the fundamental limits of the Turbo Principle while offering practical implementations.<br\/><br\/>The first research thrust aims at developing an analytical approach for computing the convergence thresholds of Turbo decoders. In addition to the expected savings in computational complexity, the analytical approach is <br\/>sought to offer more useful insights for code design. The convergence analysis will facilitate constructing <br\/>irregular ``Turbo-like\" codes that approach the capacity limit of Additive White Gaussian Noise (AWGN) channels. The code performance with small and moderate block lengths will be considered as an additional design criterion. This research will also investigate graphical code design for multi-path fading channels. Code constructions will be optimized for parametric fading models that capture the different limitations in practical systems. Furthermore, The convergence analysis will be used to explore fundamental limits on the <br\/>performance of Turbo multi-user receivers in generalized fading channels.","title":"Exploiting The Turbo Principle","awardID":"0118859","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["347888"],"PO":["348215"]},"63214":{"abstract":"Phylogenetics , the study of the relationships among genes, individuals, populations, and species, forms the basis for all of comparative biology. This IGERT grant will support a comprehensive, interdisciplinary graduate training program in Computational Phylogenetics and Applications to Biology. The program involves 27 faculty participants from the computational and biological sciences at the University of Texas at Austin, and it will support 12 graduate trainees each year for five years. Two major research areas will be emphasized: computational phylogenetics and applied phylogenetics. Phylogenies provide a fundamental framework for all of biology, and present the computational scientist with many technical challenges. Computational phylogenetics is concerned with the computational aspects of phylogenetic inference, and applied phylogenetics uses estimated phylogenies to address a wide diversity of biological questions. The training program will involve a series of new and existing courses and seminars, a summer training program for students from underrepresented areas of science, co-advisement of each graduate student by one computational and one biological faculty participant, placement of students into well-established research groups in biology and computer science, participation in spring recruitment conferences and fall phylogenetics retreats, and opportunities for internships in the bioinformatics industry, national laboratories, and non-government organizations. The goals of this project are: (i) design and implement an interdisciplinary training curriculum for graduate students across computational and biological sciences that prepares students to understand and contribute to both sides of computational biology; (ii) stimulate interdisciplinary graduate research and interdisciplinary interactions in general between computational scientists and biological scientists that will lead to development and testing of novel approaches to unsolved problems in phylogenetics and their application to problems in biology; (iii) prepare trainees for their careers beyond graduate school and help them achieve visibility in the larger research community; and (iv) evaluate and improve the program in computational and applied phylogenetics to ensure its success beyond the proposed IGERT project. This program will create a unique collaborative environment for graduate students and faculty from the computational and biological sciences.<br\/><br\/>IGERT is an NSF-wide program intended to meet the challenges of educating Ph.D. scientists and engineers with the multidisciplinary backgrounds and the technical, professional, and personal skills needed for the career demands of the future. The program is intended to catalyze a cultural change in graduate education by establishing new, innovative models for graduate education and training in a fertile environment for collaborative research that transcends traditional disciplinary boundaries. In the fourth year of the program, awards are being made to twenty-two institutions for programs that collectively span all areas of science and engineering supported by NSF. The intellectual foci of this specific award reside in the Directorates for Biological Sciences; Computer and Information Science and Engineering; and Education and Human Resources.","title":"IGERT: Computational Phylogenetics and Applications to Biology","awardID":"0114387","effectiveDate":"2001-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1713","name":"WORKFORCE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1101","name":"Division of GRADUATE EDUCATION","abbr":"DGE"},"pgm":{"id":"1335","name":"IGERT FULL PROPOSALS"}}],"PIcoPI":["456506","546362","473862",162453,"473863"],"PO":["229999"]},"64545":{"abstract":"Principles of Efficient Inference<br\/><br\/><br\/><br\/>This is the first year funding of a three year continuing award. This project seeks to uncover fundamental principles for the construction of real-time AI systems that employ declarative knowledge representations and general reasoning engines. To achieve this goal, the PI will (a) study the \"fine grained\" structure of problem hardness based on notions coming out of work on phase transitions in random problem distributions; (b) develop faster complete and incomplete reasoning engines, including systems that employ decision-theoretic control of reasoning; and (c) apply and test the new algorithms to planning problems in a robotics testbed. This research will lead to the creation of useful new algorithms for solving hard combinatorial problems in areas such as knowledge-based expert systems, autonomous systems, and operations research. The results will also promote interdisciplinary work on logic and reasoning in the AI, theory, OR, robotics, and verification communities.","title":"Principles of Efficient Inference","awardID":"0120307","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["550377"],"PO":["491702"]},"63225":{"abstract":"This IGERT award supports the establishment of a multidisciplinary graduate training program of education and research in the development of a virtual tribology system for future powertrains, which are the power-delivery systems of automobiles and aircraft. The current development of a powertrain tribological system is time-consuming, requiring integration of new materials, engine technologies, trial-and-error, laboratory experimentation and extensive field-testing. The vision is to shorten the development time by developing a virtual powertrain through advanced computer modeling that simulates the interfacial interactions among critical machine elements. The development of such technology requires new engineers and scientists with cross-disciplinary training. The traditional engineering Ph.D. training model based on one advisor and a single topic does not work well in this new paradigm. Creating Ph.D.s who are educated in a multidisciplinary environment represents the educational focus of this IGERT program. Because of the need for multiscale modeling and multidisciplinary research, an aggressive education plan requiring the creation of a multidisciplinary learning\/research environment, electronic education, industrial collaboration, international outreach and faculty re-education will be an integral part of the current program. This program is a joint effort among faculty members in chemistry, chemical engineering, civil engineering, computer engineering, materials science and mechanical engineering, as well as physics. With the successful development of virtualization technology, it is hoped to educate a new generation of engineers and scientists who have strong technical skill and are proficient in multidisciplinary collaboration and in working with computer simulations of complex systems.<br\/><br\/>IGERT is an NSF-wide program intended to meet the challenges of educating Ph.D. scientists and engineers with the multidisciplinary backgrounds and the technical, professional, and personal skills needed for the career demands of the future. The program is intended to catalyze a cultural change in graduate education by establishing new, innovative models for graduate education and training in a fertile environment for collaborative research that transcends traditional disciplinary boundaries. In the fourth year of the program, awards are being made to twenty-two institutions for programs that collectively span all areas of science and engineering supported by NSF. The intellectual foci of this specific award reside in the Directorates for Engineering; Computer and Information Science and Engineering; Mathematical and Physical Sciences; and Education and Human Resources.","title":"IGERT: On A Virtual Tribology System: Future Engineers and Future Powertrain Virtualization Technology","awardID":"0114429","effectiveDate":"2001-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0700","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"T200","name":"NAVY-N-STAR COLLABORATIVE PROG"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1633","name":"MATERIALS AND SURFACE ENG"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"1360","name":"HUMAN RESOURCES DEVELOPMENT"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1101","name":"Division of GRADUATE EDUCATION","abbr":"DGE"},"pgm":{"id":"1335","name":"IGERT FULL PROPOSALS"}}],"PIcoPI":["277392","493345","414683","553335","556394",162505],"PO":["434633"]},"64798":{"abstract":"Real-time Environmental Observation and Forecasting Systems (EOFS) will revolutionize the way scientists share information about the environment and represent an opportunity to break traditional information barriers separating scientists from society at large. EOFS are already in use, but they tend to be small-scale, application- and domain- specific, stand-alone systems. There is a need for evolution towards multi-purpose shared systems designed to adapt flexibly to evolving needs of information consumers. What is required are large-scale, shared, heterogeneous distributed systems that make extensive use of diverse sensor-based inputs, sophisticated numerical simulations, mobile and embedded real-time system components, wireless and wired communications, high-performance computers, and high capacity storage systems. <br\/><br\/>This ITR medium project has assembled an inter-disciplinary team, including computer science and environmental science researchers in addition to a heterogeneous base of pilot users. This group will collaborate to develop software technology which will enable EOFS to evolve efficiently, and to deliver quantifiably reliable information about the environment at the right time and in the right form to the right users. The project focus is on EOFS for estuarine and coastal regions. These regions are selected because they are highly variable natural systems subject to intense human activity and with great social, environmental, economic and cultural value.<br\/><br\/>The research will include:<br\/><br\/>i. Developing missing integration concepts and technologies for EOFS, with emphasis on quality-scalable information processing, storage and access (the computer science research).<br\/>ii. Closing the loop between environmental models and sensors, and implementing a next generation EOFS based on an existing prototype for an estuary with multiple and often conflicting uses (the environmental observation and forecasting systems research);<br\/>iii. Using, evaluating and refining the EOFS prototype for scientific discovery, natural resources stewardship and emergency response, thus incorporating sound science in operational and management decisions of critical regional importance and national significance (the environmental science and management applications);<br\/>iv. Developing pilot multi-level, inter-disciplinary educational programs that cross-train young people, computer scientists, environmental scientists and practitioners in the conceptualization, development and use of environmental information technology (the education impact).","title":"ITR\/IM+AP: Quality-Scalable Information Flow Systems for Environmental Observation and Forecasting","awardID":"0121475","effectiveDate":"2001-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["459571","483300","341681","562760","518376"],"PO":["565272"]},"63115":{"abstract":"Cryptography is a fundamental building block for building information systems, and as we enter the so-called \"information age\" of global networks, ubiquitous computing devices, and eletronic commerce, we can expert that cryptography will become only more import with time.<br\/><br\/>This proposal is designed to advance the state of the art in cryptography by examining some of the implicit assumptions that underlie the field. The birth of provable security has contributed significantly to the advances of the field over the past two decades, allowing us to amass strong evidence that-as long as the attacker plays by the rules specified in our formal threat model-the cryptosystem under consideration is likely to be secure. However, one problem is that, in practice, attackers don't always play by the rules: given the opportunity, they will gladly \"cheat\". Recent research has shown that there are a surprising number of ways to violate the designer's assumptions, for instance by observing timing measurements which the model does not allow for. <br\/><br\/>The goals of practical cryptographic design, then, ought to include finding ways to reduce the opportunity for attackers to \"cheat\", preferably by relaxing our assumptions and broadening our models enough so that the attacker's behavior cannot help but be covered by the model. This is the research agenda that we take up in this project. We propose first to study real systems and case studies of how these assumptions can be violated in practice. A next step is to build a set of practical countermeasures that can be used to strengthen future cryptosystems against these attacks. Finally, we will seek new theoretical tools, techniques, and models for extending the provable security methodology to take into account these failure modes. If we succeed, these results will make a positive contribution not only to the practice of cryptography but also to the theoretical foundations of the field.","title":"ITR\/SY(CISE): Cryptography: Examining the Assumptions","awardID":"0113941","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["550026"],"PO":["250082"]},"64446":{"abstract":"ABSTRACT<br\/><br\/>Information Technology Workforce (ITWF)<br\/><br\/>Proposal Id: EIA-0119839<br\/>PI: Paula G. Leventman, Thomas P. Cullinane and Ronald F. Perry<br\/>Institution: Northeastern U.<br\/>Title: Multiple Pathways towards Gender Equity in the Information Technology Workforce<br\/><br\/>This ITWF award provides support for a study of graduates of an information systems graduate program (MSIS) at Northeastern University, as well as men and women currently working in Information Technology (IT) positions, to understand the factors that influence entry and persistence of women in IT positions. The MSIS program was designed for adult learners who wished to make a career transition to the IT field. The research team will use the longitudinal data collected in the study to develop and validate a model that will predict women's IT career pathways.","title":"Information Technology Workforce - ITWF: Multiple Pathways toward Gender Equity in the Information Technology Workforce","awardID":"0119839","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":["340578","192425","500659","255197"],"PO":["289456"]},"64699":{"abstract":"No current system allows a person to naturally walk through a large-scale virtual environment. The availability of such a locomotion interface would have impacts on a broad range of applications, including education and training, design and prototyping, physical fitness, and rehabilitation; for some of these applications natural walking provides a level of realism not obtainable if movement through the simulated world is controlled by devices such as a joystick, while for others realistic walking is a fundamental requirement. Prototypes have been built for a variety of computer-controlled devices on which a person can walk, but there has been little investigation of the utility of such devices as interfaces to a virtual world and almost no study at all of the interactions of visual and biomechanical perceptual cues in such devices. This project addresses key open questions, the answers to which are needed if locomotion interfaces are to offer effective interaction between users and computer simulations. An effective locomotion interface must provide users with accurate visual and biomechanical sensations of walking; thus, a key objective of this work is to determine how to synergistically combine visual information generated by computer graphics with biomechanical information generated by devices that simulate walking on real surfaces. The PI and his collaborators will investigates methods that allow more accurate walking in a locomotion interface while accurately conveying a sense of the spaces being walked through. Specific issues to be considered include how to facilitate the perception of speed and distance traveled, how to provide a compelling sense of turning when actual walking along a curved path is not possible, how to give a user the sense that he\/she is walking over a sloped surface, and more generally how to give a user a clear sense of the scale and structure of the spaces being walked through. The PI's findings on these issues will be relevant across the spectrum of possible approaches to locomotion interfaces.","title":"ITR\/SY: Collaborative\/RUI Research on the Perceptual Aspects of Locomotion Interfaces","awardID":"0121084","effectiveDate":"2001-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["560997","513354","292838","553308"],"PO":["564316"]},"66767":{"abstract":"EIA-0130391<br\/>Gerald J. Sussman<br\/>Massachusetts Institue of Technology<br\/><br\/>Title: Robust Engineering Using Biologically-inspired Models of Cell Differentiation and Morphogenesis<br\/><br\/>This research focuses on morphogenesis and developmental biology as an inspiration for algorithms and general principles for organizing complex behavior from locally interacting agents. The goal is to design artificial systems that replicate biological robustness, and to use insights from these systems to understand the capabilities of biological systems. The general principles are formalized as programming languages --- with explicit primitives, means of combination, and means of abstraction --- thus providing a framework or the design and analysis of self-assembling systems. Previous work demonstrated this approach with a programming language that specifies a robust process for shape formation on a sheet of identically-programmed ``cells'' using local primitives from epithelial cell morphogenesis and Drosophila cell differentiation, and rules from geometry. The specific aims are: 1) developing new programming models for domains such as growth and apoptosis (cell death) and 2) investigating the connection of current programming models to biological processes. This research will have significant impact on both the engineering principles for robust design and on the understanding of biological morphogenesis.","title":"Bio-QuBIC: Robust Engineering using Biologically-Inspired Models of Cell Differentiation and Morphogenesis","awardID":"0130391","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["485691"],"PO":["565223"]},"65799":{"abstract":"The 2001 International Working Conference on Active Networking (IWAN) will be held in<br\/>Philadelphia, Pennsylvania, from September 30, October 2nd, 2001. This conference is the pre-mier<br\/>international workshop in the emerging field of active and programmable networking. This<br\/>proposal requests funding to assist fourteen United States-based graduate students in attending this<br\/>meeting. Participation in workshops such as IWAN is an extremely important part of the gradu-ate<br\/>school experience, providing the opportunity to interact with more senior researchers and be<br\/>exposed to leading edge work in the field. In addition, IWAN offers the opportunity to interact<br\/>with international researchers in this area, as both the presenters and the attendees have had strong<br\/>European and Asian presences. The support requested in this proposal will enable the participation<br\/>of students who would otherwise be unable to attend IWAN 2001.","title":"Travel Support for Internal Working Conference on Active Networking - IWAN 2001","awardID":"0126044","effectiveDate":"2001-09-15","expirationDate":"2003-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["527253"],"PO":["234222"]},"66778":{"abstract":"EIA-0130422 <br\/>Louiqa Raschid<br\/>University of Maryland College Park<br\/><br\/>CISE Research Resources: Infrastructure to Develop a Large Scale Experiment Testbed of Multi-model Resources<br\/><br\/>The use of the widely distributed collections of structured and unstructured information expressed in multiple languages or modalities provided by the Internet, requires production of scalable, robust algorithms for the discovery of replicated content, determination of delay or access latency of sources, and the confrontation of the inherently dynamic nature of the Internet.<br\/><br\/>This project's objective is to establish a laboratory testbed providing a controlled environment that captures structural, content, and latency characteristics of the (publicly accessible) Web. This will stimulate collaboration between researchers whose interests range over natural language applications, language independent processing of scanned documents, analysis of video information sources, information retrieval, and wide area applications and resource discovery across heterogeneous servers. <br\/><br\/>The testbed will support the development and testing of: (1) tools for broad-scale, cross-linguistic analysis and discovery of relevant information across languages and modalities, (2) cost models and access cost catalogs for wide area environments, reflecting the temporal variability in access latency, (3) distributed content based indexing and association of media clips for resource discovery, (4) transcoding and scheduling of multimedia resources for delivery any time and anywhere to disparate clients; from mobile wireless to high speed optical links.","title":"CISE Research Resources: Infrastructure to Develop a Large Scale Experiment Testbed of Multi-modal Resources","awardID":"0130422","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["364501","543580","334102","564282","543582"],"PO":["557609"]},"64358":{"abstract":"The focus of this research project is to develop visualization, interaction, and data management technologies to address the problems of high dimensionality and data type heterogeneity in large-scale visual data mining. The basic approach is to apply multiresolution clustering strategies across the dimensions of a data set as well as within individual dimensions containing nominal or categorical values, and exploit the ordering and positioning of data axes and data points to emphasize relationships within the data. For visualization, the tasks involve the development of methods for determining ordering and variable spacing within and between data and dimensions as well as clustering of dimensions into multi-resolution abstractions, and integrating them into several existing multivariate display techniques. For interaction, tools for intuitive navigation and exploration within the multiresolution spaces are developed. This includes interactive reclustering tools to allow users to guide the process of splitting and grouping clusters of data objects and dimensions. For data management the tasks involve the development of high-dimensional indexing and multi-resolution data view management for high-dimensional data access, and caching and prefetching strategies to support real-time visual exploration. The ease of use as well as performance of the display and interactive tools over large data sets is assessed. The results of this research will provide data analysts in domains such as bioinformatics, earth and space sciences, and e-commerce the ability to interactively explore the increasingly large and complex data sets being generated.","title":"Order, Spacing, and Clustering in Visual Exploration of Large Scale Data","awardID":"0119276","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V033","name":"NSA-ORDER SPACING & CLUSTERING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V284","name":"NSA-SPACING & CLUSTERING IN VI"}}],"PIcoPI":["543519","543520"],"PO":["563751"]},"57714":{"abstract":"Emerging infrastratureless wireless networking technologies such as MANET [1], sensor networks [31],<br\/>and bluetooth [2] will seek to support advanced applications such as smart environment, \"zero conf\"<br\/>teleconferencing setups, collaborative learning, wireless access to Web services, and emergency rescure<br\/>operations. This class of applications is mission critical, and the network has to address a number of critical<br\/>issues in order to cope with the anticipated design requirements of such applications. In an<br\/>infrastructureless wireless network, no underlying infrastructure, such as cellular layout and central control units e.g. base stations, is available for networking support. A large number of networking devices are allowed to communicate with one another over the shared wireless medium in an ad hoc manner. Some<br\/>unique design challenges posed by such networks include fully distributed and localized design, sustained<br\/>quality of service (QoS), efficient network resource utilization, unconstrained scalability and robust system<br\/>performance. State-of-the-art solutions are inadequate to address these issues and meet the applications'<br\/>requirements. A fundamental problem is that an infrastructureless wireless network is a large-scale<br\/>distributed system that may consist of a very large number of wireless networking components (e.g.<br\/>thousands, even millions in a sensor network), which have limited power and computing resources and are<br\/>prone to channel errors and failures. Therefore, any feasible system solution must be fully distributed and<br\/>localized, scalable, and robust. In some sense, the microscopic behavior of each individual node may not be<br\/>very critical, but network nodes must collectively achieve the desired global macroscopic property.<br\/> In this project, we propose a novel self-organizing protocol and algorithm design approach for such<br\/>networks, in order to meet the challenges posed by applications as well as the network itself. In a self-organizing design approach, local decision makers self-organize themselves and coordinate among one<br\/>another, in order to collectively achieve the desired global property. We apply our proposed design<br\/>methodology in two largely unaddressed problem domains: fair packet scheduling in multihop wireless<br\/>networks, and robust report forwarding in sensor networks. Toward this end, we present four self-organizing packet-scheduling algorithms and a novel report forwarding protocol that we have developed<br\/>recently [22, 24, 35, 36, 46, 47]. The key innovations of this work are:<br\/> A model-referenced self-organizing algorithm and protocol design approach.<br\/> A suite of self-organizing packet scheduling algorithms for infrastructureless wireless networks that<br\/>provide QoS performance bounds in terms of fairness, throughput and delay, maximize channel spatial<br\/>reuse, and arbitrate the conflict between achieving fairness and maximizing channel utilization.<br\/> A novel self-organizing data forwarding protocol that allows for unconstrained scalability, supports<br\/>robust message delivery along the optimal forwarding band, and ensures efficient power consumption<br\/>in the context of sensor networks.<br\/> The expected research results from this project include a formal investigation of self-organizing design<br\/>approach, and a detailed design, analysis, and evaluation of the self-organizing algorithms and protocols for<br\/>packet scheduling and report forwarding. The resulting software will be freely available to the research<br\/>community. The education plan in this proposal includes offering a new graduate course, reinventing an<br\/>undergraduate networking course, recruiting more students into undergraduate research programs, and<br\/>setting up an undergraduate networking laboratory.","title":"CAREER: Self-organizing Algorithm and Protocol Design for Infrastructureless Wireless Networks","awardID":"0093484","effectiveDate":"2001-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["451118"],"PO":["565090"]},"66789":{"abstract":"EIA-0130498<br\/>Robert H. Klenke<br\/>Virginia Commonwealth University<br\/><br\/>NGS Performance Modeling of Complex Hardware\/Software Systems through Mixed Level Modeling<br\/><br\/>This project will develop a revolutionary new capability by providing a unified design framework for complex, high performance computer systems. This framework includes a performance modeling environment that will be integrated into a mixed level hardware\/software design environment through the use of standard Hardware Description Languages (HDLs) and supporting design tools. This framework will allow the modeling of hardware and software systems at a high level to enable rapid design space exploration and system performance analysis. The framework will provide the capability to refine these high level designs in a step-wise manner into models with more design detail and, ultimately into an implementation. This step-wise refinement capability allows areas of the design that are determined to be \"high risk\" in terms of performance to be refined to a more detailed level where the effects on system performance of assumptions and design can be realized.","title":"Collaborative Research: Performance Modeling of Complex Hardware\/Software Systems Through Mixed Level Modeling","awardID":"0130498","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":[173131],"PO":["301532"]},"65469":{"abstract":"Abstract<br\/><br\/>The information revolution has led organizations worldwide to rely heavily on numerous databases to conduct their daily business. Because databases usually exist in broad, highly dynamic network-based environments, formally accessing the resources in a secure manner poses a difficult challenge. Specially, the healthcare industry has recently tried to transit from their old and disparate business models based on ink and paper to a new and consolidated ones based on digitalized information since last a few years for their customers' and stakeholders' needs. <br\/>In addition, the proposed rules of the Health Insurance Portability and Accountability Act (HIPAA), circulated by the U.S. Department of Health and Human Services (HHS) through the Health Care Financial Administration (HCFA) strongly require the services of security and privacy. Along with this movement, a secure solution for the complex environment like healthcare industry has been highly demanded. Recently, the President's Information Technology Advisory Committee (PITAC) has issued a report about how security can be deployed to modernize the nation's healthcare systems. Nobody has taken a leadership role and demanded investment in information technology. Without active leadership it will be difficult, if not possible, to get the highly decentralized healthcare industry to come up with a standard secure information system.<br\/>This motivates us to propose a scalable application that can serve as a security tool to the complex environment like healthcare industry. The problem we seek to address in this research is to provide authentication of individual identity in the context of accessing critical information including secure transmission of data across the Internet. These problems have technical solutions that are well known, but the solutions in general are strongly biased toward a single individual interacting with a single application. When an individual needs to access more than one application, or even the same application at a different location or institution, he or she needs another set of electronic keys. In a collaborative and research environment, individuals must collect and maintain a key set of electronic access mechanisms that quickly becomes cumbersome and difficult to manage. For this reason, we focus on token-based solution.<br\/>In this research, we propose scalable token-based authentication architectures & mechanisms and demonstrate how we can implement them using commercial-off-the-self technologies. Our approach focuses on vendor-neutral specifications including the feasibility of the construction of password, certificate and signature-based authentication mechanisms.","title":"Exploratory Research-Scalable Token-Based Authentication: Architectures and Mechanisms","awardID":"0124873","effectiveDate":"2001-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["492724"],"PO":["241298"]},"80561":{"abstract":"","title":"CAREER: Augmenting Expertise Networks","awardID":"0296152","effectiveDate":"2001-09-15","expirationDate":"2004-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["430298"],"PO":["495796"]},"60773":{"abstract":"EIA-0103660<br\/>Naren Ramakrishnan<br\/>Virginia Polytechnic Institute<br\/><br\/>NGS: A Microarray Experiment Management System<br\/><br\/>The objective of this proposal is to develop systems software relating to the management of microarray experiments for studying hundreds of genes in given organism simultaneously. This is a multidisciplinary collaboration between computer scientists who will perform the computer science research part of this project and will develop the computer systems software, and biologist who will use the microarray experiment as a driving case for the systems software to be developed under the project, and then they will be the users of the developed management infrastructure.","title":"NGS: A Microarray Experiment Management System","awardID":"0103660","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"1145","name":"INTEGRATIVE PLANT BIOLOGY"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"1329","name":"PLANT GENOME RESEARCH PROJECT"}}],"PIcoPI":["346629","473966","473967","208197","498314"],"PO":["301532"]},"60784":{"abstract":"EIA-0103688<br\/>Purdue University<br\/>John R. Rice<br\/><br\/>The goal of this project is to develop the tools needed for performance-directed integrated design and control of complex applications running on distributed computational systems. Its target computational systems are complex, incorporating the difficult heterogeneity, latency, and adaptive properties of computational grids. Its target applications are at the cutting edge of computational science: very large, complex applications with adaptive characteristics that do not allow their optimal system configurations or computational requirements to be estimated prior to run time. Each application will be viewed as a composition of components, with a formal, high fidelity model of performance to be designed for each component. The approach is to use model-based adaptive run-time control, based on these composed performance models, to control the execution of the application to meet specified performance goals. The control strategy will make real-time changes to parameters that modify the behavior of both application and computational platform.","title":"NGS: Collaborative Research: Performance-Driven Adaptive Software Design and Control","awardID":"0103688","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["226214","493579"],"PO":["301532"]},"62973":{"abstract":"EIA-0113137<br\/>Yanhua Shih<br\/>University of Maryland Baltimore County<br\/><br\/>Title: ITR: Quantum Entanglement, Information and Computation<br\/><br\/>This project consists of a series of experimental and theoretical investigations on multi-photon entangled states and their fundamental role in quantum information and quantum computing. Major efforts underway include experimental and theoretical investigations on N-photon (N>2 entangled states) and on \"partial entanglement\" in quantum information and quantum computation theory. <br\/><br\/>Theoretical characterization of entanglement in mixed states is at the core of this project. The experimental investigations focus on two projects. The first one is the realization of source of three-photon entangled states. These may lead to experimental generation of GHz states. The second experimental project is quantum teleportation based on the improvement on the realization of Bell-state detection.","title":"ITR: Quantum Entanglement, Information and Computation","awardID":"0113137","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":[161698,"303787",161700],"PO":["565223"]},"60795":{"abstract":"EIA-0103725<br\/>James C. Browne<br\/>University of Texas<br\/><br\/><br\/>The goal of this project is to develop the tools needed for performance-directed integrated design and control of complex applications running on distributed computational systems. Its target computational systems are complex, incorporating the difficult heterogeneity, latency, and adaptive properties of computational grids. Its target applications are at the cutting edge of computational science: very large, complex applications with adaptive characteristics that do not allow their optimal system configurations or computational requirements to be estimated prior to run time. Each application will be viewed as a composition of components, with a formal, high fidelity model of performance to be designed for each component. The approach is to use model-based adaptive run-time control, based on these composed performance models, to control the execution of the application to meet specified performance goals. The control strategy will make real-time changes to parameters that modify the behavior of both application and computational platform.","title":"NGS: Collaborative Research : Performance-Driven Adaptive Software Design and Control","awardID":"0103725","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["510448","194049"],"PO":["301532"]},"61895":{"abstract":"There has been an increasing interest in incorporating explicit spatial structure into ecological models. This research will investigate the effect of spatial structure on the dynamics of populations at the edges and borders of their ranges. The investigators will develop analytic and numerical approaches using methods from theoretical physics. They will study the spatial patterns that develop at different types of population margins, and how these patterns change when margins are either expanding or retreating. They will investigate how the range of a population in one dimension (as along a stream or a coastline) might differ from that of a two-dimensional population in an identical environmental gradient. The investigators will also study the effect of biotic factors, e.g. pathogens, on marginal populations, and whether margins can act as host refugia.<br\/><br\/>The goal of this project is to increase general understanding of the dynamics of population margins, as well as to stimulate and direct the detailed study of such margins. In the past decade, the spatial analysis of populations has been greatly facilitated by rapid technical advances in mapping, remote sensing, and computation. A strong theoretical basis for the spatial structure of population margins is an essential guide for the interpretation of such data.","title":"Spatial Dynamics and Fluctuations at Population Margins","awardID":"0108513","effectiveDate":"2001-09-01","expirationDate":"2003-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"1174","name":"POPULATION DYNAMICS"}}],"PIcoPI":["485498","349823"],"PO":["564220"]},"61312":{"abstract":"General purpose processors (GPPs) are designed to implement on fixed configuration that is good on average but may not be well suited for individual applications. In fact, applications can have drastically different execution characteristics (e.g. branch prediction technique preference, cache configuration and policy preference, low-power opportunities). This suggests the use of device reconfigurability, but generic reconfigurable logic of any substantial scale (e.g. most field programmable gate array (FPGA) technology) is slow, lacks density, and is power-hungry. Yet many processor structures are easily adaptable to a wide variety of configurations. This research will develop dynamic, small-scale, partial reconfigurability for such structures. This \"Dynaptable\" approach has the further benefit that it integrates work at the architectural, logic, and circuit levels.<br\/><br\/>The Dynaptable approach consists of three key elements:<br\/><br\/> 1. Flexible structures: designing key processor structures with judicious amounts of reconfigurable hardware to provide flexibility in a low-cost, non-invasive way.<br\/><br\/> 2. Run-time monitoring: determining the current configuration's performance or effectiveness compared to other possible competing configurations.<br\/><br\/> 3. Dynamic reconfiguration: using the results of run-time monitoring to adapt to a new configuration that improves the chosen figure of merit (e.g. performance, energy-delay product, fault tolerance).<br\/><br\/>The research will identify the most profitable places for adding small-scale reconfigurability, design the requisite reconfigurable elements, and develop the most effective and lowest-cost techniques for dynamic monitoring and adaptation. This work will have an impact on the design of a variety of processor components (branch predictor, cache, datapath, etc.) for a range of processing environments (embedded systems, superscalar, SMT, etc.). The final goal is to develop a consistent methodology for dynamically adapting GPP microarchitectures for improved performance, lower power, and increased fault tolerance.","title":"Small-Scale Dynamic Reconfigurability for Large-Scale Benefits","awardID":"0105626","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["560683","489873","527785"],"PO":["180163"]},"60597":{"abstract":"This project will develop scalable algorithms for solving discrete optimization problems (DOPs) in distributed-memory computing environments. DOPs arise in many important applications such as planning, scheduling, logistics, telecommunications, bioengineering, and robotics. Most of these problems are NP-complete, but in practice, intelligent search algorithms such as Branch, Cut, and Price (BCP) have been successful at tackling them. This research will develop parallel algorithms based on BCP that not only can use large numbers of processors efficiently, but also can handle very large problem instances. A key part of these algorithms is the data structure used for maintaining the information for each node in the search tree. This can be implemented with a memory-efficient differencing scheme relating the parent and child nodes. However, these data structures do not allow the use of current techniques for implementing scalable branch and bound search algorithms. This project will overcome that difficulty.<br\/><br\/>The project will build on previous work in which the PI developed an object-oriented, generic framework called SYMPHONY (Single- or Multi-Process Optimization over Networks). Because of its modular design, SYMPHONY is extremely flexible and can be used to solve a wide variety of DOPs. Source code and documentation for SYMPHONY is currently distributed for free to the research community. This project will develop data structures and load balancing methods to decentralize SYMPHONY's current centralized control and data storage model. These improvements will be added to the web-based distribution to improve the impact of this project.","title":"Scalable Parallel Algorithms for Large-Scale Discrete Optimization","awardID":"0102687","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}}],"PIcoPI":["550619"],"PO":["565272"]},"64843":{"abstract":"Our primary research goal is to develop a prototype voice-enabled<br\/>translating communicator which will deliver information services across<br\/>the linguistic divide for minority languages in order allow remote<br\/>linguistically-diverse users to communicate directly with Internet<br\/>content and databases, and more importantly to communicate with others<br\/>speaking a different language from their own. The latter will enable<br\/>information, education, and, for example, health services, to reach<br\/>remote minority-language communities. Achieving this goal requires<br\/>major advances in machine learning for translation and in cross-language<br\/>speech-recognition adaptability to wider language phenomena.<br\/><br\/>Traditional transfer-rule-based MT requires up to a person-century<br\/>to build and perfect a new language pair. Statistical and<br\/>Example-Based MT replaces human coding effort by vast amounts of<br\/>bilingual training data, which are virtually unobtainable for most<br\/>minority languages. Without a radical advance, leading to an<br\/>over-an-order-of-magnitude improvement in development time, the<br\/>only commercially justifiable MT applications involve the major<br\/>European languages, Japanese, Chinese, Korean, Arabic and perhaps a<br\/>couple more relatively-popular languages. The vast majority of human<br\/>languages are currently relegated to the proverbial MT dust heap.<br\/><br\/>We propose new MT approaches based on extended and new machine<br\/>learning methods. The first approach consists of statistical MT<br\/>methods that learn from orders of magnitude less training data,<br\/>and that can more effectively incorporate prior linguistic information<br\/>(including dictionaries, word classes, and known linguistic<br\/>rule classes or constraints) by using the joint source-channel<br\/>modeling approach combined with exponential (maximum entropy) models.<br\/>The second approach is a new method for acquiring high-quality MT<br\/>transfer rules from native informants which decreases dependence on<br\/>human experts and reduces development time. Semantically-conditioned<br\/>transfer rules are generalized via a new locally-constrained<br\/>Seeded Version-Space method based on a controlled bilingual corpus<br\/>and interactive tools to elicit information from native informants.<br\/>The third method builds general phone models across multiple language<br\/>families for speech recognition and adapts the recognizer to new<br\/>languages with minimal new- language training data. All of these<br\/>methods are based on new and existing machine learning algorithms<br\/>that combine prior knowledge with limited amounts of new data in<br\/>order to converge quickly on working machine translation and speech<br\/>recognition and synthesis systems.<br\/><br\/>The primary societal impact will be a significant contribution<br\/>to the global democratization of informa- tion, a process that<br\/>requires bridging current linguistic barriers, especially for<br\/>low-density or economically- disadvantaged languages. Additionally,<br\/>preservation and teaching of endangered languages will be directly<br\/>enabled by the new linguistic and acoustic knowledge coupled with<br\/>existing tutorial software. If successful, Avenue (Adaptable Voice-Enabled<br\/>Natural-translator for Universal Empowerment) will be the prototype<br\/>of an MT system that will empower world-wide access to multilingual<br\/>information.","title":"ITR\/PE: AVENUE: Adaptable Voice Translation for Minority Languages","awardID":"0121631","effectiveDate":"2001-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["485891","496511","502549","562859","226262"],"PO":["565215"]},"64854":{"abstract":"Tele-immersion will provide a dramatic new medium for groups of people remote from each other to work and share experiences together in an immersive 3D virtual environment, much as if they were co-located in a shared physical space. Immersive electronic books that in effect blend a \"time machine\" with 3D hypermedia, will add an additional important dimension, that of being able to record experiences in which a viewer, immersed in the 3D reconstruction, can literally walk through the scene or move backward and forward in time. While there are many potential application areas for such novel technologies (e.g., design and virtual prototyping, maintenance and repair, paleontological and archaeological reconstruction), the focus here will be on a societally important and technologically challenging driving application, teaching surgical management of difficult, potentially lethal, injuries. Today, the pace of surgical innovations has increased dramatically, yet the mechanisms for training and re-training suffer from inflexible timing, extended time commitments, and limited content. Traditional videotaped instruction has long been available to help surgeons learn new procedures, but this approach is only marginally effective due to the fixed point of view that is integral to the narration, lack of depth perception and interactivity, and missing information; in short, the experience of watching a video is not sufficiently close to being there and seeing the procedure. In this project the PI will develop a new paradigm for teaching surgical procedures that allows surgeons to witness and explore (in time and space) a past surgical procedure as if they were there, with the added benefit of instruction from the original surgeon or another instructor, as well as integrated 3D illustrations, annotations, and relevant medical metadata. The trainees should be able to freely and naturally walk around a life-sized, high-fidelity, 3D graphical reconstruction of the original time-varying events, pausing or stepping forward and backward in time to satisfy curiosity or allay confusion. To make this reality, the PI and his team bring together experts in several disciplines, and will be able to collectively leverage their prior work in tele-immersion, time-varying 3D scene capture, interaction metaphors, \"cinematic\" techniques. and authoring tools.","title":"ITR\/SY: Electronic Books for the Tele-immersion Age: A New Paradigm for Teaching Surgical Procedures","awardID":"0121657","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["448703","359767"],"PO":["564456"]},"55911":{"abstract":"This document describes a proposed software system, called INBOUNDS (Integrated<br\/>Network-Based Ohio University Network Detective Service), that will address the<br\/>difficult research problem of security in the dynamic real-time Internet environment<br\/>populated by both legitimate users and hostile intruders.<br\/> Internet security is becoming more critical by the day. Successful attacks on banks,<br\/>schools, government agencies, and corporations that do business online are becoming<br\/>more and more common, and the frequency of these attacks and the amount of damage<br\/>done is rising rapidly. Commercially available firewalls and intrusion detection systems<br\/>are currently the only weapons with which to defend against the threat, but they are<br\/>obviously not capable of keeping up with the ever-changing attack strategies of hackers.<br\/> Thus, we propose INBOUNDS a real-time network based intrusion detection and<br\/>response system under development at Ohio University's Laboratory for Real-Time,<br\/>Secure Systems and Applications. INBOUNDS detects and responds to suspicious<br\/>behavior by using TCPTrace (a network traffic analysis tool) and DeSiDeRaTa (dynamic,<br\/>real-time resource management middleware). INBOUNDS is intended to function in a<br\/>heterogeneous environment with fault tolerance, very low overhead, and a high degree of<br\/>scalability. A prototype of INBOUNDS is currently being used for around-the-clock<br\/>intrusion detection and response at Ohio University and we propose to add functionality<br\/>that will enable INBOUNDS to deal with the following important types of attacks:<br\/> Large-scale, distributed denial-of-service attacks<br\/> Abnormal network protocol behavior including SYN and RESET attacks<br\/> Suspicious keywords in interactive sessions\/email<br\/> Suspicious patterns of data, such as the fan-out patterns commonly seen with<br\/> email viruses<br\/> Communication over unusual network ports, which are common when attackers<br\/> target seldom used and insecure servers<br\/> Connections from unknown\/unusual hosts<br\/> Abnormal data patterns for a particular time of day<br\/> Unusual data patterns on known ports, such as would be seen when at attacker<br\/> installs programs using the fingerd port as in the Morris Worm","title":"INBOUNDS: The Integrated Network-Based Ohio University Network Detective Service","awardID":"0086642","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":[143459,"237796",143461],"PO":["565090"]},"66801":{"abstract":"0130538 <br\/>Peter Doerschuk<br\/>Purdue University<br\/><br\/>CISE Research Resources: Computer Cluster to Support Computational Biology and Other Nonlinear Signal Reconstruction and System Design Problems<br\/><br\/>The grant, an equipment grant, will purchase two computers, a compute server and a 3-D visualization workstation, in support of the investigators' NSF CISE funded work in computational mathematics and its application to the structural biology of viruses and other nonlinear signal reconstruction and system design problems. The compute server (Microway, Inc.) is a cluster computer containing 64 Intel Pentium III microprocessors and 16 GB of memory organized into 32 nodes connected by 100 Mb Ethernet. The visualization workstation (Sun Microsystems) is a workstation with one 900 MHz UltraSPARC-III microprocessor, 1 GB of memory, and the intermediate level of Sun's three levels of 3-D graphics hardware accelerators.<br\/><br\/>This equipment will support 3 projects which concern computational mathematics including multi-dimensional quadratures, transforms, and numerical optimization. The unifying theme is numerical optimization, especially global optimization. The projects are divided according to application and include 3-D reconstruction problems in structural biology and systems design problems for nonlinear communication channels. The main application is structural biology, in particular, the structural biology of viruses. The problems of particular interest are 3-D signal reconstruction problems for computing the dynamical behavior of viruses from a variety of biophysical measurements.","title":"CISE Research Resources: Computer cluster to support computational biology and other nonlinear signal reconstruction and system design problems","awardID":"0130538","effectiveDate":"2001-09-15","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["226023","518003"],"PO":[173164]},"64502":{"abstract":"ABSTRACT<br\/><br\/>Information Technology Workforce (ITWF)<br\/><br\/><br\/>Proposal Id: EIA-0120111<br\/>Investigator: Catherine J. Weinberger and Peter Kuhn<br\/>Institution: UC, Santa Barbara<br\/>Title: Entry, Earnings Growth, and Retention in IT Careers: An Economic Study<br\/><br\/>This proposal provides support for the University of California Santa Barbara to conduct three studies which together address questions pertaining to the college major choices of young women, and to the persistence and labor market success of college-educated women in Information Technology Workforce (IT) careers. The first study will examine the career paths of women who already have IT degrees and will explore whether there are labor market barriers that make IT careers less appealing to women. The second is a longitudinal study that will utilize decision theory to scrutinize common assumptions of economic models of career choice. The third study will survey young women's beliefs (or stereotypes) about the characteristics of IT jobs and the women who fill them. The information from this last survey will be linked to the longitudinal second study so that correlations between these beliefs and later career outcomes can be determined.","title":"Information Technology Workforce - ITWF: Entry, Earnings Growth, and Retention in IT Careers: An Economic Study","awardID":"0120111","effectiveDate":"2001-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"1397","name":"CROSS-DIRECTORATE  ACTIV PROGR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":["506701","362119"],"PO":["564181"]},"64986":{"abstract":"This Scalable Enterprise Systems Phase II project will develop the Discrete Event System Specification (DEVS) Formal Framework for Scalable Enterprise Design and extend earlier-developed DEVS-based modeling and simulation environments to support several real world test cases. As the Internet expands toward 1 billion nodes forming a highly interconnected and computationally powerful medium, and companies increase specialization and horizontal layered organization, new complexity and dynamics are emerging. Scalability, the ability to avoid performance degradation and system breakdown as the scale of activity greatly increases, is one of the urgent global problems that needs to be addressed. This research will seek to enhance scalability at three inter-related levels of abstraction: the Enterprise Architecture level, the Information Technology Infrastructure level, and the Modeling and Simulation level. Earlier research developed a theoretical foundation for architecting a major responsibility of enterprise systems -- to ensure that the right information about the enterprise is available to decision makers at the right time. Having extended the DEVS formalism to express time-critical behaviors in enterprise data management, the researcher proposes to implement the extended DEVS functionality by suitably extending the distributed real-time execution environment previously developed in NSF-sponsored research. This environment will be tested by two diverse applications: a small scale but complete and real factory automation test bed and a large-scale web-hosting service for e-business. <br\/><br\/>The Integrated Manufacturing Technology Initiative (IMTI) sponsored by the primary governmental funding agencies (NIST, DOE, NSF, and DARPA) states that modeling and simulation are emerging as key technologies to support manufacturing in the 21st century. This research will attempt to fill in some of the gap between the current state of the art and the IMTI vision of the future. In this vision enterprise processes, equipment and systems are linked via a robust communications infrastructure that delivers the right information at the right time; and integrated enterprise management systems that ensure that decisions to be made in real-time and on the basis of enterprise-wide impact. Achieving scalability in M&S and IT infrastructure will enable a wide array of M&S studies and implementations, as well as supporting the scalability of the future M&S-based networked, extended and distributed enterprise systems envisioned by IMTI.","title":"Scalable Enterprise Systems Phase II: Discrete Event System Specification (DEVS) as a Formal Modeling and Simulation Framework for Scaleable Enterprise Design","awardID":"0122227","effectiveDate":"2001-09-01","expirationDate":"2004-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1465","name":"PRODUCTION SYSTEMS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"5376","name":"INNOVATION & ORG SCIENCES(IOS)"}}],"PIcoPI":["524966","547801"],"PO":["315316"]},"65987":{"abstract":"EIA-0126623<br\/>Salim Hariri<br\/>University of Arizona<br\/><br\/>The overall research goal of this proposal is to design, develop, evaluate and deploy Pragma, the next generation adaptive runtime infrastructure capable of reactively and proactively managing and optimizing application execution using current system and application state, predictive models for system behavior and application performance, and an agent based control network. The overarching motivation for this research is to enable very large-scale, dynamically adaptive scientific and engineering simulations on widely distributed and highly heterogeneous and dynamic execution environments such as the computational \"grid\". The design, development and evaluation of the proposed Pragma framework will be conducted in collaboration with the Astronomy Department at the University of Arizona in the context of a real-world astrophysical hydrodynamics simulation using adaptive mesh refinement and including multigroup flux-limited diffusion, self gravity, nuclear burning, and a complex equation of state.","title":"NGS: PRAGMA: A Proactive & Reactive Grid Application Management Infrastructure for the Next Generation Simulations","awardID":"0126623","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["561892"],"PO":["301532"]},"64777":{"abstract":"Meetings are essential and ongoing processes in almost every enterprise. To record meetings is to provide a history of human interactions. However, two central challenges remain: (1) how to make sense of the group dynamics in those meetings and (2) how to search through a history of those interactions to find the information one may want. This research aims to develop automatic information processing systems based on the metaphor of a \"meeting map\", a structured representation that supports the presentation of multiple views of a meeting at different scales. The project will focus on two broad map categories: content maps, portraying topics discussed and decisions made; and interaction maps, identifying the roles and relationships of the participants and the level of concurrence. Building content and interaction maps will involve automatic classification of information from topic changes and salience to disagreement\/consensus. These maps will be used for generating simple indicative summaries, and off-the-shelf visualization tools will be used for map presentation. The project will build on analyses of 100 hours of meetings. Evaluations will use objective recognition accuracies and expert assessments of automatic summaries. Meeting maps respect the diversity of information present in meeting scenarios, and provide effective support for human-to-human interactions.","title":"ITR\/PE+SY:Mapping Meetings: Language Technology to make Sense of Human Interaction","awardID":"0121396","effectiveDate":"2001-09-01","expirationDate":"2006-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7314","name":"ITR FOR NATIONAL PRIORITIES"}}],"PIcoPI":["562965","550775","438686","554699","387675"],"PO":["564456"]},"66724":{"abstract":"EIA-0130059<br\/>Animesh Ray<br\/>Keck Graduate Institute<br\/><br\/>Title: Causes of Robustness and Vulnerability in Real-world Networks: Lessons from molecular biology<br\/><br\/>Vulnerability of natural networks (such as the Internet, power supply grid, or molecular regulatory circuits of cells) to perturbations is an important area of study. Prior work has traditionally involved observations on static networks or on computer simulations, and has revealed certain general fundamental properties. Specifically, the study of one representative natural network by direct experimental manipulation should illuminate general properties of most networks. The molecular machinery regulating the synthesis of RNA molecules in the nucleus of budding yeast forms a natural network that can be experimentally perturbed, and their effects studied by transcriptional profiling on DNA microarrays. In this initial funding period, study of the responses of a sub-section (comprised of approximately 300 nodes) of this natural network as a function of precise perturbations in the form of gene knockout mutations. A queriable, static, database model of the network is being made, which is queried by simple attack plans, and responses are tested for consistency with experimental results. This interplay is allowing a proof-of-principle demonstration of this empirical approach to studying properties of complex networks. Insights obtained from these studies is forming the basis of more sophisticated investigation of complex network properties.","title":"Bio-QuBIC: Causes of Robustness and Vulnerability in Real-world Networks: Lessons from Molecular Biology","awardID":"0130059","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}}],"PIcoPI":["410581","559061","551355","560510"],"PO":["565223"]},"54998":{"abstract":"The goal of this collaborative research project involving Christos Faloutsos and Ngai Hang Chang at Carnegie Mellon (award 0083148) and Tara Madhyastha at U of Cal Santa Cruz (award 0083130) is to develop and apply statistical and datamining tools to analyze bursty time sequences, with emphasis on I\/O traffic optimization. The interdisciplinary team includes researchers in computer science, computer engineering and statistics, and industry collaborators. The approach has three parts: (1) advanced statistical tools using the ``ARFIMA'' method; (2) wavelets and the related ``80-20 law'' to model disk traffic; and (3) incorporation of these models<br\/>inside the so-called ``Active Disks'', with the goal to build self-tuning, adaptive disk subsystems.<br\/>The results will advance data mining and statistics as well as disk design. An easy-to-use toolkit \"T-REX\" will aid in I\/O and systems design, handling bursty traffic, and better buffering and prefetching. The theory behind the T-REX toolkit will be based on new data mining algorithms and statistical methods that model self-similar time sequences (like web and network traffic,<br\/>in addition to I\/O traffic). The research team has strong ties with database, data mining and disk manufacturing industrial groups, and this will aid in testing the research toolkit and its technology transfer. It can be expected that the T-REX system will significantly aid the design of disk sub-systems with beneficial impact on the storage industry.","title":"Collaborative Research: Data Mining Meets I\/O Performance Evaluation: Advanced Statistical Tools for Analyzing Bursty Traffic","awardID":"0083148","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"1269","name":"STATISTICS"}}],"PIcoPI":["548220",140602],"PO":["563751"]},"63589":{"abstract":"EIA-0115885<br\/>Diane J. Cook<br\/>University of Texas at Arlington<br\/><br\/>MRI: Instrumentation for Intelligent Agent and Wireless Computing Research <br\/><br\/>This is a proposal for equipment acquisition under the Major Research Instrumentation (MRI) program to support research and student training on intelligent agents in a mobile environment. The Wireless Intelligent Simulator Environment being established will integrate software agents, human agents, and robot agents, so that physically distributed interacting agents can perform a variety of tasks cooperatively or competitively.","title":"MRI: Instrumentation for Intelligent Agent and Wireless Computing Research","awardID":"0115885","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["564777","547675","550149",163585,"505936"],"PO":["557609"]},"64689":{"abstract":"This is a standard award to one of three institutions collaborating as partners on Thompson's project (0121084). No current system allows a person to naturally walk through a large-scale virtual environment. The availability of such a locomotion interface would have impacts on a broad range of applications, including education and training, design and prototyping, physical fitness, and rehabilitation; for some of these applications natural walking provides a level of realism not obtainable if movement through the simulated world is controlled by devices such as a joystick, while for others realistic walking is a fundamental requirement. Prototypes have been built for a variety of computer-controlled devices on which a person can walk, but there has been little investigation of the utility of such devices as interfaces to a virtual world and almost no study at all of the interactions of visual and biomechanical perceptual cues in such devices. This project addresses key open questions, the answers to which are needed if locomotion interfaces are to offer effective interaction between users and computer simulations. An effective locomotion interface must provide users with accurate visual and biomechanical sensations of walking; thus, a key objective of this work is to determine how to synergistically combine visual information generated by computer graphics with biomechanical information generated by devices that simulate walking on real surfaces. Thompson and his collaborators will investigates methods that allow more accurate walking in a locomotion interface while accurately conveying a sense of the spaces being walked through. Specific issues to be considered include how to facilitate the perception of speed and distance traveled, how to provide a compelling sense of turning when actual walking along a curved path is not possible, how to give a user the sense that he\/she is walking over a sloped surface, and more generally how to give a user a clear sense of the scale and structure of the spaces being walked through. The team's findings on these issues will be relevant across the spectrum of possible approaches to locomotion interfaces.","title":"ITR\/SY: Collaborative\/RUI Research on the Perceptual Aspects of Locomotion Interfaces","awardID":"0121044","effectiveDate":"2001-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["474337"],"PO":["317663"]},"66647":{"abstract":"No Abstract needed. Workshop in Fall 2001","title":"Fall Workshop on Computational Geometry (Fall 2001)","awardID":"0129631","effectiveDate":"2001-09-01","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["280545"],"PO":["179846"]},"64106":{"abstract":"The technology and business of wireless communications systems have madespectacular progress since the<br\/>first systems were introduced fifteen years ago. Currently proposed third generation (3G) systems offer roaming, higher capacity, and increased exibility for low bandwidth services, such as voice calls and messaging. While future wireless systems (fourth generation (4G) and higher) are envisioned to provide higher capacity, they are also expected to support heterogeneity in the following aspects: (i) physical environments (ranging from high-bandwidth low error-rate pico-cells to low-bandwidth high error-rate macro-cells); (ii) network architectures (cellular, peer-to-peer, or other hybrid network models); and (iii) applications (ranging from low-data rate non-real-time applications to high-data rate real-time applications). In this project, we will investigate several key elements that are necessary to realize a protocol stack for a mobile station in 4G wireless systems. The ultimate objective is to develop an adaptive protocol suite that would adapt itself to the different aspects of heterogeneity exhibited by the next generation wireless systems. In particular we willinvestigate the following problems:<br\/>1. Application Layer<br\/>Error-rate scalability: We propose an adaptive multiple description algorithm for error-rate scalability.<br\/>Data-rate scalability: We introduce an optimal dynamic rate shaping technique to be utilized in the case of<br\/>congestion or bandwidth variations.<br\/>Jointly optimal real-time video streaming system: We propose a real-time video streaming system integrates the proposed unequal error protection mechanism, the multiple description coding technique, and the error-concealment method.<br\/>2. Security<br\/>An adaptive and scalable security protocols: We propose to employ finite-field wavelets to develop novel and<br\/>innovative public key security techniques that address ubiquity, scalability, mobility, and usability.<br\/>We propose efficient security protocols for mobile devices with limited processing power.<br\/>3. Transport Layer<br\/>Heterogeneous Packet Flows: We proposetoinvestigate transport protocols that can support a much richer<br\/>set of semantics, adapting to the reliability semantics chosen by applications on a per-frame basis.<br\/>Heterogeneous Network Characteristics: We propose to build a single transport protocol that will adapt itself<br\/>to the characteristics of a variety of wireless network environments.<br\/>Heterogeneous Network Architectures: We propose to explore transport layer adaptivity to the underlying<br\/>network model (cellular, peer-to-peer, or hybrid).<br\/>4. Network Layer<br\/>Application Requirements: We will explore network layer constructs that enable heterogeneous applications<br\/>to implement custom network layer policies.<br\/>Heterogeneous Network Architectures: We will explore the use of novel state propagation schemes and virtual<br\/>backbone approaches to enhance transport layer performance and help in adapting to heterogeneous network<br\/>models.<br\/>5. Data Link Layer<br\/>Rate-compatible error control coding: We develop new types of rate-compatible convolutional codes using<br\/>finite-field wavelet transforms.<br\/> The protocol suite requires a new Protocol Suite Integration Plan. The project will consist of four phases. During the first phase we will design the details of all the proposed components\/protocols\/methods of the protocol suite. During the second phase we will assess their performance in a simulation testbed. During the third phase we will integrate the individual modules into the suite and finally in the fourth phase we willprototype the proposed protocol suite and we will assess its performance on a physical testbed.","title":"An Adaptive Protocol Suite for The Next Generation Wireless Internet","awardID":"0117840","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["562752","347935","485126","560261"],"PO":["292741"]},"56208":{"abstract":"Optical communication networks employing wavelength division multiplexing can support several<br\/>communication sessions using a limited number of wavelength channels. The employment ofwave-<br\/>length reuse in different parts of the network contributes to the increase in the number of sessions<br\/>that can be supported. As such, these networks can provide a means to serve those applica-<br\/>tions which individually or collectively require large amounts of bandwidth. An important class<br\/>of services with such property is the class of multicast, or multipoint traffic, which requires the<br\/>delivery of data from the source to a group of destinations. Although a few studies have addressed<br\/>packet-switched multicast services in broadcast-and-select optical networks, the topics of routing,<br\/>wavelength assignment, dimensioning, and performance of circuit-switched multicast services in<br\/>wavelength routing optical networks have received little attention.<br\/> This project deals with multicast services in optical networks, with and without wavelength<br\/>converters. Such applications can be served using wavelength routing networks. The project has<br\/>several objectives. First, we would like to develop multicast tree construction algorithms for optical<br\/>networks which take into account the optical network constraints into account, such as thepower<br\/>budget, wavelength collisions and wavelength continuity, aswell as the cost and type of splitters and<br\/>wavelength converters. Optimal network provisioning and dimensioning under multicast service,<br\/>given the traffic demands and cost constraints, is another objective. We also plan to investigate the<br\/>possibility of formulating a joint problem for the optimal provisioning, and the optimal wavelength<br\/>converter and splitter placement. It is also planned that routing, and wavelength selection algo-<br\/>rithms will be developed for multicast services in optical networks. It is also planned to study the<br\/>effect of these algorithms on the dimensioning and performance of the network. All this requires<br\/>construction of accurate analytical models for the evaluation of call blocking probabilities under<br\/>different routing and wavelength selection algorithms. As the efficient support of multicast traffic<br\/>requires the branching of the traffic at several points in the network, these models are expected to<br\/>be very involved, especially that several standard independence assumptions cannot be used in this<br\/>case. In addition to general performance models, bounds on performance will be established, which<br\/>will provide a guide to the provisioning and dimensioning of networks for multicast service. Such<br\/>bounds will be established through the identification of extreme network topologies which serve to<br\/>provide these bounds.<br\/> The results of this work are expected to advance the understanding of the behavior of optical<br\/>networks under futuristic, yet more involved, traffic conditions. At the same time, these results<br\/>will contribute to the design and dimensioning of such networks.","title":"Routing, Wavelength Assignment, Dimensioning and Performance of Optical Networks with Multicast Service","awardID":"0087746","effectiveDate":"2001-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["521840","417502"],"PO":["565090"]},"80540":{"abstract":"","title":"ITR\/SY: A High Performance Memory Manager for Multithreaded Applications","awardID":"0296131","effectiveDate":"2001-09-01","expirationDate":"2006-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1359","name":"RES EXP FOR TEACHERS(RET)-SITE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1674","name":"NANOSCALE: INTRDISCPL RESRCH T"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}}],"PIcoPI":[209728],"PO":["325495"]},"60740":{"abstract":"EIA-0103547<br\/>Patricia J. Teller<br\/>University of Texas<br\/><br\/>The goal of this project is to develop the tools needed for performance-directed integrated design and control of complex applications running on distributed computational systems. Its target computational systems are complex, incorporating the difficult heterogeneity, latency, and adaptive properties of computational grids. Its target applications are at the cutting edge of computational science: very large, complex applications with adaptive characteristics that do not allow their optimal system configurations or computational requirements to be estimated prior to run time. Each application will be viewed as a composition of components, with a formal, high fidelity model of performance to be designed for each component. The approach is to use model-based adaptive run-time control, based on these composed performance models, to control the execution of the application to meet specified performance goals. The control strategy will make real-time changes to parameters that modify the behavior of both application and computational platform.","title":"NGS: Collaborative Research: Performance-Driven Adaptive Software Design and Control","awardID":"0103547","effectiveDate":"2001-09-15","expirationDate":"2005-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["318770"],"PO":["301532"]},"61544":{"abstract":"Multicasting has become increasingly important for real-time applications since it is the inherent mode of<br\/>delivery in several of them, e.g. teleconferencing, audio and video broadcasting, etc. The Internet, however,<br\/>does not provide end-to-end bandwidth or delay guarantees for unicast or for multicast data. As a result, a<br\/>number of multiple scale encoding schemes for real-time voice and video transmission have been developed;<br\/>these schemes allow adaptation both to the available bandwidth and to the receiver capabilities by varying<br\/>the number of levels of the information stream and therefore the corresponding bit rates. Thus, bandwidth<br\/>and receiver adaptation of multi-level information streams, in multicast delivery in particular, is an issue<br\/>of prime importance for the successful, large-scale deployment of those real-time applications. We propose<br\/>to investigate and develop methods for bandwidth sharing and adaptation in the context of multicast-<br\/>based real-time applications. A set of fairness criteria based on which the performance of different schemes<br\/>can be quantified and compared is introduced. A methodology for finding bandwidth allocations that are<br\/>optimal or suboptimal with respect to the different criteria is proposed. Scalability with the network size,<br\/>amenability to distributed implementation in terms of required control information and speed of convergence<br\/>are adopted as prime criteria, in addition to optimality, in the evaluation of the different algorithms. We<br\/>propose an approach for the design of the algorithms that allows the trade-off between optimality with<br\/>respect to the performance objective and practicality with respect to the other attributes (i.e. scalability<br\/>etc.). A methodology for network control in multicasting in the case of unknown traffic and\/or network<br\/>conditions is proposed as well. It involves explicit back-pressure based congestion notification feedback and<br\/>dynamic per ow scheduling. Finally we propose a method for the design of congestion control policies<br\/>with the objective of maximizing an aggregate network utility. A relative comparison between the two<br\/>approaches (fairness based and aggregate utility maximization) is also proposed in order to be able to select<br\/>the most appropriate one in each case.","title":"Adaptive and Scalable Quality of Service Provisioning in Multirate Multicast Networks","awardID":"0106984","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":[158256,"517945"],"PO":["565090"]},"61324":{"abstract":"The gap between processor speed and main memory access speed<br\/>can cause processors to spend much of their time waiting on memory accesses.<br\/>As the gap has grown, this memory latency has become an<br\/>increasingly significant bottleneck in processor performance.<br\/>Existing cache designs have worked well to fill the gap,<br\/>but new cache designs are needed as the gap continues to grow.<br\/>A promising new class, restricted caches, includes<br\/>skew caches, assist caches, victim caches, and other multi-lateral caches.<br\/>Experiments have indicated that some restricted caches<br\/>offer significant potential for improvement over traditional<br\/>set-associative caches. They also have revealed some interesting<br\/>phenomenon that are not possible in traditional caches. For example,<br\/>skew caches seem to exhibit self-reorganization.<br\/>However, no theoretical explanation exists for this behavior or for<br\/>why these restricted caches perform well.<br\/><br\/>The investigators study the performance of distinct restricted cache<br\/>structures and algorithms for managing them.<br\/>The investigators first identify an underlying structural difference<br\/>between restricted caches and traditional fully-associative<br\/>caches: all cache lines are not identical. Specifically, in a<br\/>restricted cache, unlike in a traditional set-associative cache,<br\/>there exist pairs of memory blocks whose sets of legal cache lines<br\/>are not identical and have a non-empty intersection.<br\/>Using this insight, the investigators evaluate and<br\/>compare different cache structures using new techniques.<br\/>Most other analytical studies of caches focus only on the performance<br\/>of algorithms for a given cache structure and do not explicitly<br\/>compare the effectiveness of distinct cache structures. The<br\/>investigators also study the performance of various algorithms<br\/>for these cache structures using a variety of techniques such<br\/>as resource augmentation, standard competitive analysis,<br\/>and trace-based simulation. Their results indicate that traditional<br\/>cache management algorithms behave very differently on restricted<br\/>caches than they do on traditional set-associative caches.<br\/>For example, the least recently used (LRU) algorithm that is strongly<br\/>competitive for traditional caches is not competitive at all for<br\/>restricted caches unless explicit rearrangement of items in the<br\/>cache is allowed. Finally, the investigators construct a<br\/>trace warehouse to facilitate the comparison of distinct trace-based<br\/>simulation studies as well as to help new researchers learn this<br\/>this evaluation technique.","title":"Collaborative Research: Restricted Caches, An Experimental and TheoreticalStudy","awardID":"0105694","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":[157684],"PO":["279077"]},"64833":{"abstract":"EIA-0121568<br\/>Kwait, Paul G<br\/>University of Illinois Urbana-Champaign<br\/><br\/>ITR\/SY: Foundations of Solid-State Quantum Information Processing<br\/><br\/><br\/> Quantum Information Processing (QIP) lies at the forefront of revolutionary computing research, promising radically new powers to computation and communication, e.g., unconditionally secure quantum cryptography and quantum logic for greatly enhanced speed on certain computational problems. This project addresses the critical question of how to achieve a physical system capable of meeting the two most challenging requirements for building a quantum computer -- scalability, the fabrication and coupling of a large number of quantum bits (\"qubits\"), and quantum coherence, the control of noise and external coupling effects so that the exquisitely fragile quantum mechanical circuits will not be perturbed by unwanted influences.<br\/><br\/> An interdisciplinary research team at the University of Illinois at Urbana-Champaign is exploring a wide range of solid state systems based on the manipulation and measurement of magnetic moments to perform quantum logic operations. By studying the full range, from single spins to small clusters of spins (in quantum dots), to large current loops in superconductors, they are attempting to assess the relative merit of different techniques, and determine the physical size limits for magnetic systems acting as qubits. The ultimate goal is the physical realization of a small system for performing quantum logic operations. A key component is the integration of research and education via a highly interactive program involving undergraduates, graduate students, and postdoctoral investigators. This project is providing a crucial role for an explosive new field such as QIP, by providing general awareness of the issues involved and by training a pool of experienced researchers.","title":"ITR\/SY: Foundations of Solid-State Quantum Information Processing","awardID":"0121568","effectiveDate":"2001-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":[167434,"244065","474073","403560","515533"],"PO":["521045"]},"64723":{"abstract":"ITR\/AP: An Ensemble Approach to Data Assimilation in the Earth Sciences<br\/><br\/>New data sources are beginning to have a dramatic impact on our ability to understand the earth as an integrated system. Our prospects for dealing with the environmental issues of the 21st century -- climate change, population pressures on natural resources, and major modifications in global element cycles -- depend largely on this new information. However, our ability to process and interpret environmental data is not keeping pace with the dramatic increase in available information, especially information from airborne and orbital remote sensing platforms. If we are to realize the potential benefits of new sensing technologies we will need to develop intelligent environmental data assimilation procedures that are able to efficiently extract useful information about the earth from a diverse set of data sources. <br\/><br\/>Environmental data assimilation can be posed as a problem of estimating a large number of unobservable or highly uncertain variables (e.g. sea surface heights, atmospheric pressures, hydrologic fluxes, etc.) from a large number of related but noisy measurements (e.g. microwave radiances or backscatter detected by a satellite sensor). The estimation procedure relies on mathematical models that relate unknowns to measurements. Environmental estimation problems are challenging because the systems of interest: 1) are spatially distributed and highly variable over a wide range of space and time scales, 2) are difficult to describe with precision, 3) are often nonlinear, even chaotic, and 4) are often characterized by non-unique relationships between unknowns and measurements.<br\/><br\/>This project is concerned with very large problems (many measurements and many unknowns) which are not amenable to traditional data assimilation techniques but are of crucial interest to researchers in the earth sciences. An interdisciplinary team will develop a better understanding of the issues of dimensionality reduction and uncertainty propagation that are crucial to large-scale data assimilation. So-called ensemble methods provide a particularly informative way to identify these key features. A new generation of \"intelligent\" data assimilation methods will be developed that build on the understanding gained from the reduced problem. The applicability of these methods will be investigated on problems of broad interest in the earth sciences, including problems that 1) deal with coupled systems, 2) cut across traditional disciplines, and 3) work with remote sensing data sets.<br\/><br\/>This ITR project brings together acknowledged experts on environmental data assimilation. It is a group ITR project, rather than several individual projects, which cuts across earth science disciplines. The research will be coordinated with: 1) a seminar series, 2) joint supervision of Ph.D. students and post-doctoral researchers, 3) a Ph.D. mentoring program, 4) a selection of cross-cutting sample problems, and 5) co-authored publications.","title":"ITR\/AP: An Ensemble Approach to Data Assimilation in the Earth Sciences","awardID":"0121182","effectiveDate":"2001-09-15","expirationDate":"2008-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":[167042,"292367","406100","264297","559934"],"PO":["565272"]},"64844":{"abstract":"CR-0121633<br\/>ITR\/SY+SI: Language Technology for Trustless Software Dissemination<br\/>Karl Crary, Robert Harper, Peter Lee, Frank Pfenning<br\/><br\/>ABSTRACT:<br\/><br\/>The project investigates the theoretical and engineering basis for <br\/>the trustless dissemination of software in an untrusted environment. <br\/>To make this possible the project investigates machine-checkable<br\/>certificates of compliance with security, integrity, and privacy<br\/>requirements. Such checkable certificates allow participants to<br\/>verify the intrinsic properties of disseminated software, rather than<br\/>extrinsic properties such as the software's point of origin.<br\/><br\/>To obtain checkable certificates the project develops certifying<br\/>compilers that equip their object code with formal representations <br\/>of proofs of properties of the code. Specifically, the project<br\/>investigates the use of proof-carrying code, typed intermediate<br\/>languages, and typed assembly languages for this purpose. In each<br\/>case certificate verification is reduced to type-checking in a<br\/>suitable type system.<br\/><br\/>To demonstrate the utility of trustless software dissemination, the<br\/>project develops an infrastructure for building applications that<br\/>exploit the computational resources of a network of computers. The<br\/>infrastructure consists of a \"steward\" running on host computers that<br\/>accepts and verifies certified binaries before installing and<br\/>executing them, and certifying compilers that generate certified<br\/>binaries for distribution on the network.<br\/><br\/>The scope of the investigation includes the theory of specification<br\/>and certification, and the systems building required to implement<br\/>these ideas.","title":"ITR\/SY+SI: Language Technology for Trustless Software Dissemination","awardID":"0121633","effectiveDate":"2001-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["424178","339843","339844","485877"],"PO":["564388"]},"63645":{"abstract":"EIA-0116050<br\/>Michael A. McRobbie<br\/>Indiana University - Bloomington<br\/><br\/>MRI: Creation of the AVIDD Data Facility: a Distributed Facility for Managing, Analyzing, and Visualizing Instrument-Driven Data <br\/><br\/>This is a proposal for equipment acquisition under the Major Research Instrumentation (MRI) program to support research and student training across a broad range of instrument-driven data-intensive science areas. The proposed distributed facility for managing, analyzing, and visualizing instrument-driven data would address the data life cycle consisting of data capture and remote data reduction; high speed data transfer; real time data analysis and processing; data storage; data retreival; data analysis and postprocessing; data visualization; and the use of remote data stores. Among the research projects enhanced and enabled by the proposed facility are both computer science and applications area projects, for example work on end-to-end real time data management for remote control and use of beam-line systems by X-ray crystallographers","title":"MRI: Creation of the AVIDD Data Facility: A Distributed Facility for Managing, Analyzing and Visualizing Instrument-Driven Data","awardID":"0116050","effectiveDate":"2001-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["511575","290799","283428","285595"],"PO":["557609"]},"61225":{"abstract":"The proposal deals with some new classes of codes applicable to computer and VLSI system. New design methods for balanced codes, where each codeword contains equal number of 1's and 0's, and low weight codes are investigated. These codes find broad applications - reducing noise and conserving power in VLSI systems, maintaining data integrity in write-once memories, obtaining delay insensitive communications in asynchronous systems, data encoding in fiber optics, etc. New classes of higher radix and binary Gray codes are also investigated. In Gray code sequence, two consecutive codewords differ in one digit position by 1. Gray codes find applications in wide areas - analog to digital converters, data compression, graphics and image processing, hashing, efficient combinatorial algorithm design, processor allocation in the hypercube, solving puzzles such as towers of Hanoi, etc. Our goal is to find new methods for designing these codes. Some preliminary results and the future research efforts related to these topics are described.","title":"Some Coding Techniques for VLSI and Computer Systems","awardID":"0105204","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["486183"],"PO":["325495"]},"64866":{"abstract":"EIA-0121680<br\/>Warnow, Tandy J<br\/>University of Texas at Austin<br\/><br\/>Collaborative Research: ITR\/AP: Reconstructing Complex Evolutionary<br\/><br\/><br\/>Reconstruction of the evolutionary history of a group of organisms has changed the face of biology and is being used increasingly in drug discovery, epidemiology, and genetic engineering. Unfortunately, such reconstructions typically involve solving difficult optimization problems, so that even moderately large datasets can require months to years of computation. In addition, almost all evolutionary reconstructions presently assume that the historical pattern is one of strict divergence that can be represented by a binary tree. This assumption is frequently violated, especially by plants which often hybridize readily and thus produce networks of relationships.<br\/><br\/>This project brings together computer scientists and biologists from two institutions to develop new models and algorithms to address these two problems. Successful completion of this project will have an enormous impact by providing tools for reconstructing phylogenies of large datasets, and the first tools for inferring network models of evolution appropriate to hybridizing speciation. Such network models will alter how biologists think about speciation, while the development of methods for large-scale analyses will strongly benefit medical and pharmaceutical practice. <br\/>Information technology will be advanced in fundamental ways as well, as the project will demonstrate how algorithm design and high-performance algorithm engineering can jointly solve very difficult discrete optimization problems.","title":"Collaborative Research: ITR\/AP Reconstructing Complex Evolutionary Histories","awardID":"0121680","effectiveDate":"2001-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["474594","456506","546362","473862","473863"],"PO":["565136"]},"64756":{"abstract":"EIA-0121326<br\/>Borning, Alan<br\/>University of Washington<br\/><br\/>ITR\/PE: Interaction and Participation in Integrated Urban Land Use, Transportation, and Environmental Modeling<br\/><br\/>Patterns of land use and transportation play a critical role in determining the economic vitality, livability, and sustainability of urban areas. Transportation interacts strongly with land use: different kinds of transportation systems induce different patterns of land use, while at the same time, different kinds of land use induce demands for different kinds of transportation systems. Both have significant environmental effects. This integrated research program will support the construction and deployment of sophisticated models of land use, transportation, and environmental impact. The goal is to provide tools for stakeholders, such as urban planners, government staff, and citizens' groups, to help predict future patterns of urban development under different possible scenarios over periods of twenty or more years, allowing them to make more informed choices. Anticipated scientific advances include: in human-computer interaction, more effective ways of understanding the results from and interacting with complex simulations, and ways of linking stakeholder values with design choices in simulations and their interfaces; in graphics, capabilities for producing simulated street-level animations of urban environments from a policy-driven simulation; and in software engineering, new software structures that allow us to design, integrate, and evolve complex and diverse urban submodels.","title":"ITR\/PE: Interaction and Participation in Integrated Land Use, Transportation, and Environmental Modeling","awardID":"0121326","effectiveDate":"2001-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["438603","542095","549589","450771","440155"],"PO":["371077"]},"61247":{"abstract":"The gap between processor speed and main memory access speed<br\/>can cause processors to spend much of their time waiting on memory accesses.<br\/>As the gap has grown, this memory latency has become an<br\/>increasingly significant bottleneck in processor performance.<br\/>Existing cache designs have worked well to fill the gap,<br\/>but new cache designs are needed as the gap continues to grow.<br\/>A promising new class, restricted caches, includes<br\/>skew caches, assist caches, victim caches, and other multi-lateral caches.<br\/>Experiments have indicated that some restricted caches<br\/>offer significant potential for improvement over traditional<br\/>set-associative caches. They also have revealed some interesting<br\/>phenomenon that are not possible in traditional caches. For example,<br\/>skew caches seem to exhibit self-reorganization.<br\/>However, no theoretical explanation exists for this behavior or for<br\/>why these restricted caches perform well.<br\/><br\/>The investigators study the performance of distinct restricted cache<br\/>structures and algorithms for managing them.<br\/>The investigators first identify an underlying structural difference<br\/>between restricted caches and traditional fully-associative<br\/>caches: all cache lines are not identical. Specifically, in a<br\/>restricted cache, unlike in a traditional set-associative cache,<br\/>there exist pairs of memory blocks whose sets of legal cache lines<br\/>are not identical and have a non-empty intersection.<br\/>Using this insight, the investigators evaluate and<br\/>compare different cache structures using new techniques.<br\/>Most other analytical studies of caches focus only on the performance<br\/>of algorithms for a given cache structure and do not explicitly<br\/>compare the effectiveness of distinct cache structures. The<br\/>investigators also study the performance of various algorithms<br\/>for these cache structures using a variety of techniques such<br\/>as resource augmentation, standard competitive analysis,<br\/>and trace-based simulation. Their results indicate that traditional<br\/>cache management algorithms behave very differently on restricted<br\/>caches than they do on traditional set-associative caches.<br\/>For example, the least recently used (LRU) algorithm that is strongly<br\/>competitive for traditional caches is not competitive at all for<br\/>restricted caches unless explicit rearrangement of items in the<br\/>cache is allowed. Finally, the investigators construct a<br\/>trace warehouse to facilitate the comparison of distinct trace-based<br\/>simulation studies as well as to help new researchers learn this<br\/>this evaluation technique.","title":"Collaborative Research: Restricted Caches, An Experimental and Theoretical Study","awardID":"0105283","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["562295",157507],"PO":["499399"]},"66967":{"abstract":"A workshop on \"Embedded Software\" was held October 8-10, 2001, in Tahoe City, California. The purpose of the workshop was to incubate a research community in embedded software. There were 35 invited presentations at the workshop, with national and international speakers from both academia and industry. The presentations covered all aspects of embedded software, including operating systems and middleware, programming languages and compilers, modeling and validation, software engineering and programming methodologies, scheduling and execution time analysis, communication protocols and fault tolerance.","title":"Workshop on Embedded Software","awardID":"0131213","effectiveDate":"2001-09-01","expirationDate":"2002-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["226709"],"PO":["187585"]},"63216":{"abstract":"The proposed research is aimed at constructing an image representation that improves performances of current image compression algorithms and organizes the information in a form suitable for fast patter discrimination and search algorithms. The approach relies on recently discovered bandlelet orthogonal bases, which can be adapted to curves and efficiently represent image profiles. The work will also build on and incorporate previous work in such areas as graphs matching. Developing new techniques in this area can greatly improve the efficiency of future image search engines.","title":"ITR\/SY (CISE) Geometrical Image Representation","awardID":"0114391","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":[162458,"170917"],"PO":["564456"]},"64679":{"abstract":"This is a standard award to one of three institutions collaborating as partners on Thompson's project (0121084). No current system allows a person to naturally walk through a large-scale virtual environment. The availability of such a locomotion interface would have impacts on a broad range of applications, including education and training, design and prototyping, physical fitness, and rehabilitation; for some of these applications natural walking provides a level of realism not obtainable if movement through the simulated world is controlled by devices such as a joystick, while for others realistic walking is a fundamental requirement. Prototypes have been built for a variety of computer-controlled devices on which a person can walk, but there has been little investigation of the utility of such devices as interfaces to a virtual world and almost no study at all of the interactions of visual and biomechanical perceptual cues in such devices. This project addresses key open questions, the answers to which are needed if locomotion interfaces are to offer effective interaction between users and computer simulations. An effective locomotion interface must provide users with accurate visual and biomechanical sensations of walking; thus, a key objective of this work is to determine how to synergistically combine visual information generated by computer graphics with biomechanical information generated by devices that simulate walking on real surfaces. Thompson and his collaborators will investigates methods that allow more accurate walking in a locomotion interface while accurately conveying a sense of the spaces being walked through. Specific issues to be considered include how to facilitate the perception of speed and distance traveled, how to provide a compelling sense of turning when actual walking along a curved path is not possible, how to give a user the sense that he\/she is walking over a sloped surface, and more generally how to give a user a clear sense of the scale and structure of the spaces being walked through. The team's findings on these issues will be relevant across the spectrum of possible approaches to locomotion interfaces.","title":"ITR\/SY: Collaborative\/RUI Research on the Perceptual Aspects of Locomotion Interfaces","awardID":"0120984","effectiveDate":"2001-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":[166921],"PO":["317663"]},"63117":{"abstract":"This project will investigate the architecture and design of a single-chip<br\/>parallel computer system. As technology continues to improve and transistor<br\/>sizes decrease, the latency of on-chip interconnect wires will have a<br\/>greater impact on the performance of computer systems. In the future,<br\/>computer designers will need to develop architectures that avoid the use of<br\/>long interconnect wires in order to reduce the effect of this latency. One<br\/>such approach would be to include a number of small, simple processors<br\/>together on a single chip, forming a single-chip parallel computer. This<br\/>would reduce the effect of the latency because the length of the<br\/>interconnect wires would depend on the size and complexity of the<br\/>individual processors, not the size of the entire system. By keeping the<br\/>processors simple, long interconnect wires will not be necessary. The<br\/>challenge to designing such a system is determining the features that the<br\/>architecture must include. This research project will investigate<br\/>architectural features that provide low-overhead support for parallel<br\/>programs, applying them to the design of the SCMP (Single-Chip<br\/>Message-Passing) parallel computer. Through the extensive use of<br\/>simulation, the design and performance of the SCMP system will be analyzed<br\/>and compared to other computer architectures.","title":"ITR\/SY: SCMP -- A Single-Chip Parallel Computer","awardID":"0113948","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["472308"],"PO":["325495"]},"66879":{"abstract":"EIA-0130857 <br\/>Elise deDoncker<br\/>Western Michigan University<br\/><br\/>CISE Research Resources: Information Visualization and Incremental Knowledge Discovery in a Cluster Computing Environment<br\/><br\/>This proposal seeks funding to enhance a 64-node PC cluster at Western Michigan University, obtained in part on a previous National Science Foundation grant and university funding. Improving the cluster will give hardware support for on-going research and education on parallel and distributed algorithm design and development. Although the cluster is currently used for various research efforts by different groups in the university, this proposal focuses on two of these projects: parallel integration and distributed incremental knowledge discovery. <br\/><br\/>The requested infrastructure includes a networking upgrade to support the current communication intensive (high bandwidth\/low latency) projects. These include the tailoring of load balancing methods underlying the migration of regions in adaptive partitioning. The system will also provide a better environment for our study of the scalability of task partitioning methods in numerical integration and other areas. The proposed project on the development of methods for incremental knowledge discovery from large databases will further be supported by the visualization components of the infrastructure. This effort includes 3D interactive visual exploration of large relational data sets. The techniques will be incorporated in a systematic way into a software system for incremental knowledge discovery, and evaluated for effectiveness and suitability in different scenarios.","title":"CISE Research Resources: Information Visualization and Incremental Knowledge Discovery in a Cluster Computing Environment","awardID":"0130857","effectiveDate":"2001-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["490801","490803",173391,"514674"],"PO":["557609"]},"58915":{"abstract":"This proposal studies the evolution and subsequent maintenance behavior of code in two very large open-source projects, Linux and GCC free software, to provide insight into the software engineering aspects of open-source software. Focusing on the coupling between components and how this coupling changes over time, successive versions of Linux and GCC are examined, analyzing the change from version to version of each product. The coupling between two units of a software product, a measure of the degree of interaction between those units, is used as a measure of maintainability. Tools are built to compute these changes in coupling, and the output from these tools will be subjected to statistical analysis. The research sheds light on the importance in software maintenance of the skill of the individual software engineer and ameliorates the lack of data as to the effectiveness of \"open software\" development as compared to commercial software development.","title":"Repeated Maintenance of Open-Source Software","awardID":"0097056","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":[151306,151307],"PO":["564388"]},"57705":{"abstract":"EIA-0093426<br\/>Vikram S. Adve<br\/>Univ. of Illinois<br\/><br\/>CAREERS: Techniques and Application of Dynamic Compilation<br\/><br\/>Compiler-based program optimization is fundamentally important for current and future computing systems. Static optimization, the predominant approach, will always be essential but is becoming increasingly insufficient for many reasons. These include the popularity of high-level, object-oriented languages, the proliferation of portable, interpreted languages like Java, and the increasing complexity of processor architectures. All of these trends imply that dynamic compilation (including runtime program analysis, runtime optimization, and runtime code generation) is likely to be extremely important technology for achieving high performance in current and future application.<br\/><br\/>The infrastructure developed through this work will support a broad career plan that integrates teaching and research. The software will contribute to the PI's educational efforts through class projects in introductory and advanced classes and through recruiting undergraduates for these research efforts.","title":"NGS: CAREERS: Techniques and Applications of Dynamic Compilation","awardID":"0093426","effectiveDate":"2001-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["542046"],"PO":["551712"]},"65339":{"abstract":"This proposal is for partial support of the conference, \"New Directions in Cluster Supercomputing\", being held June 12-14, 2001 in New York City. The conference will examine the impact of low-cost distributed \"supercomputing\" in areas of science and technology and other application areas. A goal of the event is to stimulate the exchange of ideas and examine general approaches and techniques, and encourage increased interaction among members of the systems, algorithms and natural science applications communities.<br\/>The conference will run concurrently with the Museum's first major public exhibition on the human genome, \"The Genomic Revolution.\" Support for the conference is also being provided by NASA and public sector technology corporations..","title":"New Directions in Cluster Computing: A Conference at the American Museum of Natural History \"New Directions in Cluster Supercomputing\"","awardID":"0123975","effectiveDate":"2001-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6857","name":"DIGITAL LIBRARIES AND ARCHIVES"}}],"PIcoPI":["423537","503756"],"PO":["433760"]},"64019":{"abstract":"The topic of the project is development of a framework for robust active vision, with the goal of obtaining systems capable of performing satisfactorily in the presence of uncertainty, such as due to poor calibration, noise, or a changing environment. The work will be complemented by a comprehensive experimental validation and performance characterization.","title":"Robust Active Vision Systems","awardID":"0117387","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["549740","549739"],"PO":["317663"]},"57518":{"abstract":"The goal of this project is to develop a unified framework for<br\/>developing fault-tolerant systems; this unified framework will provide<br\/>the structural continuity to developers of fault-tolerant systems<br\/>while they perform several tasks such as design, synthesis, testing,<br\/>verification, and refinement. The unified framework will be based on<br\/>the use of two fault-tolerance components, namely detectors and<br\/>correctors. Dr. Kulkarni has identified these two components as being<br\/>necessary and sufficient for adding fault-tolerance to a rich class of<br\/>systems. The use of detectors and correctors will permit efficient<br\/>implementation as the knowledge of application-specification is used<br\/>in computing the specification of the required components. Also, by<br\/>permitting the reusability of fault-tolerance components, the<br\/>framework will help in reducing the development cycle for a system.<br\/>To simplify the reuse of the fault-tolerance components, Dr. Kulkarni<br\/>will develop a component-template language to specify templates<br\/>--which will be instantiated by the developers of fault-tolerant<br\/>systems-- for commonly used components. Dr. Kulkarni will also<br\/>develop heuristics to reduce the complexity of automating the addition<br\/>of fault-tolerance. Finally, these heuristics and the<br\/>component-templates will be used to develop a tool for automating the<br\/>addition of fault-tolerance.","title":"CAREER: Unified Component-Based Framework for Fault-Tolerance","awardID":"0092724","effectiveDate":"2001-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["553603"],"PO":["543507"]},"60730":{"abstract":"Abstract<br\/>CTS-0103473<br\/>Angela Belcher, University of Texas Austin<br\/><br\/>This proposal was received in response to Nanoscale Science and Engineering (NSE) solicitation, NSF-00119, in the category Nanoscale Interdisciplinary Research Teams (NIRT). <br\/><br\/>Biological systems efficiently and accurately assemble nanoscale building blocks into complex<br\/>and functionally sophisticated structures with high perfection, controlled size and compositional<br\/>uniformity. The self-organizing processes found in these systems rely largely on non-covalent interactions that enable elegant rearrangement between usable architectural forms and self-correction. The research will take advantage of the atomic composition and plane specific recognition that a biomolecule can exhibit for an inorganic phase, and the nanostructural control and regularity that biomolecules typically impose on crystal phases and crystallographic orientations to control nanostructure formation. Furthermore, RNA templates will be used to direct the parallel self-assembly of multiple electronic components with high precision. Using combinatorial peptide evolution, peptide sequences will be identified that select for and bind to specific nanocrystal and nanowire substrates, such as magnetic and semiconductor quantum dots and silicon nanowires synthesized in solution. The peptides provide recognition specificity between the biological molecules and the inorganic substrate. The peptides couple the inorganic electronic \"building blocks\" to the biological machinery that directs the architectural \"blueprints\" for organization. In essence, genetically encoding biological-electronic interactions are selecting the mRNA sequences that code for specific amino acid sequences, but beyond that, specific secondary and ultimately tertiary structures can be achieved; thus, leading to supermolecular architectures. <br\/><br\/>An interdisciplinary effort will include synthetic chemistry, electrical and materials engineering, and molecular biology, which targets the development of specific recognition chemistries between biological and inorganic substrates for the creation of nanostructured materials and devices with novel applications. The proposed project offers highly interdisciplinary educational and research opportunities for graduate students.","title":"NIRT: Biologically Based Assemblies of Electronic Materials at the Nanoscale; Improving on Nature","awardID":"0103473","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0307","name":"Division of MATERIALS RESEARCH","abbr":"DMR"},"pgm":{"id":"1762","name":"SOLID STATE & MATERIALS CHEMIS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1402","name":"BIOCHEMICAL & BIOMASS ENG"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1415","name":"PARTICULATE &MULTIPHASE PROCES"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1517","name":"ELECT, PHOTONICS, & MAG DEVICE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1674","name":"NANOSCALE: INTRDISCPL RESRCH T"}}],"PIcoPI":["469100","563971","474722"],"PO":["278176"]},"62986":{"abstract":"Proposal Number: ITR Proposal 0113193<br\/><br\/>Title: Implementing Modular Program Analysis via Intersection<br\/>and Union Types.<br\/><br\/>PI: Assaf J. Kfoury<br\/><br\/>The proposed research will investigate real-world relevance of a <br\/>new framework for modular program-analysis, which uses \"intersection\" <br\/>and \"union\" types. The starting point of this investigation is a <br\/>recently designed polymorphic type system, called System I, for a <br\/>foundational functional language, the lambda-calculus. The chief <br\/>feature of System I is the use of \"intersection\" types together <br\/>with the new technology of \"expansion variables\", which allow <br\/>System I to satisfy a substitution-based principal-typings property. <br\/>Although fully modular, the resulting program analysis is now <br\/>restricted to a foundational language (the lambda-calculus) missing <br\/>many standard high-level programming features such as conditionals,<br\/>recursive definitions, exceptions, assignments, input\/output, etc.<br\/>Considerable work is necessary in order to turn System I into a <br\/>type system for a full-fledged programming language such as Scheme <br\/>(now considered to be the initial target language of proposed research).<br\/><br\/>The proposed research is largely engineering work, aimed at producing <br\/>an efficient prototype implementation, based on appropriate extensions <br\/>of System I. The implementation will be evaluated --- or re-designed <br\/>in parts --- by the extent to which it produces demonstrably better <br\/>results in handling large software systems (enforcing larger classes <br\/>of safety properties, statically detecting and ruling out larger classes <br\/>of run-time errors).","title":"ITR\/SY (CCR): Implementing Modular Program Analysis via Intersection and Union Types","awardID":"0113193","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["526817",161738],"PO":["564388"]},"60566":{"abstract":"EIA-0102539<br\/>Yann-Hang Lee<br\/>Arizona State University<br\/><br\/>Adaptive Performance and Power Management for Real-Time Systems<br\/><br\/>This research will enable real-time computer systems to monitor and automatically adapt their power usage to specified fault-tolerance and performance requirements, prevailing workload, and current and projected energy\/power constraints.<br\/><br\/>Many systems, which are power-constrained, do not always have a strict limit on their power consumption. Instead, they have periods of time during which energy supply is very limited, and should be used sparingly, while at other times, the power available is adequate and the system is allowed to exploit all its resources to deliver maximum performability. While there has been a great deal of research in developing circuits and design techniques to build low-power devices, there is very little reported on techniques to adjust power consumption on-the-fly to adapt to changing levels of workload and energy\/power availability. There is the need for an integrated approach, ranging from the hardware operation (using voltage-clock scaling or a sleep mode) to the application level. Our preliminary investigations have shown that such an integrated approach, exploiting the synergy between these various layers, is far more effective than single-layer approaches adopted incrementally.","title":"NGS: Collaborative Research: Adaptive Performance and Power Management for Real-Time Systems","awardID":"0102539","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["171437"],"PO":["301532"]},"64823":{"abstract":"This research project is developing a new generation of formal verification tools that can be integrated into design environments for the complex, high-assurance embedded and autonomous systems of today and of the future. Such systems are increasingly distributed, complex, and dynamic; they must operate with a high degree of autonomy and survivability in diverse and unpredictable environments. This project will focus on the development of new verification methods and tools to provide a rigorous means for checking the integrity and correctness of designs for these systems before they are deployed. The project has two broad research thrusts: <br\/><br\/>1. Verifying System Integrity. System integrity refers to correctness with respect to the interactions among the distributed software and hardware components. Systems must satisfy synchronization, resource, and real-time constraints imposed by the implementation architecture and application requirements. This project will extend automated verification methods that have been successful in hardware and protocol applications to their use with embedded and autonomous systems. <br\/>2. Modeling the Environment. Embedded and autonomous systems must interact in complex ways with physical systems and adverse environments. It is thus essential to capture correctly and effectively the continuous dynamics, feedback loops, and unpredictable features of the environment in the models used for formal verification. This project will draw on recent developments in hybrid system verification to integrate continuous state dynamics with discrete-state models used in formal verification.","title":"ITR\/SY: Verification Tools for Autonomous and Embedded Systems","awardID":"0121547","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["475099","530562","553671"],"PO":["561889"]},"60599":{"abstract":"EIA-0102696<br\/>Israe Koren<br\/>University of Massachusetts<br\/><br\/>Adaptive Performance and Power Management for Real-Time Systems<br\/><br\/>This research will enable real-time computer systems to monitor and automatically adapt their power usage to specified fault-tolerance and performance requirements, prevailing workload, and current and projected energy\/power constraints.<br\/><br\/>Many systems, which are power-constrained, do not always have a strict limit on their power consumption. Instead, they have periods of time during which energy supply is very limited, and should be used sparingly, while at other times, the power available is adequate and the system is allowed to exploit all its resources to deliver maximum performability. While there has been a great deal of research in developing circuits and design techniques to build low-power devices, there is very little reported on techniques to adjust power consumption on-the-fly to adapt to changing levels of workload and energy\/power availability. There is the need for an integrated approach, ranging from the hardware operation (using voltage-clock scaling or a sleep mode) to the application level. Our preliminary investigations have shown that such an integrated approach, exploiting the synergy between these various layers, is far more effective than single-layer approaches adopted incrementally.","title":"NGS: Collaborative Research: Adaptive Performance and Power Management for Real-Time Systems","awardID":"0102696","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["553614","553615"],"PO":["301532"]},"64834":{"abstract":"As mobile computing becomes more pervasive, users enjoy increased flexibility in terms of where and when they record, retrieve, and transmit information; at the same time, the conditions under which these devices are used are becoming more variable, less predictable, and in many situations less hospitable. With increasing frequency, computers are being used when lighting is poor, noise is unpredictable, or when the user is on the move (e.g., walking, driving a vehicle). In addition, mobile devices often cause users to interrupt an ongoing activity in order to perform secondary computer-based tasks: examples include individuals replying to e-mails during meetings, doctors reviewing operating room schedules while interacting with patients, and individuals retrieving directions from their in-vehicle navigation system while driving. The goal of this research is to address the issues involved in developing effective computer systems for individuals experiencing such situationally-induced impairments (SII). Like disability-induced impairments (DII), SII exist when the physical, cognitive, or perceptual demands placed on the user exceed their abilities. Unlike DII, SII are temporary, resulting from the environment in which the work is being performed or the tasks in which the user is engaged. Through this research, the PI and his team will develop new techniques for identifying and documenting the factors that contribute to SII, will identify methods for developing solutions that address the temporary and dynamic nature of SII, and will compare the interaction strategies of individuals experiencing SII to those of individuals with comparable DII.","title":"ITR\/PE: Universal access for situationally induced impairments: Modeling, prototyping, and evaluation","awardID":"0121570","effectiveDate":"2001-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["333704","466602","472085"],"PO":["565227"]},"64735":{"abstract":"e are proposing to develop computational tools for researchers<br\/>and students to model, visualize, and analyze historic and ancient<br\/>sites. This proposal addresses four major scientific components<br\/>to support this research. First, we are proposing new methods<br\/>of creating complex, 3-D, photorealistic models of large sites.<br\/>This includes a mobile robot sensing system that can be used as<br\/>an intelligent sensing device over a large scale. Second, we are<br\/>proposing to develop new methods to image below-ground data accurately<br\/>and efficiently. These methods are especially suited to modeling<br\/>the wealth of subsurface information at archaeological sites.<br\/>Third, we will be developing new database technology to catalog<br\/>and access a site's structures, artifacts, objects, and historical<br\/>references. This will significantly improve a user's ability to<br\/>query and analyze a site's information. Fourth, we have created<br\/>a wearable augmented reality system for presenting georegistered<br\/>information to mobile users, using overlaid graphics and sound.<br\/>We will extend this system to create a new class of information<br\/>visualization systems that integrate 3-D above- and below-ground<br\/>models, 2-D images, text and other web-based resources to annotate<br\/>the physical environment We will apply this system to support<br\/>scientists in the field, as well to allow on-site and remote tours<br\/>of historic and ancient sites. The research will utilize a local<br\/>testbed, the Cathedral of St. John the Divine in New York City,<br\/>and a unique and important archaeological excavation at the Dakhleh<br\/>Oasis in Egypt. The project will attract students and the public<br\/>to the study of world heritage; provide an exceptional opportunity<br\/>for active learning; and develop our ability to explore, analyze,<br\/>critically evaluate and interpret material culture within historical<br\/>contexts. The challenge is to bring the on-site experiences that<br\/>develop these skills to the classroom and the public in general.<br\/>Through critical inquiry and a variety of techniques, teachers<br\/>and students can reconstruct examples of material culture to develop<br\/>a complex understanding of the past. In this way, we can resist<br\/>the temptation to replicate with new technologies what we have<br\/>done successfully with other means and instead expand the possibilities<br\/>for learning. Through learning in context, this project will bring<br\/>together the primary sources of various fields and draw the social<br\/>sciences out of the classroom into the historical milieu. This<br\/>project will hopefully redefine the relationships among technology,<br\/>faculty research and curriculum content. Most important, it will<br\/>disseminate this information to as wide an audience as possible.","title":"ITR\/AP+IM: Computational Tools for Modeling, Visualizing and Analyzing Historic and Archaeological Sites","awardID":"0121239","effectiveDate":"2001-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["518026","531167","530199",167086,167087],"PO":["433760"]},"66803":{"abstract":"This proposal will bring together three specific, recent advances to study the behavior of hybrid systems, most notably those systems for which the traditional algorithmic methods fail because the reachability and omega-language problems are undecidable. The tools that will be used include:<br\/><br\/>1. The recent development of a model for the probabilistic process algebra PCSP in which the expected laws for both nondeterministic choice and for probabilistic choice operators hold,<br\/>2. The recent development of a quantified m-calculus and associated quantified temporal logic for reasoning about finite state systems that support both nondeterministic choice and probabilistic choice, and<br\/>3. Recent results about the expressibility of simple measures on locally compact spaces - in particular, the fact that any probability measure on such a space is the directed supremum of simple measures.<br\/><br\/>These results tie together to provide an interesting and novel approach to modeling hybrid systems.","title":"Probabilistic Analysis of Hybrid Systems","awardID":"0130550","effectiveDate":"2001-09-01","expirationDate":"2002-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["536741"],"PO":["564388"]},"64746":{"abstract":"Computer power has increased dramatically over the past decade and has allowed computational fluid dynamics (CFD) researchers to more accurately simulate many types of complex flow. These simulations have enabled great leaps forward in the design and safety of ships, airplanes, automobiles, and other vehicles. However, this new power has also yielded terabytes of data, and CFD researchers now face a very difficult task in trying to find, extract, and analyze important flow features (e.g., time varying vortices, shock waves) buried within these monstrous datasets. Unlike the explosive growth in computer power, visualization tools for very large datasets have evolved modestly and cannot yet help with these tasks significantly. In particular, since detailed visualization of such large datasets is impractical, CFD researchers must work at a very cumbersome, low level to dice their datasets into workable pieces.<br\/><br\/>CFD researchers desperately need new techniques that simplify and automate the iterative process of finding the appropriate portion of their data set. They need a system that will allow the user to articulate appropriate types of features of interest, provide a compact representation of those features, and effectively visualize the feature information locally. The system will have to overcome the challenges of loading a sufficient portion of the data set over a network connection into a desktop machine, mapping the entire data set to a visual representation, and rendering the results at interactive rates.<br\/><br\/>This project will attack these CFD visualization problems by developing techniques for creating and using a procedural abstraction for a dataset. The major research objectives are to:<br\/>1. Detect features (e.g. shocks) in complex flows using topological operators.<br\/>2. Characterize the data relative to these features using a procedural representation consisting of implicit models and free-form deformations.<br\/>3. Adapt the procedural representation to the appropriate level of detail using multi-resolution techniques.<br\/>4. Encapsulate domain-specific knowledge as metadata to explore these extremely large datasets.<br\/>5. Visualize the data directly from the procedural representation.<br\/>6. Verify the accuracy of the procedural representation by tracking approximation error.<br\/>7. Apply these techniques to the large-scale computational flow simulation problems currently studied at Stanford and Mississippi State University. <br\/>The resulting system will allow CFD researchers to work more effectively by interactively exploring their data to pinpoint the features of interest. Moreover, the results of this project will provide solutions not only for CFD researchers, but also for a wide variety of other visualization challenges and applications. The project's main goal is to develop techniques that allow visualization exploration, feature detection, extraction, and analysis at a higher, more effective level through the use of procedural data abstraction and representation.","title":"ITR\/AP+IM: Procedural Representation and Visualization Enabling Personalized Computational Fluid Dynamics","awardID":"0121288","effectiveDate":"2001-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["517378","499748","507476","403203",167135],"PO":["565272"]},"65604":{"abstract":"This proposal requests funding to support the 2001 ACM Symposium on Mobile Ad Hoc Networking and Computing (MobiHoc). The symposium will be held October 4-5, 2001 in Long Beach, California.","title":"2001 ACM MobiHoc Symposium Support","awardID":"0125444","effectiveDate":"2001-09-15","expirationDate":"2002-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["521384"],"PO":["234222"]},"64757":{"abstract":"This project will develop a social intelligence capability for computers, for use in educational software applications. Social intelligence plays a critical role in human tutoring and teaching. By modeling social intelligence in software it should be possible to create educational software that is aware of the learners' attitudes, that interacts harmoniously and responds to learner needs, that is able to develop rapport with learners, and that uses responsiveness and rapport to influence learner motivation. This could be <br\/>particularly valuable for learners who have motivational problems such as low self-confidence. The social intelligence model will be realized in an animated pedagogical agent, that uses a combination of speech and nonverbal gestures, that can express emotions and attitudes, and that reacts to and adapts to learners over time. It will respond to a variety of learner inputs, including learner performance on assigned problems, conversational dialog, and eye gaze and facial expressions recognized using computer vision techniques. The model will be applied in the context of the Virtual Factory Teaching System, a simulation-based learning system for teaching industrial engineering <br\/>concepts. The effectiveness of the model will be tested by comparing learner performance with and without the assistance of a socially intelligent agent.","title":"ITR\/PE: Social Intelligence in Interfaces for Educational Software","awardID":"0121330","effectiveDate":"2001-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":[167169,"540286","551113","217983",167173],"PO":["564456"]},"60049":{"abstract":"This research program will develop finite-dimensional nonlinear dynamical models for underwater robot vehicles, and incorporate these models in the development of provably stable nonlinear controllers for dynamic maneuvering of underwater vehicles. This research will directly address the following two problems:<br\/><br\/>1. Nonlinear Finite Dimensional Dynamical Modeling: We are developing unsteady dissipative hydrodynamical models and numerical simulations for marine vehicles, and experimentally verifying these analytical models under the low-speed operating conditions typical for dynamically positioned vehicles engaged in survey, sampling, docking, and maneuvering operations.<br\/><br\/>2. Stable Model-Based Nonlinear Adaptive Control: We are developing 6-DOF model-based adaptive tracking controllers, and experimentally evaluating both the new and previously reported techniques in full-scale experimental trials. <br\/><br\/>The goal is to enable marine vehicles to perform missions presently considered either infeasible or impractical with existing manned and unmanned systems. The intellectual merit of the activity is the analytical development and experimental validation of finite-dimensional plant models with explicit dissipative structure, and the development and experimental validation of a new class of model-based adaptive identifiers and tracking controllers for underwater vehicles. The broader impacts of the activity include: Development and web-based dissemination of \"Dynamics and Control of Marine Vehicles,\" a new course at JHU. Advances developed under the proposed research will be transitioned to the vehicles of the NSF supported National Deep Submergence Facility to improve their operational capabilities for U.S. oceanographic science.","title":"Physics-Based Finite-Dimensional Modeling and Adaptive Control of Underwater Vehicles","awardID":"0100783","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1632","name":"CONTROL SYSTEMS"}}],"PIcoPI":["550512"],"PO":["315982"]},"66946":{"abstract":"The objective is the joint effort of the National Science Foundation Directorate for Computer and Information Science and Engineering (CISE) and the Defense Advanced Research Projects Agency (DARPA) Information Technology Office (ITO) to establish a National Experimental Platform for Hybrid and Embedded Systems Technology (NEPHEST).<br\/><br\/>The Goal of NEPHEST is to provide a common experimental infrastructure for hybrid and embedded systems research. NEPHEST will include the following major components:<br\/><br\/>1. An open framework for integrating hardware and software components of both laboratory and large-scale experiments for hybrid and embedded systems research.<br\/>2. Reusable hardware and software components and tools for experimental systems.<br\/>3. An evolving suite of challenge problems, reference solutions, and baselines for validation and verification of technologies.<br\/>4. A National Repository of components, tools, verification results and documents.","title":"National Experimental Platform for Hybrid & Embedded Systems Technology (NEPHEST)","awardID":"0131126","effectiveDate":"2001-09-01","expirationDate":"2002-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["534923"],"PO":["561889"]},"61028":{"abstract":"The advent of the exploding Internet and the terra-bytes of<br\/>heterogeneous data in it have made more acute the topic of searching<br\/>such large digital databases. The challenges involved go beyond<br\/>questions in information retrieval. One may envision seeking images in<br\/>films, seeking words in voice data, and seeking phrases in compressed<br\/>files and in files of various types.<br\/>These challenges have boosted the appearance of myriad start-up<br\/>companies and ad-hoc methods for the various tasks.<br\/>The PI's approach has been a basic bottom-up long-term study of the<br\/>theory of searching. They have a large center of pattern matching<br\/>research that has pursued and continues to pursue understanding of the<br\/>theoretical underpinnings of generalized searching, coupled with<br\/>applications of their various ideas.<br\/><br\/>the current research will continue the investigation of issues in<br\/>generalized searching. In particular:<br\/> 1. Approximate indexing with a small number of errors.<br\/> 2. In-place compressed search.<br\/> 3. ``Reusable'' dynamic programming code.<br\/> 4. Parameterized matching with ``don't care''s.<br\/>Research on the theory of image processing will also be<br\/>continued. The particular areas of concentration are: <br\/> 1. The effect of digitization.<br\/> 2. Real multi-dimensional scaling.<br\/> 3. Efficient search of rotated images.<br\/>The investigators' research group has started a program of selective<br\/>implementation of advanced pattern matching ideas, some in conjunction<br\/>with research groups from other application areas. There are plans to<br\/>implement text fingerprinting ideas and test their applicability in<br\/>IR. In addition a project is planned that incorporates many of the<br\/>ideas on searching compressed and heterogeneous files by constructing<br\/>an automatic scientific home-page generator and maintainer (guaranteed<br\/>to be an instant hit with all professors of Computer Science!).","title":"Collaborative Research: Pattern Matching - Theory and Practice","awardID":"0104494","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["401872"],"PO":["499399"]},"63019":{"abstract":"Networked computer systems are vulnerable to malicious attack. These attacks<br\/>try to take over the control of a victim computer system by re-pointing the processor program counter (PC) to the attacker's code. This proposal explores a role for security aware compilation and processor microarchitecture in preventing unauthorized PC modifications. The two most common instances of PC compromise arise from the corruption of (1) the return address in an activation record and (2) function pointers. The basic approach to guarding PC is to apply an encoding function before any potential PC value (such as return address, or function pointer table entry) is stored in any memory location (such as a stack frame or function pointer table in the data or heap space). <br\/><br\/>Any read of a memory value into the PC first has to go through a decoding function. A compromised PC value would go only through the decoding function and hence would render the malicious attack ineffective. This research investigates several variations of PC encoding\/decoding schemes and evaluates computational overhead of these schemes and their effectiveness. This research plans to build a hardened Linux system, gcc compiler and other public domain utilities such as Apache web server incorporating the proposed return address and function pointer protection schemes.","title":"ITR-SY: System Hardening through Security Aware Compilation and Processor Architecture","awardID":"0113409","effectiveDate":"2001-09-01","expirationDate":"2002-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["409197","316670"],"PO":["180163"]},"57618":{"abstract":"The goal of this project is to develop database technologies that address the demands of data-intensive applications, which handle distributed, spatial and multimedia data sources. The research effort focuses on: (1) the development of new spatial query processing algorithms that can be dynamically and flexibly reordered and adapted during query execution to address the fluctuation in response time and the unexpected delays from the various input web-based spatial data sources; (2) the development of indexing techniques and technologies to facilitate the embedding of non-traditional spatial and high-dimensional indexing structures into database systems; and (3) the development of disk scheduling algorithms that scale up towards achieving multiple quality of service requirements for multimedia applications. The techniques generated by these research tasks will facilitate the efficient support of modern applications in database systems and will allow database systems to match the dynamically changing demands of these applications. The education effort focuses on: (1) the involvement of both undergraduate and graduate students in hands-on research activities and experimentation; (2) the development of several curriculum elements including two courses and three educational tools, and the introduction of these tools into the existing and newly developed courses; (3) the development of a multimedia database and information systems laboratory to facilitate the integration of research results and education; and (4) facilitating industrial interaction for students. The outcomes of this project -- including newly developed database technologies, research tools, and curriculum elements -- will be publicly disseminated and shared with colleagues, students, and industrial collaborators in the database systems area.","title":"CAREER: Research and Development of Database Technologies for Modern Applications","awardID":"0093116","effectiveDate":"2001-09-15","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["486458"],"PO":["469867"]},"60666":{"abstract":"EIA-0103023<br\/>Alok Choudhary<br\/>Northwestern University<br\/><br\/>Scalable I\/O Management & Access Optimizations for Scientific Applications for High-Performance Computing<br\/><br\/>The main objective of this proposal is to address the problem of large-scale storage, performance management of I\/O, automatic performance optimizations of I\/O using historical information and access patterns, data management, analysis, and access using simple interfaces which permit flow of access information to lower levels software for exploiting higher level information. Furthermore, since analysis at such a scale is simply not feasible if done manually (e.g., visualization alone or off-line analysis), integration of on-line analysis and feature extraction while simulations and experiments are executing is very important. Our observation is that neither parallel file systems nor runtime systems and database management systems (DBMS) fully-address the large-scale data management problem, as they lack global information about the applications access patterns and most of them are not effective in handling storage hierarchies.<br\/><br\/>We believe that the results from the proposed research will enable scientists to address one of the most important bottlenecks in computational simulation cycles; namely, the bottleneck of analyzing and managing massive data in high-performance distributed computing environment (such as Grid).","title":"NGS: Scalable I\/O Management and Access Optimizations for Scientific Applications for High-Performance Computing","awardID":"0103023","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["560392","542016"],"PO":["301532"]},"62976":{"abstract":"The proposal addresses the problem of simultaneous control of a machine - e.g. a robot - by a number of independent operators. Such situations are likely to appear, for example, when robots are controlled via Internet from various locations, and also in tele-immersion and teleworking. As a possibility, inputs from the participants may be combined to generate a single control stream - which is equivalent to the participants collaborating rather competing with each other. New fundamental reaserch issues that appear in systems with multi-user control of a single device - in the context of theory, algorithms, and system implementation - will be investigated.","title":"ITR\/SI: Collaborative Telerobotics: Theory and Scalable Infrastructure","awardID":"0113147","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["520937"],"PO":["234178"]},"61304":{"abstract":"The research focuses on the design and implementation of a framework,<br\/>called the ADaptive Object RE-optimization (ADORE) system, to evaluate<br\/>the effectiveness of dynamic binary re-optimization, and to study the<br\/>interaction between architecture\/micro-architecture and a dynamic<br\/>binary re-optimizer. The topics studied include: efficient profiling<br\/>techniques; runtime hot region selection and formation; light-weight<br\/>runtime optimizations; code patching and region linking techniques;<br\/>architectural and micro-architectural support for dynamic binary<br\/>optimization; and runtime specialization and value profiling.<br\/>The first implementation of the ADORE system will be based on<br\/>two different implementations of the IA-64 architecture, the<br\/>Itanium and the McKinley. The performance of application code<br\/>optimized for Itanium will be tested on McKinley using the<br\/>ADORE system.","title":"ADORE -- A Framework for Adaptive Object Code Re-optimization","awardID":"0105574","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["383979","383980"],"PO":["180163"]},"61315":{"abstract":"The certitude that software execution terminates in principle<br\/>is of little use without a grasp of the resources required,<br\/>in particular computation time and space as functions of input size.<br\/>Research over the last decade has demonstrated the potential of implicit<br\/>static analysis of computational complexity, that is, programming and<br\/>verification paradigms that automatically guarantee program execution<br\/>within feasible resources, without an explicit analysis of<br\/>algorithmic complexity in terms of machine models.<br\/><br\/>This project further explores the conceptual<br\/>underpinnings of machine-independent complexity, in particular<br\/>abstraction mechanisms in functional programs and verification systems.<br\/>It studies the implementation of these principles within major<br\/>programming paradigms and styles, notably declarative and object<br\/>oriented programming.<br\/>Finally, it initiates applications of implicit complexity<br\/>in Feasible Mathematics, in the guise of a library<br\/>of formal proofs which establish the feasible computational contents<br\/>of mathematical theorems without referring explicitly to computational<br\/>complexity.","title":"Logics and Type Systems for Computational Complexity","awardID":"0105651","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":[157665],"PO":["499399"]},"62899":{"abstract":"The numerical solution of large, sparse systems of linear equations and eigenvalue problems is central to many scientific and engineering applications. Iterative methods executed on parallel computers often provide the only means of solving these problems. Most parallel implementations of iterative methods have adopted a fine grain allocation of equations to different processors. However, recent architectural and computational advances suggest that fine-grain methods may be inadequate. Specifically, high network latencies and synchronization overheads may make fine grain methods ill suited to clusters of workstations (COWs) and massively parallel processors (MPPs). In addition, partitioning a problem to a large number of processors may lead to load imbalances and processor idling. The increasing use of Computational Grids consisting of heterogeneous networks only makes these problems worse. Achieving high performance requires new levels of sophistication in parallel algorithms and in the interaction of the implementation with the runtime system.<br\/><br\/>This project will advance the state of the art in high performance, parallel iterative methods by exploring algorithms that combine coarse and fine granularity, and dynamic resource utilization schemes. It will build a new multigrain implementation level on top of traditional parallelization methods to introduce coarser granularity during the preconditioning step. It will identify system-aware iterative algorithms and algorithmic patterns that enable dynamic load balancing, and use them to exploit available runtime system information. The resulting codes will be made available to the community.","title":"ITR\/AP: High Performance Iterative Methods on Parallel Computers and Distributed Shared Environments","awardID":"0112727","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["518256"],"PO":["565272"]},"61469":{"abstract":"To support Quality of Service (QoS) in the Next Generation Internet, new algorithms are needed for many network components, including routing, scheduling and admission control. QoS routing, which identifies paths that have sufficient resources to satisfy the QoS requirement of a connection and selects a path for that connection, is one of the most important components for QoS provision. Although many QoS routing algorithms have been proposed, a number of theoretical and practical issues remain to be addressed to achieve efficient QoS routing in large scale networks, that is, scalable QoS routing. This research will attempt to address some of these issues. Specifically, we will focus on the following four areas.<br\/><br\/>Networking state aggregation. For a large network, a common approach to achieve scalable routing is to reduce the size of global network state by aggregating information according to the hierarchical structure of the network. This approach has been adopted by the ATM private network-network interface (PNNI) standard. However, when multiple QoS metrics are involved, precisely aggregating information of a domain may not be feasible since it requires memory space that grows exponentially with respect to the size of the domain. In this research, we will design various topology aggregation schemes, study the trade-offs of the schemes between the amount of space needed and the effectiveness in summarizing the domain information, investigate the QoS routing performance with different topology aggregation schemes, and determine the topology aggregation schemes that are effective in practice for QoS routing with multiple QoS metrics. <br\/><br\/>Handling random imprecision of the global network state information. In large scale networks, maintaining precise global state information requires link states to be distributed frequently, which results in large protocol overheads along multiple dimensions including bandwidth, storage, update processing, and the associated context switching. To control the protocol overhead, the link state update frequency may be reduced, which results in the imprecise global state information. The imprecision caused by the infrequent link state updates is random in the sense that a router cannot estimate the accurate global network state. Thus, a practical QoS routing algorithm must be able to perform effective routing using the imprecise global network state information. In this research, we propose a novel routing scheme that performs effective routing in the presence of imprecise global state information. Our scheme is different from the existing methods in that it combines static and dynamic routing and adapts the routing schemes based on network status. We will compare our scheme with the existing methods in terms of routing performance and protocol overheads and identify the strengths and weaknesses of each method through extensive simulations. <br\/><br\/>Interaction between resource reservation and QoS routing. Most current QoS routing algorithms assume a separate protocol to perform resource reservation. However, in the future large scale high speed networks, it is desirable to combine resource reservation with QoS routing. Combing resource reservation with QoS routing may have negative impacts on the routing performance, especially for large networks. This research will try to understand the impact of resource reservation on various QoS routing schemes and develop techniques to achieve effective routing in the presence of resource reservation traffic.<br\/><br\/>Multi-constrained QoS routing and generic QoS routing algorithms. Multi-constrained QoS routing finds a path that satisfies multiple independent QoS constraints. This problem is NP-hard. However, distributed applications such as the Internet phone and distributed games have very diverse QoS requirements on delay, cost, delay jitter, loss ratio, bandwidth, etc. To support such applications, practical multi-constrained QoS routing algorithms must be developed. Furthermore, due to the complexity of multi-constrained QoS routing, existing QoS routing algorithms are very restrictive on the type and the number of QoS constraints, which implies that different QoS routing algorithms will be needed for different applications. In the future networks, it is desirable to use a generic QoS routing algorithm that can efficiently handle different QoS requirements. In this research, we will study the heuristic algorithms that solve the multi-constrained routing problem effectively in practice and develop a generic algorithm that performs well regardless of the number and the types of QoS requirements.<br\/><br\/>We plan to evaluate our techniques by implementing the proposed techniques in Qbone and to validate the techniques through implementation and experimentation in the real network. We believe that by developing effective mechanisms to address these four issues, we will be able to integrate the mechanisms and develop efficie","title":"Towards Scalable Quality of Service Routing","awardID":"0106706","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["554071"],"PO":["565090"]},"64736":{"abstract":"Real-time Environmental Observation and Forecasting Systems (EOFS) will revolutionize the way scientists share information about the environment and represent an opportunity to break traditional information barriers separating scientists from society at large. EOFS are already in use, but they tend to be small-scale, application- and domain- specific, stand-alone systems. There is a need for evolution towards multi-purpose shared systems designed to adapt flexibly to evolving needs of information consumers. What is required are large-scale, shared, heterogeneous distributed systems that make extensive use of diverse sensor-based inputs, sophisticated numerical simulations, mobile and embedded real-time system components, wireless and wired communications, high-performance computers, and high capacity storage systems. <br\/><br\/>This ITR medium project has assembled an inter-disciplinary team, including computer science and environmental science researchers in addition to a heterogeneous base of pilot users. This group will collaborate to develop software technology which will enable EOFS to evolve efficiently, and to deliver quantifiably reliable information about the environment at the right time and in the right form to the right users. The project focus is on EOFS for estuarine and coastal regions. These regions are selected because they are highly variable natural systems subject to intense human activity and with great social, environmental, economic and cultural value.<br\/><br\/>The research will include:<br\/><br\/>i. Developing missing integration concepts and technologies for EOFS, with emphasis on quality-scalable information processing, storage and access (the computer science research).<br\/>ii. Closing the loop between environmental models and sensors, and implementing a next generation EOFS based on an existing prototype for an estuary with multiple and often conflicting uses (the environmental observation and forecasting systems research);<br\/>iii. Using, evaluating and refining the EOFS prototype for scientific discovery, natural resources stewardship and emergency response, thus incorporating sound science in operational and management decisions of critical regional importance and national significance (the environmental science and management applications);<br\/>iv. Developing pilot multi-level, inter-disciplinary educational programs that cross-train young people, computer scientists, environmental scientists and practitioners in the conceptualization, development and use of environmental information technology (the education impact).","title":"ITR\/AP+IM: Information Processing for Integrated Observation and Simulation BAsed Risk Management of Geophysical Mass Flows","awardID":"0121254","effectiveDate":"2001-09-15","expirationDate":"2005-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["528796","542246","521163","508973","361346"],"PO":["565272"]},"64747":{"abstract":"Tele-immersion, an ability to share presence with distant individuals, situations, and environments, may provide vast new possibilities for human experience and interaction in the near future. In order to make these dreams a reality, a host of technical difficulties must be solved: acquisition, communication, display, and interaction. This project focuses on answering two of the major questions: 1) Is tele-immersion as good as its promise or is there some inherent weakness? By using overwhelming computation power, the PI hopes to accelerate development so a real system can be tried within three years. 2) Is there a show-stopper with tele-immersion over long distances? The PI will try it for real, not just simulated distance via artificial delays. Specifically, the PI will build a 60-camera system at the University of Pennsylvania, compute depth on the 3000-processor Terascale Computing System at the Pittsburgh Supercomputing Center, and display at the University of North Carolina. The PI will have a more modest acquisition system at UNC (15 cameras) and a more modest display system at UPenn to enable local development and two-way collaboration. The testbed application will be remote medical consultation by a trauma surgeon, chosen because of its inherent demand for real-time response and its great potential benefit to societal. The PI expects to be able to provide demonstrable progress within the three year period of the project. Team members who are leading trauma surgeons will guide the design; evaluation will be by other trauma surgeons. The three years of effort will lead to a testable prototype with sufficient power and scope to be evaluated by application experts not on the research team. The results will indicate the likely success of other tele-immersion applications, as well as providing experience in building real-time applications on a remote terascale facility over fast wide-area networks.","title":"ITR\/SI: Real-Time Long-Distance Terascale Computation for Full Bandwidth Tele-Immersion","awardID":"0121293","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["550455"],"PO":["317663"]},"54836":{"abstract":"This project focuses on Information Dependency (InD) measures and the application of these measures to databases and datamining. InD measures use classical (Shannon) information theory to evaluate the information structure of database relations. This work extends results by the investigators of this project which show how InD measures generalize concepts important in database design, namely functional and multivalued dependencies. Research in this project is taking place across the spectrum from theory to practice. On the theoretical side, deeper details of InD's are investigated with an eye toward mechanisms for manipulating and applying InD measures. On the theoretic side, properties of InD's are investigated with an eye toward manipulating and applying InD measures, as well as toward implications of InD's on modeling. In the center, techniques for computing the measures are being investigated. Because the ultimate goal of datamining is to inform the user, investigations also include the interaction of InD and visualization. On the applied side, the major focus is the application of InD measures on data mining. Recognizing that research into applications requires real rather than \"toy\" targets, this project seeks collaborations involving data mining: the first such collaboration being with researchers in Biology. All of the activities of this project ultimately lead toward the development of prototype toolkit components based on InD measures.","title":"Information Dependencies in Databases and Data Mining","awardID":"0082407","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":[140111,140112,140113],"PO":["563751"]},"64538":{"abstract":"With the proliferation of RF ICs in consumer electronic products there is a critical need for simulation and modeling tools that enable first pass success in silicon. The trend towards integrating complete systems on a chip, requires very high performance digital, analog, and RF circuits to be integrated on the same silicon substrate. Successful integration of these complex systems requires new design tools and design approaches that significantly advance the state-of-the-art. Certain aspects of RF system performance are easier to characterize and verify in steady state. Examples of these are distortion, power, frequency, noise, and transfer characteristics such as gain and impedance. The proposed work focuses on developing a coupled device and circuit simulator that will accurately address the modeling and simulation needs of critical and noise sensitive analog and RF devices and circuits. A coupled device and circuit simulator provides a<br\/>direct link between the IC fabrication technology, device design and the higher level of circuit design. Since the models from the device simulator (numerical models) are predictive, they can be used to evaluate the impact of technology on circuit performance. Additionally, this work provides the foundation for new design approaches that will advance the state-of-the-art for analog and RF circuits blocks.<br\/><br\/>This research will focus on modeling, simulation, and design of high performance and high frequency analog and RF circuits. The key contributions of this work will be:<br\/><br\/>A software architecture for incorporating general purpose device simulators in the coupled device and circuit simulator CODECS. The architecture will allow integration without extensive modifications to the device simulator and enable simulation of technologies such as SiGe and SOI, and also simulation of optical devices. This tool architecture also facilitates parallelization over a cluster of workstations.<br\/><br\/>Availability of time-domain and frequency-domain steady-state simulation methods within one simulator. Numerical (physical) models and compact circuit models can be used within this simulator.<br\/><br\/>Capability of simulating device-to-device interactions including substrate and thermal couplings.<br\/><br\/>Coupled device and circuit noise simulation techniques for RF circuits.<br\/><br\/>Validation of simulator with fabrication of improved designs for the following RF circuitry: low noise amplifier (LNA), mixer, and voltage controlled oscillator (VCO). These circuits are critical blocks in a transceiver and are particularly sensitive to noise.<br\/><br\/>The research in this proposal is tightly integrated with a significant educational<br\/>component. This will include development of courses in RF integrated circuits, and modeling and simulation for RF applications. A new undergraduate course will be developed. This course will focus on transceiver architectures and discrete design and will include a lab in which students will gain hands-on experience in radio design. The emphasis will be on projects related to transceiver design. The research results, including the software, circuit designs, and course-related materials will be available on the world wide web. In addition, results from the proposed work will be presented at meetings of the Semiconductor Research Corporation and the NSF Center for Design of Analog and Digital ICs.","title":"Research for Mixed Signal Electronic Technologies: A Joint Initiative Between NSF and SRC: Coupled Device and Circuit Simulation for Critical RF IC Blocks","awardID":"0120275","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["410638"],"PO":["562984"]},"58917":{"abstract":"Proposal Number: CCR-0097058<br\/><br\/>Title: Understanding Object-Oriented Software Design Evolution in the Extreme <br\/>Programming Process<br\/><br\/>Principal Investigator: Wei Li<br\/><br\/>Abstract<br\/><br\/>Extreme Programming (XP) is a new software process emphasizing source code<br\/>as the main communication medium and software testing as the quality<br\/>assurance mechanism. This research studies object-oriented (OO) software<br\/>design evolution and examines the predictive capability of software metrics<br\/>in the XP process by using carefully logged design-change data on two<br\/>commercial Java systems developed using an XP-like<br\/>process with daily (working day) log on the design change and the change<br\/>effort. This project analyzes the collected data and investigates how class<br\/>design, as measured by metrics such as CTA, CTM, NLM, WMC, and LCOM, evolves<br\/>from one story to the next: i.e. if they show continuous growth or otherwise. The<br\/>project also studies if the OO metrics collected at the end of an iteration<br\/>cycle can predict the refactoring, error-fix, and new design efforts in the<br\/>next cycle by using multiple linear regression. The result from this study<br\/>helps us understand how customer requirements, which come in small chunks<br\/>(stories) from the customer in the XP process, affect software design<br\/>change.","title":"Understanding Object-Oriented Software Design Evolution in the Extreme Programming Process","awardID":"0097058","effectiveDate":"2001-09-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["280792"],"PO":["564388"]},"57718":{"abstract":"The nature of distributed work is changing as mobile and ubiquitous technologies are being used increasingly to enable collaboration anywhere, anytime. The success of distributed teamwork depends on the ability of collaborating partners to communicate essential social and task information, referred to as awareness information. Thus, the design of next generation mobile and ubiquitous technologies need to be based on a deep understanding of social and task requirements. The purpose of this project is to investigate how technology can support awareness requirements as people's environments change during distributed work. Empirical studies of physically collocated and distributed collaboration will be done to develop a theoretical framework for how awareness information is conveyed and utilized in these different settings. Five field sites have been selected in domains where distributed work is commonplace: space mission design, aerospace, software development, microprocessor development, and disk storage technologies. Prototype awareness mechanisms will be developed based on the requirements obtained in the field studies. These technologies will be evaluated both in the field and the laboratory to test the theoretical framework of how awareness information is utilized in distributed work. This research will be integrated into a graduate study program focused on computer-supported collaborative work and human-computer interaction.","title":"CAREER: Awareness Mechanisms for Next Generation Virtual Collocation","awardID":"0093496","effectiveDate":"2001-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["518420"],"PO":["564456"]},"80444":{"abstract":"","title":"Efficient Marking Techniques for Differentiated Services in the Internet","awardID":"0296034","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["550540"],"PO":["565090"]},"60777":{"abstract":"EIA-0103670<br\/>Rastislav Bodik<br\/>University of Wisconsin<br\/><br\/>NGS: Wisconsin DOVE: Distributed Optimizing Virtual Environment<br\/><br\/>Wisconsin DOVE proposes to improve the performance of modern distributed and parallel applications as well as increase the productivity of application developers and system maintainers. Building on recent advances in distributed control, dynamic program optimization, and hardware-supported performance monitoring, our project will build a Distributed Optimizing Virtual Environment (DOVE) whose power will stem from two primary innovations.<br\/><br\/>The VM-in-OS paradigm. Dove will implant into the operating system an optimizing virtual machine (VM), whose ability to analyze a running program and correlate the analysis with hardware-based performance monitoring will achieve vertical integration, spanning the application, the kernel, and the hardware. The VM-enabled operating system will be intimately aware of both the application above and the hardware and network below, and hence it will be able to schedule resources more intelligently and adaptively.<br\/><br\/>A clan of optimizing virtual machines. Expecting that future distributed applications will be assembled from distributed components written in Java (or a similar mobile language), we propose to organize the VMs underlying the individual distributed components into a clan, in which the VMs exchange profiling and program-analysis information about their clients. By supporting \"gossip\" among the distributed VMs in a clan, we will be able to compute a run-time communication and dependence profile of the distributed application and, in response, perform a dynamic repartitioning of the application.","title":"NGS: Wisconsin DOVE: Distributed Optimizing Virtual Environment","awardID":"0103670","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["549841","556819","550390"],"PO":["301532"]},"60788":{"abstract":"EIA-0103706<br\/>Donald E. Thomas<br\/>Carnegie Mellon University<br\/><br\/>Next Generation Software: A Computer System Design Hierarchy for Simulation<br\/><br\/>Computer system design requires reasoning about the interaction of software with the underlying models of hardware resources without limiting such models to single system views. Computer system elements and their interactions are not purely software-functional or purely hardware-structural-they have properties of both. A challenge in computer system design is to define the elements and the means of resolving their interactions, so that software interacting with underlying hardware resources can be modeled flexibly; alternate designs, ones with different numbers and types of processors, network interconnections, and\/or software schedulers, may be easily considered.","title":"NGS: A Computer System Design Hierarchy for Simulation","awardID":"0103706","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["507772","464680"],"PO":["301532"]},"64803":{"abstract":"Electronic markets are emerging as a primary medium of trade in business-to-business, business-to-consumer, and consumer-to-consumer settings. In order to design viable electronic marketplaces, a host of novel interrelated game-theoretic and computational issues must be<br\/>addressed. With a team of interdisciplinary researchers from multiple institutions, this project will develop a unified theory of games and computing to guide and facilitate the growth of such markets. Specific research directions of the project include the following: (1) Market designs will be generalized to incorporate combinatorial bidding, multi-attribute preferences, multi-stage mechanisms, continuous mechanisms, and multi-unit sale; (2) New algorithms for clearing, quoting, incentive-compatible pricing as well as new incentive-compatible tractable mechanisms will be designed with particular emphasis on online and incremental updating of market states; (3) Bounded rationality of the agents will be investigated under a wide spectrum of models of computations, equilibrium concepts of game theory, and trade-offs between centers and agents; and (4) Novel approaches to relaxing the classic common prior assumption will be explored in order to develop practically useful models for ecommerce. The successful completion of this project will make significant contributions to both theory and practice in the areas of electronic commerce, multi-agent systems, algorithms, computational complexity theory, and game theory.","title":"ITR\/PE+SY: Collaborative Research: Foundations of Electronic Marketplaces: Game Theory, Algorithms and Systems","awardID":"0121491","effectiveDate":"2001-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["517969"],"PO":["564456"]},"54903":{"abstract":"This research project introduces needed advances in multimedia data management and access for applications dealing with streams of multimedia data. In particular, medical patient information involves streams of sequences of multimedia data, including streams of images (X-rays, MRIs, etc.), medical reports, treatment and medication information, and other alphanumeric data taken at various points in time, any part of which must be readily accessible for patient care. The goal of this effort is to enable doctors and the patient to store and easily retrieve and visualize the variety of such medical information, and various related data in the web. Data modeling constructs to support the needed substreams, aggregated streams, derived streams, and relationships among and within these constructs is expected to result from this research. A stream algebra for expressing queries is introduced to explore methods for effective query processing, as well as a corresponding visual language for users to easily express the queries. A Time Line end-user interface is extended to incorporate the new constructs introduced for a variety of representative medical user queries. A prototype system will be developed and tested at the UCLA Medical Center to determine the potential impact of these advances through the Time Line paradigm vs current practice in the actual medical domain. Demos will be developed for various computer science and medical domain forums, and will be accessible via Internet, to highlight the technical and medical application innovations. It is expected that the resulting multimedia stream data modeling and data accessing advances will have significant applicability in the medical domain and other areas.","title":"Multimedia Stream Modeling, Relationships, and Querying","awardID":"0082817","effectiveDate":"2001-09-15","expirationDate":"2007-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["320635",140300],"PO":["563751"]},"60359":{"abstract":"The goal of this project is to advance the state of multi-agent processing for intelligent, adaptive biomedical monitoring systems. Adaptive reasoning will align with an agent's mission and guide agent monitoring of aspects of a target environment--comprised of base models with interjected instrumentation readings. Base models are infused with \"live\" interactive data and decision functionality embedded within multiple, autonomous agents, which determine actions, set off alerts and export state. Experimentation will involve exploring the most effective guidance capabilities from genetically programmed agents and adaptive neural networks, in combination with a supportive knowledge base. While the approach has broad application possibilities, it has specific implications for supplemental assistance to medical personnel inundated with information. This project will also provide opportunities for undergraduate students to become actively involved in a growing area of computer science research.","title":"RUI: Model-based Multi-Agents with Neural Networks for Intelligent Monitoring Systems","awardID":"0101819","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":[155175],"PO":["495796"]},"64726":{"abstract":"EIA-0121201 <br\/>Kintsch, Walter<br\/>University of Colorado Boulder<br\/><br\/>ITR\/PE: Latent Semantic Analysis: Theory and Technology<br\/><br\/><br\/>This research program is designed to motivate, create and evaluate a new theory and methodology of learning, in which computer analysis of writing and speech is used to teach students to process and comprehend information more effectively. This work will inform educators on instructional and assessment strategies for improved reading comprehension to a degree not yet present in schools today. The methodology will teach students to read more effectively and to comprehend and learn more from what they read. Since the methodology can be applied to any text, it can be incorporated into reading programs to improve reading achievement, and be used as an effective tool to improve achievement in science and mathematics.<br\/><br\/>The work is intended to achieve both theoretical and research breakthroughs in four areas: (1) extend LSA to incorporate syntactic as well as semantic information; (2) extend the power and scope of LSA by advancing its conceptual and mathematical framework to include other psychological process models that handle phenomena such as metaphor and causal inferences; and (3) extend LSA to process transcriptions of natural continuous speech, enabling LSA to be used to teach comprehension of both read and spoken text by children who cannot write or type well enough to produce textual responses; and (4) demonstrate that these theoretical advances improve comprehension of speech and text by students in different grades, ethic backgrounds, and in different subjects.","title":"ITR\/PE: Latent Semantic Analysis: Theory and Technology","awardID":"0121201","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":[167054,"551122",167056,167057],"PO":["564318"]},"64847":{"abstract":"Real-time, reactive and embedded systems are widely and increasingly used throughout society (e.g., flight control, railway signaling, vehicle management systems, medical devices). This trend is likely to continue, as applications that would have been unthinkable only a few short years ago come into the reach of ever more complex processors. Many such applications are long lived, interact with their environment continuously, and are under important real-time constraints. As these reactive systems permeate our lives, bringing us everything from intelligent pace-makers to tiny freshness-tracking devices in groceries, the need for cost-effective, confidence-inspiring software validation techniques grows proportionately. <br\/><br\/>This project focuses on building new tools for checking a common class of reactive real-time systems known as interrupt-driven systems. The proposed research has four facets that complement and support each other. First, this effort will build on preliminary work in analyzing seven commercial microcontrollers to identify a static timing analysis that is sufficiently precise for a single interrupt handler. Second, ways to specify and check timing properties for multiple interrupt handlers will be investigated. Third, a typed assembly language will be designed with time bounds in which timing properties can be specified in a modular way, one handler at a time. Fourth, a timed interrupt-handler calculus will be designed that will embody the results in a language-independent way and make it tractable to prove key properties. The new tools will automatically derive a model of the software by static analysis and type checking, and submit the result to a model checker. The tools can lead to significantly reduced testing requirements, and provide support for maintenance throughout the system life-cycle.","title":"ITR\/SY: A Distributed Programming Infrastructure for Integrating Smart Sensors","awardID":"0121638","effectiveDate":"2001-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["564690","230250","292887","517810"],"PO":["561889"]},"64737":{"abstract":"EIA-0121263<br\/>Patrikalakis, Nicholas M<br\/>MIT<br\/><br\/>ITR\/AP+IM: Poseidon- Rapid Real-Time Interdisciplinary Ocean Forecasting: Adaptive Sampling and Adaptive Modeling in a Distributed Environment<br\/><br\/><br\/><br\/>Progress in understanding the complex coupled physics, biology and acoustics of the oceans is accelerating via research on realistic nonlinear multiscale interdisciplinary processes, interactions and variabilities.<br\/><br\/>To cope with the variabilities of such economies in space and time, dynamical model structures must evolve during the prediction, i.e., by adaptive modeling. The objective of this project is to enable by an effective union of information technologies and ocean sciences, efficient mulitscale interdisciplinary ocean prediction with real-time objective adaptive sampling, assimilation of multiple streams of interdisciplinary data, and autonomous adaptive modeling","title":"ITR\/AP+IM: Poseidon - Rapid Real-Time Interdisciplinary Ocean Forecasting: Adaptive Sampling and Adaptive Modeling in a Distributed Environment","awardID":"0121263","effectiveDate":"2001-09-15","expirationDate":"2004-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":[167095,"493332","317581",167098],"PO":["301532"]},"64858":{"abstract":"Shape is a key element in successful communication, interpretation, and understanding of complex data in virtually every area of engineering, art, science, and medicine. While in recent years the communication of both form and complex data have been greatly enhanced by visualization that is based on planar images, computational power has reached the point where it is possible to consider real-time interactive 3D physical communication. In this project, the PI will develop a novel interactive 2D or 3D haptic computer interface that enables both user-specified display of shapes as output from a computer, and user-directed input of shapes to a computer. This so-called \"digital clay\" will allow users to convey and\/or sense multiple-element, parallel information strands. It is a distributed input\/display device, the surface of which can be shaped by a user and acquired by a computer; alternatively, the clay can be shaped by the computer for the user to examine. Like ordinary clay, digital clay will allow an area of moderate size to be touched, reshaped with pressure, and seen by the user in true 3D form. Unlike ordinary clay, digital clay also provides parameters to the computer that will represent the shape to the computer for further analysis, storage, replication, communication and\/or modification; or, will allow the computer to prescribe its shape. This combined input and output feature of the clay enables two-way communication between the computer and the user. Some previous implementations of digital-clay-like devices have focused on reshaping of non-physical volumes of 'virtual clay' using glove-like or haptic manipulator interfaces to a computer in which the virtual clay is stored. The PI's approach is different; digital clay comprises an instrumented, actuated, computer-interfaced physical volume bounded by an actuatable surface that acts as the haptic interface. This surface is displaced by rows or arrays of controllable interconnected fluidic-driven actuators, which together act to convey the surface topography of 3D objects by means of manipulation of a stereolithographed scaffold internal to the volume of the clay. Each actuator comprises a discrete fluidically-inflatable cell that is connected to two common pressurized reservoirs (within a base) through a dedicated two-way miniature valve integrated with a pressure sensor, manufactured by MEMS technology existing at Georgia Tech. The position of each discrete surface element can be altered either by the user or by the host computer. The simple measurement of volume flow rate combined with suitable software-based kinematic analysis allows the determination of the entire volume of the clay, and therefore the coordinates of its surface. A unique feature of the digital clay is that the force that is necessary to actuate the discretized surface is derived entirely from the two fluidic reservoirs, thus eliminating the need for small-scale, electrically-driven actuators that may have limited torque or linear force. This fluidic approach overcomes the constraints imposed by actuator energy density limits, and distributed wiring and sensing requirements, that have heretofore prevented structures such as digital clay from becoming a reality. Furthermore, the user can activate the device interactively with the host computer by sensing and overcoming the force that is exerted by the liquid pressure to concomitantly set (or reset) the shape of the device to a desired state. In this project the PI will develop and demonstrate the digital clay hardware, its computer interface, and associated software, and will further illustrate its efficacy in applications of interest (e.g., computer-aided design, medical and bioengineering diagnostics, and reconfigurable input\/output displays). Of particular note is the potential of digital clay to aid visually impaired persons in receiving\/sending haptic information from\/to a computer.","title":"ITR\/PE+SY Digital Clay for Shape Input and Display","awardID":"0121663","effectiveDate":"2001-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["542602",167538,"524677","370776","182123"],"PO":["335186"]},"64869":{"abstract":"EIA-0121687<br\/>Rzhetsky, Andrey<br\/>Columbia University<br\/><br\/>ITR\/IM+AP: Automated compilation and computational analysis of regulatory networks<br\/><br\/><br\/><br\/><br\/>This project will provide advanced information management systems as well as software applications relevant to the fields of bioinformaticis, molecular biology, and medicine. It will contribute to fundamental Information Management by developing advanced algorithms for the efficient retrieval of information about biological pathways from research articles (using natural language processing techniques), machine-learning-assisted data mining in biological texts, and information management via a uniquely designed database with two levels of representation of biological information.<br\/><br\/>The specific aims of the project are the following: to implement and test natural language processing techniques for the automatic retrieval of signal-transduction pathways from the research literature; to develop general and portable text-mining techniques for the automatic recognition of genes, proteins, and other domain terms, and of relationships between them; and to develop a mathematical framework for the statistical analysis of heterogeneous data on regulatory pathways.","title":"ITR\/IM+AP: Automated Compilation and Computational Analysis of Regulatory Networks","awardID":"0121687","effectiveDate":"2001-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1994","name":"BIOINFORMATICS PROGRAM"}}],"PIcoPI":["338902","516887","506707","429111","214137"],"PO":["565136"]},"66706":{"abstract":"EIA-0129939<br\/>Ronald Breaker<br\/>Yale University<br\/><br\/>Title: Engineering Molecular Logic Gates Using Nucleic Acids<br\/><br\/>Under this project, test tube evolution is used to create molecular switches that serve as logic gates, and these chemically triggered switches are assembled into first-generation biomolecular computing devices. This project is creating new functional RNA and DNA molecules that perform as distinct types of logic gates. This advance in \"molecular hardware\" design is adding to the repertoire of molecular computing infrastructure and permitting the construction of more advanced molecular computing devices. As a demonstration of utility, these logic gates are assembled into molecular computing systems that can be used to add any two numbers. <br\/>A combination of modular rational design and in vitro evolution is being used to create nucleic acid molecular switches that are analogous to electronic logic gates. This design strategy employs the process of Darwinian evolution, where molecular \"survival-of-the-fittest\" is used to identify unique RNA switches that have AND gate function. The kinetic characteristics of the selected RNAs are examined to identify robust constructs that can be altered to produce up to 1 trillion different AND gate species. To demonstrate the utility of these logic gates, they are assembled to create a functional architecture for a molecular computer that can add any two numbers. The result of the molecular computation is reported as pixels on a chip-like surface using radioisotope signaling. In addition, other RNA and DNA switches are created using similar strategies that perform as representatives of the remaining common logic gates.","title":"Bio-QuBIC: Engineering Molecular Logic Gates Using Nucleic Acids","awardID":"0129939","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}}],"PIcoPI":["224941"],"PO":["565223"]},"63208":{"abstract":"This IGERT program is a multi-disciplinary doctoral traineeship in Socio-Technical Infrastructure for Electronic Transactions (STIET). The extraordinarily rapid changes in communications and computing technology, and in the uses and requirements people have for these technologies, have given rise to problems that are not well-suited to narrow, traditional solutions. That these problems are important should be self-evident: electronic transactions are increasingly central to social, economic and political activity in nearly every realm of human endeavor, within and between nearly every location on the planet. The infrastructure to support safe, meaningful, efficient, equitable and productive transactions will determine the extent to which the information revolution is socially beneficial. STIET will offer a comprehensive program from matriculation to graduation that will focus on the interaction between social and technical mechanisms in order to respond to these needs through current research and the training of a corps of scholars to carry forward teaching and research in this area. The program will: (i) provide fellowships for the first two years of graduate study; (ii) require 3 STIET core courses and 2 advanced STIET electives; (iii) provide a weekly research seminar and biannual day-long workshops; (iv) develop a multi-disciplinary, cross-school community of scholars within Michigan through collective and collaborative activities, both synchronous and asynchronous (with computer-supported community and collaboration technologies); and (v) build connections to the external multi-disciplinary research community through its Web site, conference travel, and research experiences at industrial partner facilities. When fully implemented, the program is expected to engage about 35 doctoral students at various stages of their degree. Through the resources and activities of STIET, the students will be encouraged and supported so that they receive serious preparation for multi-disciplinary research and pursue multi-disciplinary approaches to understanding and solving important socio-technical problems in their dissertation research. A large group of faculty are involved from several disciplines (computer science, economics, information, business, public policy) with a long-standing commitment to multi-disciplinary and collaborative research. The team includes collaborative research partners from prominent industrial labs. A professional Master's programs in this area is already in place, which provide a graduate student community, a student services infrastructure, and a fertile recruiting ground for promising doctoral students.<br\/><br\/>IGERT is an NSF-wide program intended to meet the challenges of educating Ph.D. scientists and engineers with the multidisciplinary backgrounds and the technical, professional, and personal skills needed for the career demands of the future. The program is intended to catalyze a cultural change in graduate education by establishing new, innovative models for graduate education and training in a fertile environment for collaborative research that transcends traditional disciplinary boundaries. In the fourth year of the program, awards are being made to twenty-two institutions for programs that collectively span all areas of science and engineering supported by NSF. The intellectual foci of this specific award reside in the Directorates for Social, Behavioral, and Economic Sciences; Computer and Information Science and Engineering; and Education and Human Resources.","title":"IGERT: Socio-Technical Infrastructure for Electronic Transactions","awardID":"0114368","effectiveDate":"2001-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1713","name":"WORKFORCE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1101","name":"Division of GRADUATE EDUCATION","abbr":"DGE"},"pgm":{"id":"1335","name":"IGERT FULL PROPOSALS"}}],"PIcoPI":["527566","361939","563733"],"PO":["229999"]},"63219":{"abstract":"The University of Central Florida will establish an IGERT program with a multidisciplinary research theme in Optical Communications and Networking to train 30 Ph.D. students over the next five years. This program is a joint effort of twenty scientists, engineers and educators from the Departments\/Schools of Mathematics, Statistics, Optics, Physics, Material science, Electrical Engineering and Computer Science, and Education at UCF. Optical communications and networking is a particularly well-suited IGERT theme because the diverse multidisciplinary technologies that need to be developed to enable next-generation information infrastructure. Major research efforts are grouped in four areas: advanced components, transport, switching, and networking and network management. Each IGERT thesis project is designed to build upon expertise from at least two different groups in realizing an enhanced functionality that is greater than the sum of the parts, over and above what the two groups would pursue independently. The advising team of each IGERT student, consisting of two or more faculty members from different departments, an industrial advisor and a non-technical advisor, is designed to ensure the successful integration of education, research and training. Industry, the users of technology considered in this effort, will be involved at the onset of the thesis research for each student. The research framework is complemented by the existing multidisciplinary courses, new courses in optical communications and networking to be developed under this IGERT program and being developed under an existing NSF CRCD grant, on-site training on state-of-the-art equipment at UCF, off-site training in industry, and non-technical training including business, communication\/ interpersonal skills and ethics. The objective of this IGERT program is not only to train the participating Ph.D. students to become leaders in industry and\/or academia but also for this program to serve as a national model for training scientists and engineers in today's globally competitive and technology-driven market economy. <br\/><br\/>IGERT is an NSF-wide program intended to meet the challenges of educating Ph.D. scientists and engineers with the multidisciplinary backgrounds and the technical, professional, and personal skills needed for the career demands of the future. The program is intended to catalyze a cultural change in graduate education by establishing new, innovative models for graduate education and training in a fertile environment for collaborative research that transcends traditional disciplinary boundaries. In the fourth year of the program, awards are being made to twenty-two institutions for programs that collectively span all areas of science and engineering supported by NSF. The intellectual foci of this specific award reside in the Directorates for Engineering; Computer and Information Science and Engineering; Mathematical and Physical Sciences; and Education and Human Resources.","title":"IGERT: Optical Commuications and Networking","awardID":"0114418","effectiveDate":"2001-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"1360","name":"HUMAN RESOURCES DEVELOPMENT"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1101","name":"Division of GRADUATE EDUCATION","abbr":"DGE"},"pgm":{"id":"1335","name":"IGERT FULL PROPOSALS"}}],"PIcoPI":[162470,"509628","385409","355756","557048"],"PO":["434633"]},"60700":{"abstract":"EIA-0103215<br\/>Lydia Sohn<br\/>Princeton University<br\/><br\/>Nano Exploratory Research: The Single-Molecule DNA Transfer<br\/><br\/>The focus of this project is to investigate the possibility of using single molecules of DNA for molecular-based electronic devices. Recent results of single-molecule DNA transistor shows a Coulomb Blockade Staircase and a gate-voltage dependence of the conductance enabling reliable and reproducible conducting DNA devices. This project is furthering this work to investigate the mechanism for DNA conduction and its dependence on various chemical and structural parameters. The single-molecule DNA transistor is being further investigated too understand the mechanism by which DNA conducts. Various questions such as dependence of conductivity of DNA to length and sequence; differences in conductivity between single-stranded and doubled-stranded DNA; dependence of the conduction in DNS to salts from the buffer solution; where are possible scattering centers located in the DNA molecule? Answers to such fundamental questions are expected to lead to a number of future novel molecular-scaled DNA-based electronic devices.","title":"Nano Initiative: The Single-Molecule DNA Transistor","awardID":"0103215","effectiveDate":"2001-09-15","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1708","name":"QuBIC"}}],"PIcoPI":["329226"],"PO":["565223"]},"60767":{"abstract":"EIA-0103642<br\/>Gary W. Howell<br\/>Florida Institute of Technology<br\/><br\/>CISE NGS: Cache Efficient and Parallel Bidiagonalization<br\/><br\/>Cache efficient reduction to bidiagonal form allows a significant speedup in computation of the singular value decomposition (SVD) for rectangular matrices. The SVD provides the most standard and stable means of solving least square problems and of providing low rank approximations (allowing compressions of data stored in matrix form). As such it is used constantly by researchers around the nation and the world.<br\/><br\/>This proposal will result in speedups in the standard LAPACK implementation and also in the parallel computation package SCALAPACK. The work will also extend to the parallel case with a view for inclusion in SCALPACK. In the parallel case the optimizer must take into account not only details of the local computer architecture and memory hierarchy but also communication among the processors.","title":"NGS: Cache Efficient and Parallel Householder Bidiagonalization","awardID":"0103642","effectiveDate":"2001-09-15","expirationDate":"2005-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["159328",156364],"PO":["301532"]},"62956":{"abstract":"This project will use new techniques from computational optimization to design radiation therapy planning for cancer treatment. <br\/><br\/>Radiation therapy applies ionizing radiation to cancerous tissue, damaging the DNA and interfering with the ability of the cancerous cells to grow and divide. This also damages healthy cells, but they are more able to repair the damage and return to normal function. The therapy planning problem is to specify the shapes of the applied radiation beams, times of exposure, etc., to deliver a specified dose to the tumor but not an excessive dose to the surrounding healthy tissue. New medical devices allow much control over the characteristics of the radiation, thus allowing much scope for the therapy planning. However, the full potential of these devices to deliver optimal treatment plans has yet to be realized due to the complexity of the treatment design process. By using advanced modeling techniques, state-of-the-art optimization algorithms, and implementations on parallel computing platforms this project will provide radiation oncologists with important new computational tools for treatment planning. These tools will be flexible enough to adapt to the varying priorities of different planners and different patients and robust enough to give good solutions to the most difficult planning problems. The project involves collaboration between three researchers whose collective expertise encompasses radiation oncology modeling, optimization algorithms, and parallel implementations. It builds on previous collaborations of these researchers on treatment planning and on NSF-funded work on algorithms for solving large optimization problems.<br\/><br\/>The institutions involved in the project are the University of Wisconsin, the University of Maryland School of Medicine, and the University of Chicago.","title":"ITR\/AP: Collaborative Research: Cancer Treatment Plan Optimization","awardID":"0113045","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["358793"],"PO":["565272"]},"62846":{"abstract":"ITR Small Proposal<br\/>CCR-0112501<br\/>Blum, Rick<br\/><br\/>Transmit and receive antenna arrays used to form multiple-input multiple-output (MIMO) channels have shown great potential in isolated, single link communications without cochannel interference.<br\/>Provided the same number of transmit and receive antennas are used, recent research has shown that capacity scales linearly with the number of transmit antennas. This result has created an incredible<br\/>flurry of interest among researchers. While these MIMO systems have received extensive study for cases without cochannel interference, cases with cochannel interference have received much less<br\/>attention. Further, new simulation results indicate that cochannel interference can significantly degrade the overall capacity when MIMO channels are used in a cellular system in the same manner in which<br\/>they are used for cases without interference. The investigators study the properties of MIMO systems with<br\/>interference to develop new methods of using MIMO which adapt the transmission scheme to the interference environment. These new methods, called stream control algorithms, transmit several different streams, each one using a different transmit weight vector. The maximum number of streams that can be transmitted is equal to the minimum of the number of transmit and receive antennas. The exact number of streams chosen depends on the current sensed state of the interference environment. Preliminary results indicate that significant performance gains can be achieved in this manner. Using the well developed theory of power control, distributed algorithms are being developed to control the number of streams employed in a cellular system with cochannel interference. The use of space-time coding is also being studied in conjunction with stream control. Wireless channels with frequency selective fading, various correlation structures, and other practical degradations are being studied.","title":"ITR\/SI(CISE): MIMO Processing and Space-time Coding with Interference","awardID":"0112501","effectiveDate":"2001-09-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["380971"],"PO":["564898"]},"60789":{"abstract":"EIA-0103708<br\/>Mohammed J. Zaki<br\/>Rensselaer Polytechnic Institute<br\/><br\/>NGS Performance Mining of large-scale Data-Intensive Distributed Object Applications<br\/><br\/>The objective of the proposal is to develop a performance measurements-based run-time environment for supporting large data-intensive distributed object applications. The system will provide continuous and adaptive performance optimization via a combination of performance data mining, critical path discovery and speculative execution.<br\/><br\/>To address these challenges for next generation software systems we propose to develop the PERFMINER engine for the performance mining. PERFMINER, a system for continuous performance optimization via mining, will enable a distributed object system to: 1) discover its own critical path, 2) detect new opportunities for speculative processing, and 3) to facilitate modifying an object's behaviors (i.e., methods) at run-time in response to newly acquired knowledge.","title":"NGS: Performance Mining of Large-Scale Data-Intensive Distributed Object Applications","awardID":"0103708","effectiveDate":"2001-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"H228","name":"CIA"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"T029","name":"CIA-KDD WORKING GROUP"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V513","name":"CIA-KDD WORKING GROUP"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"V068","name":"CIA-KDD & TARGET CHARACHTERIZA"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"V203","name":"CIA-KDD WORKING GROUP"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"W295","name":"CIA-KNOWLEDGE DISC & DISSEMIN"}}],"PIcoPI":["430756","541895","541893"],"PO":["565136"]},"62879":{"abstract":"Proposal 0112654<br\/><br\/>Reliability Theory of Software Designed Using Components<br\/><br\/>Dick Hamlet, Portland State University<br\/><br\/><br\/>Defining, developing, and reusing software components is today accepted<br\/>as the best line of attack on the problem of expensive and unreliable<br\/>software systems. In other engineering disciplines, component-based<br\/>systems have been the key to rational design, in which engineers can<br\/>predict the behavior of complex systems before they are built and<br\/>tested. This research focuses on the quality of software components.<br\/>A foundational theory is developed to allow the designer of a system,<br\/>working from data sheets that describe proposed components, to estimate<br\/>the reliability of the system that will result.<br\/><br\/>Goals of this research are:<br\/>-- To develop a quantitative, mathematical description of the way in<br\/>which component reliability measurements can be made and later used for<br\/>calculating system reliability.<br\/>-- To experiment with the theory in simple, revealing cases, to expose<br\/>problems in the theory and improve it by experimental feedback.<br\/>-- To implement research-prototype support tools, particularly for the<br\/>system designer, that make experimentation easier.","title":"ITR\/SY: Reliability Theory of Software Designed using Components","awardID":"0112654","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":[161446],"PO":["564388"]},"64749":{"abstract":"The MavHome project views a smart home as an intelligent agent, which is able to perceive its environment through the use of sensors and act upon the environment through the use of actuators. The home has overall goals, such as minimizing the cost of maintaining the home and maximizing the comfort and productivity of its inhabitants. In order to meet these goals, the house must be able to reason about and adapt to information using knowledge about databases, machine learning, multiagent systems, robotics, smart sensors, wireless mobile computing, and multimedia computing. Smart homes can potentially minimize home operating costs in a time when utilities fees are becoming prohibitive, and can assist individuals with disabilities to lead independent lives. Through the university visitor program, minority recruitment, course development, and dissemination of results, the project will impact research and education in the area of \"smart space technologies.\"","title":"ITR\/IM+SI - MavHome: Development of an Intelligent Home Environment","awardID":"0121297","effectiveDate":"2001-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["564777","553596","547675","550149","338092"],"PO":["564456"]},"66729":{"abstract":"EIA-0130108<br\/>Lloyd M. Smith<br\/>University of Wisconsin-Madison<br\/><br\/>Title: Multiple-Word CNA Computing on Surfaces<br\/><br\/>Under this project tools are being developed to increase the computational generality of surface-based DNA computing. It is well known that for a computing model to be general, that is, capable of efficiently simulating algorithms used in conventional electronic computing, it must be able to efficiently simulate circuits. It has been shown theoretically that the surface-based approach, when using multiple words and the MARK, DESTROY-UNMARKED, UNMARK, and APPEND operations, is a generalizable approach to computing, but this has not been implemented experimentally. The necessary tools for such an implementation is being developed. Particular tasks, which are being addressed to this end, include:<br\/><br\/>-improved designs of sets of DNA \"words\" that do not interfere with one another in hybridization experiments and do not contain strong secondary structure motifs.<br\/><br\/>-methods for the efficient purification of colloidal gold nanoparticles and the implementation of surface-based DNA computing using such particles as supports. <br\/><br\/>-development of a new DESTROY-UNMARKED operation, multiple-word AND operation, and multiple-word APPEND-MARKED operation.","title":"Bio-QuBIC: Multiple-Word DNA Computing on Surfaces","awardID":"0130108","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["471123","369365","183023","183024"],"PO":["565223"]},"64309":{"abstract":"Scientific Visualization is fast becoming a key technology that provides scientists with insights that enable them to steer their numerical simulations towards solving previously unsolvable problems. However, the size of scientific datasets has witnessed exponential growth in the past few years. This sheer size often makes interactive exploration impossible, as only a small portion of data can fit into main memory at a time and the computation cost is often too high to run in real-time. Despite the importance of time-varying datasets, most previous research has focused on the visualization of steady-state data (i.e., data with only a single time step). This project will attack the challenges of large input sizes posed by time-varying data visualization. There are two important and promising research directions towards handling large-scale problems: data compression techniques and out-of-core techniques. This project will develop integrated lossless compression and out-of-core techniques for large time-varying data visualization, including isosurface extraction and direct volume rendering. It will mainly consider the class of irregular-grid volume datasets represented as tetrahedral meshes, which often arises in computational fluid dynamics, partial differential equation solvers, and other fields.<br\/><br\/>Specifically, the project will develop new lossless compression techniques for vertex coordinates and scalar values for tetrahedral time-varying volume data. It will also develop new out-of-core isosurface extraction and direct volume rendering techniques for tetrahedral time-varying volume data, and integrate the compression and out-of-core visualization techniques together under a unified infrastructure. The expected results would be a collection of new techniques and a unified, proof-of-the-concept visualization system that will minimize the disk space requirement and the visualization rendering time cost. If successful, the system will efficiently support full visualization functionalities (isosurface extraction and volume rendering) for time-varying datasets much larger than can fit in main memory, with performance expected to be independent of the main memory size available.","title":"VISUALIZATION: Integrated Compression and Out-of-Core Techniques for Large Time-Varying Data Visualization","awardID":"0118915","effectiveDate":"2001-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}}],"PIcoPI":["559652","533228","292992"],"PO":["565272"]},"80501":{"abstract":"","title":"ITR: Development and Evaluation of a Model Information Technology Training and Education Program for Rural Communities","awardID":"0296091","effectiveDate":"2001-09-01","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1359","name":"RES EXP FOR TEACHERS(RET)-SITE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["401344"],"PO":["564181"]},"62912":{"abstract":"This project will develop new methods for the efficient dissemination of the data collected by wireless<br\/>sensor networks. With recent and projected advances in small, low cost microelectronic and micro-electromechanical sensors, it is easy to envision that a large array of sensors, distributed over an<br\/>appropriate region, will be able to measure the spatial and temporal variations of important attribute<br\/>field such as temperature, moisture, sound, light, gas concentrations, etc.. However, to realize the<br\/>benefits of such arrays, wireless communication networks must be devised that with low power encode<br\/>and disseminate the large amounts of data they generate. With this as the goal, the project will<br\/>develop new methods of distributed data compression and data dissemination for dense sensor arrays,<br\/>that is, for arrays whose sensors are so close that their measurements are highly correlated. One thesis<br\/>of this project is that the correlations in such arrays can be exploited in order to make the network<br\/>operate essentially as efficiently as a sparse sensor network, while having the additional advantages of<br\/>being resilient to sensor failures and permitting the attribute field to be measured adaptively or with<br\/>higher spatial resolution. Another thesis is that the data compression and dissemination issues for<br\/>such networks are deeply intertwined. Accordingly, the project focuses on the joint design of such.<br\/>For example, it seeks methodology for tailoring distributed data compression methods to partcular<br\/>dissemination strategies, and vice versa. In the process, it proposed to learn how the performance of<br\/>sensor networks depends on a variety of issues such as the number and placement of sensors.","title":"ITR\/SI+IM (CISE):Distributed Data Compression and Dissemination for Wireless Sensor Networks","awardID":"0112801","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["381337","517933"],"PO":["292741"]},"80578":{"abstract":"","title":"ITR: New Approaches to Human Capital Development through Information Technology Research","awardID":"0296169","effectiveDate":"2001-09-15","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1359","name":"RES EXP FOR TEACHERS(RET)-SITE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[209826,"425870","353752","541641","542299"],"PO":["564181"]},"62923":{"abstract":"The proposed work focuses on development of modular adaptable software for vision-based human-computer interaction. The key idea is to use local visual interaction cues on a video stream - mono or stereo, 2D or 3D - shared between the user and computer. The use of such cues has a number of advantages, such as limiting the processing to only those parts of the image where interaction takes place, allowing image processing to be dynamically driven by the interaction, and an easily parameterized modular basis for software development. Questions of how visual interaction cues can be flexibly defined and robustly detected based on local informaiton will be explored.","title":"ITR\/SY: Software Systems for Vision-Based Spatial Interaction","awardID":"0112882","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["531055"],"PO":["234178"]},"62946":{"abstract":"Future generation mobile wireless communication systems (third generation<br\/>and beyond) are expected to provide high data rates, accomodate highly<br\/>mobile users, and support a wide variety of services including data, voice,<br\/>video and interactive multimedia. Power (battery) limitations and<br\/>the scarcity of radio spectrum (relative to the ambitions of such services)<br\/>will dictate the need for cellular networks in which these resources<br\/>must be used highly efficiently so as to support the continued growth<br\/>in demand for wireless services into the future. The<br\/>essential infrastructure required at the physical<br\/>layer to fulfill this demand is a power and bandwidth efficient,<br\/>multi-antenna, multi-user wireless communications technology.<br\/><br\/>The investigators of this project will develop several key aspects of a<br\/>theory of multi-user, multi-transmit antenna communication through a study<br\/>of high-performance, interference resistant receivers, signature sequence<br\/>designs and multi-user signal constellation optimization. Their goal is to<br\/>realize, through simple system design, the power and spectral efficiency<br\/>trade-offs that are achievable for multi-antenna wireless communications<br\/>over fading channels. While emphasizing fundamental limits, the<br\/>investigators will also focus on complexity constrained systems as well.<br\/>They will develop results in the theory of multi-user detection and<br\/>signature sequence optimization for multiple receive antennas for overloaded<br\/>CDMA systems. Generalization of these results will be pursued to coded<br\/>modulation and multiple transmit (and receive) antenna systems in order to<br\/>further improve the performance and\/or achievable spectral efficiencies<br\/>through more sophisticated signaling strategies combined with sub-optimal,<br\/>complexity-constrained, high-performance multi-user decoding methods.","title":"ITR\/SI: Multi-Antenna, Multi-User Communications","awardID":"0112977","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}}],"PIcoPI":["508378"],"PO":["348215"]},"64805":{"abstract":"This ITR research medium research project will put together an interdisciplinary research group whose aim will be to develop a new modeling and a solution framework that nontrivially integrates a wide class of solution methods, including mathematical programming, constraint satisfaction, and a variety of heuristic algorithms. The objective of this framework is to be able to effectively tackle challenging engineering optimization problems. The group will be composed of faculty and students from Computer Science, Operations Research and Chemical Engineering. The key goal for the group will be to identify principles according to which algorithms can be integrated. These principles will then form the basis for a modeling language that guides the integration. Furthermore, new solution techniques will be developed for hybrid models and for global optimization of nonconvex discrete\/continuous problems.<br\/><br\/>Two paths of integration will be investigated. One is to exploit problem structure at the modeling stage by using an idea developed in constraint logic programming: namely, by writing the problem in the form of \"global\" constraints that individually invoke algorithms tailored to the special structure of each constraint. A second is to make a fundamental distinction, at both the modeling and solution stage, between two types of algorithms: checkers and solvers. The research will be applied primarily to the optimization of process systems, with a focus on synthesis of reactive distillation systems and the integrated testing of new products and batch manufacturing. Because these problems have both discrete and continuous aspects, and the second involves difficult nonlinearities, they provide a natural context for combining optimization and logic-based methods. However, the research will develop a general-purpose approach to modeling and solution, rather than one that is exclusively for process systems applications.","title":"ITR\/AP: Model-Based Integration of Methods for the Optimization of Process Systems","awardID":"0121497","effectiveDate":"2001-09-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1403","name":"PROCESS & REACTION ENGINEERING"}}],"PIcoPI":["492978","506987"],"PO":["565272"]},"61307":{"abstract":"Java programmers rely on clumsy \"erasure\" idiom to define generic operations: a generic class is represented by conventional classes where all references to type parameters have been replaced by the type Object. Programs that rely on this idiom must repeatedly cast the results of generic operations to the types of omitted type parameters. Generic operations in Java are slower than their non-generic counterparts because this idiom introduces a level of indirection in the representation of type parameters instantiated as primitive types.<br\/><br\/>The investigator has recently completed the construction of a prototype compiler for NexGen, a Java extension supporting genericity designed by the investigator and Guy Steele. The compiler relies on the erasure idiom to implement genericity and hence does not improve the performance of computations involving generic classes.<br\/><br\/>To produce good performance for generic Java, a compiler must eliminate indirection in the representation of generic class instances. The requisite transformation is called {\\em whole program analysis} because it is invalid if any program operation depends on the address of an inlined object. Fortunately, there is a nearly linear algorithm based on previous work by the investigator on concrete type analysis that can determine if a given object field can be inlined.<br\/><br\/>This project will develop a new optimizing compiler for NextGen that uses concrete type analysis to inline the parametric fields of generic classes.","title":"Scalable Optimization of Generic Java","awardID":"0105596","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["495364"],"PO":["565272"]},"64739":{"abstract":"The objective of this project is to advance science in information management, focusing in particular on geospatial information. It addresses the development of concepts, algorithms, and system architectures to enable users on a grid to query, analyze, and contribute to multivariate, quality-aware geospatial information. The approach consists of three complementary research areas: (1) establishing a statistical framework for assessing geospatial data quality; (2) developing uncertainty-based query processing capabilities; and (3) supporting the development of space- and accuracy-aware adaptive systems for geospatial datasets. The results of this project will support the extension of the concept of the computational grid to facilitate ubiquitous access, interaction, and contributions of quality-aware next generation geospatial information. By developing novel query processes as well as quality and similarity metrics the project aims to enable the integration and use of large collections of disperse information of varying quality and accuracy. This supports the evolution of a novel geocomputational paradigm, moving away from current standards-driven approaches to an inclusive, adaptive system, with example potential applications in mobile computing, bioinformatics, and geographic information systems. This experimental research is linked to educational activities in three different academic programs among the three participating sites. The outreach activities of this project include collaboration with U.S. federal agencies involved in geospatial data collection, an international partner (Brazil's National Institute for Space Research), and the organization of a 2-day workshop with the participation of U.S. and international experts.","title":"ITR\/IM: Enabling the Creation and Use of GeoGrids for Next Generation Geospatial Information","awardID":"0121269","effectiveDate":"2001-09-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["457136","559496","391834","376530","258283"],"PO":["563751"]},"60801":{"abstract":"EIA-0103741<br\/>Josep Torrellas<br\/>University of Illinois<br\/><br\/>NGS: Collaborative Research: SmartApps: An Application Centric Approach to High Performance Computing<br\/><br\/>The objective of this proposal is to develop new methods that allows runtime performance optimization by an enhanced monitoring, resource modeling, evaluation and remapping of the application at runtime, depending on runtime resources and application performance. The specific approaches to be pursued include application algorithm adaptation, run-time software optimization, system configuration selection and tuning reconfigurable OS services.","title":"NGS: Collaborative Research: SmartApps: An Application Centric Approach to High Performance Computing","awardID":"0103741","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["485665"],"PO":["301532"]},"80535":{"abstract":"","title":"CONACyT: Solving Visibility-Based Mobile Robotics Tasks Using Minimal Representations","awardID":"0296126","effectiveDate":"2001-09-15","expirationDate":"2004-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["553248"],"PO":["234178"]},"80546":{"abstract":"","title":"CAREER: Interprocedural Compilers for Distributed Address Space Machines","awardID":"0296137","effectiveDate":"2001-09-01","expirationDate":"2004-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}}],"PIcoPI":["558505"],"PO":["551992"]},"62924":{"abstract":"The modeling of complex systems using the concept of constrained objects is investigated. A constrained object is one whose internal state is regulated by a set of invariants, or constraints. When several constrained objects are aggregated to form a complex object, their internal states might further have to satisfy interface constraints. The resultant behavior of the complex object is determined using logical inference and constraint satisfaction. Thus, constrained objects are a declarative counterpart of traditional objects (found <br\/>in object-oriented languages). The proposed modeling paradigm has diverse uses, including engineering and organizational modeling, and supports constraints as well as preferences. The computational model <br\/>for constrained objects provides constraint satisfaction, optimization, and relaxation techniques. A visual representation for constrained objects is also provided in such a way that the components of the visual <br\/>form have logical counterparts in the underlying model. Research areas of interest include language design, execution, and applicatons. In particular, issues arising in model revision (i.e., incremental constraint satisfaction) and model inconsistency (i.e., fault diagnosis) will be investigated. The results from this research will be incorporated in the modeling environment, which is expected to make a significant advance over current modeling tools for engineering design.","title":"ITR\/SY: Constrained Objects for Modeling Complex Systems","awardID":"0112888","effectiveDate":"2001-09-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["284791"],"PO":["564388"]}}