{"202246":{"abstract":"Online deliberation seeks to improve group decision making by accessing diverse expertise and experience, informing and marshaling evidence in a fruitful exchange of ideas. Successful deliberation environments can bring great benefits, such as broadening participation, tapping a greater range of knowledge, testing ideas against each other, and fostering appreciation of other views. However, for large and complex problem spaces that generate extensive discussion, it is difficult for would-be participants to find where they could best make a contribution, to understand how various contributions fit together, or to grasp the contingencies between needs and contributions. <br\/><br\/>To address this problem, this project will develop and test a system that provides a personalized view of a large information space that reveals the shape and foci of contributions in a way that reflects the goals, expertise, and interests of each user. The system will allow participants to see how their goals and interests match current themes and to find groups of people and related sets of contributions that would be of interest. To do this, the research will integrate insights from sociolinguistics with state-of-the-art latent variable modeling techniques from the field of language technologies to extend prior work in the areas of perspective and stance modeling in order to identify the necessary structure in textual data to enable personalized information extraction, summarization, and presentation. <br\/><br\/>The project includes archival data analysis to develop algorithms and data representations, experiments to test the value to users of various ways of representing topics and social networks, a staged series of deployments for formative and summative evaluation, and the development of tool architecture and user interfaces to support experimentation and deployment. Through these activities, the investigators will systematically explore the effects of design decisions on participation, navigability and the nature of the deliberation.","title":"HCC: Medium: Personalized information access for online deliberation systems","awardID":"1302522","effectiveDate":"2013-08-01","expirationDate":"2017-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["554179","551802"],"PO":["565342"]},"204677":{"abstract":"In any design or learning activity, exploration is a key component. Significant research and conventional wisdom show that the best way to achieve a high-quality design is to explore multiple variations and iteratively evaluate them. When novices learn a new skill or system, they must explore and practice the available options. Similarly, when experts try to understand and improve an existing design, they must explore different approaches to modifying its behavior. Unfortunately, exploration is risky, error-prone, and cumbersome using today's tools. For instance, when users decide their current design is not effective, the only mechanisms available for selectively backtracking out of changes are linear undo and version control, which make it difficult to isolate backtracking to specific edits, or else users must manually remove undesired edits, which is slow and fallible. Further, today's tools do not support comparing two variants of a design or combining elements from multiple variants. Research is showing that these manual processes inhibit exploration, making users and designs less effective.<br\/><br\/>To address these problems PIs from four partner institutions have come together to undertake a research program that is both broad and deep, focusing on the creation and management of variations during a system's implementation and evolution. The goal is to discover new theories, algorithms, visualizations, and tools that support variations in code. The team will evaluate all of their approaches through lab and field studies, and they will investigate how users can be educated in more effective ways to work with variations. Based on a choice calculus for representing variations in software, they will develop a theory for formally defining and reasoning about variations. They will leverage theories of human behavior such as Minimalist Learning, Attention Investment, and Information Foraging, to develop a theory of Variation Foraging. They will develop an infrastructure including multiple levels of transcripts of users' editing operations that will support a novel form of selective undo and enable users to investigate their existing variants, return to any previous variant, and mix and match elements from multiple variants. They will develop algorithms to enable recording of interactions with variants so they can be explored and reused to explore and test new variants; these recordings will be augmented with automatically created data to help users understand behaviors they have not explicitly explored. Using this infrastructure the PIs will invent visualizations, search facilities, and interaction techniques that provide effective ways for users to find, understand, explore, reuse and create variants, and be able to ask \"why\" questions to understand the differences among variations of a system. For novices, an \"Idea Garden\" will help them explore new strategies for identifying which variations can help solve a problem and how to implement them.<br\/><br\/>Broader Impacts: This research will enhance infrastructure for research and education by producing an integrated, open source web development environment for use by researchers and the world. The work will therefore benefit society by empowering the tens of millions of end-user programmers to creatively build content and applications for the web. The PIs will advance discovery while promoting learning by integrating their research into undergraduate courses on creativity and software engineering, and by supporting summer camps for at least 300 high school students per year. Project outcomes will be disseminated to researchers through publications and presentations, to computing educators through the above-mentioned camps and the National Girls Collaborative Project, and through public deployment. The PIs expect high interest because the work will be based on JavaScript, which is today's most popular programming language and for which there is a high demand for better tools. The research will address underrepresentation via its focus on investigating how to support both male and female end-user programmers, by involving high-school members of underrepresented groups, and by engaging many of the PIs? female students.","title":"HCC: Large: Collaborative Research: Variations to Support Exploratory Programming","awardID":"1314365","effectiveDate":"2013-08-01","expirationDate":"2017-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[548131,548132],"PO":["565227"]},"202257":{"abstract":"The classical approach to wireless communication is to isolate communication links by maximizing signal strength and minimizing interference between users. This simple philosophy is supported by a rich theoretical foundation which has inspired powerful coding techniques and protocols that lie at the heart of modern wireless systems. However, these systems have recently become victims of their own success as the rising density and data requirements of wireless devices have led to a surge in interference. Fortunately, an emerging body of work indicates that the phenomenon of interference may in fact represent an untapped opportunity for increasing the spectral and energy efficiency of next-generation wireless systems. Although many interference-aware communication strategies have been proposed in the literature, the promised gains have been mostly limited to the theoretical realm. <br\/><br\/>The objective of this project is to create practical interference-aware wireless protocols that can operate near the performance predicted by theoretical bounds in terms of throughput, energy efficiency, and reliability. The project is organized into three complementary thrusts that encompass theory, algorithms, and practice. The first thrust investigates lattice-based constellations and low-complexity codes for the compute-and-forward strategy, which enables receivers to decode linear combinations of transmitted codewords. Compute-and-forward can in turn be used as a building block for realizing interference-aware protocols such as physical-layer network coding and multiple-user MIMO (multi-input-uulti-output) systems. The second thrust aims to implement these protocols on a three-node WARP (Wireless Open-Access Research Platform) testbed. A series of carefully designed experiments will be used to compare the performance of interference-aware strategies while accounting for overhead costs. The third thrust leverages the data collected from these experiments to revise channel models to capture key features that impact the performance of interference-aware strategies such as asynchronism and channel fluctuations. These models will be used to revisit the theoretical foundations of interference-aware strategies and tailor them to the channels encountered in practice. This project features several outreach efforts including undergraduate research experiences connected to the WARP testbed and a public repository of training modules and videos.","title":"CIF: Medium: Collaborative Research: Interference-Aware Cooperation via Structured Codes: Creating an Empirical Cycle","awardID":"1302616","effectiveDate":"2013-08-01","expirationDate":"2017-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["551055"],"PO":["564924"]},"205535":{"abstract":"Scientific visualization has become an indispensable tool for visual analysis of data generated from simulations and experiments across a wide variety of fields. Although there have been substantial advances in developing novel algorithms and techniques for processing, managing and rendering scientific datasets, several critical challenges still remain. These challenges include solving the inherent occlusion and clutter problem when visualizing large three-dimensional scalar and vector fields, examining complex data relationships and tracking their changes over time for time-varying multivariate data, and gaining a comprehensive overview and acquiring full control of data navigation to glean critical insights. The ever-growing size and complexity of data produced only exacerbate these challenges. To enable discovery from big scientific data, there is a need to seek a new perspective on data abstraction and relationship exploration by going beyond the traditional boundary of scientific visualization and fully incorporating information visualization techniques for effective visual data analytics. While there are encouraging, isolated examples of applying information visualization techniques such as parallel coordinates and treemaps to scientific data analysis, leveraging the more generalized and familiar form of graphs to address a wider range of scientific visualization problems at greater extent has not been fully studied. In this project, the PIs' goal is to establish systematic graph-based techniques to investigate large-scale scalar and vector scientific datasets. To this end the team pursues three major tasks: (1) exploring core graph-based techniques to analyze and explore time-varying multivariate scalar and vector field data; (2) developing scalable parallel algorithms for constructing and visualizing large graphs for scientific visualization; and (3) conducting a formal user study using the choice behavior model and tackling real problems from application domains with expert evaluation.<br\/><br\/>Because scientific visualization plays a key role in many scientific, engineering and medical fields, the potential benefits from generalized graph-based visual analytics tools are far reaching. The general ideas developed will directly benefit the understanding of volumetric scientific datasets including scalar and vector field data, time-varying and multivariate data. They will also impact the understanding of data in other forms such as adaptive mesh refinement, unstructured grid and point-based data. Since this work is a departure from traditional approaches, it could be transformative by providing a completely new way of exploring and analyzing big scientific data. From a scientific perspective, the potential impact is a new class of techniques for knowledge discovery. This project will maximize its outcomes through close collaboration with combustion and biomedical scientists. It will produce results in various forms which are publicized at the project website (http:\/\/www.cs.mtu.edu\/~chaoliw\/nsf13-graph.htm). The project provides training for graduate, undergraduate and under-represented students in big data computing and visualization. Public outreach activities are planned, including summer programs for middle and high school students, and tutorials or contests for researchers at premier visualization conferences.","title":"CGV: Small: Graph-Based Techniques for Visual Analytics of Big Scientific Data","awardID":"1319363","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[550367,550368,550369],"PO":["563751"]},"202268":{"abstract":"Much of today's computational capability is housed in massive cloud computing infrastructures sometimes known as \"Warehouse Scale Computers.\" This transition has given rise to a new class of emerging applications that run on hundreds of thousands of powerful cores, and access petabytes or exabytes of storage; these applications include web search, media streaming, big data analysis, etc. This centralization of the world's computing means that inefficiencies in those systems are magnified to a high degree -- in other words, if we can improve the efficiency of those systems, we measurably improve the efficiency (improve performance, reduce energy drain) of the world's computing infrastructure. This research addresses several sources of inefficiency, including increasingly inaccurate assumptions of hardware homogeneity, unpredictable interference between applications, and poor models of low-level resource sharing. <br\/><br\/>This research addresses these inefficiencies by (1) creating a heterogeneity-aware execution framework for cloud platforms that not only accounts for the heterogeneous capabilities of the hardware that are expected to increase over time, but intentionally employs heterogeneity (at multiple levels) to improve efficiency in running diverse workloads; (2) creating a holistic runtime system for shared resource management that accounts for resource sharing at all levels, including low-level sharing on CMPs and multithreaded cores, allowing threads to be more aggressively co-scheduled; and (3) creating new precise prediction models for performance and quality of service that can drive more intelligent scheduling decisions.","title":"SHF: Medium: Bridging the Software\/Hardware Gap Towards Efficient, Heterogeneous, and Predictable Datacenters","awardID":"1302682","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":[542069,"559984","565254"],"PO":["366560"]},"205469":{"abstract":"As power dissipation on a single-chip is increasing at an alarming rate due to massive integration of digital circuits, multicore design has become the only technique to scale performance. Multicores with tens to hundreds of cores are already available in the marketplace and future projections call for thousands of cores on the chip. To achieve scalable computing performance from the multicores, the communication between cores should also scale in bandwidth while significantly reducing the power consumption. Scaling the performance of the on-chip communication fabric, called the Network-on-Chip (NoC), has proven to be a significant challenge with traditional metallic interconnects due to fundamental signaling issues such as power dissipation, electromagnetic interference, crosstalk and reflections. Several studies and roadmaps have indicated that disruptive technology solutions such as photonics have the potential to alleviate the critical bandwidth, power and latency challenges of future multicores. This research seeks to exploit the unique advantages of photonic interconnects and 3D stacking technologies to develop scalable, energy-efficient, bandwidth-reconfigurable and reliable NoCs for future multicores. There are three goals of the proposed research: first, it will investigate and develop 3D stacked photonic NoC architectures and topologies that maximize performance and improve energy-efficiency; second, it will develop runtime reconfiguration techniques that can adapt the network to the communication needs of the application, thereby improving performance on a per-application basis; and third, it will result in an extensive modeling and simulation framework to be used for designing and validating future photonic NoC architectures.<br\/><br\/>This research has far reaching broader impacts. This research is uniquely positioned to leverage two emerging technologies namely photonics and 3D stacking to meet the multicore challenge and will significantly benefit society. The proposed research is essential to continue the growth of computing performance that our society depends upon, and will result in digital devices ranging from smartphones to laptops with faster response time and improved reliability. By investigating the design of energy-efficient and high-bandwidth photonic-3D NoC architectures, this proposal describes a transformative and viable approach to combine technology, algorithm and applications' research to enable building scalable multicores. The cross-cutting nature of this research will foster new research directions in several areas, spanning technology\/energy-aware NoC design, novel computer architectures, and cutting-edge modeling and simulations tools for emerging technologies. This research will also play a major role in education by integrating discovery with teaching and training. Several graduate students will be directly involved with all phases of the project from which the core parts of their dissertations and theses will be derived. It will also benefit a wider audience of graduate and undergraduate students by incorporating the new research into several courses on computer architecture and parallel processing taught by the PIs. Finally, the results and findings of the proposed research will be disseminated to researchers, engineers and educators through technical publications and presentations.","title":"SHF: Small: Collaborative Research: Power-Efficient and Reliable 3D Stacked Reconfigurable Photonic Network-on-Chips for Scalable Multicore Architectures","awardID":"1318981","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["559859"],"PO":["565319"]},"210793":{"abstract":"Researchers and providers alike are recognizing that human-centric smart environments can provide health monitoring services and support aging in place through adaptive interventions. The need for the development of such technologies is underscored by the aging of the population, the cost of formal health care, and the importance that individuals place on remaining independent in their own homes. The goal of this project is to design, implement, and evaluate in-home techniques for generating reports of activities and social interactions that are useful for monitoring well being and for automating intervention strategies for persons with dementia. The plan is to design machine learning techniques that make effective use of sensor data to perform automated activity monitoring and prompting-based interventions that are beneficial for the residents as well as for their caregivers and family. The environment is human-centric because it learns information about its human residents and uses this information to provide activity-aware monitoring and intervention services. By transforming everyday environments into smart environments, many older adults with cognitive and physical impairment can lead independent lives in their own homes. A key component of this project is an evaluation of the technologies in actual homes with volunteer older adults and thus will assess the technologies for acceptance with the target population. <br\/><br\/>This project addresses NSF?s Smart Health and Wellbeing goal of leveraging computational expertise leading to fundamental advances in the development of algorithms to create improvements in safe, effective, and patient-centered health and wellness services. Through design of a Gerontechnology class we are training students to design and use these technologies. This effort includes REU and IGERT students in the research project, which involves students from underrepresented groups in this multidisciplinary, collaborative effort. To facility community-wide use, comparison and collaboration, all of our datasets, tools, and course materials will be disseminated from our project web page.","title":"SHB: Medium: Collaborative Research: Crafting a Human-Centric Environment to Support Human Health Needs","awardID":"1404673","effectiveDate":"2013-08-31","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":["564777"],"PO":[564768]},"210397":{"abstract":"The method of Groebner bases has become one of the most important techniques in providing an exact solution of nonlinear problems in multivariate polynomial ideal theory, computational algebra and elimination theory, in solving systems of algebraic equations, and in many other related areas. It is also being fruitfully used in a variety of seemingly unrelated research areas such as geometric theorem proving, integer programming, solid modeling, and engineering. <br\/><br\/>This project will develop the theories and algorithms for an efficient framework of PSPACE Groebner basis computation in Boolean rings and then apply this framework to temporal logic reasoning and model checking. The theoretical and algorithmic results of this research should have a broader impact on symbolic computation, temporal logic reasoning and related areas such as automated verification of hardware and software in model checking. Symbolic computation is an active and rich area with enormous activity and progress in the last twenty years. A new approach to temporal logic reasoning and model checking making use of results from symbolic computation seems to have considerable promise, both as a supplement to existing methods and as a way to bring a large body of powerful mathematical machinery to bear on the model checking problem.","title":"AF: Small: Collaborative Research: Efficient Groebner Basis Computation in Boolean Rings for Temporal Logic Reasoning and Model Checking","awardID":"1355991","effectiveDate":"2013-08-19","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":[563805],"PO":["565157"]},"204732":{"abstract":"Most cryptographic applications crucially rely on secret keys that are chosen randomly and are unknown to an attacker. Unfortunately, the process of deriving secret keys in practice is often difficult, error-prone and riddled with security vulnerabilities. Badly generated keys offer a prevalent source of attacks that render complex cryptographic applications completely insecure, despite their sophisticated design and rigorous mathematical analysis. Even though key derivation plays a central role in the security landscape, it has received surprisingly little formal study within the cryptographic community, leading to a large disconnect between the theory and practice.<br\/><br\/>In this project, several important scenarios for key derivation are examined for their capability to improve security with provable guarantees, including the use of random number generators (RNGs), passwords, and biometrics. In particular:<br\/><br\/>- How RNGs are designed to properly combine the entropy gathering, randomness extraction and pseudorandom generation modules, while achieving the best possible subset of clearly defined security properties against a variety of adversarial scenarios.<br\/><br\/>- How to reduce the effectiveness of ?offline dictionary attacks? when generating keys from passwords.<br\/><br\/>- How biometrics can be safely reused to generate many secret keys across many applications raises several interesting questions, combining cryptographic security properties with those of error-correcting codes.","title":"TWC: Medium: Collaborative: The Theory and Practice of Key Derivation","awardID":"1314722","effectiveDate":"2013-08-01","expirationDate":"2017-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["562008"],"PO":["565239"]},"205832":{"abstract":"The storage and transmission of digital information is now ubiquitous in our society and plays a valuable role in the modern information-technology infrastructure. Error-correcting codes are a key part of infrastructure components that efficiently and reliably store and transmit digital information. Spatial coupling is a new technique for designing error-correcting codes that has been shown in some cases to achieve near-optimal performance with low-complexity decoding. This research focuses on the design and analysis of innovative techniques for the storage and transmission of digital information based on spatially-coupled codes.<br\/><br\/>The research is broken into three broad thrusts. The first thrust focuses on generalizing recent proof techniques for spatially-coupled codes to include a wide class of inference problems on spatially-coupled graphical models. The second thrust considers the design of universal spatially-coupled codes for multiuser communication problems including the noisy Slepian-Wolf problem and multiple-access communication. The third thrust targets source and channel coding problems with side information and focuses on nested spatially-coupled codes with enhanced message-passing decoding.<br\/><br\/>Spatial coupling also appears to be a general principle that is broadly applicable to problems involving message passing and inference on factor graphs. Therefore, this research is expected to have an impact on science and engineering disciplines beyond communications such as signal processing and machine learning.","title":"CIF:Small: Design and Analysis of Spatially-Coupled Coding Systems","awardID":"1320924","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":[551055,551056],"PO":["564924"]},"205601":{"abstract":"As software pervades our society and lives, failures due to software<br\/>bugs become increasingly costly. Scalable approaches for<br\/>systematically checking software to find crucial bugs hold a key to<br\/>delivering higher quality software at a lower cost. Mera is a<br\/>methodology to scale model checking and symbolic execution which are two<br\/>powerful approaches for systematic software analysis and known to be<br\/>computationally expensive.<br\/><br\/>The project builds on two novel concepts: memoization, which allows<br\/>re-using computations performed across different checks to amortize<br\/>the cost of software analysis; and ranging, which allows distributing<br\/>the analysis into sub-problems of lesser complexity, which can be<br\/>solved separately and efficiently. Mera consists of three research<br\/>thrusts. First, the core memoization and ranging techniques for model<br\/>checking and symbolic execution are developed. Second, these<br\/>techniques are optimized in the context of different kinds of changes,<br\/>like the program code, expected properties, or analysis search-depth<br\/>parameters. Third, these techniques are adapted to effectively<br\/>utilize available resources for parallel computation using static and<br\/>dynamic strategies, such as work stealing. Mera will help improve<br\/>software quality and reliability thus holding the potential to provide<br\/>substantial economic benefits and to improve our quality of life.","title":"SHF: Small: Collaborative Research: Mera: Memoized Ranged Systematic Software Analyses","awardID":"1319688","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[550525],"PO":["565264"]},"205722":{"abstract":"The problem of matching representations of one set of objects, e.g., their images, to representations of another set of objects that achieves an optimal global measure of overlap (goodness of match) is ubiquitous in computer science, and remains a fundamental challenge in areas such as machine learning, computer vision, and computational biology. While some cases are solvable in polynomial time, a majority of those encountered in practice are computationally intractable - NP-hard. This research will exploit the fact that in many matching problems of interest the space to be optimized over has the (algebraic) structure of group, which allows one to leverage an entire spectrum of ideas from abstract algebra, including non-commutative harmonic analysis and fast Fourier transforms on groups. In addition to yielding efficient optimization schemes in several important cases, this algebraic approach has the potential to serve as a basis for developing novel matching algorithms and suggest new approaches for certain classes of combinatorial optimization problems. <br\/><br\/>The proposed research has four main goals: to design faster general purpose harmonic analysis-based quadratic assignment problem (QAP) solvers and apply these to alignment and matching problems; to develop \"tailored\" QAP solution methods by coupling them to a learning component, which leverages training data to solve subsequent QAP instances much more efficiently; to design multiresolution analysis-based algorithms which yield global solutions to multi-object tracking and matching problems; and, to implement a flexible open-source library which offers a wide variety of harmonic analysis functionality (with support for wavelet and other transforms) to encourage experimentation on a broad class of inference and optimization problems. This project will yield a powerful set of algorithms and open-source software that can be used by researcher in areas of machine learning, computer vision, and optimization.","title":"III: Small: Collaborative Research: Solving Matching Problems in Machine Learning with Non-commutative Harmonic Analysis","awardID":"1320344","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[550801],"PO":["564898"]},"204754":{"abstract":"Cloud computing allows users to delegate data and computation to cloud providers, at the cost of giving up physical control of their computing infrastructure. An attacker with physical access to the computing platform can perform various physical attacks, referred to as digital insertion and observation attacks, which include probing memory buses, tampering with memory, and cold-boot style attacks. While memory encryption can prevent direct leakage of data under digital observation, memory access patterns to even encrypted data may leak sensitive information. This work will allow organizations to securely outsource their computing infrastructure to an untrusted cloud provider, while preserving a similar level of security as if hosting the infrastructure in house<br\/><br\/>This project will develop DIORE (Digital Insertion and Observation Resistant Execution) which is a combined hardware software platform immune to digital insertion and observation attacks. DIORE provides memory-trace oblivious execution, relying on efficient hardware implementations of Oblivious RAM, and novel compiler techniques for partitioning programs such that Oblivious RAM accesses are minimized. This ensures that an adversary with access to a program execution's memory trace learns nothing about the code or data other than what is revealed intentionally. DIORE opens up possibilities for new cloud applications involving sensitive information such as genomic, medical, or financial data -- domains that are considered too privacy sensitive for today's cloud.","title":"TWC: Medium: Collaborative: DIORE: Digital Insertion and Observation Resistant Execution","awardID":"1314857","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[548322,"550282",548324],"PO":["565264"]},"205756":{"abstract":"Machine learning algorithms cannot \"think on their feet\". When applied in practice, most approaches developed using traditional machine learning techniques wait for an entire input to arrive before they are able to provide an answer or react. While sufficient for some tasks, this is inappropriate for a large class of problems that require more immediate or incremental responses. This project develops new algorithms to address machine learning problems that require an algorithm to \"think on its feet\". These algorithms combine guesses about what input is likely appear in the future with actions that the algorithm should take now to provide useful, effective output in a timely fashion.<br\/><br\/>One application of these new methods is simultaneous translation. This is the problem of taking problem of \"observing\" a sentence one word at a time in a foreign language, such as German, and providing a real-time running translation in a target language (like English). This is particularly difficult for language pairs that have significant syntactic divergences, such as object-verb order differences between foreign languages like German or Japanese (verb final) and target languages like English (verb medial). Like human simultaneous translators, machine learning algorithms must learn to predict the words that will appear at the end of a sentence. The project facilitates this prediction using a framework that combined word prediction and machine translation system.<br\/><br\/>The project also uses the newly developed algorithms in academic settings to provide significant outreach to high school students and undergraduates, particularly in underrepresented communities.","title":"RI: Small: Bayesian Thinking on Your Feet---Embedding Generative Models in Reinforcement Learning for Sequentially Revealed Data","awardID":"1320538","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[550878,550879],"PO":["565215"]},"204678":{"abstract":"In any design or learning activity, exploration is a key component. Significant research and conventional wisdom show that the best way to achieve a high-quality design is to explore multiple variations and iteratively evaluate them. When novices learn a new skill or system, they must explore and practice the available options. Similarly, when experts try to understand and improve an existing design, they must explore different approaches to modifying its behavior. Unfortunately, exploration is risky, error-prone, and cumbersome using today's tools. For instance, when users decide their current design is not effective, the only mechanisms available for selectively backtracking out of changes are linear undo and version control, which make it difficult to isolate backtracking to specific edits, or else users must manually remove undesired edits, which is slow and fallible. Further, today's tools do not support comparing two variants of a design or combining elements from multiple variants. Research is showing that these manual processes inhibit exploration, making users and designs less effective.<br\/><br\/>To address these problems PIs from four partner institutions have come together to undertake a research program that is both broad and deep, focusing on the creation and management of variations during a system's implementation and evolution. The goal is to discover new theories, algorithms, visualizations, and tools that support variations in code. The team will evaluate all of their approaches through lab and field studies, and they will investigate how users can be educated in more effective ways to work with variations. Based on a choice calculus for representing variations in software, they will develop a theory for formally defining and reasoning about variations. They will leverage theories of human behavior such as Minimalist Learning, Attention Investment, and Information Foraging, to develop a theory of Variation Foraging. They will develop an infrastructure including multiple levels of transcripts of users' editing operations that will support a novel form of selective undo and enable users to investigate their existing variants, return to any previous variant, and mix and match elements from multiple variants. They will develop algorithms to enable recording of interactions with variants so they can be explored and reused to explore and test new variants; these recordings will be augmented with automatically created data to help users understand behaviors they have not explicitly explored. Using this infrastructure the PIs will invent visualizations, search facilities, and interaction techniques that provide effective ways for users to find, understand, explore, reuse and create variants, and be able to ask \"why\" questions to understand the differences among variations of a system. For novices, an \"Idea Garden\" will help them explore new strategies for identifying which variations can help solve a problem and how to implement them.<br\/><br\/>Broader Impacts: This research will enhance infrastructure for research and education by producing an integrated, open source web development environment for use by researchers and the world. The work will therefore benefit society by empowering the tens of millions of end-user programmers to creatively build content and applications for the web. The PIs will advance discovery while promoting learning by integrating their research into undergraduate courses on creativity and software engineering, and by supporting summer camps for at least 300 high school students per year. Project outcomes will be disseminated to researchers through publications and presentations, to computing educators through the above-mentioned camps and the National Girls Collaborative Project, and through public deployment. The PIs expect high interest because the work will be based on JavaScript, which is today's most popular programming language and for which there is a high demand for better tools. The research will address underrepresentation via its focus on investigating how to support both male and female end-user programmers, by involving high-school members of underrepresented groups, and by engaging many of the PIs? female students.","title":"HCC: Large: Collaborative Research: Variations to Support Exploratory Programming","awardID":"1314384","effectiveDate":"2013-08-01","expirationDate":"2017-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[548134,548135],"PO":["565227"]},"205536":{"abstract":"Like animals and humans, artificial autonomous agents that are able to predict short-term and long-term consequences of their actions can then plan their behavior, act more intelligently, and achieve greater reward. Agents that can learn such predictive models from experience can be more robust in their intelligence than agents that rely on pre-built models. The PI and graduate students are focused on the particularly challenging but natural case where observations from the agent's sensors far in the past can continue to influence the predictions of consequences of actions long into the future. (For example, the observation of where you park the car in the morning will help predict where you will see the car later in the day.) There are two broad classes of approaches to learning predictive models in such 'partially observable' settings. Finite-history models use short-term history of observations to predict future observations conditioned on actions; these are fast to learn but are limited because they cannot capture the effects of long-term history. Latent-variable models can capture the effects of long-term history by positing hidden or latent variables that capture the true state of the environment (e.g., the location of the car), but such models are difficult to learn because the latent variables have to be inferred from data. <br\/><br\/>This project builds on previous work by the PI and others on a third approach, called Predictive State Representations (or PSRs), in which the agent maintains predictions of future observations conditioned on future actions as a summary-representation of history; these models can both be fast to learn and capture the effect of long-term history. This project develops new PSR-based methods and algorithms for hierarchical models, rich-feature-based models, and local and modular models. The project applies the new methods to challenging applications from active perception and robotics. In addition, theoretical understanding of these richer and newer methods will be developed. Altogether the project significantly expands the applicability of PSR-methods as well as their theoretical foundations and algorithms. <br\/><br\/>Broader Impacts: New methods that allow artificial agents to robustly build predictive models would advance the state of knowledge across the fields of artificial intelligence, reinforcement learning, control, operations research, psychology, and neuroscience. The PI is co-leading an effort to create a new undergraduate degree in Data Sciences at the University of Michigan to be jointly managed by Computer Science & Engineering and Statistics. This future degree as well as other current undergraduate research programs will be targeted to recruit, mentor, and train students for this project.","title":"RI: Small: Reinforcement Learning with Predictive State Representations","awardID":"1319365","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[550371],"PO":["562760"]},"205426":{"abstract":"In this Cyberlearning: Transforming Education Exploration project, the PIs investigate how to help middle schoolers simultaneously develop mathematics understanding, mathematics skill, and mathematics disposition. They are taking design-based pedagogical approach, having students practice the math they are learning through architectural design. Their software environment, called \"Earthquake Rebuild,\" sets learners up in a virtual environment where an earthquake has demolished a city, and they must use geometry and arithmetic to make architectural and city planning decisions as they aim to rebuild the city. In this same context software context, the investigators are incorporating means of unobtrusive collection and analysis of performance data, called \"stealth assessment,\" for purposes of both tracking development of understanding and capabilities and providing adaptive learner support. Research addresses practical issues in design of systems that help learners deeply learn content and skills in the context of solving real-world problems and in design of stealth assessments. Research also addresses conceptual issues in mathematics learning, specifically focusing on the ways that informal mathematical conjectures emerge and are transformed into formal mathematics knowledge through concrete application.<br\/><br\/>Too many middle schoolers fail to develop the kinds of mathematics capabilities they will need to be productive in the workforce and to be engaged citizens. Even more middle schoolers complete middle school without appreciating the connections between mathematics and the real world they live in. The aim of this project is to address both of these issues: to promote deep mathematical understanding and capabilities among middle schoolers and to engage them in \"mathematizing\" their worlds -- seeing the roles mathematics plays in the natural and built environment around them. To achieve these goals, investigators are designing a software environment that allows students to combine serious play and learning as they use middle-school mathematics to reconstruct a demolished fictional city. The system is being designed to collect data about student understanding in the background (called \"stealth assessment\") so that as students engage with the system, it can help them use mathematics to rebuild the buildings in the fictional city, more deeply learn the mathematics they are using, and come to appreciate the usefulness of mathematics and mathematical thinking in engaging productively in problem solving and design activities. Investigators will learn more about how to design learning technologies that will help learners learn and appreciate mathematics, how mathematics is learned when students engage more systematically in using math, and how to accomplish the types of stealth assessment needed to personalize learning technologies to the needs of individual students.","title":"EXP: \"Earthquake Rebuild\" - Mathematical Thinking and Learning via Architectural Design and Modeling","awardID":"1318784","effectiveDate":"2013-08-15","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7645","name":"DISCOVERY RESEARCH K-12"}}],"PIcoPI":[550076,550077,550078,550079,550080],"PO":["562669"]},"205679":{"abstract":"This project will close technical gaps to enable cognitive radio receivers to explore the radio frequency spectrum online, using the most advanced form of Analog to Digital conversion, referred to as Finite Rate of Innovation (FRI) sampling coupled with the most advanced learning techniques. We plan to use the well-established framework of the multi-armed bandit (MAB) problem, which models the situation of a cognitive radio agent that simultaneously attempts to acquire new knowledge and to optimize its decisions based on what it has previously learned. Our main contribution lies in combining this framework with this novel Analog to Digital receiver front-end, sampling rate below the so called Nyquist limit, adaptively tuning parameters in the sampling structure to sense spectrum opportunities over a much wider range of frequencies than was previously considered possible, and specifically further below what is attainable myopically, without adaptation.<br\/><br\/>The outcome of our study is a cohesive system model for a cognitive sensors, endowed with a decision engine that can optimize not only what to sample but also how to sample analog signals, leveraging on its expected success in finding spectrum holes. The project will explore the complexity of the overall architecture and, ultimately, evaluate the potential benefits of a cognitive MAB-FRI receiver. By moving learning algorithms a step closer to manage directly the data-acquisition interface to the physical world, the research as broad implications in a variety of related sensing problems. The project will also include activities to engage students in classrooms presenting the basic mathematical tools used in this research and minorities in research projects that contribute to advance the broad field of adaptive systems.","title":"CCF: Small: Online Learning and Exploitation of the Radio Frequency Spectrum with Sub-Nyquist Sampling","awardID":"1320065","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[550699,"551133"],"PO":["564898"]},"200971":{"abstract":"There is considerable current interest in developing smart environment technologies. Such efforts present research challenges in, and integration of research outcomes from, diverse disciplines including artificial intelligence, pervasive computing, robotics, interfaces, middleware, and sensor networks. The lack of availability of large-scale sharable data sets from smart environments is a major stumbling block for rapid advances in this area. Against this background, this project aims to develop and deploy a data and tool repository needed by the smart environment research community.<br\/><br\/>The anticipated results of this infrastructure project include 1) a streamlined, do-it-yourself smart home kit, 2) a web interface to upload, access, and annotate smart environment data, 3) meta data including functional assessment scores and energy usage, and 4) software tools to recognize, visualize, and analyze home-based behaviors. The investigators aim to assess the impact of the resulting repository (CASAS) using measures such as number and diversity of researchers utilizing the repository, number of datasets and tools contributed to the repository, research, education, and commercial advances related to the repository, and publication citations to the repository.<br\/><br\/>Broader impacts of the project include (i) the do-it-yourself smart home toolkit, data sets and software tools that enable research and educational efforts by a large community of researchers in artificial intelligence, pervasive computing, robotics, interfaces, middleware, and sensor networks; (ii) enhanced opportunities for researchers in cognitive psychology, gerontology, and sociology to contribute to interdisciplinary research in smart environments; and (iii) enhanced research-based training opportunities for students from underrepresented groups. The datasets, software tools and educational materials that result from this work will be made available as part of the CASAS repository at http:\/\/ailab.wsu.edu\/casas\/.","title":"CI-ADDO-EN: Smart Home in a Box: Creating a Large Scale, Long Term Repository for Smart Environment Technologies","awardID":"1262814","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["547675"],"PO":["560586"]},"210794":{"abstract":"The last few years have witnessed an explosive growth in the number of personal mobile devices, such as smartphones and tablets. This growth has been followed by an even more exceptional increase in the download of mobile applications, as well as in the related security threats. In this context, the cloud computing paradigm can be leveraged to improve mobile application security. The fundamental idea is to install the mobile application on a remote server in the cloud infrastructure rather than on the device. Then the application can be accessed with techniques similar to remote desktop computing. This approach is referred to as remote sandboxing.<br\/><br\/>The major advantage of this scheme is that it is very suitable to efficiently offer advanced security features. To this end, remote sandboxing is complemented with a framework for cloud-based security services tailored to mobile applications. The framework supports heterogeneous mobile devices and platforms, and provides methods to improve the resource utilization of the cloud infrastructure. Furthermore, it provides energy-efficient and reliable support for remote networking of mobile devices.<br\/><br\/>The remote sandboxing framework will enable a new cloud delivery model, where security services specific to mobile applications are offered to the users. It will also benefit cloud computing by improving efficiency in resource allocation and management, as well as by fostering research on security. Finally, the research will promote the awareness of security threats and privacy issues affecting personal devices, and include activities targeted to undergraduate and K-12 students.","title":"EAGER: Mobile Application Security through Remote Sandboxing and Cloud Computing","awardID":"1404677","effectiveDate":"2013-08-31","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["564777"],"PO":["565255"]},"205800":{"abstract":"Nowadays, graphics processing units (GPUs) have been widely adopted for general-purpose computing, and are known as GPGPUs. However, current and future GPGPUs confront power and energy as the dominant constraints. The number of transistors integrated on a single GPU chip continues to increase due to shrinking feature size and the demand for massively parallel computing cores to increase throughput. On the other hand, the continuous decrease of transistor supply voltage at each new technology node has largely stalled because of leakage constraints, leading to an ever-increasing power density. Therefore, future GPGPUs must become more inherently energy efficient to avoid hitting the power wall. <br\/><br\/>To meet the increasing demands on performance and energy-efficiency, emerging technologies such as non-volatile memory, inter-bank tunneling field effect transistors (TFETs), silicon nanophotonics, and three-dimensional (3D) integration are being deployed in hardware design and promise realization of power efficiency at a scale never expected before. The investigators are exploring a synergetic program to holistically and hierarchically improve the GPGPU's energy efficiency through emerging technology integration. The project objectives include (1) non-volatile memory in the GPU computing cores and low-power mechanisms to substantially reduce leakage and dynamic power consumption; (2) a hybrid TFET-CMOS (complementary metal-oxide semiconductor) methodology to effectively address the energy challenge at both intra- and inter-core levels; (3) a novel 3D-stacked throughput architecture based on silicon-nanophotonics technology to improve memory access performance yet reduce power consumption; (4) integration of the key research innovations and cross-technology optimizations to fully explore the potential of GPGPU design enabled by these emerging technologies. The proposed research will facilitate GPGPUs staying on track with deep sub-micron scaling and meeting the increasing demand for high-performance computing, and will hence benefit numerous real-life applications. This project will also contribute to society through engaging high-school and undergraduate students from minority-serving institutions in research, attracting women and other under-represented groups into graduate education, expanding the computer engineering curriculum with GPGPU power modeling and optimization techniques, disseminating research infrastructure for education and training, and collaborating with the GPU R&D industry.","title":"SHF:Small:Collaborative Research:Exploring Energy-Efficient GPGPUs Through Emerging Technology Integration","awardID":"1320730","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1675","name":"NANOSCALE: SCIENCE & ENGIN CTR"}}],"PIcoPI":["539562"],"PO":["366560"]},"205712":{"abstract":"The task of characterizing human activities using multimodal sensing and automated inference techniques is critically important in many applications. Human activities when observed using traditional audio and video sensors, as well as novel emerging sensors such as depth cameras, orientation sensors, and smart personal devices, result in complex, high-dimensional spatiotemporal signatures that are difficult to analyze. The sources of difficulty are many: high data throughput, the need for sensor registration, variable execution rates associated with activities, pose variability in sensing, the non-Euclidean nature of feature spaces due to physical constraints on environments and actors, and data corruption due to occlusions. The current techniques, involving Euclidean representations and multivariate analyses, fall short in characterizing human activities, as they do not handle non-Euclidean structures nor obtain invariances to pose and execution rates. <br\/><br\/>This research uses tools spanning differential geometry, statistics and signal approximation theory to develop novel frameworks for characterizing human activities. These fundamental tools lead to comprehensive solutions that are applicable to a broad swath of traditional and emerging sensors. The salient aspects of this approach are: 1) geometry awareness, encompassing both classical Euclidean as well as non-Euclidean feature spaces, 2) invariance to sensor placement and execution rate tightly integrated into the representation, and 3) data adaptivity leading to low bitrate representation of human activities for reduced communication and low computational scenarios. Applications of this research include monitoring of human activities using off-the-shelf sensors in resource-constrained environments, such as at homes and on mobile devices.","title":"CIF: Small: Collaborative Research: Geometry-aware and data-adaptive signal processing for resource constrained activity analysis","awardID":"1320267","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[550781],"PO":["564898"]},"202203":{"abstract":"Citation is an essential part of scientific publishing and, more generally, of scholarship. It is used to gauge the trust placed in published information and, for better or for worse, is an important factor in judging academic reputation. Now that so much scientific publishing involves data and takes place through a database rather than conventional journals, how is some part of a database to be cited? More generally, how should data stored in a repository that has complex internal structure and that is subject to change be cited?<br\/><br\/>The goal of this research is to develop a framework for data citation which takes into account the increasingly large number of possible citations; the need for citations to be both human and machine readable; and the need for citations to conform to various specifications and standards. A basic assumption is that citations must be generated, on the fly, from the database. The framework is validated by a prototype system in which citations conforming to pre-specified standards are automatically generated from the data, and tested on operational databases of pharmacological and Earth science data. The broader impact of this research is on scientists who publish their findings in organized data collections or databases; data centers that publish and preserve data; businesses and government agencies that provide on-line reference works; and on various organizations who formulate data citation principles. The research also tackles the issue of how to enrich linked data so that it can be properly cited.","title":"III: Medium: Collaborative Research: Citing Structured and Evolving Data","awardID":"1302236","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[541902],"PO":["565136"]},"205855":{"abstract":"The contemporary landscape of information technology production is one that has been profoundly influenced by the emergence of so-called \"maker culture\" in the 1960s and 1970s. From Mac OS X to Android, from TiVo DVRs to Linksys network appliances, from Amazon.com to Google Chrome, the technology landscape is full of products that depend upon open source and similar alternative models of production. Society currently finds itself in the middle of a new maker movement that both harkens back to the earlier model and also departs from it in significant ways. It is rooted in a growing network of \"makerspaces\" that expands ideas and practices of the Web generation into hardware and manufacturing. Makerspaces are cooperative studios where people develop new approaches to technology design based on the open sharing of software code and hardware designs through the use of technology such as computer controlled laser cutters, 3-D printers, and microcontroller kits. Makerspaces are places where new models of innovation are explored, where values of openness and participation are re-assessed, and where new relationships between people and technology are forged.<br\/><br\/>To understand these phenomena, this project will conduct ethnographic research at four makerspaces, studying them from a socio-technical perspective. The goal of the project is to understand the relationship between cultural and material practices in the maker movement. Accordingly, the focus is on the daily practices in makerspaces, with particular attention to how they experiment with models of social organization, distributed collaboration, and peer production. Specific research sites have been chosen to highlight key questions. Two are located in the United States, in centers of information technology (IT) innovation and production (New York and San Francisco); two are located in China, at key sites for the development of new models of commercial development (in Shenzhen, a major Chinese production hub, and in Shanghai, a center for the Chinese creative and IT industry). Through ethnographic investigation, the project will examine the questions of how DIY (Do-It-Yourself) making as a practice, and makerspaces as physical sites, contribute to the development of new models of technical, economic, and social innovation.<br\/><br\/>Within a broad cultural and sociopolitical context, this research will study peer production, DIY and open source making, models of innovation in action, and the material production of IT work. This exploration will help us to understand non-professional expertise and alternative forms of technical knowledge, distributed collaboration, and inter-cultural exchange of ideas and artifacts. This study complements previously published investigations of peer production by focusing on the effect of physical sites on social organization and open source production. The project provides a concrete, ethnographic foundation for emerging questions of materiality in human-computer interaction.<br\/><br\/>Broader Impacts: As sites of DIY production, makerspaces provide an important interface between technological production and the everyday world. At the same time, they may also represent important sites for rethinking contemporary processes of technological and commercial innovation. This research will help to assess and understand these possibilities, support educational developments in this area (such as makerspace infrastructures within schools), explore alternative forms of small-scale commercial production, incentivize participation, and develop intellectual property. To the extent that makerspaces embody a set of broader cultural values about relationships between people, technologies, and the innovation cycle, this project will provide empirical and conceptual material to support social processes around these questions. As a large-scale public practice, DIY production provides an important forum for connecting academic-based and citizen-based models of knowledge production, and the opportunity for outreach into communities in which scientific and technical work is part of their identity.","title":"HCC: Small: How Do-It-Yourself Makers are Reinventing Production, Labor, and Innovation","awardID":"1321065","effectiveDate":"2013-08-15","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[551116,551117],"PO":["565362"]},"205768":{"abstract":"Micro-chips are at the heart of modern microelectronic systems for computing, communication, entertainment, and other consumer electronics. In order to design and manufacture the next generations of complex microelectronic systems, major innovations in the design of Electronic Design Automation (EDA) software are needed. This project focuses on developing novel EDA software. In the past 50 years, the exponential growth of the semiconductor industry has been primarily fueled by the continuous advancement in Integrated Circuit (IC) manufacturing technology, allowing the industry to produce chips with ever-increasing numbers and ever-decreasing sizes of transistors and wires. Today, the most advanced silicon chips have billions of transistors and tens of miles of wires, and the minimum feature size on a chip is less than 20nm. Lithography continues to be the backbone of chip manufacturing. In advanced IC technology, lithography has become the bottleneck for the chip design process. Design for Manufacturing (DFM) is no longer an option but a necessity. Since physical design determines the locations and geometries of all the transistors and wires, it must understand the down-stream lithography process so that the layout patterns generated are printable on silicon. This is a challenging problem and the requirements oftentimes are non-intuitive to the designers. In this proposal, we study lithography-aware physical design for several leading next-generation lithography (NGL) technologies. The NGL technologies considered here are triple-patterning lithography (TPL), self-aligned double patterning (SADP), directed self-assembly (DSA) and extreme ultraviolet (EUV) lithography. All the proposed topics are critical to their respective NGL technologies and their solutions are expected to greatly impact future generations of micro-chip design for years to come. <br\/><br\/>The proposed research will advance knowledge in Electronic Design Automation (EDA). It will also add new knowledge to other fields such as scientific computing and combinatorial optimization since ultimately we will need to solve large scale optimization problems. The broader impacts of this project include Very Large Scale Integration (VLSI) technology advancement and the education of next generation engineers. VLSI circuits are at the heart of modern information and communication systems. The proposed research improves the design and manufacturing of VLSI circuits, which will benefit society at large. New research results will be passed on to undergraduate and graduate students through dissertation research, course projects, homework, and classroom teaching.","title":"SHF: Small: Lithography Aware Physical Design","awardID":"1320585","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":[550908],"PO":["562984"]},"202259":{"abstract":"The classical approach to wireless communication is to isolate communication links by maximizing signal strength and minimizing interference between users. This simple philosophy is supported by a rich theoretical foundation which has inspired powerful coding techniques and protocols that lie at the heart of modern wireless systems. However, these systems have recently become victims of their own success as the rising density and data requirements of wireless devices have led to a surge in interference. Fortunately, an emerging body of work indicates that the phenomenon of interference may in fact represent an untapped opportunity for increasing the spectral and energy efficiency of next-generation wireless systems. Although many interference-aware communication strategies have been proposed in the literature, the promised gains have been mostly limited to the theoretical realm. <br\/><br\/>The objective of this project is to create practical interference-aware wireless protocols that can operate near the performance predicted by theoretical bounds in terms of throughput, energy efficiency, and reliability. The project is organized into three complementary thrusts that encompass theory, algorithms, and practice. The first thrust investigates lattice-based constellations and low-complexity codes for the compute-and-forward strategy, which enables receivers to decode linear combinations of transmitted codewords. Compute-and-forward can in turn be used as a building block for realizing interference-aware protocols such as physical-layer network coding and multiple-user MIMO (multi-input-uulti-output) systems. The second thrust aims to implement these protocols on a three-node WARP (Wireless Open-Access Research Platform) testbed. A series of carefully designed experiments will be used to compare the performance of interference-aware strategies while accounting for overhead costs. The third thrust leverages the data collected from these experiments to revise channel models to capture key features that impact the performance of interference-aware strategies such as asynchronism and channel fluctuations. These models will be used to revisit the theoretical foundations of interference-aware strategies and tailor them to the channels encountered in practice. This project features several outreach efforts including undergraduate research experiences connected to the WARP testbed and a public repository of training modules and videos.","title":"CIF: Medium: Collaborative Research: Interference-Aware Cooperation via Structured Codes: Creating an Empirical Cycle","awardID":"1302630","effectiveDate":"2013-08-01","expirationDate":"2017-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":[542042],"PO":["564924"]},"208826":{"abstract":"The IEEE International Conference on Healthcare informatics (ICHI) is the premier international forum concerned with the application of computer science principles, information science principles, information technology, and communication technology to address problems in healthcare, public health, and wellness. The ICHI 2013 program includes several invited talks by leading researchers in Health Informatics, contributed paper presentations, as well as several workshops on emerging topics. ICHI 2013 is scheduled to be held during September 9-11 in Philadelphia, PA, USA.<br\/><br\/>The award supports approximately 20 students from U.S. universities to attend the ICHI 2013 doctoral consortium, an event that is specifically targeted to Ph.D. students. Special effort will be made to actively encourage women and members of other groups that are currently underrepresented in STEM disciplines to participate. The doctoral forum enables doctoral students to benefit from one-to-one mentoring from senior researchers, and interactions with other students in Health Informatics at a critical stage in their careers. The award contributes to the education and training of the next generation of researchers and educators in an increasingly important area. It also helps broaden the participation of members of underrepresented groups and women in Health Informatics research.","title":"IEEE International Conference on Healthcare Informatics","awardID":"1342445","effectiveDate":"2013-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[559753],"PO":["560586"]},"209607":{"abstract":"This project is exploring algorithms for computing multiagent strategies that are in exact and approximate equilibrium. The context involves economic games that are played repeatedly by agents each of whom privately observes noisy signals about other players' actions. A complete characterization of equilibria for such games, missing until recently, introduces the concept of a finite state equilibrium in which each player's strategy is represented as a finite state automaton. Players' strategies are verified to be in equilibrium by solving a partially observable Markov decision process. The research is building on this surprising and deep application of decision theory toward equilibrium analysis in a pragmatic class of games, which provides a bold and innovative bridge between decision and game theories. It is designing novel algorithms that utilize approximate and error-bounded solutions of partially observable Markov decision processes for computing approximate finite state equilibrium in games with increasing dimensions.<br\/><br\/>This research is contributing insights for broader classes of games such as stochastic games with noisy signals. The interdisciplinary outcomes of this research are being integrated into courses and conference tutorials on multiagent decision making for dissemination. New international research collaborations with eminent multiagent researchers in Japan are being established.<br\/><br\/>This research is bringing together the disciplines of decision and game theories with mutual benefit. Key outcomes include scalable algorithms for solving highly complex games thereby contributing to the understanding of sophisticated interactions under uncertainty. Applications include analyzing auctions without release of public information, covert price wars between firms, and managing resource congestion.","title":"EAGER: Decision-Theoretic and Scalable Algorithms for Computing Finite State Equilibrium","awardID":"1346942","effectiveDate":"2013-08-01","expirationDate":"2015-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[561860],"PO":["565035"]},"202787":{"abstract":"This award is aimed at the development and community release of a Wideband Software Extensible Radio (WiSER) platform along with a reference implementation for small outdoor deployment of a multi-node dynamic spectrum network. Dynamic spectrum technologies are strategically important to the wireless community because of the urgent need to alleviate spectrum congestion resulting from ongoing exponential growth in mobile data usage. While a great deal of theoretical work has already been done on dynamic spectrum techniques, definitive experimental evaluations of potential gains have yet to be conducted. The lack of experimental research is mainly due to the fact that available open platforms suitable for academic experimentation with software defined radio (SDR) are limited to first-generation technologies that operate at low bandwidth and can only handle a limited amount of MAC\/PHY customization due to inherent processing constraints. The proposed WiSER platform is a second generation wideband open-source SDR platform that will enable new experimental research in the fields of dynamic spectrum and cognitive radio networking. The WiSER radio?s target release is timed to coincide with significant new national research and policy initiatives in dynamic spectrum involving the NSF, FCC, PCAST, NIST, DARPA and other agencies. This platform enables a richer range of experimental dynamic spectrum research than is currently possible because of its key technical features: operation across 400MHz-4000MHz in 125MHz increments, hardware acceleration for real-world PHY waveforms at speeds of 100 Mbps and higher, hardware virtualization capable of supporting multiple radios on the same platform, and an open-source software toolkit.<br\/><br\/>This project will develop a community resource supported by currently available radios along with an open-source software framework and reference system implementation. Such a resource will allow for research into a very scarce and important public resource ? radio spectrum. By improving reliable access to spectrum, our society benefits in terms of enhancing mobile broadband, improving public safety communications, and ensuring that radar and other spectrum uses are not degraded as the spectrum becomes more densely used. The WiSER team will work closely with experimental research groups nationally to help develop relevant and timely experimental deployments of dynamic spectrum technology. Dynamic spectrum access technology has the potential for order-of-magnitude improvement in spectrum efficiency necessary to cope with the recent explosion of mobile data traffic. Cognitive radio systems will also provide improved connectivity to end users, and enable new applications such as emergency response systems and automotive networks. This project will directly inform these important societal needs by enabling the research community to build state-of-the-art experimental systems for conclusive evaluation of these emerging technologies. Lastly, this platform will offer a powerful educational tool for students wanting to better understand modern digital and software-based radio communications.","title":"CI-ADDO-NEW: Collaborative Research: WiSER Dynamic Spectrum Access Platform and Infrastructure","awardID":"1305171","effectiveDate":"2013-08-01","expirationDate":"2015-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["564746","564745"],"PO":["565303"]},"204514":{"abstract":"This award provides travel support for U.S. based graduate student participants to attend the 2013 International Conference on Data Mining (ICDM 2013), which will be held in Dallas, Texas, from December 9-12, 2013. ICDM has established itself as the world's premier research conference in data mining. The total number of ICDM participants in the past has been in excess of 500, with a majority of the participants coming from the U.S., followed by Europe and Asia. The award provides travel scholarships to 16 U.S. based graduate student participants to attend the ICDM conference and participate in the Doctoral Forum.<br\/><br\/>ICDM provides an international forum for presentation of original research results, as well as exchange and dissemination of innovative and practical development experiences. The conference covers all aspects of data mining, including algorithms, software and systems, and applications, as well as related areas such as data management, machine learning and bioinformatics. The conference proceedings are published by IEEE. The conference seeks to continuously advance the state-of-the-art in data mining. With the growth of the Web, the Internet, and data intensive technologies such as sensor networks and bioinformatics, data mining has become an extremely important area in information technology. Besides the technical program, the conference features workshops, tutorials, panels, data mining contest. Since 2007 the conference has included a data mining contest, and since 2011, it has also included a Ph.D. forum that provides valuable feedback on preliminary research methods and results.<br\/><br\/>A strong representation of U.S. researchers, especially graduate students, in ICDM 2013 is critical for maintaining U.S. competitiveness and for nurturing the next generation of young researchers in an increasingly important area. The award also helps broaden the participation of women and members of underrepresented groups in data mining research.","title":"Supporting US-Based Students to Attend the 2013 IEEE International Conference on Data Mining (ICDM 2013)","awardID":"1313551","effectiveDate":"2013-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[547675,"562519"],"PO":["565136"]},"205625":{"abstract":"Efficient computation of expressive nonmonotonic first-order reasoning is important for realizing robust intelligence. Answer Set Programming (ASP) is a successful nonmonotonic declarative programming paradigm, but is limited in handling first-order reasoning involving functions due to its propositional setting. Satisfiability Modulo Theories (SMT) is a successful approach to solving some specialized first-order reasoning, but is limited in handling nonmonotonic reasoning.<br\/><br\/>This project aims at correcting these deficiencies by tightly integrating ASP and SMT in the framework of \"Answer Set Programming Modulo Theories\" (ASPMT). ASPMT will enjoy the expressiveness of the ASP modeling language while leveraging efficient constraint \/ theory solving methods available in SMT and other related computing paradigms. It will provide a viable approach to solving problems that requires both discrete high level reasoning and continuous low level reasoning, and will provide an effective way to handle heterogeneous knowledge and\/or computation sources in a uniform framework. The project will also deliver an online computation model of the framework and its implementation.<br\/><br\/>The success of the project will produce a general method of efficient computation of expressive reasoning by intelligently combining different formalisms and their implementations, and will promote cross-fertilization among the involved communities. The success of this project will have a significant impact on a wide range of domains that can benefit from a powerful declarative programming paradigm. It will provide a practically usable knowledge representation programming language and tools, which can be easily used by non-KR experts while hiding the details of various computational methods.","title":"RI: Small: Answer Set Programming Modulo Theories","awardID":"1319794","effectiveDate":"2013-08-15","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[550578],"PO":["565035"]},"202237":{"abstract":"Although locating and navigation devices embedded in smartphones have already generated large volumes of location and trajectory data, the next generation of consumer electronics are likely to generate even larger volumes of location-dependent data where spatial and trajectory data management techniques will play critical roles in understanding the data to facilitate decision making. Modern Graphics Processing Units (GPUs) are capable of general computing. Current generation of commodity GPUs have large numbers of processing cores, support even larger numbers of current threads and provide high memory bandwidth, yet are available at affordable prices. The massively data parallel computing power of GPUs makes the hardware ideal for spatial and trajectory data management which is both data and computing intensive.<br\/><br\/>This project develops parallel indexing structures and query processing algorithms for spatial and trajectory data on GPUs to provide high performance which is crucial in speeding up existing applications and enabling new scientific and business inquiries. The project achieves its goals by developing: 1) novel spatial indexing techniques on GPUs; 2) novel spatial joins on GPUs; 3) novel trajectory segmentation and indexing techniques and trajectory similarity query processing techniques on GPUs; and 4) an end-to-end prototype system incorporated with open source database and GIS systems for performance evaluations and real world applications. Compared with existing spatial and trajectory data management systems that are mostly disk-resident and adopt a serial CPU computing model, the performance of GPU accelerated main-memory based systems is expected to achieve several orders of magnitude speedup and brings the performance of spatial and trajectory queries to a new level. The research results are beneficial to many applications, such as transportation, urban planning, wild bird ecology, and epidemiology of infectious diseases. Collaboration is carried out with transportation engineers at the University Transportation Research Center in New York City and ecology scientists at the University of Oklahoma?s Earth Observing and Modelling Facility. The project also makes important impacts on education as it provides training for students in the areas of national critical needs: database research, high performance computing, GPU programming, GIS, transportation, mobile and ecology applications. The developed algorithms and prototype system, real datasets and performance evaluation results are made available to the public at the Website: http:\/\/www.cs.ou.edu\/~database.","title":"III: Medium: Collaborative Research: Spatial Data and Trajectory Data Management on GPUs","awardID":"1302439","effectiveDate":"2013-08-01","expirationDate":"2017-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["562677"],"PO":["565136"]},"198872":{"abstract":"Many critical functions performed by organisms are governed by a complex network of interactions among various biochemical molecules. Understanding how different functions are served through these interactions is of utmost importance. Like many processes in the biological realm, interactions are probabilistic events. An interaction may or may not happen with some probability, depending on a variety of factors such as the size, abundance or proximity of the interacting molecules. The probabilistic nature of the interactions introduces significant computational challenges in studying biological networks.<br\/><br\/>Intellectual Merit:<br\/>This project develops novel computational techniques that characterize and compare probabilistic networks. More specifically, this proposal addresses the following problems.<br\/> - (Modeling) It will develop novel mathematical models that characterize topological properties of probabilistic networks precisely and efficiently.<br\/>- (Comparative analysis) It will develop a framework that allows comparing biological networks when at least one of them is probabilistic.<br\/><br\/>Characterizing the implications of uncertainties in interactions of biological networks is a computationally interesting and challenging problem. The main difficulty is that probabilistic interactions yield an exponential number of alternative network topologies. At the heart of this project lies a novel mathematical technique based on probability generating functions. This technique reduces a broad set of questions on the network structure to operations on polynomials resulting in very efficient algorithms. This project will use this technique to address the problem of aligning probabilistic biological networks. <br\/><br\/>Broader Impact:<br\/>Numerous applications follow an interaction pattern that resembles biological networks. Wireless networks, sensor networks, social networks and homeland security are just a few examples. A critical common property of these applications is that the interactions that define them are probabilistic events. This project will enable studying such networks and thus will help answering fundamental queries such as: What are the similar patterns between two social networks?, How fast do we expect a virus spread through a given wireless network? precisely and efficiently even when interactions are probabilistic.<br\/><br\/>This project will also have educational impact. The PIs will recruit and train a graduate student as a part of this project. Finally, the code developed in this project will serve as an excellent educational tool to analyze and query data for a broad spectrum of applications, where the database consists of a set of interacting entities.","title":"CIF: EAGER: Modeling and Querying of Probabilistic Biological Networks","awardID":"1251599","effectiveDate":"2013-08-01","expirationDate":"2015-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7931","name":"COMPUTATIONAL BIOLOGY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[533539,"538607"],"PO":["565223"]},"205758":{"abstract":"The project aims at quantifying a general network's inner potential<br\/>for supporting various forms of security by achieving secret common<br\/>randomness between pairs or groups of its nodes. Statistical and<br\/>computational secrecy measures are being considered against a general<br\/>passive adversary. Common-randomness-achieving protocols are classified<br\/>into two groups: culture-building and crowd-shielding. The former achieves<br\/>common randomness between nodes situated in close proximity of each other,<br\/>from correlated observations of specific (natural or induced) network<br\/>phenomena. The latter ties together the security of multiple communication<br\/>links, to the point where an adversary can no longer isolate and attack<br\/>a single link without attacking the group as a whole. The broad range of<br\/>investigated protocols cover multiple topics, from multipath diversity<br\/>to network tomography, from secure network coding to protocol coding,<br\/>and from anonymous routing to the spread of epidemics. The protocols<br\/>harvest network randomness from diverse sources like ciphertext blocks<br\/>originating at various terminals, contention protocols (delay randomness)<br\/>or network topology (in highly-dynamic, or ad-hoc networks).<br\/><br\/>Communication networks are naturally dynamic, inherently redundant,<br\/>and largely unpredictable. While the former two features have long<br\/>been recognized as a valuable resource for integrity, efficiency<br\/>and confidentiality, network unpredictability is often regarded as an<br\/>incommodity. This project shows how network randomness can be harvested,<br\/>and, together with diversity, exploited to enhance communication<br\/>security. In doing so, it develops a more profound understanding about<br\/>the statistical nature of networks, which can be applied to a broad range<br\/>of information-assurance objectives. The technical approaches and the<br\/>general philosophy developed in this project, and disseminated through<br\/>conferences and seminars, have the potential to inspire an abundance of<br\/>related research. The project will directly impact dozens of students<br\/>through Senior Design projects, a research-and-open-project approach to<br\/>curriculum development, and three new graduate courses containing related<br\/>topics. The PIs are actively involved in programs aimed at increasing<br\/>the involvement of women, underrepresented minorities, and persons with<br\/>disabilities in engineering and computing sciences.","title":"CIF: Small: Collaborative Research: Security in Dynamic Environments: Harvesting Network Randomness and Diversity","awardID":"1320543","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[550884],"PO":["564924"]},"205648":{"abstract":"The primary objective of this research is to develop new, cognitively informed computational models of the generation of narrative that is told within three-dimensional virtual environments. Motivated by theoretic models of narrative structure and psychological models of narrative comprehension, techniques will be developed for creating accounts of sequences of events and the techniques needed to convey them to users. These techniques will use these models to search for narratives that are at once coherent and effective at communicating the underlying event structure. The project will explore how computational models of the mental processes performed by people when experiencing film or machinima can inform an automatic process used to generate the films themselves. Extensive empirical studies will provide a comprehensive evaluation of the effectiveness of the models.<br\/><br\/>The research program has three major thrusts: (1) Integrating generative models of character plans with narrative theoretic structural models to create storylines that reflect both rich character goal structures and recognizable narrative elements. (2) Developing methods for shot sequence selection that build on pragmatic models from linguistic communication to effectively convey characters' plans and goals. (3) Developing and then evaluating a system that integrates these parts to search for narratives that are both coherent and effective.<br\/><br\/>The project will contribute to the infrastructure of science and education by training new researchers (graduate research assistants) in an area that is broadly multidisciplinary (computer science, cognitive science and psychology). These new researchers will gain from the project a unique integrated view of the contributing disciplines. Team members will participate in the dissemination of results through journal articles and presentations at national and international conferences on creativity, artificial intelligence, human-computer interaction and psychology. It is expected that the work will have a significant impact on the theory and understanding of creativity, particularly in the context of narrative, serving as a foundation for a new generation of tools that support the creative process.","title":"HCC: Small: Collaborative Research: Integrating Cognitive and Computational Models of Narrative","awardID":"1319912","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[550629],"PO":["564456"]},"205659":{"abstract":"In this project, the PI studies any-angle search methods. Any-angle search methods are variants of the heuristic search method A* that interleave the search with path optimizations by propagating information only along grid edges (to achieve small runtimes) but without constraining the paths to grid edges (to find short \"any-angle\" paths, namely paths whose headings can change by any angle). The objective of this project is to broaden any-angle search from a few isolated search methods to a well-understood framework and to extend its applicability. To this end, the PI is developing new any-angle search methods and analyzing their properties, which is complicated by the fact that even base properties often do not transfer from A* to them. The team will also evaluate all new and existing any-angle search methods against each other and against alternative search methods, for example, to understand how they trade off among runtime, path length and memory consumption.<br\/><br\/>Any-angle search is a recent search paradigm that promises to result in a new class of powerful path-planning methods for mobile robots, including underwater and aerial vehicles. The project includes dissemination activities to raise awareness of any-angle search in artificial intelligence and robotics (such as via tutorials, open-source code and web applets) and offers research opportunities to both graduate and undergraduate students.","title":"RI: Small: Any-Angle Search","awardID":"1319966","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["460643"],"PO":["565035"]},"198795":{"abstract":"A key challenge in natural language processing is defining the computational representation of words. Data-driven distributional approaches use corpora to induce vector-space representations for words, based on the contexts they occur in. This project goes beyond traditional approaches (e.g., latent semantic analysis; Deerwester et al., 1990), which use words that tend to occur near a word in corpora to define the context, by extending the types of contexts used in constructing semantic vectors. First, this project incorporates translation contexts, i.e., words readily available in multilingual parallel corpora, alongside traditional monolingual corpora. This allows evidence-sharing across languages, most importantly from resource-rich languages with large corpora to more resource-poor languages. Second, this project incorporates social context inferable from social network platforms, captured through author, time, geographic, and social connection metadata. Taken together, these additional features give a broader definition of a word's context and lead to a more unified approach to the distributional approach to modeling human language, moving in the direction of a language-independent semantics. The project focuses on ten typologically diverse languages representing several major language families (English, Arabic, Chinese, Spanish, Russian, German, Portuguese, Swahili, Malagasy, and Farsi). A key emphasis is scaling up algorithms for inferring distributional representations to web-scale corpora and dealing with much larger contextual vectors representing the expanded notion of context. The approach also leverages noisy syntactic processing to enable syntactic information, rather than just information about neighboring words, to be considered when defining context.<br\/><br\/>In addition to improving the quality of the learned lexico-semantic representations by including richer contextual information, this project creates lexical semantic representations that link word types across languages. These have direct use in text processing applications such as text categorization, machine translation, information extraction, and semantic analysis of text, and they will enable the construction of robust lexical semantic resources in lower-resource languages that benefit from the richness of resources in languages they are paired with. The multilingual vector representations produced will be released to the research community and will be used in undergraduate class projects. The project provides integrated educational and research experience for two graduate students in a dynamic research environment. The project website (http:\/\/www.ark.cs.cmu.edu\/BigMultilinguality) will be used for dissemination of results.","title":"BIGDATA: Small: DA: Big Multilinguality for Data-Driven Lexical Semantics","awardID":"1251131","effectiveDate":"2013-08-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8083","name":"Big Data Science &Engineering"}}],"PIcoPI":["563245","563246"],"PO":["563751"]},"210598":{"abstract":"This research examines how and why members of the public are using technology to work with nonprofit organizations and begins to explore how new technologies might be designed to foster more productive partnerships between nonprofit organizations and the public. Mobile information and communication technologies have fundamentally changed the nature of grassroots organizing, enabling members of the public to rapidly and flexibly organize themselves in order to accomplish a variety of goals. However, nonprofit organizations have often failed to leverage the public's innovative and civically-engaged uses of technology for their benefit. This research will undertake two synergistic lines of inquiry to address such issues, one consisting of empirical research, and the other developing design principles.<br\/><br\/>A three-phase empirical study will examine the role of technologies in fostering partnerships between the public and nonprofits. The first phase will explore the use of social media, a technology foregrounding social context, for online advocacy. The second will examine distributed work technologies, predominantly foregrounding temporal context, for virtual volunteering. The third will investigate the use of mobile technologies, foregrounding physical context, for mobile giving. Each phase will be motivated by the same high-level research questions, allowing synthesis across phases and generalization about the role of technology in bridging between the public and nonprofit organizations.<br\/><br\/>In the design inquiry, a series of low-fidelity and medium-fidelity prototypes will be developed that embody design recommendations derived from the empirical inquiry, taking advantage of new permutations of social, physical and temporal contexts. A series of focus groups and design workshops will provide feedback to help guide iteration on the design of the prototypes.<br\/><br\/>This research will provide empirical evidence of how technologies used for online advocacy, virtual volunteering and mobile giving influence the dynamics between nonprofit organizations and members of the public. It will advance theoretical knowledge about the role of nonprofits in a changing technological landscape of public civic engagement. This research will also derive theory about the roles of social, physical, and temporal contexts in civically-engaged technology use. <br\/><br\/>Understanding the way that members of the public are using technology to work with nonprofit organizations is critical for fostering and designing technologies to support productive partnerships moving forward. This research also provides an opportunity for students to participate in civically engaged scholarship, the kind of scholarship that has been shown to attract the participation of minorities in computing disciplines.","title":"HCC: Small: Exploring the Emergent Dynamics Between Nonprofit Organizations and a Technologically-Enabled, Innovative Public","awardID":"1360035","effectiveDate":"2013-08-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[564286],"PO":["564456"]},"203756":{"abstract":"This collaborative research project aims at developing mathematical methods for the analysis\/mining of large scale, high dimensional data that arise in engineering\/physicochemical computations, and, more importantly, in exploiting these methods and algorithms to accelerate the computations themselves. This type of synergy between data mining and scientific computation has the potential to significantly enhance the way we extract knowledge from large scale modeling and simulation. The focus of the approach is the discovery a small number of key, intrinsic features of simulations characterized by very large numbers of degrees of freedom - and the exploitation of these key features to systematically design subsequent simulations. Another important feature of the work is the development of algorithms that \"translate\" between fine scale, detailed, and coarse scale, compact descriptions of the data, as well as algorithms for the fast incorporation of new data\/information in previous computational frameworks. Deliverables of the effort will be the algorithms themselves, as well as documented illustrative examples of their application to large scale molecular and agent-based simulations.<br\/><br\/>If successful, this research will create, document and make available a computational protocol for enhancing large scale scientific computations in the modeling of complex dynamical systems. Example applications include nanoscale self-assembly, such as micelle formation in materials computations, macromolecular foldling, large scale agent-based models of collective motion in ecology and cellular biology, as well as large scale, Partial Differential Equation simulations of engineering problems, like combustion. The results will be disseminated to allow their use by other researchers. The research will form the basis of cross-disciplinary education of graduate students in engineering and in mathematics, and of undergraduate research projects in these disciplines. It will also underpin the development of course materials in large scale data processing.","title":"CDS&E\/Collaborative Research: The Integration of Data-Mining with Multiscale Engineering Computations","awardID":"1309858","effectiveDate":"2013-08-15","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"8069","name":"CDS&E-MSS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"8084","name":"CDS&E"}}],"PIcoPI":[545793,545794],"PO":["565069"]},"205824":{"abstract":"To support an integrated global economy, it is essential that people of all backgrounds be able to function together effectively despite language barriers, and development of Computer Aided Language Learning (CALL) and accent modification tools is a key part of making this possible. In order to support effective learning and provide specific, useful pronunciation feedback to users, systems for pronunciation correction must be able to capture and accurately describe errors in articulation. Accurate acoustic-to-articulator inversion, the estimation of articulatory trajectories from an acoustic signal, has the potential to significantly improve the accuracy and specificity of such feedback to language learners, and enhance methods for in-depth study of both native speaker and second language learner articulatory patterns.<br\/><br\/>This research addresses the problem of robust speaker-independent acoustic-to-articulator inversion, which is a challenging problem due to the complexity of articulation patterns and significant inter-speaker differences. To overcome this difficulty, a novel speaker-independent inversion approach called Parallel Reference Speaker Weighting is being developed, which uses parallel acoustic-articulator adaptation to create speaker-specific models for new speakers without kinematic training data, represented in a normalized articulatory working space. The new approach is being evaluated on the Marquette University EMA-MAE Corpus of parallel acoustic \/ 3-D electromagnetic articulography data including both American English and Mandarin Accented English speakers. <br\/><br\/>The primary impact of this work focuses on the improvement of pronunciation assessment and accent modification systems, with potential for contribution to numerous other speech technologies, including speech recognition, speech coding, and audio and video synthesis.","title":"RI: Small: Speaker Independent Acoustic-Articulator Inversion for Pronunciation Assessment","awardID":"1320892","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"1311","name":"LINGUISTICS"}}],"PIcoPI":[551034,551035],"PO":["565215"]},"205736":{"abstract":"How much power is a set of wind farms likely to generate over the next 24 hours? How will occupants in a commercial building interact to consume energy? Being able to answer prediction questions like these is vital to developing a more sustainable energy infrastructure: If we can predict renewable energy production and demand ahead of time, we can schedule energy resources more efficiently and reliably, leading to significant reductions in greenhouse gas emissions. Unfortunately, these are also inherently uncertain quantities we need to predict; for example, no matter how good our algorithms are, we can't predict human behavior with perfect accuracy. In order to use such predictions, we need to be able to properly model the uncertainty inherent in these domains. We need to make predictions that are not only correct on average, but which capture the complex random fluctuations and correlations between predicted quantities. Only then can we schedule energy resources in a way that accounts for these uncertainties.<br\/><br\/>This project develops and uses a recently-proposed framework for modeling --- sparse Gaussian conditional random fields --- a generalization of the commonly used Markov random field. This framework efficiently models high-dimensional distributions by exploiting sparsity in the inverse covariance matrix. The project extends the state of the art by greatly accelerating model learning, by extending existing theory to understand when these models can effectively learn high-dimensional predictors, and by generalizing the predictions to the non-Gaussian setting through copula methods. The project uses these algorithms to build forecasting models in four crucial domains in the energy sector: energy demand, wind power, user occupancy in homes and commercial buildings, and personal energy consumption from smart meters.<br\/><br\/>The project has exemplary broader impacts. First, the research deals directly with application domains crucial to efficient energy management, where even small advances can have a sizable impact on sustainability. Second, the PI leverages the research to bring the power systems and machine learning communities closer together, disseminating the results at both machine learning and power systems venues, and releasing material and video lectures to practitioners in energy. Finally, the project harnesses the research to increase diversity within STEM fields by advising under-represented minorities at the graduate and undergraduate level, and by engaging High School students and teachers with talks illustrating how computation can be used to address problems in sustainability.","title":"RI: Small: Large-scale Probabilistic Forecasting for Energy Systems","awardID":"1320402","effectiveDate":"2013-08-01","expirationDate":"2015-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["560596"],"PO":["562760"]},"205638":{"abstract":"The main goal of this research project is to develop a language independent method for automatic idiom recognition. Idiomatic expressions, such as 'a blessing in disguise' and 'kick the bucket' are plentiful in everyday language, though they remain mysterious, as it is not clear exactly how people learn and understand them. There is no single agreed-upon definition of idiom that covers all members of this class, but idioms tend to be relatively fixed in grammatical form and meaning, but with relatively little predictability in the relation between form and meaning. Also, many idiomatic expressions can appear with both literal, i.e. fully predictable, interpretations given their form -- compare 'The little girl made a face at her mother.' (idiomatic) vs. 'The little girl made a face on the snowman using a carrot and two buttons.' (literal) As a result, idioms present great challenges for a variety of natural language processing applications, including machine translation systems, which often do not detect idiomatic language. To address these challenges, an algorithm is proposed that neither relies on target idiom types, lexicons, or large manually annotated corpora, nor limits the search space by a particular type of linguistic construction. The starting point is that idioms are semantic outliers that violate cohesive structure, especially in local contexts. The following properties are quantified and are incorporated into the outlier detection algorithm: 1) lack of compositionality comparing to literal expressions or other types of collocations; 2) violation of local cohesive ties, so that they tend to be semantically distant from the local topics; 3) while not all semantic outliers are idioms, non-compositional semantic outliers are likely to be idiomatic; 4) idiomaticity is not a binary property; rather, idioms fall on the continuum from being compositional to being partly unanalyzable to completely non-compositional.<br\/><br\/>This research contributes to the better understanding of idiomatic language, to the computational treatment of such phenomena and, with the creation of high quality, publicly available linguistic resources annotated for idioms, to the facilitation of machine learning research and big data science. Additional benefits include efficient algorithms for computing compositionality and topicality from large corpora, interesting new generalizations about the nature of figurative language, and the training of a cadre of undergraduate and graduate students in highly practical work on a difficult interdisciplinary problem.","title":"RI: Small: RUI: AIR: Automatic Idiom Recognition","awardID":"1319846","effectiveDate":"2013-08-01","expirationDate":"2015-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[550606,550607],"PO":["565215"]},"205759":{"abstract":"Future heterogeneous multicore microprocessors are expected to be so<br\/>power constrained that not all transistors will be able to be powered<br\/>on at once. The general-purpose cores will be required to nimbly<br\/>adapt to severely constrained power allocations when power is diverted<br\/>to accelerators, and vice versa. In addition, energy-aware scheduling<br\/>of threads to cores is becoming imperative as multicore architectures<br\/>become more heterogeneous. This research develops power gated<br\/>multicore architectures and integrated scheduling and power allocation<br\/>algorithms for maximizing throughput given varying and potentially<br\/>stringent limits on allocated power.<br\/><br\/>One facet of the research is the design, synthesis, and evaluation of<br\/>power gated general-purpose and data-parallel accelerator<br\/>microarchitectures comprised of deconfigurable lanes--horizontal<br\/>slices through the pipeline--that permit dynamic tailoring of each<br\/>core to the application. The goal is to demonstrate tolerable<br\/>performance and power-gating overheads yet flexibility in adapting to<br\/>workload behaviors. A second aspect of the work is a new optimization<br\/>approach that efficiently finds a near-global-optimum configuration of<br\/>lanes and thread-to-core assignment without requiring offline training<br\/>or foreknowledge of the workload. The approach combines reduced<br\/>sampling techniques, adaptation of response surface models to online<br\/>optimization, incorporation of limited online profiling information,<br\/>and heuristic online search. The research will improve the<br\/>computational capability of future severely power-constrained devices;<br\/>involve undergraduate, graduate, and\/or postdoc women engineers; and<br\/>be incorporated into computer architecture and heuristic optimization<br\/>classes.","title":"SHF: Small: Dynamic Power Management in the Dark Silicon Era","awardID":"1320545","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":[550886,550887],"PO":["366560"]},"205418":{"abstract":"Humans are extremely adept at learning new skills by watching and imitating others. Attempts to endow robots with a similar ability have failed to generalize beyond specific tasks, partly because the focus has been on following the trajectory of an action demonstrated by an expert. <br\/><br\/>The current project investigates a new interdisciplinary approach to imitation learning that is inspired by how humans learn via goal-based imitation. The project's specific objectives include: (1) a new method for imitation based on inferring the underlying goals of human actions rather than following trajectories: actions are executed based on sequences of inferred goals and successfully executed action sequences are cached as higher level goals, leading to hierarchical goal-based imitation; (2) a new approach based on hierarchical Bayesian models (HBMs) is proposed for generalization across objects and tasks, and (3) developmental studies of goal-based imitation learning are proposed for testing predictions of the project?s models in imitation learning experiments with children. <br\/><br\/>The project represents one of the first efforts to develop rigorous probabilistic models of goal-based imitation learning based on insights from human learning. The results are expected to pave the way for a new generation of machines that can interact fluently with humans, learn new skills from human teachers, and cooperatively solve problems with human partners. The project also provides graduate and undergraduate students with multidisciplinary training in computer science and cognitive science, with K-12 outreach activities aimed at encouraging students from underrepresented groups to pursue careers in science and engineering.","title":"RI: Small: Probabilistic Goal-Based Imitation Learning","awardID":"1318733","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[550052,550053,550054],"PO":["565035"]},"205319":{"abstract":"To date most of the research concerned with exploring the use of the skin for human-computer communication has focused on tactile displays, which represent a promising arena for enhancing the display of information in situations in which the visual and auditory systems are overloaded. But in addition to its tactile sensors, the skin also houses thermal receptors that respond to changes in skin temperature and convey information about the magnitude and rate of change in temperature. Thermal feedback may potentially be of use as a channel of communication or in enhancing tactile and visual feedback in multisensory displays. The PI's objective in this research is to explore the domains in which thermal feedback can be used as a medium of communication and to identify the types of inputs that are most effective for users, with the long term goal of discovering conditions under which thermal feedback enhances human performance as reflected in more efficient information processing or the ability to respond more effectively to an external event. The focus is on using thermal interfaces within the context of a multisensory environment to display abstract information rather than to facilitate object recognition in a virtual environment or when controlling a tele-operated robot. The human thermal sensory system presents unique challenges when considered as a medium of communication due to its spatial and temporal properties which differ from those of other sensory systems. Although this constrains the types of cues that can be presented to users, it also opens up the possibility of creating new forms of feedback which by virtue of their novelty may be quite compelling to users. The work will be divided into three thrusts: determine the optimal configuration and operating characteristics of thermal displays interfaced with input devices used to interact with computers; evaluate the feasibility of using thermal stimuli to represent abstract information and appraise the viability of using thermal cues to present novel sensory experiences such as illusions of moisture or wetness; and examine whether the representation of information in multisensory displays is enhanced when thermal feedback is presented concurrently with tactile and visual cues.<br\/><br\/>Broader Impacts: There is very little research on the feasibility of using thermal displays to present abstract information, so this work has the potential to open a fundamentally new application domain for thermal interfaces. The availability of thermal cues in displays should increase the designer's ability to choose among modalities and assign functions and types of information to the channel that is best suited for their presentation. Project outcomes will also contribute to the development of sensory substitution systems for those with visual, auditory or vestibular impairments; there has been a considerable amount of research on using the sense of touch to compensate for deficiencies in other senses and the addition of thermal feedback to such displays provides an added dimension for communication, potentially increasing the reliability of communication.","title":"HCC: Small: Thermal Displays in Human Computer Interactions","awardID":"1318215","effectiveDate":"2013-08-15","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[549792],"PO":["565227"]},"208729":{"abstract":"This grant will support of the attendance of 22 US-based graduate students to attend The 24th ACM Symposium on Operating Systems Principles (SOSP 2013). Participation in leading conferences is an extremely important part of the graduate school experience, providing the opportunity to interact with more senior researchers and to be exposed to leading edge work. In the area of computer systems, SOSP is one of the few such leading conferences. The support requested in this proposal will make possible the participation of students who would otherwise be unable to attend. SIGOPS is among the oldest of the ACM SIGs, and has a distinguished history of contributions to the advancement of systems research. Many of the key components of the in-formation revolution, from memory management to the Internet, secure communications protocols, net-work file systems, and ubiquitous computing, were first showcased in SIGOPS-affiliated conferences. SIGOPS is a sponsor of SOSP as well as the annual EuroSys conference.","title":"CNS Student Travel Support for the 25th ACM Symposium on Operating Systems Principles (SOSP 2013)","awardID":"1341823","effectiveDate":"2013-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[559530],"PO":["565255"]},"208509":{"abstract":"Models and Algorithms for Genome Evolution (MAGE) is an international meeting addressing the interdisciplinary area of genome evolution. MAGE is also celebrating the 50-year career of David Sankoff, a pioneer in computational genomics and biology. The community of computational evolutionary biologists is composed of mathematicians, computer scientists, statisticians, physicists and biologists, all willing to contribute to a better knowledge of the history of life on earth. The plurality of backgrounds yields a plurality of approaches, theoretical and empirical. The organizers represent a diverse international set of researchers at different stages of their careers. While the core of senior and early-career researchers have been invited and accepted, these funds will enable up to 20 students and postdocs to participate in the conference. In addition to the presentations and daily poster sessions, the meeting will also provide input to a book to be published by Springer in its series Computational Biology.","title":"Conference on Models and Algorithms for Genome Evolution","awardID":"1340180","effectiveDate":"2013-08-01","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[558865],"PO":["565136"]},"210797":{"abstract":"This project addresses homeland security, an issue of the highest national priority, with a goal of monitoring, preventing, and recovering from natural and inflicted disasters. In particular, in collaboration with team from UT Arlington, Penn State University and the University of Kentucky, the project will create a novel technology-enabled security framework, called Pervasively Secure Infrastructures (PSI), that will make use of such advanced technologies as smart sensors, wireless networks, pervasive computing, mobile agents, data mining, and profile-based learning in an integrated, collaborative and distributed manner. The uniqueness of this multi-disciplinary, multi-university proposal lies in the synergistic combination of the proposed research in (i) efficient data collection and aggregation from heterogeneous sensors and monitors; (ii) novel techniques for real-time, secured, authenticated information transmission and sharing, and (ii) intelligent situation awareness (e.g., threat detection and security services) through new learning, data mining, and knowledge discovery techniques. The project will mainly focus on authentication and secure data transmission in wireless networks. The project will integrate these research efforts in the novel paradigm of pervasive community computing that can efficiently handle dynamically changing information, adapt to changing situations, and provide scalability in terms of the number of users, devices, and data sizes.","title":"ITR Collaborative Research: Pervasively Secure Infrastructures (PSI): Integrating Smart Sensing, Data Mining, Pervasive Networking, and Community Computing","awardID":"1404694","effectiveDate":"2013-08-31","expirationDate":"2014-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["564777"],"PO":["565136"]},"205825":{"abstract":"The problem of ranking objects occupies a central place in key technologies such as web search and recommendation systems. These technologies have a tremendous daily impact on the lives of millions of people. Moreover, the enormous scale of data on the web makes the use of machine learning especially attractive in constructing ranking algorithms. A huge amount of research effort has been devoted to developing efficient ranking algorithms that can deal with a variety of data sets encountered in web search and recommendation systems.<br\/><br\/>This project develops unifying mathematical theory that will provide a basis for understanding and categorizing existing algorithms and, more importantly, lead to deeper insights and new algorithms for the problem of learning to rank. The investigators also apply ranking algorithms to new domains. For example, ranking chemical reactions based on their plausibility will help chemists discover much-needed reaction bases for technologies such as carbon dioxide reduction, and conversion of natural gas into gasoline. <br\/><br\/>Fundamental advances in the statistical theory of ranking will be incorporated into undergraduate and graduate courses. Data sets and software developed will be made freely available to the scientific community. The investigators will also organize a workshop with a focus on interdisciplinary participation and involvement of under-represented groups in computer science and statistics.<br\/><br\/>The primary technical challenge in developing statistical ranking theory is the absence of a universally agreed-upon loss functions for ranking. This is in contrast to classic machine learning problems such as classification and regression, where there are only a few natural possibilities for the loss function and these are well-understood theoretically. The project addresses this gap by investigating how different loss functions for ranking affect fundamental theoretical properties such as learnability, and by creating a theory of convex surrogates that is applicable when loss functions abound. The project re-examines existing statistical literature on ranking with a computational lens. This will enable development of flexible and efficient plug-in decision rules that model the conditional probability of labels given inputs.<br\/><br\/>By incorporating the results of this research into courses and survey articles, the PIs help train a new generation of machine learning researchers and practitioners who will view ranking as a learning problem on par with classification and regression in mathematical depth as well as practical importance. Theoretical guidance for practitioners formulating new algorithms for ranking will improve the most common applications on the web.","title":"RI: Small: Collaborative Research: Statistical ranking theory without a canonical loss","awardID":"1320894","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[551037],"PO":["562760"]},"205836":{"abstract":"Many engineering and scientific projects require planning experimental activities in order to optimize an objective. Such planning involves jointly reasoning about both the budget-limited resource constraints among activities along with the utility of potential information that they may provide. Unfortunately, for many real-world planning problems, with rich structure among potential activities, tools from classic experimental design are not directly applicable due to their simplifying assumptions and poor scalability. This project aims to transform the practice of experimental planning by developing new algorithms that account for the complexities exhibited in a wide range of domains.<br\/><br\/>The project involves three key activities. First, the experimental design description language (EDDL) is being created for formally modeling complex real-world experimental domains. Second, novel planning algorithms are being developed for efficiently computing high-quality solutions to problems expressed in EDDL. Third, work with bioengineers is assessing and improving the usability of the tools and producing benchmark problems based on real and simulated bioengineering data. The creation of the language and benchmarks will help facilitate algorithm comparisons for continued progress by the wider research community.<br\/><br\/>The broader impact of the project is to facilitate experiment planning in a wide range of experimental domains for which there are currently no available computational tools. Currently, in such domains, planning is largely ad-hoc and often done without computer support. Our research has broad economic impact potential by helping engineers and scientists to get the most value out of limited experimental resources. The project also advances high school, undergraduate, and graduate education in the areas of computer science and bio-engineering, with an emphasis on recruiting female students. The students will get the unique experience of working across disciplines and research labs.","title":"RI: Small: Automated Planning of Experiments for Design Optimization","awardID":"1320943","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[551065,551066],"PO":["565035"]},"205616":{"abstract":"We will soon enter the manycore era, in which systems will include<br\/>hundreds of cores, large multi-level cache structures, sophisticated<br\/>networks-on-chip, many memory controllers, and huge amounts of main<br\/>memory. These systems will also embody a rich array of power<br\/>management mechanisms and will strive to achieve high performance<br\/>under various power, energy, and thermal constraints. Unfortunately,<br\/>the uncoordinated power management of a system's components can<br\/>produce oscillating behavior, higher power\/energy\/temperature, and\/or<br\/>excessive performance degradation. Given their large number of<br\/>hardware components and the wide spectrum of available mechanisms,<br\/>manycore systems will have to coordinate the actions of their various<br\/>power managers. Moreover, to decide on a (coordinated) course of<br\/>action, these systems will have to comprehensively and rigorously<br\/>reason about various performance and power\/energy\/temperature<br\/>tradeoffs.<br\/><br\/>This project will develop global power coordination (GPC) to manage the<br\/>combinatorial explosion of possible power management configurations in<br\/>manycore systems. GPC will be realized using an engine that analyzes<br\/>the space of possible power state configurations for the entire<br\/>system. It will then decide which configurations are most appropriate,<br\/>and use per-component power managers to actuate the proper settings.<br\/>To optimize the search for good configurations, GPC will consider<br\/>greedy search heuristics that prune the space by relying on novel<br\/>techniques that estimate the benefit of power state changes, group<br\/>resources with similar power management hooks, and leverage prior<br\/>observed behavior and a hierarchical organization.<br\/><br\/>This project will broadly impact society in many ways. First,<br\/>addressing the power, energy, and temperature problems of manycore<br\/>systems can greatly impact the datacenters that run our Internet<br\/>services and the high-performance systems that advance our science.<br\/>Second, tackling these problems will address one of the key<br\/>technological barriers in the computing industry. Third, the project<br\/>will educate graduate, undergraduate, and high-school students, while<br\/>broadening the participation of underrepresented groups in computer<br\/>science.","title":"SHF: Small: Taming the Combinatorial Explosion of Power Management for Future Manycore Systems","awardID":"1319755","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["556616","556617"],"PO":["366560"]},"204769":{"abstract":"Ever-larger data centers are powering the cloud computing revolution, but the scale of these installations is currently limited by the ability to provide sufficient internal network connectivity. Delivering scalable packet-switched interconnects that can support the continually increasing data rates required between literally hundreds of thousands of servers is an extremely challenging problem that is only getting harder. This project leverages microsecond optical circuit-switch technology to develop a hybrid switching paradigm that spans the gap between traditional circuit switching and full-fledged packet switching, achieving a level of performance and scale not previously attainable. This will result in a hybrid switch whose optical switching capacity is orders of magnitude larger than the electrical packet switch, yet whose performance from an end-to-end perspective is largely indistinguishable from a giant (electrical) packet switch.<br\/><br\/>The research provides a quantitative baseline for hybrid network design across a wide range of present and future technologies. The project will consist of five parts: i) traffic characterization to identify the class of network traffic that a circuit switch can support as well as the partitioning of the traffic between the circuit and packet portions of the network; ii) circuit scheduling to enable the circuit switch to rapidly multiplex a set of circuits across a large set of data center traffic flows; iii) traffic conditioning to reduce the variability of traffic at the end hosts, easing the demands placed on switch scheduling; iv) a prototype hybrid network that can use an optical circuit switch that operates three orders of magnitude faster than existing solutions; and v) a trend analysis to understand the tradeoffs resulting from potential future technology advances.<br\/><br\/>The work stands to dramatically improve data center networks, significantly reducing operating costs and increasing energy efficiency. The research material will be incorporated into courses, helping to train the next generation of computer networking scientists and engineers. The PIs will also continue ongoing outreach to high school students, both through the UCSD COSMOS summer program and through talks delivered at local high schools.","title":"NeTS: Large: Collaborative Research: HCPN: Hybrid Circuit\/Packet Networking","awardID":"1314921","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[548361,548362,548363,548364],"PO":["564993"]},"205408":{"abstract":"Mobile devices (e.g., smartphones and tablets) allow users to execute rich third-party applications that are capable of making extensive use of device hardware and personal data. This poses security risks, as applications may perform undesirable operations such as deleting data, damaging hardware, or even directly incurring charges on the user's phone bill. Mobile devices also pose privacy risks, as they store sensitive personal information that may be accessed and shared inappropriately.<br\/><br\/>Empowering users to decide how resources on their mobile devices are accessed (i.e., \"granting permission\") is an important challenge for the future of mobile computing. Our research has shown that existing mechanisms are ineffective: users frequently grant permissions because they either do not understand them, are habituated to them, or feel that they have no other choice. This research project aims to identify and study potential solutions to these problems.<br\/><br\/>This project develops a user-centered approach to mobile device permission requests. The project is conducting human-subjects experiments to design and validate more effective mechanisms for regulating privacy- or security-sensitive actions. The research agenda involves minimizing habituation to security warnings by substituting them with protected widgets (i.e., \"trusted UI\") or audit mechanisms, when possible; improving the design of security warnings, because alternative permission-granting mechanisms are sometimes inappropriate; and integrating these mechanisms into a platform that improves system security by taking a user-centered approach to granting permissions. If successful, this project could help develop a secure foundation for future generations of mobile devices.","title":"TWC: Small: A Choice Architecture for Mobile Privacy and Security","awardID":"1318680","effectiveDate":"2013-08-15","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[550026],"PO":["564246"]},"198775":{"abstract":"Although big data has had a huge impact in several areas, this impact is limited by the high cost and poor quality of analyzing unstructured data, and the costs of integrating data of multiple types. Lowering these costs will bring the benefits of big data based research to many new areas. Against this background, this project aims to develop machine-learning methods that read, analyze, and integrate web-scale collections of text and other data. The project can be expected to yield fundamental advances in data integration, machine learning, natural language understanding, and automated inference. <br\/><br\/>The project includes research thrusts in (1) robust semi-supervised bootstrap learning algorithms that can cope with ambiguity in text, (2) algorithms for detecting and aligning the schemas implicit in semi-structured sources relative to a shared common ontology, (3) NLP algorithms that perform deeper analysis on text to extract infrequently mentioned yet important facts, and (4) targeted reading agents capable of pursuing specific queries or conjectures based on the scientist's current focus. <br\/><br\/>Anticipated results of the project include fundamental advances in each of the research thrusts and their synergistic integration into software system (NESSIE) designed to help scientists in exploring scientific hypotheses in their respective domains of interest, by supporting targeted extraction of knowledge from large amounts of textual sources in relevant areas. <br\/><br\/>Broader impacts of the research include advanced techniques for extracting and organizing structured knowledge from text, and integrate the learned information with existing structured knowledge in multiple domains. The Additional broader impacts of the research include enhanced opportunities fore advanced research-based training of graduate students. The softare and data resulting from the research will be made freely available to the larger scientific community.","title":"BIGDATA: Small: Big Data for Everyone","awardID":"1250956","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8083","name":"Big Data Science &Engineering"}}],"PIcoPI":[533288,"533936"],"PO":["565136"]},"210644":{"abstract":"Numerous applications involve massive, high-dimensional datasets. For example, the search industry routinely deals with billions of web pages, where each page is often represented as a binary vector in 2^64 dimensions. In computer vision, images are often represented as non-binary vectors in millions of dimensions. Algorithms which are capable of efficiently compressing, retrieving, and mining these datasets are of high practical importance. Mathematically rigorous and computationally efficient hashing methods will be developed to dramatically reduce ultra-high-dimensional datasets. These algorithms will be integrated with a variety of learning techniques including classification, clustering, near-neighbor search, matrix factorizations, etc. <br\/><br\/>The project builds on and extends minwise hashing, and b-bit minwise hashing which are standard hashing techniques in search applications. The project aims to (i) rigorously analyze b-bit minwise hashing and develop, analyze, and apply significantly more efficient (and more accurate) to problems in search and learning; (ii) develop a unified framework of probabilistic hashing which essentially consists of one permutation followed by (at most) one random projection; (iii) develop a unified theory of summary statistics under a variety of engineering constraints (storage space, computational speed, indexing capability, adaptation to streaming, etc.). <br\/><br\/>Hashing algorithms developed under this framework are expected to be substantially much more efficient and more accurate than existing popular algorithms such as random projections and minwise hashing. This general framework allows the design algorithms to accommodate many different data types (sparse or dense data, binary or real-valued data, static or streaming data), many different engineering needs (computing inner products or lp distances, kernel learning or linear learning), and different storage requirements. Anticipated results of the proposed research include rigorous and computationally efficient hashing algorithms for dealing with ultra-high-dimensional datasets, the integration of the resulting hashing algorithms into with a variety of learning techniques for classification, clustering, near-neighbor search, singular value decompositions, matrix factorization, etc; and rigorous experimental evaluation of the resulting methods on big (e.g., TeraByte or potentially PetaByte) data of the order of up to 2^64 dimensions. <br\/><br\/>Broader Impacts: Effective approaches to building predictive models from extremely high dimensional data can impact many areas of science that rely on machine learning as the primary methodology for knowledge acquisition from data. The PI's education and outreach efforts aim to broaden the participation of women and underrepresented groups. The publications, software, and datasets resulting from the project will be freely disseminated to the larger scientific community.","title":"III: Small: Probabilistic Hashing for Efficient Search Learning","awardID":"1360971","effectiveDate":"2013-08-28","expirationDate":"2016-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["565250"],"PO":["565136"]},"210798":{"abstract":"This project will support students to attend SustainIT conference to be held in Palermo, Italy on Oct 30-31, 2013. The SustainIT conference focuses on applications of information and communication technologies (ICT) for Sustainability. SustainIT 2013 will include Ph.D. forum, work in progress session, poster session, industry track and keynotes. Extended versions of selected papers will be published. The conference will provide an opportunity for students to interact with researchers, particularly computer scientists, working on applications of ICT for sustainability. The students will be selected based on applications that explain how they will benefit from the conference. Preference will be given to minority students and students with accepted papers in SustainIT.","title":"SustainIT 2013 Student Travel Support Request","awardID":"1404702","effectiveDate":"2013-08-31","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[564777],"PO":[564778]},"204704":{"abstract":"Most cryptographic applications crucially rely on secret keys that are chosen randomly and are unknown to an attacker. Unfortunately, the process of deriving secret keys in practice is often difficult, error-prone and riddled with security vulnerabilities. Badly generated keys offer a prevalent source of attacks that render complex cryptographic applications completely insecure, despite their sophisticated design and rigorous mathematical analysis. Even though key derivation plays a central role in the security landscape, it has received surprisingly little formal study within the cryptographic community, leading to a large disconnect between the theory and practice.<br\/><br\/>In this project, several important scenarios for key derivation are examined for their capability to improve security with provable guarantees, including the use of random number generators (RNGs), passwords, and biometrics. In particular:<br\/><br\/>- How RNGs are designed to properly combine the entropy gathering, randomness extraction and pseudorandom generation modules, while achieving the best possible subset of clearly defined security properties against a variety of adversarial scenarios.<br\/><br\/>- How to reduce the effectiveness of ?offline dictionary attacks? when generating keys from passwords.<br\/><br\/>- How biometrics can be safely reused to generate many secret keys across many applications raises several interesting questions, combining cryptographic security properties with those of error-correcting codes.","title":"TWC: Medium: Collaborative: The Theory and Practice of Key Derivation","awardID":"1314568","effectiveDate":"2013-08-01","expirationDate":"2017-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["550227"],"PO":["565239"]},"205815":{"abstract":"MOS (metal-oxide-semiconductor) transistors, being on\/off switches, have served as an ideal match to the abstractions of switching functions and Boolean logic, which (together with von Neumann architecture) form the underpinnings of modern computing. While current computing platforms are well-suited to applications that involve arithmetic computations and storing and retrieving large amounts of data, they are known to be highly inefficient - requiring orders of magnitude more energy consumption - for performing tasks that humans routinely perform, such as visual recognition, semantic analysis, and reasoning. The key insight behind the proposed research is that emerging spin torque based devices make it possible to realize the neuron functionality in a highly energy efficient manner, well beyond the capabilities of CMOS (complementary MOS). This is due to two factors - the inherent match between the characteristics of these devices and the functionality of a neuron (leading to a drastic decrease in the number of devices required), and the possibility of ultra-low voltage operation (~20mV). Inspired by this vision, the PIs (principal investigators) propose a research program that spans from devices to architectures to investigate spin-based neuromorphic computing. The goals of the proposed research are to (i) establish the benefits of spin-based device technologies for neuromorphic computing (where CMOS implementations are energy-inefficient), (ii) synergistically explore spin devices, circuits and architecture in a regime where these devices are integrated with CMOS to augment its capabilities and (iii) incorporate the findings from the proposed research in education and outreach programs. <br\/><br\/>The project will leverage outreach programs at Purdue, including the outreach program at NCN (Network for Computational Nanotechnology), and the Women and Minority in Engineering programs in the College of Engineering, to involve undergraduates and minority students in the proposed research. The PIs will develop a summer REU (Research Experiences for Undergraduates) program that builds on their prior experience in integrating undergraduate students into their research groups. The broad nature of the proposed project provides an attractive opportunity for undergraduate students to not only explore novel research, but also get exposed to the emerging fields of spintronics and neuromorphic computing. The project will also establish research, mentoring and education partnerships with primarily undergraduate and minority serving institutions.","title":"SHF: Small: Ultra Low Power Neuromorphic Computing with Spin-devices","awardID":"1320808","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":[551012,551013],"PO":["562984"]},"205826":{"abstract":"Most coding schemes developed in network information theory are combinations of a handful of basic components using Shannon's random coding technique. With the goal of advancing our understanding of these random coding schemes and making them applicable in practice, this research explores three important problems in network information theory. First, this project investigates the simultaneous decoding rule that is easy to analyze, yet powerful enough to achieve the maximum achievable rates of random coding over interference channels. Second, this project applies the insights thus gained on random coding and simultaneous decoding to the index coding problem, in which multiple messages are communicated through a single, noise-free link to multiple receivers with different pieces of side information. Third, this project develops a concatenated coding architecture based on random coding, product codes, and iterative decoding that can provide a systematic method for translating random coding schemes to practical, implementable coding techniques for real-world networks.<br\/><br\/>Playing an ever-increasing role in our networked society, network information theory studies the fundamental limits on information flow over networks and the optimal coding techniques, protocols, and architectures that achieve these limits. This research investigates canonical problems in network information theory that involve interference and broadcast, offering fresh insights and new mathematical tools for optimal information flow in several important applications such as network coding, wireless communication, peer-to-peer networking, and content broadcasting. The concatenated coding architecture developed in this research has potential to provide a new framework for transforming theoretical concepts in network information theory into practical algorithms for applications.","title":"CIF: Small: New Directions in Network Information Theory","awardID":"1320895","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":[551039],"PO":["564924"]},"205837":{"abstract":"Many applications in signal and image processing and imaging depend critically on sparse representations for natural signals or images. This research addresses the development of improved sparse representations that are directly adapted to the data, rather than being fixed a priori by general theoretical considerations. Such data-driven learning of sparse structure has been finding broad applications. The improvements over fixed representation are especially significant for high-dimensional data. This research aims to overcome limitations of the current methods by reducing the computation to enable scaling to big data problems, improving robustness and predictability of outcome, and developing a theory quantifying the expected performance and the factors affecting it. Applications are foreseen in all areas of science and engineering, including medical diagnostics, multimedia, defense, manufacturing, communications, database retrieval, and data analytics. <br\/><br\/>In particular, this research leverages a new formulation recently introduced by the PI for data-driven learning of \"sparsifying transforms\", which are relatives of analysis dictionaries. Initial results in image denoising show slightly better PSNR than with learnt synthesis dictionaries, but at orders of magnitude less computation. Theory predicts better scaling with exemplar size, and experiments demonstrate robust convergence irrespective of initialization. Specific objectives of this research are: (1) develop theory and scalable algorithms for learning sparsifying transforms; (2) develop theory for joint learning of sparsifying transforms and signal recovery in compressed sensing and other inverse problems; and, (3) demonstrate key large-scale applications with real data. These applications include: (i) denoising, restoration, and compressed sensing of 3D and 4D data in magnetic resonance imaging, in computerized tomography, in microscopy, and in video; and (ii) image classification and recognition.","title":"CIF: Small: Theory and Algorithms for Scalable Learning of Sparse Representations","awardID":"1320953","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[551068],"PO":["564898"]},"204748":{"abstract":"Many simulation algorithms depend on an underlying spatial discretization---a mesh that decomposes the domain into a finite set of elements that can be analyzed by a computer. The quality of the simulation is, in part, determined by the quality of the mesh. However, in the past, mesh generation and simulation were done as separate processes. Better results can be achieved by tightly integrating simulation with mesh generation and recent advices in computational topology provide the key to doing so. Computational topology allows for the analysis of the structure of data---in this case simulation variables. By understanding the structure of the simulation the mesh generation algorithms can adapt to it, providing meshes that are closely linked to the actual simulation.<br\/><br\/>Because simulation is a powerful tool for discovery throughout computational science, this research has the potential to have broad impact across all fields of science and enable new scientific breakthroughs that could have tremendous societal impact. This research will also produce open-source software, short courses, and workshops around the topic of coupling simulation and meshing. The interdisciplinary nature of this project will lead to a rich educational and research environment for graduate and undergraduate students. The project web site provides access to research results, software and educational materials (http:\/\/sealab.cs.utah.edu\/SimulationMeshingTopology).","title":"CGV: Large: Collaborative Research: Coupling Simulation and Mesh Generation using Computational Topology","awardID":"1314813","effectiveDate":"2013-08-01","expirationDate":"2017-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[548308],"PO":["563751"]},"205727":{"abstract":"The project aims at quantifying a general network's inner potential<br\/>for supporting various forms of security by achieving secret common<br\/>randomness between pairs or groups of its nodes. Statistical and<br\/>computational secrecy measures are being considered against a general<br\/>passive adversary. Common-randomness-achieving protocols are classified<br\/>into two groups: culture-building and crowd-shielding. The former achieves<br\/>common randomness between nodes situated in close proximity of each other,<br\/>from correlated observations of specific (natural or induced) network<br\/>phenomena. The latter ties together the security of multiple communication<br\/>links, to the point where an adversary can no longer isolate and attack<br\/>a single link without attacking the group as a whole. The broad range of<br\/>investigated protocols cover multiple topics, from multipath diversity<br\/>to network tomography, from secure network coding to protocol coding,<br\/>and from anonymous routing to the spread of epidemics. The protocols<br\/>harvest network randomness from diverse sources like ciphertext blocks<br\/>originating at various terminals, contention protocols (delay randomness)<br\/>or network topology (in highly-dynamic, or ad-hoc networks).<br\/><br\/>Communication networks are naturally dynamic, inherently redundant,<br\/>and largely unpredictable. While the former two features have long<br\/>been recognized as a valuable resource for integrity, efficiency<br\/>and confidentiality, network unpredictability is often regarded as an<br\/>incommodity. This project shows how network randomness can be harvested,<br\/>and, together with diversity, exploited to enhance communication<br\/>security. In doing so, it develops a more profound understanding about<br\/>the statistical nature of networks, which can be applied to a broad range<br\/>of information-assurance objectives. The technical approaches and the<br\/>general philosophy developed in this project, and disseminated through<br\/>conferences and seminars, have the potential to inspire an abundance of<br\/>related research. The project will directly impact dozens of students<br\/>through Senior Design projects, a research-and-open-project approach to<br\/>curriculum development, and three new graduate courses containing related<br\/>topics. The PIs are actively involved in programs aimed at increasing<br\/>the involvement of women, underrepresented minorities, and persons with<br\/>disabilities in engineering and computing sciences.","title":"CIF:Small:Collaborative Research:Security in Dynamic Environments: Harvesting Network Randomness and Diversity","awardID":"1320351","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[550813],"PO":["564924"]},"205738":{"abstract":"Large scale content sharing, social networking sites and cloud storage providers require massive amounts of data (on the order of hundreds of petabytes) to be stored in a distributed manner. In these systems, node failures and loss of data are the norm rather than the exception. Thus, it is of critical importance to investigate storage techniques and algorithms that (a) allow for data recovery in the presence of node failures and (b) allow for efficient regeneration of failed nodes. It is, of course, desirable to perform the regeneration in a distributed manner and optimize performance metrics associated with it. For instance, it is desirable that the regeneration process be fast and that only a few nodes be contacted for the repair. The investigator will research storage methods that allow for very simple and efficient repair while simultaneously allowing for data recovery in the presence of a large number of failures. The research involves the investigation of distributed storage systems that are resilient to multiple failures and can be repaired in an exact and uncoded manner; i.e., the new node may produce an exact copy of the failed node by simply downloading packets from the surviving nodes, with no computational overhead. <br\/><br\/>Replication codes are increasingly deployed in large-scale data centers in use by major internet companies. Advances in reconstruction codes are expected to translate into millions of dollars in savings in maintenance costs in such data centers. To ensure accessibility of the results of this research, implementation will be carried out using the open source Hadoop distributed file system, the preferred platform for cutting-edge research and development in distributed cloud storage.","title":"CIF: Small: Distributed Storage Systems from Combinatorial Designs","awardID":"1320416","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":[550838],"PO":["564924"]},"205859":{"abstract":"This is a multidisciplinary research program combining medical informatics, human-computer interaction and behavioral science exploring effective user-centric technology mediated reflection (TMR) to promote psychological well-being. It will design, develop and evaluate a radically new class of user-centric TMR system, thereby creating methods that will have much wider applications as well. People currently experience problems of memory and compliance in carrying out TMR. However these problems are addressable by computational intervention using mobile tools for user-centric TMR to capture data about personal events and support reflection about emotional reactions to those events. These mobile augmentation tools will overcome critical limitations of unaided reflection, by being lightweight, user tailored and context-aware, and they will support adaptive reminding about positive and negative events. Novel visualizations should also improve people?s ability to infer general patterns in emotional behavior in order to promote long-term behavior change.<br\/><br\/>Using predictions derived from prior social science, this research will test the efficacy of TMR for improved well-being when users remind themselves about positive events, adaptively deal with negative past experiences, and modify long-term behavioral patterns in response to events. The research will then contribute fundamental new scientific knowledge to the social and psychological sciences, in part because collection of data about memory states during real life experiences goes beyond what it is possible to measure within the confines of academic laboratories. In addition, the project will develop techniques to analyze how reminiscences about the same event change over time. This will allow the development of new psychological and clinical models concerning the relations between memory, emotions and well-being.<br\/><br\/>A significant fraction of the population experiences a major depressive episode at least once in their life, and other problems such as anxiety are also common, yet many people respond poorly to conventional forms of treatment, and the exact boundaries of these problems are poorly defined. Effective TMR can address these pressing problems, by providing new tools and an experimental platform that will enable the rigorous testing of TMR interventions, addressing calls for disruptive interventions in mental healthcare. It may be that one limitation of some current forms of treatment is that the benefits do not transfer well from the help-giver's office to the client's daily life, and mobile TMR may bridge that gap. Diaries composed with mobile devices can also contribute to more formal accounts of historical events, thereby facilitating the emergence of citizen science in which ordinary users collaborate with each other scholars and social scientists, to complete valuable projects and experience the enrichment of life-long learning. This project will also train undergraduates and graduate students in an interdisciplinary area of human computer interaction, medical informatics, and psychology.","title":"HCC: Small: Designing and Understanding Technology Mediated Reflection to Improve Well-Being","awardID":"1321102","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[551128],"PO":["564456"]},"210139":{"abstract":"This project is to organize a national conference with leading engineering, computer science and policy making thought leaders and exchange ideas on future energy management systems (EMS). The objectives of the new EMS architectures will particularly be discussed to support the premise that IT-enabled distributed loosely coordinated architecture is both efficient and robust during major unplanned natural disasters, like hurricanes and tornadoes. At present, EMS software does not have applications that enable electricity users to pro-actively respond to system conditions during such major natural disasters. There are no tools for fast bottom-up restoration, either. The workshop will address possible problem formulations for next generation multi-layered EMS architectures capable of incentivizing the groups of users (one may refer to them as the intelligent balancing authorities (iBAs)) to utilize resources as efficiently as possible during normal condition, and be sufficiently adaptive and flexible to ensure differentiated reliable service during single\/double equipment outages (planned for by the utilities now by keeping conservative stand-by the worst case reserves) as well as during natural disasters (for which utilities do not have methods to ensure reliable prioritized service without requiring excessive stand-by reserve). The workshop will explore how the distributed intelligence and the right IT signals with the right parallel asynchronous algorithms embedded into different layers would enable both social choice and system-level performance.","title":"Workshop Proposal: Data-Driven Energy Systems: From Data Collection to Information Technology for Sustainable Services","awardID":"1352133","effectiveDate":"2013-08-15","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[563201],"PO":["565255"]},"204705":{"abstract":"The critical role of spectrum as a catalyst for economic growth was highlighted in the 2010 National Broadband Plan (NBP). A challenge for the NBP is realizing optimal spectrum sharing in the presence of interference caused by rogue transmissions from any source, but particularly secondary users who share the spectrum. This complex problem straddles wireless technology, industrial economics, international standards, and regulatory policy. <br\/><br\/>This interdisciplinary, multi-university collaborative project studies the many dimensions of the problem from algorithms to law enforcement. The investigators study (1) ex-ante spectrum rule enforcement mechanisms (i.e., preventive) such as spectrum access control via policy reasoners, (2) ex-post spectrum rule enforcement schemes (i.e., punitive) with policy conformance monitoring that employ cryptographic commitments, (3) ex-post enforcement schemes that can uniquely identify rogue transmitters, and (4) the economic viability of spectrum sharing with different enforcement schemes.<br\/><br\/>The project provides a broad range of education and industry outreach activities in order to rapidly insert research advances into curriculum and university-industry partnerships. Specifically, the investigators will present short courses and tutorials at the annual Virginia Tech Wireless Symposium and Summer School, and widely disseminate findings through NSF Industry & University Collaborative Research Centers (I\/UCRC) at the Virginia Polytechnic Institute and State University.","title":"TWC SBE: Medium: Collaborative: Dollars for Hertz: Making Trustworthy Spectrum Sharing Technically and Economically Viable","awardID":"1314589","effectiveDate":"2013-08-01","expirationDate":"2017-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[548198],"PO":["565239"]},"205805":{"abstract":"The problem of matching representations of one set of objects, e.g., their images, to representations of another set of objects that achieves an optimal global measure of overlap (goodness of match) is ubiquitous in computer science, and remains a fundamental challenge in areas such as machine learning, computer vision, and computational biology. While some cases are solvable in polynomial time, a majority of those encountered in practice are computationally intractable - NP-hard. This research will exploit the fact that in many matching problems of interest the space to be optimized over has the (algebraic) structure of group, which allows one to leverage an entire spectrum of ideas from abstract algebra, including non-commutative harmonic analysis and fast Fourier transforms on groups. In addition to yielding efficient optimization schemes in several important cases, this algebraic approach has the potential to serve as a basis for developing novel matching algorithms and suggest new approaches for certain classes of combinatorial optimization problems. <br\/><br\/>The proposed research has four main goals: to design faster general purpose harmonic analysis-based quadratic assignment problem (QAP) solvers and apply these to alignment and matching problems; to develop \"tailored\" QAP solution methods by coupling them to a learning component, which leverages training data to solve subsequent QAP instances much more efficiently; to design multiresolution analysis-based algorithms which yield global solutions to multi-object tracking and matching problems; and, to implement a flexible open-source library which offers a wide variety of harmonic analysis functionality (with support for wavelet and other transforms) to encourage experimentation on a broad class of inference and optimization problems. This project will yield a powerful set of algorithms and open-source software that can be used by researcher in areas of machine learning, computer vision, and optimization.","title":"III: Small: Collaborative Research: Solving Matching Problems in Machine Learning with Non-commutative Harmonic Analysis","awardID":"1320755","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":["563992"],"PO":["564898"]},"205618":{"abstract":"Wireless sensor networks (WSNs) have the potential to significantly impact many aspects of our everyday life and are anticipated to be critically important for environmental monitoring, health monitoring, surveillance, military, and homeland security applications. Distributed parameter estimation serves as one of the main challenges in WSNs, where spatially distributed battery-powered sensors are deployed over a sensing field to monitor physical or environmental conditions. This research will investigate distributed estimation of an unknown vector with a general observation model, when the transmission strategy is digital. <br\/><br\/>The following three problems will tackled: (1) Bayesian Cramer-Rao bound (CRB) and linear estimators for hard-decoding and soft-decoding link layer designs. The Bayesian CRB will be derived and linear estimators will be developed. In hard-decoding design, the fusion center (FC) uses the recovered transmitted discrete messages for estimation, whereas in soft-decoding design, the FC uses directly the continuous-valued channel outputs for estimation. The impacts of the observation model, fading and communication channel noises and choice of modulation on the optimization solutions will be studied, and the existing tradeoffs between transmit power, rate, and estimation accuracy will be explored. Contrasting the power-rate-distortion regions will enable the investigator to quantify the performance improvement provided by soft-decoding (compared with hard-decoding) link layer design; (2) channel estimation problems in distributed vector estimation. The influence of wireless channel estimation errors on the distributed signal processing designs will be studied. Also, the investigator will study how the combined effects of channel estimation errors and energy cost of transmitting training symbols further limit the estimation accuracy; and, (3) distributed vector estimation in a cluster-based hierarchical network architecture with digital transmission. The existing tradeoffs between transmit power allocation among the clusters and the estimation accuracy will be explored.","title":"CIF: Small: Power-constrained distributed vector estimation in wireless sensor networks","awardID":"1319770","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":["559577"],"PO":["564898"]},"205629":{"abstract":"It is difficult to simultaneously convey the subtle forces and motions of a task to another person when teaching a physical skill. A common technique is for the expert to move the novice through the task. But this guiding motion is only partially effective at portraying the full experience because the novice only performs the task passively. To fully experience the physical interaction, an active recreation of the actions would be much more effective. The PI's goal in this research is to enable a person to recreate the actions performed by another person while fully experiencing the forces that result from those actions. To this end, the PI will explore a bimanual approach that takes advantage of our inherent ability to synchronize motions between both sides of our bodies, to allow a person to independently generate a desired path while feeling the task-related forces actively. Note how easy it is to simultaneously draw a pair of identical circles (or other shape) with both hands. Based on this observation, and in contrast to training methods that guide the dominant hand, the PI's method will guide the non-dominant hand and ask the individual to recreate the motions in the dominant hand, which will receive all the forces involved in the interaction. In this way, one arm will both receive forces while actively generating motions and will fully experience the task forces. Prior to implementing and testing this bimanual guidance method, several experiments will be conducted to determine the involved sensorimotor control parameters; specifically, hypotheses will be tested to evaluate our abilities to recreate a motion that is applied to one hand and to evaluate whether people can be taught to perceive passively applied forces similarly to actively applied forces. In contrast to methods that aim to make the physical interaction with an environment as realistic as possible, this method is transformative in that it aims to make the perception of the physical interaction as similar as possible to another person's actions by incorporating the human's sensorimotor control system. The scientific challenge lies in determining how the two modalities (force from one side and position from the other) are integrated and in determining and overcoming the sensorimotor delays associated with perception and recreating the force.<br\/><br\/>Broader Impacts: This research will fundamentally advance our understanding of force perception, bimanual interactions, and how forces and motions are cognitively integrated to perceive objects in active and passive tasks. The work will enable one person to fully experience the same physical interaction as another person, which will transform teaching and training techniques for surgeons, athletes, and helicopter and airplane pilots, among others. In addition to directly supporting a graduate and an undergraduate student, this research will also impact engineering students in the PI's class on haptics who will learn about performing psychophysical experiments on humans.","title":"HCC: Small: Perception of Accurate Interactions through Bimanual Integrated Forces and Motions","awardID":"1319802","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[550586],"PO":["565227"]},"198810":{"abstract":"BIGDATA: Small: DA: Classification Platform for Novel Scientific Insight on Time-Series Data<br\/><br\/>Abstract<br\/><br\/>The deepest insights into the nature of complex physical systems arise from the measurement of how observables of those systems change with time. Such dynamism - witnessed on scales ranging from atomic to Universal - reveals the underlying forces that govern the interaction of the constituents of those systems. The temporal sampling of data from sensors and from simulations, then, may be seen as a primary vector towards the deepest scientific insight. In this respect, mechanisms to quickly and robustly extract and mine knowledge from diverse time-series data can be fundamental tool of modern data-driven science. <br\/><br\/>This project will build a webservice portal for scientific teams to train state-of-the-art machine-learning algorithms on existing data and receive autonomously generated classification statements on new data, whatever the scale. Massive data storage and the scaling\/parallelism of computational algorithms (using commodity cloud services) will be abstracted from the end users. The envisioned framework will act both to simplify the algorithm selection and application processes as well as to educate the broad user base in modern machine-learning approaches. <br\/><br\/>This project will lead to the implementation of novel and efficient feature extraction algorithms on irregularly sampled time-series data, and will make them available in the context of a robust and scalable platform integrated with classification and cross-validation, that will lead to informed use of the algorithms for reliable scientific insight. This learning and prediction platform will accelerate data-intensive decision-making, and will be a new data analytics tool for the autonomous discovery of knowledge across a diverse range of scientific disciplines. Geo-scientists may use it to find new robust earthquake trigger algorithms, enabling on-the-fly decision-making to improve emergency response times. Astronomers may rapidly detect anomalies, identifying a class of new variable stars buried within data from a time-domain imaging survey. Neuroscientists could incorporate improved real-time feedback and prediction into prosthetics control systems. As an intelligent agent, the platform could be used as an automated annotator for streaming biomedical data.<br\/><br\/>This work will deliver a new open-source toolkit and web platform that can serve as a fundamental tool for time-domain science. By design, it will grow organically as user-contributed code is integrated into the platform. With burgeoning adoption among some data-driven science disciplines the webservice will emerge as an educational platform in the use of learning algorithms for time-series data and as a societal service that can be used by anyone (even outside of traditional scientific disciplines) to test hypotheses on large scales with minimal effort. The website will also act as a public repository for large, well-described datasets useful for validating new time-series classification and prediction algorithms. A series of short and semester-long courses will be developed (and broadly disseminated) to teach a new generation of scientists how to use the platform (and other widely available resources) as central 21st century research instruments.","title":"BIGDATA: Small: DA: Classification Platform for Novel Scientific Insight on Time-Series Data","awardID":"1251274","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8083","name":"Big Data Science &Engineering"}}],"PIcoPI":[533371,533372],"PO":["565292"]},"204739":{"abstract":"Many simulation algorithms depend on an underlying spatial discretization---a mesh that decomposes the domain into a finite set of elements that can be analyzed by a computer. The quality of the simulation is, in part, determined by the quality of the mesh. However, in the past, mesh generation and simulation were done as separate processes. Better results can be achieved by tightly integrating simulation with mesh generation and recent advices in computational topology provide the key to doing so. Computational topology allows for the analysis of the structure of data---in this case simulation variables. By understanding the structure of the simulation the mesh generation algorithms can adapt to it, providing meshes that are closely linked to the actual simulation.<br\/><br\/>Because simulation is a powerful tool for discovery throughout computational science, this research has the potential to have broad impact across all fields of science and enable new scientific breakthroughs that could have tremendous societal impact. This research will also produce open-source software, short courses, and workshops around the topic of coupling simulation and meshing. The interdisciplinary nature of this project will lead to a rich educational and research environment for graduate and undergraduate students. The project web site provides access to research results, software and educational materials (http:\/\/sealab.cs.utah.edu\/SimulationMeshingTopology).","title":"CGV: Large: Collaborative Research: Coupling Simulation and Mesh Generation using Computational Topology","awardID":"1314757","effectiveDate":"2013-08-01","expirationDate":"2017-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[548281],"PO":["563751"]},"205839":{"abstract":"In forensic investigations, the skeletal evidence analysis and facial reconstruction play important roles in identification of the decedent. In current practice, effective skull processing and facial reconstruction are accomplished manually. This project studies 3D geometric analysis and modeling algorithms to automate and augment fragmented\/incomplete skull restoration and craniofacial reconstruction and advocates a potential evolution of manual processing to a digital platform for better efficiency, robustness, and objectivity. Two key challenging problems to solve in these forensic tasks are geometric restoration (from small fragmented pieces) and geometric shape synthesis (with complex geometric and semantic constraints). This project studies effective 3D shape matching and transformation techniques to tackle these problems. Geometric restoration is solved through reliable partial matching and symmetry guidance; geometric synthesis is explored via heterogeneous volumetric deformation that enforces given geometric constraints on non-uniform interior layers. <br\/><br\/>The new geometric algorithms can benefit incomplete data modeling and analysis in many computer graphics and vision tasks. In this project, computer scientists are collaborating with forensic specialists to build a digital computational platform and evaluate the application of these new geometric algorithms in forensic skull processing and craniofacial reconstruction. This project facilitates incomplete data analysis and reconstruction in forensic law enforcement, archaeology, biological anthropology, and craniofacial orthopedics. The research and education are integrated by taking research advances into existing and future courses, involving RET\/REU\/K-12 students in geometric modeling research and graphics\/visualization system development; and attracting K-12 and under-representative students into STEM education.","title":"CGV: Small: Digital Forensic Facial Reconstruction from Incomplete Datasets","awardID":"1320959","effectiveDate":"2013-08-15","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[551072,551073,"531467"],"PO":["564316"]},"210955":{"abstract":"The recent emergence of a variety of high-throughput DNA sequencing instrumentation, and the concomitant rapid decline in the cost per base, is causing severe data deluge in all areas of life sciences. The heterogeneity of sequencing instrumentation and the vast diversity of applications enabled by them are creating numerous analytics problems for the bioinformatics community to address. In addition, the conventional serial algorithms that have been the mainstay of bioinformatics research are severely challenged by the ever increasing data sets. The goal of the proposed project is to develop core techniques and software libraries to enable scalable, efficient, high performance computing solutions for high-throughput DNA sequencing, also known as next-generation sequencing (NGS). To empower the larger community, the project seeks to 1) identify a set of core functionalities that frequently occur in many types of high-throughput sequencing applications, 2) develop efficient parallel algorithms and high performance implementations for them, 3) pursue mapping to HPC architectures including clusters, multicores, and GPUs, 4) develop software libraries encapsulating these functionalities with the goal of enabling the bioinformatics community to exploit HPC architectures, and 5) design a domain specific language to enable bioinformatics researchers unfamiliar with parallel processing to benefit from this work through automatic generation of parallel codes. The research will be conducted in the context of challenging problems in human genetics and metagenomics, in collaboration with domain specialists.<br\/><br\/>This project is focused on a key capacity building activity to facilitate pervasive use of parallelism by NGS bioinformatics researchers and practitioners. The goal is to empower the broader community to benefit from clever parallel algorithms, highly tuned implementations, and specialized HPC hardware, without requiring expertise in any of these. The software libraries will be released as open source for use, further development, enhancements, and incorporation by the community. The project will provide opportunities for training postdoctoral and graduate students in bigdata analytics and computer science driven interdisciplinary research. Diverse existing mechanisms at the partner institutions will be leveraged to advance goals of minority and women recruitment, undergraduate participation in research, and K-12 outreach.","title":"BIGDATA: Mid-Scale: DA: Collaborative Research: Genomes Galore - Core Techniques, Libraries, and Domain Specific Languages for High-Throughput DNA Sequencing","awardID":"1416259","effectiveDate":"2013-08-31","expirationDate":"2015-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8083","name":"Big Data Science &Engineering"}}],"PIcoPI":[565135],"PO":[565136]},"199108":{"abstract":"Creating and maintaining software is an increasing challenge for software developers. Software development tools can help meet this challenge, but most developers use only a small subset of the available tools because they are unaware of the existence of relevant tools. To learn about relevant tools, prior work suggests that most effective approach is social learning, where a developer learns about a tool from a peer, yet research also suggests that social tool learning is rare. The aim of this research is to increase the frequency and effectiveness of social tool learning, and in turn, fundamentally advance our understanding of how technology can mediate tool learning in software development and beyond. In reaching this aim, we will help improve the software on which people increasingly rely.<br\/><br\/>The researchers will create a testbed system that will record a continuous screencast of the developer's work, indexed with time-stamped data on tool usage. By comparing the developer's tool usage data with her peers', the system selects a list of candidate tools that the developer does not use, but that her peers do use. The system then encourages peers to teach and learn from one another by sharing tool-usage clips chosen from each others' screencasts. The approach aims to enable distributed and asynchronous developers to share tool knowledge efficiently, effectively, and frequently. The testbed will allow the researchers to experiment with various types of tool learning to determine how, why, and when different types of tool learning are effective or ineffective.","title":"CAREER: Expanding Developers' Usage of Software Tools by Enabling Social Learning","awardID":"1252995","effectiveDate":"2013-08-01","expirationDate":"2018-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["549910"],"PO":["564388"]},"210614":{"abstract":"High-throughput next-generation DNA sequencing technologies (NGS) are causing a major revolution in life sciences research by allowing rapid and cost-effective sampling of genomes and transcriptomes (expressed genomic sequences). Assembly of genomes and transcriptomes from billions of such randomly sampled sequences is an important problem in computational biology. While significant strides have been made, much work remains in addressing the diverse and rapidly emerging platforms, improving assembly quality, and scaling to both large-scale data sizes and large genomes.<br\/><br\/> This project will harness the power of high performance computing to develop effective solutions for sequence assembly. It will lead to the development of scalable, efficient parallel algorithms and a parallel integrated software framework for genome and transcriptome assembly. The project seeks to advance the state of the art by targeting important unsolved problems such as hybrid assembly of sequences from multiple NGS platforms, making fundamental algorithmic advances to improve assembly quality, and conducting an in-depth effort at parallel algorithms development for the entire gamut of problems that arise in connection with assembly. It will be carried out by an interdisciplinary team of investigators, in partnership with leading NGS manufacturers and academicians involved in large plant genome sequencing projects.<br\/><br\/> The project will lead to the release of a scalable parallel software package for sequence assembly that will be made available to the scientific community. Postdoctoral and graduate students will be trained in computer science driven interdisciplinary research and in writing efficient high performance computing software. The project will influence curriculum development and will lead to educational materials in bioinformatics for next-generation sequencing.","title":"AF: Medium: Parallel Algorithms and Software for High-Throughput Sequence Assembly","awardID":"1360593","effectiveDate":"2013-08-12","expirationDate":"2015-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["565135"],"PO":["565223"]},"202837":{"abstract":"This award is aimed at the development and community release of a Wideband Software Extensible Radio (WiSER) platform along with a reference implementation for small outdoor deployment of a multi-node dynamic spectrum network. Dynamic spectrum technologies are strategically important to the wireless community because of the urgent need to alleviate spectrum congestion resulting from ongoing exponential growth in mobile data usage. While a great deal of theoretical work has already been done on dynamic spectrum techniques, definitive experimental evaluations of potential gains have yet to be conducted. The lack of experimental research is mainly due to the fact that available open platforms suitable for academic experimentation with software defined radio (SDR) are limited to first-generation technologies that operate at low bandwidth and can only handle a limited amount of MAC\/PHY customization due to inherent processing constraints. The proposed WiSER platform is a second generation wideband open-source SDR platform that will enable new experimental research in the fields of dynamic spectrum and cognitive radio networking. The WiSER radio?s target release is timed to coincide with significant new national research and policy initiatives in dynamic spectrum involving the NSF, FCC, PCAST, NIST, DARPA and other agencies. This platform enables a richer range of experimental dynamic spectrum research than is currently possible because of its key technical features: operation across 400MHz-4000MHz in 125MHz increments, hardware acceleration for real-world PHY waveforms at speeds of 100 Mbps and higher, hardware virtualization capable of supporting multiple radios on the same platform, and an open-source software toolkit. <br\/><br\/>This project will develop a community resource supported by currently available radios along with an open-source software framework and reference system implementation. Such a resource will allow for research into a very scarce and important public resource ? radio spectrum. By improving reliable access to spectrum, our society benefits in terms of enhancing mobile broadband, improving public safety communications, and ensuring that radar and other spectrum uses are not degraded as the spectrum becomes more densely used. The WiSER team will work closely with experimental research groups nationally to help develop relevant and timely experimental deployments of dynamic spectrum technology. Dynamic spectrum access technology has the potential for order-of-magnitude improvement in spectrum efficiency necessary to cope with the recent explosion of mobile data traffic. Cognitive radio systems will also provide improved connectivity to end users, and enable new applications such as emergency response systems and automotive networks. This project will directly inform these important societal needs by enabling the research community to build state-of-the-art experimental systems for conclusive evaluation of these emerging technologies. Lastly, this platform will offer a powerful educational tool for students wanting to better understand modern digital and software-based radio communications.","title":"CI-ADDO-NEW: Collaborative Research: WiSER Dynamic Spectrum Access Platform and Infrastructure","awardID":"1305405","effectiveDate":"2013-08-01","expirationDate":"2015-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[543625,543626],"PO":["565303"]},"204729":{"abstract":"Cloud computing allows users to delegate data and computation to cloud providers, at the cost of giving up physical control of their computing infrastructure. An attacker with physical access to the computing platform can perform various physical attacks, referred to as digital insertion and observation attacks, which include probing memory buses, tampering with memory, and cold-boot style attacks. While memory encryption can prevent direct leakage of data under digital observation, memory access patterns to even encrypted data may leak sensitive information. This work will allow organizations to securely outsource their computing infrastructure to an untrusted cloud provider, while preserving a similar level of security as if hosting the infrastructure in house<br\/><br\/>This project will develop DIORE (Digital Insertion and Observation Resistant Execution) which is a combined hardware software platform immune to digital insertion and observation attacks. DIORE provides memory-trace oblivious execution, relying on efficient hardware implementations of Oblivious RAM, and novel compiler techniques for partitioning programs such that Oblivious RAM accesses are minimized. This ensures that an adversary with access to a program execution's memory trace learns nothing about the code or data other than what is revealed intentionally. DIORE opens up possibilities for new cloud applications involving sensitive information such as genomic, medical, or financial data -- domains that are considered too privacy sensitive for today's cloud.","title":"TWC: Medium: Collaborative: DIORE: Digital Insertion and Observation Resistant Execution","awardID":"1314709","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[548259],"PO":["565264"]},"198119":{"abstract":"Bioinformatic data sets are large and complicated. Marshalling and managing necessary resources (e.g., hardware; computer and programmer time) requires significant skill. Effective analysis and comprehension involves sophisticated statistical understanding. Domains of application and available data types change rapidly, requiring flexible and familiar programming environments. Collaborations involve diverse research groups of heterogeneous size and expertise. This project develops and disseminates new and efficient approaches to solving present and emerging problems in statistical analysis and interpretation of very large data. The project combines the strengths of two very widely used and complementary bioinformatics projects, Bioconductor and Galaxy.<br\/><br\/>The project has three components. The first, providing scalable access, develops R programming paradigms appropriate for scalable analysis. R\/Bioconductor software will be developed for efficient reduction of large data to statistical descriptions by iterating data through transformation kernels. Bioconductor will be deployed for use in an accessible cloud-based environment, and will be integrated into the Galaxy deployment scheme. The second component is to provide statistical methods for big genomic data bydeveloping high performance statistical methodologies for analysis of large bioinformatics data. This applies the initial technical achievements to specific requirements of statistical analysis in genomics. Domains of application include: quality assessment and normalization of very large raw data; data reduction and uncertainty measure calculation for downstream interrogation; and discovery, reporting and auditing of novel biological findings. Developments require novel computational approaches that avoid all-data-in-memory computational models (prevalent in current algorithm implementations), and that re-express monolithic algorithms as concurrently executable independent components. This emphasizes extensible and composable elements to yield a richer toolkit for statistical genomics. The aim leverages R?s strength as a language for rapid development of statistical methodologies, and emphasizes areas of proven strength in the Bioconductor project. The third component addresses decision making. This aspect provides integration of R \/ Bioconductor work flows into Galaxy. We will deploy key results from Aim 2 as Galaxy work flows. New real-time feedback for streaming analytics will be introduced to Galaxy, and leveraged by Bioconductor.<br\/><br\/>The project includes very significant capacity building. The Bioconductor project successfully solicits, tests, and disseminates over 600 R packages for the statistical analysis and comprehension of high-throughput genomic data. All packages include extensive documentation, including vignettes describing intent, function, and interoperability. Packages reflect contributions from a broad scientific community, and enable national and international graduate, post-graduate, and commercial research activities in statistical, bioinformatic, and computational domains. This project furthers the capacity building impact of Bioconductor by addressing memory and performance limitations to statistical analysis of large and complicated bioinformatic data. Galaxy enables broad access to computational resources for data intensive biomedical research. This project enhances the capacity building impacts of Galaxy by providing scalable processing of big bioinformatic data, and enabling exploratory analysis by a broad bioinformatic community. The coupling of Bioconductor and Galaxy provides significant synergy, facilitating rapid translation of statistical and bioinformatic research developed in R to broad use through Galaxy.","title":"BIGDATA: Mid-Scale: DA: ESCE: Collaborative Research: Scalable Statistical Computing for Emerging Omics Data Streams","awardID":"1247813","effectiveDate":"2013-08-01","expirationDate":"2015-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8083","name":"Big Data Science &Engineering"}}],"PIcoPI":[531685],"PO":["565136"]},"210505":{"abstract":"The goal of this research is to create a flexible, micro-scale additive manufacturing platform utilizing a team of untethered micro-scale robots and modular, multifunctional building blocks to create smart micro-devices and structures. Externally applied magnetic fields are commonly used for the power and actuation of individual magnetic mobile microrobots. However, in order to achieve different behaviors from individual robots within a team of microrobots, there must be either significant variation in their design or in the magnetic control signals applied to each microrobot.<br\/><br\/>The intellectual merit of this research, therefore, lies in the novel approach to create a specialized magnetic potential field generating substrate from MEMS-fabricated planar microcoils and the related control methodology to enable truly independent control of multiple mobile microrobots. Thus, the research objectives of the proposal are: the design and fabrication of the micro-coils and related control electronics; motion control for mobile magnetic microrobot swarms; and magnetic microrobot and modular component design and fabrication, based on specialized micro-components with various material properties and functions.<br\/><br\/>Successful completion of the objectives will result in a transformative mobile microrobot swarm platform capable of executing various advanced additive manufacturing tasks. Potential applications include very high-density energy storage, high strain actuation, energy harvesting, very low power communications devices, and composite structures with integrated sensors. Further broader impacts of this project reside in disseminating the research output in industry and academia along with an educational agenda spanning related outreach activities from the K-12 through graduate levels.","title":"RI: Medium: Collaborative Research: Mobile Microrobot Platform for Advanced Manufacturing Applications","awardID":"1358446","effectiveDate":"2013-08-01","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[564068],"PO":[564069]},"202805":{"abstract":"This Computing Research Infrastructure project aims to enhance Worcester Polytechnic Institute's (WPI) high-performance infrastructure to support its ongoing research and education centered around big data analytics over scalable infrastructure. The enhanced compute clustering will provide a scalable infrastructure to support large-scale data analytics research along a number of important directions, including (1) a full-fledged software platform for seamlessly supporting large-scale continuous and recurring workloads with stream-window-centric query processing, (2) scalable annotation and provenance management for natively supporting annotations as first-class citizen over big data and exploiting their semantics in query processing and quality inference, (3) complex event analytics that combines complex event processing with OLAP techniques for efficient multi-dimensional event pattern detection in high-speed large-volume data, and (4) multi-model-driven analytics system on high-velocity data streams with visual exploration of the derived models and patterns. The projects collectively address key research challenges related to the analysis of large volume, high velocity, and wide variety of data.<br\/><br\/>The infrastructure is expected to significantly enhance the integration of research and education at both the undergraduate and graduate levels at WPI, including in particular, WPI's project-oriented undergraduate curriculum, which requires each undergraduate to complete a year-long research project. The infrastructure will also benefit a diverse group of researchers at WPI in different departments -- as is the case with the current compute cluster -- to conduct their data-intensive research. Broad dissemination of results of research enabled by the infrastructure including research publications, open-source software, and educational materials are expected to benefit the scientific community at large.","title":"II-EN: Compute Infrastructure for Large-Scale Data Analytics","awardID":"1305258","effectiveDate":"2013-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[543519,543520,543521],"PO":["560586"]},"203806":{"abstract":"This collaborative research project aims at developing mathematical methods for the analysis\/mining of large scale, high dimensional data that arise in engineering\/physicochemical computations, and, more importantly, in exploiting these methods and algorithms to accelerate the computations themselves. This type of synergy between data mining and scientific computation has the potential to significantly enhance the way we extract knowledge from large scale modeling and simulation. The focus of the approach is the discovery a small number of key, intrinsic features of simulations characterized by very large numbers of degrees of freedom - and the exploitation of these key features to systematically design subsequent simulations. Another important feature of the work is the development of algorithms that \"translate\" between fine scale, detailed, and coarse scale, compact descriptions of the data, as well as algorithms for the fast incorporation of new data\/information in previous computational frameworks. Deliverables of the effort will be the algorithms themselves, as well as documented illustrative examples of their application to large scale molecular and agent-based simulations.<br\/><br\/>If successful, this research will create, document and make available a computational protocol for enhancing large scale scientific computations in the modeling of complex dynamical systems. Example applications include nanoscale self-assembly, such as micelle formation in materials computations, macromolecular foldling, large scale agent-based models of collective motion in ecology and cellular biology, as well as large scale, Partial Differential Equation simulations of engineering problems, like combustion. The results will be disseminated to allow their use by other researchers. The research will form the basis of cross-disciplinary education of graduate students in engineering and in mathematics, and of undergraduate research projects in these disciplines. It will also underpin the development of course materials in large scale data processing.","title":"CDS&E\/Collaborative Research: The Integration of Data-Mining with Multiscale Engineering Computations","awardID":"1310173","effectiveDate":"2013-08-15","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"8069","name":"CDS&E-MSS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"8084","name":"CDS&E"}}],"PIcoPI":[545920,545921],"PO":["565069"]},"204708":{"abstract":"The critical role of spectrum as a catalyst for economic growth was highlighted in the 2010 National Broadband Plan (NBP). A challenge for the NBP is realizing optimal spectrum sharing in the presence of interference caused by rogue transmissions from any source, but particularly secondary users who share the spectrum. This complex problem straddles wireless technology, industrial economics, international standards, and regulatory policy.<br\/><br\/>This interdisciplinary, multi-university collaborative project studies the many dimensions of the problem from algorithms to law enforcement. The investigators study (1) ex-ante spectrum rule enforcement mechanisms (i.e., preventive) such as spectrum access control via policy reasoners, (2) ex-post spectrum rule enforcement schemes (i.e., punitive) with policy conformance monitoring that employ cryptographic commitments, (3) ex-post enforcement schemes that can uniquely identify rogue transmitters, and (4) the economic viability of spectrum sharing with different enforcement schemes.<br\/><br\/>The project provides a broad range of education and industry outreach activities in order to rapidly insert research advances into curriculum and university-industry partnerships. Specifically, the investigators will present short courses and tutorials at the annual Virginia Tech Wireless Symposium and Summer School, and widely disseminate findings through NSF Industry & University Collaborative Research Centers (I\/UCRC) at the Virginia Polytechnic Institute and State University.","title":"TWC SBE: Medium: Collaborative: Dollars for Hertz: Making Trustworthy Spectrum Sharing Technically and Economically Viable","awardID":"1314598","effectiveDate":"2013-08-01","expirationDate":"2017-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[548204,548205],"PO":["565239"]},"210913":{"abstract":"This project studies the design of information systems like wikis and information markets. Research in social science has established that often there is a \"wisdom of the crowd\" -- i.e., collectives can display more intelligence than the individuals they are composed of. When such collective information systems work, they serve as superb aggregators and disseminators of information. However, fundamental computational challenges remain in understanding how to design them optimally.<br\/><br\/>This research is advancing along several lines, including<br\/><br\/>(1) general theories of how information is aggregated in different social media, developed and validated using real data gathered from existing databases and generated from user experiments; <br\/><br\/>(2) algorithms for facilitation of user interactions so that the medium in question can deliver the promised results (for example, market-making algorithms for liquidity provision in information markets);<br\/><br\/>(3) theoretical and practical characterization of the possibilities for rogue users to manipulate collective wisdom systems;<br\/><br\/>(4) algorithms for detecting malicious users, and mechanisms that thwart miscreants. <br\/><br\/>The research is naturally interdisciplinary in nature, drawing from machine learning and probabilistic reasoning, data mining and social networks, as well as finance and economics. It contributes to our understanding of complex social phenomena like the growth of information in wikis and blogs, as well as to the development of intelligent reasoning algorithms for agents in complex, uncertain multi-agent environments like markets.<br\/><br\/>The design of agents that participate in markets and social systems improves the quality of online markets and improves information flow in virtual spaces. Further, insights gained from modeling market structures and social spaces can tell us how to design them better. For example, understanding the impact of different levels of central control on wiki articles or open source software projects yields guidelines for how much central control is optimal in different settings.<br\/><br\/>In a world where computation and social systems are increasingly intertwined, the PI's research and education program exposes students to multidisciplinary ideas through the introduction of a new class on collective intelligence, social networks and e-commerce, and the development and extensive use of the very objects of study -- information markets and wikis -- in classroom and lab settings. The PI is also developing an experimental project for putting freely accessible course wikis online, similar to online course materials at other universities, but open to editing by the community.","title":"CAREER: The Dynamics of Collective Intelligence","awardID":"1414452","effectiveDate":"2013-08-10","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[565034],"PO":[565035]},"198989":{"abstract":"Two types of users, Primary Users (PUs) and Secondary Users (SUs), share common spectrum bands in Cognitive Radio Networks (CRNs). SUs communicate through un-assigned spectrum bands without disrupting PUs. It is widely assumed that the activities of PUs follow some probabilistic models regardless of time, geography and social relationships. However, the time-and-geography-dependent social activity patterns of PUs can definitely be taken advantage of by SUs to obtain more spectrum opportunities and help with featuring the fundamental characteristics of CRNs in a more meaningful way. Unfortunately, this fact has been overlooked. This project conducts a comprehensive study on designing routing protocols\/algorithms integrating technologies from social networks and traditional CRNs. New statistic learning models and community detection methods considering PUs' activity patterns are proposed. The fundamental properties of secondary networks under certain activity patterns and community patterns of PUs are investigated. Corresponding guidance for designing upper layer protocols for CRNs is provided. This project has a strong impact on both theoretical and practical aspects of CRNs as well as social networks. Considering the characteristics of PUs, new research challenges and significance of the corresponding problems are elaborated. The project integrates research and education with the intent of attracting undergraduate and graduate students to the area of CRNs. It also outreaches high school students. The outcomes will provide valuable resources for the CRN society and will be published in conferences, journals, and on the Internet.","title":"CAREER: Routing in Cognitive Radio Networks Considering Activities of Primary Users","awardID":"1252292","effectiveDate":"2013-08-01","expirationDate":"2018-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[533838],"PO":["557315"]},"198803":{"abstract":"Detailed three-dimensional models of urban environments provide critical information for many applications, including emergency response preparation, security analysis, urban planning, and augmented-reality maps. For example, if 3D models of complete cities were publicly available with detailed labels for all semantic objects (e.g., buildings, fire hydrants, fire escapes, doors, windows, trees, etc.), then fire fighters, police forces, and other emergency response teams could use them to make plans for rescue operations, taking into account possible access points, lines of sight, and risks to the neighborhood. Or, if the 3D model contained labeled representations of stop lights, traffic signs, parking spaces, store locations, mailboxes, and ATMs, then augmented reality displays could help people navigate their daily lives.<br\/><br\/>The research goal of this project is to develop algorithms to build detailed, labeled 3D models from currently available data. Several companies (e.g., Google, Nokia, Microsoft, etc.) are currently collecting photographic imagery and LIDAR data with scanners mounted on cars driving up and down streets of cities throughout the world. This data contains a vast amount of information about our world, but in a very primitive form: pixels and points. The PI is developing algorithms to analyze this raw data to build semantically labeled 3D models: 1) new methods for discovering correspondence relationships between heterogeneous data types, focusing on LIDAR, images, and 3D polygonal models found in online repositories, 2) new ways to infer surface geometry, segmentations, and labels simultaneously based on a model learned from examples, 3) new interactive systems to allow users to visualize and guide the algorithms as they operate by incorporating user input into incrementally updated solutions, and 4) data management algorithms for multiresolution storage, compression, and retrieval of massive scanned 3D data sets.<br\/><br\/>The broader goals of the project include educational programs, industrial collaboration, free distribution of software and data sets, and outreach activities. Besides the published research results, the PI will disseminate 3D models of major cities that can be used directly in applications developed by other people. He will also distribute code, benchmark data sets, and statistical models that could benefit researchers in a variety of disciplines. This proposed work is integrated with educational programs, including interdisciplinary workshops and courses at the graduate, undergraduate, and professional levels, and diversity enhancement programs that promote opportunities for disadvantaged groups","title":"BIGDATA: Small: DA: Semantic Modeling of Cities from Scanned Data","awardID":"1251217","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8083","name":"Big Data Science &Engineering"}}],"PIcoPI":[533355],"PO":["565272"]},"209030":{"abstract":"This project explores the extent to which personality traits predict privacy and security behaviors. Over the past decade, computer privacy and security have improved by leaps and bounds by considering human factors in the design process. However, previous work to improve the usability of privacy and security systems has only examined the behaviors of \"average users,\" which is believed to only yield local maxima because no individual perfectly fits this profile. Therefore, this project is examining the extent to which additional improvements can be made by catering system designs to individual differences (e.g., in personality traits). Through a series of surveys and controlled experiments, researchers are discovering how these personality traits are predictive of certain privacy decisions, as well as interactions with various security mitigations. For instance, knowledge of a user's personality traits may result in more appropriate default privacy settings on a social networking website or web browser security warnings that are more salient to that user. The researchers' goal is to ultimately design systems that infer personality traits and then adjust privacy and security mechanisms so as to yield outcomes that are optimally aligned with a particular user's preferences.","title":"EAGER: Designing Individualized Privacy and Security Systems","awardID":"1343451","effectiveDate":"2013-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[560277],"PO":["565327"]},"209283":{"abstract":"The insecurity of most software update systems poses a major security risk. As a result, an attacker with a minimal amount of technical knowledge can cause a huge amount of damage to a huge number of computers. This poses a potential crisis for global security, with the scientific community a particularly likely victim. The scientific community possesses computational resources that are particularly attractive to hackers. The high speed networks and computation available to scientists would make an excellent platform for sending SPAM, flooding major sites with traffic to knock them off the Internet (DDOS), or even launching cyber-warfare attacks against US targets.<br\/><br\/>TUF (The Update Framework) is a tool, developed in prior research by the PI, to secure their new or existing software update systems. Software update systems are vulnerable to many known attacks, including those that can result in clients being compromised or crashed. TUF helps solve this problem by providing a flexible security framework that can be added to software updaters. This project will transition our TUF tool into practical use for secure package management. The added security will be completely invisible to users unless an attack is underway, silently preventing malicious package manager attacks from being effective. TUF provides unique capabilities for secure key revocation, private security update retrieval, and offline\/online hybrid role protections. This work will protect millions of government systems, military servers, scientists, and average internet users from attack.","title":"TTP: Securing Python Package Management with The Update Framework (TUF)","awardID":"1345049","effectiveDate":"2013-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[561066],"PO":["564388"]},"205390":{"abstract":"The distinction between computing and communication has blurred with the improvements in semiconductor technology as well as the speed and reliability of computer networks. At a macroscopic level, individuals increasingly rely upon smart phones, cloud computing, and similar infrastructure that combines computing systems with networking to accomplish their daily tasks. Many end-users even consider the client device, the server, and the network as one blended unit that is used for productivity and\/or entertainment. At the microscopic level, the linkage between the two areas ideally should not require the use of special-purpose software, because installing software on a network node to enable this blending can potentially cause the node to be unstable or more complex, and potentially introduce security flaws. However, linking the two domains without the use of additional software remains a significant challenge. This research focuses on understanding and characterizing the connection between the computing node and the network to meet that challenge. For example, by simply probing a node's network traffic and collecting its responses, it can be determined that the internal components (e.g., microprocessor) are heavily utilized. If the node is expected to be idle, then this indicator could signal that the node has been compromised and is running unauthorized software.<br\/>\u00a0<br\/>This project uses a holistic approach that combines computer architecture and computer networking to investigate and characterize how the microarchitecture affects the network packet generation process. Since the internal components of a node are shared resources among all processes, including those that require network-based I\/O, it is possible to infer the load on the internal components by observing variations in delay between successive network packets that are generated by the node. This inference materializes as a \"delay signature,\" and can be used to blend the areas of architecture and networking. The delay signature provides information that can be attributed to the internal state and settings of the microarchitecture. Architectural settings, such as processor affinity, multi-threading, and power-saving modes, affect the delay signature. The PIs use a hardware testbed and a system simulator to characterize and model the basic system components that can have a significant (direct or indirect) impact on packet generation. The project culminates with the creation of a general-purpose engine that automates the detection of utilization signatures and uses those signatures to predict node utilization remotely. The PIs incorporate team-based laboratory projects within their computer architecture and computer networking courses to demonstrate the relationship between the two domains and to promote integrated learning by students in both areas. Further, the investigators employ an outreach plan with complementary components to: (1) encourage students to enter the science and engineering fields and (2) mentor potential faculty members to serve as educators and role models. Potential applications of the delay signature include: (1) providing security for networked nodes by monitoring unauthorized utilization and (2) providing efficient scheduling in cluster grids.","title":"SHF: Small: Collaborative Research: Delay Signatures: Blurring the Boundary between the Network and the Processor","awardID":"1318571","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":[549985],"PO":["366560"]},"205181":{"abstract":"Functional logic languages seamlessly integrate the most appealing features of the functional and the logic paradigms: independence from evaluation order, higher-order functions, and polymorphic typing from the functional paradigm, and evaluation with partial information (logic variables), constraint solving, and non-deterministic search for solutions from the logic paradigm. Unfortunately, compiling a language with this rich combination of features is a difficult problem. Code generators of current compilers for functional logic languages are complicated ad-hoc modules that, with two exceptions, do not even attempt to address in a disciplined way the correctness of the generated code or relate its performance to that of the source code. The exceptions state the correctness in a very weak, double negative form: no result of a source program is not producible by the object program.<br\/><br\/>This project is for the design and implementation of a disciplined compiler for the functional logic language Curry. The generated code will be abstract and easily mappable to common programming languages and hardware architectures, and will be formally defined and proved correct. In particular, every result of a source program will be produced by the object program. The steps executed by the generated code will be closely related to the needed steps in a formal model of the source code. This will ensure that program executions will be more predictable and as efficient as theoretically possible. The code produced by the research will be available to the research community as part of a modern compiler for Curry.","title":"SHF: Small: A principled compiler for functional logic languages","awardID":"1317249","effectiveDate":"2013-08-15","expirationDate":"2015-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":[549403],"PO":["564588"]},"208591":{"abstract":"This award will support student travel to the ninth ACM\/IEEE Symposium on Architectures for Networking and Communications Systems (ANCS), which will be held in in October in San Jose, California. ANCS is a top conference in the fields of computer architecture and networking. The funds will help support U.S. students, focusing on Ph.D. students at an advanced stage in their program and students who would otherwise not be able to attend ANCS. Supporting student travel to attend professional conferences and workshops is a very important mission of the NSF. Broader impacts include training the next generation of researchers in this important research area.","title":"Travel Support for the Symposium on Architectures for Networking and Communications Systems","awardID":"1340876","effectiveDate":"2013-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":[559098],"PO":["565264"]},"208096":{"abstract":"This project will investigate the ethics and values of the computer scientists, information scientists, and software engineers who create algorithms. The research will contribute to the study of ethics and values in science and engineering in four key ways. First, it will bridge silos between philosophical and social scientific approaches to ethics to develop an integrated theoretical approach which simultaneously identifies the analytical, moral reasoning that is happening during the conceptualization and design phase as well as critically analyzes the interplay between an individual's personal ethics and values and the ethics and values created by aspects of policies, institutional, economic, and cultural contexts. Second, the work will further the literature on information ethics by taking an upstream approach that focuses on the design process. The literature concerned with the ethical use of information technology and computer science often focuses on the outcomes of these endeavors; switching the analytical lens, the PI will join a small but growing literature that addresses ethical questions at the design stage. Third, the research will provide an empirical contribution to information science given its investigation of the intersection of people, technology design and knowledge. Finally, by focusing on algorithms, the project will contribute to broader discussions about ethics, values, and big data; algorithms are the driving technique behind the creation of big data sets, yet there is little talk about the decisions and values that shape algorithm design and thus impact big data content.<br\/><br\/>Broader Impacts: The interrelationship between algorithms and big data is a timely and important topic for investigation. This research will open the black box of algorithmic design in order to provide more transparency for public discussion and debate on the implications of this new way of organizing knowledge and social life. Project outcomes will include a series of provocative images, concepts, and scenarios (to be presented in a well-designed series of cards), to impact graduate students in computer science, information science, and engineering. The PI plans to work with professional organizations such as the Association of Computing Machinery [ACM] and Computer Professionals for Social Responsibility [CPSR] to address a wider range of issues in the professional code of ethics.","title":"EESE: The Ethics of Algorithms","awardID":"1338205","effectiveDate":"2013-08-15","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7787","name":"EESE"}}],"PIcoPI":[557628,"436600"],"PO":["565227"]},"205380":{"abstract":"Current worldwide trends towards remote data storage solutions such as cloud storage, in which large stores of data on insecure networks must be efficiently accessible, and increasing security requirements emphasized the need to support efficient search functionality on large encrypted databases. Searchable encryption is a balancing act of efficiency, functionality, and security. The solutions either require extensive interaction and computation, linear data scan on each query, which is prohibitive for large databases, or knowing all data in advance. This research advances the state of the art of efficiently-searchable encryption (ESE) by focusing on three key areas: new security guarantees for order-preserving encryption, searchable encryption for fuzzy queries, and seeking a general definition of ESE. <br\/><br\/>The PI has conducted a cryptographic study of order-preserving encryption for supporting efficient range queries on remote encrypted data. This project clarifies the security guarantees of the previous definition and studies the alternative settings in order to develop new secure solutions. This research focuses on fuzzy queries which return database elements that correspond to messages which are close to the underlying queried message. This work initiates the first formal cryptographic study of fuzzy searchable encryption (FSE). In particular, the work focuses on developing appropriate security definitions and building provably-secure FSE schemes. This research seeks a general definition that will cover all known types of ESE, and investigates related impossibility issues. The research extends security definitions for various ESE to security of the database as a whole.","title":"TWC: Small: New Advances for Efficiently-Searchable Encryption","awardID":"1318511","effectiveDate":"2013-08-15","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[549957],"PO":["565264"]},"205281":{"abstract":"The distinction between computing and communication has blurred with the improvements in semiconductor technology as well as the speed and reliability of computer networks. At a macroscopic level, individuals increasingly rely upon smart phones, cloud computing, and similar infrastructure that combines computing systems with networking to accomplish their daily tasks. Many end-users even consider the client device, the server, and the network as one blended unit that is used for productivity and\/or entertainment. At the microscopic level, the linkage between the two areas ideally should not require the use of special-purpose software, because installing software on a network node to enable this blending can potentially cause the node to be unstable or more complex, and potentially introduce security flaws. However, linking the two domains without the use of additional software remains a significant challenge. This research focuses on understanding and characterizing the connection between the computing node and the network to meet that challenge. For example, by simply probing a node's network traffic and collecting its responses, it can be determined that the internal components (e.g., microprocessor) are heavily utilized. If the node is expected to be idle, then this indicator could signal that the node has been compromised and is running unauthorized software.<br\/>\u00a0<br\/>This project uses a holistic approach that combines computer architecture and computer networking to investigate and characterize how the microarchitecture affects the network packet generation process. Since the internal components of a node are shared resources among all processes, including those that require network-based I\/O, it is possible to infer the load on the internal components by observing variations in delay between successive network packets that are generated by the node. This inference materializes as a \"delay signature,\" and can be used to blend the areas of architecture and networking. The delay signature provides information that can be attributed to the internal state and settings of the microarchitecture. Architectural settings, such as processor affinity, multi-threading, and power-saving modes, affect the delay signature. The PIs use a hardware testbed and a system simulator to characterize and model the basic system components that can have a significant (direct or indirect) impact on packet generation. The project culminates with the creation of a general-purpose engine that automates the detection of utilization signatures and uses those signatures to predict node utilization remotely. The PIs incorporate team-based laboratory projects within their computer architecture and computer networking courses to demonstrate the relationship between the two domains and to promote integrated learning by students in both areas. Further, the investigators employ an outreach plan with complementary components to: (1) encourage students to enter the science and engineering fields and (2) mentor potential faculty members to serve as educators and role models. Potential applications of the delay signature include: (1) providing security for networked nodes by monitoring unauthorized utilization and (2) providing efficient scheduling in cluster grids.","title":"SHF: Small: Collaborative Research: Delay Signatures: Blurring the Boundary between the Network and the Processor","awardID":"1318072","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["560166"],"PO":["366560"]},"208680":{"abstract":"This Dagstuhl workshop is to bring together scientists from the research areas of Design Verification, Formal Methods, High-level Design, Manufacturing Testing, Robust System Design, and related disciplines in the context of integrated circuit manufacturing. The objective is to discuss major upcoming obstacles in the design, verification, and testing of robust systems and their potential solutions. Existing pre-silicon verification is insufficiently scalable, and today's manufacturing test methodologies may not be adequate in screening marginal and reliability failures. Bugs and defects that impact system correctness and\/or security must be detected, localized, and corrected in the system environment, during post-silicon validation, or during system operation in the field. New methodologies, that are radical departures from today's practice and require multi-disciplinary effort spanning traditionally distinct research areas are to be discussed.<br\/><br\/>The outcome of this workshop is expected to influence US semiconductor industry by making connections between the academic and industrial researchers. The industry experts present at the workshop will also be instrumental in the benchmarking efforts critical to the research in the field. The workshop will also use the technical topic as a means to assess the value of joint collaborations between the relevant US and German scientific communities and explore various collaboration mechanisms that can be supported by the respective funding agencies. To this end, the workshop is co-sponsored by the German Science Foundation (DFG) as well.","title":"Workshop: Bugs and Defects in Electronic Systems: The Next Frontier","awardID":"1341270","effectiveDate":"2013-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":[559405],"PO":["562984"]},"209021":{"abstract":"This project explores the extent to which personality traits predict privacy and security behaviors. Over the past decade, computer privacy and security have improved by leaps and bounds by considering human factors in the design process. However, previous work to improve the usability of privacy and security systems has only examined the behaviors of \"average users,\" which is believed to only yield local maxima because no individual perfectly fits this profile. Therefore, this project is examining the extent to which additional improvements can be made by catering system designs to individual differences (e.g., in personality traits). Through a series of surveys and controlled experiments, researchers are discovering how these personality traits are predictive of certain privacy decisions, as well as interactions with various security mitigations. For instance, knowledge of a user's personality traits may result in more appropriate default privacy settings on a social networking website or web browser security warnings that are more salient to that user. The researchers' goal is to ultimately design systems that infer personality traits and then adjust privacy and security mechanisms so as to yield outcomes that are optimally aligned with a particular user's preferences.","title":"EAGER: Designing Individualized Privacy and Security Systems","awardID":"1343433","effectiveDate":"2013-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[560257],"PO":["565327"]},"205172":{"abstract":"Spectral value sets arise in the modeling of linear dynamical systems with uncertain feedback. They are important because they model uncertainty inherent in the feedback which is assumed to depend linearly on the output. They are parametrized by a parameter E which bounds the norm of the uncertainty in question. Theoretical aspects of the project include analysis of properties of specific extremal points of spectral value sets for a given value of E and at points of coalescence of the spectral value set components for critical values of E, both in terms of local geometry and algebraic measures. Algorithmic aspects include the development and analysis of fast methods to compute (1) maximizers of the real part or modulus over a given spectral value set for fixed E and (2) the complex stability radius (or its reciprocal, the H-infinity norm) defined as the largest value of E such that the associated spectral value set lies inside the stability region (the left half-plane or the unit disk). They also include developing methods to design controllers for open-loop plants that result in closed-loop systems with desired stability and optimality properties, such as locally maximizing the stability radius (minimizing the H-infinity norm). Since these functions are not concave or convex and their optimizers are typically at points where they are not differentiable, methods for nonsmooth, nonconvex minimization are needed, including methods that can handle constraints efficiently.<br\/><br\/>The mathematical properties of spectral value sets and associated algorithms to compute their extremal values have both theoretical and practical importance. The broader goal of the project is to bring the tools of algorithms for optimization over spectral value sets and related problems to a wide community of scientists and engineers, for use in many different kinds of applications. The investigator's open-source software is already in use in a variety of applications, including the design of aircraft controllers, a proton exchange membrane fuel cell system, power systems, observer-based fault detection and minimally invasive surgery. All of these systems require controllers to work effectively: a complex system such as an airplane or a power plant requires automatic controllers to function safely and effectively, in addition to skilled operators who know how to use such systems. However, current methods are limited to small or moderate-sized systems, which cannot model real physical systems accurately. The new methods will allow the design of controllers for much larger systems than was previously possible, including control of discretized systems of partial differential equations, which have applications throughout the natural sciences and engineering.","title":"Spectral Value Sets: Theory, Algorithms and Applications","awardID":"1317205","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7933","name":"NUM, SYMBOL, & ALGEBRA COMPUT"}}],"PIcoPI":[549376],"PO":["565027"]},"209572":{"abstract":"The nation's economic progress and national security are critically dependent on maintaining a trajectory of steady advances in computing. Such advances are crucially dependent on the use of multiple processing units that are programmed using parallel programming languages. As these parallel processing systems find uses in critical applications such as national security infrastructures, medical devices, airplanes, and computing installations that predict our weather, they must be highly reliable as well as energy efficient. Unfortunately, today's multi-processors are extremely difficult to reliably employ and to efficiently program using current parallel programming languages. In addition to the generally recognized difficulty of writing parallel programs, one of the central unresolved difficulties is the development of a clearly defined shared memory semantics that allows sufficient parallelism. This semantics dictates how the computing elements exchange data, as well as how compilers can safely optimize parallel programs.<br\/><br\/>This work primarily focuses on addressing critical problems relating to concurrent shared memory interactions in parallel programs. It helps advance the current state of the art by developing a collection of mathematical models for clearly defining these interactions. These mathematical models will form the bedrock for developing parallel processors as well as compilers that reliably translate user intentions into correctly functioning computing systems. A central emphasis of our work is that it uniformly addresses the multiplicity of parallel processing element types as well as computer languages by erecting these mathematical models based on a Concurrency Intermediate Verification Language. An equally important feature of this work is that this understanding of memory consistency models directly translates into rigorous error-checking tools to avoid egregious mistakes in deployed computer software. A key aspect of this project is the development of such error-checking tools for parallel programs and demonstrating the effectiveness of these tools on realistic programs acquired from national labs and industrial partners.","title":"EAGER: Memory Models: Specification and Verification in a Concurrency Intermediate Verification Language (CIVL) Framework","awardID":"1346756","effectiveDate":"2013-08-01","expirationDate":"2015-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[561774,561775],"PO":["565264"]},"209121":{"abstract":"This project will demonstrate the feasibility of generalized network slicing for Software Defined Networks (SDN) that would enable multiple multi-tenant virtual clouds on the same physical infrastructure. The generalized network slicing is aimed at network operators as opposed to the end users or tenants of a cloud. The network operators require network slicing with the ability to specify performance, topology, network programmability, and independent address space and require performance isolation. In this regard the proposed network slicing is distinct compared to other efforts in the broader area of network virtualization and can be used independent of network virtualization aimed at supporting 100s and 1000s of cloud tenants.<br\/><br\/>The project will demonstrate generalized network slicing system by focusing on four fundamental challenges:<br\/> - Topology Mapping. Goal is to allow an experimenter or a tenant to specify topology of her network slice and map the (virtual) slice topology on the physical network and maintain this mapping as both physical and slice topologies change over time.<br\/> - Address Space Mapping. Goal is to allow a tenant to use her own private address space and translate the private address space to the physical address space while exploiting packet forwarding capabilities of the existing devices.<br\/> - Control Function Mapping. Goal is to allow each tenant to have SDN style programming capability of her virtual network slice and map control functions on to the corresponding physical instantiation of the network.<br\/> - Performance Isolation. Goal is to allow each tenant to specify resource requirements for her network slice and allocate and police resource usage for each virtual slice to ensure performance isolation.<br\/><br\/>The project will focus on demonstrating the functionality and gaining valuable experience with experimentation. This will help the community to subsequently focus on performance, scale, robustness, and other attributes of the solution that are needed for a real world deployment.<br\/><br\/>The cloud is rapidly changing the face of computing, and as such, is having an increasing effect on experimental systems research, teaching and research in the broader Computer Science community, and how research is done across the breadth of science and engineering. By demonstrating the feasibility of network slicing as an important building block of a research cloud this project will inform the the on-going discussion about the cloud?s evolution.","title":"EAGER: Generalized Network Slicing for NSF OpenCloud","awardID":"1343906","effectiveDate":"2013-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[560546],"PO":["564993"]},"202280":{"abstract":"This project will study and develop technology for Elastic Optical Networks (EONs). In EONs flexible amounts of spectral bandwidth may be allocated to each data channel without requiring adherence to a fixed wavelength grid. Such an approach is well-suited for supporting a wide range of dynamic traffic demands in a bandwidth-efficient manner. Key enabling technologies, optical arbitrary waveform generation<br\/>(OAWG) and optical arbitrary waveform measurement (OAWM), will enable elastic optical networking over a large spectrum by dividing the spectrum into spectral slices and dynamically processing information at lower rates compatible with CMOS electronics. The project will leverage these technologies as a basis for innovative hardware and software solutions for EON technology, architectures, protocols, network control and management, system integration, and testbed integration. <br\/><br\/>Advances in the basic architecture and technology for optical networking is important for US competitiveness. The project will work with several US-based industrial organizations as a means of technology transfer. The research results and publications will likely to impact standardization activities of flexible grid networking (e.g. International Telecommunication Union ITU-T SG15 on flex grid). The project will link education and research and serve as a rich platform for crossdisciplinary education in optical and higher-layer networking, and in computer engineering.","title":"NeTS: Medium: Collaborative Research: GOALI: Adaptive and Flexible Spectrum Optical Networking","awardID":"1302719","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["551148",542106,542107],"PO":["564993"]},"205690":{"abstract":"Libraries for matrix computations have had a huge impact on computational science since many computations can be cast in terms of linear algebra. As a result, widely used libraries have been available and in broad use for decades. More recently, multi-linear computations, also known as tensor computations, have become important. Application areas include computational chemistry, physics, and large data analysis. Until now, little research has been dedicated towards the development of high quality, high performing libraries for such computations. This project will make strides towards remedying this.<br\/><br\/>This project transfers insights from more than a decade of research and development of dense linear algebra libraries as part of the NSF-sponsored FLAME project to the field of tensor computations. The goal is to create new abstractions for expressing algorithms and their implementations, to derive new algorithms that can take advantage of symmetry in tensors, and discover how to take advantage of the memory hierarchies of modern processors. A prototype library will be implemented and made available to the scientific computing community. Together, this will advance the state-of-the-art in this domain.","title":"SHF: Small: From Matrix Computations to Tensor Computations","awardID":"1320112","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}}],"PIcoPI":["556801",550725],"PO":["565272"]},"205481":{"abstract":"The availability of ideal randomness is a common assumption used not only in cryptography, but in many other areas of computer science, and engineering in general. Unfortunately, in many situations this assumption is highly unrealistic, and cryptographic systems have to be built based on imperfect sources of randomness. Motivated by these considerations, this project will investigate the validity of this assumption and consider several important scenarios where secure cryptographic systems must be built based on various kinds of imperfect randomness. <br\/><br\/>This project investigates the feasibility of cryptography with imperfect sources of randomness, and whether ideal randomness is necessary for building various cryptographic primitives. These techniques will be applied to the area of leakage-resilient cryptography. Namely, we consider a realistic attack scenario where the adversary can gain partial knowledge of some secret information. This project will design novel protocols which are resilient to such leakage of partial information.","title":"TWC: Small: On Imperfect Randomness and Leakage-Resilient Cryptography","awardID":"1319051","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[550227],"PO":["565264"]},"209661":{"abstract":"This project supports hosting the 18th GENI Engineering Conference, including organizing and hosting a demo session, to be held October 27-29, 2013, on the campus of the Polytechnic University of New York. The Global Environment for Network Innovations (GENI) is a virtual instrument that is rapidly emerging in prototype form across the United States. GENI aims to transform experimental research in networking and distributed systems, as well as emerging research into very large socio-technical systems, by providing a suite of infrastructure for 'at scale' experiments in future internets.<br\/><br\/>About 250 to 300 leading researchers and Ph.D. students from diverse U.S. institutions will gather in New York to showcase their ideas and results. In the demo session, each demo will be provided with a wired connection to the GENI infrastructure. The NYU Poly information technology department will support both the conference and demo session with high speed and high bandwidth connectivity for researchers to demonstrate their experiments, both wired and wireless. The demo venue will also provide connectivity to Internet2, National Lambda Rail, and\/or regionals, thus enabling researchers and practitioners to access all the GENI resources nationwide for supporting their demo needs. Each GEC demo project will be issued with temporary campus-wide wireless credentials that will grant access to the campus wireless infrastructure and commodity Internet for the duration of the demo evening.<br\/><br\/>The GEC meeting and demo sessions provide graduate students with an opportunity to demonstrate and explain their work to the GENI community prior to formal publication. It is a key part of helping new graduate students understand what is being done with GENI and who amongst their peers at other institutions might be valuable resources. It also supports outreach to new community members, including the emerging US Ignite community. GENI is already being used as an instrument for research. This project supports further development and use of the research instrument.","title":"Proposal for Organizing the 18th GENI Engineering Conference (GEC 18) Networking Event","awardID":"1347321","effectiveDate":"2013-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[561993,561994],"PO":["564993"]},"207252":{"abstract":"The National Academies will plan and organize a cross-disciplinary public workshop to explore perspectives on the training that students from diverse fields need in order to extract value from Big Data. The workshop will identify key skills that are needed to prepare students for analyzing Big Data. It will consider the needs of industry, academia, and government and build on the experience gained from emerging courses and curricula for this topic. Invited participants to the workshop will include experts in statistics, machine learning, databases, large-scale computing systems, streaming computing, user domains, health and biological informatics, and industry.<br\/><br\/>Many traditional methods for data analysis do not work, or do not work well, with the massive amounts of data emerging in numerous endeavors. In order to reliably extract insight from Big Data, students need to learn new skills, and many of those skills cut across multiple disciplines and, thus, are not necessarily accessible through standard courses and curricula. During the academic year 2012-2013, a number of courses were introduced at various universities to impart the needed understanding. The planned workshop will enable educators to share insights gained from these courses and make adjustments. A summary report of the workshop will make these insights available more broadly.","title":"Workshop On Training Students To Extract Value From Big Data","awardID":"1332693","effectiveDate":"2013-08-15","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1260","name":"INFRASTRUCTURE PROGRAM"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1269","name":"STATISTICS"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"8069","name":"CDS&E-MSS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[555004],"PO":["565309"]},"207032":{"abstract":"Teach For America (TFA) will conduct a pilot to develop a new model for recruiting and training new teachers to effectively teach Exploring Computer Science (ECS) at 5-10 New York City public high schools in 2013-2014. The course will be taught by TFA corps members who are qualified to teach a secondary core subject and who also have taken 2 or more semester-long core CS courses in college. TFA will conduct targeted recruitment of CS college students on 10 New York and New Jersey university campuses. This recruitment will include outreach to CS departments, presentations to CS classes, engagement with TFA campus recruitment teams, participation of TFA alums with a CS background, and a general messaging campaign articulating CS education as an equity issue. An external evaluation consultant will conduct teacher surveys at the beginning and end of the course, interviews with school leaders in the schools in which ECS is being taught, and analysis of student work and instructional materials. In addition, TFA will assess whether targeted CS recruitment efforts lead to an increase in the number of people with a CS background who apply to TFA and who are accepted to TFA. This pilot will test a novel model for pre-service teacher recruitment and professional development that will contribute to the CS 10K initiative. Students in the participating high schools that currently lack CS courses and CS teachers will be directly affected. In addition, this pilot can inform expansion of CS courses within NYC and throughout high schools in other TFA regions around the country. The model of recruiting recent college graduates with CS expertise and training them to be CS teachers also has the potential to inform recruitment strategies of pre-service teachers at other college campuses.","title":"EAGER: Increasing the Supply of High-Quality Computer Science Instructors to Low-Income Communities","awardID":"1331409","effectiveDate":"2013-08-01","expirationDate":"2015-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}}],"PIcoPI":[554303],"PO":["560704"]},"208484":{"abstract":"The International Society for Computational Biology is awarded a grant to support student and early-career researcher participation in the annual meeting on Intelligent Systems for Molecular Biology in Berlin, Germany, July 21-23, 2013. The conference holds thematic sessions for invited presentations, tutorial programs on related subjects, and special interest group workshops. Cutting-edge bioinformatics areas presented at the conference include bio-imaging and visualization, databases and ontologies, evolution and comparative genomics, gene regulation and transcriptomics, mass spectrometry and proteomics, population genomics, protein interaction, and molecular networks and structure. <br\/><br\/>This award will assist students and postdoctoral researchers, particularly under-represented minorities, at a critical but resource-limited stage in their careers by partially funding the travel and expenses associated with attending the conference. Through their participation, these students will have the opportunity to be exposed to leading edge research and methods, gain introductions to international and world-renown keynote speakers and senior level scientists, seek out prospective postdoctoral and collaborative opportunities, and meet their peers from all over the world. Results will be disseminated as published proceedings indexed in MEDLINE and Current Contents, and video recordings of selected presentations will be available online.","title":"Conference: ABI: Toward Advanced Understanding in Biological Systems - Intelligent Systems for Molecular Biology Conference Support for Training Students & Young Scientists.","awardID":"1340055","effectiveDate":"2013-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"1165","name":"ADVANCES IN BIO INFORMATICS"}}],"PIcoPI":[558784],"PO":["565262"]},"204690":{"abstract":"The critical role of spectrum as a catalyst for economic growth was highlighted in the 2010 National Broadband Plan (NBP). A challenge for the NBP is realizing optimal spectrum sharing in the presence of interference caused by rogue transmissions from any source, but particularly secondary users who share the spectrum. This complex problem straddles wireless technology, industrial economics, international standards, and regulatory policy. <br\/><br\/>This interdisciplinary, multi-university collaborative project studies the many dimensions of the problem from algorithms to law enforcement. The investigators study (1) ex-ante spectrum rule enforcement mechanisms (i.e., preventive) such as spectrum access control via policy reasoners, (2) ex-post spectrum rule enforcement schemes (i.e., punitive) with policy conformance monitoring that employ cryptographic commitments, (3) ex-post enforcement schemes that can uniquely identify rogue transmitters, and (4) the economic viability of spectrum sharing with different enforcement schemes.<br\/><br\/>The project provides a broad range of education and industry outreach activities in order to rapidly insert research advances into curriculum and university-industry partnerships. Specifically, the investigators will present short courses and tutorials at the annual Virginia Tech Wireless Symposium and Summer School, and widely disseminate findings through NSF Industry & University Collaborative Research Centers (I\/UCRC) at the Virginia Polytechnic Institute and State University.","title":"TWC SBE: Medium: Collaborative: Dollars for Hertz: Making Trustworthy Spectrum Sharing Technically and Economically Viable","awardID":"1314468","effectiveDate":"2013-08-01","expirationDate":"2017-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[548162],"PO":["565239"]},"205570":{"abstract":"Computational infrastructure for efficient and accurate searching of bio-molecules from various databases is foundation of any modern biology, biochemistry, pharmacology, and biotechnology. The goal of this project is to develop computational methods and databases that allow fast, real-time screening of various types of three dimensional (3D) structural data of proteins and their interacting molecules in a seamless fashion. The structure data to be searched include 3D protein structures and protein complexes, predicted protein structures, low-resolution protein complexes solved by cryo-electron microscopy, small chemical ligand molecules, and drug molecules. The project employs a mathematical representation of biomolecules that can quickly compare and search biomolecules that have similar global and local surface shape and properties with a query molecule. The project will further expand the applicability of the molecule representation for searching interacting molecules by identifying complementarity of shapes and surface properties. The methods to be developed in the project allow biologists to quickly identify potentially interacting proteins to a query protein, which will help generating testable hypothesis of molecular mechanisms of diseases through building molecular networks. Moreover, the methods will also enable quick searching of ligand molecules and potential drug molecules that fit to a target protein.<br\/><br\/>Biology has entered the informatics era, when combining different types of big omics data are routinely required to reach a systems-level understanding of biological function of molecules and cells. In order to effectively glean useful structural data for biological studies, there is a strong need for computational methods that can quickly and seamlessly search for different types of structural data. Establishing efficient methods for searching biomolecular shape and physicochemical properties is essential for capitalizing on the large number of efforts directed towards determining molecular and cellular structures by structural genomics and other projects. The project will develop computational methods and databases to screen various types of protein structures and their interacting molecules seamlessly and quickly. Using the molecular representation proposed in the project, global and local shapes and surface properties (electrostatic potential, hydrophobicity) of proteins and ligand molecules can be compared ery fast. In contrast to conventional 3D structure search methods for biomolecules that take hours or even more than a day to finish a database search, the methods to be developed will allow real-time searches against large databases. Thus, structural analysis will become as convenient as sequence database searches for biology researchers. The 3D molecule search methods will be applied to identify interacting molecules for a query protein, ligand molecules that would bind to a pocket region of the query protein as well as interacting proteins. Knowing molecular interactions is critical for understanding functions of proteins. The key innovations include 1) finding interacting molecules to proteins, i.e. pocket-ligand interactions and protein-protein interactions; 2) local surface comparisons for functional annotations; Developed methods will be implemented into 3D-Surfer, a one-stop website for biomolecular shape retrieval.<br\/><br\/>The proposed approach can be applied for other types of rapid shape and property comparisons, such as 2D and 3D medical images, microscope images, geographical landscapes, and face recognition. Graduate and undergraduate students in biological sciences and computer science will be trained in cross-listed courses among several departments. Several existing programs at Purdue for recruiting minority students and undergraduate students will contribute to broad participation in the project. Overall the proposed project leverages Purdue University?s efforts in interdisciplinary computational life science and engineering.","title":"III: Small: Rapid screening of interacting ligands and proteins","awardID":"1319551","effectiveDate":"2013-08-15","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[550449],"PO":["565136"]},"205460":{"abstract":"Modern multicores are designed around complex memory hierarchies that<br\/>achieve high performance with a high cost in design complexity and<br\/>efficiency. The reason is that delaying the memory access just a few<br\/>cycles has an unacceptable performance impact. This proposal decouples<br\/>the memory operations in non-critical and critical. The critical<br\/>component is allowed to be incorrect which results in a system with<br\/>power savings, simplifications in the memory hierarchy, and even the<br\/>removal of complex memory coherence. The proposed sequential<br\/>consistency model allows simple programming models without performance<br\/>or power consumption impact.<br\/><br\/><br\/>This proposal addresses the challenge of excessive complexity in modern<br\/>multicore memory hierarchy. This complexity results in a power waste and<br\/>difficult programming models. For modern systems, the memory hierarchy<br\/>represents over half of the power. The proposed decoupled execution<br\/>allows an energy efficient implementation by moving the complex<br\/>operations out of the critical path. Furthermore, the proposed memory<br\/>hierarchy allows for simpler parallel applications because it avoids<br\/>complex consistency models commonly used. This proposal solution allows<br\/>for an efficient implementation of the simplest consistency model<br\/>available. Overall, the PI hopes to make fundamental advances toward<br\/>energy efficient and simpler to use memory hierarchies.","title":"CSR: Small: Rethinking the Memory Hierarchy","awardID":"1318943","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["556721"],"PO":["565319"]},"205350":{"abstract":"Multicore chips are now mainstream, and increasing the number of cores per chip has become the primary way to improve performance. Current multicores rely on sophisticated cache hierarchies to mitigate the high latency, limited bandwidth, and high energy of main memory accesses, which often limit system performance. These on-chip caches consume more than half of chip area, and most of this cache space is shared among all cores. Sharing this capacity has major advantages, such as improving space utilization and accelerating core-to-core communication, but poses two fundamental problems. First, with more cores, cache accesses take longer and consume more energy, severely limiting scalability. Second, concurrently executing applications contend for this shared cache capacity, which can cause unpredictable performance degradation among them. The goal of this project is to redesign the cache hierarchy to make it both highly scalable, and to provide strict isolation among competing applications, enabling end-to-end performance guarantees. If successful, this work will improve the performance and energy efficiency of future processors, enabling systems with larger numbers of cores than previously possible. Moreover, these systems will eliminate interference and enforce quality of service guarantees among competing applications, even when those applications are latency-critical. This will enable much higher utilization of shared computing infrastructure (such as cloud computing servers), potentially saving billions of dollars in IT infrastructure and energy consumption.<br\/><br\/>To achieve the dual goals of high scalability and quality-of-service (QoS) guarantees efficiently, this project proposes an integrated hardware-software approach, where hardware exposes a small and general set of mechanisms to control cache allocations, and software uses these mechanisms to implement both partitioning and non-uniform access policies efficiently. At the hardware level, a novel cache organization provides thousands of fine-grained, spatially configurable partitions, implements lightweight monitoring and reconfiguration mechanisms to guide software policies effectively, and supports full-system scalable cache coherence cheaply. At the software level, a system-level runtime leverages this hardware to implement dynamic data classification, placement, migration, and replication mechanisms, maximizing system performance and efficiency, while at the same time enforcing the strict QoS guarantees of latency-critical workloads, transparently to applications. Combined with existing bandwidth partitioning approaches, these techniques will enforce full-system QoS guarantees by controlling all on-chip shared resources (caches, on-chip network, and memory controllers). In addition, the infrastructure and benchmarks developed as part of this project will be publicly released, allowing other researchers to build on the results of this work, and enabling the development of course projects and other educational activities in large-scale parallel computer architecture, both at MIT and elsewhere.","title":"SHF:Small:Scalable Memory Hierarchies with Fine-Grained QoS Guarantees","awardID":"1318384","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":[549877],"PO":["366560"]},"205361":{"abstract":"The security of critical information infrastructures depends upon effective techniques to detect vulnerabilities commonly exploited by malicious attacks. Due to poor coding practices or human error, a known vulnerability discovered and patched in one code location may often exist in many other unpatched code locations, either in the same code base or other code bases. Furthermore, patches are often error-prone, resulting in new vulnerabilities. This project develops practical techniques for detecting code-level similarity to prevent such vulnerabilities. It has the potential to help build a more reliable and secure information system infrastructure, which will have tremendous economical impact on society because of our growing reliance on information technologies.<br\/><br\/>In particular, the project aims to develop practical techniques for similarity-based testing and analysis to detect unpatched vulnerable code and validate patches to the detected vulnerable code at both the source code and binary levels. To this end, it focuses on three main technical directions: (1) developing techniques for detecting source-level vulnerabilities by adapting and refining an industrial-strength tool, (2) developing capabilities of detecting binary-level vulnerabilities by extending preliminary work on detecting code clones in binaries, and (3) supporting patch validation and repair by developing methodologies and techniques to validate software patches and help produce correct, secure patches. This project helps discover new techniques for source- and binary-level vulnerability analysis and gain better understandings of the fundamental and practical challenges for building highly secure and reliable software.","title":"TWC: Small: Collaborative: Similary-Based Program Analyses for Eliminating Vulnerabilities","awardID":"1318419","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["562727"],"PO":["564388"]},"209574":{"abstract":"Parallel programming has become increasingly common with the advent of<br\/>\"multi-core\" computer chips that pack many processors into a single<br\/>chip. Most standard laptop and desktop computers now come with anywhere<br\/>from two to thirty-two such cores. Such chips offer unprecedented computing power, but at a price: to<br\/>extract their full potential, programmers writing software for the new<br\/>chips must use special programming language \"libraries\" in order to<br\/>specify how the program is to do two (or more) things at once. One<br\/>popular such library is called OpenMP. These so-called parallel<br\/>programs are notoriously difficult to get right, and many contain<br\/>undetected defects (\"bugs\") that can cause the program to crash or<br\/>produce incorrect results.<br\/><br\/>The CIVL project has the potential to dramatically reduce the effort<br\/>required to develop new static analysis tools. The key idea is a<br\/>unified language for describing parallel programs, whether these use<br\/>MPI, OpenMP, or both. One tool translates the original program into<br\/>the new language, also called CIVL. Other tools perform static<br\/>analysis on the CIVL program. Eventually, many other parallel<br\/>libraries will be added to the new system. The advantage of this<br\/>approach is that the designer of a new static analysis tool need only<br\/>design the tool for a single language---CIVL---but then gets a tool<br\/>that works on all the source libraries \"for free\". Similarly, when a<br\/>new parallel library comes along, by developing a translator from it<br\/>to CIVL, one can immeidately reap the benefits of all the static<br\/>analysis tools. The researchers expect that the resulting platform<br\/>will make it much easier to develop correct parallel programs, no<br\/>matter how that parallelism is expressed.","title":"CIVL: A Concurrency Intermediate Verification Language","awardID":"1346769","effectiveDate":"2013-08-01","expirationDate":"2015-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}}],"PIcoPI":[561781,561782],"PO":["565272"]},"204680":{"abstract":"In any design or learning activity, exploration is a key component. Significant research and conventional wisdom show that the best way to achieve a high-quality design is to explore multiple variations and iteratively evaluate them. When novices learn a new skill or system, they must explore and practice the available options. Similarly, when experts try to understand and improve an existing design, they must explore different approaches to modifying its behavior. Unfortunately, exploration is risky, error-prone, and cumbersome using today's tools. For instance, when users decide their current design is not effective, the only mechanisms available for selectively backtracking out of changes are linear undo and version control, which make it difficult to isolate backtracking to specific edits, or else users must manually remove undesired edits, which is slow and fallible. Further, today's tools do not support comparing two variants of a design or combining elements from multiple variants. Research is showing that these manual processes inhibit exploration, making users and designs less effective.<br\/><br\/>To address these problems PIs from four partner institutions have come together to undertake a research program that is both broad and deep, focusing on the creation and management of variations during a system's implementation and evolution. The goal is to discover new theories, algorithms, visualizations, and tools that support variations in code. The team will evaluate all of their approaches through lab and field studies, and they will investigate how users can be educated in more effective ways to work with variations. Based on a choice calculus for representing variations in software, they will develop a theory for formally defining and reasoning about variations. They will leverage theories of human behavior such as Minimalist Learning, Attention Investment, and Information Foraging, to develop a theory of Variation Foraging. They will develop an infrastructure including multiple levels of transcripts of users' editing operations that will support a novel form of selective undo and enable users to investigate their existing variants, return to any previous variant, and mix and match elements from multiple variants. They will develop algorithms to enable recording of interactions with variants so they can be explored and reused to explore and test new variants; these recordings will be augmented with automatically created data to help users understand behaviors they have not explicitly explored. Using this infrastructure the PIs will invent visualizations, search facilities, and interaction techniques that provide effective ways for users to find, understand, explore, reuse and create variants, and be able to ask \"why\" questions to understand the differences among variations of a system. For novices, an \"Idea Garden\" will help them explore new strategies for identifying which variations can help solve a problem and how to implement them.<br\/><br\/>Broader Impacts: This research will enhance infrastructure for research and education by producing an integrated, open source web development environment for use by researchers and the world. The work will therefore benefit society by empowering the tens of millions of end-user programmers to creatively build content and applications for the web. The PIs will advance discovery while promoting learning by integrating their research into undergraduate courses on creativity and software engineering, and by supporting summer camps for at least 300 high school students per year. Project outcomes will be disseminated to researchers through publications and presentations, to computing educators through the above-mentioned camps and the National Girls Collaborative Project, and through public deployment. The PIs expect high interest because the work will be based on JavaScript, which is today's most popular programming language and for which there is a high demand for better tools. The research will address underrepresentation via its focus on investigating how to support both male and female end-user programmers, by involving high-school members of underrepresented groups, and by engaging many of the PIs? female students.","title":"HCC: Large: Collaborative Research: Variations to Support Exploratory Programming","awardID":"1314399","effectiveDate":"2013-08-01","expirationDate":"2017-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[548140],"PO":["565227"]},"205780":{"abstract":"Current radio receiver designs are pushing the boundaries of Analog-to-Digital conversion and digital signal processing technology in terms of speed and energy efficiency. These technology limitations present a major bottleneck in transferring promising wideband and energy-efficient receiver design paradigms from theory to practice. This project investigates whether these bottlenecks can be circumvented by designing digital communication system receivers that are sampled at sub-Nyquist rates. By sampling below the Nyquist rate, current technology can be used for very wideband communication systems and energy consumption can be significantly reduced below that required for Nyquist-rate sampling. The proposed research brings together the areas of Shannon theory and sampling theory by exploring the fundamental capacity limits of single-user and multi-user subsampled channels as well as the optimal sampling mechanisms that achieve these limits. In addition, the project will extend the ideas of sub-sampled communication to determine the rate-distortion trade-off of sub-sampled sources along with joint source-channel coding when both the source and channel are undersampled. The proposed activity will develop a broader understanding of communication system design subject to hardware constraints by exploring an important and unanswered question at the intersection of two important fields within electrical engineering: signal processing and information theory. The results of the proposed work can enable low-complexity high-performance radio designs for 60 GHz wideband communications and for cognitive radios. Furthermore, these results impact other engineering systems such as radar, optical systems, medical imaging and more, since the mathematical machinery and hardware insights developed in the proposed research can provide important insights into related areas in which reduced rate sampling and processing is needed.<br\/><br\/>The broader impacts resulting from the proposed activity will include significant enhancement of the communications capabilities beyond the current state of the art in wideband, cognitive, and energy-efficient radio design. Wideband radios are of key importance to meet the significant demand for multimedia wireless communications, especially video. Cognitive radios have the ability to more efficiently utilize the limited available radio spectrum. In addition, there is a great need to design communication systems that consume minimal energy, especially sensor networks, which have application to enable smart buildings, enhance homeland security, and improve the reliability and robustness of our power grid.","title":"CIF: Small: Fundamental Performance Limits And Design Techniques For Sub-Sampled Communication Systems","awardID":"1320628","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["553691"],"PO":["564924"]},"205593":{"abstract":"The task of characterizing human activities using multimodal sensing and automated inference techniques is critically important in many applications. Human activities when observed using traditional audio and video sensors, as well as novel emerging sensors such as depth cameras, orientation sensors, and smart personal devices, result in complex, high-dimensional spatiotemporal signatures that are difficult to analyze. The sources of difficulty are many: high data throughput, the need for sensor registration, variable execution rates associated with activities, pose variability in sensing, the non-Euclidean nature of feature spaces due to physical constraints on environments and actors, and data corruption due to occlusions. The current techniques, involving Euclidean representations and multivariate analyses, fall short in characterizing human activities, as they do not handle non-Euclidean structures nor obtain invariances to pose and execution rates. <br\/><br\/>This research uses tools spanning differential geometry, statistics and signal approximation theory to develop novel frameworks for characterizing human activities. These fundamental tools lead to comprehensive solutions that are applicable to a broad swath of traditional and emerging sensors. The salient aspects of this approach are: 1) geometry awareness, encompassing both classical Euclidean as well as non-Euclidean feature spaces, 2) invariance to sensor placement and execution rate tightly integrated into the representation, and 3) data adaptivity leading to low bitrate representation of human activities for reduced communication and low computational scenarios. Applications of this research include monitoring of human activities using off-the-shelf sensors in resource-constrained environments, such as at homes and on mobile devices.","title":"CIF: Small: Collaborative Research: Geometry-aware and data-adaptive signal processing for resource constrained activity analysis","awardID":"1319658","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[550508],"PO":["564898"]},"205296":{"abstract":"This research will develop new ways to (1) prompt intentional behavior and reflection among children when they become new social media users; (2) support parents in taking a proactive, rather than reactive, role in guiding their children's social media use; and (3) develop theoretical insights about prompting self-awareness among users with and through social systems. Parents are concerned about the content, context, and frequency of their children?s social media use and struggle to cope with these facets. Unfortunately, many parenting approaches to date are reactive and are focused on tracking, logging, or cutting off access to social media. Furthermore, the lack of empirical research in this area has left parents ill-equipped to try alternate strategies. Trying to cut off access to social media could lead to psychological reactance, where children engage in risky behaviors secretly instead of communicating openly with their parents. If we expect parents to raise their children effectively in a complex and rapidly changing digital world, we must develop new tools, approaches, and theories to help them do so. To address this gap, this research casts a new perspective on social media design that focuses on the study and development of social systems that prompt proactive and reflective behavior based on context-dependent cues. <br\/><br\/>The research will use a mixed-methods approach with four phases: (1) conduct parent-child interviews to understand why parents worry about social media and how their worries relate to children?s behaviors; (2) conduct a mobile phone experiment to prompt intentionality and reflection with mobile phone use among children and parents; (3) conduct a web-based experiment to prompt intentionality and reflection with laptop use among children and parents; and (4) synthesize results and develop new theories about ways of prompting reflection and self-awareness in social media systems. Mobile phones and laptops were chosen because they are widely adopted among youth and they are personal and portable, which introduces new parenting challenges. Effectiveness will be evaluated by comparing experimental and control group outcomes using a variety of measures including mobile phone logs, browser logs, self-reports, and validated behavioral scales.<br\/><br\/>Understanding how to prompt regular, real-time reflection with and through social media can guide the design of new kinds of social systems that prompt increased self-awareness and competency. The project will disseminate mobile phone and web-based tools to local parents, schools, and community organizations and will make them publicly available online. It will also disseminate research outcomes for a non-technical audience in the form of presentations, media outputs, and short reports. This research can have a vital and potentially transformative impact on early social media use among children and their parents, addressing a challenge that almost every parent in the U.S. now faces.","title":"HCC: Small: Prompting Intentional Social Media Use Among Children and Parents","awardID":"1318143","effectiveDate":"2013-08-15","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[549737],"PO":["564456"]},"209344":{"abstract":"This award provides travel support for 25-30 U.S.-based graduate and undergraduate students to participate in the 21th ACM SIGSPATIAL GIS 2013 Conference, held in Orlando, FL, USA, November 5-8, 2013 (http:\/\/sigspatial2013.sigspatial.org). The ACM SIGSPATIAL GIS conference has established itself as the world's premier conference to foster research in the areas of Spatial Data and Analysis and Geographic Information Systems (GIS). The conference provides a forum for original research contributions covering all conceptual, design, and implementation aspects of GIS ranging from applications, user interfaces, and visualization to storage management and indexing issues. It brings together researchers, developers, users, and practitioners carrying out research and development in novel systems based on geospatial data and knowledge, and fostering interdisciplinary discussions and research in all aspects of GIS. It is the premier annual event of the ACM Special Interest Group on Spatial Information (ACM SIGSPATIAL). The conference seeks to continuously advance the state of-the-art in spatial data management and spatial data analysis and broaden its impact.<br\/><br\/> The participation of U.S. graduate and undergraduate students results in the intellectual simulation of young minds to pursue advanced research and development activities in an area that has huge technical and societal impact. The students greatly benefit from attending this conference, as they are able to partake in the current state-of-the-art in the area of geospatial systems and applications, present their work, and potentially make connections for research collaborations and research mentoring. The total number of ACM SIGSPATIAL GIS participants in the past has been in excess of 300 participants, with a majority of the participants from the U.S., followed by Europe and Asia. A strong representation of U.S.-based graduate students at ACM SIGSPATIAL GIS is useful in maintaining U.S. competitiveness in the important research areas crucial for U.S. infrastructures and applications that critically depend on geo-referenced information. Applications of spatial and geographical information contribute to a wide-array of societal contexts: improving the lives of ordinary citizens through advanced transportation applications, increasing the security of the nation through better intelligence gathering using geospatial knowledge, and developing applications that will have a positive impact on the global environment. Educating and training the next generation of scientists, engineers, and practitioners in the area of spatial and geographical information systems will have a significant impact and will enhance the continuation of the competitive edge of the United States in this important area.","title":"U.S.-Based Students Travel Support for the ACM SIGSPATIAL 2013","awardID":"1345472","effectiveDate":"2013-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[561230],"PO":["563751"]},"202261":{"abstract":"This project will study and develop technology for Elastic Optical Networks (EONs). In EONs flexible amounts of spectral bandwidth may be allocated to each data channel without requiring adherence to a fixed wavelength grid. Such an approach is well-suited for supporting a wide range of dynamic traffic demands in a bandwidth-efficient manner. Key enabling technologies, optical arbitrary waveform generation<br\/>(OAWG) and optical arbitrary waveform measurement (OAWM), will enable elastic optical networking over a large spectrum by dividing the spectrum into spectral slices and dynamically processing information at lower rates compatible with CMOS electronics. The project will leverage these technologies as a basis for innovative hardware and software solutions for EON technology, architectures, protocols, network control and management, system integration, and testbed integration. <br\/><br\/>Advances in the basic architecture and technology for optical networking is important for US competitiveness. The project will work with several US-based industrial organizations as a means of technology transfer. The research results and publications will likely to impact standardization activities of flexible grid networking (e.g. International Telecommunication Union ITU-T SG15 on flex grid). The project will link education and research and serve as a rich platform for crossdisciplinary education in optical and higher-layer networking, and in computer engineering.","title":"NeTS: Medium: Collaborative Research: GOALI: Adaptive and Flexible Spectrum Optical Networking","awardID":"1302645","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[542048],"PO":["564993"]},"205660":{"abstract":"Big data leads to big challenges, not only in the volume of data but also in its dynamics and variety. Multiple descriptions about the same set of objects or events from different sources unavoidably lead to data or information inconsistency. Then, among conflicting pieces of data or information, it is crucial to tell which data source is reliable or which piece of information is correct. Accurate information is referred to as the truth and the chance of a source providing accurate information is denoted as source reliability or trustworthiness. The objective of this project is to detect truths without supervision, by integrating source reliability estimation and truth finding. A unified framework is developed to model complex trustworthiness factors, heterogeneous data types, incremental and parallel computation, and source and data dependencies so that truth and trustworthiness can be inferred from multiple conflicting sources of heterogeneous, disparate, correlated, gigantic, scattered, and streaming data.<br\/><br\/>This project makes tangible contributions to data integration, information understanding and decision making, and benefits many applications where critical decisions have to be made based on the correct information extracted from diverse sources. Research results of this project are integrated into course materials and projects, and into training students and new generation researchers, especially female and minority students. For further information about this project, please refer to the project website: http:\/\/www.cse.buffalo.edu\/~jing\/truth.htm","title":"III: Small: Collaborative Research: Conflicts to Harmony: Integrating Massive Data by Trustworthiness Estimation and Truth Discovery","awardID":"1319973","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[550658],"PO":["563727"]},"205671":{"abstract":"The energy efficiency of high-end computers has reached a plateau for some time now, yielding devices that are constrained by power and thermal limits and do not realize the full performance potential of advanced semiconductors. This research project will explore computing architectures that rely on energy recycling to operate with significantly improved energy efficiency and are thus capable of achieving sustained clock speeds well in excess of 10GHz without any special cooling requirements. The resulting technologies will be assessed through the design and evaluation of silicon prototype chips. The outcomes of this research project can be transformative, demonstrating integrated computing systems that achieve unprecedented performance levels.<br\/><br\/>The proposed research is expected to have a significant impact on the realization of next-generation high-performance computers, promoting discovery, teaching, and learning in novel design technologies that yield energy-efficient electronics. Broader outcomes of the proposed effort include the integration of research activities into graduate-level courses, the development of lectures and projects for advanced undergraduate-level courses, the direct involvement of electrical engineering and computer science majors through senior-level design projects, and the engagement of high school students.","title":"SHF:Small:Deca-GHz CMOS","awardID":"1320027","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":[550681,550682],"PO":["562984"]},"205583":{"abstract":"Monitoring and understanding aquatic environments is critical to water sustainability. The goal of this award is to establish a theoretical framework and provide an enabling technology for robust underwater collaborative sensing with small, inexpensive robots. Inspired by the source-seeking behavior of live fish, computationally efficient algorithms are developed for cooperative tracing of the gradients of environmental fields, and their robustness is analyzed in the presence of localization error and changing communication topology. The algorithms are experimentally validated in thermal source seeking and tracing with a group of energy-efficient and highly maneuverable gliding robotic fish, which are enhanced in this project with optical communication and localization capabilities. Advanced controllers are developed for these robots to realize three-dimensional maneuvering and to track reference paths planned through collaborative sensing algorithms. This award offers fundamental understanding of limits and robustness properties of collaborative sensing by resource-limited robots, and contributes to the knowledge base in underwater communication and ranging for small robots. It enables technological advances for persistent sampling of versatile aquatic environments including coastal waters, lakes, and rivers, with a myriad of applications such as oil spill response, ecological monitoring, and port and drinking water security. The findings from this project are disseminated through publications, software sharing, and technology commercialization. The project provides interdisciplinary training opportunities for students, including those from underrepresented groups. Outreach activities, including museum\/aquarium exhibits and teacher training, are developed to pique the interest of K-12 students, teachers, and the public in science and engineering.","title":"RI: Small: Collaborative Research: Bio-inspired Collaborative Sensing with Novel Gliding Robotic Fish","awardID":"1319602","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["560245"],"PO":["564069"]},"202195":{"abstract":"Citation is an essential part of scientific publishing and, more generally, of scholarship. It is used to gauge the trust placed in published information and, for better or for worse, is an important factor in judging academic reputation. Now that so much scientific publishing involves data and takes place through a database rather than conventional journals, how is some part of a database to be cited? More generally, how should data stored in a repository that has complex internal structure and that is subject to change be cited?<br\/><br\/>The goal of this research is to develop a framework for data citation which takes into account the increasingly large number of possible citations; the need for citations to be both human and machine readable; and the need for citations to conform to various specifications and standards. A basic assumption is that citations must be generated, on the fly, from the database. The framework is validated by a prototype system in which citations conforming to pre-specified standards are automatically generated from the data, and tested on operational databases of pharmacological and Earth science data. The broader impact of this research is on scientists who publish their findings in organized data collections or databases; data centers that publish and preserve data; businesses and government agencies that provide on-line reference works; and on various organizations who formulate data citation principles. The research also tackles the issue of how to enrich linked data so that it can be properly cited.","title":"III: Medium: Collaborative Research: Citing Structured and Evolving Data","awardID":"1302212","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["541876","541878",541876,541877,541878],"PO":["565136"]},"205760":{"abstract":"More than 2.5 quintillion bytes of data are created daily in the form of sensor measurements, web posts and clicks, surveillance videos, purchase transactions, and health-care records. However, not all data collected is informative and not all features are relevant to the outcomes of interest. While several researchers have focused attention on compressive sampling for minimum error data reconstruction to improve data storage and acquisition, the objective of this research is broader and is focused on salient feature discovery. The key insight is sparsity, namely, that there is a tight coupling between a small relevant set of observations and the outcomes of interest. This research is focused on the sparse identification of the most relevant observations that are essential to predicting the outcomes.<br\/><br\/>The investigators will develop a new information-theoretic framework and algorithmic tools for understanding the intrinsic relationships and sparse interactions between outcomes of interest and a set of features\/observations in order to improve inferencing capabilities for enhanced decision-making in the context of this data-deluge. The goal is to discover the most relevant sparse subset of features that are essential to predicting the outcomes, and to uncover the fundamental limits of the associated sparse models. The approach is based on a unifying Shannon information-theoretic framework, whereby the problem of salient feature identification is mapped to a problem of capacity analysis for an equivalent channel model. This research addresses challenges posed by models with correlated features, models with missing features, models with latent variables, and the non-linearities of the measurement processes, in a unified way. Furthermore, this research involves the development of data-driven sparse recovery algorithms that reinforce the value of information when the underlying statistical models are partially or completely unknown. The investigators will use the developed methods to enhance the detection of sparse mixtures of explosives with fluorescence sensor arrays, and to identify high-degree hubs in computer networks using network tomography.","title":"CIF: Small: Collaborative Research: A Unifying Approach for Identification of Sparse Interactions in Large Datasets","awardID":"1320547","effectiveDate":"2013-08-15","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[550889],"PO":["564898"]},"205661":{"abstract":"The primary objective of this research is to develop new, cognitively informed computational models of the generation of narrative that is told within three-dimensional virtual environments. Motivated by theoretic models of narrative structure and psychological models of narrative comprehension, techniques will be developed for creating accounts of sequences of events and the techniques needed to convey them to users. These techniques will use these models to search for narratives that are at once coherent and effective at communicating the underlying event structure. The project will explore how computational models of the mental processes performed by people when experiencing film or machinima can inform an automatic process used to generate the films themselves. Extensive empirical studies will provide a comprehensive evaluation of the effectiveness of the models.<br\/><br\/>The research program has three major thrusts: (1) Integrating generative models of character plans with narrative theoretic structural models to create storylines that reflect both rich character goal structures and recognizable narrative elements. (2) Developing methods for shot sequence selection that build on pragmatic models from linguistic communication to effectively convey characters' plans and goals. (3) Developing and then evaluating a system that integrates these parts to search for narratives that are both coherent and effective.<br\/><br\/>The project will contribute to the infrastructure of science and education by training new researchers (graduate research assistants) in an area that is broadly multidisciplinary (computer science, cognitive science and psychology). These new researchers will gain from the project a unique integrated view of the contributing disciplines. Team members will participate in the dissemination of results through journal articles and presentations at national and international conferences on creativity, artificial intelligence, human-computer interaction and psychology. It is expected that the work will have a significant impact on the theory and understanding of creativity, particularly in the context of narrative, serving as a foundation for a new generation of tools that support the creative process.","title":"HCC: Small: Collaborative Research: Integrating Cognitive and Computational Models of Narrative","awardID":"1319974","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[550660],"PO":["564456"]},"205782":{"abstract":"The widespread availability of communication networks fosters interactions among nodes that constantly affect each other by exchanging information over the available communication links. This dynamic, interactive, aspect of communication is common to many networked systems, from social networks to biological networks. Its causal nature differs from the batch coding and processing of classical communication systems and is not handled well by the traditional information theory results. These settings are more appropriate for the functioning and the understanding of control and regulation processes and, more generally, processes of learning and adaptation.<br\/><br\/>The main objective of the proposed research is to characterize the fundamental limitations of interacting dynamical systems over noisy communication links. We start analyzing the problem of interactive point-to-point communication where the encoder has access to noisy feedback from the receiver based on a new information theoretic quantity that captures the actual information flow in the forward channel when the feedback channel is noisy. From it, we propose to derive computable bounds on the noisy feedback capacity for common channels, to develop control-inspired practical coding schemes that are robust to noise in the feedback link, and to characterize costs and benefits of using noisy feedback. Further, we propose extensions of the theory to other new noisy feedback structures motivated by remote guidance and virtual reality applications. The resulting dynamical systems are both communication and control systems at the same time. We aim to study properties and limitations of these interacting dynamical systems, in an integrated way, by extending the relevant results in networked control systems.","title":"CIF: Small: Limitations of communication and control and over noisy feedback links","awardID":"1320643","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":[550938],"PO":["564924"]},"205584":{"abstract":"This collaborative research project (IIS-1320046, IIS-1319606) designs a 3-dimensional immersive visualization environment for volume data that is critical in a variety of application domains, such as medicine, engineering, geophysical exploration, and biomechanics. For example, biomechanics researchers examine volumes derived from insect scans to understand how form relates to function, particularly in regard to how insects create internal fluid flows. For effective analysis of a 3D volume, scientists and other users need to integrate various views, peer inside the volume, and separate various structures in the data. However, despite many advances in volume rendering algorithms, neither traditional displays nor traditional interaction techniques are sufficient for efficient and accurate analysis of complex volume datasets. This project develops an approach for interactively exploring and segmenting volume datasets by combining and extending: (1) utilization of advanced, high-fidelity displays based on virtual reality (VR) technologies for improving the visual analysis of volume data, and (2) the use of natural, gesture-based 3D techniques. Using controlled, empirical studies with real-world volume datasets from biomechanics and other biological sciences, the investigators are determining what characteristics of advanced displays can lead to faster, more accurate visual analysis. Iterative design and evaluation methods are being used to develop usable and natural 3D interaction techniques with which users can explore the interior of volume datasets. Beyond the empirical findings of these studies, an important outcome of the project is the design of a next-generation volume data analysis system that can be used by scientists and researchers to improve the efficiency and accuracy of their work.<br\/><br\/>The expected results will provide a deep understanding of visualization principles fostering further advancements in the realm of volume data analysis. Easier, more accurate, and faster analysis can lead to improvements in healthcare, breakthroughs in science, and advances in education. For example, this work may lead to insights into fundamental physiological mechanisms of feeding, breathing, and circulation in insects - one of the most important animal groups on earth. There are millions of insect species living in almost every habitat, and their lifestyles have profound impacts on human societies. Their effects in areas such as agriculture and health can be both positive (e.g., pollination) and negative (e.g., crop damage, disease), and understanding their fundamental physiologies is critical to controlling their impact. The project provides opportunities for interdisciplinary educational and research activities for graduate and undergraduate students, and outreach activities to underrepresented students. The results of this work will be disseminated broadly via publication in archival journals, peer-reviewed conferences, and online forums. The project website (https:\/\/research.cs.vt.edu\/3di\/node\/188) will provide access to research results, including data sets and software.","title":"CGV: Small: Collaborative Research: Immersive Visualization and 3D Interaction for Volume Data Analysis","awardID":"1319606","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[550484],"PO":["563751"]},"205474":{"abstract":"As power dissipation on a single-chip is increasing at an alarming rate due to massive integration of digital circuits, multicore design has become the only technique to scale performance. Multicores with tens to hundreds of cores are already available in the marketplace and future projections call for thousands of cores on the chip. To achieve scalable computing performance from the multicores, the communication between cores should also scale in bandwidth while significantly reducing the power consumption. Scaling the performance of the on-chip communication fabric, called the Network-on-Chip (NoC), has proven to be a significant challenge with traditional metallic interconnects due to fundamental signaling issues such as power dissipation, electromagnetic interference, crosstalk and reflections. Several studies and roadmaps have indicated that disruptive technology solutions such as photonics have the potential to alleviate the critical bandwidth, power and latency challenges of future multicores. This research seeks to exploit the unique advantages of photonic interconnects and 3D stacking technologies to develop scalable, energy-efficient, bandwidth-reconfigurable and reliable NoCs for future multicores. There are three goals of the proposed research; first, it will investigate and develop 3D stacked photonic NoC architectures and topologies that maximize performance and improve energy-efficiency. Second, it will develop runtime reconfiguration techniques that can adapt the network to the communication needs of the application, thereby improving performance on a per-application basis. Third, it will result in an extensive modeling and simulation framework to be used for designing and validating future photonic NoC architectures.<br\/><br\/>This research has far reaching broader impacts. This research is uniquely positioned to leverage two emerging technologies namely photonics and 3D stacking to meet the multicore challenge and will significantly benefit society. The proposed research is essential to continue the growth of computing performance that our society depends upon, and will result in digital devices ranging from smartphones to laptops with faster response time and improved reliability. By investigating the design of energy-efficient and high-bandwidth photonic-3D NoC architectures, this proposal describes a transformative and viable approach to combine technology, algorithm and applications? research to enable building scalable multicores. The cross-cutting nature of this research will foster new research directions in several areas, spanning technology\/energy-aware NoC design, novel computer architectures, and cutting-edge modeling and simulations tools for emerging technologies. This research will also play a major role in education by integrating discovery with teaching and training. Several graduate students will be directly involved with all phases of the project from which the core parts of their dissertations and theses will be derived. It will also benefit a wider audience of graduate and undergraduate students by incorporating the new research into several courses on computer architecture and parallel processing taught by the PIs. Finally, the results and findings of the proposed research will be disseminated to researchers, engineers and educators through technical publications and presentations.","title":"SHF: Small: Collaborative Research: Power-Efficient and Reliable 3D Stacked Reconfigurable Photonic Network-on-Chips for Scalable Multicore Architectures","awardID":"1318997","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["559883"],"PO":["565319"]},"205595":{"abstract":"A novel class of small low-cost unmanned underwater vehicles (UUVs) is beginning to perform oceanographic, environmental assessment, and national security missions that are faster and less expensive than previous methods such as large high-cost UUVs, human-piloted vehicles, and human divers. A significant limitation of small low-cost UUVs is their low-cost navigation systems which presently limit them to missions requiring comparatively low-precision navigation. This project is developing new methods for high-accuracy navigation with low-cost sensors to provide dramatically improved navigation accuracy for low-cost UUVs. The three-part approach (1) employs Doppler sonar velocity measurement and low-cost low-power inertial measurement units to estimate attitude; (2) develops nonlinear model-based state estimators employing a full nonlinear model of the vehicle's second order plant dynamics; and (3) utilizes underwater acoustic modem networks to provide simultaneous acoustic communication and acoustic range and range-rate data, and employ these data for improved underwater vehicle navigation. Experimental validation of these methods includes full-scale experimental trials with two disparate testbed underwater vehicles. Dissemination of the results includes research publications and more general public outreach. This project involves hands-on training and mentoring of undergraduate students and graduate students. The undergraduates will be involved in the research, and will also serve as mentors in a program which provides introductory engineering experiences for middle school girls in the Baltimore area through half-day weekend programs on the Johns Hopkins University campus. This research will enable UUVs to perform missions requiring high navigation accuracy that are presently considered either impractical or infeasible with existing low-cost UUVs.","title":"RI: Small: Fast, Cheap, and In Control: New Methods for Precision Navigation of Low-Cost Autonomous Underwater Vehicles for Ocean Science","awardID":"1319667","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[550512],"PO":["564069"]},"209643":{"abstract":"This research involves the development of a set of computational tools for addressing problems of image formation arising in fields ranging from medical imaging and non-destructive evaluation of the manufactured components to subsurface environmental remediation and civil infrastructure monitoring. Common to these as well as many other problems is the need to characterize the internal structure of a region of space from data collected along the periphery. While common examples such as X-ray Computed Tomography or Magnetic Resonance Imaging yield high resolution images, the problems of interest in this effort are far more challenging due to complications associated with the physics of the underlying sensing technology as well as restrictions concerning where and how data can be acquired.<br\/><br\/>To address these challenges, the work in this project exploits the fact that in many cases, the processing objective is the identification of specific regions of interest containing flaws or other anomalies. Through a multidisciplinary effort in engineering, mathematics, and computation, the investigators develop and study a powerful new class of innovative shaped based computational tools which combine variational Active Surface models, Level Set Methods, Boundary Element Methods, and Partial Differential Equations to detect\/reconstruct geometric structures of interest directly from raw tomographic data in a general class of PDE-based tomographic modalities. This study has the potential to yield a substantial paradigm shift in extracting geometric knowledge from tomographic measurements for a diverse collection of societally important applications characterized by challenging physics and restrictive sensing scenarios. Of specific interest here are problems of geotechnical surface wave inversion, non-destructive testing, and impedance tomography for environmental monitoring.","title":"Shape Based Tomographic Inversion for Maximal Geometric Resolution","awardID":"1347191","effectiveDate":"2013-08-01","expirationDate":"2015-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[561949,561950,561951],"PO":["564898"]},"201481":{"abstract":"The project entails research on software engineering (e.g., mapping requirements to software architectures, software architecture models and their adaptation, software re-factoring, adaptable\/autonomic middleware, etc), networking (software-defined networking, ad-hoc peer-to-peer networks, social private networks, etc), computer systems (virtualization, distributed computing, etc). The work will also provide techniques and middleware for distributed cyberinfrastructure supportive of mobile-hosted apps for science and education (e.g. middleware for virtual networking, social collaboration, resource virtualization and virtual appliances for different domains). By studying the mobile application-induced workload at the lowest layers of the systems software stack, such as the VMM, the project will identify how these layers can be improved to better support such workloads.<br\/><br\/>The project will advance the fundamental understanding of multiple technical issues faced in enabling flexible end-to-end management of cloud-supported mobile applications. Methods are needed to (re)implement applications so that their software architectures can reconfigure in response to changes in requirements as the environment changes, and to allow for runtime re-factoring of components for execution locally or remotely. Virtual networking techniques are needed to enable seamless off-loading of computation from a device to remote resources possibly provided by multiple clouds. In addition, both software adaptation and network configuration must be done on demand.","title":"EAGER: Collaborative Research: Model-based Autonomic Cloud Computing Software Technology","awardID":"1265341","effectiveDate":"2013-08-01","expirationDate":"2015-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[540130,"558495",540132],"PO":["564993"]},"205640":{"abstract":"As software pervades our society and lives, failures due to software<br\/>bugs become increasingly costly. Scalable approaches for<br\/>systematically checking software to find crucial bugs hold a key to<br\/>delivering higher quality software at a lower cost. Mera is a<br\/>methodology to scale model checking and symbolic execution which are two<br\/>powerful approaches for systematic software analysis and known to be<br\/>computationally expensive.<br\/><br\/>The project builds on two novel concepts: memoization, which allows<br\/>re-using computations performed across different checks to amortize<br\/>the cost of software analysis; and ranging, which allows distributing<br\/>the analysis into sub-problems of lesser complexity, which can be<br\/>solved separately and efficiently. Mera consists of three research<br\/>thrusts. First, the core memoization and ranging techniques for model<br\/>checking and symbolic execution are developed. Second, these<br\/>techniques are optimized in the context of different kinds of changes,<br\/>like the program code, expected properties, or analysis search-depth<br\/>parameters. Third, these techniques are adapted to effectively<br\/>utilize available resources for parallel computation using static and<br\/>dynamic strategies, such as work stealing. Mera will help improve<br\/>software quality and reliability thus holding the potential to provide<br\/>substantial economic benefits and to improve our quality of life.","title":"SHF: Small: Collaborative Research: Mera: Memoized Ranged Systematic Software Analyses","awardID":"1319858","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["553368"],"PO":["565264"]},"205772":{"abstract":"In the world of high-performance scientific computing, the rapid emergence of hybrid processors that make heavy use of accelerator technologies, such as Graphics Processing Units (GPUs) or the Intel Xeon Phi (a.k.a., Many Integrated Cores, MIC), raises critical new challenges for computational scientists. Their research applications typically depend on computational kernels (i.e., software implementations of one or more of the basic patterns of scientific computing) that are optimized for speed. Such programs spend most of their computing time executing one or more of these kernels, and long experience has taught developers that tuning their kernels for the architecture of a given processor is absolutely essential to achieving excellent performance at the level of the individual computing node. Since scientists want to run these applications on supercomputers with thousands of such nodes, high performance at the node level is essential to high productivity for the application at large. Unfortunately, for the vast majority of computational kernels, the three classic approaches to performance tuning?compiler-driven code transformations, low-level manual programming, or empirical autotuning?have always been very difficult, often producing mixed results; and the emerging era of hybrid processors makes all three techniques less effective still. The Bench-testing Environment for Automated Software Tuning (BEAST) makes a substantial contribution to solving this important problem. <br\/>BEAST creates a framework for exploring and optimizing the performance of computational kernels on hybrid processors that 1) applies to a diverse range of computational kernels, 2) (semi)automatically generates better performing implementations on various hybrid processor architectures, and 3) increases developer insight into why given kernel\/processor combinations have the performance profiles they do. To achieve this three-fold goal, it applies the model used for traditional application benchmarking in a completely novel way: it combines an abstract kernel specification and corresponding verification test, similar to standard benchmarking, with an automated testing engine and data analysis and machine learning tools, called the BEAST workbench. Using a new method for specifying language-neutral code stencils and a prototype BEAST workbench, the project explores alternative tuning methods and strategies for a diverse range of computational kernels. <br\/>Experiments carried out under this project are expected to show that the BEAST framework can dramatically improve the performance of many computational kernels that are of fundamental importance to scientific computing. As this software and the techniques for using it are made widely available to the science and engineering community, they will help to ensure the timely delivery of performance- optimized kernels for many domains and many types of hybrid processors, making the impact of the BEAST bench-tuning software infrastructure very broad indeed. Scientists and engineers, across a vast array of intellectually, economically and socially important domains, will be able to rapidly tune the underlying kernels in their applications to the characteristics of the latest platform, and thereby quickly gain the productivity benefits of each successive generation of accelerator technology.","title":"SHF: Small: Bench-testing Environment for Automated Software Tuning (BEAST)","awardID":"1320603","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"6892","name":"CI REUSE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}}],"PIcoPI":["558550"],"PO":["565272"]},"205783":{"abstract":"Auditory experience is an integral part of our daily life. Our perception of sound affects how we interpret and respond to various events around us. Overall, interactive modeling and simulation of sound effects and auditory events can significantly enhance numerous scientific and engineering applications, and also support more intuitive human-computer interaction for desktop and mobile applications. It also offers an alternative means to visualize datasets with complex characteristics (multi-dimensional, abstract, conceptual, spatial-temporal, etc.). Yet despite the fact that hearing is one of our dominant senses, sound rendering has not received as much attention as visual rendering to better serve as an effective communication channel for human-computer systems, and interactive audio rendering still poses major computational challenges. In this project, the PI focuses on rendering of aural effects, with attention to a greater correlation between sound and visual rendering, to communicate information (events, spatial extent, physical setting, emotion, ambience, etc.) to a user in a virtual world and to thereby increase the user's sense of presence and spaciousness while improving his\/her ability to locate sound sources. The PI's goal is to make radical advance in interactive sound rendering and application-specific auditory interaction techniques in order to achieve high-fidelity auditory interfaces for large-scale virtual reality. In particular, she will address the computational bottlenecks in example-guided, physics-based sound synthesis, develop new hybrid algorithms for creating realistic acoustic effects in complex, dynamic 3D virtual environments, demonstrate the techniques on acoustic walkthrough for a variety of applications, and evaluate the resulting auditory systems and their impact on target applications. The work will build upon the PI's prior accomplishments to make several major scientific advances that will significantly extend the state of the art in auditory displays and human-centric computing. Project outcomes will include new hybrid acoustic algorithms for realistic sound effects, novel example-guided physics-based sound synthesis, innovative applications of auditory displays, and better understanding of human auditory perception.<br\/><br\/>Broader Impacts: Applications of interactive sound rendering enabled by this project will span a wide variety of domains, include assistive technology for the visually impaired, multimodal human-centric interfaces, immersive teleconferencing, rapid prototyping of acoustic spaces for urban planning, structural design, and noise control. Project outcomes, including scientific advances and software systems, will be disseminated through websites, publications, workshops, community outreach, and other professional contacts. In addition to acoustic simulation, this research will ultimately offer fundamental scientific foundations for solving wave\/sound propagation problems in complex domains for seismology, geophysics, meteorology, engineering design, urban planning, etc.","title":"CGV: Small: Interactive Sound Rendering for Large-Scale Virtual Environments","awardID":"1320644","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["559716"],"PO":["565227"]},"205552":{"abstract":"A large number of \"big data\" and \"big simulation\" applications, such as those for determining network models or simulations of partial differential equation models, concern high dimensional data that are sparse. Sparse data structures and algorithms present significant advantages in terms of storage and computational costs. However, with only a few operations per data element, efficient and scalable implementations are difficult to achieve on current and emerging high performance computing systems with very high degrees of core level parallelism, complex node interconnect topology and multicore\/manycore nodes with non-uniform memory architectures (NUMA). This proposal develops and evaluates \u00e1-embedded graph hardware-software models and attendant data locality-preserving and NUMA-aware application to core\/thread mappings to enhance performance and parallel scalability. <br\/>Consider an application task graph A, weighted with measures of work and data sharing that is approximately embedded in two or three dimensions, to obtain an \u00e1-embedded graph A. Additionally, consider a weighted graph of a HPC system that is naturally assigned coordinates to obtain an \u00e1-embedded host graph model H. This proposal develops parallel algorithms to compute interconnect topology-aware mappings of A to H in order to optimize performance measures such as congestion and dilation while preserving load balance. Additionally, at a multicore node in H that is assigned a subgraph of A, (i) sparse data are reordered to enhance parallelism and locality, and (ii) a dynamic fine-grain NUMA-aware task scheduling is applied to respond through work-stealing to core variations in performance from resource conflicts, throttling etc. Finally, through insights gained from \u00e1-embedded graph models, sparse matrix algorithms are reformulated to enhance communication avoidance, soft error resilience and data preconditioning. Outcomes include enabling weak scaling to a very large number of cores by extracting parallelism at fine, medium and large-grains, and significantly enhanced fixed and scaled problem efficiencies through locality preservation. <br\/>The interconnect topology-aware models and maps hold the potential for impact on very large scale HPC workloads through potential incorporation into the Message Passing Interface for enhanced sparse communications. Additionally, the proposed locality-aware mappings and NUMA-aware scheduling can potentially benefit the very large base of modeling and simulation applications that run on small multicore clusters. Graduate student training is enhanced through a \"scale-up\" challenge component in an interdisciplinary course on computational science and engineering. High school students are introduced to parallel computing through summer in-residence programs seeking to broaden participation in science and engineering from underrepresented communities.","title":"SHF: Small: Embedded Graph Software-Hardware Models and Maps for Scalable Sparse Computations","awardID":"1319448","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}}],"PIcoPI":[550407],"PO":["565272"]},"205277":{"abstract":"The proposed project catalyzes a new collaboration between the Louisiana State University and three institutes in China, in the area of computational algebraic geometry.Research is planned in 3 distinct domains:<br\/><br\/>Problems in Arithmetic Algebraic Geometry. Specifically: (1) Moduli of genus 3 curves with special endomorphisms of their Jacobians. (2) Modularity questions for the Galois representations that arise from curves in part (1); (3) Special values of L-functions for Galois representations of the shape &#961;f &#8855; &#966; where f is a modular form and &#966; is a nonabelian Artin representation; (4) Dynamical systems arising from integer matrices.<br\/><br\/>Polynomial systems. Develop efficient algorithms for solving systems of polynomials via in- volutive bases such as Pommaret bases. Extend work already done for solving 0-dimensional systems to higher dimensions.<br\/><br\/>Generalized hypergeometric equations. Study the GKZ hypergeometric systems attached to interesting polytopes, for instance those coming from root systems. These give rise to interesting families of varieties, such as Calabi-Yau varieties.<br\/><br\/>All three areas are related to currently active research going on in algebraic geometry, and projects will involve both theoretical and computational tools.<br\/><br\/>Algebraic Geometry - is concerned with solutions to systems of polynomial equations. Polynomials are ubiquitous in pure and applied mathematics. They are fundamental objects occurring in practically every domain of science, and their study is central to many areas of current mathematical research. Part of the project is a study of spaces defined by polynomials. Another part is to study algorithms for the efficient solution to polynomial equations. This project also explores connections to other parts of mathematics, for instance number theory.<br\/><br\/>This proposal also supports one month visits each for a graduate student and a young post- doctoral researcher. The locus of this research is China, especially Beijing and Tianjin. The PI will be collaborating with Chinese mathematicians, and also teaching courses on related topics. This project allows two young U.S. mathematicians to participate in the exciting mathematical world developing in China. Establishing and extending such international collaborations can have a major positive impact not only on the narrow goals of a research project, but also on the long-term development of research and teaching in the US.","title":"US-China Collaboration: Problems in Computational Algebraic Geometry","awardID":"1318015","effectiveDate":"2013-08-01","expirationDate":"2014-12-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7299","name":"Catalyzing New Intl Collab"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0507","name":"Division of SCIENCE EDUCATION RESOURCES IM","abbr":"SER"},"pgm":{"id":"1264","name":"ALGEBRA,NUMBER THEORY,AND COM"}}],"PIcoPI":[549684],"PO":["563279"]},"209897":{"abstract":"Planning is one of the key technologies in robotics. Yet, robots are deployed in only a small number of niche areas, and most deployed robots have very minimal planning capability. This workshop discusses how the field of robot planning should progress to make robots deployable more widely, performing more novel tasks and relying less on human supervision. It brings together researchers from robotics, artificial intelligence, and related research disciplines to discuss the state of the art in planning, its use in various robotic applications and current research challenges. By studying planning research across different applications, analyzing planning challenges as part of complete robot architectures, and discussing the interaction of planning with other robot modules (such as perception, control, and user interfaces), the workshop participants will gain new insights into how planning can help robots become more robust and efficient. The workshop consists of invited talks, breakout sessions, panels and a final discussion aiming to converge on the roadmap for the field of robot planning that will be summarized in a report. The report and all presentations will be posted on the workshop website. The workshop is expected to stimulate future research towards robot planning in the real world and have strong potential to enable advances in all areas of robotics, from home assistance to medicine to exploration to manufacturing.","title":"Workshop: Robot Planning in the Real World: Research Challenges and Opportunities","awardID":"1349355","effectiveDate":"2013-08-15","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["460643",562687,562688],"PO":["564069"]},"209545":{"abstract":"In recent years, computer systems designed to understand ordinary language have improved rapidly. These advances depend in part on improving the language resources that help systems recognize different senses of individual words and how the parts of a sentence fit together. <br\/><br\/>People understand words largely by relating them to common situations; in 'She tossed the letter across the table to Jerry', one recognizes that the main idea comes from 'toss', and understands the different roles that 'she', 'the letter', 'across the table', and 'to Jerry' play. For the past fifteen years, the FrameNet team at the International Computer Science Institute has been defining situations, called semantic frames, and labeling examples with semantic roles on the constituents of illustrative sentences. The FrameNet knowledge database contains over 1,100 semantic frames, ranging from getting a job to curing a disease, and almost 200,000 labeled sentences. Other researchers have created software to automatically label sentences in open text based on FrameNet data; these automatic semantic role labeling (ASRL) systems facilitate the automatic recognition of events and their participants in documents ranging from news stories and military reports.<br\/><br\/>This award funds a one-week workshop, September 9-13, 2013, introducing FrameNet to a wider range of industry and academic participants. Speakers include the FrameNet team as well as developers and users of ASRL systems. Topics covered range from implications of FrameNet for protecting privacy to using frames in understanding metaphor. Software developers have a hands-on coding session using the new FrameNet library for NLTK; other participants perform hands-on frame definition and annotation.","title":"FrameNet Workshop: Developing New NLP Applications","awardID":"1346605","effectiveDate":"2013-08-01","expirationDate":"2015-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[561714],"PO":["565215"]},"199183":{"abstract":"The recent adoption of Transactional Memory (TM) in mainstream microprocessors and programming languages heralds a new era in parallel programming. Simply put, support for low-overhead speculative execution of critical sections will enable greater productivity, more straightforward designs for scalable data structures, and simplified reasoning about the correctness of programs. The full promise of TM, however, will only be realized through the development of a complete software ecosystem to enable scalable and conflict-free execution of transactions at any and all levels of the systems stack; including operating systems, language-level runtime libraries, and end-user code. The design of such an ecosystem is the focus of this research.<br\/><br\/>This research explores algorithms and software systems that provide a seamless environment for transactional programming. Through a focus on both the C++ and Java languages, this project will invent both data structures and supporting libraries (such as garbage collectors) that can be used both to leverage TM support in programs that are, themselves, unaware of modern transactional features, and to exploit TM support in programs that are explicitly parallel and transactional. The project also considers programming models, with a focus on delivering a purely transactional model of program execution, via parallel open and closed-nested transactions that can exploit the first generation of transactional hardware. The outcomes of this research will influence the design of second generation TM hardware, and will result in prototypes and source code that will be distributed as open-source software. In addition, a broad array of educational and outreach activities are planned, to include deeper integration of parallel programming into undergraduate courses and activities in the local community that aim to widen the pipeline of students considering degrees and careers in science and technology.","title":"CAREER: A Transactional Software Ecosystem","awardID":"1253362","effectiveDate":"2013-08-01","expirationDate":"2018-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":[534282],"PO":["564588"]},"202791":{"abstract":"Despite significant progress in Neural Engineering in recent years, overall progress in the field does not appear to have been commensurate with the scope of investment. It has become evident that the field can benefit from a new paradigm in research and development that focuses on robust algorithm development. The purpose of this planning grant is to develop community support for the creation of the Neural Engineering Data Consortium (NEDC) at Temple University. The NEDC is focusing the attention of the research community on a progression of research questions as well as generating and curating massive data sets to be used in addressing those questions. Under this award, we are conducting an extensive series of workshops and site visits to build consensus amongst various research groups from academia and industry. Guided by this site research, we are developing an operational model for the NEDC that is simultaneously relevant to academic research, industry R&D, and government funding agencies. The NEDC is structured to significantly accelerate research progress and provide resources that promote the development of more robust technology. We are also broadening participation in neural engineering research by making data available to research groups who have significant signal processing expertise but who lack capacity for data generation. The impact of funded research is thus improved by enticing more participation in focused evaluation tasks. Finally, the NEDC is accelerating the transfer of technology to the healthcare marketplace, where it can directly enhance quality of life for a variety of patients.","title":"The Neural Engineering Data Consortium: Building Community Resources to Advance Research","awardID":"1305190","effectiveDate":"2013-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[543479,543480],"PO":[543481]},"203781":{"abstract":"Intellectual merit: This award is for a program on fundamental experiments in quantum optics using superconducting integrated circuits. Based on the paradigm of \"circuit QED\" developed by the PI's group, in which superconducting qubits are combined with microwave resonant cavities to realize the physics of the Jaynes-Cummings model with ultra-strong coupling, we are pursuing the generation, manipulation, and measurement of non-classical states of the electromagnetic field. Using the tools developed for quantum information processing with superconducting devices, we have realized a new 3D version of a \"two-cavity\" circuit architecture with significantly extended coherence times during the current funding period. Here a single qubit, which provides nonlinearity, is combined with two microwave cavities, allowing new possibilities for nonlinear optics at the single quantum level. We have been able to use these devices to observe new quantum phenomena, such as the single-photon Kerr regime, and to manipulate states of microwave fields in new ways. We have the ability to create interesting non-classical states, including the largest \"Schrodinger cat states\" (superpositions of Glauber coherent states) ever produced, and measure them with full Wigner state tomography. This opens new possibilities for employing cavities and the physics of continuous variables in quantum information processing. Our main goal with this architecture is to develop real-time quantum non-demolition measurements capable of detecting single quantum jumps, and utilize this to actively stabilize states and perform quantum error correction. The physics and capabilities developed here can have significant impact on the prospects for scalable quantum information processing with solid-state devices.<br\/><br\/>Broader impacts: This work opens a new area for fundamental studies of the quantum measurement of the electromagnetic field, as well as to develop new technology for integrated circuits which operate at the single quantum level. The experiments employ the novel features of the circuit QED system to observe and study phenomena which are mostly inaccessible with traditional AMO systems in quantum optics. The techniques and capabilities for single photon generation and detection could have major impact on the prospects for scalable quantum computation and communication in these superconducting circuits and also atomic\/condensed matter hybrid systems such as ion and molecule chips. This project also continues the trend established by earlier work to forge new connections between atomic and condensed matter physics communities. The project supports graduate student research. Results will be disseminated via publications and presentations at conferences in the areas of AMO physics, quantum information, and condensed matter physics, as well as in tutorials and introductory lectures at summer schools and conferences. This research will take advantage of the infrastructure and technical knowledge for fabrication and measurement of superconducting devices developed as part of the large, applied effort for development of quantum computing at Yale, but allows new and distinct directions of fundamental physical interest.","title":"Quantum Optics with Superconducting Circuits","awardID":"1309996","effectiveDate":"2013-08-15","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"1290","name":"OPTICAL PHYSICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1710","name":"CONDENSED MATTER PHYSICS"}}],"PIcoPI":[545858],"PO":["564326"]},"205641":{"abstract":"Monitoring and understanding aquatic environments is critical to water sustainability. The goal of this award is to establish a theoretical framework and provide an enabling technology for robust underwater collaborative sensing with small, inexpensive robots. Inspired by the source-seeking behavior of live fish, computationally efficient algorithms are developed for cooperative tracing of the gradients of environmental fields, and their robustness is analyzed in the presence of localization error and changing communication topology. The algorithms are experimentally validated in thermal source seeking and tracing with a group of energy-efficient and highly maneuverable gliding robotic fish, which are enhanced in this project with optical communication and localization capabilities. Advanced controllers are developed for these robots to realize three-dimensional maneuvering and to track reference paths planned through collaborative sensing algorithms. This award offers fundamental understanding of limits and robustness properties of collaborative sensing by resource-limited robots, and contributes to the knowledge base in underwater communication and ranging for small robots. It enables technological advances for persistent sampling of versatile aquatic environments including coastal waters, lakes, and rivers, with a myriad of applications such as oil spill response, ecological monitoring, and port and drinking water security. The findings from this project are disseminated through publications, software sharing, and technology commercialization. The project provides interdisciplinary training opportunities for students, including those from underrepresented groups. Outreach activities, including museum\/aquarium exhibits and teacher training, are developed to pique the interest of K-12 students, teachers, and the public in science and engineering.","title":"RI: Small: Collaborative Research: Bio-inspired Collaborative Sensing with Novel Gliding Robotic Fish","awardID":"1319874","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[550613],"PO":["564069"]},"205773":{"abstract":"Software plagiarism is an act of reusing someone else's code, in whole or in part, into one own program in a way violating the terms of original license. Along with the rapid developing software industry and the burst of open source projects, software plagiarism has become a very serious threat to Intellectual Property Protection and the \"healthiness\" of the open-source-embracing software industry. Meanwhile, software plagiarism (and what is called app repackaging) has become an even more common phenomenon in the mobile app markets for monetary profit or propagation of malware by inserting malicious payloads into the original apps. To address this threat, computer-aided, automated plagiarism detection tools should play a major role. However, existing plagiarism detection schemes are not resilient to code obfuscation, and often they can be defeated by (in most cases rather simple) code-obfuscation-based counter-detection tools which are freely available.<br\/><br\/>In this project, the software plagiarism detection problem is studied in a systematic way. The proposed plagiarism detection methods for PC applications leverage program logic and longest semantically-equivalent-basic-block subsequences. They are capable of detecting partial program plagiarism and also provide formal guarantee on obfuscation resilience. The proposed method for mobile apps exploits user interface for plagiarism detection, and this unique design angle empowers it to defeat various code obfuscation techniques. Our proposed research will significantly deter the intention or practice of software plagiarism. It will not only serve as a useful tool in collecting strong plagiarism evidences for lawsuits related to intellectual property, but also promote a more healthy and trustworthy sharing environment for the open source community and for the mobile app markets. Broader impact will also result from the education and dissemination initiatives.","title":"SHF: Small: Towards Obfuscation-Resilient Software Plagiarism Detection","awardID":"1320605","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[550918,"277956",550920],"PO":["564388"]},"205663":{"abstract":"Genes in living cells interact with each other and form a complex network to regulate molecular functions and biological processes. Recent studies have shown that gene regulatory networks (GRNs) can undergo substantial rewiring when cells respond to different environmental signals. More generally, differential changes of GRNs can occur depending on environment, tissue type, disease state, development and speciation. Identification of such changes in GRNs is thus an important step to fully understand how GRNs work, and may have profound impact on the understanding of various biological processes and on biomedical research. However, current computational methods are focused on the inference of GRNs under a single condition or attempt to identify differential gene co-expression. No method currently exists that is capable of systematically identify structural changes in GRNs. The objectives of this project are to design systematic methods that can exploit gene expression and other relevant data to infer structural changes of GRNs, and to develop software that implements such inference methods. <br\/><br\/>Intellectual merit: The proposed inference methods seek to leverage an important attribute of GRNs, the sparsity in both GRNs and their structural changes, and they are built on the innovative ideas of sparse signal processing. They employ novel inference techniques to integrate various types of data into a unified framework. This systematic approach is expected to significantly improve inference accuracy over existing ad hoc methods. The proposed methods and the resulting software will provide a valuable tool for the analysis of differential GRNs and help to uncover differential gene-gene interactions under different conditions. Although mathematical formulations are framed for the problem of inference of differential GRNs, the underlying mathematical ideas and the associated inference methods may also find applications in more general domain of sparse signal processing and sparse model learning.<br\/><br\/>Broader impact: Successful completion of the proposed project will have a broad impact on the fields of signal processing, systems biology, and medicine. It will contribute a novel set of inference methods to the field of sparse signal processing. It will also help to understand the dynamic changes of GRNs that occur in various disease states, during cell differentiation, or in cellular response to environmental changes. In particular, understanding differential gene-gene interactions in genetic diseases such as cancer will open the door to new diagnostics and therapeutics development. Overall, the proposed research will help to discover new knowledge and potentially find applications in medical research, thereby benefiting society as a whole. The proposed project will also positively impact interdisciplinary education at both graduate and undergraduate levels, and attract minority students to be involved in cutting edge research.","title":"CIF: Small: Sparse Signal Processing Methods for Inference of Differential Gene Regulatory Networks","awardID":"1319981","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[550664],"PO":["565223"]},"205432":{"abstract":"Smartphones and tablets are being used widely, and with such a pervasive use, protecting mobile systems is of critical importance. One of the unique features in mobile systems is that many applications incorporate third-party components, such as advertisement, social-network APIs, and the WebView component (that runs third-party JavaScript code). <br\/><br\/>With third-party components, the code developed by application developers and the code from third parties are executed within the same context and with the same privilege. No access control system is developed to separate the privilege of the first-party application code from that of third-party components. This has resulted in over-privilege issues. <br\/><br\/>The objective of this project is to develop adequate access control systems to remedy the risks introduced by third-party components. The development is based on a systematic study of various third-party components, how they interact with applications, what features are desirable, and what their protection needs are. The project meets this objective using a three-pronged approach: (1) add new access controls to WebView to control the interactions with third-party code; (2) add package-level access controls within apps to prevent over-privilege; and (3) isolate third-party components with visual elements. <br\/><br\/>This project can offer mobile system developers a deeper understanding of the security problems in the systems, suggest to them how better to design into mobile systems desired security properties, and eventually improve the security of mobile systems.","title":"TWC: Small: Develop Fine-Grained Access Control for Third-Party Components in Mobile Systems","awardID":"1318814","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["550133"],"PO":["562974"]},"205674":{"abstract":"Massive modern data centers consisting of tens of thousands of servers, such as Microsoft's Azure platform, Google's App engine, and Amazon's EC2 platform, have emerged to form the backbone of a variety of powerful distributed computing frameworks. Meanwhile, many companies are moving their services such as e-commerce, scientific computing and social networking to the cloud, due to its ability to offer scalable and elastic computing and storage services. In such large-scale distributed computing frameworks, efficient communication is often required among huge datasets stored in tens of thousands of servers across a data center. The data center network (DCN) that connects different servers would become the bottleneck of the system, and its performance is essential to the successful operation of a data center. On the other hand, many online applications and back-end infrastructural computations hosted by data centers require one-to-many or multicast communication from a server to a group of servers. This research aims to investigate the fundamental and challenging issues faced in building cost-efficient multicast data center networks with guaranteed performance. As cloud computing is penetrating into all aspects of society, this research will have a profound impact on society and help change the world. <br\/><br\/>The objective of this research is to design cost-efficient multicast fat-tree data center networks (DCNs) with guaranteed performance through exploring some unique novel features and techniques in data centers. The project combines theoretical analysis, algorithm design, network optimization, simulation, and prototyping techniques to provide a comprehensive working solution that enables high performance multicast in fat-tree DCNs. More specifically, the research focuses on following closely coupled issues: (1) cost-efficient provisioning of fat-tree DCNs to deploy guaranteed-bandwidth multicast by exploring server redundancy and link oversubscription in data centers; (2) leveraging the OpenFlow framework to develop practical multicast scheduling algorithms that ensure traffic load balance and efficient network utilization under volatile data center traffic; (3) employing virtual machine technology to offer multicast with differentiated bandwidth guarantees tailored to application-specific demand; (4) conducting a comprehensive performance evaluation through extensive simulations and implementation of proposed schemes in a network prototype. This research hopes to impact fundamental design principles of high performance multicast fat-tree DCNs. The outcome of this research has the potential to boost the performance of cloud computing applications currently hosted in data centers, and to facilitate cloud adoption for future applications that rely on group communication and demand predictable high bandwidth. A project goal is to train graduate students and promote the participation of female engineering students. The important findings of this project are to be disseminated to the research community by way of conferences, journals and web site access.","title":"SHF: Small: Towards Cost-Efficient Guaranteed Performance Multicast in Fat-Tree Data Center Networks","awardID":"1320044","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":[550688],"PO":["366560"]},"205685":{"abstract":"What does it mean to \"understand\" an image? One popular answer is simply naming the objects seen in the image. During the last decade most computer vision researchers have focused on this \"object naming\" problem. While there has been great progress in detecting things like \"cars\" and \"people\", such a level of understanding still cannot answer even basic questions about an image such as \"What is the geometric structure of the scene?\" \"Where in the image can I walk\"?<br\/><br\/>The goal of this project is to develop a geometric and functional representation of our visual world for scene understanding. This project aims to develop this functional representation by learning relationships between the physical\/visual representation of the scene and the space of the interactions an agent can perform in that scene. The key advantage of functional scene representation is that it is subjective, explicitly task-based and takes into account the agent?s capabilities.<br\/><br\/>This project is anticipated to result in major advances within the image understanding community, bringing it closer to researchers in robotics. It is anticipated to result in improvements in: (a) 3D Scene Understanding; (b) Recognition; (c) Human Activity Understanding, and hence could be a critical enabling technology for applications such as autonomous systems, surveillance, and personal robotics. This project is also expected to contribute to education through course development, student projects, workshops, and tutorials involving a broader audience as well as using popular online media (e.g., YouTube) and interactive web demos to involve young children.","title":"RI: Small: Functional Scene Representation for Image Understanding","awardID":"1320083","effectiveDate":"2013-08-15","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[550714],"PO":["565035"]},"202198":{"abstract":"Power consumption of datacenters poses economic, societal and environmental concerns. A large datacenter spends millions of dollars in yearly operational expenditures (op-ex) paying its electricity bills, and in provisioning the power delivery network, to accommodate the peak power draw, even if this draw is rarely sustained. Re-shaping the power draw temporally (over time) and spatially (across regions of the datacenter, or even across datacenters), broadly referred to as Demand Response (DR), is a common technique to reduce cap-ex and op-ex costs. Until now, datacenter DR has primarily used computing knobs -- consolidation, scheduling, migration, and power state modulation -- to manage the power draw. <br\/><br\/>This project will investigate a novel set of complementary techniques leveraging Energy Storage Devices (ESDs) in the datacenter for DR. The project will explore specific issues related to provisioning -- type, capacity and location -- ESDs in the datacenter power hierarchy. It will also develop control techniques for sourcing from these devices, and coupling their usage with current computing DR techniques, all the while optimizing for performance, cost, availability and ESD health related criteria. This research will have a direct impact on datacenter power cost reduction and the ability to source renewable energy. The platforms, models and power traces from this work can be useful to further ESD research in datacenters. This project will also enhance interdisciplinary curriculum in the related areas, and lead to new undergraduate honor's thesis projects.","title":"CSR: Medium: Provisioning and Harnessing Energy Storage for Datacenter Demand Response","awardID":"1302225","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["542015",541886,541887],"PO":["565255"]},"209777":{"abstract":"EAGER: Hierarchical Topic Modeling by Nonnegative Matrix Factorization for Interactive Multi-scale Analysis of Text Data<br\/><br\/>Nonnegative matrix factorization (NMF) has proven to be an important tool of choice for numerous data analytic problems in text, imaging, and computer vision. It provides advanced mathematical methods for improvements in dimensionality reduction, clustering, etc. A distinguishing feature of the NMF is the requirement of non-negativity in the factors that represent the matrix in a lower rank. This property greatly enhances the interpretability and modeling capability for many applications, where preserving non-negativity is important. This project is studying foundational properties of the NMF, producing new algorithmic methods using the framework of NMF for efficient and effective hierarchical clustering and topic modeling of large scale text data for multi-scale analysis, generating labels for the topics, and interactive analysis. In addition, an interactive visual analytic system for the proposed methods is being developed to make these theoretical and algorithmic discoveries readily available to the research and applications communities. New multi-scale hierarchical methods for generating clusters and discovering topics in the documents and detection of topic changes over time are being explored to enable computationally efficient and perceptually effective ways of exploring text data and discovering latent group structure. Visual analytic systems are also being developed based on this foundational work to enable more effective and informed discovery of topics in a large-scale document collection.<br\/><br\/>This project will have a significant impact on the analysis and development of NMF algorithms and new modeling of problems for applications utilizing the NMF (e.g., 'Big Data'). The project is yielding effective computational methods with solid analysis that will enhance the analysis of high-dimensional data in broad areas of science, engineering, medicine, and business disciplines beyond the application areas being considered within this project.","title":"EAGER: Hierarchical Topic Modeling by Nonnegative Matrix Factorization for Interactive Multi-scale Analysis of Text Data","awardID":"1348152","effectiveDate":"2013-08-15","expirationDate":"2015-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[562362],"PO":["565227"]},"205630":{"abstract":"The problem of ranking objects occupies a central place in key technologies such as web search and recommendation systems. These technologies have a tremendous daily impact on the lives of millions of people. Moreover, the enormous scale of data on the web makes the use of machine learning especially attractive in constructing ranking algorithms. A huge amount of research effort has been devoted to developing efficient ranking algorithms that can deal with a variety of data sets encountered in web search and recommendation systems.<br\/><br\/>This project develops unifying mathematical theory that will provide a basis for understanding and categorizing existing algorithms and, more importantly, lead to deeper insights and new algorithms for the problem of learning to rank. The investigators also apply ranking algorithms to new domains. For example, ranking chemical reactions based on their plausibility will help chemists discover much-needed reaction bases for technologies such as carbon dioxide reduction, and conversion of natural gas into gasoline. <br\/><br\/>Fundamental advances in the statistical theory of ranking will be incorporated into undergraduate and graduate courses. Data sets and software developed will be made freely available to the scientific community. The investigators will also organize a workshop with a focus on interdisciplinary participation and involvement of under-represented groups in computer science and statistics.<br\/><br\/>The primary technical challenge in developing statistical ranking theory is the absence of a universally agreed-upon loss functions for ranking. This is in contrast to classic machine learning problems such as classification and regression, where there are only a few natural possibilities for the loss function and these are well-understood theoretically. The project addresses this gap by investigating how different loss functions for ranking affect fundamental theoretical properties such as learnability, and by creating a theory of convex surrogates that is applicable when loss functions abound. The project re-examines existing statistical literature on ranking with a computational lens. This will enable development of flexible and efficient plug-in decision rules that model the conditional probability of labels given inputs.<br\/><br\/>By incorporating the results of this research into courses and survey articles, the PIs help train a new generation of machine learning researchers and practitioners who will view ranking as a learning problem on par with classification and regression in mathematical depth as well as practical importance. Theoretical guidance for practitioners formulating new algorithms for ranking will improve the most common applications on the web.","title":"RI: Small: Collaborative Research: Statistical ranking theory without a canonical loss","awardID":"1319810","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[550588],"PO":["562760"]},"205751":{"abstract":"The project is motivated by the need of small-to-medium sized businesses in the United States to automate handling and assembly of compliant parts. As a case study, it focuses on robotic installation of a wire harness (a bundle of wires that terminate in electrical connectors). This manufacturing task is ubiquitous but hard to automate because it requires reasoning about deformation of the wire harness. The project is addressing this challenge with new algorithms for manipulation and perception of deformable objects that are based on novel representations of object shape. It considers first the manipulation of a single wire (one piece of a wire harness). It expresses the shape of this wire as the solution to a geometric optimal control problem, and shows that the set of all solutions to this problem is a smooth manifold that can be parameterized by a single coordinate chart. This result leads to an algorithm for manipulation planning that works well and is easy to implement. Objectives include extending this model to consider variable stiffness, plastic deformation, and branching; making manipulation plans robust to perturbation; estimating material properties and shape from sensor data; and experimentally demonstrating robotic installation of a wire harness. Outreach efforts include co-directing a week-long summer institute for high school students, mentoring undergraduate researchers, and organizing an industrial forum.","title":"RI: Small: Mechanics, Manipulation, and Perception of Deformable Objects for Robotic Manufacturing","awardID":"1320519","effectiveDate":"2013-08-15","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[550866],"PO":["564069"]},"205675":{"abstract":"This collaborative research project (IIS-1320046, IIS-1319606) designs a 3-dimensional immersive visualization environment for volume data that is critical in a variety of application domains, such as medicine, engineering, geophysical exploration, and biomechanics. For example, biomechanics researchers examine volumes derived from insect scans to understand how form relates to function, particularly in regard to how insects create internal fluid flows. For effective analysis of a 3D volume, scientists and other users need to integrate various views, peer inside the volume, and separate various structures in the data. However, despite many advances in volume rendering algorithms, neither traditional displays nor traditional interaction techniques are sufficient for efficient and accurate analysis of complex volume datasets. This project develops an approach for interactively exploring and segmenting volume datasets by combining and extending: (1) utilization of advanced, high-fidelity displays based on virtual reality (VR) technologies for improving the visual analysis of volume data, and (2) the use of natural, gesture-based 3D techniques. Using controlled, empirical studies with real-world volume datasets from biomechanics and other biological sciences, the investigators are determining what characteristics of advanced displays can lead to faster, more accurate visual analysis. Iterative design and evaluation methods are being used to develop usable and natural 3D interaction techniques with which users can explore the interior of volume datasets. Beyond the empirical findings of these studies, an important outcome of the project is the design of a next-generation volume data analysis system that can be used by scientists and researchers to improve the efficiency and accuracy of their work.<br\/><br\/>The expected results will provide a deep understanding of visualization principles fostering further advancements in the realm of volume data analysis. Easier, more accurate, and faster analysis can lead to improvements in healthcare, breakthroughs in science, and advances in education. For example, this work may lead to insights into fundamental physiological mechanisms of feeding, breathing, and circulation in insects - one of the most important animal groups on earth. There are millions of insect species living in almost every habitat, and their lifestyles have profound impacts on human societies. Their effects in areas such as agriculture and health can be both positive (e.g., pollination) and negative (e.g., crop damage, disease), and understanding their fundamental physiologies is critical to controlling their impact. The project provides opportunities for interdisciplinary educational and research activities for graduate and undergraduate students, and outreach activities to underrepresented students. The results of this work will be disseminated broadly via publication in archival journals, peer-reviewed conferences, and online forums. The project website (https:\/\/research.cs.vt.edu\/3di\/node\/188) will provide access to research results, including data sets and software.","title":"CGV: Small: Collaborative Research: Immersive Visualization and 3D Interaction for Volume Data Analysis","awardID":"1320046","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["210005",550691],"PO":["563751"]},"205796":{"abstract":"This project aims to advance stereo vision and optical flow algorithms to work in challenging real-world conditions. It contributes novel algorithmic approaches, new high-resolution datasets with ground truth, and an update to the Middlebury benchmarks.<br\/><br\/>The algorithmic advances include fast matching algorithms that employ radiometric and geometric self-calibration, including smart data terms that establish noise and color models during the matching process, and novel layer-based surface reconstruction algorithms with explicit reasoning about half-occluded regions, reflections, and transparency. The new datasets reflect current challenges, including high-resolution images of real-world scenes with complex occlusions, specular surfaces and reflections under different illuminations and taken with different cameras. Undergraduate students are actively involved in all components of this research.<br\/><br\/>The project has strong potential impact along several fronts. The new datasets and benchmarks challenge the community and serve as catalysts for new research. The algorithmic advances allow harnessing the explosion of images available online, and enable real-world applications such as automated driving, geolocation, and automatic 3D reconstruction of whole cities. Finally, the project exposes undergraduates at a liberal-arts college in rural Vermont to the world of research, experimentation, and discovery.","title":"RI: Small: RUI: Image Matching in the Wild","awardID":"1320715","effectiveDate":"2013-08-15","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"8084","name":"CDS&E"}}],"PIcoPI":[550972],"PO":["564316"]},"205686":{"abstract":"Information-theoretic security is the science of safeguarding information across a communication network based on the use of concepts and techniques in information theory. It encompasses protection against eavesdropping, impersonation, and substitution attacks made by potential adversaries present in the network. Whereas eavesdropping and impersonation attacks (and solutions) are well studied, substitution attacks, in which the adversary replaces messages from a source by different valid messages from the same source, present new risks in an increasingly networked world. This work explores how it is possible to make use of side information that is often available in a typical communication network to check against substitution attacks made directly on raw messages by potential adversaries in the network. This frees the process of guaranteeing information integrity of the messages from the requirements of secrecy and authentication, and better isolates the mathematical structure that leads to information integrity in relation to the network topology. <br\/><br\/>The separation principle developed in this work then allows one to more easily incorporate secrecy and authentication back into the overall information-theoretic security design. The broader implications of information-theoretic network security are increasingly manifest in electronic commerce, reliable communications, and confidentiality of legal, proprietary, diplomatic, and medical information.","title":"CIF: Small: Information transfer with guaranteed integrity","awardID":"1320086","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[550716],"PO":["564924"]},"208733":{"abstract":"This award will support student travel to the fifth Midwest Verification Day (MVD), to be held at the University of Illinois at Chicago in September 2013. MVD is an informal regional workshop with the goal of cultivating a regional research network in verification and formal methods. The funds will help support U.S. students, focusing on Ph.D. students at an advanced stage in their program and students who would otherwise not be able to attend MVD. Supporting student travel to attend professional conferences and workshops is a very important mission of the NSF. Broader impacts include training the next generation of researchers in this important research area.","title":"Midwest Verification Day (MVD) 2013","awardID":"1341855","effectiveDate":"2013-08-01","expirationDate":"2015-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["362818","564387"],"PO":["565264"]},"208898":{"abstract":"This award provides travel support for students and postdoctoral fellows to attend the 29th Annual Symposium on Computational Geometry, to be held June 17?20, 2013 in Rio de Janeiro, Brazil.<br\/><br\/>The Symposium on Computational Geometry (SOCG) is the oldest and most influential international conference in computational geometry. Throughout its almost 30-year history, SOCG has played a seminal role in the formation and evolution of the field, and it continues to serve as the flagship venue for groundbreaking research in all areas of geometric computing.<br\/><br\/>The funds will be used to encourage and facilitate the participation of under-represented groups in this top-tier computer science conference. They will also contribute towards attracting more underrepresented groups to computer science research giving students an opportunity to engage in the important technical, professional and social exchanges that SOCG fosters. Finally, the conference itself and all conference attendees will benefit from the greater attendance and consequently higher proportion of students and under-represented groups that this travel grant makes possible.","title":"Student Travel Support for SOCG 2013","awardID":"1342819","effectiveDate":"2013-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7929","name":"COMPUTATIONAL GEOMETRY"}}],"PIcoPI":["468851"],"PO":["565157"]},"209646":{"abstract":"This project addresses a problem which has kept virtual reality from widespread use. Some 15 years ago high-capability graphics cards in PCs reduced the cost of computing for virtual environments from hundreds-of-thousands of dollars to (today) hundreds of dollars. Low-cost head-mounted displays have just appeared. The similar advance in viewpoint tracking has not occurred; accurate, low-latency wide-area viewpoint tracking remains very costly. Virtual reality demands stereo 60 frames per second per eye and system latencies below 50 ms. This research is developing a novel system to provide accurate, low-latency viewpoint tracking to meet these requirements with consumer-cost components. The research is based upon a recently demonstrated proof-of-concept system. A standard RGB-Depth camera sits on the user's head. Pose is calculated by matching images against an environment model. A Kalman filter integrates rotational velocity and linear acceleration from a cheap high-speed inertial measurement unit (IMU) to update the pose estimate many times between frames. This not only gives low-latency pose readings, it also improves initial values for the next camera calculation. The depth images and reconstruction software are concurrently used to incrementally build\/update the depth model of the environment for the camera matching. <br\/><br\/>The current research is demonstrating the system's potential. To work completely successfully, both conceptual and algorithmic advances are in process. IMU calibrations are being improved. Temperature and dynamic bias must be compensated in the calibration to improve stimation and reduce jitter. Using multiple cameras to reduce overall noise and handle difficult cases (such as blank walls) are being addressed with new algorithms and evaluated. The merging of new and modeled data is computationally expensive. The feasibility demo uses two GPUs, one for rendering; one for tracking. Ways are being invented to do it on one. Additional future research includes tracking dynamic objects and incorporating object recognition (e.g., such as a desk or chairs) to improve estimates. Widespread access to virtual reality may well open new, unexpected creative uses of the technology. The research is inventing the proof-of-concept system forward to one that can make this exciting leap.","title":"EAGER: Viewpoint Tracking via Acceleration Stabilized with Computer Vision","awardID":"1347208","effectiveDate":"2013-08-15","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[561957],"PO":["565227"]},"209217":{"abstract":"This project is exploring the use of crowd-sourcing, or citizen science, to produce a large database of analyzed human manipulation video. Every human is an expert on human manipulation. Harnessing this expertise has the potential to radically transform our knowledge of manipulation. A large analyzed video database directly serves several important goals of robotics, including autonomous robotic manipulation and recognition of human behavior. This new approach is in its earliest stages. The project goals are to explore the new approach, identify problems, assess the value, refine the vision, and formulate plans. Activities include development of pilot interfaces, testing different approaches to user training, and developing approaches to the filtering and aggregation of results. The ultimate impact will be a broader scientific understanding of human manipulation, and a large dataset to support research in robotic manipulation and human behavior recognition. Results will be disseminated through publication of discoveries related to human manipulation, open access to the database, and open access to the crowd-sourcing interface and related software.","title":"EAGER: Exploratory Research on Harnessing Human Manipulation","awardID":"1344361","effectiveDate":"2013-08-15","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[560864,560865],"PO":["564069"]},"201484":{"abstract":"The project entails research on software engineering (e.g., mapping requirements to software architectures, software architecture models and their adaptation, software re-factoring, adaptable\/autonomic middleware, etc), networking (software-defined networking, ad-hoc peer-to-peer networks, social private networks, etc), computer systems (virtualization, distributed computing, etc). The work will also provide techniques and middleware for distributed cyberinfrastructure supportive of mobile-hosted apps for science and education (e.g. middleware for virtual networking, social collaboration, resource virtualization and virtual appliances for different domains). By studying the mobile application-induced workload at the lowest layers of the systems software stack, such as the VMM, the project will identify how these layers can be improved to better support such workloads.<br\/><br\/>The project will advance the fundamental understanding of multiple technical issues faced in enabling flexible end-to-end management of cloud-supported mobile applications. Methods are needed to (re)implement applications so that their software architectures can reconfigure in response to changes in requirements as the environment changes, and to allow for runtime re-factoring of components for execution locally or remotely. Virtual networking techniques are needed to enable seamless off-loading of computation from a device to remote resources possibly provided by multiple clouds. In addition, both software adaptation and network configuration must be done on demand.","title":"EAGER: Collaborative Research: Model-based Autonomic Cloud Computing Software Technology","awardID":"1265347","effectiveDate":"2013-08-01","expirationDate":"2015-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[540138],"PO":["564993"]},"205730":{"abstract":"This project focuses on an emerging challenge in computation: to extend programmatic control over matter and phenomenon at the nanoscale. Nanosystems making use of DNA-based reactions are a promising technique to achieve this since they are feasible to design, simulate and test experimentally. DNA computation systems of increasing complexity have been demonstrated over the past two decades. Most of these systems involve multiple strands of DNA that interact with each other via diffusion based hybridization chemistry. While this paradigm has many advantages and merits, there are fundamental limits to diffusion based DNA hybridization computations, particularly due the increased time for larger-scales of complexity. This work seeks to study an alternate paradigm of DNA hybridization-based computations that operate locally on a substrate. Locality allows reactions to proceed at higher speed due to increased local concentration of reacting species - this localization could potentially speed up DNA hybridization-based computations by an order of magnitude. Also, since each of the local reaction pathways do not interfere with each other, it is also possible to simultaneously execute multiple pathways in parallel. This also allows one to reuse DNA sequences in spatially separated regions that increase the modularity and scalability of the reactions. <br\/><br\/>Intellectual Merit: The research work spans both theory and experimental techniques, and includes development of biophysical mathematical models, design software, computational simulations, small-scale experimental demonstrations. In particular, the work will develop biophysical models of localized hybridization, which will be simulated, and also verified via simple kinetic experiments. The experiments provide crucial data about the rate constants involved in the hybridization chemistry of localized molecules. The simulation model will be further refined based on the experimental data,. A major challenge addressed as a center-piece of this effort is leaks: the unintended reactions that cause the nanosystem to significantly deviate from its programmed trajectory that might occur in localized hybridization systems. Multiple leak models will be tested in the lab via simple experiments. Continuing an on-going collaboration with Dr. Andrew Phillips (Microsoft Research Cambridge), funded internally by Microsoft, this work will also create software systems that will simulate localized hybridization networks. The simulation software development will be tightly coupled to the experimental progress by constantly refining the simulation models and parameters based on experimental data. Finally, this work will experimentally implement a series of small to moderate scale localized hybridization systems to demonstrate the feasibility and the potential of localized hybridization reactions. The work will also investigate the broader issues of the use of locality to speed-up other related molecular-scale computation processes, including reactions that make use of enzymes, or other protein-based reactions, in addition to DNA hybridization reactions. <br\/><br\/>Broader Impact: There is substantial multidisciplinary impact to nanoscience, biochemistry and chemistry, which will profit from the introduction of key methodologies derived from mainstream computer science, such as mathematical modeling, software engineering, algorithms and modular design methodologies. Educational impact includes cross-disciplinary training of four PhD students, carefully supervised mentoring and summer internships for undergraduates.","title":"SHF: Small: Localized DNA Hybridization Computation","awardID":"1320360","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7946","name":"BIO COMPUTING"}}],"PIcoPI":[550822],"PO":["565223"]},"204641":{"abstract":"Magnetic recording is the most widely used technology for reliably storing digital information. A stored bit is physically realized as a collection of tiny magnetic grains magnetized to one of two stable polarities. This project relies on a new paradigm of two-dimensional magnetic recording, which exploits a small number of grains to store one bit as well as two-dimensional coding of user data combined with signal detection to ensure reliable storage and retrieval of information.<br\/><br\/>The project addresses the main challenge in two-dimensional magnetic recording which arises due to the fact that grains are irregularly shaped and randomly positioned on the media surface, and hence, the signal read back is dominated by noise due to this random granularity of the medium. The project develops novel data recovery algorithms capable of compensating such high noise levels. These algorithms are based on advanced information theory and coding theory concepts, namely, constrained codes, probabilistic graphical models, and iterative detection and decoding. A two-dimensional constraint is viewed as a colored tiling of a plane, which affords using the rich theory of planar gas models from statistical mechanics and the theory of domino and lozenge tilings from combinatorics. On the detection front, the project develops generalized belief propagation and linear programming algorithms for dealing with the large number of loops in two-dimensional magnetic recording graphical models.<br\/><br\/>In light of the tremendous growth of the amount of digital data created, processed and stored, it is vitally important to ensure the continued rapid increases in capacity of magnetic hard disk drives. The project is concerned with a new technology that has the potential to increase hard drive capacity by an order of magnitude. Signal processing methods for improving storage capacity developed in this project have a crucial role in providing a foundation for development of future storage systems. They provide not only a new standard of performance in the area of data storage, but have a direct impact on the performance capabilities of a new generation of computers, data networks and services provided on the internet.","title":"Small CIF: Coding and Detection for Two-dimensional Magnetic Recording Systems","awardID":"1314147","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":[548044],"PO":["564924"]},"205741":{"abstract":"The project aims at quantifying a general network's inner potential for supporting various forms of security by achieving secret common randomness between pairs or groups of its nodes. Statistical and computational secrecy measures are being considered against a general passive adversary. Common-randomness-achieving protocols are classified into two groups: culture-building and crowd-shielding. The former achieves common randomness between nodes situated in close proximity of each other, from correlated observations of specific (natural or induced) network phenomena. The latter ties together the security of multiple communication links, to the point where an adversary can no longer isolate and attack a single link without attacking the group as a whole. The broad range of investigated protocols cover multiple topics, from multipath diversity to network tomography, from secure network coding to protocol coding, and from anonymous routing to the spread of epidemics. The protocols harvest network randomness from diverse sources like ciphertext blocks originating at various terminals, contention protocols (delay randomness) or network topology (in highly-dynamic, or ad-hoc networks).<br\/><br\/>Communication networks are naturally dynamic, inherently redundant, and largely unpredictable. While the former two features have long been recognized as a valuable resource for integrity, efficiency and confidentiality, network unpredictability is often regarded as an incommodity. This project shows how network randomness can be harvested, and, together with diversity, exploited to enhance communication security. In doing so, it develops a more profound understanding about the statistical nature of networks, which can be applied to a broad range of information-assurance objectives. The technical approaches and the general philosophy developed in this project, and disseminated through conferences and seminars, have the potential to inspire an abundance of related research. The project will directly impact dozens of students through Senior Design projects, a research-and-open-project approach to curriculum development, and three new graduate courses containing related topics. The PIs are actively involved in programs aimed at increasing the involvement of women, underrepresented minorities, and persons with disabilities in engineering and computing sciences.","title":"CIF: Small: Collaborative Research:Security in Dynamic Environments: Harvesting Network Randomness and Diversity","awardID":"1320428","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[550844],"PO":["564924"]},"205752":{"abstract":"Recreational activity is a fundamental aspect of human existence and an important part of the human condition within familial and social groups, where it serves to strengthen social ties by increasing affect between individuals and as a form of education in creative thinking. Despite a sizable accumulation of knowledge about such activity from sociology, anthropology, and psychology, \"play\" as a first-class concept has not been studied through the lens of computation. When today's agents engage with humans, they do so in the context of structured environments and are highly dependent on well-defined goals and\/or behaviors. Contrast this to the domain of pretend play, which involves non-goal directed peer-to-peer activity in a shared imaginary second reality that is continually altered. Pretend play is a common form of engagement that is relevant to an array of social domains, such as elder care, peer learning, or social skills therapy for children with autism spectrum disorders. The PI's goal in this research is to imbue robot systems with procedural and declarative representations of play so that they are capable of engaging in such activity with humans as peers. The work aims to discover how to develop humanoid robots with the ability to engage, improvise, and create with humans in unstructured environments. Such robot capability would foster perceptions of lifelikeness, social acceptance, and companionship similar to the experience of playing with other people. These agents would encourage spirited behaviors and creativity in people. They would elicit high levels of interest, intrinsic motivation, and positive affect, which in turn would lead to better concentration, learning, and personal investment by the human participant. To achieve these goals, the PI will leverage his prior work on creativity and cognition to conduct a study of adults engaging in object-based pretend play to elicit a formal understanding of it in dyads. The findings will subsequently be applied to building social robots that engage, based on the team's expertise in human-centered AI and human-robot interaction. The resulting robot architecture will be evaluated to see how it can enhance robot affect and social acceptance. <br\/><br\/>Broader Impacts: This research will create a new academic research direction of Computational Play within the field of social robotics that has the potential to contribute a solid and unique advance to the field, and also to change how we interact with intelligent agents thereby increasing agents' social value and acceptance by the humans around them. The work will increase via empirical study our understanding of human engagement, and in particular of the knowledge and social dynamics involved in pretend scenarios. The playful robots to be designed, implemented and formally evaluated in this work will inform the human-robot interaction community as to how such activity can be used within HRI contexts to increase affect. This work also has the potential of improving the learning and creativity of those that interact with social agents, making computational play a valuable research direction for education. The project will provide a fertile ground for interdisciplinary training of graduate and undergraduate students, and a wealth of interaction data that will be shared with the scientific community.","title":"HCC: Small: Social Agents and Robots for Open-Ended Domains","awardID":"1320520","effectiveDate":"2013-08-15","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[550868,550869,550870],"PO":["565227"]},"206853":{"abstract":"Mitochondria, the energy-generating organelles, form interconnected membrane-bound tubular networks within the cell. These mitochondrial networks undergo both fission and fusion dynamics as a result of which there may be many individual mitochondria or a single large network in the cell. The network dynamics are believed to contribute to maintaining mitochondrial function by segregating out damaged sub-regions of the network for turnover. Innovative image analysis methods will be used to accurately quantify the 3 dimensional topology and dynamics of the entire mitochondrial network of yeast cells. These data will be combined in an iterative process with computational modeling, genetic manipulations, and functional assays to advance fundamental understanding of how mitochondrial network topology, dynamics, and function are integrated by the cell. <br\/><br\/>Broader Impacts: Undergraduate students training to be STEM teachers will be integrated into the project and will learn how to develop and implement research-based lesson plans for K12 students. Opportunities for cross-disciplinary training in computation and biology will be provided by this project at undergraduate, graduate and postdoctoral levels.<br\/><br\/>This award is funded jointly by the Cellular Dynamics and Function Cluster of the Molecular and Cellular Biosciences Division and by the Mathematical Biology Program of the Division of Mathematical Sciences.","title":"Integrating Mitochondrial Network Topology, Dynamics, and Function","awardID":"1330451","effectiveDate":"2013-08-15","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"7275","name":"CROSS-EF ACTIVITIES"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0807","name":"Division of MOLECULAR AND CELLULAR BIOSCIE","abbr":"MCB"},"pgm":{"id":"1114","name":"Cellular Processes"}}],"PIcoPI":[553840],"PO":["565043"]},"205764":{"abstract":"More than 2.5 quintillion bytes of data are created daily in the form of sensor measurements, web posts and clicks, surveillance videos, purchase transactions, and health-care records. However, not all data collected is informative and not all features are relevant to the outcomes of interest. While several researchers have focused attention on compressive sampling for minimum error data reconstruction to improve data storage and acquisition, the objective of this research is broader and is focused on salient feature discovery. The key insight is sparsity, namely, that there is a tight coupling between a small relevant set of observations and the outcomes of interest. This research is focused on the sparse identification of the most relevant observations that are essential to predicting the outcomes.<br\/><br\/>The investigators will develop a new information-theoretic framework and algorithmic tools for understanding the intrinsic relationships and sparse interactions between outcomes of interest and a set of features\/observations in order to improve inferencing capabilities for enhanced decision-making in the context of this data-deluge. The goal is to discover the most relevant sparse subset of features that are essential to predicting the outcomes, and to uncover the fundamental limits of the associated sparse models. The approach is based on a unifying Shannon information-theoretic framework, whereby the problem of salient feature identification is mapped to a problem of capacity analysis for an equivalent channel model. This research addresses challenges posed by models with correlated features, models with missing features, models with latent variables, and the non-linearities of the measurement processes, in a unified way. Furthermore, this research involves the development of data-driven sparse recovery algorithms that reinforce the value of information when the underlying statistical models are partially or completely unknown. The investigators will use the developed methods to enhance the detection of sparse mixtures of explosives with fluorescence sensor arrays, and to identify high-degree hubs in computer networks using network tomography.","title":"CIF: Small: Collaborative Research: A Unifying Approach for Identification of Sparse Interactions in Large Datasets","awardID":"1320566","effectiveDate":"2013-08-15","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":["553668"],"PO":["564898"]},"204675":{"abstract":"In any design or learning activity, exploration is a key component. Significant research and conventional wisdom show that the best way to achieve a high-quality design is to explore multiple variations and iteratively evaluate them. When novices learn a new skill or system, they must explore and practice the available options. Similarly, when experts try to understand and improve an existing design, they must explore different approaches to modifying its behavior. Unfortunately, exploration is risky, error-prone, and cumbersome using today's tools. For instance, when users decide their current design is not effective, the only mechanisms available for selectively backtracking out of changes are linear undo and version control, which make it difficult to isolate backtracking to specific edits, or else users must manually remove undesired edits, which is slow and fallible. Further, today's tools do not support comparing two variants of a design or combining elements from multiple variants. Research is showing that these manual processes inhibit exploration, making users and designs less effective.<br\/><br\/>To address these problems PIs from four partner institutions have come together to undertake a research program that is both broad and deep, focusing on the creation and management of variations during a system's implementation and evolution. The goal is to discover new theories, algorithms, visualizations, and tools that support variations in code. The team will evaluate all of their approaches through lab and field studies, and they will investigate how users can be educated in more effective ways to work with variations. Based on a choice calculus for representing variations in software, they will develop a theory for formally defining and reasoning about variations. They will leverage theories of human behavior such as Minimalist Learning, Attention Investment, and Information Foraging, to develop a theory of Variation Foraging. They will develop an infrastructure including multiple levels of transcripts of users' editing operations that will support a novel form of selective undo and enable users to investigate their existing variants, return to any previous variant, and mix and match elements from multiple variants. They will develop algorithms to enable recording of interactions with variants so they can be explored and reused to explore and test new variants; these recordings will be augmented with automatically created data to help users understand behaviors they have not explicitly explored. Using this infrastructure the PIs will invent visualizations, search facilities, and interaction techniques that provide effective ways for users to find, understand, explore, reuse and create variants, and be able to ask \"why\" questions to understand the differences among variations of a system. For novices, an \"Idea Garden\" will help them explore new strategies for identifying which variations can help solve a problem and how to implement them.<br\/><br\/>Broader Impacts: This research will enhance infrastructure for research and education by producing an integrated, open source web development environment for use by researchers and the world. The work will therefore benefit society by empowering the tens of millions of end-user programmers to creatively build content and applications for the web. The PIs will advance discovery while promoting learning by integrating their research into undergraduate courses on creativity and software engineering, and by supporting summer camps for at least 300 high school students per year. Project outcomes will be disseminated to researchers through publications and presentations, to computing educators through the above-mentioned camps and the National Girls Collaborative Project, and through public deployment. The PIs expect high interest because the work will be based on JavaScript, which is today's most popular programming language and for which there is a high demand for better tools. The research will address underrepresentation via its focus on investigating how to support both male and female end-user programmers, by involving high-school members of underrepresented groups, and by engaging many of the PIs? female students.","title":"HCC: Large: Collaborative Research: Variations to Support Exploratory Programming","awardID":"1314356","effectiveDate":"2013-08-01","expirationDate":"2017-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[548127],"PO":["565227"]},"205654":{"abstract":"Thin-film transistors (TFTs) are one of the most important components of macro-electronic circuits used in various flexible electronic applications such as displays, large area sensors, radio frequency identification (RFID) tags, and antennas. In this context, Carbon Nanotube Thin-Film Transistors (CN-TFTs) are very promising for enhancing performance and expanding the range of operation of many flexible-electronic applications due to several reasons. However, some critical issues need to be addressed before CN-TFTs can be made available for commercial flexible electronic use. The objectives of this research are to: (a) analyze the effects of different coatings of CN-TFT substrates and self-heating on CN-TFT performance and reliability; and (b) design and analyze energy efficient and self-healing CN-TFT circuits and establish\/control the effects of statistical and morphological variability of transistors on circuit-level performance. A multi-scale modeling framework consisting of an atomistic model for Carbon Nanotube (CNT) junctions, electro-thermal transport model for CN-TFTs, and circuit models will be developed to enable this analysis. The multi-scale framework will facilitate the design of energy efficient, high performance, and reliable CN-TFT circuits and establish guidelines for significant decrease in the power consumption, hot spot temperature, and performance variations. <br\/><br\/>Efficient numerical methods developed for multi-scale electrical and thermal transport will boost the field of efficient computing and analysis of electronic devices. This program will develop education modules on power consumption, energy transport and heat dissipation in electronic devices and energy-efficient circuit design, which will enhance the undergraduate and graduate curriculum. Small demonstrations and hands-on sessions prepared by this program will motivate K-12 students for higher education.","title":"SHF: SMALL: Energy Efficient Self-Healing Design of Carbon Nanotube Thin Film Transistors","awardID":"1319935","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":[550643,550644],"PO":["562984"]},"208943":{"abstract":"Abstract: This project will design a \"Cloud Management System (CMS)\" that provides a uniform way to acquire and control a wide range of resources from compute to storage to network, and from the data center to the network edge but do so at multiple levels of abstraction. The project will create a data model (a set of abstract objects, operations on those objects, and relationships among objects) that collectively defines how users interact with the underlying research cloud. The CMS unifies the underlying cloud resource substrate and presents widely different classes of users with customized projections and extensions of those resources.<br\/><br\/>The project will demonstrate the feasibility of the CMS by addressing the biggest risk to its success: defining a set of abstractions-in the form of an operational data model-that both (a) unifies the research cloud?s diverse hardware resources, and (b) supports widely different usage models. These abstractions form the heart of the CMS, but they must satisfy two competing objectives. On the one hand, the CMS provides a unified interface to a widely diverse set of compute and network resources, spanning many autonomous hosting sites, each with their own operational policies. On the other hand, thousands of users want to access the system in significantly different ways, ranging from traditional cloud users that just want a set of VM instances, to cloud researchers that want to create new cloud architectures. <br\/><br\/>Cloud Computing is rapidly changing the face of computing infrastructure and is a major economic driver in the technology sector. This project will benefit the cloud computing industry by informing the design of future cloud computing infrastructure and contributing prototype implementations to the Openstack community.","title":"EAGER: Unifying Abstractions for OpenCloud -- Supporting a Diverse User Community.","awardID":"1343001","effectiveDate":"2013-08-01","expirationDate":"2015-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[560046],"PO":["564993"]},"205555":{"abstract":"With the rapid proliferation of wireless devices in the last decade, it has become increasingly important to efficiently utilize limited spectrum resources through close coordination of devices in the network. While several advanced techniques have been developed recently to address this problem, these techniques require an accurate and consistent view of the channel states as well as some degree of synchronization among the devices in the network to be effective. The research plan in this project is focused on developing an analytical framework and efficient techniques for channel state dissemination and network synchronization to enable close coordination of devices in a network and efficient utilization of the channel resources. The proposed research is based on the view that, in order to determine the best use of the spectral and temporal resources available to the network, channel state estimation and dissemination should be performed continuously as part of the normal network operation. By estimating and disseminating network channel state information continuously through existing network traffic, devices in the network can adaptively determine an appropriate network structure and mitigate the effects of interference to facilitate efficient communication under current and predicted channel states.<br\/><br\/>The foundational nature of the research plan makes it broadly applicable in a wide range of wireless communication systems such as cellular networks, wireless local area networks, vehicular networks, and emergency communication systems. The analytical framework and techniques for efficient channel state dissemination and network synchronization developed on this project will impact emerging wireless communication systems such as informed-transmitter multi-input multi-output (MIMO), cognitive radio, cooperative relaying, distributed transmission, and interference alignment. The proposed research will establish a solid theoretical foundation for understanding the limits of minimum-staleness channel state dissemination and clock synchronization in wireless networks and will also include experimental verification through testbed implementations of the channel state dissemination and network synchronization techniques.","title":"An Efficient Framework for Channel State Dissemination and Network Synchronization","awardID":"1319458","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":[550414,550415],"PO":["564924"]},"205797":{"abstract":"Until recently, a cost-effective way to make a program run faster was to buy a computer with a more recent processor, without making any changes to the program itself. However, in recent years this approach no longer works - instead of one ever-faster processor core, recent processors rely on increasing numbers of cores to provide better performance. To benefit from these new multi- and many-core processors, programs must be explicitly written to \"scale,\" i.e., to keep getting faster as they run on more cores. Re-design for scaling is time-consuming and costly, especially considering that most programmers are not used to (nor trained for) writing programs that use more than one core. This NSF-funded project will analyze scaling problems in programs and report them to programmers with enough accuracy to help rapidly deal with the problems. An important aspect of this approach is that it also helps educate current programmers and future ones (e.g., college students) to anticipate scaling problems and avoid them in the future. Additional outreach activities are planned in middle and high schools in Atlanta (where minority students are the majority of the population) to educate both students and their teachers about key concepts in computer hardware and software. <br\/><br\/>The main technical challenge in this project is that there are many types of scaling problems. Some scaling problems are related to the application itself, e.g., serial sections, lock contention, etc., and some are hardware-related, such as contention for interconnect bandwidth, serialization in directories, contention for capacity in shared caches, etc. The symptoms of these problems are often ambiguous, which makes them even more difficult for programmers to identify and correct. This project will provide hardware support for profiling that will help disambiguate some of the symptoms and attribute them to specific parts of the code, along with software tools that will analyze and report both software- and hardware-related scaling limiters. Our reporting will be specific enough to lead programmers directly to the code that should be \"fixed\" and help them understand why and how this code needs to be modified.","title":"SHF:Small: Hardware\/Software Support for Debugging of Scaling Limiters in Many-Core Execution","awardID":"1320717","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":[550974],"PO":["366560"]},"209933":{"abstract":"Statistical machine translation has been enormously successful over the last two decades, resulting in what is today a thriving industry highlighted by offerings such as Google Translate. Yet translation systems still often fail to preserve the semantics of sentences -- the \"who did what to whom\" relationships that they express. This is because they model translation as simple substitution and permutation of words, or at best as the reordering of syntactic units, such as nouns and adjectives. To preserve semantics, they must model semantics. At the same time, computational linguists have developed rigorous, expressive mathematical models of language that exhibit high empirical coverage of semantically annotated linguistic data, correctly predict a variety of important linguistic phenomena in many languages, and can be processed with highly efficient algorithms. However, these models are untested as the basis of statistical translation models. <br\/><br\/>This EArly Grant for Exploratory Research aims to close the gap, building the foundations of empirical semantics-preserving transduction models based on modern, linguistically-informed mathematical models of language. The project derives new mathematical functions that map linguistically expressive representations from one language to another, and implement them to align translated documents and translate new documents. Though high-risk, this exploratory project has the potential to unify and transform the disparate fields of empirical machine translation and theoretical computational linguistics.","title":"EAGER: Formal and Empirical Foundations of Semantics-Preserving Machine Translation","awardID":"1349902","effectiveDate":"2013-08-15","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[562774],"PO":["565215"]},"205599":{"abstract":"Software traceability serves a critical role in ensuring that software systems operate correctly. It is used to support a wide variety of software engineering activities such as change management, compliance verification, and safety analysis. Unfortunately current practices fall far short of delivering cost-effective traceability, primarily because creating and managing trace links in large and\/or complex systems is time-consuming, arduous, and error-prone. These problems were highlighted in a recent report entitled 'Critical Code: Software Producibility for Defense' commissioned by the Department of Defense. The report stressed the need for the research community to develop cost-effective and accurate traceability solutions. While state of the art tracing techniques offer significant promise for reducing the cost and effort of tracing, they fall short of meeting industrial needs primarily because the quality of the generated links is imprecise. This work will investigate ways to integrate techniques from feature modeling, product line development, artificial intelligence and machine learning to deliver a dynamically configurable trace infrastructure. The framework will then be used to investigate and integrate a broad set of novel tracing techniques which are expected to significantly improve the quality of generated trace links.<br\/><br\/>The results of the project will contribute towards the development of software intensive systems, especially safety-critical ones in which traceability is mandatory. Technology transfer will be facilitated by delivering solutions on the TraceLab platform, disseminated via the Center of Excellence for Software Traceability (CoEST.org) and through training materials targeted at industrial users. Ongoing research opportunities will be provided for a diverse group of undergraduate and graduate students, and pedagogical materials will be developed and made publicly available for use in a variety of courses on requirements engineering, software engineering and software architecture.","title":"SHF: Small: RUI: Generating High Quality Trace Links through Intelligent Composition of Tracing Features","awardID":"1319680","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[550521],"PO":["564388"]},"209548":{"abstract":"Large scale Internet testbeds such as PlanetLab and GENI are widely used by the academic community. Unfortunately, wireless infrastructure to support wireless networking systems research is not as prevalent. Projects such as Orbit and GENI\/WiMAX provide a valuable service framework, but these wireless testbeds are limited in scale in terms of geographic footprint as well as in terms of diversity of radio access and device technology. Not only the networking community but also application domain specific research communities such as environmental sensing and intelligent transportation systems require wireless cyberinfrastructure. Currently the effort required to design and deploy wireless infrastructure to support such research 'in the wild' imposes a significant burden on projects.<br\/><br\/>The proposed project builds and trials a nationwide wireless network that supports the academic research community called the network the Science Wireless Network or SciWiNet. SciWiNet is based on a Mobile Virtual Network Operator (MVNO) model: SciWiNet (a collaboration between Clemson University and Rutgers University) represents the Service Operator; the operator of the NVMO infrastructure represents the Carrier of Record and FCC license holder; the Wireless Network Operator (WNO)owns the underlying spectrum and network infrastructure. The underlying infrastructure is not under investigation. Instead, this project is developing and evaluating a possible service framework that can support a broad set of academic researchers and which can integrate campus-provided wireless infrastructure. More specifically, the objectives of this project are to: <br\/>1. Evaluate the efficacy of an MVNO model to provide a wireless testbed for the academic research community; <br\/>2. Integrate and build upon innovations and resources made available from the GENI community; <br\/>3. Develop appropriate support for the community of SciWiNet users that are from outside the networking research community; <br\/>4. Identify viable paths by which SciWiNet can evolve to become a self-sustaining, national resource.<br\/><br\/>This project will enable research that currently not feasible because of the limited coverage of existing GENI\/WiMax base stations, including research in areas such as eHealth, intelligent transportation systems, smart buildings and structures, homeland security, and Internet of Things. It is expected that the combination of campus provided wireless access and the NVMO will facilitate development and deployment of new applications and will be instrumental in educating students to consider the combination of theory and practice in complex heterogeneous wireless systems.","title":"EAGER: Collaborative Research: SciWiNet: a Science Wireless Network for the Research Community","awardID":"1346632","effectiveDate":"2013-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["24532",561722],"PO":["564993"]},"210593":{"abstract":"Scientists and Engineers often struggle to deduce the state or structure of a system from partial, noisy measurements. The corresponding problems are ill-posed because there are fewer measurements available than the number of parameters they would like to estimate. In practice, however, many interesting signals or models contain considerably fewer degrees than the apparent number of parameters: a small number of genes may constitute the signature of a disease, very few parameters may specify the correlation structure of a time series, or a sparse collection of geometric constraints may determine a molecular configuration. Discovering, leveraging, or recognizing such low-dimensional structure plays an important role in posing inverse problems well.<br\/><br\/>This project pursues a unified approach to transform notions of simplicity and latent low-dimensionality into convex penalty functions. The investigators focus on a theoretically sound suite of data analysis algorithms designed to decompose complex signals into sums of a small number of simple atoms. The work first catalogs the objects and structures that can be recovered from a small number of measurements using atomic decomposition algorithms, in order to show that many structures of significant scientific and technological interest need only be probed a few times to extract complete and accurate knowledge. Second, the project explores a range of practically useful implementations of atomic decomposition algorithms for data recovery, enabling efficient solutions of large-scale problems with guaranteed success. Finally, practical implementation in a diverse set of applications, including web-scale data analysis, high-throughput biology, and experimental physics, continually motivate and refine this mathematical research program.","title":"CAREER: Efficient Atomic Decompositions of Massive Data Sets","awardID":"1359814","effectiveDate":"2013-08-01","expirationDate":"2017-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[564275],"PO":["564898"]},"204763":{"abstract":"Many simulation algorithms depend on an underlying spatial discretization---a mesh that decomposes the domain into a finite set of elements that can be analyzed by a computer. The quality of the simulation is, in part, determined by the quality of the mesh. However, in the past, mesh generation and simulation were done as separate processes. Better results can be achieved by tightly integrating simulation with mesh generation and recent advices in computational topology provide the key to doing so. Computational topology allows for the analysis of the structure of data---in this case simulation variables. By understanding the structure of the simulation the mesh generation algorithms can adapt to it, providing meshes that are closely linked to the actual simulation.<br\/><br\/>Because simulation is a powerful tool for discovery throughout computational science, this research has the potential to have broad impact across all fields of science and enable new scientific breakthroughs that could have tremendous societal impact. This research will also produce open-source software, short courses, and workshops around the topic of coupling simulation and meshing. The interdisciplinary nature of this project will lead to a rich educational and research environment for graduate and undergraduate students. The project web site provides access to research results, software and educational materials (http:\/\/sealab.cs.utah.edu\/SimulationMeshingTopology).","title":"CGV: Large: Collaborative Research: Coupling Simulation and Mesh Generation using Computational Topology","awardID":"1314896","effectiveDate":"2013-08-01","expirationDate":"2017-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[548347,548348],"PO":["563751"]},"205511":{"abstract":"The security of critical information infrastructures depends upon effective techniques to detect vulnerabilities commonly exploited by malicious attacks. Due to poor coding practices or human error, a known vulnerability discovered and patched in one code location may often exist in many other unpatched code locations, either in the same code base or other code bases. Furthermore, patches are often error-prone, resulting in new vulnerabilities. This project develops practical techniques for detecting code-level similarity to prevent such vulnerabilities. It has the potential to help build a more reliable and secure information system infrastructure, which will have tremendous economical impact on society because of our growing reliance on information technologies.<br\/><br\/>In particular, the project aims to develop practical techniques for similarity-based testing and analysis to detect unpatched vulnerable code and validate patches to the detected vulnerable code at both the source code and binary levels. To this end, it focuses on three main technical directions: (1) developing techniques for detecting source-level vulnerabilities by adapting and refining an industrial-strength tool, (2) developing capabilities of detecting binary-level vulnerabilities by extending preliminary work on detecting code clones in binaries, and (3) supporting patch validation and repair by developing methodologies and techniques to validate software patches and help produce correct, secure patches. This project helps discover new techniques for source- and binary-level vulnerability analysis and gain better understandings of the fundamental and practical challenges for building highly secure and reliable software.","title":"TWC: Small: Collaborative: Similary-Based Program Analyses for Eliminating Vulnerabilities","awardID":"1319187","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["562712"],"PO":["564388"]},"202256":{"abstract":"The classical approach to wireless communication is to isolate communication links by maximizing signal strength and minimizing interference between users. This simple philosophy is supported by a rich theoretical foundation which has inspired powerful coding techniques and protocols that lie at the heart of modern wireless systems. However, these systems have recently become victims of their own success as the rising density and data requirements of wireless devices have led to a surge in interference. Fortunately, an emerging body of work indicates that the phenomenon of interference may in fact represent an untapped opportunity for increasing the spectral and energy efficiency of next-generation wireless systems. Although many interference-aware communication strategies have been proposed in the literature, the promised gains have been mostly limited to the theoretical realm. <br\/><br\/>The objective of this project is to create practical interference-aware wireless protocols that can operate near the performance predicted by theoretical bounds in terms of throughput, energy efficiency, and reliability. The project is organized into three complementary thrusts that encompass theory, algorithms, and practice. The first thrust investigates lattice-based constellations and low-complexity codes for the compute-and-forward strategy, which enables receivers to decode linear combinations of transmitted codewords. Compute-and-forward can in turn be used as a building block for realizing interference-aware protocols such as physical-layer network coding and multiple-user MIMO (multi-input-uulti-output) systems. The second thrust aims to implement these protocols on a three-node WARP (Wireless Open-Access Research Platform) testbed. A series of carefully designed experiments will be used to compare the performance of interference-aware strategies while accounting for overhead costs. The third thrust leverages the data collected from these experiments to revise channel models to capture key features that impact the performance of interference-aware strategies such as asynchronism and channel fluctuations. These models will be used to revisit the theoretical foundations of interference-aware strategies and tailor them to the channels encountered in practice. This project features several outreach efforts including undergraduate research experiences connected to the WARP testbed and a public repository of training modules and videos.","title":"CIF: Medium: Collaborative Research: Interference-Aware Cooperation via Structured Codes: Creating an Empirical Cycle","awardID":"1302600","effectiveDate":"2013-08-01","expirationDate":"2017-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["550997"],"PO":["564924"]},"205655":{"abstract":"This Cyberlearning: Transforming Education Exploration Project is designed to advance understanding of how to personalize feedback and advice to learners as they engage in exploratory and creative activities in constructionist technology-enhanced learning environments. During such activities, learners often engage in programming (using, e.g., Scratch, Alice) with the goal of creating a model or an animation of their own choosing. Assessment of learner capabilities and conceptions would allow automated personalization of advice to learners, facilitate self-reflection, and help teachers or mentors to know the range of capabilities and understanding across a classroom. This project brings together a PI who is expert at promoting learning in the context of constructionist learning activities and another who is expert at educational data mining to identify indicators of young learners' (middle schoolers) conceptions of computational concepts and programming capabilities. The project uses a data analytic approach; data mining methods are used to mine the thousands of operations learners carry out to find patterns that might indicate understanding and capability, qualitative methods are used to analyze what learners were intending and thinking as they were carrying out those operations, patterns are identified in the observational data, and the two streams of data are matched to identify the ways conceptions and capabilities show themselves while learners are programming. The intellectual activity focuses both on the combination of data mining and ethnographic methods for such purposes and on the specifics of those indicators.<br\/><br\/>Automating assessment is difficult in a project-based learning environment where learners are creating products of their own choosing. Because the activity is quite unconstrained, collecting and analyzing the data necessary for providing help and feedback to the learner is quite difficult. This project uses a combination data analytic and ethnographic approach to find indicators of the conceptions and capabilities of middle schoolers as they are using Scratch to create models and animations of their choosing. The results of this project will make contributions in several areas: (i) advancing methods for automating assessment for learners using the Scratch programming language, (ii) advancing methods for data collection and analysis for personalizing feedback in a relatively open-ended programming environment (iii) broadening understanding of how to assess computational thinking in the context of open-ended programming assignments, and (iv) advancing methodology for automatically assessing capabilities and understanding when learners are engaged in open-ended kinds of assignments.","title":"EXP: Macro Data for Micro Learning: Developing FUN! for Automated Assessment of Computational Thinking in Scratch","awardID":"1319938","effectiveDate":"2013-08-15","expirationDate":"2015-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7645","name":"DISCOVERY RESEARCH K-12"}}],"PIcoPI":["557596",550647],"PO":["562669"]},"205776":{"abstract":"Big data leads to big challenges, not only in the volume of data but also in its dynamics and variety. Multiple descriptions about the same set of objects or events from different sources unavoidably lead to data or information inconsistency. Then, among conflicting pieces of data or information, it is crucial to tell which data source is reliable or which piece of information is correct. Accurate information is referred to as the truth and the chance of a source providing accurate information is denoted as source reliability or trustworthiness. The objective of this project is to detect truths without supervision, by integrating source reliability estimation and truth finding. A unified framework is developed to model complex trustworthiness factors, heterogeneous data types, incremental and parallel computation, and source and data dependencies so that truth and trustworthiness can be inferred from multiple conflicting sources of heterogeneous, disparate, correlated, gigantic, scattered, and streaming data.<br\/><br\/>This project makes tangible contributions to data integration, information understanding and decision making, and benefits many applications where critical decisions have to be made based on the correct information extracted from diverse sources. Research results of this project are integrated into course materials and projects, and into training students and new generation researchers, especially female and minority students. For further information about this project, please refer to the project website: http:\/\/www.cse.buffalo.edu\/~jing\/truth.htm","title":"III: Small: Collaborative Research: Conflicts to Harmony: Integrating Massive Data by Trustworthiness Estimation and Truth Discovery","awardID":"1320617","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["563535"],"PO":["565136"]},"205677":{"abstract":"The goal of this project is to develop a new binaural model to separate sounds in complex environments. The new aspect of the model is that it can utilize head movements to improve its localization performance by analyzing dynamic localization cues and combining these with information about its own head position. In addition, the model uses a dual approach to eliminate the influence of room reflections on sound source localization and segregation. In the first stage, specular reflections are eliminated using an autocorrelation- based algorithm. In the second stage, diffuse reverberation is removed by measuring interaural cross correlation across time\/frequency bins, knowing that these values decrease with decreasing direct-to- reverberant energy ratio. The model development is accompanied by a behavioral study to better understand the underlying principles of how humans can perform robustly in complex scenarios. The results are also used as a benchmark test for the model algorithms.<br\/><br\/>This project intends to bridge the gap that exists between fundamentally knowing how the auditory system processes binaural tasks for simple multiple-sound-source scenarios, and understanding and modeling how it performs when the environment reaches real-life complexity. The resulting model is expected to operate in real time to localize sound sources in robot or surveillance applications or serve as a front end for sound- source separation algorithms, speech recognizers, predictors for acoustical quality of rooms, and Computational Auditory Scene Analysis (CASA) models.","title":"RI: Small: Binaural Sound Source Separation Robust to Listener Head Movements","awardID":"1320059","effectiveDate":"2013-08-01","expirationDate":"2015-07-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"7252","name":"PERCEPTION, ACTION & COGNITION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[550695],"PO":["565215"]},"205688":{"abstract":"Nowadays, graphics processing units (GPUs) have been widely adopted for general-purpose computing, and are known as GPGPUs. However, current and future GPGPUs confront power and energy as the dominant constraints. The number of transistors integrated on a single GPU chip continues to increase due to shrinking feature size and the demand for massively parallel computing cores to increase throughput. On the other hand, the continuous decrease of transistor supply voltage at each new technology node has largely stalled because of leakage constraints, leading to an ever-increasing power density. Therefore, future GPGPUs must become more inherently energy efficient to avoid hitting the power wall. <br\/><br\/>To meet the increasing demands on performance and energy-efficiency, emerging technologies such as non-volatile memory, inter-bank tunneling field effect transistors (TFETs), silicon nanophotonics, and three-dimensional (3D) integration are being deployed in hardware design and promise realization of power efficiency at a scale never expected before. The investigators are exploring a synergetic program to holistically and hierarchically improve the GPGPU's energy efficiency through emerging technology integration. The project objectives include (1) non-volatile memory in the GPU computing cores and low-power mechanisms to substantially reduce leakage and dynamic power consumption; (2) a hybrid TFET-CMOS (complementary metal-oxide semiconductor) methodology to effectively address the energy challenge at both intra- and inter-core levels; (3) a novel 3D-stacked throughput architecture based on silicon-nanophotonics technology to improve memory access performance yet reduce power consumption; (4) integration of the key research innovations and cross-technology optimizations to fully explore the potential of GPGPU design enabled by these emerging technologies. The proposed research will facilitate GPGPUs staying on track with deep sub-micron scaling and meeting the increasing demand for high-performance computing, and will hence benefit numerous real-life applications. This project will also contribute to society through engaging high-school and undergraduate students from minority-serving institutions in research, attracting women and other under-represented groups into graduate education, expanding the computer engineering curriculum with GPGPU power modeling and optimization techniques, disseminating research infrastructure for education and training, and collaborating with the GPU R&D industry.","title":"SHF: Small: Collaborative Research: Exploring Energy-Efficient GPGPUs Through Emerging Technology Integration","awardID":"1320100","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1675","name":"NANOSCALE: SCIENCE & ENGIN CTR"}}],"PIcoPI":[550720],"PO":["366560"]},"205589":{"abstract":"This research will advance a novel technological approach that relies on machine learning techniques in general and Natural Language Processing (NLP) in particular to develop models and support for creativity during collaborative science, technology, engineering, and mathematics (STEM) educational activities. We will extend existing educational software with NLP capabilities to automatically assess and subsequently support creativity during collaborative tasks. The research questions are: (1) Which factors influence moment-by-moment creativity during collaborative problem solving activities? (2) How can NLP be used to build student models that detect those factors? (3) How can an ITS use this information to create personalized interventions to support creativity?<br\/><br\/>The first phase in this research will collect data from students solving problems in pairs with an educational application to identify factors that are relevant to creativity processes and outcomes. These data will be used to derive computational student models for automatically assessing student creativity in terms of both moment-to-moment processes and outcomes through machine learning methodologies focusing on an NLP approach. In addition to providing automatic assessment, the models will also inform factors that influence creativity during collaboration through educational data mining techniques. The final phase of the work will design and test a set of interventions to foster creativity during collaborative activities.<br\/><br\/>Using data corresponding to pairs of students solving open-ended STEM-based problems, this research will develop a rich and nuanced understanding of creativity processes and outcomes in collaborative contexts, and how these relate to knowledge, affect and creative thinking styles. Relying on that understanding, it will develop and evaluate novel student models that recognize salient, creativity-related events through NLP techniques, as well as personalized support for creativity during collaborative activities and evaluating that support through an experiment with university students. This project will pave the way for a new class of collaborative cyberlearning technologies to both assess and foster creativity, through just-in-time personalized support based on easily deployed NLP-based student models.","title":"HCC: Small: Modeling and Supporting Creativity During Collaborative STEM Activities","awardID":"1319645","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[550495,"552861","552862"],"PO":["564456"]},"205358":{"abstract":"Social networking services have been transformed from one-stop websites, to social interaction platforms deeply integrated with third-party websites, applications, and even operating systems. As prominent examples, social plugins such as Facebook's Like and Google's +1 buttons enable websites to offer personalized content and allow their visitors to seamlessly share and interact with their social circles, while Facebook and Twitter support is already integrated in iOS 6. These social features offer multifaceted benefits to both users and content providers, and have driven their widespread adoption across the web and the mobile application ecosystem. However, this increasing integration has raised concerns about the implications of these social features to user privacy, as they enable social networking services to track a growing part of their members' activity, including their browsing histories, locations, and communications.<br\/><br\/>The research in this project seeks to address these privacy concerns by exploring a novel design for privacy-preserving virtual private social networks, which fulfills two seemingly contradicting requirements: it protects user privacy by minimizing the transmission of user-identifying information to the social networking platform, while preserving all existing functionality by delivering the same personalized content. The main insight of this approach is to shift content personalization from a server-side to a client-side process, by decoupling the retrieval of potentially sensitive social information from the presentation of personalized content that uses that information. The PIs are developing a personalized \"information overlay\" that prefetches information from a user's social circle independently of third-party accesses, and keeps this information consistent across the user's devices. The outcomes of this research effort are expected to significantly improve the privacy of members of social networking services, without degrading the current personalization experience to which they have grown accustomed.","title":"TWC: Small: Virtual Private Social Networks","awardID":"1318415","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[549898],"PO":["562974"]},"209868":{"abstract":"This project will support a two-day workshop entitled \"The Social, Economic and Workforce Implications of Big Data Analysis and Decision-Making\" to be held in January 2014. Big Data, the analysis and application of very large datasets, is an important new area of computer science research that has given rise to a number of new journals, conferences and funding opportunities as well as great interest in practice. Public and private sectors organizations of all kinds, including the National Science Foundation, are making huge investments in Big Data in the well-justified belief that innovations in data analytics can bring enormous benefits in such areas as public health and safety, economic competitiveness and consumer welfare. At the same time, history makes clear that innovations do not always realize their intended benefits and that they sometimes have negative (in addition to positive) unintended consequences. <br\/><br\/>The goal of the workshop is to develop an agenda for research on the Social, Economic and Workforce consequences of Big Data to mobilize research momentum in this important area.<br\/><br\/>The workshop will bring together policy makers and subject matter experts representing a range of relevant disciplines and perspectives, including computer science, economics, social sciences, and philosophy. The workshop will be organized as plenary and breakout sessions, organized around four major themes: 1) consequences for citizens and social life (e.g., democratic participation and interpersonal interaction), 2) consequences for employment and economic opportunity (e.g., job availability and quality and access to credit and investment opportunities), 3) consequences for science and innovation (e.g., scientific practices and rewards and the structure of R&D), and 4) consequences for critical infrastructure (e.g., public health and safety and financial system stability). <br\/><br\/>Intellectual Merit: The workshop will advance computer science and engineering by developing an agenda for systemic research to document emerging consequences and to anticipate plausible future consequences of Big Data. The science of the social, economic, and workforce consequences of revolutionary technological innovations like Big Data is challenging for at least two reasons. First, it is inherently interdisciplinary. Second, to be useful, such a science must be anticipatory as well as post-hoc, but criteria and approaches for evaluating forward-looking research are still nacent. <br\/><br\/>Broader Impacts: Big data is growing in importance for many areas critical to society, including health, finance and science. However, current research is focused primarily on the underlying technology, leaving the societal, economic and workforce impacts largely unexamined. The outputs of this workshop will help researchers identify the key issues in understanding these impacts and articulate possible approaches for future research.","title":"Big Data, Big Decisions: A Workshop for a Research Agenda on the Social, Economic and Workforce Implications of Big Data","awardID":"1348929","effectiveDate":"2013-08-15","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[562605],"PO":["565342"]},"209549":{"abstract":"Large scale Internet testbeds such as PlanetLab and GENI are widely used by the academic community. Unfortunately, wireless infrastructure to support wireless networking systems research is not as prevalent. Projects such as Orbit and GENI\/WiMAX provide a valuable service framework, but these wireless testbeds are limited in scale in terms of geographic footprint as well as in terms of diversity of radio access and device technology. Not only the networking community but also application domain specific research communities such as environmental sensing and intelligent transportation systems require wireless cyberinfrastructure. Currently the effort required to design and deploy wireless infrastructure to support such research 'in the wild' imposes a significant burden on projects.<br\/><br\/>The proposed project builds and trials a nationwide wireless network that supports the academic research community called the network the Science Wireless Network or SciWiNet. SciWiNet is based on a Mobile Virtual Network Operator (MVNO) model: SciWiNet (a collaboration between Clemson University and Rutgers University) represents the Service Operator; the operator of the NVMO infrastructure represents the Carrier of Record and FCC license holder; the Wireless Network Operator (WNO)owns the underlying spectrum and network infrastructure. The underlying infrastructure is not under investigation. Instead, this project is developing and evaluating a possible service framework that can support a broad set of academic researchers and which can integrate campus-provided wireless infrastructure. More specifically, the objectives of this project are to: <br\/>1. Evaluate the efficacy of an MVNO model to provide a wireless testbed for the academic research community; <br\/>2. Integrate and build upon innovations and resources made available from the GENI community; <br\/>3. Develop appropriate support for the community of SciWiNet users that are from outside the networking research community; <br\/>4. Identify viable paths by which SciWiNet can evolve to become a self-sustaining, national resource.<br\/><br\/>This project will enable research that currently not feasible because of the limited coverage of existing GENI\/WiMax base stations, including research in areas such as eHealth, intelligent transportation systems, smart buildings and structures, homeland security, and<br\/>Internet of Things. It is expected that the combination of campus provided wireless access and the NVMO will facilitate development and deployment of new applications and will be instrumental in educating students to consider the combination of theory and practice in complex heterogeneous wireless systems.","title":"EAGER: Collaborative Research: SciWiNet: a Science Wireless Network for the Research Community","awardID":"1346633","effectiveDate":"2013-08-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["564745"],"PO":["564993"]},"199286":{"abstract":"Intellectual Merit:<br\/><br\/>This project addresses Cloud Computing.<br\/><br\/>To ensure that cloud users are comfortable with running their critical applications on shared infrastructures and that cloud providers can support economical performance-based service-level agreements, there is an increasingly urgent need for virtualized systems to deliver performance guarantees. And, as virtualization and cloud computing become pervasive, it is also important that these topics are taught in a systematic manner; especially to minority students served by this PI's university. In order to address these challenges, this NSF CAREER project is creating a coordinated resource management framework that optimizes the allocations of cloud computing and storage resources according to application-desired Quality of Service (QoS). <br\/><br\/>Specifically, this project is accomplishing its objectives through the following three research and education components: 1) A QoS-driven virtual machine resource management framework that can coordinate the allocations of various computing and storage resources and optimize them according to the virtualized applications; 2) QoS-driven distributed virtual machine storage management that allows the allocation of shared cloud storage resources, including the emerging solid-state-drive-based virtual machine storage and caching, according to application QoS needs; 3) Systematic education on virtualization and cloud computing that harnesses the research outcomes to provide training in virtualization and cloud computing, including new education activities for graduate, undergraduate, and K-12 students, as well as a new virtual-machine-based online education system to facilitate these activities.<br\/><br\/>This project's research outcomes will enable virtualized systems to support performance guarantees for modern applications with dynamic and complex behaviors. As a result, a broader range of applications with different QoS requirements will benefit from cloud computing, and cloud services will be able to offer their users more economical QoS-based charging models instead of the currently used resource-capacity-based models. This project's education outcomes will enable systematic education on virtualization and cloud computing from K-12 to undergraduate and graduate classrooms and prepare a pipeline of students who are equipped with the necessary knowledge and skills in these emerging technologies and prepared to contribute in the coming cloud computing era.","title":"CAREER: Coordinated QoS-Driven Management of Cloud Computing and Storage Resources","awardID":"1253944","effectiveDate":"2013-08-01","expirationDate":"2018-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[534488],"PO":["551712"]},"210242":{"abstract":"The 13th ACM SIGCOMM Internet Measurement Conference (IMC), sponsored by ACM SIGCOMM and ACM SIGMETRICS, in cooperation with USENIX, is to be held in Barcelona, Spain, October 23-25, 2013. Funding will assist approximately 7-8 graduate students from US institutions who attend this conference. IMC is the primary venue for presenting new research results on collecting and analyzing measurements of the Internet. Attending conferences such as IMC is of paramount importance for graduate students pursuing research in the field. Authors have the opportunity to present their work and all attendees have a chance to interact with many others performing leading-edge research in the field. <br\/><br\/>Intellectual Merit: This proposal will serve to widen the audience attending the Internet Measurement Conference (IMC), raising the level of interaction and the potential for new collaboration, new investigations, and higher quality research. Given the rising cost of international travel, the grant will enable students (who otherwise do not have sufficient funds) to attend the conference in Germany. <br\/><br\/>Broader Impacts: This proposal, by enabling students to attend who might not otherwise be able, will increase the dissemination of the conference?s research results to a larger and more diverse audience. It also integrates research and education of graduate students by allowing students to observe high-quality presentations and interact with senior researchers in the field. By giving preference in grant awards to women and minority students, we hope to widen the participation among these underrepresented groups. Furthermore, by advertising to a wide range of colleges and universities, participants from a more diverse set of institutions should be able to attend and benefit from the conference.","title":"Student Travel Support for the 2013 Internet Measurement Conference","awardID":"1353609","effectiveDate":"2013-08-15","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[563433],"PO":["565090"]},"204731":{"abstract":"Ever-larger data centers are powering the cloud computing revolution, but the scale of these installations is currently limited by the ability to provide sufficient internal network connectivity. Delivering scalable packet-switched interconnects that can support the continually increasing data rates required between literally hundreds of thousands of servers is an extremely challenging problem that is only getting harder. This project leverages microsecond optical circuit-switch technology to develop a hybrid switching paradigm that spans the gap between traditional circuit switching and full-fledged packet switching, achieving a level of performance and scale not previously attainable. This will result in a hybrid switch whose optical switching capacity is orders of magnitude larger than the electrical packet switch, yet whose performance from an end-to-end perspective is largely indistinguishable from a giant (electrical) packet switch.<br\/><br\/>The research provides a quantitative baseline for hybrid network design across a wide range of present and future technologies. The project will consist of five parts: i) traffic characterization to identify the class of network traffic that a circuit switch can support as well as the partitioning of the traffic between the circuit and packet portions of the network; ii) circuit scheduling to enable the circuit switch to rapidly multiplex a set of circuits across a large set of data center traffic flows; iii) traffic conditioning to reduce the variability of traffic at the end hosts, easing the demands placed on switch scheduling; iv) a prototype hybrid network that can use an optical circuit switch that operates three orders of magnitude faster than existing solutions; and v) a trend analysis to understand the tradeoffs resulting from potential future technology advances.<br\/><br\/>The work stands to dramatically improve data center networks, significantly reducing operating costs and increasing energy efficiency. The research material will be incorporated into courses, helping to train the next generation of computer networking scientists and engineers. The PIs will also continue ongoing outreach to high school students, both through the UCSD COSMOS summer program and through talks delivered at local high schools.","title":"NeTS: Large: Collaborative Research: HCPN: Hybrid Circuit\/Packet Networking","awardID":"1314721","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[548263],"PO":["564993"]},"205721":{"abstract":"With the spread of Internet and mobile devices, transferring information safely and securely has become more important than ever. The hardware and software systems utilized in such applications, e.g. cryptography, perform arithmetic computations over Galois fields. The specialized nature and the high complexity of the hardware architectures require manual, custom design, which raises the potential for errors\/bugs in the design implementation. Hardware bugs in arithmetic circuits not only cause unintended operation, but they also make cryptosystems vulnerable to security attacks. Validating the correctness of, and bug-catching in, arithmetic hardware is imperative. This project investigates the use of modern Symbolic Computer Algebra techniques for formal verification of Galois field arithmetic circuits. <br\/><br\/>Verification of cyber-security is a problem of great importance, and it is attracting a lot of research at the software-level. However, hardware verification of primitive Galois field computations in crypto-systems has not seen much breakthrough. The main reason for this is that the arithmetic circuit architectures employed in cryptography are very complex and their size is extremely large. Conventional verification techniques are unable to scale with respect to the large size. To address these problems, the project aims to integrate computer algebra with circuit analysis techniques for verification. By exploiting the circuit design information, the project will attempt to overcome the complexity of symbolic computation. This research enables design of domain-specific computer-aided verification tools for efficient, scalable verification of Galois field circuits. The project impacts computer-aided verification technology, secure system-design and validation, and it advances fundamental knowledge in both computer algebra and design verification of arithmetic circuits. Enabling the validation of security and privacy of data also, in general, impacts the society.","title":"SHF: Small: Collaborative Proposal: Efficient Computer Algebra Techniques for Scalable Verification of Galois Field Arithmetic Circuits","awardID":"1320335","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":[550799],"PO":["562984"]},"202212":{"abstract":"Scientific research is increasingly reliant on advanced social and technical infrastructures called cyberinfrastructure (CI). In turn, the cornerstone of scientific cyberinfrastructure is Scientific Cyberinfrastructure Software (SCIS) that enables data collection from digital instruments, analysis of data through the execution of mathematical algorithms, data visualization and sharing of data through standardized file formats and widely accessible databases. Despite the importance of SCIS for data-intensive research, too little is known about how scientists actually use, adopt and develop scientific software. More research is needed to explore how software, software development and software sharing practices are, and can be, community products, resources or practices. <br\/><br\/>This research project will examine how scientists develop SCIS as part of their day-to-day research practice through a qualitative, ethnographic study of 6 research groups using observations, semi-structured interviews, and document analysis. The researchers will investigate how decisions about SCIS are made; document, classify and analyze actual practices for using, adopting, developing or sharing software; identify scientists' incentives and disincentives to share software at the local, organizational and community levels; and discern the impacts, intentional and unintentional, that SCIS systems have on scientific data and the scientific research process.<br\/><br\/>Understanding SCIS development and sharing is necessary to ensure continued integrity of datasets shared within and among communities, facilitate the sharing of the tools and practices that are developed using national research funds and most importantly, support a fundamental tenet of scientific research: the open communication of the processes and practices behind published research findings. Furthermore, understanding these practices will support the education and training of our nation's future generations of scientists and engineers. This project will thus benefit domain scientists, SCIS developers, Computer Supported Cooperative Work (CSCW) and Software Engineering (SE) scholars and policy makers by providing conceptual tools that will provide guidance when considering how and when software can be designed and supported to be accessible and useful to the broader research community.","title":"HCC: Medium: Scientists and their Software: A Sociotechnical Investigation of Scientific Software Development and Sharing","awardID":"1302272","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7642","name":"VIRTUAL ORGANIZATIONS"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["335186"],"PO":["565342"]},"205732":{"abstract":"With the spread of Internet and mobile devices, transferring information safely and securely has become more important than ever. The hardware and software systems utilized in such applications, e.g. cryptography, perform arithmetic computations over Galois fields. The specialized nature and the high complexity of the hardware architectures require manual, custom design, which raises the potential for errors\/bugs in the design implementation. Hardware bugs in arithmetic circuits not only cause unintended operation, but they also make cryptosystems vulnerable to security attacks. Validating the correctness of, and bug-catching in, arithmetic hardware is imperative. This project investigates the use of modern Symbolic Computer Algebra techniques for formal verification of Galois field arithmetic circuits. <br\/><br\/>Verification of cyber-security is a problem of great importance, and it is attracting a lot of research at the software-level. However, hardware verification of primitive Galois field computations in crypto-systems has not seen much breakthrough. The main reason for this is that the arithmetic circuit architectures employed in cryptography are very complex and their size is extremely large. Conventional verification techniques are unable to scale with respect to the large size. To address these problems, the project aims to integrate computer algebra with circuit analysis techniques for verification. By exploiting the circuit design information, the project will attempt to overcome the complexity of symbolic computation. This research enables design of domain-specific computer-aided verification tools for efficient, scalable verification of Galois field circuits. The project impacts computer-aided verification technology, secure system-design and validation, and it advances fundamental knowledge in both computer algebra and design verification of arithmetic circuits. Enabling the validation of security and privacy of data also, in general, impacts the society.","title":"SHF: Small: Collaborative Proposal: Efficient Computer Algebra Techniques for Scalable Verification of Galois Field Arithmetic","awardID":"1320385","effectiveDate":"2013-08-01","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[550826],"PO":["562984"]},"205853":{"abstract":"The ability to learn is essential to the survival and robustness of biological systems. There is also growing evidence that learning is essential to build robust artificial intelligent systems and solve complex problems in many application domains. However, solutions to complex problems ranging from recognizing faces to understanding speech, cannot be implemented in a single step. Instead they require multiple processing stages, for instance to extract increasingly more abstract and refined features from an input image. <br\/><br\/>Thus computers and brains are both faced with the problem of deep learning --- how to simultaneously optimize the parameters of a hierarchy of processing stages in order to solve complex tasks and display intelligent behavior. In the past few years there has been remarkable progress in computer science to address the deep learning problem, and deep learning methods now claim state-of-the-art performance in several application areas. The next generation of machine learning methods holds the promise to not only approach human performance in tasks previously impossible for computers, but also to exceed it. However, our theoretical understanding of deep learning remains limited and there are several important areas where deep learning has not yet been applied systematically. This project addresses these challenges and opportunities by furthering formal understanding of the theory and algorithms behind deep learning, and by applying deep learning methods to new problems in the life sciences. Because deep learning can be used in almost any domain, the results have the potential for broadly impacting science, engineering, and technology across multiple areas. <br\/><br\/>The project has educational and outreach components, ranging from courses to virtual 3D world interactions, for undergraduate and graduate students at UCI, as well as talented students from local high schools, and underrepresented minority students from local colleges. Scientific results, data, and software resulting from the project will be disseminated in scientific journals and over the web.<br\/><br\/>The project has three main thrusts: theory, algorithms, and applications. From a theoretical standpoint, the project develops better mathematical understanding of deep architectures, including stacks of autoencoder networks, and their properties. These theoretical results will inform the design of deep-learning architectures. From an algorithmic standpoint, the project investigates, formally and through simulations, several deep learning algorithms, including the dropout algorithm and the PI's deep targets algorithm. From an application standpoint, the project uses the new theoretical and algorithmic knowledge in application to the life sciences, for instance for protein structure prediction, and in predicting chemical reactions. Advancing the state-of-the-art for any one of these thrusts will have a significant impact in computer science, artificial intelligence, statistical machine learning, and the corresponding application field.","title":"RI: Small: Deep Learning: Theory, Algorithms, and Applications","awardID":"1321053","effectiveDate":"2013-08-15","expirationDate":"2016-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[551111],"PO":["562760"]},"202234":{"abstract":"Although locating and navigation devices embedded in smartphones have already generated large volumes of location and trajectory data, the next generation of consumer electronics are likely to generate even larger volumes of location-dependent data where spatial and trajectory data management techniques will play critical roles in understanding the data to facilitate decision making. Modern Graphics Processing Units (GPUs) are capable of general computing. Current generation of commodity GPUs have large numbers of processing cores, support even larger numbers of current threads and provide high memory bandwidth, yet are available at affordable prices. The massively data parallel computing power of GPUs makes the hardware ideal for spatial and trajectory data management which is both data and computing intensive.<br\/><br\/>This project develops parallel indexing structures and query processing algorithms for spatial and trajectory data on GPUs to provide high performance which is crucial in speeding up existing applications and enabling new scientific and business inquiries. The project achieves its goals by developing: 1) novel spatial indexing techniques on GPUs; 2) novel spatial joins on GPUs; 3) novel trajectory segmentation and indexing techniques and trajectory similarity query processing techniques on GPUs; and 4) an end-to-end prototype system incorporated with open source database and GIS systems for performance evaluations and real world applications. Compared with existing spatial and trajectory data management systems that are mostly disk-resident and adopt a serial CPU computing model, the performance of GPU accelerated main-memory based systems is expected to achieve several orders of magnitude speedup and brings the performance of spatial and trajectory queries to a new level. The research results are beneficial to many applications, such as transportation, urban planning, wild bird ecology, and epidemiology of infectious diseases. Collaboration is carried out with transportation engineers at the University Transportation Research Center in New York City and ecology scientists at the University of Oklahoma?s Earth Observing and Modelling Facility. The project also makes important impacts on education as it provides training for students in the areas of national critical needs: database research, high performance computing, GPU programming, GIS, transportation, mobile and ecology applications. The developed algorithms and prototype system, real datasets and performance evaluation results are made available to the public at the Website: http:\/\/www.cs.ou.edu\/~database.","title":"III: Medium: Collaborative Research: Spatial Data and Trajectory Data Management on GPUs","awardID":"1302423","effectiveDate":"2013-08-01","expirationDate":"2017-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[541978,541979],"PO":["564768"]}}