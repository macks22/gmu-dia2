{"198099":{"abstract":"Many applications call for representation and analysis of 'distributional' data sets where each data point is a collection of samples from a high dimensional distribution (as opposed to valuations of a typically vector valued random variable). In this setting, each data point can be modeled by a collection of distributions, one for each measured attribute. A concrete example of distributional data arises in the context of brain connectivity mapping. The human brain contains around a hundred billion neurons with several hundred trillion physical connections. Neuroimaging approaches, like Diffusion Spectrum Imaging attempt to visualize the underlying anatomical architecture of neural pathways by creating 3D probability distributions of water diffusion along nerve fiber bundles, called orientation distribution functions. <br\/><br\/>The project aims to develop new statistical and algorithmic approaches to natural generalizations of a class of standard machine learning problems (where multi-dimensional vector valued data points are replaced by distributions), including techniques for measuring distances and inner products between distributional data points, estimating variants of entropy, mutual information, conditional mutual information, clustering distributional data, constructing low-dimensional embeddings of distributional data, and learning classifiers and function approximators from distributional data. The resulting methods will be evaluated on large diffusion scan imaging data sets (where the data point for each patient consists of 500,000 distributions). <br\/><br\/>The novel machine learning approaches for descriptive and predictive modeling of distributional data resulting from this project are expected to benefit other scientific fields where data points can be naturally modeled by sets of distributions, which is a common situation in physics, psychology, economics, epidemiology, medicine, and social network-analysis. New distributional data set to be obtained at CMU to augment the data available from NTU are likely to allow other research groups to engage in research on big data analytics from distributional data. Release of open source software, video tutorials, research-training of graduate students contribute to the broader impacts of the project. Additional information about the project can be found at: http:\/\/www.autonlab.org\/autonweb\/20928.html.","title":"BIGDATA: Mid-Scale: DA: Distribution-based machine learning for high dimensional datasets","awardID":"1247658","effectiveDate":"2013-01-01","expirationDate":"2015-12-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8083","name":"Big Data Science &Engineering"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"1269","name":"STATISTICS"}}],"PIcoPI":["541682","563138","533021"],"PO":["565136"]},"199310":{"abstract":"What are the foundational principles of computation? Any computer, however advanced, is ultimately limited by quantum mechanics, so the laws of computation and physics intertwine. Quantum computers, that take full advantage of quantum physics, do not yet exist, but are under active development. This award seeks to discover new algorithms and algorithmic frameworks for future quantum computers, as well as new techniques for proving stronger security guarantees on present-day quantum cryptography devices. The award will also be used for advising and supporting students, working with the PI and taking part in this research. <br\/><br\/>Quantum algorithms can work in very different ways than classical algorithms. Two of the most successful approaches for developing quantum algorithms---span programs and learning graphs---were developed only recently, but have led both to many concrete algorithms and to general computational rules, e.g., for composing algorithms. This research will extend and combine these approaches with physically inspired algorithmic techniques. In addition, the research will consider what quantum computation can teach us about the principles of physics. Are there intrinsic limits to how well we, as classical beings, can characterize quantum systems? Answers to this question tie closely to cryptography, and should allow for highly secure key-distribution schemes. By investigating the ultimate capabilities of quantum computers, the research will deepen our understanding of the basic principles of computation and physics.","title":"CAREER: Fundamental principles of computation and physics","awardID":"1254119","effectiveDate":"2013-01-01","expirationDate":"2017-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7928","name":"QUANTUM COMPUTING"}}],"PIcoPI":[534536],"PO":["565157"]},"198144":{"abstract":"Dynamic spectrum access (DSA) allows new wireless systems to reuse the spectrum currently occupied exclusively by primary systems. A DSA system must be intelligent enough to detect primary system's activity and be flexible enough to allow new and advanced technology to be adopted to compete for spectrum access. The intelligence and flexibility make DSA system to have complex dynamic behaviors such as oscillation and fluctuation that are quite different from what was intended. They also make it difficult to guarantee the coexistence of heterogeneous DSA systems. This project develops a theoretical framework for modeling and analyzing the dynamic behavior and the coexistence of heterogeneous DSA systems. It employs many methodologies from theoretical ecology to study the cooperation, competition, altruism, selfishness, and other intelligent human-like behaviors. Two approaches are exploited to study such complex interactions among multiple spectrum access strategies: an evolutionary game theoretic approach based on an efficient Markov-model bank, and a population dynamic approach based on a spectrum-usage model. In addition, this project initiates pioneering research on DSA policy modeling and analysis by applying the two approaches. <br\/><br\/>This project builds the underlying theoretical foundation to support the development of new DSA techniques, new heterogeneous DSA systems, and new DSA policies that enhance the efficiency and fairness of spectrum access. The theoretical methodologies are useful for the development of many other heterogeneous and intelligent systems in general. This project stimulates the integration of the two traditionally disparate areas: wireless communications and theoretical ecology, in both research and education.","title":"Dynamic Behavior and Coexistence of Intelligent Radio Spectrum Access Systems","awardID":"1247909","effectiveDate":"2013-01-01","expirationDate":"2015-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7976","name":"EARS"}}],"PIcoPI":[531748],"PO":["557315"]},"198067":{"abstract":"The ability to analyze massive-scale datasets has become an important tool both in industry and in the sciences and many systems have recently emerged to support it. However, effective methods for deep data analytics are currently high-touch processes: they require a highly specialized expert who thoroughly understands the application domain and pertinent disparate data sources and who needs to perform repeatedly a series of data exploration, manipulation and transformation steps to prepare the data for querying, machine learning or data mining algorithms. This project explores the foundations of big data management with the ultimate goal of significantly improving the productivity in big data analytics by accelerating the bottleneck step of data exploration. The project integrates two thrusts: a theoretical study, which leads to new fundamental results regarding the complexity of various new (ad hoc) data transformations in modern massive-scale systems, and a systems study, which leads to a multi-platform software middleware for expressing and optimizing ad hoc data analytics techniques. The middleware is designed to augment and integrate existing analytics solutions in order to facilitate and improve methods of interest to the community and compatible with many existing platforms.<br\/><br\/>The results of this project will make it easier for domain experts to conduct complex data analysis on big data and on large computer clusters. All research results will be released in a middleware package layered on top of existing big-data systems. The middleware includes all the new algorithms, optimization techniques, fault-tolerance and skew mitigation mechanisms, and generalized aggregates developed during the project. In addition, the project develops and deploys a Web-based query-as-a-service interface to the new middleware. The project Web site (http:\/\/myriadb.cs.washington.edu) provides access to the software, additional results and information. Project results will be included in educational and outreach activities in big data analytics, including new curricula at the undergraduate, graduate, and professional levels.","title":"BIGDATA: Mid-Scale: DCM: A Formal Foundation for Big Data Management","awardID":"1247469","effectiveDate":"2013-01-01","expirationDate":"2015-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8083","name":"Big Data Science &Engineering"}}],"PIcoPI":[531543,"536677",531545],"PO":["563751"]},"199079":{"abstract":"Reports and presentations are frequently used to share information. In business, science, education, law, and government, such documents are ubiquitous. When they are well-designed reports and presentations combine text with charts, tables and diagrams to visually highlight important findings. Good designers carefully choose colors, fonts, layout and composition to clarify and emphasize key ideas. Yet, creating an effective graphic design is challenging; most people who need to produce reports and presentations do not have the relevant training in art and design. Even with the proper training, creating effective designs can be extremely time-consuming. The result is that all too often reports and presentations are poorly designed. The goal of this exploratory research is to develop new tools for improving the graphic design of reports and presentations to highlight the desired information content. The initial work centers on the problem of identifying the principles of effective visual communication and graphic design for generating high-quality reports and diagrams. The challenge is to identify the most significant dimensions of visual design (e.g. spatial layout, fonts, colors, etc.) based on a large corpus of reports and presentations. A combination of crowdsourcing, image analysis and machine learning techniques will be used to determine the visual properties that characterize good graphic designs. <br\/><br\/>The expected result will lead to better understanding of how graphic design contributes to the clarity and usability of a report or presentation. This work will produce an explicit set of principles for creating effective graphic design and web-based materials for teaching these principles to improve design literacy in society at large. The project provides research experience to students and design principles will also be presented to high school and college students. The project Web site (http:\/\/vis.berkeley.edu\/projects\/graphicDesignPrinciples ) is used to disseminate results, including software; a corpus of reports and presentations from web-based sources; papers and technical reports; and educational materials.","title":"EAGER: Identifying Graphic Design Principles for Reports and Presentations","awardID":"1252819","effectiveDate":"2013-01-01","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[534062],"PO":["563751"]},"197100":{"abstract":"This Pan-American Advanced Studies Institutes (PASI) award, jointly supported by the NSF and the Department of Energy (DOE), will take place on July 2013 at the University of Costa Rica in San Jos\u00e9, Costa Rica. Organized by Dr. Charles R. Wallace and Dr. Linda M. Ott, both from Michigan Technological University, the PASI will bring together software engineering researchers, industrial representatives, students and practitioners in the area of software quality. Junior researchers will be exposed to state-of-the-art research in a personal, interactive setting that is conducive to building long-term relationships. Connections formed at the PASI may lead to a community of professionals committed to collaboration to enhance software quality throughout the Americas.<br\/><br\/>This PASI will introduce students to many important techniques in software quality. In addition to the benefits from developing long term synergistic relationships among faculty members, post docs, and senior PhD students, the PASI is intended to help initiate student exchanges between the programs and institutions involved. It will help make advances in several dimensions: research, teaching, and industrial practice. Information from the institute will be available on a website hosted at Michigan Tech, which will showcase the activities that result from the PASI and will include a membership option to allow subscribers to locate others with common interests and communicate with one another through a wiki.","title":"Pan-American Advanced Study Institute on Software Quality, San Jose, Costa Rica, July 2013","awardID":"1242257","effectiveDate":"2013-01-01","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0106","name":"Office of INTEGRATIVE ACTIVITIES","abbr":"OIA"},"pgm":{"id":"1385","name":"SPECIAL STUDIES AND ANALYSES"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"LX16","name":"Department of Energy Chicago O"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[528843,528844],"PO":["559975"]},"198101":{"abstract":"Big data analytics is, fundamentally, the problem of bringing the massive amounts of data produced today down to human scale. In particular scientists, engineers, physicians, and many others in knowledge-intensive professions face data that is beyond human scale. This data is in the repositories that collect the data and the reports or results in their fields. This project will address the problem of bringing all this knowledge under control by using even more data, namely the individual and social patterns of how these repositories are accessed and used, and user-specific judgments (valuations) of the data. The proposed research will develop novel algorithms and an open-source infrastructure for improving discovery within and access to data repositories. These algorithms will aggregate and analyze the social analytic data, gathered from professional communities of data users, and will motivate them to participate by providing recommendations.<br\/><br\/>The transformative goal is to develop methods for organizing, and operationalizing the access and preference patterns of users of large repositories, and for integrating those valuations to accelerate discovery within the collections. Diverse human minds interacting with data collections, as they carry out their own research or operational activities, provide a powerful source of information about the value of the data itself. Those data items may be textual documents, numerical datasets, or other kinds of media content. The novel methods for representing, aggregating, organizing and valuating interactions between the users and the items can reveal structures within data collections, which were previously invisible to any individual. This discovery of interrelations within data, driven by the capture of human intelligence, will accelerate the processes of scientific discovery. Users who are permitted to valuate data, and who are motivated by receiving valuable recommendations in return, reveal more about their own interests. This makes it possible to discover relations among the data items and among the users themselves. The educational goals are to: (a) contribute to the education of specific graduate students supported by the project, and undergraduates via the REU mechanism; (b) generate new educational materials related to algorithmic innovations, and to research findings; and (c) improve access to and discovery within specific collections of materials. Research findings will be included in courses at all three collaborating universities.<br\/><br\/>Additional information about the project (including publication, software, data sets) will be made available through the project web site: http:\/\/arxiv_xs.rutgers.edu\/.","title":"BIGDATA: Mid-Scale: ESCE: Collaborative Research: Discovery and Social Analytics for Large-Scale Scientific Literature","awardID":"1247664","effectiveDate":"2013-01-01","expirationDate":"2015-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8083","name":"Big Data Science &Engineering"}}],"PIcoPI":[531640],"PO":["565136"]},"198145":{"abstract":"Today's wireless networks are facing an emerging spectrum crisis due to increased demand. FCC has recently allowed non-licensed devices to operate in the TV spectrum band, leading to cognitive radio networks (CRNs). It is argued that CRNs result in a technical and economical conflict with the TV broadcast companies, which own licenses to the TV spectrum. In this project, CRNs are considered as a business opportunity for broadcast companies. The answer to the following question is sought: \"Is it economically and technically viable for broadcast companies to utilize TV white spaces for low-cost Internet provision and web-enabled TV services?\" To facilitate the involvement of broadcast companies in the cognitive radio business, the concept of cognitive radio-enabled TV set (Cog-TV) is considered. Cog-TV provides low-cost access to the Internet and local area network capabilities. Cog-TVs are assigned optimal spectrum sensing schedules to provide service differentiation capabilities through a novel neighborhood watch concept. Dynamic pricing techniques are developed with the objective of distributing the peak-time demand load. Moreover, the cost of building the Cog-TV infrastructure in urban and rural areas is analyzed to determine its economic feasibility. Through this architecture, broadcast companies can leverage their channel ownership to create a competitive advantage.<br\/><br\/>The results from this research are expected to enable transformative and economically viable CRN development and management approaches. The Cog-TV concept has the potential to bring affordable Internet service to a large group of American households and impact consumer market by creating a niche market in new TV sets.","title":"Collaborative Research: Cog-TV: Business and Technical Analysis of Cognitive Radio TV Sets for Enhanced Spectrum Access","awardID":"1247914","effectiveDate":"2013-01-01","expirationDate":"2015-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7976","name":"EARS"}}],"PIcoPI":[531750],"PO":["557315"]},"198156":{"abstract":"Today's wireless networks are facing an emerging spectrum crisis due to increased demand. FCC has recently allowed non-licensed devices to operate in the TV spectrum band, leading to cognitive radio networks (CRNs). It is argued that CRNs result in a technical and economical conflict with the TV broadcast companies, which own licenses to the TV spectrum. In this project, CRNs are considered as a business opportunity for broadcast companies. The answer to the following question is sought: \"Is it economically and technically viable for broadcast companies to utilize TV white spaces for low-cost Internet provision and web-enabled TV services?\" To facilitate the involvement of broadcast companies in the cognitive radio business, the concept of cognitive radio-enabled TV set (Cog-TV) is considered. Cog-TV provides low-cost access to the Internet and local area network capabilities. Cog-TVs are assigned optimal spectrum sensing schedules to provide service differentiation capabilities through a novel neighborhood watch concept. Dynamic pricing techniques are developed with the objective of distributing the peak-time demand load. Moreover, the cost of building the Cog-TV infrastructure in urban and rural areas is analyzed to determine its economic feasibility. Through this architecture, broadcast companies can leverage their channel ownership to create a competitive advantage.<br\/><br\/>The results from this research are expected to enable transformative and economically viable CRN development and management approaches. The Cog-TV concept has the potential to bring affordable Internet service to a large group of American households and impact consumer market by creating a niche market in new TV sets.","title":"Collaborative Research: Cog-TV: Business and Technical Analysis of Cognitive Radio TV Sets for Enhanced Spectrum Access","awardID":"1247941","effectiveDate":"2013-01-01","expirationDate":"2015-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7976","name":"EARS"}}],"PIcoPI":[531778,"554534"],"PO":["557315"]},"199267":{"abstract":"Automated program analyses developed over the last three decades have demonstrated the ability to prove non-trivial properties of real-world programs. This ability, in turn, has applications to emerging software challenges in security, software-defined networking, cyber-physical systems, and beyond. The diversity of such applications necessitates adapting the underlying program analyses to client needs, in aspects of scalability, applicability, and accuracy. Today's program analyses, however, do not provide useful tuning knobs. The goal of this research is a general computer-assisted approach to effectively adapt program analyses to diverse clients. It bridges the gap between decades of program analysis research on one hand and diverse artifacts built atop them to address emerging software challenges on the other. In doing so, it broadens and enhances the benefits of program analysis to its users, as well as users of software whose quality is impacted by program analysis.<br\/><br\/>The research has three key ingredients. First, it poses optimization problems that expose a large set of choices to adapt various aspects of a program analysis, such as its cost, the accuracy of its result, and the assumptions it makes about missing information. Second, it solves those optimization problems by new search algorithms that efficiently navigate large search spaces, reason in the presence of noise, interact with users, and learn across programs. Third, it builds a program analysis platform that facilitates users to specify and compose analyses, enables search algorithms to reason about analyses, and allows using large-scale computing resources to parallelize analyses. The approach is demonstrated in the context of analyzing mobile apps -- programs that run on advanced mobile devices such as smartphones and tablets. Mobile apps represent an increasing use of non-expert programmers and they are likely to be used across a wide range of users in heterogeneous and demanding conditions that can benefit from what-if analyses that program analysis can offer.","title":"CAREER: Adaptive Large-Scale Program Analysis","awardID":"1253867","effectiveDate":"2013-01-15","expirationDate":"2017-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":[534450],"PO":["564588"]},"196550":{"abstract":"This Cyberlearning Capacity-Building project brings together learning scientists, experts in media creation, experts in child development, producers of public media assets, parent, and educators in an effort to build social infrastructure that will support bringing what is known about how people learn to the design of public media that can effectively connect school learning and out-of-school learning for young children. The team's theoretical framing and working hypothesis highlights the importance of media as a catalyst for collaboration and learning conversations; according to the theoretical base, these collaborations and learning conversations, when carried out across peers and in families, can play a powerful role in connecting children's school and outside-of-school experiences. Two workshops are being convened for the purpose of shedding light on the pragmatics of doing this -- the R&D partnerships needed, the methods that might be used, and the issues that need to be addressed for success. Through partnerships with children's educational media producers, the team is building capacity for interdisciplinary teams that include learning scientists and media producers to engage in research around how to use public media assets to promote the kinds of learning conversations in and out of school that will connect home and school settings into a distributed learning environment. <br\/><br\/>This project is laying the groundwork for new interdisciplinary research efforts addressing issues in early learning. The team's theoretical framework points to media as a catalyst for the kinds of collaborations and conversations that might promote learning and connect children's school and out-of-school experiences. Thus, this project is bringing together learning scientists and children's educational media producers (PBS, Sesame Workshop, the Joan Ganz Cooney Center) to seed future collaborations. The goals of this initial collaboration are to work together to establish new methods for studying learning with media and advance understanding of how public media assets can be leveraged to support the learning and interest development of young children and their families.","title":"CAP: Collaborative Research: Building a Network to Advance Collaborative Research on Young Children's Learning through Public Media Assets","awardID":"1239599","effectiveDate":"2013-01-01","expirationDate":"2014-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":["554123","562575"],"PO":["562669"]},"197783":{"abstract":"Workflows, especially data-driven workflows and workflow ensembles are becoming a centerpiece of modern computational science. However, scientists lack the tools that integrate the operation of workflow-driven science applications on top of dynamic infrastructures that link campus, institutional and national resources into connected arrangements targeted at solving a specific problem. These tools must (a) orchestrate the infrastructure in response to application demands, (b) manage application lifetime on top of the infrastructure by monitoring various workflow steps and modifying slices in response to application demands, and (c) integrate data movement with the workflows to optimize performance.<br\/><br\/>Project ADAMANT (Adaptive Data-Aware Multi-domain Application Network Topologies) brings together researchers from RENCI\/UNC Chapel Hill, Duke University and USC\/ISI and two successful software tools to solve these problems: Pegasus workflow management system and ORCA resource control framework, developed for NSF GENI. The integration of Pegasus and ORCA enables powerful application- and data-driven virtual topology embedding into multiple institutional and national substrates (providers of cyber-resources, like computation, storage and networks). ADAMANT leverages ExoGENI - an NSF-funded GENI testbed, as well as national providers of on-demand bandwidth services (NLR, I2, ESnet) and existing OSG computational resources to create elastic, isolated environments to execute complex distributed tasks. This approach improves the performance of these applications and, by explicitly including data movement planning into the application workflow, enables new unique capabilities for distributed data-driven \"Big Science\" applications.","title":"Collaborative Research: CC-NIE Integration: Transforming Computational Science with ADAMANT (Adaptive Data-Aware Multi-Domain Application Network Topologies)","awardID":"1245926","effectiveDate":"2013-01-01","expirationDate":"2014-12-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8080","name":"Campus Cyberinfrastrc (CC-NIE)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[530742,530743],"PO":["564246"]},"197552":{"abstract":"This project will strengthen the organizational and technical infrastructure of the Center for Historical Information and Analysis (http:\/\/chia.pitt.edu), a multi-institutional collaborative of scholars in social, natural, and information sciences structured as a Research Collaborative and a Headquarters. The Research Collaborative links participating institutions that are collecting data on population, climate, and other topics with a crowdsourcing tool to demonstrate the feasibility of building a continuously growing collection of diverse historical data and metadata. The Headquarters assembles and develops knowledge on repository design to develop a repository sufficient to house the incoming data and permit global and interactive analysis. The Center for Historical Information and Analysis?s future plans include expanding its collection and processing of historical data, broadening its community of social and natural science researchers, analyzing historical patterns of global change, and sharing its resources with researchers, policy-makers, teachers and students. CHIA is headquartered at the University of Pittsburgh with participating research groups at Boston University, Harvard University, Michigan State University, and University of California-Merced.<br\/><br\/>To understand global social patterns as they exist today, it is increasingly clear that we need to understand how they have evolved over recent centuries. The Center for Historical Information and Analysis responds to this need and takes historical analysis into the realm of Big Data. It is expected that the data resources will grow to several terabytes in size. This project will stimulate development of more efficient research collaborations, enabling systematic large-scale consolidation of diverse historical data sources. Once collected and integrated, the data repository and analytical system will allow scholars to address a wider set of questions testing hypotheses about long-term and short-term social change at the global scale and catalyzing an expansion of the evidence base in social sciences. For example, our understanding of important societal issues can advance by linking health to demography and by incorporating climate and health factors into economic studies. Disciplinary theory will advance through interaction among the various scientific fields, so that a global network of social-science researchers will emerge.","title":"Collaborative Research: Center for Historical Information and Analysis (CHIA)","awardID":"1244796","effectiveDate":"2013-01-01","expirationDate":"2015-12-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"8068","name":"Data Infrastructure"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}}],"PIcoPI":[530026],"PO":["561290"]},"198994":{"abstract":"As our reliance on IT continues to increase, future applications will involve the processing of massive amounts of data and will require an exascale computing infrastructure in which the number of computing, communications and storage elements will increase by several orders of magnitude. Such an infrastructure will inevitably incorporate new classes of high density, low latency and low power non-volatile memory. This, in turn, will increase by orders of magnitude the rate of failures making resiliency a major concern. <br\/><br\/>This project addresses this resiliency challenge by taking a radical approach to fault-tolerance, which goes beyond the current approach of checkpointing and rollback recover. It introduces innovative and scalable fault-tolerance mechanisms, namely shadow-computing and quality-of-data (QoD) aware replication, as building blocks for a ?tunable? resiliency framework that leverage the new and emerging memory technology and takes into consideration the nature of the data and the requirements of the underlying application. <br\/><br\/>It is expected that the project will lead to new insights into the multi-faceted and challenging resiliency problem in exascale computing platforms. The expected outcomes of the project are a new fault-tolerance computational model and a suite of QoD-aware replication methods that, when combined with storage level resiliency, will lead to high availability with minimized access delay in exascale computing environments.<br\/><br\/>The project seeks to involve graduate and undergraduate students in all its research thrusts. In addition to their contributions in the research activities, involved students also participate fully in outreach, dissemination and community efforts activities. The project also seeks to leverage existing collaboration with industrial partners to involve students in summer internships and provide them with first hand exposure to research and development in an industrial setting. A main objective of the recruiting effort is to seek the involvement of students from minorities and under-represented groups in the project.","title":"CSR: EAGER: Exploratory Research on Scalable Resiliency Through Shadow Computing and Differential Data Replication","awardID":"1252306","effectiveDate":"2013-01-01","expirationDate":"2014-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[533851,"194325"],"PO":["565255"]},"196552":{"abstract":"This Cyberlearning Capacity-Building project brings together learning scientists, experts in media creation, experts in child development, producers of public media assets, parent, and educators in an effort to build social infrastructure that will support bringing what is known about how people learn to the design of public media that can effectively connect school learning and out-of-school learning for young children. The team's theoretical framing and working hypothesis highlights the importance of media as a catalyst for collaboration and learning conversations; according to the theoretical base, these collaborations and learning conversations, when carried out across peers and in families, can play a powerful role in connecting children's school and outside-of-school experiences. Two workshops are being convened for the purpose of shedding light on the pragmatics of doing this -- the R&D partnerships needed, the methods that might be used, and the issues that need to be addressed for success. Through partnerships with children's educational media producers, the team is building capacity for interdisciplinary teams that include learning scientists and media producers to engage in research around how to use public media assets to promote the kinds of learning conversations in and out of school that will connect home and school settings into a distributed learning environment. <br\/><br\/>This project is laying the groundwork for new interdisciplinary research efforts addressing issues in early learning. The team's theoretical framework points to media as a catalyst for the kinds of collaborations and conversations that might promote learning and connect children's school and out-of-school experiences. Thus, this project is bringing together learning scientists and children's educational media producers (PBS, Sesame Workshop, the Joan Ganz Cooney Center) to seed future collaborations. The goals of this initial collaboration are to work together to establish new methods for studying learning with media and advance understanding of how public media assets can be leveraged to support the learning and interest development of young children and their families.","title":"CAP: Collaborative Research: Building a Network to Advance Collaborative Research on Young Children's Learning through Public Media Assets","awardID":"1239605","effectiveDate":"2013-01-01","expirationDate":"2014-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":["560145",527102],"PO":["562669"]},"194056":{"abstract":"This research project studies a new area of research - exposure detection - that is at the intersection of data mining, security, and natural language processing. Exposure detection refers to discovering components\/attributes of a user's public profile that reduce the user's privacy. To help the public understand the privacy risks of sharing certain information on the web, this research project focuses on developing efficient algorithms for modeling how an adversary learns information using incomplete and schemaless public data sources. Theoretically sound and efficient techniques for identifying accurate web footprints are introduced, including: new methods for data matching using a novel probabilistic join operator on multi-granular data, automated approaches for generating inference rules, and new solutions for identifying missing information and unifying mismatched vocabulary using lightweight natural language processing and text mining. The research activities also investigate methods for quantifying and adjusting exposure and risk, facilitating a better understanding of individuals' vulnerability on the web. These techniques not only advance the state of the art in re-identification, probabilistic reasoning and inference logic, and natural language understanding, but also serve as a foundation for exposure detection.","title":"TWC: Small: Assessing Online Information Exposure Using Web Footprints","awardID":"1223825","effectiveDate":"2013-01-15","expirationDate":"2015-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["557843",519691,"540794"],"PO":["562974"]},"205309":{"abstract":"This is funding to support a Doctoral Consortium (workshop) for approximately 11 graduate students, along with a panel of about 4 distinguished research faculty mentors. The event will take place in conjunction with the 2013 IEEE Symposium on Visual Languages and Human-Centric Computing (VL\/HCC), to be held September 15-19, 2013, in San Jose, California, and sponsored by the IEEE Computer Society. The long-running VL\/HCC series occupies a unique niche among HCI and Programming Language conferences, in that it focuses specifically on how to help end users successfully develop and use software. Recent advances in computing have led to continually deeper integration between computers and human society. People now swim in a \"sea\" of socio-technical systems that synthesize large numbers of contributing users with vast amounts of source code. Examples include social media systems, open source repositories, online marketplaces and massively multiplayer online games. Yet as the socio-technical systems in this sea have grown in complexity, they have become increasingly difficult for end users to understand and direct toward productive ends. <br\/><br\/>The primary goal of this year's VL\/HCC Doctoral Consortium, the eleventh to be funded by NSF in this series, is to stimulate graduate students' and other researchers' thinking about how to make computation easier to express, manipulate, and understand. In particular, what methods, models and tools can people use to visualize, analyze, tailor, and direct socio-technical systems? The doctoral consortium aims to stimulate novel approaches that go far beyond simplistic solutions like web browsers and search engines. Although search engines do provide information that is useful in simple situations, they represent only one portion of a socio-technical system (information retrieval). For example, search engines alone are not powerful enough to be used to start new businesses and run them competitively, since they only give people the ability to find resources provided by other people, rather than the ability to create new resources. Effective approaches will bring users and software together in creative and productive ways that bear directly on the needs of modern society. <br\/><br\/>The workshop will build community among young researchers working on different aspects of these problems from the perspectives of diverse fields including computer science, the social sciences, and education. It will guide the work of these new researchers by providing an opportunity for experts in the research field (as well as their peers) to give them advice, in that student participants will make formal presentations of their work during the workshop and will receive feedback from a faculty panel. The feedback is geared to helping students understand and articulate how their work is positioned relative to other human-computer interaction research, whether their topics are adequately focused for thesis research projects, whether their methods are correctly chosen and applied, and whether the results are appropriately analyzed and presented. As in prior years the VL\/HCC 2013 Doctoral Consortium will be part of the regular conference program. A 2-page extended abstract of each participant's work will be published in the conference proceedings. More information about this year's VL\/HCC conference may be found online at https:\/\/sites.google.com\/site\/vlhcc2013. <br\/><br\/>Broader Impacts: The workshop will help shape ongoing and future research projects aimed at alleviating a pressing problem of relevance to a great many people within our society. This event will promote discovery and learning, by encouraging the student researchers to explore a difficult and challenging open problem, through involvement of a panel of well-known researchers whose task is to provide constructive feedback, and through inclusion of other conference participants who will also learn from and provide additional feedback to the students and to each other. The PI and the members of the organizing committee will make special efforts to attract a diverse and interdisciplinary group of student participants, with special attention paid to recruitment of students from underrepresented institutions and women. While most of the students supported by this award will come from U.S. universities, as in past years due to the highly international make-up of the research community a couple of non-U.S. students may be invited to participate as well. To further increase diversity, no more than 2 student participants will be accepted from any one institution.","title":"WORKSHOP: VL\/HCC 2013 Graduate Consortium","awardID":"1318174","effectiveDate":"2013-01-15","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[549767],"PO":["565227"]},"198115":{"abstract":"This project is aimed at achieving significant spectrum efficiency gains through inter network collaboration in radio resource management. The proposed SAVANT (spectrum access via inter network collaboration) architecture is based on a new protocol interface for dissemination of spectrum usage information, policies and algorithms between neighboring networks to enable spectrum coexistence algorithms that reduce interference and improve spectrum packing efficiency. A new inter-domain spectrum coordination protocol (ISCP) is being developed to enable independent networks to negotiate radio resource management policies and optionally merge radio resource controllers for joint optimization.<br\/><br\/>The scope of research to be conducted includes ISCP protocol design\/validation, evaluation of alternative algorithms involving network collaboration, prototype implementation and performance evaluation. The methodology for the project involves a mix of analysis, simulation and experimental prototyping. Generalized analytical models for radio localization, propagation and interference are developed and incorporated into simulation studies of inter-network cooperation using the ISCP protocol framework. These simulation models are expected to provide insight into the type of collaborative radio resource optimization algorithm to be used along with quantitative evaluation of ISCP overhead, complexity and performance. The project also includes an experimental prototyping track in which emerging software-defined network (SDN) technology is used to develop a proof-of-concept system with multiple collaborating networks. <br\/><br\/>The proposed ISCP inter-network protocol has the potential for large gains in wireless spectrum utilization, and could thus influence future industry standards. The project will also produce educational materials for training of graduate students in software-defined networking and wireless systems.","title":"EARS: SAVANT - High Performance Dynamic Spectrum Access via Inter Network Collaboration","awardID":"1247764","effectiveDate":"2013-01-01","expirationDate":"2015-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7976","name":"EARS"}}],"PIcoPI":[531675,"564746"],"PO":["557315"]},"196520":{"abstract":"This project is to develop a dynamical systems model of distributed computation motivated from recent work on the distributed computation of averages. The key idea is that static optimization problems (particularly convex optimization problems) can be solved by designing a dynamic system that stabilizes around the optimal solution of the problem. Moreover, when the optimization problem is separable, then the designed dynamic system decomposes into a set of locally-interacting dynamic systems. This is expected to open a door to a host of new computational approaches that take advantage of recent developments in control engineering including robust control (providing a mechanism for errors introduced by discretization), Markovian Jump Linear Systems (providing a mechanism for random discretization time), event-driven control (providing a mechanism for assured asynchronous execution), control over networks (providing a mechanism for improved performance of distributed computational systems in general). The new approach is essential in emerging applications, where the optimization runs on physically separated agents, operating in a noisy environment and communicating over unreliable channels. As a test bed, the project will make use of a two-vehicle robotic system developed by the PI designed to monitor a crop of corn plants, where the dynamic systems perspective of this grant will, for example, allow for distributed optimal estimation toward the goal of optimal station-keeping.<br\/><br\/>By studying how natural systems can collectively compute and optimize, this research has potential to impact many disciplines involving networked systems, from controlling the electric power grid, to modeling the behavior of social, biological or economic systems. It is directly applicable to cooperative networked multi-agent systems like robotic search and rescue missions and disaster-relief operations, distributed machine learning problems, and intelligent systems. An intriguing mix of motivating applications and theoretical problems offer a unique multidisciplinary educational opportunity to students who will be involved in the project, and provide exciting innovative material for courses and labs. Software developed will be distributed as open source via the CPS Virtual Organization.","title":"CPS: Breakthrough: Distributed Computing Under Uncertainty: A New Paradigm for Cooperative Cyber-Physical Systems","awardID":"1239319","effectiveDate":"2013-01-01","expirationDate":"2015-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["550938"],"PO":["565274"]},"197797":{"abstract":"Workflows, especially data-driven workflows and workflow ensembles are becoming a centerpiece of modern computational science. However, scientists lack the tools that integrate the operation of workflow-driven science applications on top of dynamic infrastructures that link campus, institutional and national resources into connected arrangements targeted at solving a specific problem. These tools must (a) orchestrate the infrastructure in response to application demands, (b) manage application lifetime on top of the infrastructure by monitoring various workflow steps and modifying slices in response to application demands, and (c) integrate data movement with the workflows to optimize performance.<br\/><br\/>Project ADAMANT (Adaptive Data-Aware Multi-domain Application Network Topologies) brings together researchers from RENCI\/UNC Chapel Hill, Duke University and USC\/ISI and two successful software tools to solve these problems: Pegasus workflow management system and ORCA resource control framework, developed for NSF GENI. The integration of Pegasus and ORCA enables powerful application- and data-driven virtual topology embedding into multiple institutional and national substrates (providers of cyber-resources, like computation, storage and networks). ADAMANT leverages ExoGENI - an NSF-funded GENI testbed, as well as national providers of on-demand bandwidth services (NLR, I2, ESnet) and existing OSG computational resources to create elastic, isolated environments to execute complex distributed tasks. This approach improves the performance of these applications and, by explicitly including data movement planning into the application workflow, enables new unique capabilities for distributed data-driven \"Big Science\" applications.","title":"Collaborative Research: CC-NIE Integration: Transforming Computational Science with ADAMANT (Adaptive Data-Aware Multi-Domain Application Network Topologies)","awardID":"1245997","effectiveDate":"2013-01-01","expirationDate":"2014-12-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8080","name":"Campus Cyberinfrastrc (CC-NIE)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["553906"],"PO":["564246"]},"198105":{"abstract":"The recent emergence of a variety of high-throughput DNA sequencing instrumentation, and the concomitant rapid decline in the cost per base, is causing severe data deluge in all areas of life sciences. The heterogeneity of sequencing instrumentation and the vast diversity of applications enabled by them are creating numerous analytics problems for the bioinformatics community to address. In addition, the conventional serial algorithms that have been the mainstay of bioinformatics research are severely challenged by the ever increasing data sets. The goal of the proposed project is to develop core techniques and software libraries to enable scalable, efficient, high performance computing solutions for high-throughput DNA sequencing, also known as next-generation sequencing (NGS). To empower the larger community, the project seeks to 1) identify a set of core functionalities that frequently occur in many types of high-throughput sequencing applications, 2) develop efficient parallel algorithms and high performance implementations for them, 3) pursue mapping to HPC architectures including clusters, multicores, and GPUs, 4) develop software libraries encapsulating these functionalities with the goal of enabling the bioinformatics community to exploit HPC architectures, and 5) design a domain specific language to enable bioinformatics researchers unfamiliar with parallel processing to benefit from this work through automatic generation of parallel codes. The research will be conducted in the context of challenging problems in human genetics and metagenomics, in collaboration with domain specialists.<br\/><br\/>This project is focused on a key capacity building activity to facilitate pervasive use of parallelism by NGS bioinformatics researchers and practitioners. The goal is to empower the broader community to benefit from clever parallel algorithms, highly tuned implementations, and specialized HPC hardware, without requiring expertise in any of these. The software libraries will be released as open source for use, further development, enhancements, and incorporation by the community. The project will provide opportunities for training postdoctoral and graduate students in bigdata analytics and computer science driven interdisciplinary research. Diverse existing mechanisms at the partner institutions will be leveraged to advance goals of minority and women recruitment, undergraduate participation in research, and K-12 outreach.","title":"BIGDATA: Mid-Scale: DA: Collaborative Research: Genomes Galore - Core Techniques, Libraries, and Domain Specific Languages for High-Throughput DNA Sequencing","awardID":"1247693","effectiveDate":"2013-01-01","expirationDate":"2015-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8083","name":"Big Data Science &Engineering"}}],"PIcoPI":["563449"],"PO":["565136"]},"203539":{"abstract":"This proposal is to collect perishable data on the physical response of the transportation infrastructure in New York City following Hurricane Sandy. It makes use of a new human-in-the-loop smartphone-based crowd-sourcing sensing technology, called TrafficTurk. TrafficTurk is a smartphone application which enables intelligent, human?centric sensing of traffic flows during extreme events.<br\/><br\/>The aftermath of Hurricane Sandy represents a rare opportunity to observe transient behavior of a transportation network in response to a significant loss of physical infrastructure (due to flooding and gas shortages) and cyber infrastructure (due to loss of power for traffic control devices). The data gathered by this project, which will be shared with researchers across the country, will enable study of how traffic dynamics evolve after a major disruption to the cyber and physical components of a transportation infrastructure system. Potential benefits include improved preparedness and response to future disasters.","title":"RAPID: Monitoring the Response of Transportation Cyber Physical Systems in the Wake of Hurricane Sandy","awardID":"1308842","effectiveDate":"2013-01-15","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["563130"],"PO":["564778"]},"197885":{"abstract":"Prism@UCSD creates a campus-wide \"Big Data freeway\" composed of high-bandwidth end-to-end optical connections routed by a next-generation Arista switch. This creates an optical fabric capable of more than 10 Terabit\/s of aggregate bandwidth, has full bisection similar to in-machine room clusters but is deployed at a campus scale. This researcher-defined network unites users of in-lab scientific instruments such as genome sequencers and microscopes with remote compute, visualization, data-storage and analysis systems. Prism bridges to, augments, and protects the existing campus production network by providing a complementary, specialized, cost-effective, massive-capacity network to a targeted group of data-intensive labs. <br\/><br\/>Prism builds upon and upgrades the Quartzite \"campus-scale network laboratory\" NSF MRI (awarded 2006) that was motivated by applications with extreme-scale bandwidth requirements. Compared to Quartzite, Prism not only adds IPv6 capability and support for software defined networks via OpenFlow, but also increases port capacity by 4x, lowers power consumption by 3x, and removes all card-to-switch-backplane over-subscription at the core switch. In addition, the existing optical fiber connection to the San Diego Supercomputer Center is being expanded to 120Gbps as a high-bandwidth bridge to cloud\/parallel storage and NSF XSEDE resources. This fundamentally enables research in multiple disciplines, including physics, chemistry, biology, climate change, oceanography, and computer science to address big-data challenges.<br\/><br\/>Workshops will be held with regional optical networks and EDUCAUSE to disseminate experience to research campuses and fully describe this cost-effective, expandable and replicable infrastructure. In addition, a summer workshop aimed at minority serving institutions will build on Calit2 \/ SDSC's tradition of diversity outreach. Prism will form a model for others to follow in building their own big-data transportation systems.","title":"CC-NIE Network Infrastructure: PRISM@UCSD: A Researcher Defined 10 and 40Gbit\/s Campus Scale Data Carrier","awardID":"1246396","effectiveDate":"2013-01-01","expirationDate":"2014-12-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8080","name":"Campus Cyberinfrastrc (CC-NIE)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["554382","559498"],"PO":["564246"]},"195269":{"abstract":"Since noteworthy events happen only occasionally in any data, it is imperative for smart sensors to learn the norms in data so that authorities can be alerted and appropriate action can be taken at the occurrence of an abnormal or noteworthy event. The aim of this project is to develop algorithms that can learn the norm in terms of a hierarchy of meaningful features from data in an unsupervised and online manner. The application testbed is the problem of automatically tuning cochlear implants (CIs) of patients with severe-to-profound hearing loss by continuously monitoring their speech output. The working hypothesis is that deficiencies in hearing for people with significant hearing loss are reflected in their speech production. This project will develop and use unsupervised, online, and biologically plausible machine learning algorithms to learn feature hierarchies from the speech output data of severely-to-profoundly hearing-impaired patients. The learned feature hierarchy from the speech of a patient will be compared to those learned from the speech of a comparable normal hearing population. Deficiencies in the patient's hearing will be ascertained by identifying the missing or distorted features. Algorithms will be developed to map this information into the signal processing strategies used in CIs to enhance the audibility of speech.<br\/><br\/>The proposed project promises transformative changes to three major interdisciplinary fields: machine learning and artificial intelligence, healthcare, and sensors. It will transform the traditional ways in which the clinical needs of patients are met. For example, the results of this project will provide doctors with evidence-based practices that will better address the specific needs of individual patients by monitoring each patient around the clock at minimal effort and cost.<br\/><br\/>Hearing loss is the most common birth defect in the U.S. with slightly over 15,000 new pediatric cases each year and societal losses amounting to $4.6 billion over a lifetime. A proven technology for CI tuning would make a significant difference to the lives of over 1.2 million CI candidates in the U.S. and many more around the world, thereby leading to substantial health and economic benefits to society. Other than CI tuning, the proposed algorithms will be applicable to a variety of monitoring applications within healthcare, such as blood pressure, cerebrospinal fluid pressure, intracavitary pressure of the bladder, etc., and beyond healthcare, such as web, machine health, traffic, etc. Continuous monitoring with wearable and implantable body sensors will increase early detection of emergency conditions and diseases in at-risk patients and also provide a wide range of healthcare services for people with various degrees of cognitive and physical disabilities. Not only the elderly and chronically ill, but also the families in which both parents have to work will benefit from these systems to provide high-quality care services for their babies and children. Finally, the proposed project will integrate diversity by promoting teaching, learning, and interdisciplinary research among underrepresented groups.","title":"SHB: Type I (EXP): Algorithms for Unsupervised and Online Learning of Hierarchy of Features for Tuning Cochlear Implants for the Hearing Impaired","awardID":"1231620","effectiveDate":"2013-01-01","expirationDate":"2015-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[523471,523472],"PO":["565136"]},"196831":{"abstract":"Westminster College of Salt Lake City, in partnership with Brigham Young University, proposes to create a new one-semester course modeled on the LAUSD Exploring Computer Science curriculum. The vast majority of Utah high school students do not have the opportunity to learn about computing beyond a required computer literacy course. This project seeks to provide all students in Utah public schools with an alternative to this existing computer literacy course. The Utah Exploring Computer Science Initiative will adapt the Exploring Computer Science (ECS) curriculum into a half-year course that meets the computer literacy high school graduation requirement for the state of Utah. Over three years, the project will prepare and support 100 teachers with summer professional development workshops, monthly meetings held during the academic year, a mentoring program, and a supportive online community. The proposed project will better prepare students with more advanced 21st century computing skills and will increase student, parent and counselor awareness of computing. It is anticipated that the ECS course will improve student perception of computing as a discipline, leading to increased student interest in additional CS courses, which will in turn drive demand for more rigorous course offerings, such as AP CS A or the proposed, new AP Computer Principles course. The project goal is to have the majority of Utah students taking the ECS course to fulfill their computer literacy high school graduation requirement within 5 years.","title":"CS 10K: The Utah Exploring Computer Science Initiative","awardID":"1240977","effectiveDate":"2013-01-01","expirationDate":"2015-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["562082",528010,528011],"PO":["561855"]},"197810":{"abstract":"Duke University is enhancing the capabilities of its data network to better support data-intensive research. By deploying a mix of next-generation software-defined networking (SDN) hardware along with enhanced high-speed conventional networking links, Duke creates on-demand high speed paths either through Duke's own network (connecting resources in different parts of campus) or directly from campus laboratories to external networks. In both cases these dynamically managed links can bypass layers of network management which, while sensible for routine traffic, add latency and limit speed for trusted high volume science flows.<br\/><br\/>As Duke's core network is already fast and agile, the emphasis in this work is on improving network capability over the last few meters through local building switches and directly to the instrument or computer sourcing or sinking the data. Faster networking to the devices coupled with intelligent (SDN-mediated) routing at the building level of specific scientific data flows via \"short-cut\" paths through the core is expected to result in higher overall performance.<br\/><br\/>The work is expected to demonstrate that judicious deployment of intelligent edge devices can provide data-intensive science researchers with all the advantages of a dedicated science network without expensive re-engineering of an already capable core network.","title":"CC-NIE Network Infrastructure: Using Software-Defined Networking to Facilitate Data Transfer","awardID":"1246042","effectiveDate":"2013-01-01","expirationDate":"2014-12-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8080","name":"Campus Cyberinfrastrc (CC-NIE)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[530834,530835],"PO":["564246"]},"197744":{"abstract":"Wide spread adoption of cyberinfrastructure advances has been a challenge to researchers mainly due to the traditional cyberinfrastructure equipment, policies and engineering practices at campuses. This University of Missouri (MU) project enables a 100 GB connection extending across the state of Missouri from St. Louis through Columbia to Kansas City directly on the I2 Innovation Network backbone. It includes wide-area network experimentation to seamlessly integrate MU's cyberinfrastructure and Science DMZ with a remote campus (Ohio State University) cyberinfrastructure. It also involves integrating advanced technologies (e.g., 100Gbps connectivity, perfSONAR, OpenFlow, RoCE\/iWARP) relevant to the use cases of diverse researchers at MU and OSU.<br\/><br\/>Building CI in this environment requires authentication, authorization, and policy-limited access to resources. The project engages all three elements of Internet2's Innovation Network: Software Defined Networking (SDN), OpenFlow and Federated Identity. The University of Missouri is modifying its existing cyberinfrastructure to accommodate advanced tools enabled by OpenFlow and SDN. The existing science DMZ is compatible with the Innovation Network Science DMZ. MU is also customizing Shibboleth Federated Identity Management services <br\/>to provide fine-grained authorization and access to specific resources. The entitlement server implements policy that controls the bandwidth consumed by individual users or programs. The project broadly disseminates research results through publication on the project web site, disseminated through various regional and national conferences, and journal articles. Open source software from the project will also be made available.","title":"CC-NIE Integration: Creation of an Institutional Cyberinfrastructure to Enable Researcher-Oriented, Federated Environment for Large, Collaborative Science Projects","awardID":"1245795","effectiveDate":"2013-01-01","expirationDate":"2014-12-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8080","name":"Campus Cyberinfrastrc (CC-NIE)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[530614,"562286","518557",530617,"550551"],"PO":["564246"]},"198108":{"abstract":"The recent emergence of a variety of high-throughput DNA sequencing instrumentation, and the concomitant rapid decline in the cost per base, is causing severe data deluge in all areas of life sciences. The heterogeneity of sequencing instrumentation and the vast diversity of applications enabled by them are creating numerous analytics problems for the bioinformatics community to address. In addition, the conventional serial algorithms that have been the mainstay of bioinformatics research are severely challenged by the ever increasing data sets. The goal of the proposed project is to develop core techniques and software libraries to enable scalable, efficient, high performance computing solutions for high-throughput DNA sequencing, also known as next-generation sequencing (NGS). To empower the larger community, the project seeks to 1) identify a set of core functionalities that frequently occur in many types of high-throughput sequencing applications, 2) develop efficient parallel algorithms and high performance implementations for them, 3) pursue mapping to HPC architectures including clusters, multicores, and GPUs, 4) develop software libraries encapsulating these functionalities with the goal of enabling the bioinformatics community to exploit HPC architectures, and 5) design a domain specific language to enable bioinformatics researchers unfamiliar with parallel processing to benefit from this work through automatic generation of parallel codes. The research will be conducted in the context of challenging problems in human genetics and metagenomics, in collaboration with domain specialists.<br\/><br\/>This project is focused on a key capacity building activity to facilitate pervasive use of parallelism by NGS bioinformatics researchers and practitioners. The goal is to empower the broader community to benefit from clever parallel algorithms, highly tuned implementations, and specialized HPC hardware, without requiring expertise in any of these. The software libraries will be released as open source for use, further development, enhancements, and incorporation by the community. The project will provide opportunities for training postdoctoral and graduate students in bigdata analytics and computer science driven interdisciplinary research. Diverse existing mechanisms at the partner institutions will be leveraged to advance goals of minority and women recruitment, undergraduate participation in research, and K-12 outreach.","title":"BIGDATA: Mid-Scale: DA: Collaborative Research: Genomes Galore - Core Techniques, Libraries, and Domain Specific Languages for High-Throughput DNA Sequencing","awardID":"1247701","effectiveDate":"2013-01-01","expirationDate":"2015-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8083","name":"Big Data Science &Engineering"}}],"PIcoPI":["556786"],"PO":["565136"]},"202409":{"abstract":"The NSF CAREER awards program serves a critical role in innovative research and education in the United States by identifying, fostering, nurturing and supporting the nation's most promising and creative junior faculty. Beyond the CAREER program solicitation, the majority of junior faculty members usually have little exposure to NSF, let alone interactions with program directors. Many young professors also have no experience in writing successful grant proposals. The goal of this one-day CAREER Proposal Writing Workshop to be held at the University of Texas at Arlington is aimed to fill this gap. This workshop not only introduces young faculty to the CAREER program but also gives them unique opportunities to network with CISE program directors, former program directors and recent awardees. Major activities of the workshop include presentations on proposal writing, experience sharing, mock panels, and proposal writing clinic. The workshop is open to participants from U.S. national universities including HBCU\/MEI. Indeed, significant effort is made to involve HBCU\/MEI junior faculty into CAREER proposal writing practice, and helps them to become more successful in cutting-edge research and education, thus enhancing their overall research capability to a competitive level. Overall, the workshop is expected to be an invaluable experience for junior faculty as they become successful in their academic careers. By giving priority to participants from under-represented groups, the workshop is expected to make tangible impact to the society. Key presentations and workshop materials are planed to be archived and to be available for download, extending the broader impact of the workshop beyond the one-day event.","title":"2013 NSF CISE CAREER Proposal Writing Workshop","awardID":"1303400","effectiveDate":"2013-01-01","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":["564777","542439",542439],"PO":["564316"]},"193147":{"abstract":"How to best process and forward received signals, or relay, in wireless networks has been an open question for many years. We will revisit determining the capacity of relay networks by taking a fresh look at the problem focussed on understanding the potential of exploiting two types of codebook structure in relay networks: 1) messages received at relays, even those received at rates above capacity, originated from codebooks. This codebook structure should be harnessed in relaying and we seek to determine how to best compress signals coded at rates above capacity; 2) matching codebook structure (e.g. linearity of lattice codes is well suited to linear additive Gaussian noise channels) to channel structure has recently been shown to be efficient in decoding functions of messages. In this thrust, we seek to make precise how and when structured codes may be exploited in multi-source relay networks. Our two approaches both involve novel departures from and additions to our understanding of random coding based schemes. <br\/><br\/> A full solution would constitute a significant step towards the understanding of network information theory, and will provide new insight into the elusive relay channel. However, the significance of solving this problem goes well beyond information theory: understanding how to most efficiently relay in wireless networks is of direct relevance to satiating the demands on WiFi, cellular, ad hoc military and first responder wireless networks of the present and future. The fundamental limit -- or capacity -- of such networks not only acts as a benchmark for engineers building systems, but also provides guidance as to what schemes perform well. The PI will integrate portions of this research into UIC's curriculum and will integrate this theoretical approach with practice through the PI-founded UIC Software Defined Radio lab.","title":"CIF Small Wireless Relay Networks: Coding Above Capacity and Exploiting Structure","awardID":"1216825","effectiveDate":"2013-01-01","expirationDate":"2015-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[517407],"PO":["564924"]},"197813":{"abstract":"Workflows, especially data-driven workflows and workflow ensembles are becoming a centerpiece of modern computational science. However, scientists lack the tools that integrate the operation of workflow-driven science applications on top of dynamic infrastructures that link campus, institutional and national resources into connected arrangements targeted at solving a specific problem. These tools must (a) orchestrate the infrastructure in response to application demands, (b) manage application lifetime on top of the infrastructure by monitoring various workflow steps and modifying slices in response to application demands, and (c) integrate data movement with the workflows to optimize performance.<br\/><br\/>Project ADAMANT (Adaptive Data-Aware Multi-domain Application Network Topologies) brings together researchers from RENCI\/UNC Chapel Hill, Duke University and USC\/ISI and two successful software tools to solve these problems: Pegasus workflow management system and ORCA resource control framework, developed for NSF GENI. The integration of Pegasus and ORCA enables powerful application- and data-driven virtual topology embedding into multiple institutional and national substrates (providers of cyber-resources, like computation, storage and networks). ADAMANT leverages ExoGENI - an NSF-funded GENI testbed, as well as national providers of on-demand bandwidth services (NLR, I2, ESnet) and existing OSG computational resources to create elastic, isolated environments to execute complex distributed tasks. This approach improves the performance of these applications and, by explicitly including data movement planning into the application workflow, enables new unique capabilities for distributed data-driven \"Big Science\" applications.","title":"Collaborative Research: CC-NIE Integration: Transforming Computational Science with ADAMANT (Adaptive Data-Aware Multi-Domain Application Network Topologies)","awardID":"1246057","effectiveDate":"2013-01-01","expirationDate":"2014-12-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8080","name":"Campus Cyberinfrastrc (CC-NIE)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["535329"],"PO":["564246"]},"197814":{"abstract":"This project develops an infrastructure to support managing the transfer and analysis of big data as required by several projects at the University of California at Davis. For example, the Large Synoptic Survey Telescope (LSST) Project will soon produce 30 terabytes of data each night. Scientists at UC Davis examine the data, testing new search and analysis algorithms to find new or unexpected phenomena. This collaborative project requires high-speed connections to the other 22 institutions involved in the project. Similarly, the Genome project and other projects benefit, or will shortly benefit, from the changes being made to the internal networking infrastructure. <br\/><br\/>The project also provides data for campus research groups that study networks. For example, the Robust and Ubiquitous Networking Laboratory and the Computer Security Laboratory use network traffic and performance measurements in their research, and the enhancements to the network enable them to gather this data in ways that do not violate University privacy regulations. Further, the network architecture enables administrative staff to deploy enhanced monitoring capabilities to detect network traffic problems. Support personnel including undergraduates act as a bridge between the research projects using this enhanced network and the network managers, so researchers can obtain the optimum network performance that they need, and the network itself can be tuned as appropriate to minimize overhead.","title":"CC-NIE Integration: Improved Infrastructure for Data Movement and Monitoring","awardID":"1246061","effectiveDate":"2013-01-01","expirationDate":"2014-12-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8080","name":"Campus Cyberinfrastrc (CC-NIE)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["560876","550540",530846],"PO":["564246"]},"196814":{"abstract":"The Howard University Department of Systems and Computer Science proposes the Partnership for Early Engagement in Computer Science High School (PEECS-HS) program. This program partners Howard University with Washington, D.C. Public Schools (DCPS) and Google, Inc. to introduce a new course titled \"Introduction to Computer Science (CS)\" across DCPS high schools. The course will adopt and extend the Exploring Computer Science curriculum, originally piloted in the Los Angeles Unified School District (LAUSD). PEECS-HS will introduce students to the broad range of opportunities in CS, and allow them to develop basic competencies in CS fundamentals, and maintain a positive perception of CS. In addition, the program will produce a new unit on Mobile Application Development, which will be added to the general Exploring Computer Science curriculum. PEECS-HS will prepare in-service and pre-service DCPS teachers to teach the new curriculum. For sustainability, PEECS-HS will prepare in-service teachers to lead future Introduction to CS professional development sessions. As with many urban school districts, DCPS is predominately African-American, an important but often overlooked, component of the U.S. computing workforce. Many of these students exit or never enter the computing pipeline, in part because they often see CS as boring and unrelated to their interests. Introduction to CS aims to change those misperceptions. Adapting the Exploring Computer Science model to this environment will give further insight into mechanisms for attracting and retaining students from underrepresented populations in urban environments.","title":"CS 10K: The Partnership for Early Engagement in Computer Science High School (PEECS-HS) Program: Exposing Students to Computer Science in Washington, DC Public Schools","awardID":"1240822","effectiveDate":"2013-01-01","expirationDate":"2015-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}}],"PIcoPI":["554684","530768","554685"],"PO":["561855"]},"196804":{"abstract":"The Council for Opportunity in Education, in collaboration with TERC, seeks to advance the understanding of social and cultural factors that increase retention of women of color in computing; and implement and evaluate a mentoring and networking intervention for undergraduate women of color based on the project's research findings. Computing is unique because it ranks as one of the STEM fields that are least populated by women of color, and because while representation of women of color is increasing in nearly every other STEM field, it is currently decreasing in computing - even as national job prospects in technology fields increase. The project staff will conduct an extensive study of programs that have successfully served women of color in the computing fields and will conduct formal interviews with 15 professional women of color who have thrived in computing to learn about their educational strategies. Based on those findings, the project staff will develop and assess a small-scale intervention that will be modeled on the practices of mentoring and networking which have been established as effective among women of color who are students of STEM disciplines. By partnering with Broadening Participation in Computing Alliances and local and national organizations dedicated to diversifying computing, project staff will identify both women of color undergraduates to participate in the intervention and professionals who can serve as mentors to the undergraduates in the intervention phase of the project. Assisting the researchers will be a distinguished Advisory Board that provides expertise in broadening the representation of women of color in STEM education. The external evaluator will provide formative and summative assessments of the project's case study data and narratives data using methods of study analysis and narrative inquiry and will lead the formative and summative evaluation of the intervention using a mixed methods approach. The intervention evaluation will focus on three variables: 1) students' attitudes toward computer science, 2) their persistence in computer science and 3) their participant attitudes toward, and experiences in, the intervention. <br\/><br\/>This project extends the PIs' previous NSF-funded work on factors that impact the success of women of color in STEM. The project will contribute an improved understanding of the complex challenges that women of color encounter in computing. It will also illuminate individual and programmatic strategies that enable them to participate more fully and in greater numbers. The ultimate broader impact of the project should be a proven, scalable model for reversing the downward trend in the rates at which women of color earn bachelor's degrees in computer science.","title":"BP: Computing Beyond the Double Bind: Women of Color in Computing Education and Careers","awardID":"1240768","effectiveDate":"2013-01-01","expirationDate":"2015-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}}],"PIcoPI":[527940,527941],"PO":["560704"]},"196816":{"abstract":"Trinity College, in partnership with the Hartford Public School System, the Connecticut Chapter of the Computer Science Teachers Association, and other Hartford area high schools, will train approximately 30 Connecticut high school teachers to teach Advanced Placement (AP) computing courses in Connecticut high schools that currently do not teach AP computer science. The course will be based on a mobile Computer Science Principles curriculum, Mobile CSP, which uses the new mobile computing language, App Inventor for Android, to provide a rigorous, programming-based introduction to computational thinking. The main research question addressed is whether the Mobile CSP curriculum is an effective way to teach CS Principles and whether it can serve as one model to help train teachers for the CS 10K project. The curriculum is project-based and takes a constructionist approach to learning computing -- i.e., students learn through constructing their own artifacts and mental models. Student projects will focus on building socially useful, place-based mobile apps using the App Inventor programming language. In this way, student learning will be associated closely with their interests and grounded in their schools, their homes, and their communities. The curriculum, which was developed and tested at Trinity College and the Greater Hartford Academy of Mathematics and Science (GHAMAS) as one of the Phase 2 pilot courses for the College Board's CS Principles project, will be carefully evaluated along several dimensions, including its efficacy at improving programming and problem solving skills and its impact on student and teacher attitudes toward computer science education. The Mobile CSP project has three main goals: (i) To develop a rigorous computer science principles AP curriculum based on mobile computing; (ii) to teach it to Connecticut teachers in 6-week summer workshops; and (iii) to support participating teachers in their effort to implement the AP pilot courses in Connecticut schools that do not currently teach AP computer science. The 2013-2014 cohort of teachers will be drawn primarily from the Hartford school district, a district whose students come mostly from demographic and socio-economic backgrounds that have been underrepresented in computer science. In years two and three the project will expand to other, similarly situated, Connecticut cities and towns.","title":"CS 10K: Mobile CSP: Using Mobile Learning to Teach CS Principles in Connecticut Schools","awardID":"1240841","effectiveDate":"2013-01-01","expirationDate":"2015-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}}],"PIcoPI":[527969],"PO":["561855"]},"196827":{"abstract":"The University of Alabama (Tuscaloosa) proposes to develop and evaluate a model for the scalable deployment and sustainable persistence of the new CS Principles course across a statewide network of teachers. The model adopts the successful practices of a national Advanced Placement (AP) training program developed by the National Math and Science Initiative (NMSI). It applies those practices in a professional development program based on in-person training and distance learning collaboration. It will provide year-long professional development to support teachers, rather than the week-long summer institutes that are typical of most AP training programs in other STEM areas. A statewide \"Teacher Leader\" model will be explored where those already teaching more rigorous CS courses (e.g., the existing AP CS A) will assist in training new peer cohorts as they establish CS Principles in their schools. Teachers in these cohorts will collaborate together on content and pedagogical learning experiences, fostered by peer leaders and facilitated through A+ College Ready (A+CR), the NMSI partner for Alabama. A+CR has demonstrated success in promoting AP advancement in other STEM areas, especially among students from underrepresented populations. The pedagogical approach will be centered on inquiry\/discovery-based techniques that introduce computer science as a broad set of topics as defined by the learning objectives contained in the Big Ideas of CS Principles. The elaboration of the model will support both rural and urban school teachers through use of virtual collaboration tools (e.g., Blackboard Collaborate or ACCESS, which is a statewide distance learning infrastructure deployed in all Alabama schools). The assessment, led by Haynie Research and Evaluation, will uncover the facets of the proposed model that are most suitable for building a successful and sustainable nationwide network of CS Principles teachers. The participants will include: a cohort of 50 high school teachers who will receive year-long professional development training to teach the CS Principles course; students of those teachers, who will participate in summer camps, weekend study sessions, and statewide competitions; and college students from secondary education and computer science majors who will assist with project tasks. Partners include A+CR and the Alabama State Department of Education, which has committed support and needed resources (e.g., ACCESS) to the project. <br\/><br\/>To address scalability, NMSI will recommend the model developed in this project to six partner states across over 320 high schools (in 2011-2012, NMSI supported 75,000 students). To address sustainability, all teachers will be supported after project completion by A+CR under its operations as a NMSI partner. The results of the project will be submitted for publication in journals, and a Moodle website will be created to serve as a repository for disseminating the results of the project, including developed curricular materials. The PI has conducted one of the College Board's CS Principles pilots and leads several K-12 outreach and broadening participation in computing activities in Alabama.","title":"CS 10K: A Model for Statewide Deployment of CS Principles Courses","awardID":"1240944","effectiveDate":"2013-01-01","expirationDate":"2015-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}}],"PIcoPI":["555863",527999],"PO":["561855"]},"208063":{"abstract":"Machine learning is transforming the way many fields make sense of data, from engineering and science to medicine and business. Machine learning has vastly improved speech recognition, machine translation, robotic navigation and many other prediction tasks. A crucial goal of machine learning is automating intelligent processing of information: this project will focus on automatically describing videos by detecting objects, people, actions and interactions between them, and parsing documents by extracting entities, events and relationships between them. All these prediction tasks require more than just true-false or multiple-choice answers, but have an exponential number of possible answers to consider. Breaking these joint predictions up into independent decisions (for example, translating each word on its own, recognizing a phoneme at a time, detecting each object separately) ignores critical correlations and leads to poor accuracy.<br\/><br\/>Structured models, such as grammars and graphical models, can capture strong dependencies but at considerable computational costs. The barrier to improving accuracy in such structured prediction problems is the prohibitive cost of inference. Structured prediction problems present a fundamental trade-off between approximation error and inference error due to computational constraints as we consider models of increasing complexity. This trade-off is poorly understood but is constantly encountered in machine learning applications.<br\/><br\/>The primary outcome of this project will be a framework for addressing very large scale structured prediction using a novel coarse-to-fine architecture. This architecture will enable explicit, data-driven control of the approximation\/computation trade-off. It promises to drastically advance state-of-the-art accuracy in computer vision and natural language applications and greatly enhance search and organization of documents, images, and video. The PI's plan includes an active role in the machine learning community, disseminating results through tutorials, code and data and organizing workshops.","title":"CAREER: Computation and Approximation in Structured Learning","awardID":"1338054","effectiveDate":"2013-01-01","expirationDate":"2016-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[557470],"PO":["562760"]},"207063":{"abstract":"This research advances the knowledge and capability for securely<br\/>performing general-purpose computation and communication on zero-power<br\/>devices that rely on harvested energy stored in extremely small<br\/>reservoirs such as capacitors. A type of zero-power device,<br\/>computational RFIDs (CRFIDs) harvest RF energy and endure continual<br\/>interruptions to power. Complete loss of RAM on the order of every<br\/>second makes the notion of a computational checkpoint fundamental to<br\/>this model of computing. A significant problem is how to perform<br\/>effective computation and checkpoints in a secure and<br\/>privacy-preserving manner. The most fundamental question is: how to<br\/>securely make forward progress of computation on zero-power devices?<br\/>The exploration of checkpointing strategies that exploit the<br\/>energy-centric properties of computational RFIDs will lay a solid<br\/>foundation for designing secure software and systems for pervasive<br\/>devices. Beyond security and privacy, the research seeks to discover<br\/>what kinds of computational problems can be solved in a practical<br\/>sense on extremely resource-constrained devices. While the<br\/>experiments focus on computational RFIDs, many of the techniques will<br\/>apply broadly to devices with batteries as well.<br\/><br\/>The impact of this work will lead to improved security for computation<br\/>in low-power, untrusted infrastructure. The expected results will be<br\/>published in venues at the intersection of security & privacy and<br\/>low-power computation. Potential applications include improved<br\/>security and privacy for (1) implantable medical devices and (2)<br\/>sensors embedded in concrete components of bridges and roads.","title":"CAREER: Computational RFID for Securing Zero-Power Pervasive Devices","awardID":"1331652","effectiveDate":"2013-01-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[554404],"PO":["565327"]},"208395":{"abstract":"Motorized exoskeletal orthoses are being actively researched today for gait training of stroke patients. These machines are typically designed to apply assistive\/resistive forces on the impaired leg to help human subjects to improve walking, similar to what therapists do during training. While a number of such machines have been developed and used for gait training, these studies have only yielded \"mixed\" results in benefiting stroke patients clinically. The reasons for these disappointing results are the high inertia of the mechanisms, a mis-match in constraints between human and machine, and misalignment of the mechanism joints with the human joints. The proposed work investigates a novel and ground-breaking design of a cable driven exoskeleton to address these shortcomings. Based on extensive study of mechanisms and therapeutic control methods, cables will actuate the moving limbs and will also serve as structural members in tension. The design will consist of an inertial fixed cuff attached to the pelvis and three lightweight cuffs on the thigh, shank, and foot of each leg. This results in an order-of-magnitude reduction in the inertia of the links and eliminates rigid joints which, in turn, eliminates the mis-match and misalignment. Yet, the fact that cables can only pull and not push raises many scientific and design challenges that will be addressed theoretically and experimentally.<br\/><br\/>Broader Impact: Each year, about 700,000 people in the U.S. have an incidence of a stroke and currently there are 4.5 million people in the U.S. living with the after-effects of stroke. This research can directly impact the quality of life of these individuals with potentially better rehabilitative equipment and better rehabilitative results for retraining of their gait. This project will broaden the application of cable-driven robots to the emerging field of \"neuro-rehabilitation\" and \"functional learning.\" This project will also involve close co-operation with Professor Clement Gosselin's research group at Laval University, who along with the PI, is credited with fundamental developments to the field of \"cable robots.\" The project will also encourage undergraduate involvement in research as well as provide training and examples for a high school teacher\/student to incorporate into the local curriculum. The PI has active links with high schools through a college-wide NSF-funded RET program. Several high school teachers and students have worked in the PI's laboratory to identify technologies to improve quality of life of neural impaired subjects.","title":"NRI-Small: A Novel Light-weight Cable-driven Active Leg Exoskeleton (C-ALEX) for Training of Human Gait","awardID":"1339666","effectiveDate":"2013-01-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1632","name":"CONTROL SYSTEMS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0709","name":"Division of BIOENGINEERING & ENVIRON SYSTE","abbr":"BES"},"pgm":{"id":"1385","name":"SPECIAL STUDIES AND ANALYSES"}}],"PIcoPI":[558467],"PO":["564069"]},"209750":{"abstract":"This project is a Computing Research Infrastructure Enhancing Infrastructure (CRI II-EN) project focused on measurement and evaluation of thin clients and ?virtual desktop clouds? (VDCs) at Ohio State University . By transitioning their ?traditional desktops? that have dedicated hardware and software installations to VDCs that are accessible via thin-clients, user communities greatly benefit in terms of user convenience, and cost-savings. However, to allocate and manage VDC resources in a scalable and cost-effective manner, cloud service providers are faced with unique challenges. User workload profiles in VDCs are bursty (e.g., during daily desktop startup, when user switches between text and graphic intensive applications), and thin-client user Quality of Experience (QoE) is highly sensitive to network health variations in the Internet. Unfortunately, existing works focus mainly on managing server-side resources based on utility functions of CPU and memory loads, and do not consider network health and thin-client user experience. Resource allocations without combined utility-directed information of system loads, network health and thin-client user experience in VDC platforms inevitably results in costly over-provisioning of resources, even for as few as tens of users. Also, due to lack of tools to measure the user experience from the server-side of VDCs, management functions in VDCs such as configuring thin client protocol parameters are often performed using guesswork, which in turn impacts user QoE. To address the above research challenges in developing scalable VDCs with satisfactory thin-client user QoE, the PIs have developed a ?VMLab? pilot infrastructure that can support desktop virtualization experiments for research and education communities. Over the last two years, this infrastructure has supported: (a) research and development activities relating to VDC resource allocation and thin-client performance benchmarking, (b) desktop virtualization sandboxes for system administrators, (c) virtual desktops for classroom labs involving faculty and students, and (d) evaluation of the feasibility to deploy computationally intensive interactive applications (e.g., remote volume visualization) in virtual desktops. This project will expand the VMLab infrastructure and enable system measurement and user experience evaluation during productive use. <br\/><br\/>Broader Impact<br\/>The broader impacts of this project include serving high-school students and other users from under-represented groups. The proposed research will explore the potential for using the thin-client computing model to provide high-quality user experience to groups otherwise unable to purchase or maintain a full blown PC. The thin-client model may not only be cost effective in terms of purchase costs (assuming end-users do not have to amortize the cost of back-end infrastructure, which is the case in this scenario), but also has a low steady-state cost due to simplicity of device maintenance and troubleshooting. The area of desktop applications hosted in a cloud is an important and rapidly emerging area (both in academia and industry). The broad dissemination of results will have positive impact in an economically valuable technology.","title":"II-EN: Infrastructure to Support Desktop Virtualization Experiments for Research and Education","awardID":"1347889","effectiveDate":"2013-01-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[562286],"PO":["564993"]},"209563":{"abstract":"This project will develop a programmable sensing and action platform that allows application developers to efficiently and continually capture human activity with minimal deployment cost in support of national priority projects such as energy-saving or health-at-home applications that need to monitor and predict user-activities. The existing GENI-enabled Bismark Router the platform will be the starting point for developing a platform that addresses the large fraction of US citizens that already have a home network. The platform extends the Bismark Router code base to serve as a programmable information fusion device for sensing and actuation. Combined with smartphones and other sensing devices, the resulting system will allow construction of sophisticated applications that rely on continuous and pervasive sensing but which can also use GENI's 'slicing' (network and process isolation) capabilities to provide privacy.<br\/><br\/>The resulting applications platform will enable beneficial actions such as notifying medical emergency personnel, reducing unnecessary power usage, and providing for greater public safety. The PI will disseminate the outcomes of the project via workshops, the first of which is planned for the 15th GENI Engineering Conference in October 2012. In addition, the PI will engage in outreach to under-represented institutions and groups via \"summer camps\". All source code produced as part of this project will be publicly available","title":"EAGER: Personal Information Fusion with In Situ Sensing Infrastructure","awardID":"1346723","effectiveDate":"2013-01-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[561756],"PO":["564993"]},"207243":{"abstract":"Today's computer systems are more powerful than ever, but have become so complex that it is now difficult for programmers to produce high-performance software. Even slight changes in programs or differences in a user's system can cause dramatic slowdowns. Currently, there is no way to guarantee that a program will perform as well as it did during testing. This situation makes it extremely difficult to track down the sources of inefficiencies or repair them. The result is reduced power and computational efficiency on servers, and a degraded user experience on client platforms.<br\/><br\/>This research aims to deliver reliable performance on modern computer systems. By introducing randomness into the way a computer runs programs, a reliably performant system will significantly reduce the probability that any small change will have a large impact on performance. For instance, consider a cache miss caused by a conflict. With standard caches, repeated access to the same elements would always cause misses, degrading performance. In a randomized cache or with randomized object placement, it would be very unlikely for the same line to be repeatedly evicted. The investigators are designing and evaluating the use of both randomized algorithms in software and hardware, separately and in combination, to remedy the numerous sources of pathological behavior in modern systems. The result will enable performance-portable applications that are immune to unfortunate interactions with microprocessor components.","title":"SHF: Large: Collaborative Research: Reliable Performance for Modern Systems","awardID":"1332654","effectiveDate":"2013-01-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}}],"PIcoPI":[554979],"PO":["565272"]},"204670":{"abstract":"This is funding to support travel for a diverse group of U.S. PhD students and distinguished faculty mentors to participate in a doctoral colloquium (workshop) on research on information science that will be co-located with the 2013 iConference to be hosted by the University of North Texas in Fort Worth on February 11-15. The iConferences, the annual meetings of the iSchool community, are a leading forum that brings together faculty, students, research staff, and industry practitoners with a common interest in supporting and augmenting human engagement with information and technology. Open to broad participation, the iConferences have been successful in building a sense of community around the information field, bringing together people who otherwise might rarely interact with one another, and helping them share findings and exchange views relating to their interdisciplinary research. More information about the iConference may be found online at http:\/\/www.ischools.org\/iConference13\/participation, <br\/><br\/>The 2013 iConference Doctoral Colloquium, which will take place on February 15, 2013 (the final day of the iConference), will be a research-focused meeting of about 25 selected Ph.D. candidates studying all aspects of information science (IS), along with approximately 10 distinguished mentors. The primary objective of the Doctoral Colloquium is to help train the next generation of information science researchers. To this end, it will provide the student participants with an environment in which they can share and discuss their goals, methods and results at an early stage of their research. By participating in the doctoral colloquium, students will gain feedback on their work both from the mentors and from other students, which should allow them to enhance their research. Students will also develop a better understanding of the different research communities engaged in the study of information science, and learn how to position their work within the IS community. In addition, the colloquium will provide students with opportunities to make new professional connections beyond their own disciplines. <br\/><br\/>Broader Impacts: The iConference doctoral colloquia traditionally bring together the best of the next generation of researchers in information science and related areas, allowing them to create a social network both among themselves and with senior researchers at a critical stage in their professional development. Participation is encouraged from a broad range of relevant disciplines and approaches, thereby broadening attendees' perspectives on their topics of study and promoting advancement of the field. No more than one student will be accepted from any given institution, and priority will be given to students who have not previously attended an iConference Doctoral Colloquium. The organizers will proactively work to include women and minority representation among the student participants to the extent possible. As a consequence of these steps, the student and faculty participants will constitute a diverse group across a variety of dimensions, which will help broaden the students' horizons to the future benefit of the field.","title":"WORKSHOP: Doctoral Colloquium at the iConference 2013","awardID":"1314331","effectiveDate":"2013-01-15","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[548113],"PO":["565227"]},"200194":{"abstract":"This is an EAGER proposal supported under the SAVI initiative that is conducting research on knowledge organization techniques for visualizing and presenting STEM content digitally so as to engage students and engender deep learning. The PIs are applying the results of their research (in an iterative fashion) toward the development of new presentation, interaction, and navigation techniques for digital STEM content, and then evaluating these digital artifacts in the context of an inquiry-based pedagogy designed around dynamic digital text. In the long term, the team envisions a cloud-based service architecture that allows anytime, anywhere, and as-needed access to dynamic digital content covering an extensive set of topics for school and college level STEM education that is integrated with a proven pedagogy that makes effective use of digital STEM content. Collaboration with researchers in Finland is a key component of this work, as the team is testing its theoretical framework for dynamic digital texts with content in science and computing, for middle school and college, in Finnish and English. As such, this project is a first attempt to systematically evaluate the use and utility -- across multiple content domains, learner levels, and cultures -- of dynamic digital texts founded on concept map-based organizations of domain knowledge. In keeping with the spirit of the EAGER mechanism, this project is exploratory in nature; and while its multi-faceted nature presents risks in execution, there is a potentially transformative payoff to this work in that it can lay an excellent technological foundation for dynamic digital texts of the future.","title":"EAGER: SAVI: Dynamic Digital Text: An Innovation in STEM Education","awardID":"1258471","effectiveDate":"2013-01-01","expirationDate":"2014-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7625","name":"REESE"}}],"PIcoPI":[536668,"203833",536670],"PO":["560894"]},"202152":{"abstract":"This award provides support for the \"Workshop on Task-based Information Search Systems\", to be held March 14-15, 2013 in Chapel Hill, NC with the goal to discuss challenges of designing a new generation of information search systems that go beyond simple searches and can support people in resolving a underlying need or task. While contemporary search engines are good at helping people resolve simple look-up tasks, they are not as useful in helping people engaged in more complex tasks whose resolution might require multiple search sessions and multiple search strategies. Most search environments are tailored to support a small set of basic search tasks and provide searchers with few options to search and interact with information, and little to help them synthesize and integrate information across session. Participants of the workshop, leading researchers in interactive information retrieval from academia and industry will discuss challenges of incorporating task models into systems and tools to support complex, multi-search and multi-session tasks. The goal of this workshop is to enumerate, discuss, and document these issues into a research agenda that can help guide work in this field. Specifically, this workshop is focusing on the following topics: (1) identification, elicitation, modeling and tracking of tasks, processes and states, including the identification of frameworks for conceptualizing task and relevance models; (2) creation of task-specific and task-aware search environments, including the development of interfaces, tools, features, indexing techniques and search algorithms; and (3) development of methods and measures for studying user behavior and evaluating task-based search systems, including session-based measures. <br\/><br\/>The workshop will outline directions for short, mid-, and long-term research, seed interdisciplinary and international collaborations and generate a unified and multidisciplinary bibliography for researchers and students interested in working in this area. Workshop will include junior and underrepresented attendees in order to broaden participation in computer science. Workshop results will be summarized in a report that will be disseminated via the workshop web site (http:\/\/ils.unc.edu\/taskbasedsearch) and various publications. In addition, it is expected that general users of search tools will benefit from resulting advances in technology that will provide better tools and services to support task-based retrieval across multiple search sessions.","title":"Workshop on Task-based Information Search Systems","awardID":"1301958","effectiveDate":"2013-01-01","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[541769,541770,541771],"PO":["563751"]},"209533":{"abstract":"Statistical analysis is key to many challenging applications such as text classification, speech recognition, and DNA analysis. However, often the amount of data available is comparable or even smaller than the set of symbols (alphabet) constituting the data. Unfortunately, not much is known about optimal inference in this so-called large-alphabet domain. Recently, several promising approaches have been developed by different scientific communities, including Bayesian nonparametrics in statistics and machine learning, universal compression in information theory, and the theory of graph limits in mathematics and computer science.<br\/><br\/>The investigators study the problem drawing from these multiple perspectives, but with a particular focus on developing the information theoretic approach. The research studies analytical properties of the \"pattern maximum likelihood'' estimator, which performs well in practice but is not understood theoretically, and also explores computational speedups. Moreover, it attempts to delineate which problem classes are better handled by Bayesian nonparametric techniques and which by the pattern approach, and explores links between these approaches. The investigators use the resulting theory for automatic document classification, allowing for more automation in storing, retrieving, and analyzing data. Furthermore, the investigators use the theory to study genetic variations, whose link with disease diagnosis is a crucial step in the systematic quantification of biology that is playing an increasingly important role in medical advancement. The research also brings new courses to the classroom, with a special outreach effort to involve women and under-represented minorities, including through the Native Hawaiian Science and Engineering Mentorship Program.","title":"CIF: Medium: Collaborative Research: Information Theory and Statistical Inference from Large-Alphabet Data","awardID":"1346564","effectiveDate":"2013-01-01","expirationDate":"2015-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["564929"],"PO":["564924"]},"204596":{"abstract":"The past decade has witnessed numerous developments in technology that can be applied to rehabilitation practice. The biennial International Conference for Virtual Rehabilitation (ICVR) evolved from the desire and need for rehabilitation practitioners to play an integral role in the development and evaluation of new technologies, which incorporate virtual reality (VR) technology. One goal of the conference is to assist engineers who develop the technology to recognize the value they could derive by consulting with rehabilitation professionals in order to make their machine-user interfaces more efficient, user friendly, and effective for specific disabilities. Another goal is to advance translation efforts that bridge the gap between knowledge generation from research and knowledge uptake in clinical practice so that rehabilitation professionals become more comfortable with technology and recognize how to incorporate it into their individualized interactions with patients. ICVR 2013, the 9th conference in the series, will be collocated with the 8th annual Saffran conference entitled \"Virtual Reality Technology and Rehabilitation of Speech and Language Disorders,\" which will focus on virtual reality applications being developed for rehabilitation of aphasia. The joint ICVR-Saffron conference is a 4-day event which will take place August 26-29, 2013, in Philadelphia. A combined attendance of approximately 150-200 at the two conferences is expected from clinical practitioners, scientists, faculty and students with interest in the many disciplines ICVR has historically embraced, such as motor rehabilitation with virtual technology, brain-computer interfaces, rehabilitation robotics, haptic interfaces, novel applications of game consoles, psychological and environmental rehabilitation in virtual reality, cognitive rehabilitation in virtual reality, tele-rehabilitation, balance and gait rehabilitation in virtual reality, regulatory and educational efforts to promote virtual rehabilitation, and sociological, demographic and legal aspects of virtual rehabilitation. More information about the ICVR conference is available online at http:\/\/virtual-rehab.org\/2013.<br\/><br\/>This is funding to promote student involvement and educational initiatives in these conferences. Aside from the usual reduced student registration fees and stipends to assist with hotel and travel costs, four novel events are planned for ICVR 2013, three of which are specifically designed with student and post-doc advancement in mind. First, there will be two moderated poster sessions with one session dedicated specifically to student presenters. Posters will be grouped by topic area with teams of two senior investigators assigned to all posters within a topic area, who will facilitate discussion following a brief presentation by the investigator. Coffee breaks and dessert will be provided during poster sessions to encourage attendance. Second, lunch on Day 3 will be lengthened and held in the room with the commercial exhibitors, who will be encouraged to provide hands-on experiences with their technologies. Third, on Day 4 an oral platform session by graduate students and post-docs will give them the opportunity to present their research; student presentations will be selected by members of the organizing committee based on a written recommendation by the student's mentor and a one-page abstract. (these abstracts will be uploaded as part of the conference proceedings). Lastly, Day 4 will conclude with a panel-led discussion where clinicians, scientists, and technology developers can generate ideas about future promotion of technology transfer into the clinical environment; one student and one post-doc will be invited to serve on this panel. The net result of these innovations is that ample opportunities will exist for students and young investigators to interact with the keynote speakers, established scientists and clinicians throughout the conference. The organizers expect these initiatives will encourage more students to attend, both by reducing financial burden and by rewarding meritorious scientific achievements. <br\/><br\/>Broader Impacts: Raising awareness for science and technology students of the need for their skills in the interdisciplinary field of technology-oriented rehabilitation science is a necessary step to promoting interest in the field. Informing students at the earliest possible stages of their education about the opportunities that will be available to them later will help remove one major barrier to interdisciplinary collaboration, which is student readiness to engage in this type of research. This conference will create a forum whereby students and experts alike can gain interdisciplinary knowledge and develop a common language. Not only will this conference increase the opportunity to form interdisciplinary partnerships, but it will also help bridge any generational gap that exists as we transition from the traditional compart","title":"Combined Cognitive Neuroscience\/International Virtual Rehabilitation Conferences: Student Support","awardID":"1313890","effectiveDate":"2013-01-15","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[547941,547942],"PO":["565227"]},"199250":{"abstract":"Providing seamless, high quality wireless service anytime and anywhere requires substantial structural changes in today's macro-cellular networks. One such change, introducing small cell base stations, is seen as a highly promising solution. However, it requires meeting fundamental challenges: 1) nodes? self-organization, 2) network heterogeneity, and 3) high sensitivity of resource allocation to the system parameters. The proposed research addresses these challenges by exploring a dimension that has often been overlooked: the user's context. To achieve this goal, first, machine learning techniques are proposed to extract context from three dimensions: device, geo-location, and social metrics. Then, context-aware resource management schemes are developed by advancing novel techniques from matching theory - a powerful tool from economics and game theory. Subsequently, the learned context is leveraged to devise cooperative small cell models using new tools from coalitional game theory. Comprehensive evaluation is done via testbed implementation and software simulations. <br\/><br\/><br\/>The developed analytical tools will lay the foundations of context-aware, self-organizing small cell networks and will impact multiple disciplines such as communications, game theory, and social sciences. The generated results will provide fresh ideas for developing new small cell products. The research is fully integrated into the educational plan via incorporation in new and existing courses as well as training students via mentoring, participation in testbed development, and internships at industrial labs. A developed small cell educational tool will foster this integration via new hands-on activities and demonstrations to the community. Specialized outreach activities will contribute to increasing the participation of minority high school students in science and engineering.","title":"CAREER: Towards Context-Aware, Self-Organizing Wireless Small Cell Networks","awardID":"1253731","effectiveDate":"2013-01-01","expirationDate":"2017-12-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0302","name":"Division of ASTRONOMICAL SCIENCES","abbr":"AST"},"pgm":{"id":"1045","name":"CAREER: FACULTY EARLY CAR DEV"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["564874"],"PO":["565303"]},"209766":{"abstract":"Physical (robotic) agents and virtual (software) agents are becoming increasingly common in industry, education, and domestic environments. Although recent research advances have enabled agents to learn how to complete tasks without human intervention, little is known about how best to have humans teach agents or agents teach other agents or even how agents might teach humans. Considering the full matrix of agent\/human learning, in which either an agent or a human can play the role of teacher or student, would increase the potential benefits of leveraging human and agent expertise and knowledge. <br\/><br\/>This project aims to study agent\/human learning in the context of sequential decision-making problems, a class of central importance for real-world agent systems. This project aims to develop a novel teacher\/student framework that integrates autonomous learning with teaching by another agent or a human. The project plans to develop and evaluate a set of core algorithms to allow: (1) agents to teach agents, thus enabling robust knowledge sharing among agents; (2) humans to teach agents, thus allowing humans to share or transfer common sense or domain-specific knowledge with agents; and (3) agents to teach humans, thus helping humans better understand how to perform or recast sequential decision-making tasks already understood or performed by autonomous agents. In all cases, the goal is to develop methods that significantly improve learning performance relative to learning without guidance from a teacher. Issues to be explored include mismatch between teacher\/student abilities, learning from multiple teachers, and shared knowledge representation between teacher\/student. The PI plans to focus on several scenarios, each with different sets of assumptions about the knowledge or skill of the student or teacher and the kind of interaction possible between them (e.g., whether the teacher can tell the student what action to take). The techniques developed in the project will be evaluated in a variety of tests domains and will involve simulations as well as actual robots.<br\/><br\/>The teacher\/student framework will enable agents to teach other agents and humans, as well as integrate autonomous learning with agent and human teaching. Understanding how to best teach agents is of key importance in developing deployable agent systems. The platform- and domain-independent approach incorporates ideas from multiagent systems, machine learning, human-computer interaction, and human-robot interaction communities, and has the potential to impact each of these areas. This work takes a step towards transitioning agents from specialized systems usable only by experts into useful tools and teammates for people without programming expertise. <br\/><br\/>This project has a strong educational component. The PI teaches at an undergraduate college and undergraduate students will play a crucial role throughout the project. Furthermore, the research produced by this project will be incorporated into five of the PI's courses, providing exciting new material to attract and retain computer science majors. The PI will also continue outreach to secondary school students as well as to underrepresented groups via Lafayette College's S-STEM and Higher Achievement programs.","title":"CAREER: A Multiagent Teacher\/Student Framework for Sequential Decision Making Tasks","awardID":"1348109","effectiveDate":"2013-01-02","expirationDate":"2017-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[562335],"PO":["565035"]},"207236":{"abstract":"Microprocessors use devices called branch predictors to predict the near-term behavior of a program so that work on future instructions may begin early, reducing the amount of time the program takes to run. Branch predictors must be highly accurate, and a small improvement in accuracy can give a large benefit for performance. This project is a principled approach to continuing the study of branch prediction. Several new ways to understand and improve branch prediction will be explored:<br\/><br\/>1) Exploring the limits of the potential of branch prediction to improve performance by developing a model of an idealistic branch predictor given reasonable assumptions;<br\/><br\/>2) Improving technologies for running computer programs on real computer systems so that these programs will have better branch prediction accuracy;<br\/><br\/>3) Discovering ways of improving the communication between computer programs and computer systems such that information available to a computer program can be used to improve the accuracy of branch prediction in a computer system; and<br\/><br\/>4) Working on new branch predictor designs for future computer systems, incorporating techniques from other disciplines such as machine learning, i.e., the study of how computer systems can learn by observing data.<br\/><br\/>In each of these areas, technological constraints on branch prediction will be taken into account. In particular, a branch predictor must act very quickly to deliver its prediction in time to improve performance, and it should do so in an energy-efficient way. This research will be brought to the classroom with a special seminar class on the interaction of research into computer systems and research on machine learning.","title":"CAREER: Branch Prediction","awardID":"1332597","effectiveDate":"2013-01-01","expirationDate":"2014-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["554979"],"PO":["366560"]},"198084":{"abstract":"Dynamic Spectrum Access (DSA) technologies have been proposed and researched for 15 years, yet only some relatively experimental systems are in operation today. This research explores some essential but unexplored techno-economic aspects of DSA that are crucial if these systems are to come to commercial reality. One major thrust is an exploration of how substitutable different frequency bands that these systems might use are with each other. Another major thrust is how a firm that might be considering the use of DSA technologies can manage the technical and financial risk inherent in them. To accomplish this, a fungibility score based on mathematical models and agent-based simulations are developed to evaluate the substitutability among spectrum bands to assist firms as well as policymakers in assessing candidate bands for use in a DSA system. For risk management, the project employs real options analysis to develop a set of risk measures and mitigation strategies for technical and financial risk to assist secondary users in DSA systems. This work will help policymakers develop better guidelines for the industry. It will also help firms seeking to use DSA technologies reason more clearly about which technical and financial choices are best and why, providing guidelines for growth and job creation. The expected outcomes of this project will include a set of tools that will enable entrants into a secondary spectrum market to make decisions as well as for policy makers to evaluate the factors that may influence their regulatory guidelines in order to promote viable DSA markets.","title":"Techno-Economic Models of Secondary Spectrum Use","awardID":"1247546","effectiveDate":"2013-01-01","expirationDate":"2015-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7976","name":"EARS"}}],"PIcoPI":[531589,"466424","563662"],"PO":["557315"]},"202682":{"abstract":"This project supports hosting the three day sixteenth edition of the GENI Engineering conference, including organizing and hosting the demo session, to be held on the University of Utah campus. The Global Environment for Network Innovations (GENI) is a virtual instrument that is rapidly emerging in prototype form across the United States. GENI aims to transform experimental research in networking and distributed systems, as well as emerging research into very large socio-technical systems, by providing a suite of infrastructure for 'at scale' experiments in future internets.<br\/><br\/>The GENI Project Office organizes three major GENI Engineering conferences (GECs) per year, in which the entire GENI community meets to review current status, and to decide on subsequent steps in GENI's evolution. These GECs include community-based working groups leading GENI's design and planning, and demonstrating progress with live experiments. About 250 leading researchers and Ph.D. students from diverse US institutions will gather in Salt Lake City to showcase their ideas and results. In the demo session each demo will be provided with a wired connection to the GENI infrastructure. Additionally, wireless connectivity will be available for demonstrations and participants. The GEC 16 conference will be held on the University of Utah campus, with organizational oversight by an experienced University of Utah event coordinator. <br\/><br\/>Broader Impact: <br\/>The GEC meeting and Demo sessions provide graduate students with both an opportunity to demonstrate and explain their work to the GENI community prior to formal publication. It is a key part of helping new graduate students understand what is being done with GENI and who amongst their peers at other institutions might be valuable resources. It also supports outreach to new community members, including the emerging US Ignite community. GENI is already being used as an instrument for research. This project supports the development and use of the research instrument.","title":"The Sixteenth GENI Engineering Conference","awardID":"1304751","effectiveDate":"2013-01-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["559299"],"PO":["564993"]},"207985":{"abstract":"As modern technology infrastructure spreads throughout the world, the quantity of electronic text, written in hundreds of different languages, continues to grow in size and diversity. Building effective information retrieval, extraction, and translation systems across this vast array of languages currently requires time-consuming and expensive linguistic annotations for each language. Generic, fully unsupervised, methods are unlikely to provide a language independent solution to this problem.<br\/><br\/>Focusing on part-of-speech prediction, this project undertakes a novel approach, combining elements of supervised and unsupervised learning without assuming any specific knowledge of the target language. Instead of treating individual languages as closed systems, language-independent \"universals\" are statistically estimated from dozens of languages for which annotated corpora exist, and these learned universals are used to predict the part-of-speech categories of unannotated languages. At the heart of the project is a data-driven exploration of language-independent corpus characteristics that relate cross-lingual linguistic categories to surface statistics of text. These learned patterns are incorporated into expressive structured prediction models using novel approximate learning and inference methods developed by the Principal Investigators of the project.<br\/><br\/>Of the world?s spoken languages, hundreds are at risk of immediate extinction and thousands more are likely to disappear over the coming decades. By facilitating the rapid creation of language-independent linguistic analysis tools, the technology developed under this project has the potential to revolutionize the documentation of endangered languages. In the long-term, this research direction will also help realize the full social benefits of the global technology infrastructure by creating intelligent text processing tools for hundreds of low-resource languages.","title":"RI: Small: Collaborative Research: Statistical Learning of Language Universals","awardID":"1337691","effectiveDate":"2013-01-01","expirationDate":"2014-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["557470",557091],"PO":["565215"]},"207237":{"abstract":"For several decades, computers have been getting faster. Much of this improvement in performance is due to Moore's Law, i.e., the rapid growth in the number of devices that can be integrated into a single microchip. However, techniques that exploit the growing resources provided by Moore's Law are often inefficient and wasteful. This project takes a hard look at techniques used to improve performance, showing how resource-hungry techniques can be made less wasteful. The improved structures use techniques borrowed from other areas of Computer Science to predict the near-term resource usage of the computer to do a better job of allocating those resources. These prediction techniques result in a system that is both more power efficient and better performing.<br\/><br\/>Improvements in power efficiency and performance have a wide-ranging impact, from improving battery life in mobile devices to reducing energy costs and environmental impact of data centers. The project will involve university students in research, helping to train the next generation of technology workers and educators.<br\/><br\/>This project applies microarchitectural prediction techniques to recover wasted resources and thus improve the efficiency of microprocessors. The project explores the following opportunities for reducing waste with prediction: 1) applying highly accurate branch prediction techniques to other domains such as caches, 2) using mixed analog\/digital circuit implementations to improve prediction accuracy while reducing waste in the predictor itself, and 3) developing a set of new confidence estimation techniques and considering their use in a variety of microarchitectural optimizations.","title":"SHF:CSR:Small:Improving Processor Efficiency with Prediction","awardID":"1332598","effectiveDate":"2013-01-01","expirationDate":"2015-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["554979"],"PO":["366560"]},"198184":{"abstract":"This INSPIRE award is partially funded by the Cyberlearning: Transforming Education program in the Division of Information and Intelligent Systems (IIS) in Computer and Information Science and Engineering (CISE), the Research and Evaluation on Education in Science and Engineering (REESE) program in the Division of Research on Learning in Formal and Informal Environments (DRL) in Education and Human Resources (EHR), and the Linguistics program in the Division of Behavioral and Cognitive Sciences (BCS) in Social, Behavioral, and Economic Sciences (SBE). <br\/><br\/>This project addresses the issue of how to help those whose mother tongue is a language that does not include scientific and technological terminology to nonetheless learn STEM content and practices well. While research in linguistics and on how people learn suggests that learning in one's native language will promote deeper learning than learning in another language, no research has specifically been done around this question when the native language does not include scientific and technological terminology.<br\/><br\/>The focus of this project is on the creation and innovative uses of Open Education Resources (OER) for STEM learning at the post-secondary level with Haitian Creole (Kreyol) as the language of instruction. As part of their work, the PI and his team are creating a set of Haitian Creole-based, technology-enabled active-learning resources for STEM higher education in Haiti. Haitian public policy is to teach in French, a distinct disadvantage for the Kreyol-speaking public. In addition, there are few materials, and almost no on-line materials, available in Kreyol that can serve as resources. Interactive materials and resources created at MIT (STAR; Software Tools for Academics and Researchers) are being translated into Kreyol and embedded within the active-learning framework for learning science and engineering created by and used successfully in large classes at MIT (TEAL; Technology-Enabled Active Learning). Professional development materials for TEAL are being translated into Kreyol as part of the project, and Haitian teachers are learning to use an active-learning approach. A variety of fundamental research questions are being addressed, pertaining to (i) the effects, impacts, and challenges of creating opportunities to learn in one's mother tongue, especially when it does not already contain relevant vocabulary (ii) the creation and diffusion of scientific and technical vocabulary in languages without technical words, called \"language engineering\", (iii) technical and socio-technical issues in adapting and incorporating learning technologies into the learning environments of underserved populations.<br\/><br\/>The proposed project crosses goals of NSF programs in linguistics, education, and cyberlearning but does not fit directly into any existing NSF programs. With respect to linguistics, the project makes systematic use of Kreyol in the production of materials and includes substantial language engineering. As such, it is a translational linguistics project, putting knowledge about language structure to work in ways that may raise fundamental new questions for linguistics research. With respect to STEM education, the proposed project promotes large-scale adoptions of proven educational innovations, and its approach (systematic use of the language of discourse of a community) is quite different from other scale-up and dissemination projects. With respect to cyberlearning, the proposed work aims to study impacts of available educational software and other resources on learning and extend the reach of existing well-designed learning technologies. The infrastructure that will be set up may very well provide other researchers opportunities to learn more about personalizing learning for specialized populations. This project aims to bring together what is known across disciplines for positive societal change. <br\/><br\/>In Haiti and other parts of the \"Global South,\" education is offered only in the language of previous colonial powers rather than in the native language of the population. Because the colonial language is not the mother tongue of either teachers or students, most of the population are at a huge disadvantage with respect to STEM learning. This, in turn, contributes to perpetuating the poverty and lack of economic development in these countries. Two hypotheses form the foundation for this project: (1) Better science, technology, engineering, and math education in under-developed countries will lead to better economic development. (2) Education in the language of the community will qualitatively and transformationally improve learning. The investigators are therefore bringing together what is known across the fields of linguistics, education, and learning technologies to develop effective educational materials in the mother tongue of Haitian students and to help teachers learn up-to-date active-learning methodologies for teaching S","title":"INSPIRE: Kreyol-based Cyberlearning for a New Perspective on the Teaching of STEM in local Languages","awardID":"1248066","effectiveDate":"2013-01-01","expirationDate":"2017-12-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"8078","name":"INSPIRE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"1311","name":"LINGUISTICS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7625","name":"REESE"}}],"PIcoPI":["562301",531859],"PO":["562669"]},"205972":{"abstract":"This 1.5 day invitation-only workshop will be held in Washington DC in early 2013, and will address challenges in information sharing and coordination in financial market regulation. Topics to be addressed include the challenges created through the volume and complexity of the data as well as the dynamic relationship between markets, financial instruments, technologies, and institutions involved in the markets and their regulatory processes. Therefore, computational scientists as well as information and social scientists will be included among the participants, and participants from industry, academia, and government will be invited. A workshop report will be published a s a result of this workshop.<br\/><br\/>The 1.5 day invitation-only workshop, to be held in Washington DC in early 2013, will address challenges in information sharing and coordination in financial market regulation. Topics to be addressed include the challenges created through the volume and complexity of the data as well as the dynamic relationship between markets, financial instruments, technologies, and institutions involved in the market and the regulatory process. Experts in computational science, information science, and social science will be invited from industry, academia, and government. The multi-disciplinary approach will increase the likelihood of impact on future regulatory practices.","title":"Information Sharing and Coordination Challenges in Financial Market Regulation: A research agenda setting workshop","awardID":"1321614","effectiveDate":"2013-01-15","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8083","name":"Big Data Science &Engineering"}}],"PIcoPI":[551443,551444,551445,551446],"PO":["565136"]},"200175":{"abstract":"Combinatorial Materials Science represents a potentially powerful approach to identifying new and unexpected materials. This involves the rapid, high-throughput synthesis, measurement, and analysis of a large number of different materials. Understanding the functional behavior of the materials requires a characterization of the structure-property relations. Crystalline structure information can be obtained through X-ray diffraction studies. An unsolved challenge is to develop automated techniques for identification of unique diffraction patterns and to cluster the resulting patterns into contiguous phase fields corresponding to regions with different material composite structures. <br\/><br\/>Intellectual Merit: This exploratory project is aimed at establishing the feasibility of a unique interdisciplinary approach, involving a team of materials scientists and computer scientists, to address the challenge of structure (crystalline phase) identification of the composite materials. Specifically, the PIs propose to extract the key diffraction pattern features from the raw experimental data as a first step towards the development of computational methods for the identification of crystalline phases. <br\/><br\/>Broader Impacts: The project, if successful, will establish the feasibility of a key first step in an overall methodology to significantly speed the materials scientific discovery process in general, and in the search for new materials for the next generation fuel-cell technology in particular. The project brings together faculty and students, providing training in materials science, engineering, and computer science.","title":"EAGER: Exploratory Research in Automated Computational Analysis of Inorganic Materials Libraries","awardID":"1258330","effectiveDate":"2013-01-01","expirationDate":"2014-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["560670","560671"],"PO":["565136"]},"200176":{"abstract":"This project will develop a series of lab exercises comprising a senior-level undergraduate or introductory graduate lab course on fundamental design issues of wireless networks and technologies. Over the course of this lab sequence, students will practice designing, implementing and running wireless experiments using the GENI wireless testbed infrastructure. These labs enable student to learn wireless networks protocols and technologies by working with real systems and evaluating wireless schemes in real conditions, instead of relying on the 'protected' environment of software simulations.<br\/><br\/>Through building protocols on a real platform, students will understand the challenges in the design of wireless systems and the approaches and techniques that are used today, and will become familiar with open research issues in the wireless field. They will learn how to resolve realistic issues and how to design algorithms that work in practical situations.<br\/><br\/>The outcome of the project will be a set of materials (including a lab manual, disk images, experiment scripts, software, and slides) that can be used by academic institutions throughout the US, together with the integrated GENI wireless facilities, to supplement traditional courses on wireless networks with a hands-on lab component. All data generated as part of the proposed effort will be electronically disseminated using the portal of the WiTEST Lab in NYU-Poly and on the GENI.net website. Developed software and results of the lab development will be made available in the open-source format and will be free for academic use. Educational materials will be announced on the web site and will be shared with academic colleagues upon request.","title":"EAGER: Design, Development and Standardization of a New Hands-On Lab Component for use in Wireless Information Systems Courses, based on the GENI Wireless Research Facilities","awardID":"1258331","effectiveDate":"2013-01-01","expirationDate":"2014-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["561994"],"PO":["564993"]},"208834":{"abstract":"Popular applications such as email, image\/video galleries, and file storage are increasingly being supported by ?cloud? platforms in residential, academia and industry communities. The next frontier for these user communities will be to transition ?traditional desktops? that have dedicated hardware and software configurations into ?virtual desktop clouds? that are accessible via thin clients. This project aims to develop optimal resource allocation frameworks and performance benchmarking tools that can enable building and managing thin-client based virtual desktop clouds at Internet-scale. Virtual desktop cloud experiments under realistic user and system loads will be conducted by leveraging multiple kinds of GENI resources such as aggregates, user opt-in mechanisms, measurement services and experimenter workflow tools. Project outcomes will help in minimizing costly cloud resource over-commitment, and in avoiding thin client protocol configuration guesswork, while delivering optimum user experience. Further, they will positively impact computer desktop user communities, GENI-like testbeds, and equipment vendors.","title":"EAGER: Thin Client Performance Benchmarking based Resource Adaptation in Virtual Desktop Clouds","awardID":"1342499","effectiveDate":"2013-01-01","expirationDate":"2013-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["562286"],"PO":["564993"]},"209219":{"abstract":"Compressed sensing (CS) is a rapidly advancing area of signal processing and statistics that has the potential to radically change the way that analog signals are transformed into digital signals. The main idea is to acquire a sparse signal from a very small number of measurements using a specialized sampling and reconstruction process. Since one promising application of CS is medical imaging, improvements in CS systems are also expected to advance real-world healthcare applications. In this project, the investigators will study the fundamental connection between error-correcting codes (ECC) and CS and leverage recent advances in ECC to design improved CS measurement and reconstruction systems.<br\/><br\/>In particular, the connection between linear-programming (LP) decoding of binary linear codes and LP reconstruction will be used to develop a non-asymptotic theory for the design and analysis of CS algorithms and measurement matrices. The first part of the project will focus on novel relaxations of the CS reconstruction problem that allow non-convex regularization and iterative solution. The second part of the project will focus on applying the theory of pseudo-codewords, which was originally developed to understand iterative and LP decoding of binary linear codes, to achieve a non-asymptotic analysis of iterative reconstruction algorithms for CS. The third part of the project will focus on exploiting additional signal structure (i.e., beyond sparsity) that exists in high-contrast imaging applications such as angiograms.","title":"CIF: Small: Collaborative Research: Design and Analysis of Novel Compressed Sensing Algorithms via Connections with Coding Theory","awardID":"1344364","effectiveDate":"2013-01-16","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[560870],"PO":["564898"]},"204533":{"abstract":"Breakthroughs in the decoding of brain activity using microelectrode arrays in non-human primates and humans, and noninvasive electroencephalography in humans, now enable relatively accurate predictions of upper and lower limb movements. As a consequence, peripheral nervous system interfaces are now being developed to reliably control prosthetic limbs. However, translational efforts to bring these technologies to end-users are confronted with important regulatory, scientific, engineering, clinical, ethical, and financial challenges that stakeholders need to better understand. This is partial support for an International Workshop on Clinical Brain Neural-Machine Interface Systems (BMI, for short) intended to identify and discuss current challenges and potential solutions leading to the development and deployment of interface systems based on neural activity in clinical\/home applications. The meeting will be organized by the University of Houston and held at The Methodist Hospital Research Institute (TMHRI) in the Texas Medical Center (Houston), on February 24-27, 2013. The workshop will bring together expert speakers (at both junior and senior levels) and discussants representing the forefront of BMI research, rehabilitation clinicians, neurologists, neurosurgeons, engineers, computer scientists, neuroscientists, program managers at federal agencies, representatives of the industrial sector, end-users and other stakeholders for discussions and interaction in an academic setting with the goal of developing a strategic plan (\"roadmap\") to bring BMI systems out of the lab and into the clinic\/home. Topics to be explored will include: what are the clinical needs and application \"pulls\" that require BMIs (the \"market\"); what is the best approach for uncovering basic mechanisms and validating BMI systems technology; what are the scientific, engineering and regulatory challenges that affect clinical use of BMIs, and potential solutions; what are the needs of patients who could benefit from this co-robot technology; how to address potential ethical concerns regarding the use of BMI systems to enhance the body\/brain; and how to train the next generation of students in neural and rehabilitation engineering.<br\/><br\/>Broader Impacts: A \"roadmap\" summarizing the findings of the workshop will be submitted for peer-review to Frontiers in Neuroprosthetics, a first-tier electronic open access journal devoted to BMI systems. To this end, faculty and graduate students from selected university science writing programs will be invited to blog and write summaries of the group interactions and final group briefings during the workshop; these summaries, edited by the discussants, will serve as drafts of the consensus attained by the participants (minority opinions will also be included). This roadmap will serve as a guide to program managers at federal agencies to develop funding opportunities and support mechanisms to enhance and accelerate the deployment of clinical BMI systems. The workshop organizers will actively recruit participants from under-represented groups, including women and minorities, and across institutions, to ensure that their voice is heard.","title":"2013 International Workshop on Clinical Brain-Neural Machine Interface Systems","awardID":"1313620","effectiveDate":"2013-01-01","expirationDate":"2013-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[547729],"PO":["565227"]}}