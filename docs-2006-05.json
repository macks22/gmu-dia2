{"116457":{"abstract":"ABSTRACT<br\/>0612879<br\/>Mary Beth Rosson<br\/>PA St U University Park<br\/><br\/>DIS 2006 DOCTORAL CONSORTIUM<br\/><br\/>The Doctoral Consortium at the ACM DIS Conference (the ACM Conference on Designing Interactive Systems) in University Park, Pennsylvania (June 25, 2006) will bring together ten dissertation-stage doctoral students researching design analysis, design representations, design methods, design rationale capture, presentation and use, innovation in design, and tools and environments for designing interactive systems for<br\/>two days of presentations and interactions with a panel of four faculty members. The students will come from both the US and abroad, and represent a variety of DIS subfields. The DIS Doctoral Consortium, which was held at previous DIS Conferences in 2002 and 2004, has been successful in providing a forum for the initial socialization into the field of young doctoral scholars. This project provides support for the registration, travel, and lodging of the students as well as the operational expenses of running the Doctoral Consortium at the DIS 2006 meeting. <br\/>Intellectual Merit:<br\/>The focus of the DIS Doctoral Consortium is the students doctoral dissertation research. Because the students are selected chiefly on grounds of research excellence, this research represents the state-of-the-art in research on designing interactive systems. The Doctoral Consortium provides an opportunity both for these projects to be shaped and improved through intellectual exchange as well as for the students to present and communicate the character of their work to a key group of their peer professionals.<br\/>Broader Impact:<br\/>The DIS Doctoral Consortium brings together the best of the next generation of researchers in the design of interactive systems. This allows them to create a social network both among themselves and with several senior researchers, which plays a major role in their enculturation into the profession. This is particularly critical for PhD students in the DIS area, which is highly interdisciplinary. Because the students and faculty are a diverse group on several dimensions (scientific discipline, research specialization, academic background), the students horizons are broadened at a critical stage in their professional development.","title":"Doctoral Consortium for ACM DIS 2006: Designing Interactive Systems","awardID":"0612879","effectiveDate":"2006-05-01","expirationDate":"2007-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7372","name":"ITR-SCIENCE OF DESIGN"}}],"PIcoPI":["549540"],"PO":["564388"]},"119735":{"abstract":"Workflows have recently emerged as a paradigm for conducting large-scale scientific analyses. The structure of a workflow specifies what analysis routines need to be executed, the data flow amongst them, and relevant execution details. These workflows often need to be executed in distributed environments, where data sources may be available in different physical locations and the steps may have execution requirements calling for high-end computing and memory resources at remote locations. Workflows help manage the coordinated execution of related tasks. They also provide a systematic way to capture scientific methodology and provide provenance information for their results. Yet, robust and flexible workflow creation, mapping, and execution are largely open research problems.<br\/><br\/>Scientific workflows present new challenges over business workflows and other kinds of process models. They typically use very large, distributed data sets, employ computationally intensive tasks, and require high-end and distributed computing technology. They are also often iteratively and interactively designed, since that is the nature of the scientific exploration and analysis process they reflect. On the other hand, scientific workflows also have simplified requirements in terms of their data flow structure, execution management, or security\/privacy constraints. Currently, scientific workflows are mostly designed without formal principles and are rarely optimized, scalable or reusable.<br\/><br\/>The aim of this workshop is to bring together IT researchers and practitioners as well as domain scientists. Application scientists will be asked to describe requirements and desired new analyses and computations that are not possible with today's technologies. IT researchers will be asked to identify problems in their specific areas of expertise. Discussions will focus on four main topics: (1) applications and requirements; (2) dynamic workflows and user steering; (3) data and workflow descriptions; and (4) system-level management to support large-scale workflows. <br\/><br\/>The outcome of the workshop will be a report outlining research directions and activities that will bring the needed communities together to work on producing a new paradigm for scientific workflows. Easy-to-use tools for building efficient, scalable and reusable scientific workflows are likely to bring benefits to many fields, and can raise the pace and quality of research work in many areas. <br\/><br\/>The workshop Web site (http:\/\/vtcpc.isi.edu\/wiki) provides further information about the workshop and will be used for disseminating the workshop report and other results.","title":"NSF Workshop on Scientific Workflows Challenges (WSW-06)","awardID":"0629361","effectiveDate":"2006-05-01","expirationDate":"2009-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["535329","563687"],"PO":["563751"]},"112486":{"abstract":"This project, acquiring and deploying infrastructure for several data-intensive stream processing applications, supports the following core projects:<br\/><br\/>-ETL: High-performance data warehouse load and maintenance strategies using innovative memory-resident pipelined processing techniques;<br\/>-D-CAPE: Continuous stream processing technologies supporting on-line plan adaptation and optimization strategies coordinating run-time query workload re-distribution versus disk spilling; <br\/>-RAINDROP: Scalable Xquery processing over XML streams offering novel advances in automata-style processing, in stream-specific multi-query optimization, and in XML-specific load shedding.<br\/><br\/>With expectations of break-throughs in scalable stream handling, the work impacts applications that require real-time stream monitoring, such as monitoring for changes in environmental conditions (e.g., smoke in buildings, medical conditions that require attention or medication, and critical military government, etc.). The project also deals with the challenges and opportunities raised by portable computers, wireless communications, and high bandwidth, environments where high volumes (in the order of tera-bytes) of stream data sources may be present anywhere and at any instant.<br\/><br\/>Broader Impact: The infrastructure enhances the integration of research and education. WPI is known for its project-oriented undergraduate education, where all undergraduates must conduct a year-long senior level research project, the Major Qualifying Project (MQP). The cluster services these students as well as the faculty, and graduate students.","title":"CRI: High-Performance Infrastructure for Data-Intensive Stream Processing Technologies","awardID":"0551584","effectiveDate":"2006-05-01","expirationDate":"2009-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["543520","355586","467660"],"PO":["535244"]},"119516":{"abstract":"This exploratory research seeks to demonstrate that new approaches to<br\/>Automatic Speech Recognition (ASR) and Machine Translation (MT) permit<br\/>automatic, real-time translation well enough for emergency triage. In<br\/>any major disaster, such as a hurricane, there will be a huge number<br\/>of 9-1-1 emergency calls in a short period of time; many will be in<br\/>languages other than English. Even in the best of times, there is a<br\/>chronic shortage of translation for triage of non-English calls at<br\/>many U.S. 9-1-1 centers.<br\/><br\/>For emergency triage, full recognition and translation are<br\/>unnecessary; only the type of emergency and relevant details, such as<br\/>location, need be recognized. Nevertheless, new advanced ASR methods<br\/>are needed to handle the difficult characteristics of non-English<br\/>9-1-1 calls, which contain emotionally-distressed speech in noisy<br\/>environments and may include English phrases mixed in with the other<br\/>language. For ASR, the exploratory system uses multilingual acoustic<br\/>models enhanced by articulatory features, and multilingual grammars<br\/>combined with n-gram language models, to recognize speech. As for MT,<br\/>the exploratory system only classifies the ASR outputs into ``Domain<br\/>Actions'', categories relevant to triage such as ``Request-Ambulance''<br\/>or ``Report-Flooding''. The exploratory system works with Spanish,<br\/>but the approaches used are applicable to any language, and<br\/>transferable to other task domains.<br\/><br\/>Demonstrating the feasibility of speech translation technology for<br\/>serving 9-1-1 call centers should enable follow-on projects to better<br\/>serve all non-English speakers during major disasters. We expect to<br\/>make the resulting transcribed and annotated speech corpus available<br\/>for other researchers.","title":"NineOneOne: Exploratory Research on Recognizing Non-English Speech for Emergency Triage in Disaster Response","awardID":"0627957","effectiveDate":"2006-05-01","expirationDate":"2008-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["396893",316983,"338010"],"PO":["565215"]},"117338":{"abstract":"The PIs will develop a comprehensive solution for protecting identity and protecting consumer-computing resources under the viral threat model (VTM). The PIs will take a three-pronged integrated approach to develop: 1) a non-tamper able, non-programmable hardware-device with secure I\/O with human in-the-loop control for personal identity management; 2) an autonomous non-tamper able hardware security core with secure I\/O for root kit detection, recovery, and hierarchical trust management; and 3) a virtual memory based autonomous security kernel for systems which lack hardware support.<br\/><br\/>This proposed research would make consumer computing and personal financial transactions safer.","title":"CNS-SGER Integrated Security Infrastructure for Personal Identities and Consumer Computing","awardID":"0617671","effectiveDate":"2006-05-01","expirationDate":"2008-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["448647","535238","401065"],"PO":["402055"]},"110573":{"abstract":"CCF-0541169 <br\/>PI: Bertacco, Valeria <br\/>Institution: University of Michigan Ann Arbor <br\/>Title: Design Methodologies for Defect-Tolerant Computing Systems <br\/><br\/>The proposal focuses on the development of computing systems capable of tolerating a moderate to medium number of defects in the silicon hardware. Silicon defects are a pressing problem for hardware parts, mainly because of the shrinking of transistors sizes down to a few tens of nanometers. The proposal attacks this goal from a few angles: first it develops a framework for the analysis of the impact and exposure risks associated with a range of silicon failures. In this context, the types of failures analyzed are: 1) soft-errors, that is, transient faults due to energy particles present in the atmosphere, which are estimated to be relevant for silicon technologies in the next few years; 2) manufacturing defects due to the imprecision of manufacturing small scale transistor parts; and 3) wear-out failures, due to the weakening of transistors as they approach nanometer sizes. The second goal of the proposal develops software to support the analysis and evaluation of a range of potential future scenarios, which include these types of failures. <br\/><br\/>Finally, the third goal of this proposal develops two experimental microprocessor designs which explore two solutions points in the resilient systems design space: one design can sustain a medium to high level of defects, while the other can sustain only the first failure but with a minimum cost and performance impacts.","title":"Design Methodologies for Defect-Tolerant Computing Systems","awardID":"0541169","effectiveDate":"2006-05-15","expirationDate":"2010-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["309179","517965"],"PO":["562984"]},"111376":{"abstract":"Future microprocessor chips will contain numerous computational cores, large cache hierarchies, and complex on-chip networks between cores and cache banks. For an application to exploit a processor's peak throughput, it will have to necessarily be composed into many threads. As part of this project, the curriculum at Utah will be revised so that graduating students have the skills to write efficient multi-threaded programs that can harness the compute power in future processors. When multi-threaded applications execute on a chip, different threads and data transfers make varied demands on the hardware in terms of speed, bandwidth, power, reliability, etc. By optimizing specific cores and networks on the chip for different metrics, the hardware can meet the diverse needs of software. A processor that packs in heterogeneous functionalities and device characteristics will likely allow processor throughput to continue its steady rise while not compromising reliability or power-efficiency. This project explores the effect of optimizing on-chip networks for either speed, bandwidth, or power. It also explores the effect of customizing cores to execute the operating system, redundant threads, or speculative threads.","title":"CAREER: Exploring Heterogeneity Within Chip Multiprocessors","awardID":"0545959","effectiveDate":"2006-05-01","expirationDate":"2011-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["556789"],"PO":["559883"]},"119529":{"abstract":"This project is a pioneering effort to collect data about Massively Multiplayer Online game players, their actions, attitudes, social networks, and economic activities. People increasingly conduct major parts of their lives in virtual worlds: online spaces where large numbers of users are able to congregate, interact, play, and socialize. Most of these worlds are built as competitive games, and are termed Massively Multiplayer Online games (MMOs). Best estimates indicate in excess of five million North Americans now interact in these worlds, with more than 20 million worldwide. Yet while the serious study of virtual worlds has begun in earnest, it is hamstrung by the absence of systematic data. No research project has been conducted with a representative sample, access to server-side data, or the cooperation of game administrators. However, this project has secured the cooperation of a large game developer, which has agreed to release its in-game data as well as help coordinate a survey instrument of its players. The resulting data set will thus be the first comprehensive study of virtual world behaviors, and will contain a rare combination of both unobtrusive behavioral data with standard attitudinal, demographic and psychographic measures.<br\/><br\/>This data set must be properly collected, cleaned and organized in order to facilitate access by a wide range of researchers. Thus the initial effort will involve programming innovations, cleaning and hosting tasks, as well as the creation of new algorithms for several social science tests. The first three areas to be tested will be social networks, social capital, and economic activity. In each area, the dataset will be a testbed for examining theories in ways that were previously impossible, while also offering several programming and analysis challenges relating to dealing with a massive and comprehensive dataset. For example, social networks tested with multi-theoretical multilevel (MTML) models have generally been small due to the difficulty of collecting complete datasets on groups, yet the current project will offer thousands of complete groups of sizes ranging from two to 2,000, with complete behavioral data over a 16-month time window. For research into the social implications of online worlds, the data offer tests of the cyberbalkanization hypothesis, new media isolation hypotheses and explorations of virtual communities. The dataset also offers the ability to do something never yet done in economic analysis: generate a time series of an entire economy. The wealth of data will require the creation of indices, new metrics and new ways of interpretation.<br\/><br\/>This project has no precedent in social science, both because virtual worlds have not yet been studied systematically, and because it combines attitudinal data with previously unattainable levels of unobtrusive behavioral data. The project allows for both methodological ground breaking as well as innovative theory testing. The research will require the creation of new techniques bridging the domains of both computer science and social science. These new methods will be valuable for future scientific research, for improving the games themselves, and for exploiting the educational potential of virtual worlds.","title":"Collaborative Research: Instrumenting Behaviors and Attitudes in Virtual Worlds","awardID":"0628036","effectiveDate":"2006-05-01","expirationDate":"2007-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["532398","348394"],"PO":["564456"]},"110553":{"abstract":"Proposal number: 0541087<br\/>PI: Phyllis Gail Frankl<br\/>Polytechnic University of New York<br\/><br\/>TITLE: Test Generation and Coverage for Database Applications<br\/><br\/><br\/>Database application programs play a central role in our information based society. Given the ubiquitous and, in many cases, critical nature of these systems, testing whether they behave correctly is of great importance. Until recently, there has been little research focused on how to do this effectively. This research project aims to enhance and evaluate a set of testing techniques for database applications.<br\/><br\/>Challenges in testing such systems include the large number of database states that must be considered and the need to check whether applications modify the database state correctly. This research builds on previous work, in which tools were developed to generate database states suitable for testing, generate inputs to the application, and check the results of executing the application on those inputs. The first phase of the research <br\/>focuses on improving the input generation technique, further automating analysis of the application code, and developing new measures of test data adequacy. The second phase focuses on empirical evaluation of how <br\/>effectively these techniques detect faults in database applications.","title":"Test Generation and Coverage for Database Applications","awardID":"0541087","effectiveDate":"2006-05-01","expirationDate":"2011-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["528387"],"PO":["564388"]},"112500":{"abstract":"The principal investigators at the University of Virginia will develop a community resource toolset for early design stage thermal modeling of VLSI designs. Thermal limits are widely cited by industry as a severe limit on future VLSI design capabilities. Efforts to reduce scale, increase transistors and functionality increase thermal loads while increasing power leakage, faults, and electrical usage. This project will develop tools for the pre-RTL design stage where there is the greatest opportunity to address space and time characteristics of computation, packaging and cooling choices and interactions with other components. Users will be able to model full systems; tools will be validated, allow for flexible connections with each other as well as system simulators; and they will support rapid learning. The tools will enable a broad research and education community to participate in power-aware architecture studies. The tools will build on Virginia's existing chip modeling capabilities. Broader impacts include providing new research and education infrastructure to a wide community or researchers and educators, supporting the education and training of engineers who can solve these pressing problems in industry, and an outreach program for women, minorities, and high school students.","title":"CRI: Comprehensive, Pre-RTL Architectural Thermal Modeling","awardID":"0551630","effectiveDate":"2006-05-15","expirationDate":"2011-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[297773,"560683","489873","325247"],"PO":["565272"]},"112511":{"abstract":"This project, establishing a security laboratory, called SecLab, provides a computing cluster for supporting large-scale computation needs in security and crypto research, a heterogeneous lab environment for security research, and a safe environment to experiment with hostile software. The infrastructure supports a mix of established and new research. Grounded in cryptography, formal methods, complexity theory, operating systems, networks, and programming languages and compilers, the research couples strong theory with experimental research in programming language and systems, algorithms, and model checking. The projects are aimed at providing a strong set of the well-grounded protections necessary for computer security. Addressing the issues raised by the President's Information Technology Advisory Committee (PITAC) in a report entitled Cyber Security: A Crisis in Prioritization, SecLab supports experimental research in:<br\/><br\/>-High speed cryptography so that all communications over the Internet can be protected from modification by an attacker;<br\/>-Cryptanalysis to increase understanding of the strength of cryptographic protections;<br\/>-Authorization models to protect against hostile software, hackers, and insiders; and<br\/>-Distributed authentication to support safe computing involving multiple organizations.<br\/><br\/>Broader Impact: Broader impacts include providing much needed computer security research in a broad range of areas; educating and training students in an area where there is shortage; developing courses and materials; producing and making available needed software, and increasing the ability for outreach to the community on security issues. Additionally, helping others to replicate some courses and set up similar labs, findings are shared with the general research community.","title":"CRI: The SecLab at UIC","awardID":"0551660","effectiveDate":"2006-05-15","expirationDate":"2010-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["362818","438703","528421","548359","532213"],"PO":["493916"]},"110422":{"abstract":"Southeastern Oklahoma State University (SOSU) proposes an alliance with the Choctaw Nation, and 10 regional high schools that aims to engage, recruit, and retain Native American\/Choctaw post-secondary students in computing. 80,000 members of the Choctaw Nation live in a rural area of 15,000 square miles, many of them in extreme poverty. SOSU is the only accredited, 4 year college in the area, and though it serves many Choctaw students, few are enrolled in the CS\/CIS programs and even fewer graduate from them (typically just 1 or 2 a year). This project focuses on high school students and assists them in pre-college preparation and the transition to college. Its centerpiece is a 2-semester, dual-credit, concurrent enrollment course in computer fluency and basic computer science concepts. The course will be free to participants. Due to the large distances between high schools and the university, the course will be taught in a hybrid manner, utilizing both face-to-face and online instruction. The face-to-face piece will be done by local teachers trained by SOSU staff; the online piece will be done by SOSU adjunct faculty. Orientations for students will involve their parents, extended family members, and tribal elders; monthly newsletters will help to maintain interest. As an added incentive, each participating high school will be given up to 10 computers for a distance learning lab, providing the only access to modern technology for many of these students. To further entice the students, the program will include Microsoft Office Software certification. Thus, participating students will get a marketable skill along with strong grounding in basic CS concepts, instruction on career opportunities, training in academic skills, experience on a web-based project, and mentoring. A Choctaw Native working with the program will provide an accessible role model. The program was developed in cooperation with the Choctaw Nation. Choctaw students who successfully complete the program will be eligible to receive a $2000 year-long scholarship provided by the Nation if they enroll at SOSU in CS\/CIS.","title":"SOSU and Choctaw Nation Alliance - Project IMPACT! to Broaden Native American Participation in Computing","awardID":"0540456","effectiveDate":"2006-05-01","expirationDate":"2009-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7584","name":"ITR-BROADENING PARTICIPATION"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[292510,292511],"PO":["561855"]},"118848":{"abstract":"The award will support a workshop to develop a roadmap for creating regional and national language archives and the tools to achieve these aims. The Digital Tools Summit for Linguistics, http:\/\/www.ku.edu\/pri\/DTSL\/ is a workshop on digital tools and cyberinfrastructure development in linguistics, to bring together trusted repositories such as national libraries as well as major corpus research institutions, language software engineers, computational linguists, and linguists. The workshop, to be held June 22-23, 2006, at Michigan State University, aims to facilitate new interdisciplinary collaboration to design and create digital tools specifically for linguistic analysis. During the workshop, participants will prioritize and design tools and data structures within working groups (e.g. in data annotation, migration, visualization, and resource interoperation) and will prepare design sketches of and implementation plans for at least one tool. A special goal of the workshop is to address the needs of non-technologically-oriented language researchers, simulating the development of truly useful, stable, cross-platform open-source tools. The participation of Indigenous\/First Nations language workers and graduate students is particularly encouraged and will be subsidized through this funding from the NSF programs in Linguistics and in Human Language & Communication.","title":"Conference:DT-Summit\/Linguistics: Proposal for a Tool Development Workshop","awardID":"0624048","effectiveDate":"2006-05-01","expirationDate":"2008-10-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"1311","name":"LINGUISTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7274","name":"HUMAN LANGUAGE & COMMUNICATION"}}],"PIcoPI":["475470"],"PO":["564500"]},"110599":{"abstract":"Current technology trends predict continued transistor shrinking but less improvement in switching speeds and energy efficiency. These trends have led industrial and academic computer architects to abandon their traditional staples of single-thread performance and high-clock rate designs and to rally around multi-core designs as the best hope for continued exponential improvements in performance and power efficiency. Traditional multi-core designs are effective at providing throughput for workloads with abundant explicit thread-level parallelism, but the vast majority of current programs have few or no explicit programmer-visible threads and thus do not observe substantial benefits. <br\/><br\/>This proposal describes ON-Core (short for Operand Network Core and pronounced \"encore\"), a new multi-core design that provides increased single-thread performance by the transparent aggregation of multiple cores. Inspired by both the pioneering speculative multithreading work and recent advances in the scaling of traditional single-core designs, ON-Core abandons the philosophy of adding only minimal speculative multithreading hardware support to an existing multi-core design. Instead, ON-Core uses a new microarchitecture that is specifically designed to support segmentation\/aggregation. An ON-Core chip can flexibly act as either a traditional multi-core for high multithreaded throughput or as a tightly integrated speculatively multithreaded multi-core that provides high single-thread performance without compiler support.","title":"ON-Core: Single-thread Performance via Multi-core Aggregation","awardID":"0541292","effectiveDate":"2006-05-01","expirationDate":"2009-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["451152","556655"],"PO":["550859"]},"110589":{"abstract":"The PIs proposes to bring Granite data management technologies to Grid computing to allow scientists with modest resources to work directly with n-dimensional datasets that are far too large to be stored locally.<br\/>The size of scientific data sets has grown explosively in recent years, presenting new challenges for researchers and educators without local access to high performance computing resources. The vast majority of researchers cannot store datasets such as Sloan Digital Sky Survey (15 Terabytes) or Visible Woman dataset from the National Institutes of Health on local machines, but networked access to a remote data server can make valuable data available to a large number of scientists. <br\/><br\/>One of the problem areas of Grid Computing environments is a lack of tools for efficient access to multidimensional data. Currently, grid support for multidimensional data sets is largely provided using underlying scientific data APIs such as HDF5, and only recently has work begun on ways of querying remote sources of data within a multidimensional paradigm. <br\/><br\/>Intellectual Merit: <br\/><br\/>The proposal improves prefetching in environments with regular data and data access patterns by having applications encode their I\/O patterns using iterators and then leveraging iterators to direct prefetching. This is a mixed approach that lies between compiler directed prefetching and predictive prefetching based on workload access patterns. <br\/>The ability to extract knowledge and even to visualize the enormous amounts of data being produced daily through both observation and simulation is central to the promise of Grid computing. This capability could have significant impact on both research and education in a variety of fields, including Physics, Engineering, Medicine, and Earth Science. <br\/><br\/>Broader Impact <br\/><br\/> This project will provide support for three graduate student positions over three years. It is likely that this project will involve students from under-represented minority groups. Students will gain important research and development experience in a cutting-edge area of Computer Science. They will also attend conferences and workshops to present their own work, see the work of others, and build connections with their future colleagues.","title":"DCS: Iteration Aware Prefetching for Remote and Grid Computing Applications","awardID":"0541239","effectiveDate":"2006-05-15","expirationDate":"2012-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["396976"],"PO":["565272"]},"110568":{"abstract":"ABSTRACT<br\/>0541150<br\/>Steven Levitan<br\/>U of Pittsburgh<br\/><br\/>Physical phenomena in nature are inherently nonlinear. However, most techniques used by engineers to model and analyze these complex interactions are based on linear approximations. Until recently, these approximations were acceptable for most engineering applications. However, we are now forced to rethink this approach due the fact that emerging micro- and nano- technologies have lead to systems that are complex, with many degrees of freedom, and highly nonlinear behavior. For example, consider the design of lab-on-a-chip type systems, which use micromechanics and optoelectronics to manipulate and analyze the behavior of complex fluids. These systems could revolutionize the way that bio-chemical synthesis and analysis are performed. However, they are inherently difficult to design because they involve interacting electronic, optoelectronic, fluidic, thermal and mechanical sub-systems. On the one hand, such multi-technology systems can only be accurately modeled with formulations that have many degrees of freedom and also capture the nonlinear characteristics of the underlying physics; and these models are necessarily computationally expensive. On the other hand, to effectively design such systems, it is necessary to simulate and analyze their behavior over a broad range of stimuli in a realistic operating environment. This requires models that can be simulated efficiently in order to explore the range of behaviors that they exhibit, in an engineering product design flow.<br\/>Consequently, it is essential to have a methodology to reduce the complexity of nonlinear systems of high dimensionality, without recourse to linear approximation, since only such a solution will give an accurate description for ever increasingly complex micro- and nano- multi-technology systems. To address these needs, this research will develop a methodology for extraction of nonlinear behavioral models.<br\/>The results of this work will lead to a general methodology for nonlinear model order reduction. Such methodologies are essential for reducing design costs and increasing both quality and reliability of multi-technology micro systems. Having accurate compact models that can be efficiently simulated will enable the robust design of complex heterogeneous systems that span multiple energy domains. This methodology will be broadly applicable not only to electronic systems design, but also to emerging technologies at the confluence of engineering and physical sciences, such as nanotechnology based sensors, smart materials and systems biology.","title":"Nonlinear Model Order Reduction for Behavioral Models of Emerging Technologies","awardID":"0541150","effectiveDate":"2006-05-01","expirationDate":"2010-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["560649","549458"],"PO":["562984"]},"119808":{"abstract":"This award supports a workshop on New Research Directions in High Confidence Soft-ware Infrastructure for future Distributed Real-time and Embedded (DRE) systems. The workshop is co-located with the Object Management Groups Workshop on Distributed Object Computing for Real-time and Embedded Systems on July 10-13, 2006. This workshop contributes to a study by the National Coordination Office (NCO) for Networking and Information Technology Research and Development (NITRD), and its High Confidence Software and Systems (HCSS) Coordinating Group, and is co-funded by the NSF and HCSS agencies. The workshop focuses on High Confidence Software Infrastructure for assured, networked\/distributed, real-time, embedded systems. The purpose of the workshop is to bring together key representatives from academia, industry, and government to identify research needed for the development of a next-generation real-time technology base, one that can address the growing needs for highly-automated and dynamically-configured networked embedded sensing and control systems of the future.","title":"CSR-EHS: Real-Time and Embedded Systems Workshop","awardID":"0630133","effectiveDate":"2006-05-01","expirationDate":"2008-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"T366","name":"NSA-SOFTWARE VERIFICATION & HI"}}],"PIcoPI":["534923"],"PO":["561889"]},"110624":{"abstract":"Multicore and multithreaded processors are replacing single-threaded processors in high-performance computer clusters, servers, workstations and high-end personal computers. The memory demand of those processors increases proportionally with the degree of multithreading. The proposed research aims to alleviate the memory bandwidth pressure by using new methods of memory access scheduling and by adjusting multithreaded execution in accordance with memory bandwidth pressure. A set of interdependent and complementary approaches are proposed: Urgency and confidence levels of memory accesses are used to guide the memory access scheduling; memory load index is used to control the progress of multithreaded execution; memory accesses from multiple threads are smoothed out to avoid bandwidth congestion; and several prediction-based techniques are proposed to reduce cache miss penalty in deep cache hierarchies. All together, both the processor computing power and the memory bandwidth will be better utilized; and higher system throughput can be achieved. The proposed research will help high-performance computing applications benefit from the emergence of highly multithreaded processors by alleviating the crucial bottleneck of off-chip memory bandwidth. It will also deepen the understanding of complex interactions between highly multithreaded processors and their memory subsystems, which will complement education in computer architecture and parallel computing.","title":"Collaborative Research: Memory Access Throttling for Highly Multi-Threaded Processors","awardID":"0541408","effectiveDate":"2006-05-01","expirationDate":"2010-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["432712"],"PO":["559883"]},"110558":{"abstract":"Today's society highly depends on portable digital devices such as cell phones, PDAs, laptop computers, MP3 players, digital cameras\/camcorders, etc. Battery life is one of the major concerns when using these devices. Caches have accounted for a significant fraction (30-60%) of the overall CPU chip dynamic and leakage energy, and tomorrow's computer systems will use even larger caches which will consume more power. Thus lowering the power-consumption of a cache system is an important research topic. Set-associative caches are commonly used because they incur fewer misses than direct-mapped caches. One the other hand, they typically have slower hit times and higher power consumption, because multiple tag and data banks are probed in parallel. The goal of this project is to examine address affinity and partial comparison information which can be used to reduce operational cache set-associativity, thus save cache access energy and some times even access latency. Two new cache architectures will be studied to significantly reduce the dynamic power consumptions for set-associative caches. Other research topics include new fault models, test methods, and fault-tolerant designs for cache memories that implement low-leakage power dissipation circuits using the drowsy cache technique.","title":"Selective Way Activation of Set-Associativity Caches: Low-Power Design and Test","awardID":"0541103","effectiveDate":"2006-05-01","expirationDate":"2010-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":[292905,292906],"PO":["559883"]},"110614":{"abstract":"Multicore and multithreaded processors are replacing single-threaded processors in high-performance computer clusters, servers, workstations and high-end personal computers. The memory demand of those processors increases proportionally with the degree of multithreading. The proposed research aims to alleviate the memory bandwidth pressure by using new methods of memory access scheduling and by adjusting multithreaded execution in accordance with memory bandwidth pressure. A set of interdependent and complementary approaches are proposed: Urgency and confidence levels of memory accesses are used to guide the memory access scheduling; memory load index is used to control the progress of multithreaded execution; memory accesses from multiple threads are smoothed out to avoid bandwidth congestion; and several prediction-based techniques are proposed to reduce cache miss penalty in deep cache hierarchies. All together, both the processor computing power and the memory bandwidth will be better utilized; and higher system throughput can be achieved. The proposed research will help high-performance computing applications benefit from the emergence of highly multithreaded processors by alleviating the crucial bottleneck of off-chip memory bandwidth. It will also deepen the understanding of complex interactions between highly multithreaded processors and their memory subsystems, which will complement education in computer architecture and parallel computing.","title":"Collaborative Research: Memory Access Throttling for Highly Multi-Threaded Processors","awardID":"0541366","effectiveDate":"2006-05-01","expirationDate":"2009-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["486357"],"PO":["550859"]},"110625":{"abstract":"Background<br\/><br\/>The difficulty of developing high-performance software using the available languages and tools is being recognized as one of the most significant challenges today in the effective use of high-performance computers. As computers have increased in achievable performance, making it feasible to accurately model more complex phenomena, the time and effort required to develop the software has become the bottleneck in many areas of science and engineering.<br\/>This proposal seeks to develop a performance-model driven a compiler optimization framework that integrates the algebraic model for loop representation\/transformation with a search-based approach for loop fusion, loop tiling and data\/work partitioning. The result of the project will make scientific applications, such as quantum chemistry calculations, and other parallel modeling and simulations, easier programmable, and will cut project implementation and development time.<br\/><br\/><br\/><br\/>Intellectual Merit<br\/><br\/>The goal of this proposal is to develop a framework for compiler optimization that performs loop transformations using performance models such as cache miss cost, disk I\/O cost, and inter-processor communication cost, that can be expected to correlate directly with measured performance. Since it will generally be infeasible to analytically determine optimal parameters, or even create cost models that are expressible as algebraic functions of pertinent parameters, our approach is to use search strategies in a potentially large parameter space. This novel optimization framework has potential for high payoffs in generating high-performance code.<br\/><br\/>Broader Impact<br\/><br\/>Compiler technology can be very effective in reducing the time for developing applications in<br\/>several areas of science and engineering without sacrificing performance. There is an increasing need for automated support that can relieve the burden from users, of low-level details needed to optimize performance. The framework we propose to build will be applicable to a number of high-level language models such as Matlab, Global Arrays, UPC, Co-Array Fortran, ZPL etc. The development will be done in the Open64 framework and the resulting software will be made available to others. It is anticipated that the developed framework will be valuable to researchers in academia and research laboratories. Finally, this proposal includes the development of new courses and the training of two graduate students.","title":"ST-CRTS: Search-Based Model-Driven Framework for Compiler Optimizations","awardID":"0541409","effectiveDate":"2006-05-15","expirationDate":"2011-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["557461","472178"],"PO":["565272"]},"112506":{"abstract":"The University of South Carolina will establish a generic networking research infrastructure comprised on routers, laptop computers, hand-held devices and sensors. The infrastructure will be used in research on resilient routing and forwarding, multimedia computation and communication, and ubiquitous network security. The infrastructure will be used in research, research training and education. The infrastructure will also be used in outreach and REU programs including the South Carolina Alliance for Minority Participation.","title":"CRI: Generic Experimental Networking Infrastructure for Research on Emerging Networks and Services","awardID":"0551650","effectiveDate":"2006-05-15","expirationDate":"2009-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["451202",297790,"423741"],"PO":["402055"]},"112517":{"abstract":"The principal investigators at Texas A&M will acquire a 72 node cluster computing system for use in research and education in scalable computing techniques and large-scale applications. Scalable techniques include improvements in compilers, performance analysis, cluster interconnects, operational transformations, and numerical methods. Large-scale applications include efficient parallel and distributed execution on applications such as bioinformatics, particle transport, and submicron VLSI simulation. The system will allow researchers to reconfigure the system to explore network and operating system support and permit experimental research that would not be compatible with shared infrastructure used in production computing. The system will also be used in graduate and undergraduate education including a program focused on increasing the participation of women and underrepresented students.","title":"CRI Infrastructure Acquisition: A Cluster Testbed for Experimental Research in High Performance Computing","awardID":"0551685","effectiveDate":"2006-05-15","expirationDate":"2013-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["541641","561154","496841"],"PO":["565272"]},"110626":{"abstract":"The traditional way to realize computation in hardware is to devise an algorithm that generates the desired result and then implement that algorithm using combinational logic. Another way to realize computation in hardware is rote memorization, i.e., precompute all the results and store them in memory, a method we call Computational Memory. Our premise is that Computational Memory has properties that are particularly useful as technologies scale to higher densities, but lower reliability and higher performance variability. Memories are very regular and thus very dense, easy to test, and dissipate power much more smoothly than logic. Fault-tolerance on memories and interconnects can, in principle, be systematically implemented using error-correcting codes and\/or error detection and recomputation, providing an avenue to address both reliability and performance variability in ultrascaled technology substrates. Such computational memory blocks are cleanly composable, making fault-tolerant designs more tractable with much higher fault coverage. However, even with the high densities that are at our disposal, the exponential memory requirements of a naive implementation of Computational Memory calls into question its practicality. The proposed research will show that this scalability problem can be overcome through the combined use of alternative number systems, coding, caching and architectural techniques. If this work is successful, programmable fabrics based on Computational Memory might emerge as a standard computing framework for the nanotechnology era. This might someday enable inexpensive \"computing sticks\" that provide portable computing power, along with persistent storage in the form-factor of today?s flash memory.","title":"Computational Memory : The computing fabric of the future","awardID":"0541416","effectiveDate":"2006-05-01","expirationDate":"2010-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["560221",293070,"535119","535119"],"PO":["559883"]},"111419":{"abstract":"Motivated by the need to understand the basic properties of next generation large-scale wireless systems, this project introduces new paradigms for their analysis and design that lie at the frontier of statistical physics and network information theory. Leveraging state of the art tools from random graphs and percolation theory, as well as developing new methods, the objective is to set the foundations for a new theory of large-scale communication systems. <br\/><br\/>In wireless networks there is no a priori notion of static links, but only spatial configurations of nodes that can share the medium in arbitrarily complex ways. Hence, a new dynamic definition of network link is introduced. This depends on the notion of interference and of information rate. Exploiting geometric properties of node configurations, a series of fundamental problems that range from achievable throughput to energy efficiency, fault tolerance, and distributed network coding are then considered.<br\/><br\/>The research effort is complemented by an educational effort to train new engineers through curriculum development, plans to introduce a new course on random networks to be taught at the graduate level, and through the writing of a book devoted to random networks for communication.<br\/><br\/>Expected results include the foundations of a new mathematical theory that will lead to basic advancements in both the current understanding and the predicted behavior of large-scale networks of wireless devices. Results are also expected to have implications well beyond the field of wireless communication networks, both in terms of the introduction of new mathematical methods, and of their applicability to other fields of science.","title":"CAREER: Random Networks for Wireless Communication","awardID":"0546235","effectiveDate":"2006-05-01","expirationDate":"2012-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["409707"],"PO":["565303"]},"110628":{"abstract":"For future architectures, execution and compilation should no longer be thought of as separate activities. Instead, compilation should take place concurrently with execution. Concurrent optimization allows the processor to exploit available thread contexts for higher multithreaded performance in two ways -- it uses available thread contexts or cores to improve the quality of running code, and allows the processor to take full advantage of runtime information, with minimal overhead, to dynamically adapt the running code to the parallel architecture. This research will create a concurrent optimization system that uses available cores\/contexts to continuously optimize a program's execution. The optimization system sits as a thin virtual machine layer underneath the operating system, optimizing the native ISA application binaries, libraries, and even operating system, tailoring each to the runtime behavior of the system. The optimization system will dynamically search the optimization space trying different compiler optimizations and levels of optimization to hot traces finding the most aggressive combination of optimizations to achieve the best possible performance.","title":"Concurrent Optimization for Multi-Core and Multithreaded Architectures","awardID":"0541434","effectiveDate":"2006-05-01","expirationDate":"2009-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}}],"PIcoPI":["542069","542069",293079],"PO":["550859"]},"111607":{"abstract":"Abstract<br\/><br\/>This CAREER award seeks to develop an integrated research and educational foundation in nonlinear control methods for artificial electrical stimulation of human skeletal muscle. Current clinical practices for treating medical disorders through the application of electrical stimulation are based on patient independent protocols for the open-loop adjustment of stimulation parameters (e.g., amplitude, phase, and pulse duration). Research focused on closed-loop electrical stimulation is based on either pure feedback control or feedback control with the addition of a feedforward component composed of soft computing elements (e.g., artificial neural networks, fuzzy logic sets). Unfortunately, these methods do not fully exploit the potential benefits of on-going research focused at more effectively modeling muscle response. Research efforts in this project will focus on the development and experimental validation of nonlinear control methodologies that incorporate muscle models in the design and analysis as a means to achieve a predictable response despite intra- and inter-subject variability and fatigable force production capabilities of the muscle. Outcomes of this research will advance knowledge in artificial electrical stimulation research through the development of new mathematical models that can be used to alter stimulation parameters to reduce fatigue. These models will be incorporated in the first ever use of Lyapunov-based methods as a means to encapsulate muscle response phenomena in a neuromuscular electrical stimulation controller. Lyapunov-based methods will be used to design controllers that exhibit input saturation and are adaptive to time-varying inter- and intra-subject variations, yielding a customizable neuroprosthesis. There are direct outcomes of the research efforts that impact society through the clinical applications and the scientific advancement of modeling and control research, but further outcomes will result by the exposure of students to human-machine interaction technologies and the impacts of science and engineering for the treatment of disease and disability.<br\/><br\/>Neuromuscular electrical stimulation (i.e., the application of an electrical current via internal or external electrodes which results in a muscle contraction) offers an enormous promise to treat or alleviate the debilitating morbidity associated with certain diseases and dysfunctional conditions. Neuromuscular electrical stimulation is currently prescribed to treat a wide range of disorders and has rapidly grown because of the potential improvement in the activities of daily living for individuals with movement disorders such as stroke and spinal cord injuries that affect over one million Americans annually. In addition to serving as a treatment, neuromuscular electrical stimulation can provide an artificial extension to the body (i.e., a neural prosthetic) to restore or supplement function lost due to disease or injury with the goal of reducing the resulting implications on society and improving the quality of life of individuals. An attraction of such a neuroprosthesis is that the bodys own muscles are used to restore movement, leading to significant secondary benefits such as reducing muscle atrophy and the associated changes in metabolism and reduced risk for heart failure, the leading cause of death among individuals with spinal cord injuries. Unfortunately, current commercial electrical stimulation products have yielded limited functional outcomes for patients because ad hoc stimulation strategies are used that are not patient specific and lead to rapid muscle fatigue. The goals of this project are to develop new electrical stimulation controllers that (1) would enable long periods of physical activity that (2) could be customized and adapt to an individuals ever changing musculoskeletal system. To achieve the goals, efforts will focus on bridging the current gap between biological physiology research and control engineering research by incorporating neuromuscular models in novel adaptive control designs that elicit a desired muscle response. Given the potential benefits to the quality of life of an individual and the impacts on society of such emerging research, the worldwide market for neurotechnology products including motor system neuroprostheses, neuromodulation devices, and therapeutic muscle stimulators is predicted to grow from $2.4 billion in 2004 to $7.2 billion by 2008.","title":"CAREER: Nonlinear Control of Human Skeletal Muscle","awardID":"0547448","effectiveDate":"2006-05-01","expirationDate":"2012-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7496","name":"COLLABORATIVE SYSTEMS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1632","name":"CONTROL SYSTEMS"}}],"PIcoPI":["561494"],"PO":["563744"]},"110609":{"abstract":"Recent trends of nanoscale integrated circuits will not be mitigated by contemporary architectural innovations and will introduce significant bottlenecks in the design of future microprocessors. First, the growing complexity of models for high performance circuits make it difficult to identify critical characteristics which could aid architects in optimizing the design. Second, there is an increasing variability both in the process parameters and in environmental variables such as power supply and temperature. These increasing variations are directly reflected in microprocessor yield statistics as more manufactured chips fail to meet performance targets. Furthermore, it will be difficult if not impossible to recover from these losses with architectural modifications, which do not directly consider the circuit level causes. Without intervention, the design cycle of future processors will be dominated by exhaustive verification related to model complexity and parameter variation. <br\/><br\/>This project offers a paradigm shift where the design cycle features focused analysis of possible failures and the addition of self-monitoring, self-adjusting mechanisms that can both improve the yield, increase the performance, and reduce the requirements of verification. At the heart of this approach lies the design of flexible architectures that can tolerate variations. Particularly, this project involves generation of: (1) variation-aware architectural models which are based on physical properties and are essential for an initial estimate of the critical segments in the processor and possible failures, as well as tradeoff studies, (2) innovative self-adjusting architectures which consider physical aspects of circuits and can be reconfigured based on in-field readings, (3) algorithms for placement of sensing and monitoring elements on the chip as well as the deployment of the adaptive structures and determination of the adaptation type needed, and (4) circuit synthesis algorithms, which determine how to adjust processors for improved yield and performance. This project directly attacks a critical problem in the microprocessor industry: process variation, and hence would have significant commercial and social benefits. Academic benefits include the close interaction between the design automation, circuits, and architecture researchers and educators. This will open new avenues for learning and present a new set of interesting challenges.","title":"Self-Adjusting Architectures\/Circuits for Improved Performance and Reduced Design Complexity","awardID":"0541337","effectiveDate":"2006-05-01","expirationDate":"2009-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["409687","518459",293032,"485831"],"PO":["550859"]},"118330":{"abstract":"The Anita Borg Institute for Women and Technology (ABIWT) has received a Special Projects award to allow approximately eighty undergraduate and graduate students to attend the 2006 Grace Hopper Celebration of Women in Computing. The fifth Grace Hopper Celebration will be held on October 3-7, 2006 in San Diego. This international conference will feature keynote talks by some of the most successful women in the computing field, technical presentations by a wide range of conference participants, as well as panels, workshops, birds-of-a-feather sessions, and technology innovation forums for an in-depth look at new computing issues.","title":"CNS Special Projects: Scholarship and Travel Grants for the Grace Hopper Celebration of Women in Computing 2006","awardID":"0621706","effectiveDate":"2006-05-15","expirationDate":"2007-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["425926","529248"],"PO":["564181"]},"118298":{"abstract":"This study represents the first step in a plan of programmatic research designed to identify the cognitive processes associated with the transition from novice to expert levels of performance with the use of complex software programs. The unique perspective of this research is the investigation of how social influences (such as watching someone using different techniques) contribute to this transition. Furthermore, the PI will investigate how users' judgment of the costs and benefits of utilizing efficient strategies influences the likelihood of their subsequently utilizing the more efficient method. To test the effects of observing others on the subsequent use of efficient strategies as well as the weighing of the costs and benefits, the PI will employ a quasi-experimental correlational design, in which the predictor is the number of times participants observe someone using the efficient technique and the criteria are their subsequent use of the efficient technique and their weighing of the pros and cons of using that technique. To create a situation in the lab where someone is observing another person using an efficient strategy, participants will be assigned to dyads. One participant will be trained on the use of an efficient technique while the other will be trained on an unrelated task. The dyad will work together to complete a task and the participant trained on the efficient strategy will operate the computer. The number of times the trained participant uses the efficient strategy will be recorded through camera observations, keystroke recordings, and experimenter observations. Subsequent to performing the task together, both participants will individually complete a task similar to the previous task. Again, the number of times the efficient technique is used will be recorded. The PI's hypothesis is that the untrained participants' use of the efficient strategy will be related to the number of times they observed the trained participants use the strategy. Both participants will also be asked to weigh the pros and cons of using the more efficient technique. The intellectual merit of this study is primarily associated with its novel approach to an old problem. Although researchers have previously examined how people achieve expert levels of performance with the use of software programs, the results are certainly equivocal. In this project the PI will specifically investigate how the adoption of efficient micro-strategies (hallmarks of the efficient\/expert user) is impacted through observing others.<br\/><br\/>Broader Impacts: The results of this study will indicate whether it is necessary to overtly instruct users regarding how and when to use efficient strategies, or if observing others provides enough information to appropriately adjust users' selection rules to use the more efficient method. If observation alone turns out to be enough to change the selection rules, this will have important implications regarding the cognitive mechanisms associated with selection rule adjustment. Once these cognitive mechanisms are known, this change in selection rule could be modeled with a model of cognitive architecture such as that in ACT-R PM, which is particularly exciting because such a model that accurately predicted the transition from novice to expert levels of performance with complex procedural tasks could be used to test training protocols and interfaces for new devices and software.","title":"SGER: Efficient Strategy Selection-Predictors and Cognitive Mechanisms","awardID":"0621560","effectiveDate":"2006-05-01","expirationDate":"2007-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}}],"PIcoPI":["412550"],"PO":["565227"]},"111390":{"abstract":"With uniprocessor systems running into fundamental limitations such as power consumption and design complexity, single-chip multiprocessors provide a realistic path toward scalable performance for server, embedded, and desktop applications. Nevertheless, the key factor limiting the potential of multiprocessor architectures is the difficulty of developing parallel programs. Existing multithreading models with lock-based synchronization introduce complex tradeoffs between functional correctness and performance that most programmers cannot master. Transactional memory provides an alternative model for concurrency management in multiprocessors based on the well-known database concept of atomic transactions. This project will develop new multiprocessor architectures to efficiently implement transactional memory. The first goal is to define the architectural semantics of transactional memory that support intuitive parallel programming models. The second goal is to develop practical hardware implementations of transactional memory that provide high performance in single-chip multiprocessor systems. The project will result in a restructuring of the hardware and software interfaces for synchronization and concurrency management and will pave the way towards multiprocessors that are easy to program, cost-effective to implement, and fast. The project will also provide students with the knowledge and skills necessary to develop and efficiently program the next generation of single-chip multiprocessors for server, embedded, and desktop applications.","title":"CAREER: Practical Transactional Memory for Highly Parallel Systems","awardID":"0546060","effectiveDate":"2006-05-01","expirationDate":"2013-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["556787"],"PO":["366560"]},"115241":{"abstract":"The Centre de Recherches Mathematiques in Montreal (CRM) is organizing a<br\/>Theme Semester on Combinatorial Optimization that will include a NATO<br\/>Advanced Study Institute and five workshops. Broadly speaking, <br\/>combinatorial optimization is the study of optimization problems in <br\/>which there are a finite (but usually very large) number of potential<br\/>solutions, also called feasible solutions. These are not <br\/>enumerated but rather defined implicitly by constraints, i.e., linear or<br\/>nonlinear relations. For instance, the famous traveling salesman problem <br\/>(TSP) consists of selecting the least expensive tour of a given set of<br\/>locations, and the minimum spanning tree problem (MST) of selecting the<br\/>least expensive network connecting given sites. Combinatorial <br\/>optimization has been applied to many fields of huge practical import, <br\/>such as transport scheduling, telecommunications planning and circuit <br\/>design (where problems similar to the TSP, among others, must be solved <br\/>routinely). Since most combinatorial optimization problems are very<br\/>difficult to solve, researchers have, on the one hand, improved the<br\/>time-consuming algorithms that compute optimal solutions of difficult<br\/>problems such as the TSP, and on the other, designed efficient<br\/>algorithms that compute near-optimal solutions (also called heuristic<br\/>solutions). Two of the workshops will address the design of such <br\/>algorithms (from different angles). The three others will address the <br\/>computation of polyhedra related to optimization, the use of <br\/>optimization in data mining, and the design of computer and <br\/>communication networks such as the Internet.","title":"Conference Proposal: CRM Theme Semester on Combinatorial Optimization (June 2006 - December 2006)","awardID":"0607951","effectiveDate":"2006-05-01","expirationDate":"2007-04-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1264","name":"ALGEBRA,NUMBER THEORY,AND COM"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7351","name":"THEORETICAL FOUNDATIONS (TF)"}}],"PIcoPI":["485468"],"PO":["565286"]},"119753":{"abstract":"Title: SGER: Recognizing Objects by Simultaneously Combining Appearance and Geometry<br\/><br\/>PI: Daniel Huttenlocher<br\/><br\/>The 40 year history of object recognition in computer vision has been dominated by bottom-up approaches where local features are first detected in an image and then those features are matched to geometric models of objects. The proposed project investigates methods that formulate the object recognition problem as a single overall optimization rather than as successive stages of feature detection and matching. The approach combines bottom-up information about the appearance of local image patches with top-down information about geometric relations between those patches. The main focus is on recognizing generic classes of objects such as bicycles, people, motorbikes, or cars. Each object class is modeled as a collection of parts arranged in a deformable configuration, where certain pairs of parts are connected by springs. Recognition is formulated in terms of energy minimization, where there is a cost for placing each patch at each possible location in the image, and a cost for placing pairs of patches in a manner that stretches the springs connecting them.<br\/><br\/>Such an energy minimization formulation was proposed in the 1970's under the name Pictorial Structures, but was abandoned due to its computational complexity. Recent algorithmic advances have made it possible to further investigate this kind of approach. Initial results on detecting and localizing objects have been promising, but also demonstrate how much remains to be done for this approach to form a viable alternative to feature-based object recognition. The proposed project investigates some of the key initial questions in determining whether the energy minimization approach to object recognition could be a viable alternative to current feature-based approaches, including how to learn such models with minimal supervision, and how to incorporate global geometric information such as object scale and orientation into the models.<br\/><br\/>The proposed approach computes cost maps that determine how well each part matches at each possible location in the image. These cost maps are then combined together in the energy minimization process. In contrast, traditional feature detection approaches find a small number of locations where each feature or part might be present in the image. While the sparse nature of feature locations may seem to require less computation than working with entire cost maps, the necessity of handling spurious and missed feature detections in fact makes such feature-based methods quite computationally intensive.<br\/><br\/>Project URL http:\/\/www.cs.cornell.edu\/~dph\/simulrec\/","title":"SGER: Recognizing Objects by Simultaneously Combining Appearance and Geometry","awardID":"0629447","effectiveDate":"2006-05-01","expirationDate":"2007-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7339","name":"COMPUTER VISION"}}],"PIcoPI":["420975"],"PO":[317663]},"111371":{"abstract":"As computers interact with people in increasingly complex and human ways through robots, wearable devices, PDAs, and various other ubiquitous interfaces, the psychological aspects of our relationships with them take on an increasingly important role. It is important to not only understand the nature of this phenomenon and its effects in work and leisure contexts, but also to develop strategies for building and managing these relationships, which directly impact productivity, enjoyment, engagement and other important outcomes of human-computer interaction. In this research, the PI intends to explore such issues via relational agents, computational artifacts designed to build long-term, social-emotional relationships with their users by managing expectations, attitudes and intentions. While such agents can take on a number of embodiments (e.g., as jewelry, clothing, handheld, robotic, and various non-humanoid physical or nonphysical forms), the current project will focus on the development of purely software humanoid animated agents. Building on his prior work, the PI will develop a \"virtual laboratory\" consisting of a networked software architecture and experimental methodology to support very long-term human-computer interaction studies, in which new experiments and agent capabilities can be dynamically integrated into a running system serving a persistent group of human subjects. The virtual laboratory will then be used as a means to studying how social interface agents can conduct very long-term interactions with users - spanning months or years of daily use - and the impacts these interactions can have on user education, behavior change and overall well-being. While social interface agents have broad applicability, this project will target one application domain (physical activity promotion) and one user group (urban older adults) in order to focus and ground the research. Special care will be paid to imparting to the agents the ability to interact naturally with users and to form social-emotional relationships with them over time, in order to promote their effectiveness in both maintaining long-term interaction and achieving positive task outcomes. In addition to advancing knowledge relating to human-computer interaction, this research will make significant contributions to the fields of computational linguistics, psychology, and communication. In the field of computational linguistics, the work will advance our knowledge of how to build dialog planners that can produce both task-oriented and social dialogue - including both verbal and nonverbal conversational behavior - intended to build and maintain social relationships with users within specifically targeted task domains; it will also address how to model and reason about human-machine dialog that spans multiple interactions. In psychology and communication, this work will provide a better understanding of the nature and types of social relationships that people can have with computer agents, techniques that agents can use to build and maintain these relationships, and how human-computer relationships can improve certain kinds of task performance.<br\/><br\/>Broader Impacts: The outcomes of this effort will include new ways of modeling human relationships and social and relational behavior. The project will also lead to an understanding of how people and computer agents can optimally live and work together over extended periods of time, which in turn may improve our understanding of human-human relationships by providing new vocabulary, models and paradigms for thinking about relationships. Finally, this work will target an underserved population (older adults) while focusing on an application domain (healthy lifestyle promotion) that has the potential for significant positive impacts on our overall society.","title":"CAREER: A Virtual Laboratory for Studying Long-Term Human-Computer Relationships","awardID":"0545932","effectiveDate":"2006-05-01","expirationDate":"2012-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7496","name":"COLLABORATIVE SYSTEMS"}}],"PIcoPI":["448734"],"PO":["565227"]},"118434":{"abstract":"ABSTRACT<br\/>Zena Ariola<br\/>0622244<br\/>U of Oregon Eugene<br\/><br\/>Everyday life and critical aspects of our economy, defense, and government depend on software. Increasingly, this software is concurrent (with multiple computations proceeding in parallel) and distributed (with computations spread across large heterogenous networks). With chip multiprocessors and ubiquitous computing environments on the horizon, concurrent programming will soon become a primary issue for many programmers. The main aim of this school is to enable participants to conduct programming-language research to meet this pressing societal need. By presenting a range of material, from foundational work on logic and type systems to advanced techniques for analyzing real concurrent software, we will provide a unique opportunity for participants to understand the current research landscape.","title":"Summer School on Language-Based Techniques for Concurrent and Distributed Software","awardID":"0622244","effectiveDate":"2006-05-01","expirationDate":"2007-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["489107"],"PO":["564388"]},"111450":{"abstract":"CAREER: Autonomous and Assistive Trail Following<br\/>PI: Christopher Rasmussen<br\/><br\/>Abstract:<br\/><br\/>This project will study algorithms for finding and following trails, both in the context of autonomous mobile robots and assistive devices that may be mounted on vehicles or carried by people. Paths along the ground are ubiquitous features of man-made and natural outdoor environments, \"showing the way\" to those who can recognize them and ``smoothing the way'' to ease passage. These two functions place each path along a spectrum of distinctiveness and traversability, which bear on the difficulty of the perceptual and control tasks, respectively, that following it poses. Trails occupy the more tenuous ends of both axes, comprising dirt and other unimproved roads as well as true hiking trails. A unique characteristic exhibited by some trails is discontinuity, in which visual markers such as cairns, blazes, footprints, and other \"tells\" indicate a sequence of waypoints. The research will focus on computer vision and robotic problems stemming from three core trail following tasks: (1) keeping, or discriminating and staying on continuous and discontinuous trails; (2) negotiation, or avoiding within-trail obstacles and setting control policies appropriate to changing terrain conditions; and (3) finding trails and mapping unknown trail networks, including detecting branches, dead-ends, and discontinuities. Using stereo color cameras, GPS, static aerial imagery, and topographical data, the PI will investigate (1) Texture-based methods for robust segmentation to incorporate rich models of natural image statistics, (2) On-line visual tracking and activity analysis of other mobile agents for efficiently learning control policies, and (3) Integration of directed search, recognition, and footprint structure estimation algorithms for discontinuous trails. The benefits of robust trail following skills will extend to wheeled, walking, and low-and-slow-flying robots, with applications including resupply of difficult-to-reach camps and research stations, inspection and maintenance of trails, and patrolling and reconnaissance operations as part of a border security or military force. Assistive applications include augmenting driver awareness on dangerous roads, guiding for visually-impaired hikers, and as a smart device for wildlife study through animal tracking and search-and-rescue efforts through person tracking. Educational impacts will derive from extensive involvement in this work by students from the graduate level down through high school. The PI will start an undergraduate team to compete in national robot competitions in order to encourage participation in vision and robotics research, run a program of summer internships for high school and undergraduate students to help program and test aspects of the trail following system, and introduce a novel web-based system to allow a wider group of students to contribute to the research through image segmentation and video annotation to provide data for robot<br\/>learning.<br\/><br\/>URL: http:\/\/vision.cis.udel.edu\/trails","title":"CAREER: Autonomous and Assistive Trail Following","awardID":"0546410","effectiveDate":"2006-05-01","expirationDate":"2012-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[295121],"PO":["564316"]},"119536":{"abstract":"This project is a pioneering effort to collect data about Massively Multiplayer Online game players, their actions, attitudes, social networks, and economic activities. People increasingly conduct major parts of their lives in virtual worlds: online spaces where large numbers of users are able to congregate, interact, play, and socialize. Most of these worlds are built as competitive games, and are termed Massively Multiplayer Online games (MMOs). Best estimates indicate in excess of five million North Americans now interact in these worlds, with more than 20 million worldwide. Yet while the serious study of virtual worlds has begun in earnest, it is hamstrung by the absence of systematic data. No research project has been conducted with a representative sample, access to server-side data, or the cooperation of game administrators. However, this project has secured the cooperation of a large game developer, which has agreed to release its in-game data as well as help coordinate a survey instrument of its players. The resulting data set will thus be the first comprehensive study of virtual world behaviors, and will contain a rare combination of both unobtrusive behavioral data with standard attitudinal, demographic and psychographic measures.<br\/><br\/>This data set must be properly collected, cleaned and organized in order to facilitate access by a wide range of researchers. Thus the initial effort will involve programming innovations, cleaning and hosting tasks, as well as the creation of new algorithms for several social science tests. The first three areas to be tested will be social networks, social capital, and economic activity. In each area, the dataset will be a testbed for examining theories in ways that were previously impossible, while also offering several programming and analysis challenges relating to dealing with a massive and comprehensive dataset. For example, social networks tested with multi-theoretical multilevel (MTML) models have generally been small due to the difficulty of collecting complete datasets on groups, yet the current project will offer thousands of complete groups of sizes ranging from two to 2,000, with complete behavioral data over a 16-month time window. For research into the social implications of online worlds, the data offer tests of the cyberbalkanization hypothesis, new media isolation hypotheses and explorations of virtual communities. The dataset also offers the ability to do something never yet done in economic analysis: generate a time series of an entire economy. The wealth of data will require the creation of indices, new metrics and new ways of interpretation.<br\/><br\/>This project has no precedent in social science, both because virtual worlds have not yet been studied systematically, and because it combines attitudinal data with previously unattainable levels of unobtrusive behavioral data. The project allows for both methodological ground breaking as well as innovative theory testing. The research will require the creation of new techniques bridging the domains of both computer science and social science. These new methods will be valuable for future scientific research, for improving the games themselves, and for exploiting the educational potential of virtual worlds.","title":"Collaborative Research: Instrumenting Behaviors and Attitudes in Virtual Worlds","awardID":"0628072","effectiveDate":"2006-05-01","expirationDate":"2007-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":[317042],"PO":["564456"]},"111660":{"abstract":"This project defines a new approach to massive graphs that identifies three fundamental challenges common to many applications: scale, dynamism, and uncertainty. The project advances graph compression schemes that are universal and independent of the application to summarize massive graphs at large scales. These algorithms should be highly efficient, using a small amount of space and time to produce a compressed representation. Furthermore, these algorithms should be provably correct. In addition, the tools should be adapted to dynamic graph data. They should learn a model of the graph from historical data. Finally, this project will design tools that can infer graph properties from samples of a massive graph, since such a graph cannot be observed in its entirety. In applications where sampling schemes can be devised, we strive to do so as effectively and as efficiently as possible.<br\/><br\/><br><br><br\/><br\/>We live in an information age. Behind many of our technological, scientific, and economic forces are large volumes of data. An increasingly important type of data is relational data or graph data. These data capture how entities are related to one another, how they interact with one another, or how objects are linked together. All forms of communication amongst entities give rise to graph data, including the communication of source and destination IP addresses via IP packets in the Internet, people sending email to one another, web pages referring to one another, or proteins interacting with one another in large biological systems. Many scientific, engineering, and medical applications depend on our abilities to model, to analyze, to process, and to synthesize this type of data quickly, in the face of changes to the data, and under imperfect information. Indeed, our security and the security of the Internet may hinge upon our understanding of how entities (be they people or IP addresses) interact with one another. Our current statistical and algorithmic tools for relational data are not adequate for massive graphs. They have not kept pace with our ability to collect enormous amounts of data and our need to accurately and efficiently analyze that data. We must be able to model, to compress, and to highlight the important features of graphs that are gigantic, that evolve over time (perhaps quickly), and that may capture a limited view of a larger graph. This project aims to develop robust, highly efficient, and provably correct methods for managing massive graphs.","title":"CAREER: Modeling and Analysis of Data from Massive Graphs","awardID":"0547744","effectiveDate":"2006-05-15","expirationDate":"2012-04-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1266","name":"APPLIED MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7351","name":"THEORETICAL FOUNDATIONS (TF)"}}],"PIcoPI":["507958"],"PO":["565356"]},"112760":{"abstract":"This project renews an exemplary existing Research Experience for Undergraduates site focused on the areas of pervasive and mobile computing. While the previous project focused on the use of wireless and handheld devices by law enforcement and emergency response personnel, this project incorporates a more general research track. A nationwide recruitment process is used to select cohorts of undergraduate students to participate in a ten-week summer research program at the host institution. Particular emphasis is placed on recruitment of students from under-represented populations. The project includes mentoring by the experienced computer science faculty members, technical seminars and workshops, student presentations, and field trips and other professional development opportunities. The project refines the recruitment, selection, and performance evaluation processed developed in the previous REU site project at the institution.<br\/><br\/>Intellectual Merit: The intellectual merit of this project lies in strong research basis and the expertise of the faculty. The projects are in current research areas that are of interest to the community at large and that have clear practical applications. The students participate in a full range of research activities from preparing research literature reviews to production and dissemination of research results.<br\/><br\/>Broader Impact: The broader impacts of the project include providing a quality research experience to undergraduate students, particularly students from underrepresented groups and community college students. The participating faculty members are committed to under-represented minority students in their research. Thus this project has the potential to produce new computer science graduate students and faculty members and to advance discovery and understanding while promoting learning.","title":"REU Site: REU Site for Pervasive and Mobile Computing","awardID":"0552627","effectiveDate":"2006-05-15","expirationDate":"2010-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1139","name":"RSCH EXPER FOR UNDERGRAD SITES"}}],"PIcoPI":["489515","505916"],"PO":["564181"]},"110582":{"abstract":"Abstract<br\/>0541200<br\/>Kim Bruce<br\/>U of Alabama <br\/>CPA: Testing of Nano-Interconnects in System-in-Package Substrates <br\/>Integrating digital logic, flash memory, analog, and RF blocks on a single integrated circuit (IC) chip to meet the high demands of todays small and low-cost consumer products has become increasingly difficult. Todays System-in-Package (SiP) technology involves the system integration of multiple semiconductor dies from various technologies into a common package. This high-density system integration is made possible through interconnections between active devices, such as IC chips or between other discrete components, mounted on the package substrate. High resolution testing for todays SiP is becoming increasingly difficult due to the ultra fine geometry associated with the nano-scale wafer level packaging. The goal of this research is to explore a new and low-cost test technique for detecting interconnect defects in nano-scale SiP substrates. We propose to (1) develop the nano-scale interconnect modeling, (2) establish look-up table database, (3) fabricate an integrated MEMS probe that incorporates a MEMS resonator, and (4) implement embedded system integration for practical demonstration. The overall program ties research and education at all levels (K-12, undergraduate, graduate, continuing-education). Through the Multicultural Engineering Program (MEP), we are planning to facilitate recruitment, retention and graduation of minority engineering students by providing participation and education in nanoelectronics testing areas. We plan to develop Internet-based modules on nano-scale packaging and testing.","title":"CPA: Testing of Nano-Interconnects in System-in-Package Substrates","awardID":"0541200","effectiveDate":"2006-05-01","expirationDate":"2010-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["559029","335395"],"PO":["562984"]},"111330":{"abstract":"The overall goal of this research is to develop methods for organizational adaptation in artificial agent societies, resulting in short-term and long-term changes to the society's structure that lead to demonstrable performance improvements. Specifically, the project will develop techniques to locally adjust connections between agents and to form long-term stable teams, resulting in responsive, effective agent societies. A closely related educational objective is to develop course materials centered around the organizational learning software to be developed. <br\/><br\/>The organizational structure of a multi-agent system refers to the nature of the physical or virtual connections among agents, including their communication, familiarity, and trust and reputation relationships. Agents can adapt this organization by modifying connections, by changing their patterns of interaction with other agents, and by establishing authority relationships and subcontracts. Effective organizational adaptation requires the agents to maintain knowledge of the other agents to whom they are connected, including their capabilities, competence, resource capacities, reliability, and trustworthiness. From the system designer's perspective, developing protocols and methods by which agents can adapt their own organization requires an understanding of how organizational change affects the system dynamics at an individual and at a global level. This project will develop a theoretical framework for organizational adaptation in a simulated multi-agent society, implement this framework within an experimental testbed, and use the framework to develop techniques for two forms of organizational learning: local adaptation of network structure and contract-based approaches for forming stable teams and coalitions. These techniques will be applied to several multi-agent applications: multi-robot exploration, distributed vehicle monitoring and tracking, and supply chain management. <br\/><br\/>Software agents with varying degrees of autonomy are the focus of many current research projects. They are currently used for information gathering, e commerce, virtual entertainment, and mobile robot applications. As intelligent agents become more ubiquitous, it will be of great benefit if the resulting \"agent societies\" can work effectively to provide value to their users. This research will result in fundamental advances in representations, modeling, and self-organizing environments and protocols for agent societies. A primary educational objective of the work is to distribute software and benchmarks to facilitate education and research on multi-agent organizational adaptation. This distribution will include a suite of \"mini-projects\" suitable for classroom assignments or independent study research projects. The other educational objectives include outreach to underrepresented students at primarily undergraduate institutions and involvement in mentoring programs for doctoral students in the artificial intelligence community.","title":"CAREER: Organizational Adaptation in Artificial Agent Societies","awardID":"0545726","effectiveDate":"2006-05-15","expirationDate":"2013-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7496","name":"COLLABORATIVE SYSTEMS"}}],"PIcoPI":["558297"],"PO":["564456"]}}