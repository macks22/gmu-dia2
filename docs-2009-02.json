{"153670":{"abstract":"This award supports the Doctoral Colloquium program at the 2009 iConference to be held on the campus of the University of North Carolina at Chapel Hill February 8 - February 11, 2009. This workshop will bring together 15 dissertation-stage doctoral students in diverse information and informatics subfields for one day of presentations, interaction, and feedback with five faculty members selected from among distinguished information researchers. The iConference Doctoral Research Colloquium is designed to assist doctoral students to become stewards of the information and informatics disciplines, by providing an opportunity for interaction with distinguished research faculty and for the development of a global cohort group of new researchers. This project provides support for the travel, lodging and registration of students, plus the registration for the participating faculty mentors, as well as the direct expenses of putting on the Doctoral Colloquium at the meeting.","title":"Workshop: i-Conference Doctoral Research Colloquium","awardID":"0915594","effectiveDate":"2009-02-01","expirationDate":"2010-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[408947],"PO":["565342"]},"146443":{"abstract":"Unlike most bioinformatics data, such as DNA sequences and protein<br\/>structures, pathways show the interactions of different bio-chemical<br\/>entities. Thus, each entity or subpathway can have a function in its<br\/>pathway that the pathway can not realize without it. Formulating these<br\/>functions presents exciting computational challenges. <br\/><br\/>This proposal develops algorithms for efficient and accurate<br\/>computational analysis of pathways. The first step in achieving this<br\/>goal is to build a mathematical model for functions of pathways and<br\/>subpathways. This proposal defines the function of a subpathway as its<br\/>contribution to the steady state of the entire pathway. Computing this<br\/>contribution is a difficult problem especially for gene regulatory<br\/>pathways. Existing methods can compute this for metabolic pathways,<br\/>but they do not scale to even medium sized gene regulatory<br\/>pathways. This proposal develops efficient methods for computing<br\/>function.<br\/><br\/>Finding the subpathway that has a desired function is a challenging<br\/>problem. There is no clear way of searching for subpathways with<br\/>desired functions using existing tools. This proposal develops<br\/>efficient algorithms for searching subpathways with desired function.<br\/>This proposal takes this one step further, and develops mathematically<br\/>sound algorithms for comparing two pathways so that the entities that<br\/>map are functionally, homologically and topologically similar. This<br\/>proposal also explores feature and reference-based index structures<br\/>for biological pathway databases.<br\/><br\/>Further information on the project can be found at the project web<br\/>page:<br\/> http:\/\/bioinformatics.cise.ufl.edu\/","title":"CAREER: New Technologies for Querying Pathway Databases","awardID":"0845439","effectiveDate":"2009-02-15","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["538607"],"PO":["543481"]},"146476":{"abstract":"Career: Adaptive Concurrency Management for Multicore Computing<br\/>Abstract: Given the increasing emphasis on multicore computing, concurrency management is likely to be one of the key techniques to unleash the power of multicore processors. Concurrency is the capability of executing multiple tasks simultaneously, but it is often difficult to achieve due to data and control dependencies. The proposed research aims to optimize thread-level concurrency for multicore applications. It will investigate architecture features for efficient shared data accesses, and use these features to dynamically control the advancement of concurrent threads and the allocation of CPU resources. The project will target computing platforms of immediate concern and the techniques will be made accessible to the programming community by integrating them into existing programming tools. The project will also extend theoretical results towards efficient multi-threaded algorithms. The proposed research project is expected to significantly improve the performance of multicore computing and expand the range of applications that can benefit from such processor platforms. It is expected to facilitate efficient multicore processing for computation-demanding applications in science, engineering, and business.","title":"CAREER: Adaptive Concurrency Management for Multicore Computing","awardID":"0845583","effectiveDate":"2009-02-15","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["564503"],"PO":["535244"]},"146377":{"abstract":"Recent advances in computing hardware and wireless technology have resulted in widespread popularity of applications and systems involving highly distributed wireless networks. In such a network, each node may belong to an independent organization or individual that has its own interests, and so may not always want to behave cooperatively. However, if these nodes do not cooperate, the performance of the network may degrade, or the entire network may become dysfunctional. Consequently, we need to design economic mechanisms to stimulate these nodes to cooperate. <br\/><br\/>In this project, we study the design of enforceable economic mechanisms. We say an economic mechanism is enforceable if it provides sufficiently strong incentives<br\/>for cooperative behavior and security protection against cheating and has been systematically evaluated in experiments. We emphasize the great importance to make economic mechanisms enforceable because if an economic mechanism is not enforceable, it cannot be effectively used in practice to simulate cooperation. <br\/><br\/>Our research plan is to focus on two specific problems, namely the Routing and Packet Forwarding Problem and the FDMA Channel Assignment Problem, because they are simple but fundamental. Besides these two problems, it is also planned to study experimental methods for systematically evaluating the incentive compatibility and computation and communication efficiency of economic mechanisms in wireless networks, as well as a few other selected problems of non-cooperation in wireless networks. In addition, the plan includes education activities to disseminate cutting-edge knowledge on cooperation in wireless networks to undergraduate and graduate students.","title":"CAREER: Enforceable Economic Mechanisms for Cooperation in Wireless Networks","awardID":"0845149","effectiveDate":"2009-02-15","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["536356"],"PO":["557315"]},"146510":{"abstract":"A growing and inevitable trend in the use and management of storage resources is the consolidation of distributed storage into a large data center to reduce the rapidly growing administration cost and to improve resource utilization. Despite its compelling advantages and years of efforts on research and product development, a critical challenge in turning this promising technology into reality remains to be addressed, which is that the quality of the I\/O services (QoS) cannot be conveniently presented and efficiently guaranteed for users who outsource their dedicated storages to the shared system. To this end, a performance interface, or specification of required service quality, must be able to allow a diverse set of users to easily relate each of their I\/O QoS requirements to their respective application performance and enable efficient system implementation to meet the QoS requirements. Currently, the QoS requirements are usually presented in the form of service-level agreements (SLAs) to bound latency and throughput of I\/O requests. SLA is not suitable for I\/O requests from application servers to storage servers because users have difficulties in using the performance interface and resources allocation can be misguided by the SLA measures, which do not consistently reflect users' resource demands.<br\/><br\/>To address this critical issue, the investigator will develop a reference (or virtual) storage device as performance interface and will implement consolidated storage service based on the interface. In this way, a user is guaranteed to receive an I\/O service whose quality is at least as good as that on the reference system regardless of variations and instantaneous changes of data access patterns. The research project aims to remove the significant barrier for users and system administrators to communicate I\/O performance requirements and pave the road to wide acceptance of the storage consolidation technology.","title":"CAREER: Building Virtual Devices with QoS Assurance in a Consolidated Storage Infrastructure","awardID":"0845711","effectiveDate":"2009-02-15","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["518050"],"PO":["366560"]},"146631":{"abstract":"The PI has developed two prototype magnetic levitation systems with novel designs, which provide unprecedented extended motion ranges in addition to the many advantages of magnetic levitation for 6 degree-of-freedom haptic human-machine interaction (such as mechanical simplicity, absence of friction and backlash, and high impedance range and control bandwidths). The first device uses a novel coil and magnet configuration to approximately double the translation and triple the rotation range of previous Lorentz force levitation devices in all directions (increasing the motion volume 8 times and reachable orientations 27 times). The second device is a modular system to levitate a platform of one or more magnets above a planar array of 5 or more cylindrical coils, which provides a planar motion range extendable to any area (by increasing the size of the coil array) and a potentially unlimited rotation range (the current prototype uses 10 coils to levitate one magnet with a motion range of 60x80 mm in the horizontal plane, 30 mm vertical, and 30 degrees of roll and pitch rotation). .In this project the PI will extend the performance capabilities of two magnetic levitation systems in terms of their motion and impedance ranges, control bandwidths, and accuracy, through new modeling, control, and computation methods. He will formulate and implement novel haptic simulation methods to benefit from the unique capabilities of the new devices for task-specific simulated environments including surgical simulation and other haptic skill tasks. And he will evaluate the resulting haptic interaction systems in terms of the realism of the haptic perception by users and system effectiveness for haptic training and task performance. The PI's overall objective in this work is to bring to bear topics in electromagnetic analysis, multivariable nonlinear dynamic control, computational methods, haptic modeling and real-time physical simulation methods, and human haptic perception and task performance, in order to improve the fidelity and effectiveness of human-machine haptic interaction using magnetic levitation devices. The PI's hypothesis is that application of the proposed methods will lead to significant measurable improvements in haptic perception, interaction, and task performance, both for general human-machine interaction and in specific applications such as training of haptic medical skills and upper-limb rehabilitation.<br\/><br\/>Broader Impacts: The realization of magnetic levitation systems with extended translation and rotation ranges in all directions (Lorentz device) and\/or easily extensible translation in horizontal directions and unlimited rotation (planar device), will provide dramatic benefits in a wide range of domains including robotic manipulation, fine positioning and orientation, automation, materials handling and processing, force and vibration control, and camera and antenna pointing not to mention entertainment. High-fidelity haptic interaction will also have application to the study of psychophysical human haptic perception, and to the display of complex multidimensional abstract data. The new technologies will provide exciting opportunities to teach physics and engineering concepts at any level in a memorable, intuitive way; to this end, the PI will develop educational materials with haptic magnetic levitation demonstrations and simulations, which will be made available to complement materials already in development in robotics areas for university classes and secondary schools.","title":"CAREER: High Fidelity Haptic Interaction using Large Range of Motion Magnetic Levitation Systems for Medical Applications","awardID":"0846172","effectiveDate":"2009-02-01","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[390888],"PO":["565227"]},"146224":{"abstract":"CAREER: Dynamic and Autonomous Software-to-Hardware Translation for High-Performance and Low-Power Embedded Computing<br\/>Circuits implemented using field-programmable gate arrays (FPGAs) share many of the same advantages of software solutions and provide a complimentary technology for increasing system performance of reducing power. Implementing critical kernels of a software application within an FPGA can provide substantial speedups in application execution time. However, traditional hardware\/software partitioning approaches either require extensive manual efforts or rely on automated partitioning compilers that significantly depart from mainstream software development tools and practices. This CAREER project seeks to overcome these challenges by investigating and developing new methods for dynamically translating kernels within an executing application binary into circuits executing on an FPGA ? a process referred to as warp processing. Warp processing provides an innovative technology that allows FPGAs to be readily integrated into computing systems without requiring hardware design expertise, specialized tools, or even knowledge of the FPGA. This CAREER project will investigate several interrelated research problems, including: 1) dynamic application profiling, 2) dynamic optimization of multitasked applications, 3) adaptable fixed point representations for efficient support of floating point arithmetic in hardware circuits, and 4) low-power warp processing. This CAREER project also seeks to significantly improve embedded systems education through several concerted efforts aimed at training engineers to understand the fundamental similarities and differences between software and hardware implementations and enable those engineers to apply that knowledge to evaluate the tradeoffs between alternative design solutions.","title":"CAREER: Dynamic and Autonomous Software-to-Hardware Translation for High-Performance and Low-Power Embedded Computing","awardID":"0844565","effectiveDate":"2009-02-01","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["408607"],"PO":["565255"]},"146488":{"abstract":"The goal of the Semantic Web is to free Web data from the applications that control them, so that data can be easily described and exchanged. <br\/>This is accomplished by supplementing natural language and other data found on the Web with machine readable metadata in statement form (e.g., X is-a person, X has-name Joe, X has-age 35) and enabling descriptions of data ontologies so that data from different applications can be integrated through ontology mapping. One element of this vision is to turn the Web into a giant database, against which one can issue structured queries and receive structured answers in response.<br\/><br\/>The SW-Store project is undertaking the clean-slate design of a DBMS specifically architected for this type of Web metadata and the prevalent Semantic Web data model, the Resource Description Framework, or RDF. The management of Semantic Web data presents many difficult challenges. The size of the data is growing rapidly, and in theory could reach the scale of the Web. The types of queries vary greatly in complexity, ranging from keyword search to complicated parameterized subgraph matching. Data integration, inference, and reasoning must be primitive operations that can operate at scale without human intervention. A data management system must not only be a place where data is stored and from which data is accessed; it must use the machine-readable semantics of the data to develop higher level models and help guide a user through the mass of information. In sum, a data management system for the Semantic Web will look very different from a standard, transactional, relational database system.<br\/><br\/>The SW-store project researches the architecture of such a system. This research is inherently interdisciplinary, bringing in ideas from the data management, Semantic Web, and artificial intelligence communities. The project involves experimenting with partitioning schemes, where data is allocated to different nodes on a shared-nothing cluster so that queries can be run in parallel across multiple machines. It also involves exploring how ontology reasoning can be integrated inside the database system so that it can benefit from the near limitless scalability a shared-nothing cluster can offer. SW-Store further investigates providing iterative query interfaces and integrating complex queries with text search. Finally, the project involves studying the design of the storage layer for a Semantic Web data management system, looking at how data should be laid out, updates should be performed, and what materialized views to create.<br\/><br\/>Further information about the project can be found at the project Webpage: <br\/>http:\/\/db.cs.yale.edu\/swstore\/","title":"CAREER: Architecting A Database Management System for Semantic Web Data","awardID":"0845643","effectiveDate":"2009-02-15","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["532784"],"PO":["543481"]},"146136":{"abstract":"The Center for Intelligent Information Retrieval (CIIR) is investigating the impact of statistically derived semantic word relationships on information retrieval. Exploiting these relationships, for example, by identifying when different words express the same content can lead to more effective rankings of retrieval results. Semantic relationships are not labeled explicitly in text and are too varied to be identified solely by hand. The CIIR is mining massive corpora for direct and indirect word co-occurrence data using both offline and retrieval-time computation. The particular focus is on techniques that create and use Web-based corpora of \"comparable\" sentences and text chunks for estimating word and phrase translation probabilities, and on techniques that derive relationships from \"context vectors\" that represent word and phrase meanings. The quality of the word relationships that are discovered is being tested using large-scale retrieval experiments. In addition, the CIIR is addressing computational barriers to large-scale data mining by moving its new distributed computational framework, TupleFlow, to Hadoop. That framework was developed for the type of indexing and analysis operations that are required for large-scale studies of relational structure in text. TupleFlow is an extension of MapReduce, with advantages in flexibility, scalability, disk abstraction, and low abstraction penalties. This work is expected to have broad impact by improving the quality of search results.","title":"Learning Word Relationships Using TupleFlow","awardID":"0844226","effectiveDate":"2009-02-01","expirationDate":"2012-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7782","name":"CLUSTER EXPLORATORY (CLuE)"}}],"PIcoPI":["553228","507668"],"PO":["563751"]},"146499":{"abstract":"CAREER: Tags: A Unifying Primitive to Build Storage Data Paths for<br\/>Swiftly Evolving Workloads and Storage Media<br\/>Digital storage is now a part of our lives. However, storage management in legacy operating systems becomes quickly outmode due to swift advances in storage media (e.g., memory cards and thumb drives) and new user requirements (e.g., energy efficiency, security, etc.). In particular, legacy storage management presumes the use of disks rather than memory-based storage and is structured in layers with poor cross-layer coordination and little support for data-intensive applications.<br\/>This project introduces tags?a unifying primitive that can be used to build storage layers. The idea is to tag each piece of data with how they relate to each other and how they are handled by each layer. Tags will ease storage service composition and data sharing. For example, file searches can be based on its association with e-mails and calendar events. Tags will ease the isolation of system changes required to adapt to new storage media. Tags describe the nature of data pieces (e.g., confidential, streaming media, etc.) so that storage layers can coordinate to improve performance, energy efficiency, etc. Tags will track data dependencies so that confidential data and derivatives (e.g., temporary files) can be handled securely.<br\/>Intellectual merits: The challenges for this research include: (1) exploring the representation and interface of tags; (2) examining the management of tags under constraints of scaling, security, and assumptions of usage models and storage media; (3) developing ways to track data dependencies via tags; and (4) demonstrating the benefits of tags across diverse usage patterns and storage media. <br\/>Broader impacts: Tags support data-intensive applications such as databases and search engines. The design of tags is similar to machine instructions and allows the application of hardware optimization techniques. The data-tracking service offered by tags will support secure storage services. The tag framework will become a valuable instructional tool, a platform to explore new ideas, and a gateway to explore ideas from other fields. The research will lead to the development of a seminar course on storage that emphasizes on infusing ideas from various fields to advance storage frontiers.","title":"CAREER: Tags: A Unifying Primitive to Build Storage Data Paths for Swiftly Evolving Workloads and Storage Media","awardID":"0845672","effectiveDate":"2009-02-01","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["537229"],"PO":["535244"]},"153397":{"abstract":"This is funding to support participation by approximately 15 graduate students currently enrolled in Ph.D. programs in the United States and abroad in the 2009 International Conference on Intelligent User Interfaces (IUI 2009), to be held in Sanibel Island, Florida, on February 8-11, 2009. Sponsored by ACM, the annual IUI conferences are the premier forum where researchers from academia and industry, who work at the intersection of Human-Computer Interaction (HCI) and Artificial Intelligence (AI), come together to exchange complementary insights and to present and discuss outstanding research and applications whose goal is to make the computerized world a more amenable place. Unlike traditional AI the focus is not so much on making the computer smart all by itself, but rather on making the interaction between computers and people smarter. Unlike traditional HCI, there is a focus on solutions that involve large amounts of knowledge and emerging technologies such as natural language understanding, brain computer interfaces, and gesture recognition. To this end, IUI encourages contributions not only from computer science but also from related fields such as psychology, cognitive science, computer graphics, the arts, etc. IUI 2009 will be the 12th conference in the series; topics of interest this year include user input, generation of system output, ubiquitous computing, help, categories of intelligence, IUI design, and user studies. NSF funds will be used to support two groups of participants: students who are the primary author of a submission that has been accepted as a full paper or poster but whose institution is either unable to provide any funding for conference attendance or able to provide only partial funding that is insufficient to cover the student?s expenses; and other students who would benefit from the conference but who would be unable to attend due to restrictions by their department on funding conference travel for non-authors. The IUI 2009 organizing committee has undertaken to proactively recruit student participants from schools that have not traditionally been well represented in the IUI community, and also that the bulk of students supported (70-80%) will be from U.S. institutions.<br\/><br\/>Broader Impacts: This funding will enable attendance at this conference by students who might otherwise be unable to do so for financial reasons. It will enhance the educational experience of funded participants, by bringing them into contact with leading researchers in the field and by exposing them to the lively discussion during the course of the conference that often leads to opportunities for career advancement. The quality of the conference itself will be enhanced as well, thanks to a broadening of the base of institutions represented and increased diversity of participants. The rich exchange of ideas at IUI has previously proven to be a valuable source of ideas for future research, as well as leading to collaborative efforts; this funding will extend the opportunities for collaboration and provide intellectual stimulus to programs that have previously sent few or no representatives to this conference.","title":"Supporting Students Attending IUI 2009 Conference","awardID":"0914591","effectiveDate":"2009-02-01","expirationDate":"2010-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["450900"],"PO":["565227"]},"146555":{"abstract":"The growth and value of the Internet today are fueled by a variety of wireless edge networks including WiFi access points in homes and public places, wireless local area networks (WLANs) in workplaces, cellular data services such as 3G, multi-hop wireless mesh networks, wireless sensor networks, mobile ad hoc networks (MANETs), and delay-tolerant networks (DTNs). This diversity poses fundamental challenges to traditional network protocols that are fragile under highly fluctuating loss, delay, and topology characteristics, and completely break down in disruption-prone environments. The diversity increases management complexity?a network administrator must pick from an intimidating number of protocol options and optimizations tuned to one environment have to be re-engineered in a different environment?stifling innovation and the long-term value of interconnecting diverse wireless edge networks. <br\/><br\/>The goal of this proposal is to architect, analyze, and implement a simple network protocol stack that ensures robust performance across diverse wireless edge networks. The key insight is to incorporate uncertainty as a first-class design concern. We adopt an unusual approach: instead of trying to make protocols in otherwise well-connected environments robust to intermittent fluctuations or disruptions, we design for an extreme point in the design space?an always-partitioned network or a DTN?and work back from those insights to ensure robust performance of protocols even in well-connected mesh networks.","title":"CAREER: A Robust Protocol Stack for Diverse Wireless Edge Networks","awardID":"0845855","effectiveDate":"2009-02-01","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["497218"],"PO":["565303"]},"146346":{"abstract":"A pseudorandom generator is an efficient procedure that stretches a short input seed into a much longer sequence that looks random. These fascinating objects have a striking variety of applications, for example in algorithm design, cryptography, and complexity theory.<br\/><br\/>The main objective of this project is to obtain new pseudorandom generators. This objective will be approached from different, mutually enriching routes, whose unifying theme is the quest for pseudorandom generators that are unconditional, i.e., do not rely on any unproven assumption. The central points of the research are: (1) Obtain new unconditional pseudorandom generators for important computational models, (2) analyze and improve the efficiency of constructions of pseudorandom generators from assumptions, and (3) develop new paradigms and interdisciplinary connections.<br\/><br\/>This research is closely integrated with a program to achieve broad impact through education on multiple levels. Specific points of this program are: (1) Develop new theory courses, (2) involve students at all levels, and (3) foster interdisciplinary collaboration.","title":"CAREER: New Pseudorandom Generators: Unconditional Results and Efficient Constructions (TOC)","awardID":"0845003","effectiveDate":"2009-02-15","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1100","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}}],"PIcoPI":["550308"],"PO":["565157"]},"146588":{"abstract":"With the increasing demand of ubiquitous sensing and cyber-physical interaction, wireless sensor networks have emerged as one of the key technologies for many long-term applications such as such as habitat monitoring, microclimate study, structural integrity analysis, precise agriculture, traffic engineering and assisted living. Compared with competing high-end technologies, sensor networks are acclaimed as low-cost, low-profile, and easy to deploy. These attractive advantages, however, imply that resources available to individual nodes are severely limited. Among them, energy constraint is by far the most critical hurdle hindering the practical deployment of this emerging technology. A central challenge addressed by this project is to sustain the operation of wireless sensor networks for years in energy-dynamic environments. The driven idea of this project is energy-synchronized computing ?a holistic approach to synchronize sensor network activities with dynamic energy supply from the environments. The expected deliveries of this project are (i) the design and implementation of sustainable sensor nodes, (ii) the architecture principles, theoretical insights, design methodologies, and protocols for sustainable networking technology, (iii) the running prototype systems for long-term sustainable applications, and (iv) the educational test-beds, outreach activities for K-12 students and minority groups, and curriculum designs for undergraduate and graduate courses.","title":"CAREER: Energy Synchronized Computing in Sustainable Sensor Networks","awardID":"0845994","effectiveDate":"2009-02-01","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["526936"],"PO":["565303"]},"146478":{"abstract":"The theoretical computer science community has recently witnessed a significant expansion in research interest at the intersection of algorithms and game theory. As part of this trend, there has also been a resurgence of interest in ordinal matching problems, where one seeks to pair up elements in two or more sets, with the quality of a solution characterized in game theoretic terms by ranked preference lists of the individual elements participating in a matching problem, rather than in terms of a global objective function involving explicit numeric costs. Ordinal matching problems arise in a diverse number of applications in practice, including matching medical school graduates to residencies at hospitals, maximizing the number of donor matches in kidney exchange networks, and efficient load balancing on the Internet. Dr. Dean will develop improved algorithms for a broad range of ordinal matching problems, helping to bridge the gap in complexity between methods for ordinal matching and traditional cost-based matching problems.<br\/><br\/>Dr. Dean is an award-winning teacher and also serves as the associate director for the USA Computing Olympiad (USACO), where his training initiatives increase the enthusiam and algorithmic problem-solving proficiency of students at the high-school level.","title":"CAREER: Algorithmic Aspects of Ordinal Matching Problems","awardID":"0845593","effectiveDate":"2009-02-15","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["539076"],"PO":["565251"]},"146215":{"abstract":"This project is studying the effectiveness of dynamic strategies for provisioning data intensive applications by conducting a thorough performance evaluation of alternative provisioning strategies using the NSF CluE facility and the Apache Hadoop programming environment. Current systems adopt a \"one size fits all\" and relatively static solution approach even as they serve applications with a wide range of access and processing needs. The reference data sets in the study are high-resolution topographic data sets from airborne LiDAR surveys. The performance of alternative solutions using parallel database technology versus the Hadoop environment is being evaluated. Hybrid strategies, which blend the parallel database approach with the Hadoop-based approach?based, for example, on user directives and\/or workload analysis?are also being tested and evaluated. The research will contribute to an understanding of the performance tradeoffs in dynamic provisioning strategies for data intensive applications. The potential impact is a reassessment of how data archives are implemented and data sets served to a broad user community based on on-demand and dynamic approaches to provisioning data sets, as opposed to the current static approaches. <br\/><br\/>The results from this study will include a thorough performance evaluation and recommendations on the best use of large cluster computing environments for supporting data intensive applications, and an evaluation of a dynamic, blended approach to data management. Results will be disseminated via professional conferences and journals. The recommended approaches will be implemented in real data intensive environments, such as the OpenTopography.org portal.","title":"Performance Evaluation of On-Demand Provisioning of Data Intensive Applications","awardID":"0844530","effectiveDate":"2009-02-01","expirationDate":"2013-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7782","name":"CLUSTER EXPLORATORY (CLuE)"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0603","name":"Division of EARTH SCIENCES","abbr":"EAR"},"pgm":{"id":"7255","name":"GEOINFORMATICS"}}],"PIcoPI":["559496",390009],"PO":["560586"]},"146535":{"abstract":"Increasingly, different organizations need to securely share their private data to execute many critical tasks. Recently, several different approaches based on secure multi-party computation (SMC) and data sanitization techniques have emerged to enable privacy preserving distributed data analytics. Although SMC based privacy-preserving protocols allow the participating parties to learn only the final (accurate) result, they do not scale well for large amounts of data. On the other hand, sanitization based techniques allow organizations to reveal privacy sensitive data under some privacy guarantees by distorting the data. In many cases, significant data distortion that is needed to preserve privacy could lead to inaccurate results. <br\/>Due to the limitations of the current approaches, efficient and accurate privacy-preserving solutions are needed for handling large distributed data sets. To address this challenge, we design and develop a novel framework where sanitization and SMC techniques are integrated to develop efficient privacy-preserving solutions under resource constraints. Basically, we use the data sanitization techniques to get initial approximate results and carry out SMC operations selectively to increase the accuracy. Since we use existing techniques in a black box fashion, our approach is orthogonal to any new sanitization or SMC techniques.<br\/>Our new techniques will substantially decrease the cost of executing privacy-preserving distributed data analytics protocols. This will have a direct economic impact by opening the way for new applications (e.g., e-health and e-government applications) that are at present considered infeasible due to the lack of necessary privacy-preserving solutions that can work efficiently on large data sets.","title":"CAREER: An Integrated Approach For Efficient Privacy Preserving Distributed Data Analytics","awardID":"0845803","effectiveDate":"2009-02-01","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["558641"],"PO":["565327"]},"146205":{"abstract":"This project is investigating linguistic extensions to map\/reduce abstractions for programming large-scale distributed systems, with special focus on applications that manipulate large, unstructured graphs. It targets real-world graph analysis tasks found in comparative analysis of biological networks as an important case study.<br\/><br\/>The project is investigating the following specific questions: (i) how can highly unstructured graph-based formalisms be cast in the map\/reduce framework? (ii) how effectively can these specifications leverage existing map\/reduce infrastructure? (iii) how can these abstractions and their execution environments be enhanced to provide the semantic expressiveness necessary for programmability and scalable performance? (iv) how can these analysis tasks be integrated into comprehensive scientific resources usable by the wider applications community? Answers to these questions entails exploring linguistic extensions to existing map\/reduce abstractions, defining new implementations on wide-area multicore\/SMP platforms, and crafting an expressive graph analysis toolkit suitable for realistic deployment in important domains such as systems biology.<br\/><br\/>Results that arise from this project advance the state-of-the-art in analysis of large sparse unstructured graphs and directly impact a very broad class of scientific applications. Beyond specific target applications in biology, graph-based formalisms find direct applications in social sciences (social networks), recommender systems, and commerce (networks of transactions).","title":"Eager Maps and Lazy Folds for Graph-Structured Applications","awardID":"0844500","effectiveDate":"2009-02-01","expirationDate":"2013-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7782","name":"CLUSTER EXPLORATORY (CLuE)"}}],"PIcoPI":["540776","558390"],"PO":["560586"]},"146525":{"abstract":"Cyber-physical systems (CPSs) allow computer systems to monitor and control the physical world in a new way that could revolutionize many areas of science and engineering. However, they are often too complex for non-specialists to use. The aim of this work is to develop new technology to manage this complexity, enabling scientists and engineers to use CPSs just like other tools and instruments. This research takes a comprehensive approach to macroprogramming -- the task of programming an entire network of devices as a single, programmable substrate. This research exploits global, network-wide information about a CPS provided by a macroprogram to improve traditional software engineering techniques such as testing, debugging, analysis, and optimization. New techniques are being developed that use global information to optimize system performance, automatically generate test cases, and reduce the state space for analysis. This work is developing new programming abstractions that allow the separation of the application logic from quality-of-service requirements and hardware requirements, improving code portability and reuse. This research will produce a comprehensive development environment for CPSs called MacroLab. The new tools developed will greatly simplify the process of their programming and make them more accessible to non-experts. By taking a holistic view of the network and its software, MacroLab will manage a range of complex, interacting issues that would be extremely difficult to manage by hand. MacroLab will be tested pilot studies, including environmental monitoring. A graduate CPS course will be developed. MacroLab will be used for course experiments and in senior capstone projects.","title":"CAREER: MacroLab: a Comprehensive Macroprogramming System for Cyber-physical Systems","awardID":"0845761","effectiveDate":"2009-02-15","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["543576"],"PO":["561889"]},"146536":{"abstract":"To assert their legitimacy, French kings were borne under witness, and awoke, bathed, and dressed in public. America's Congress implemented a Freedom of Information Act to create methods for citizens to audit their government. These examples show how traditionally, organizations establish their legitimacy through protocols for disclosure.<br\/> <br\/>But disclosure has its practical limits; even organizations need a modicum of privacy. This project aims to balance the needs for both legitimacy and privacy by replacing disclosure protocols by more nuanced cryptographic ones. <br\/> <br\/>Although well-studied cryptographic protocols can help achieve this goal, several key challenges must be addressed. As a conceptual challenge, this project studies how the use of cryptographic protocols may inadvertently introduce ways for individuals to cheat by colluding. The eventual goal is to eliminate this phenomena. As an implementation challenge. this project proposes a principled way to transform high-level specifications of special cryptographic protocols into implementations. Finally, as an efficiency challenge, this project studies a promising ``optimistic rational'' method for protocol design that can dramatically reduce communication complexity.<br\/> <br\/>In summary, this project studies methods organizations can use to establish their legitimacy by analyzing new models, new ways of organizing communication, and new methods for implementation. To disseminate these ideas, this project's educational activities include course development, outreach to high school teachers so that ideas from cryptography can be woven into their lessons, direct interaction with high school students, development of privacy tools, and mentoring.","title":"CAREER: Legitimacy through Cryptography","awardID":"0845811","effectiveDate":"2009-02-15","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["486395"],"PO":["565239"]},"146228":{"abstract":"Science is becoming a data management problem. Advancements in sensing and computational modeling have dramatically increased data acquisition rates, establishing queries --\"in ferro\" experiments -- as an essential method of scientific discovery alongside in situ, in vitro, and in silico experiments. Unfortunately, the infrastructure to design and conduct in ferro experiments over massive datasets has not kept pace with our collective ability to create these datasets. Computational modelers, who have long enjoyed the benefits of a research focus on creating larger and faster CPU farms, now face terabytes of simulation results in which deep insights into the health of the planet remain locked. The key is seamlessness: to interactively analyze these data, quantitatively and qualitatively, without regard to boundaries manifesting from time and space domains, physical location, hardware architecture, storage medium, or file organization.<br\/><br\/>This project is building a new infrastructure that uses the CluE platform to allow ad hoc, longitudinal query and visualization of massive ocean simulation results at interactive speeds. This infrastructure leverages and extends two existing systems: GridFields, a library for general and efficient manipulation of simulation results; and VisTrails, a comprehensive platform for scientific workflow, collaboration, visualization, and provenance. By cloud-enabling these systems, the proposed infrastructure provides: (1) seamless access to the 10 year history of simulation results at interactive speeds; (2) an architecture and execution strategy that exploit both remote cloud and local desktop resources; and (3) a provenance capture and manipulation platform that enables repeatability, code reuse, forensics, and collaboration.","title":"Where the Ocean Meets the Cloud: Ad Hoc Longitudinal Analysis and Collaboration Over Massive Mesh Data","awardID":"0844572","effectiveDate":"2009-02-15","expirationDate":"2012-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7782","name":"CLUSTER EXPLORATORY (CLuE)"}}],"PIcoPI":["531545"],"PO":["543481"]},"146537":{"abstract":"Today's cognitive radio is characterized by its capability to perceive the existence of spectrum holes through spectrum sensing, and then transmitting on these unutilized frequencies. While each individual cognitive radio is very capable and can make independent decisions, lack of user coordination and network control raises serious issues in efficiency, security and resource waste in wireless environments. These problems call for fundamental changes in cognitive communication network design. <br\/><br\/>In this research, we introduce and develop the concept of cognitive network, which is defined as an intelligent wireless system that can collect and analyze the current network conditions, and then make real-time corresponding changes in network operating parameters, such as modulation scheme, transmission power, carrier frequencies, data frame structure, coding schemes, resource allocation and security management. We provide a comprehensive framework for the development of cognitive networks from a network-centric perspective. More specifically, we plan to: (i) Introduce a novel architecture for cognitive network; (ii) Design efficient and secure resource management protocols; (iii) Develop highly efficient and resilient anti-interference\/interception systems through multi-layer diversity; (iv) Develop cryptographic algorithms and protocols for anonymous routing and network integrity.<br\/><br\/>The proposed research on cognitive networks introduces innovative methodologies on architecture development, system design, secure and efficient network management. It will significantly improve spectral efficiency, security and interoperability of communications between versatile wireless devices, and therefore provides an ideal human-technology platform for e-commerce, national security, environmental protection, health monitoring, as well as many future applications that can benefit from fast and reliable information exchange.","title":"CAREER: Towards Cognitive Communications in Wireless Networks","awardID":"0845812","effectiveDate":"2009-02-15","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["523780"],"PO":["557315"]},"146427":{"abstract":"This research will examine two related issues: (1) how to motivate people to contribute more to communities such as open source software and Wikipedia that produce public goods, and (2) how to strengthen people's self-concepts and relationships with others by using content they create online to support reminiscence. This work deeply intertwines computing and social science, using insight about people's motivation, goals, and behavior to drive models, algorithms, and interfaces that leverage people's online activity to create value for individuals and society. The online nature of this activity allows it to be aggregated into large data sets for modeling (e.g., social network analysis) and mining (e.g., collaborative filtering); a major theme of the research is to effectively wring more value out of the activities people already do.<br\/><br\/>Understanding why people act online will lead to process models that explain important features of the data people generate through their actions as well as new algorithms for exploiting that data. For example, the research will model how critical events and roles people adopt affect people's contributions over time in Wikipedia. Such models models will drive algorithms that expose people to other people, groups, tools, policies, and group norms in contexts the models suggest will increase people's motivation to contribute.<br\/><br\/>Understanding users' goals will also lead to new applications for data and more effective interfaces for presenting it. The research will study how and why people reminisce through a series of lightweight prototypes that cue memories, as well as through analysis of online behavior in social media. This work will lead to algorithms that capture memory-laden content from activity in social media and interfaces that effectively use that content to support reminiscence. Preliminary work suggests that spontaneous, mobile delivery of appropriately chosen reminders promises to increase the value people derive from the content they create.<br\/><br\/>More broadly, the process of designing these models, algorithms, and interfaces will lead to insights about using social science theory in design that can be captured and shared with practitioners, new methodologies for analyzing complex social data, and the production of useful behavioral datasets that will benefit other researchers. Increasing participation in public goods like Wikipedia will improve the individual experience of members and the social goods they create. Tools developed in the domain of reminiscing have the potential to improve many people's lives, especially as the population ages. The education plan provides for richer research experiences through conference attendance and summer exchange programs with other labs. It also helps students develop the interdisciplinary attitudes and skills needed for this work through courses that look at real systems and the data they provide from both technological and social perspectives.","title":"CAREER: Leveraging Online Behavior to Support Knowledge and Memory","awardID":"0845351","effectiveDate":"2009-02-01","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["565070"],"PO":["564456"]},"146207":{"abstract":"Progress in the field of machine translation (MT) has come to depend heavily on open-source toolkits, which make it easier for new research groups to tackle the problem at lower cost, broadening participation. Unfortunately, toolkits have not kept up with modern computing infrastructure (e.g., the MapReduce framework) required for modern \"big data\" approaches to MT, the \"primitives\" in most toolkits are hardly extensible to new models since they focus on pipeline components rather than algorithmic concepts, and experiment management has been all but ignored.<br\/><br\/>This project is developing the Integrated Cluster Computing Architecture (INCA) for translation to overcome these challenges, by implementing an extensible, open-source toolkit that can leverage MapReduce clusters and flexibly implement many types of MT systems. MT is not a perfect fit for MapReduce (it has massive memory footprints and requires iterative algorithms); new algorithms are being developed to take advantage of the framework without being limited by it. Experiment management, evaluation, and advice about \"best practices\" are also part of the toolkit, to make it as widely accessible as possible.<br\/><br\/>This project is expected to have broad impact in MT research through the open-source toolkit to be made available to the research community. A course project suitable for undergraduates will be developed and shared openly using the toolkit. Technical solutions to problems in large-scale, parallelized MT will be applicable in areas of data-intensive natural language processing and machine learning, and elements of the toolkit are expected to be useful in such research efforts as well.","title":"INCA: An Integrated Cluster Computing Architecture for Machine Translation","awardID":"0844507","effectiveDate":"2009-02-15","expirationDate":"2012-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7782","name":"CLUSTER EXPLORATORY (CLuE)"}}],"PIcoPI":["467050","563246"],"PO":["560586"]},"146328":{"abstract":"With the advent and continuing spread of the Internet and the World-Wide Web, information resources are becoming more and more widely available. As people in all walks of life try to use these resources to find answers to questions about issues ranging from finance to personal health, there is a general recognition that it is very difficult for individuals to find relevant information. One approach to dealing with this problem is to combine the abilities and experiences of multiple information seekers. Future information retrieval systems will therefore have to focus not only on how individuals can access and search the volumes of available information, but also on how they can collaborate with each other to find the most relevant information that meets their needs. The mounting evidence that collaborative information behavior (CIB) plays an important role in organizational work notwithstanding, most information retrieval systems (and their underlying conceptualizations of information behavior) still adopt the individual user's perspective. Focusing solely on individual information behavior has led to processes and technologies that often constrain CIB, which can be acutely problematic in settings where teams and team work are important. The PI argues that while individual information behavior cannot be ignored, we must strive to develop processes that equally support CIB, because effective integration of information retrieval technology into collaborative environments requires us to incorporate not eliminate collaboration in these technologies. His goal in this project is to address our current inability to do that, by improving our theoretical understanding of the CIB process and by advancing the design of information retrieval systems as well, in the hope of thereby alleviating the impediments to team success in critical domains. To these ends, the PI will investigate CIB in team settings within the healthcare and education domains. He will develop a model of CIB, design and implement a collaborative information retrieval prototype system, and conduct both laboratory and field evaluations of it. Project outcomes will include a better understanding of how and why people collaborate when searching for information, and how to design technologies that effectively support that collaboration.<br\/><br\/>Broader Impacts: This research will lead to the development of new processes and technologies that will allow people to share their knowledge, techniques, and results with each other in order to quickly and effectively meet their information needs.","title":"CAREER: Collaborative Information Behavior: Exploring and Supporting Collaboration during Information Seeking and Retrieval Activities","awardID":"0844947","effectiveDate":"2009-02-01","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["559463"],"PO":["565227"]},"146229":{"abstract":"This project is studying research challenges to support efficient fuzzy queries on large text repositories using the MapReduce\/Hadoop parallel computing paradigm. Supporting fuzzy queries is becoming increasingly more important in applications that need to deal with a variety of data inconsistencies in structures, representations, or semantics. Many existing algorithms require an offline analysis of data sets to construct an efficient index structure to support online query processing. Fuzzy join queries of data sets are more time consuming due to the computational complexity. The PI is studying three research problems: (1) constructing high-quality inverted lists for fuzzy search queries using Hadoop; (2) supporting fuzzy joins of large data sets using Hadoop; and (3) using the developed techniques to improve data quality of large collections of documents. The PI is collaborating with industrial partners on these topics.<br\/><br\/>The techniques developed in this project will have a broad impact on many information systems that need to support approximate query processing on large data sets. The specific areas where the project is likely to have the most direct impact are Web search, enterprise search, data integration, data cleaning, and query relaxation. These areas have many data-intensive applications in scientific research, commercial systems, and Web-data management. The PI is also using the results of this research to provide teaching materials for students to learn the MapReduce\/Hadoop computing paradigm to process large amounts of information.","title":"Supporting Efficient Fuzzy Queries on Large Text Repositories Using Hadoop","awardID":"0844574","effectiveDate":"2009-02-15","expirationDate":"2012-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7782","name":"CLUSTER EXPLORATORY (CLuE)"}}],"PIcoPI":["385755"],"PO":["469867"]},"146219":{"abstract":"Science is becoming a data management problem. Advancements in sensing and computational modeling have dramatically increased data acquisition rates, establishing queries -- \"in ferro\" experiments -- as an essential method of scientific discovery alongside in situ, in vitro, and in silico experiments. Unfortunately, the infrastructure to design and conduct in ferro experiments over massive datasets has not kept pace with our collective ability to create these datasets. Computational modelers, who have long enjoyed the benefits of a research focus on creating larger and faster CPU farms, now face terabytes of simulation results in which deep insights into the health of the planet remain locked. The key is seamlessness: to interactively analyze these data, quantitatively and qualitatively, without regard to boundaries manifesting from time and space domains, physical location, hardware architecture, storage medium, or file organization.<br\/><br\/>This project is building a new infrastructure that uses the CluE platform to allow ad hoc, longitudinal query and visualization of massive ocean simulation results at interactive speeds. This infrastructure leverages and extends two existing systems: GridFields, a library for general and efficient manipulation of simulation results; and VisTrails, a comprehensive platform for scientific workflow, collaboration, visualization, and provenance. By cloud-enabling these systems, the proposed infrastructure provides: (1) seamless access to the 10 year history of simulation results at interactive speeds; (2) an architecture and execution strategy that exploit both remote cloud and local desktop resources; and (3) a provenance capture and manipulation platform that enables repeatability, code reuse, forensics, and collaboration.","title":"Where the Ocean Meets the Cloud: Ad Hoc Longitudinal Analysis of Massive Mesh Data","awardID":"0844546","effectiveDate":"2009-02-15","expirationDate":"2011-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7782","name":"CLUSTER EXPLORATORY (CLuE)"}}],"PIcoPI":["521992","521991"],"PO":["427499"]},"146506":{"abstract":"One of the most significant recent advances in wireless networks is the<br\/>Cognitive Radio Network (CRN), which can allow unlicensed (or secondary) users to access spectrum bands allocated to licensed (primary) users, without disrupting their performance.<br\/>Since many licensed spectrum bands have been found to be greatly underutilized,<br\/>CRNs can potentially enhance the spectrum usage significantly.<br\/>The basic principle underlying CRNs is to first sense the spectrum usage by primary users, and then allocate power levels and channels opportunistically to the secondary users, so that the interference levels at primary users are within an acceptable threshold. Most theoretical analyses of protocols in such networks use disk\/graph based approximations (in which \"close-by\" links cannot transmit simultaneously) to model wireless interference; however, these are inadequate and can lead to infeasible solutions with unacceptable interference levels at the primary users.<br\/><br\/>The goal of this proposal is to examine the theoretical foundations of cross-layer optimization in Cognitive Radio Networks in the Physical interference model, which is considered a much better approximation of interference than disk based models. The results of this proposal will contribute to the theoretical underpinnings of the broader area of wireless networks, not just the application of CRN, because of the central role interference plays.","title":"CAREER: Cross-layer optimization in Cognitive Radio Networks in the Physical interference model based on SINR constraints: Algorithmic Foundations","awardID":"0845700","effectiveDate":"2009-02-15","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["516910"],"PO":["557315"]},"146606":{"abstract":"An emergent area of impact and significance is the application of mobile and ubiquitous computing technologies to chronic healthcare. The long-lasting nature of chronic medical conditions makes record-keeping and long-term analysis of diagnostic and evaluative measures extremely important and challenging. Capture and access technologies, i.e., ubiquitous computing technologies that enable recording and access to recorded data, are particularly promising for monitoring the effectiveness of interventions for chronic conditions. Health and behavioral data can be captured, analyzed, and mined over time, providing valuable evidence for tracking the progress of interventions. This research will examine the role that novel mobile and ubiquitous computing technologies can play in record-keeping for chronic care of young children. <br\/><br\/>Specifically, this research addresses three major challenges. First, technological interventions must be developed that support better record keeping and associated visualization and hypothesis testing to allow caregivers to understand the impacts of their pharmaceutical and behavioral interventions. Second, these interventions must be understood in the short-term to support testing of clinical efficacy and also over the lifetime of these patients whose chronic conditions can span several decades. Third, the focus of these technologies must be not only on capturing and allowing access to appropriate data but also in accomplishing these goals while easing the extensive burden on families.","title":"CAREER: Mobile and Ubiquitous Computing Technologies for Young Children with Chronic Health Conditions","awardID":"0846063","effectiveDate":"2009-02-15","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["519772"],"PO":["564456"]},"150710":{"abstract":"We propose to provide support for graduate students and postdoctoral researchers to attend a<br\/>conference on Engineering Principles for Biological Systems, to be held at Cold Spring Harbor<br\/>Laboratory on 10--13 December 2008. The conference is intended to foster cross-disciplinary<br\/>exchange of ideas and expertise between engineers, mathematicians and biologists interested<br\/>in the analysis of diverse biological systems through the application of engineering principles.<br\/>Support from this grant would be used to help offset the cost of the conference for graduate<br\/>students and postdoctoral researchers who wish to attend.<br\/><br\/>Intellectual Merit: Through the process of evolution, living systems retain solutions arisen by<br\/>chance to problems they must solve in order to survive. In the past, theoretical biology has<br\/>largely focused on explanations of the physico-chemical mechanisms behind such solutions,<br\/>while explanation in the form of function-solution pairs has been studied in a relatively ad hoc<br\/>manner and has not been approached from a disciplinary perspective. This conference will<br\/>promote the development of an emerging approach to theoretical biology with more formal<br\/>emphasis on design or engineering principles. Here, the premise is that although solutions or<br\/>designs in biological systems are not engineered but instead arise incrementally through natural<br\/>selection, they may nevertheless be studied in their existing forms in the framework of<br\/>engineering theories developed alongside human-engineered systems.<br\/>This conference is part of a series of workshops and conferences organized by Partha Mitra<br\/>(CSHL), Richard Murray (Caltech) and others to help foster a community of researchers working<br\/>on theoretical frameworks for understanding biological systems across a variety of scales. A<br\/>starting point for these theories can be drawn from courses taught in engineering departments.<br\/>The idea is therefore to start with major existing engineering theories (controls, communication,<br\/>computation) and to examine whether these apply to biological systems, and if not, what<br\/>modifications are in order. The conference series and this CSHL conference in particular, will<br\/>provide an educational opportunity for biological researchers to learn about engineering theories<br\/>which may be relevant to their work, and for engineering theorists and computer scientists to<br\/>learn about biological problems they might help to be understood. Each session at the<br\/>conference will have a two invited talks, one each by a biologist and a theoretician\/engineer,<br\/>integrated with a set of contributed talks, chosen from submitted abstracts.<br\/><br\/>Dissemination and Broader Impact: The proposed conference will foster this new approach to<br\/>understanding biological systems and the collaborative culture across disciplines that its<br\/>success will require. The conference venue and format are ideal for encouraging open<br\/>discussion and initiating collaborative efforts, and it is hoped that a continuing series of such<br\/>meetings will also encourage the development of an enduring and progressive theoretical<br\/>framework. To complement the direct training opportunity for conference participants, talks<br\/>presented at the conference will be put on a website for the benefit of the wider scientific<br\/>community. Options will be provided to individual presenters to make their talks publicly<br\/>available through the Leading Strand web site.","title":"CSHL Conference: Engineering Principles for Biological Sciences, December 10-13, 2008 in Cold Springs Harbor Laboratory, New York.","awardID":"0904373","effectiveDate":"2009-02-01","expirationDate":"2010-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7607","name":"ENERGY,POWER,ADAPTIVE SYS"}}],"PIcoPI":["561880","560613"],"PO":["564728"]},"142638":{"abstract":"This project explores connections between computational logic and polyhedral combinatorics through the paradigm of Quantified Polyhedral programming. Quantified Polyhedral programming encompasses Quantified Linear Programming (QLP) and Quantified Integer Programming (QIP); both the programming paradigms are extremely useful in modeling environment-dependent actions in real-time scheduling problems. Quantified Integer Programs can also be used to formally verify the correctness of programs through the mechanism of Abstract Interpretation. This project aims to provide a framework in which traditional notions of duality and convexity can be extended to the 2-person game setting. For instance, a typical optimization problem is defined by an optimization function and a convex set, called the domain of feasibility. In real-world applications, such as robot navigation, the domain is not fixed but varies continuously as a consequence of events initiated by the environment. Thus, the concept of optimality needs to be defined in a 2-person setting.<br\/><br\/>On a broader front, the investigator plans to significantly advance the state-of-the-art in Quantified Polyhedral Programming through a combination of innovative research and the integration of research themes into graduate and undergraduate education. This work will have the added benefit of increasing the participation of women and under-represented minorities in computer science research.<br\/><br\/>This award is co-funded by West Virginia EPSCoR.","title":"Polyhedral Approaches to Selected Problems in Computational Logic","awardID":"0827397","effectiveDate":"2009-02-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["543376"],"PO":["565157"]},"152946":{"abstract":"US-India Program for Exploratory Experiences for<br\/>Researchers and Students (PEERS)<br\/><br\/>The objective of this proposal is to organize a workshop focusing on ways to foster research and collaboration between Indian and US scientists in the area of distributed systems and networks, and to retain and encourage students to pursue advanced degrees in computer science. The workshop is being organized in conjunction with ICDCN 2009 (International Conference on Distributed Computing and Networking) at Hyderabad, India during January 3-6, 2009. A panel of 8-10 US and Indian scientists are to be invited to meet over two days and develop a set of recommendations for effective collaboration and refine them via interactions with other ICDCN participants. A comprehensive report on the recommendations will be generated and submitted to NSF. The workshop is planned to be followed up with activities to develop concrete collaboration proposals with the help of NSF Office of International Science and Engineering (OISE).<br\/><br\/>Both US and India are facing unique challenges in terms of interest of students in Computer Science and engineering discipline. This workshop intends to address some of these via collaborative programs and by exploiting the unique strengths of each country so that both can benefit and learn from each other. The collaboration is expected to lead to sustained activities where senior and junior researchers and graduate students in Computer Science from both India and US will benefit from exchange visits, student co-advising and other collaborative programs. The resulting synergy will help us recruit and retain better students in our advanced degree in computer science and help improve the participation of women and minorities.","title":"US-India Program for Exploratory Experiences for Researchers and Students (PEERS)","awardID":"0912210","effectiveDate":"2009-02-01","expirationDate":"2010-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["472231"],"PO":["493916"]},"150719":{"abstract":"The Institute of Electrical and Electronic Engineers requests travel support for participants in the Broader Engagement (BE) Program at the Supercomputing (SC) 2008 Conference. That program aims to increase opportunities for U.S. undergraduate, graduate, faculty, industry professionals, and researchers to learn about high performance computing (HPC). It emphasizes the participation of members of the groups that are underrepresented within the HPC community: African Americans, Hispanics, Native Americans, Alaska Natives, Native Hawaiians, Pacific Islanders, persons with disabilities, and women. Participants will have the opportunity to connect with mentors, and attend a doctoral symposium, a student job fair, and other special sessions. This award will make it possible for additional participants to attend.","title":"SC08 Broader Engagement Program","awardID":"0904417","effectiveDate":"2009-02-15","expirationDate":"2010-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}}],"PIcoPI":["553190"],"PO":["561855"]},"148071":{"abstract":"This project is a Numerical Computing and Optimization REU site hosted by Florida International University (FIU). This site?s region, Southeast Florida, is a rapidly growing communication industry hub. This REU Site contributes to a well trained technical workforce in response to information from to the US and Florida Bureau of Labor Statistics indicating that the need for computer systems and data communication analysts is projected to grow during the 2006-2016 period. FIU is recruiting a diverse group of students and engaging them in a research experience to ensure that greater numbers will attend graduate school. Each summer 10 students are selected from across the country to participate in a variety of research projects that are supervised by the faculty for a period of 10 weeks. Projects span fundamental multidisciplinary areas in reconfigurable algorithms, software and operating systems for emerging applications. Students also attend a number of technical and professional seminars. <br\/><br\/>Intellectual Merit: Undergraduate students participating in this summer program perform supervised research and obtain rich experiences in a diverse and multicultural environment. Female and under represented minorities are selected from across the country to participate in the program, thus giving a diverse perspective and strength to the research. The student projects allow participants to learn fundamental principles of theoretical and practical telecommunications and networking. The undergraduate students attend structured training sessions to learn how research is conducted and how to be effective team members. The research projects involve a combination of model design, development and testing of algorithms, and software and tools necessary to design and validate secure, context-aware and adaptable next generation computing and communication systems and devices. <br\/><br\/>Broader Impacts: This project engages students from underrepresented groups in research and exposes them to the possibilities of graduate study and encourages them to choose a career path involving research. The students develop intellectual confidence as they associate with other students who share their commitment to science and engineering. This REU site advances the research skills of the undergraduate participants and improves the employment options for these students. This provides a stronger technically educated American workforce. The REU research advances are integrated into the curriculum of related classes at FIU and thus benefit other students.","title":"REU SITE: Numerical Computing and Optimization in Multidisciplinary Applications: Methods and Software","awardID":"0851733","effectiveDate":"2009-02-15","expirationDate":"2013-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1139","name":"RSCH EXPER FOR UNDERGRAD SITES"}}],"PIcoPI":["539039",394642],"PO":["523800"]},"146290":{"abstract":"The ever increasing amount of data that is being communicated and stored in our information reliant world poses unique challenges to the traditional notions of efficient data processing. For example, as we pack more data into physical media such as a transmission cable or a hard disk, errors will occur more frequently than can currently be handled by such devices. Additionally, as we transmit more data through our routers, they will have less resources available per packet for processing. As a final example, large number of buyers in an online market will try to ``game\" the system for their selfish gain. It has become clear that the traditional notions of efficient computation are not capable of handling these growing complexities. In particular, it is provably impossible to compute solutions under these new requirements that are as good as those that were possible with the previous lax notions of efficient computation. Thus, these new obstacles necessitate designing algorithms to compute approximate solutions. This project will consider fundamental open questions in and applications of ``list decoding\" (an approximation of the traditional ``unique\" decoding that can handle more errors than before), ``sub-linear\" algorithms (algorithms that scale well with data by using amounts of resources that are sub-linear in the input size) and pricing algorithms (which deal with input data that are controlled by selfish agents).<br\/><br\/>Course material developed in the educational component of this project will be made freely available on the Internet and will be used to update\/create relevant Wikipedia pages. The PI will also take advantage of the geographical proximity of active theory research groups to Buffalo by organizing annual workshops to promote and foster regional interaction among researchers in theory of computation.","title":"CAREER: (TF\/TOC) Efficient Computation of Approximate Solutions","awardID":"0844796","effectiveDate":"2009-02-15","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":["550387"],"PO":["565251"]},"146380":{"abstract":"The semiconductor industry has hit a wall - chip-level power and cooling constraints have slowed the march of clock frequency, forcing industry to instead bet on multicore to provide energy-efficient performance scalability. Although the multicore trend poses daunting challenges for application developers, it also creates new opportunities unavailable in traditional multi-chip multiprocessors: the drastic change in the relative costs of on-chip communication and computation enable application designs with tightly-coupled threads and frequent sharing that would prove latency- and bandwidth-prohibitive in traditional multiprocessors. Unfortunately, current multicore memory systems are inflexible and poorly-suited to support coordinated execution, as they provide no direct means for core-to-core communication or to optimize data placement on chip. Moreover, intra-chip access patterns vary drastically across applications - there is no one-size-fits-all static cache architecture. <br\/><br\/>To address these deficiencies, this project seeks to develop a Polymorphic Multicore Cache Architecture (PMCA) - a modular on-chip cache design where software configures primitive hardware mechanisms to provide a cache architecture suited to a specific workload. The PMCA concept will be pursued along three fronts: First, PMCA?s architectural interface and behavioral design through a full system, cycle accurate simulation will be conducted. Second,language level constructs, software management policies, and virtualization of PMCA through FPGA based functional emulation will be investigated. Third, trade-offs in performance, area, and power for various designs will be examined.","title":"CAREER: Programming Interfaces and Hardware Designs for a Polymorphic Multicore Cache Architecture","awardID":"0845157","effectiveDate":"2009-02-15","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["508097"],"PO":["366560"]},"146182":{"abstract":"Many important image processing tasks involve solving some type of inverse problem. Examples include: eliminating noise, compensating for low quality optical systems, enhancing a black-and-white image with plausible colors and improving the resolution of an image. All are ill-conditioned and so their solutions must incorporate assumptions about natural images. Although researchers have made astounding progress on these problems in the last fifty years, a key limiting property of current techniques is that they analyze their input more or less in isolation.<br\/><br\/>This research will ask the question of whether an image can be improved by evaluating trillions of image patches constructed from millions of on-line images and using the set of relevant patches to improve the quality of the original. This work will focus on one particular inverse problem: super-resolution, or increasing the resolution of an image to reveal missing details. The IBM\/Google compute cluster in conjunction with the MapReduce programming framework will be instrumental in developing and evaluating these data-intensive algorithms. This research will investigate scaling existing example-based techniques to use a massive training database and develop entirely new techniques that better capitalize on this amount of data by incorporating higher-level patterns in images such as scene categories and object boundaries.","title":"Image Super-Resolution Using Trillions of Examples","awardID":"0844416","effectiveDate":"2009-02-01","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7782","name":"CLUSTER EXPLORATORY (CLuE)"}}],"PIcoPI":["448317"],"PO":["565136"]},"146591":{"abstract":"CAREER: Dynamic Run-Time Tuning of Parallel, Adaptive and Hybrid Applications<br\/><br\/>The complexity of today?s High Performance Computing systems mandate significant efforts by end users and application developers to tune their code for each platform. Processor and node architecture, network interconnect and the software stack all expose a significant number of parameters which influence the performance of an application. These parameters are furthermore often correlated, which further complicates the predictability of the performance of any application. The most popular tuning approach as of today applies a static tuning for the most time consuming operations of the code, i.e. the performance of different versions of the same operation is evaluated for certain problem sizes and the best performing version is chosen for the subsequent executions of the application. However, this approach is not practical for adaptive applications. These applications vary the problem sizes at run-time, e.g. by locally refining the computational mesh based on certain error criteria. Thus, the problem sizes are typically unknown in advance and therefore expensive operations cannot be tuned for the relevant problem sizes.<br\/><br\/>This project focuses on run-time tuning of parallel, adaptive applications utilizing either a distributed memory parallel programming model such as MPI or a hybrid shared memory\/distributed memory parallelization strategy using OpenMP and MPI. The focus of the project is on introducing novel run-time selection algorithms which incorporate knowledge gathered from previous executions, algorithms from factorial design theory for very large parameter spaces and advanced algorithms from machine learning. The project also targets the development of a recommendation system, which presents a human readable form of experiences gathered from an optimization run in order to reuse them in other applications. <br\/><br\/>This proposal tackles one of the most pressing and fundamental problems in High Performance Computing. Code portability and maintainability on one side and performance on the other side often seem to be contradicting goals. The project develops the fundamental knowledge required to develop performance portable parallel code and thus avoid the necessity to maintain multiple versions of the same code for different platforms.","title":"CAREER: Dynamic Run-Time Optimization of Parallel, Adaptive and Hybrid Applications","awardID":"0846002","effectiveDate":"2009-02-15","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["558507"],"PO":["535244"]},"146086":{"abstract":"This goal of this research project is to understand the tradeoffs between the MapReduce and parallel DBMS approaches to performing large-scale data analysis over large clusters of computers, and to bring together ideas from both communities. Both MapReduce and parallel database systems provide scalable data processing over hundreds to thousands of nodes. Both provide a stylized, high-level programming environment that allows users to efficiently filter and combine datasets while masking much of the complexity of parallelizing computation over a cluster. But they differ in substantial ways as well, such as their approaches to dealing with fault tolerance, their data modeling requirements, their query flexibility, and their ability to function in a heterogeneous processing environment.<br\/><br\/>This multi-university team of researchers is investigating the effect of these differences on the performance and scalability of these two approaches. The research team is running a set of experiments that compare an open source MapReduce implementation (Hadoop) to two commercial parallel database systems (DB2 and Vertica) on a benchmark that includes a range of tasks designed to assess the tradeoffs between both approaches. The research team is seeking to understand which differences between the two approaches to performing large scale data analysis are fundamental tradeoffs, and which differences are possible to combine inside a single solution, so that ideas from one community can benefit the other.","title":"Collaborative Research: A Comparative Study of Approaches to Cluster-Based Large Scale Data Analysis","awardID":"0844013","effectiveDate":"2009-02-01","expirationDate":"2012-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7782","name":"CLUSTER EXPLORATORY (CLuE)"}}],"PIcoPI":["483585","525076"],"PO":["543481"]},"146230":{"abstract":"Astrophysics is addressing many fundamental questions about the nature of the universe through a series of ambitious wide-field optical and infrared imaging surveys (e.g. studying the properties of dark matter and the nature of dark energy). To accomplish these goals requires new methodologies for analyzing and understanding petascale data sets (with the data being collected at a rate 1000x greater than current surveys). This research focusses on exploring an emerging paradigm for data intensive applications, map-reduce(using Hadoop for the implementation of map-reduce), and how it scales to the analysis of astronomical images. The work is addressing the efficiency of map-reduce for determining spatial and temporal overlaps between terabyte scale imaging data sets when compared to standard database techniques. We are delivering new algorithms for indexing, accessing and analyzing astronomical images using map-reduce that can balance the load between the compute nodes on distributed systems. We are also delivering applications that will analyze the spatial distribution of star formation within galaxies (combining large multispectral data sets) and for identifying asteroids within a time series of data where the asteroid may be below the detection threshold of any one image. This work will have a broad range of applications to any data intensive field.","title":"Putting Astronomy's Head in the Cloud","awardID":"0844580","effectiveDate":"2009-02-01","expirationDate":"2012-01-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0302","name":"Division of ASTRONOMICAL SCIENCES","abbr":"AST"},"pgm":{"id":"1798","name":"SPECIAL PROJECTS (AST)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7782","name":"CLUSTER EXPLORATORY (CLuE)"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0600","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"1679","name":"INTERNATIONAL COORDINATION ACT"}}],"PIcoPI":["536675","392597"],"PO":["560586"]},"146252":{"abstract":"The proposal offers an innovative approach to automatic music audio analysis using signal processing and harmonic methods. This is a contribution to the field of Music Information Retrieval (MIR) based on isolating chord sequences in western tonal music archives. The approach is modeled in part on work in bioinformatics, particularly work in structure alignment. The proposed work intends to expand on current approaches to music analysis whcih are limited because of insufficient attention to temporality - a key aspect of musical composition. A new signal processing method is proposed for the isolation of chords and chord sequences.","title":"CAREER: Analyzing the Sequential Structure of Music Audio","awardID":"0844654","effectiveDate":"2009-02-01","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[390091],"PO":["563751"]},"146561":{"abstract":"In software engineering, dynamic analysis is the checking of correct program behavior during program executions. Dynamic analysis is advancing beyond traditional capabilities such as profiling, trace traversing, and simple property verification. The broader ramifications of dynamic analysis hinge on meeting a key challenge called dynamic reasoning, which asks what transformations on a program execution would lead to logical satisfaction of the properties. For example, in data race detection, deciding whether a data race is benign can be translated into deciding if changing the order of the two conflicting memory accesses affects the output. Automatically patching faulty code is equivalent to looking for changes so that the desired output can be produced. <br\/><br\/>This research targets a number of key challenges for dynamic reasoning. Novel canonical representations facilitate aligning executions, particularly the original execution and its transformed version, so that execution comparison can be performed at compatible places. Efficient transformation techniques include checkpointing long executions and selectively perturbing execution state to observe satisfiability. A reasoning engine based on constraint solving aims to translate an arbitrary execution region into symbolic constraints and then use a solver to reason about satisfiability. Using dynamic slicing to delimit the execution region is the key to scalability. Among the broader impacts will be certifiably more correct software.","title":"CAREER: Scalable Dynamic Program Reasoning","awardID":"0845870","effectiveDate":"2009-02-15","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["550848"],"PO":["523800"]},"146595":{"abstract":"Tiny, embedded computers will collect real-time data on our homes, our cities, and our planet. Collecting and processing rich streams of sensor data will transform public health, medicine, natural resource management, science, engineering, and disaster response. But today, despite years of research and engineering, these sensor networks often fail to meet their performance goals. Data yields are low; networks last weeks, rather than months; long downtimes are common.<br\/><br\/>Professor Levis proposes a long-term agenda of research and education to improve the robustness, manageability, and scalability of low-power wireless sensing systems. The dominant design principle behind this agenda is network visibility. Described colloquially, visibility measures a user?s ability to identify the cause of a network event, such as a packet drop. We propose to research how to make networks more visible.<br\/><br\/>The research agenda is grounded in the exploration, development, and evaluation of the Mote Network<br\/>(MNet) architecture, an open-source protocol suite and toolkit for sensor network application development and deployment. The protocol suite will include existing dominant protocols redesigned for improved visibility as well as novel protocols whose designs maximizes visibility. Our principal goal is to make long-lived sensornets significantly simpler to deploy and maintain. Our second goal is to apply our lessons learned to wireless meshes more generally.","title":"CAREER: Visibility as a Wireless Sensor Network Design Principle","awardID":"0846014","effectiveDate":"2009-02-01","expirationDate":"2014-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["475015"],"PO":["565303"]},"143086":{"abstract":"Problems that require communication between among users abound in modern life. Such problems present a collection of users and all possible links among all pairs of users, each link carrying a cost. The links can be directed or undirected (in the undirected case both parties can exchange information along the link). The goal is to select a minimum cost collection of links under some communication constraints. The simplest example of such problem is that every user will be able to send a message to every other user perhaps via a series of links. One of the main goals of this proposal is to understand some of the most fundamental network design problems on directed networks whose exact approximability status remains unclear for a very long time. Directed networks appear frequently when modeling the problem by an undirected network is not enough. Applications for which the networks arising are naturally directed include web related problems, problems in social networks, problems on dynamic (namely changing) links in artificial intelligence and more. A crucial example is the directed Steiner problem that is to connect a set of given terminals (stations, users) to a given root (central command) by directed links at low cost. The intellectual merit of the proposal includes expanding our understanding of the power of approximation algorithms and their limitations. In a more broader context, the project will include the creation of a new graduate course on approximation algorithms in the Computer Science department at Rutgers University, Camden. Students taking the course will be encouraged to undertake research work in this subject, or alternatively, work on a large practical project that will compare the theoretical performance guarantees of approximation algorithms versus their performance in practice.","title":"Approximating Network Design Problems on Directed and Undirected Graphs","awardID":"0829959","effectiveDate":"2009-02-01","expirationDate":"2012-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["518386"],"PO":["565251"]},"146199":{"abstract":"This goal of this research project is to understand the tradeoffs between the MapReduce and parallel DBMS approaches to performing large-scale data analysis over large clusters of computers, and to bring together ideas from both communities. Both MapReduce and parallel database systems provide scalable data processing over hundreds to thousands of nodes. Both provide a stylized, high-level programming environment that allows users to efficiently filter and combine datasets while masking much of the complexity of parallelizing computation over a cluster. But they differ in substantial ways as well, such as their approaches to dealing with fault tolerance, their data modeling requirements, their query flexibility, and their ability to function in a heterogeneous processing environment.<br\/><br\/>This multi-university team of researchers is investigating the effect of these differences on the performance and scalability of these two approaches. The research team is running a set of experiments that compare an open source MapReduce implementation (Hadoop) to two commercial parallel database systems (DB2 and Vertica) on a benchmark that includes a range of tasks designed to assess the tradeoffs between both approaches. The research team is seeking to understand which differences between the two approaches to performing large scale data analysis are fundamental tradeoffs, and which differences are possible to combine inside a single solution, so that ideas from one community can benefit the other.","title":"Collaborative Research: A Comparative Study of Approaches to Cluster-Based Large Scale Data Analysis","awardID":"0844480","effectiveDate":"2009-02-01","expirationDate":"2012-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7782","name":"CLUSTER EXPLORATORY (CLuE)"}}],"PIcoPI":["532784"],"PO":["543481"]},"145980":{"abstract":"This goal of this research project is to understand the tradeoffs between the MapReduce and parallel DBMS approaches to performing large-scale data analysis over large clusters of computers, and to bring together ideas from both communities. Both MapReduce and parallel database systems provide scalable data processing over hundreds to thousands of nodes. Both provide a stylized, high-level programming environment that allows users to efficiently filter and combine datasets while masking much of the complexity of parallelizing computation over a cluster. But they differ in substantial ways as well, such as their approaches to dealing with fault tolerance, their data modeling requirements, their query flexibility, and their ability to function in a heterogeneous processing environment.<br\/><br\/>This multi-university team of researchers is investigating the effect of these differences on the performance and scalability of these two approaches. The research team is running a set of experiments that compare an open source MapReduce implementation (Hadoop) to two commercial parallel database systems (DB2 and Vertica) on a benchmark that includes a range of tasks designed to assess the tradeoffs between both approaches. The research team is seeking to understand which differences between the two approaches to performing large scale data analysis are fundamental tradeoffs, and which differences are possible to combine inside a single solution, so that ideas from one community can benefit the other.","title":"Collaborative Research: A Comparative Study of Approaches to Cluster- Based Large Scale Data Analysis","awardID":"0843487","effectiveDate":"2009-02-01","expirationDate":"2012-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7782","name":"CLUSTER EXPLORATORY (CLuE)"}}],"PIcoPI":["451905"],"PO":["543481"]},"148873":{"abstract":"0854959<br\/>Elghazawi<br\/><br\/>Description: This award is to support a US-Egypt ?Workshop on Software Development for Multicore and Heterogeneous Processors?, to be held in Cairo, Egypt, June 22 to 24, 2009. The U.S. organizer is<br\/>Dr. Tarek El-Ghazawi, Department of Electrical and Computer Engineering, George Washington University, Washington, DC. The Egyptian organizers are Dr. Hisham El-Shishiny, Advanced Technology Center, IBM, Cairo, and Dr. Ayman El-Dessouki, President, National Authority for Remote Sensing and Space Sciences, Cairo, Egypt. Due to unprecedented levels of integration, multicore, manycore and heterogeneous processor technologies are becoming widely available and used. Software, however, is lagging behind, and with this new array of exotic processor architectures, traditional sequential programming methods are no longer applicable. Both systems and application software have a long way to catch with these hardware developments, and computer scientists and engineers as well as application scientists across the world must work together to close this gap. The workshop will bring together U.S. computer scientists and engineers who are leaders in the architectural issues of such modern processors and who are aware of system software and application software requirements with Egyptian scientists who are focused on software engineering and development to tackle the new software challenges. The workshop attendees will include U.S. prominent researchers and select students. Egyptian participants will include scientists from IBM Egypt, Ain Sham University, Cairo University, Alexandria University, the National Research Center, and the National Authority for Remote Sensing and Space Science (NARSSS). The proposed workshop will be co-sponsored by the IBM Center for Advanced Studies at Cairo, Egypt. To ensure success, a follow-up focused meeting will be held a few months after the workshop in order to monitor the promote progress on the planned collaborations such as joint proposal writing. <br\/><br\/>Intellectual merits: These include identifying new operating systems and programming languages research directions to cope up with the new multicore\/heterogeneous processor challenge through a highly collaborative framework bringing together experts and students from US and Egypt. The resulting interactions may lead to practical suggestions for new programming models, new features to be incorporated in OS\/run-time systems, methods to migrate existing software applications to multicore systems. Longer range collaboration will be enacted by using this workshop and follow up event to produce joint research proposal(s) to funding agencies in Egypt and\/or the U.S. <br\/><br\/>Broader impacts: The broader impact lies in the fact that the proposed workshop is expected to result in innovative research directions, due to the participation of top experts in the field. The workshop would involve active participation of U.S. and Egyptian researchers and students including women from both sides. The workshop will be an opportunity to get the new generation of scientists to explore working together and understanding the differences in the culture of science across the globe.<br\/>This project is co-funded by the Office of International Science and Engineering and the Division of Computing and Communication Foundations.","title":"US-Egypt Workshop on Software Development for Multicore and Heterogeneous Processors, Cairo, Egypt, June 22-24, 2009","awardID":"0854959","effectiveDate":"2009-02-01","expirationDate":"2011-01-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7299","name":"Catalyzing New Intl Collab"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}}],"PIcoPI":["523119"],"PO":["540599"]}}