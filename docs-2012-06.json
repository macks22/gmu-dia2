{"196570":{"abstract":"This project involves supporting students to attend the ACM Sigmetrics conference to be held in London, UK in June 2012. Sigmetrics is the premier conference in the area of performance modeling and it is important to expose students to this conference, particularly in an environment where students tend to shy away from mathematical modeling. The students will be chosen based on a open competition and preference will be given to students who don't have any existing support or belong to underrepresented groups","title":"Student Travel Support for SIGMETRICS\/Performance 2012","awardID":"1239675","effectiveDate":"2012-06-01","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["545655"],"PO":["535244"]},"187275":{"abstract":"The cloud computing model, however appealing from economic and management perspectives, brings risks that should be understood before too much critical infrastructure \"moves to the cloud.\" While the privacy and information security risks are well-known, cloud computing may bring other long-term risks that are neither widely recognized nor addressed. EverCloud is a novel cloud computing model that explores and attempts to mitigate these risks.<br\/><br\/>First, clouds exacerbate security risks from timing side-channels, which current approaches cannot address without undermining the cloud business model. EverCloud introduces a Timing Information Flow Control (TIFC) model, providing a tool to reason about and limit timing channels despite fine-grained hardware resource multiplexing.<br\/><br\/>Second, cloud services built atop one another risk hidden interactions that might lead to unpredictable instabilities or \"meltdowns,\" as well as resource interdependencies that undermine a service's resilience to failure. EverCloud adapts labeling techniques to enforce stability constraints on reactive cloud computations, and to ensure independence in the provisioning of cloud hardware infrastructure.<br\/><br\/>Third, clouds exacerbate digital preservation challenges, because no one but a cloud application's provider can archive a \"working\" copy of the application and its data. EverCloud enables any stakeholder (e.g., customer, librarian) to create and independently preserve fully-functional \"snapshots\" of cloud applications, while mitigating the computing, storage, and bandwidth costs of preservation via proportionate cost-sharing among stakeholders.<br\/><br\/>By exploring these possible cloud computing risks and potential solutions, EverCloud may increase the security, robustness, and predictability of cloud computing systems throughout the many areas in which cloud computing is increasingly used.","title":"CAREER: From Storm Clouds to EverClouds: Heading Off Long-Term Cloud Computing Risks","awardID":"1149936","effectiveDate":"2012-06-01","expirationDate":"2017-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[502304],"PO":["565255"]},"189464":{"abstract":"The objective of the proposed research is to develop the foundations for resource allocation in femtocell networks, and evaluate the performance of the solutions using real testbeds. Wireless resource allocation in femtocell-based networks is particularly challenging due to four main reasons: (1) interference between femtocells and between femto- and macro-cells; (2) variable and unpredictable delays in signaling and data communication between each femtocell and the operator's network; (3) limited bandwidth for signaling over a wireless channel to a large number of femtocells; and, (4) involvement of three parties with differing priorities: the operator, the users, and the femtocell owners. The specific research tasks in this project are: (1) For legacy systems, develop distributed solutions for both downlink and uplink scheduling and handover under co-deployment of macro- and femto-cells that do not require any changes to existing hardware and standards; (2) Develop distributed, adaptive and self-organizing solutions (unconstrained by legacy requirements) for resource allocation by using a powerful tool from statistical physics, called Glauber dynamics; and (3) Design mechanisms to facilitate offline truthful auctions in practical settings involving the end-users, the femtocell owners, and the operator. The solutions will be implemented and evaluated on two testbeds under development at University of Michigan and at Ohio State University. The proposed research has the potential to significantly impact the cellular industry and end-users. Given the high penetration rates of cell-phones worldwide, this research has an immediate and widespread impact.","title":"NeTS: Medium: Collaborative Research: Enabling Cellular Services over Unplanned Femto-Cell Deployments: From Theory to Implementation","awardID":"1161404","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["509442"],"PO":["565303"]},"187088":{"abstract":"Malicious software (a.k.a. malware) is at the basis of most cyber-criminal operations, causing significant financial loss and posing great risks to national security.<br\/><br\/>This research creates novel network-centric behavior-based malware detection systems that automatically learn how to identify malware-compromised machines within a network, and that can self-tune to achieve the best possible trade-off between malware detection rate and false alarms for a given network. This self-tuning property is achieved by combining models of malware-generated network traffic with models of legitimate user-generated network activities to build hybrid detection models that can adapt to a specific network environment and accurately detect malware-generated network traffic crossing the network perimeter.<br\/><br\/>This new approach to malware detection takes into account events that occur within an entire network, rather than focusing on events that occur at each single host, and focuses on adaptive detection of all types of malware, rather than being limited to a specific malware type (e.g., botnets). Therefore, the detection systems resulting from this research will provide new effective detection capabilities that can complement current anti-malware technologies and significantly contribute to a better defense-in-depth strategy against malware.","title":"CAREER: Automatic Learning of Adaptive Network-Centric Malware Detection Models","awardID":"1149051","effectiveDate":"2012-06-01","expirationDate":"2017-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["550131"],"PO":["565327"]},"193062":{"abstract":"The proposal explores how software designers and developers with can obtain information about the power behavior of the software they are developing and guide them toward designing and developing more energy efficient solutions. Very little is understood today about what factors in software design\/development influence power consumption, and therefore this exploratory project will do empirical studies to measure the power consumption of executing software and map the power profiles to implementation and design properties of the software applications. The research will measure power consumption of executing software and map it to code sequences, then identify a set of program properties that are correlated to specific power consumption behavior. While research on energy sustainability has so far focused on the role of hardware design, compilation techniques aimed at optimizing with respect to power consumption, and operating systems, this exploratory project is aimed at understanding how the programming the source code can be correlated to low-power implementations.","title":"Shf: Eager: Exploring Relations Between Consumption And Software Engineering","awardID":"1216488","effectiveDate":"2012-06-01","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["527984","517186",517186,517187,517188],"PO":["564388"]},"189652":{"abstract":"\/O on High-End Computing (HEC) machines is increasingly becoming the killing performance bottleneck. However, conventional execution paradigms for HEC are computing-centric and have inherent limitations in addressing critical I\/O issues of data-intensive applications. There is a great need for developing unconventional execution paradigms to meet the growing I\/O demand of high-end computing.<br\/><br\/>In this project, the PIs propose a decoupled execution paradigm (DEP) to address I\/O bottleneck issues. DEP is the first paradigm enabling users to identify and handle data-intensive operations separately. The objective of the proposed research is three-fold: 1) understanding the execution paradigm requirement from the data-centric point of view, 2) studying the feasibility of the proposed decoupled execution paradigm, and 3) providing a partially implemented prototyping of DEP and its associated system design to support the first two objectives. Several technical hurdles have been identified, which include system architecture, programming model, and runtime system. Solutions are proposed and detailed plans are provided to evaluate the newly proposed decoupled execution paradigm.","title":"CSR: Medium: Collaborative Research: Decoupled Execution Paradigm for Data-Intensive High-End Computing","awardID":"1162488","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["474923"],"PO":["565255"]},"187111":{"abstract":"Virtualization is an increasingly popular strategy for users to run applications designed for one platform on another platform---the holy grail of write once, run anywhere. The caveat for virtualization is that 'anywhere' has to be a powerful system with resources to spare. In a virtual machine, users can bundle an application with all of its operating system dependences in an easily-migrated environment---as long as users are willing to drag along duplicate networking stacks, CPU schedulers, virus scanners, swapping heuristics, and so on. <br\/><br\/>This project investigates a radical restructuring of the operating system in order to reduce these redundancies and overheads.<br\/><br\/>This project is driven by a vision of the future where each application and system service runs in a dedicated virtual machine; moreover, the operating system is no longer a single piece of software running on bare hardware, but its functionality is decomposed into several independent layers between the virtual machine monitor and the unmodified application. <br\/><br\/>This project investigates previously unstudied classes of applications and host services, as well as new system layers for hardware management and storage, with the end goal of making per-application virtual machines practical on mobile devices. If successful, this research will establish a richer scientific understanding of the trade-offs in computer system design and dramatically improve the efficiency and flexibility of modern computer systems.","title":"CAREER: Beyond Virtual Hardware: VMM\/OS Co-Design for Lightweight, Flexible Virtualization","awardID":"1149229","effectiveDate":"2012-06-01","expirationDate":"2017-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["521618"],"PO":["565255"]},"197111":{"abstract":"A one day workshop on \"Research Directions in the <br\/>Principles of Parallel Computing\" is scheduled on June 28, 2012 at <br\/>Carnegie Mellon University (CMU) in Pittsburgh, PA. The workshop will <br\/>bring together researchers from academia and industry to inform, <br\/>discuss, and initiate collaborations on understanding the key research <br\/>challenges in the foundations of parallel computing, and directions to <br\/>possibly address these challenges. The emphasis of the workshop is on <br\/>theoretical approaches to parallel computation and how to bridge these <br\/>approaches with practice. It will be held the day after the ACM <br\/>Symposium on Parallelism in Algorithms and Architectures (SPAA), which <br\/>is to be held June 25-27, 2012 also at CMU. <br\/><br\/>The workshop will address several issues described in NSF's Advanced <br\/>Computing Infrastructure Strategic Plan including, but not limited to, <br\/>computational models, programming languages, rethinking the canonical <br\/>computing \"stack\" and new algorithmic paradigms. The workshop will <br\/>consist of approximately 20 invited speakers who will be asked to <br\/>present their thoughts on \"what are three big research challenges in <br\/>the principles of parallel computing\". Attendance to the workshop is <br\/>open to all students, faculty and industry researchers at no charge (as <br\/>space permits). The output of the workshop will be a public report <br\/>documenting the discussions. It is hoped this report and other <br\/>interactions at the workshop will have broad impact on future <br\/>directions of research in the theory and practice of parallel <br\/>computation.","title":"NSF Workshop on Research Directions in the Principles of Parallel Computing","awardID":"1242283","effectiveDate":"2012-06-01","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["548200"],"PO":["565251"]},"196143":{"abstract":"The Great Recession of 2008, and its reverberations that are being felt all over the world even several years later, have highlighted significant limitations in the ability of regulators and analysts\/researchers to monitor and model the national and global financial ecosystem. Specifically, there is an urgent need for financial cyberinfrastructure to ingest and process numerous streams of financial transactions, as well as the accompanying data streams of economic activity, in real time. Also absent are open standards and shared semantics so that this data can be used to populate models of individual markets, financial networks and the interconnected ecosystem representing the global financial system. This calls for focused efforts aimed at developing computational research frameworks, models and methods, as well as the necessary cyberinfrastructure for regulating systemic risk in financial systems on par with efforts in other areas of national priority. <br\/><br\/>Against this background, this workshop (and related activities) aims to bring together an interdisciplinary group of academics in Computer Science, Finance, Economics and Social Sciences to work closely with the OFR and other regulatory agencies, and the financial and the computing industrises to: (1) Develop a blueprint for next generation financial cyberinfrastructure for regulating and mitigating systemic risk in financial markets (2) Identify the computational research challenges that need to be addressed in order to realize a cyber-enabled framework for regulating systemic risk; (3) Develop best practices for a cyber-enabled regulatory framework; and (4) Prepare a diverse cadre of PhD students to pursue multi-disciplinary research in Finance Informatics.<br\/><br\/>A one and a half day workshop will be organized in Washington D.C. A doctoral consortium will be held concurrently with the workshop and continued at the University of Maryland. The doctoral consortium will be aimed at graduate students with strong backgrounds in mathematics and computer science and an interest in some aspect of finance informatics. The doctoral consortium participants will be exposed to a multi-disciplinary curriculum that reflects many of research areas and methodologies that are discussed in the report on computational research challenges. The workshop report will be widely disseminated through a variety of venues.","title":"Workshop on the Next Generation Financial Cyberinfrastructure","awardID":"1237476","effectiveDate":"2012-06-01","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["543580"],"PO":["565136"]},"187255":{"abstract":"The ability to communicate and readily access information helps make possible positive social and political change. The Internet's effects on developing nations' educational, economic, and governmental institutions have been well explored by social scientists and technical experts. However, in unfortunately many instances, undemocratic governments monitor and censor Internet communication to attempt to control their populations. Although there are a number of existing technologies that support private communication in the presence of a restricted adversary who controls only a fraction of the network and has limited resources, we currently lack solutions that enable anonymous communication when the network is fully controlled by a nation-state adversary.<br\/><br\/>This research develops methods of providing unfiltered, anonymous, and high performance Internet access, even in the presence of strong nation-state adversaries. The project (i) investigates methods of improving connectivity in heavily regulated networks using novel hidden channels, (ii) improves the resilience of anonymity networks to denial-of-service attacks, (iii) introduces techniques for detecting suspicious behavior in anonymity networks, and (iv) enables high performance anonymous messaging through the development of novel anonymity protocols and algorithms.<br\/><br\/>The project's themes of privacy and security have been integrated into security courses developed for Georgetown's newly established Ph.D. program. More broadly, the project benefits society by improving the ability to privately access information, even in networks controlled by oppressive governments. The project will increase the participation of groups whose ability to communicate is currently muted, and will provide unfettered Internet access to regions in which free communication would otherwise be unavailable.","title":"CAREER: Private Communication in Strongly Adversarial Networks","awardID":"1149832","effectiveDate":"2012-06-15","expirationDate":"2017-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["519691"],"PO":["565327"]},"189444":{"abstract":"Optimization is a powerful paradigm for expressing and solving a variety of imaging problems. Modern optimization methods have had considerable success on problems that involve interactions between pairs of pixels. This has lead to important advances, but many imaging problems clearly require explicit modeling of higher-order interactions. This project is addressing this challenge through a close collaboration between researchers with expertise in graph algorithms and computer vision. The project is focused on two core applications: MRI image reconstruction and boundary detection in natural images. Besides their innate interest, these applications are closely related to other important imaging problems such as fMRI distortion correction, super-resolution, angiography and road detection. <br\/><br\/>Optimization problems with high-order interactions are inherently difficult from a computational point of view. The computational complexity can be reduced for problems with specific properties. By identifying common properties in many important imaging problems it is possible to design powerful optimization methods that are broadly applicable. The project is bringing together researchers in computer vision and algorithms. The collaboration is leading to new algorithms that are of broad interest to the computer vision and imaging communities. These algorithms have the potential to transform the way that several important classes of problems are solved. All of the algorithms being developed are being carefully evaluated, with their implementations made widely available on a web repository. Dissemination of the ideas is facilitated by workshops and mini-courses being organized at Brown, Cornell and Rutgers.","title":"RI: Medium: Collaborative Research: Graph Cut Algorithms for Domain-specific Higher Order Priors","awardID":"1161282","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["516805"],"PO":["564316"]},"187266":{"abstract":"Since the completion of genome sequencing projects for various organisms including human and other model organisms, the fundamental goal of research in computational genomics, systems biology, and genetics has been to gain a complete understanding of how the instruction sets encoded in genomes get executed within a cell system and organism. The recent advances in the high-throughput technology and next-generation sequencing technology have allowed the researchers to collect a large amount of data for the genomes and various other aspects of a cell system. Such datasets hold the key to understanding the detailed mechanisms of the genetic control of a biological system and further deepening our knowledge of cell biology with the potential for broad application. This project will develop statistical machine learning methods based on high-dimensional sparse graphical models for integrative analysis of genomic datasets. As graphical models provide a powerful tool for representing the complex structure of the unknown biological processes that underlie the observed genomic data, the computational methods to be developed in this project will be able to extract rich information on the genetic control of gene regulation systems from genome-scale datasets.<br\/><br\/>This project will also include training the next-generation computational biologists by supervising graduate students and incorporating the research results into the curriculum. The project will involve collaboration between computational scientists and biologists to participate in outreach programs for high-school students to present them an alternative career path that combines biological and computer sciences. In addition, the project will contribute to increasing womens participation in science and engineering.","title":"CAREER: Dissecting the Mechanisms of Genetic Control of Biological Systems via High-Dimensional Sparse Graphical Models","awardID":"1149885","effectiveDate":"2012-06-01","expirationDate":"2017-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0807","name":"Division of MOLECULAR AND CELLULAR BIOSCIE","abbr":"MCB"},"pgm":{"id":"8011","name":"Networks and Regulation"}}],"PIcoPI":[502286],"PO":["560660"]},"197188":{"abstract":"The PIs and Co-PIs of grants supported through the NSF-NIH-BMBF Collaborative Research in Computational Neuroscience (CRCNS) program meet annually. This eighth meeting of CRCNS investigators brings together a broad spectrum of computational neuroscience researchers supported by the program, and includes poster presentations, talks, plenary lectures, and discussions. The meeting is scheduled for June 3-5, 2012 and is hosted by Washington University in Saint Louis.","title":"CRCNS 2012 PI Meeting at Washington University in St. Louis","awardID":"1242614","effectiveDate":"2012-06-15","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}}],"PIcoPI":[529059],"PO":["564318"]},"189587":{"abstract":"Multi-core processors with hundreds of embedded functional blocks are designed to achieve unprecedented performance benefits for a wide variety of applications such as graphics, financial and scientific modeling, networking, multimedia and wireless infrastructure. The Network-on-Chip (NoC) is an enabling methodology to integrate many embedded cores on a single die. However, with growing levels of integration traditional NoCs suffer from high latency and energy dissipation in on-chip data transfer due to conventional metal\/dielectric based interconnects. The wireless NoC (WiNoC) simultaneously addresses the latency, power consumption and interconnect routing problems of conventional NoCs by replacing multi-hop wired links with high-bandwidth single-hop long-range wireless channels. Recent investigations have characterized silicon integrated on-chip antennas operating in the millimeter (mm)-wave range of 50-110 GHz, and this is now a viable technology. Coupled with significant advances in mm-wave transceiver design, this development opens up new research opportunities for designing high bandwidth and low power WiNoCs.<br\/><br\/>The proposed research will develop a cross-layer design methodology for an on-chip wireless micro-network. Suitable physical, data link and network layer protocols will be developed for the WiNoC. The expected contribution of this work is the development and demonstration of broadband and integrable mm-wave WiNoCs. The transformational aspect of this proposal lies in addressing the on-chip interconnect problem from a fundamentally new perspective, namely by developing a broadband millimeter wave wireless network at the micro\/nanoscale, as opposed to pursuing incremental improvements in traditional wired interconnects. By bringing wireless networking to the on-chip environment, the proposed research will introduce a paradigm shift in the design of multi-core chips. <br\/><br\/>The proposed research will facilitate the education of undergraduate and graduate students by allowing them to apply classroom knowledge to a research problem requiring hardware, software and theoretical expertise. Such expertise will be developed in both university and industrial laboratory settings using state-of-the-art test equipment and computing facilities, and will ultimately be necessary to maintain the technological leadership of the United States. Students from various underrepresented groups, including women, African Americans and Hispanics, will be engaged in this project. The project's educational impacts will be complemented by the positive effect that the research outcomes are expected to have on society as a whole.","title":"SHF: CSR: Medium: Collaborative Research: Hierarchical On-Chip Millimeter-Wave Wireless Micro-Networks for Multi-Core Systems","awardID":"1162063","effectiveDate":"2012-06-01","expirationDate":"2016-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["554786"],"PO":["366560"]},"187299":{"abstract":"Planning is a useful capability -- for instance, it enables robots to be autonomous and it helps people save money and conserve natural resources. Traditional planning methods search for perfect plans; this often requires exponential time and therefore takes too long for many problems. It is often better to promptly take a reasonable but possibly suboptimal action than it is to deliberate long enough to guarantee an 'optimal' plan. This project develops new methods for time-aware search and planning, along with an on-line handbook to help those who use search techniques choose an appropriate method.<br\/><br\/>This project focuses on developing algorithms for time-aware search in four different settings. (1) In utility-based search, the algorithm optimizes a user-specified combination of planning time and plan execution time. This captures the situation in which one wishes to achieve a goal as soon as possible (e.g., minimize the sum of planning time and plan execution time). (2) In incremental search, actions can be selected and begin to be executed while planning continues. This allows the algorithm to benefit from early execution if a good first action is apparent, but deliberate carefully if the selection of the first action appears crucial. (3) In on-line continual search, new goals can arrive asynchronously during execution. This requires the algorithm to determine if it is worthwhile to re-plan from scratch or whether simple additions to the existing plan will suffice. (4) In search under a deadline, a complete plan must be found within a given bound on search time. This is the objective in many applications.<br\/><br\/>This project also involves the creation and curation of an online Handbook of Search Algorithms. It will provide a comprehensive taxonomy of planning and optimization problem settings, together with the most appropriate algorithms that have been proposed for each setting. The handbook will integrate on-going research and educational activities of the PI. It will accelerate the uptake of academic research on heuristic search and draw attention to compelling settings that have traditionally received less attention, such as time-aware planning. The creation and curation of the handbook will be a long-term collaboration between the PI, students in a yearly seminar course taught by the PI, and students in the PI's research group. For graduate and advanced undergraduate students, authoring the handbook immerses them in research, while promoting fundamental skills in literature review, scientific writing, and empirical methodology.","title":"CAREER: Time-Aware Heuristic Search","awardID":"1150068","effectiveDate":"2012-06-01","expirationDate":"2017-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[502353],"PO":["565035"]},"196880":{"abstract":"The International Society for Computational Biology is awarded a grant to support student and early-career researcher participation in the annual meeting on Intelligent Systems for Molecular Biology in Long Beach, CA, July 15-17. The conference holds thematic sessions for invited presentations, tutorial programs on related subjects, and special interest group workshops. Cutting-edge bioinformatics areas presented at the conference include bio-imaging and visualization, databases and ontologies, evolution and comparative genomics, gene regulation and transcriptomics, mass spectrometry and proteomics, population genomics, protein interaction, and molecular networks and structure. <br\/><br\/>This award will assist students and postdoctoral researchers, particularly under-represented minorities, at a critical but resource-limited stage in their careers by partially funding the travel and expenses associated with attending the conference. Through their participation, these students will have the opportunity to be exposed to leading edge research and methods, gain introductions to international and world-renown keynote speakers and senior level scientists, seek out prospective postdoctoral and collaborative opportunities, and meet their peers from all over the world. Results will be disseminated as published proceedings indexed in MEDLINE and Current Contents, and video recordings of selected presentations will be available online.","title":"ISMB 2012 Conference Support for Students & Young Scientists-in Long Beach, CA, July 15-17, 2012","awardID":"1241290","effectiveDate":"2012-06-15","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"1165","name":"ADVANCES IN BIO INFORMATICS"}}],"PIcoPI":["558784"],"PO":["561151"]},"186980":{"abstract":"The Message Passing Interface (MPI) is a very widely used parallel programming model on modern High-End Computing (HEC) systems. Many performance aspects of MPI libraries, such as latency, bandwidth, scalability, memory footprint, cache pollution, overlap of computation and communication etc. are highly dependent on system configuration and application requirements. Additionally, modern clusters are changing rapidly with the growth of multi-core processors and commodity networking technologies such as InfiniBand and 10GigE\/iWARP. They are becoming diverse and heterogeneous with varying number of processor cores, processor speed, memory speed, multi-generation network adapters\/switches, I\/O interface technologies, and accelerators (GPGPUs), etc. Typically, any MPI library deals with the above kind of diversity in platforms and sensitivity of applications by employing various runtime parameters. These parameters are tuned during its release, or by<br\/>system administrators, or by end-users. These default parameters may or may not be optimal for all system configurations and applications.<br\/><br\/>The MPI library of a typical proprietary system goes through heavy performance tuning for a range of applications. Since commodity clusters provide greater flexibility in their configurations (processor, memory and network), it is very hard to achieve optimal tuning using released version of any MPI library, with its default settings. This leads to the following broad challenge: \"Can a comprehensive performance tuning framework be designed for MPI library so that the next generation InfiniBand, 10GigE\/iWARP and RoCE clusters and applications will be able to extract `bare-metal' performance and maximum scalability?\" The investigators, involving computer<br\/>scientists from The Ohio State University (OSU) and Ohio Supercomputer Center (OSC) as well as computational scientists from the Texas Advanced Computing Center (TACC) and San Diego Supercomputer Center (SDSC), University of California San Diego (UCSD), will be addressing the above challenge with innovative solutions.<br\/><br\/>The investigators will specifically address the following challenges: 1) Can a set of static tools be designed to optimize performance of an MPI library during installation time? 2) Can a set of dynamic tools with low overhead be designed to optimize performance on a per-user and per-application basis during production runs? 3) How to incorporate the proposed performance tuning framework with the upcoming MPIT interface? 4) How to configure MPI libraries on a given system to deliver different optimizations to a set of driving applications? and 5) What kind of benefits (in terms of performance, scalability, memory efficiency and reduction in cache pollution) can be achieved by the proposed tuning framework? The research will be driven by a set of applications from established NSF computational science researchers running large scale simulations on the TACC Ranger and other systems at OSC, SDSC and OSU. The proposed designs will be integrated into the open-source MVAPICH2 library.","title":"Collaborative Research: SI2-SSI: A Comprehensive Performance Tuning Framework for the MPI Stack","awardID":"1148371","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["561947","515816"],"PO":["565247"]},"196111":{"abstract":"User interfaces that adapt themselves to available user information (such as special needs or individual preferences) are becoming increasingly important, so much so that adaptability has become a selling point for software products. A system with the ability to construct and consult a user model (an explicit representation of properties of a particular user or group of users) can adapt diverse aspects of its performance and enhance its effectiveness, usability and\/or acceptance in a variety of situations (e.g., to reduce information overload, to improve the quality of information retrieval, filtering and annotation, and to generate useful information visualizations). Applications for user modeling range from electronic commerce and intelligent learning environments to health care and assistive technologies. Relevant platforms for user modeling include mobile and wearable systems and smart environments, as well as individual desktop systems, groupware, adaptive hypermedia, and other web-based systems. <br\/><br\/>The annual International Conferences on User Modeling, Adaptation and Personalization (UMAP) provide the premier forum in which academic and industrial researchers from all of these fields can exchange their complementary insights on user modeling issues. UMAP is a merger of the long-running and successful International Conferences on User Modeling (UM, 1986-2007), and the more recent important series of Adaptive Hypermedia and Adaptive Web-Based Systems Conferences (AH, 2000-2008). This is funding to support travel by approximately 10 graduate students to present their accepted papers and posters and\/or to present their research plans at the Doctoral Consortium associated with the 20th event in the UMAP series, to be held July 16-20, 2012, in Montreal, Canada. More information about the conference is available at http:\/\/umap2012.polymtl.ca\/en. <br\/><br\/>UMAP-12 will include a Doctoral Consortium session, thereby continuing a tradition established at UMAP-09 and before that at both the UM and AH conferences. Lively and useful discussions have enabled students to receive suggestions about their ongoing research and allowed more experienced participants to hear some fresh ideas and view some of the new trends in the field. Students whose work has been selected for presentation at the Doctoral Consortium will be invited to write a paper that will be published in the UMAP-12 conference proceedings. They will have 15 minutes to present their work (which may include a short demonstration if appropriate), to be followed by an additional 15 minutes for questions and discussion. During both the question\/discussion period and in subsequent informal interactions, organizing committee members and other participants will provide constructive comments on each student's work and attempt to address aspects on which the student has requested advice. <br\/><br\/>Broader Impacts: Attending and presenting their work at UMAP, the top conference in its field, will have a significant impact on the careers of the future generation of user modeling, adaptation, and personalization researchers. Students who participate in the Doctoral Consortium will also benefit from that experience in several ways. First, they will have the opportunity to present their work to a knowledgeable audience and get useful comments at an early stage of their research when it will be most useful. Just as importantly, they will have an opportunity to meet established researchers and other graduate students doing similar work, to exchange ideas, and to make contacts that will be invaluable to them as they progress in their scientific careers. Interacting with the young researchers is also useful to more experienced investigators, by providing new perspectives and fresh ideas. Thus, the Doctoral Consortium is a great confidence builder for the students involved, and highly stimulating to the established researchers who participate. The organizers have reaffirmed the long-standing and demonstrated UMAP commitment to diversity. To this end, they will make special efforts to recruit women and members of under-represented groups from among the candidates for receiving financial support, and they will ensure institutional diversity by supporting no more than one student from any single institution.","title":"Supporting Students Attending the User Modeling, Adaptation and Personalization 2012 Conference","awardID":"1237292","effectiveDate":"2012-06-01","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":[525682],"PO":["565227"]},"189324":{"abstract":"The objective of the proposed research is to develop the foundations for resource allocation in femtocell networks, and evaluate the performance of the solutions using real testbeds. Wireless resource allocation in femtocell-based networks is particularly challenging due to four main reasons: (1) interference between femtocells and between femto- and macro-cells; (2) variable and unpredictable delays in signaling and data communication between each femtocell and the operator's network; (3) limited bandwidth for signaling over a wireless channel to a large number of femtocells; and, (4) involvement of three parties with differing priorities: the operator, the users, and the femtocell owners. The specific research tasks in this project are: (1) For legacy systems, develop distributed solutions for both downlink and uplink scheduling and handover under co-deployment of macro- and femto-cells that do not require any changes to existing hardware and standards; (2) Develop distributed, adaptive and self-organizing solutions (unconstrained by legacy requirements) for resource allocation by using a powerful tool from statistical physics, called Glauber dynamics; and (3) Design mechanisms to facilitate offline truthful auctions in practical settings involving the end-users, the femtocell owners, and the operator. The solutions will be implemented and evaluated on two testbeds under development at University of Michigan and at Ohio State University. The proposed research has the potential to significantly impact the cellular industry and end-users. Given the high penetration rates of cell-phones worldwide, this research has an immediate and widespread impact.","title":"NeTS: Medium: Collaborative Research: Enabling Cellular Services over Unplanned Femto-Cell Deployments: From Theory to Implementation","awardID":"1160775","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["553551"],"PO":["565303"]},"189489":{"abstract":"\/O on High-End Computing (HEC) machines is increasingly becoming the killing performance bottleneck. However, conventional execution paradigms for HEC are computing-centric and have inherent limitations in addressing critical I\/O issues of data-intensive applications. There is a great need for developing unconventional execution paradigms to meet the growing I\/O demand of high-end computing.<br\/><br\/>In this project, the PIs propose a decoupled execution paradigm (DEP) to address I\/O bottleneck issues. DEP is the first paradigm enabling users to identify and handle data-intensive operations separately. The objective of the proposed research is three-fold: 1) understanding the execution paradigm requirement from the data-centric point of view, 2) studying the feasibility of the proposed decoupled execution paradigm, and 3) providing a partially implemented prototyping of DEP and its associated system design to support the first two objectives. Several technical hurdles have been identified, which include system architecture, programming model, and runtime system. Solutions are proposed and detailed plans are provided to evaluate the newly proposed decoupled execution paradigm.","title":"CSR: Medium: Collaborative Research: Decoupled Execution Paradigm for Data-Intensive High-End Computing","awardID":"1161507","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["557487"],"PO":["565255"]},"189137":{"abstract":"Recent years have seen extraordinary breakthroughs in computational sentiment analysis and social network analysis. This research has helped to reveal that robust language understanding --- in dialogue, in text, on the Web --- depends on accurately identifying attitudes, emotions, and social relationships. However, missing from the current scientific and technical picture is a deep understanding of the ways in which sentiment affects, and is affected by, our interpersonal relationships and social networks. The central goal of this project is to fill this gap by developing algorithms, methods, and data sets for modeling sentiment as social and interpersonal. The approach balances fine-grained sociological and linguistic study, computational modeling, and large-scale data-mining of weblogs and other interactive social media.<br\/><br\/>This research aims to reshape the field of sentiment analysis by moving it towards inferential models of emotional language as situated in specific social contexts. It also provides social network analysis with rich features for characterizing social ties, thereby facilitating the identification of new latent structure in social networks. The work addresses a wide variety of social and political issues, including the extent of media polarization, the effects of bias and framing, and the role of emotional content in shaping the flow of information. It can also inform the creation of the next generation of communication tools --- software for virtual meetings and online collaboration that intelligently tracks users' evolving attitudes, social networking platforms that distinguish relationship types, and data-mining tools relevant for legal discovery, intelligent tutoring, and media analytics.","title":"RI: Medium: Bringing Sentiment Analysis and Social Network Analysis Together","awardID":"1159679","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["517444",507063,507064,507065],"PO":["565215"]},"186970":{"abstract":"Parallel computing has entered the mainstream with increasingly large multicore processors and powerful accelerator devices. These compute engines, coupled with tighter integration of faster interconnection fabrics, are drivers for the next-generation high end computing (HEC) machines. However, the computing potential of HEC machines is delivered only through productive parallel program development and efficient parallel execution. This project enables application developers to improve performance on future HEC machines for their scientific and engineering processes. This project challenges the current model for parallel application development via \"black box\" tools and services. Instead, the project offers an open, transparent software infrastructure -- a Glass Box system -- for creating and tuning large-scale, parallel applications. `Opening up' the tools and services used to create and evaluate peta- and exa-scale codes involves developing interfaces and methods that make tool-internal information and available for new performance management services that improve developer productivity and code efficiency.<br\/><br\/>The project will explore the information that can be shared 'across the software stack'. Methods will be developed for analyzing program information, performance data and tool knowledge. The resulting Glass Box system will allow developers to better assess the performance of their parallel codes. Tool creators can use the performance data to create new analysis and optimization techniques. System developers can also better manage multicore and machine resources at runtime, using JIT compilation and binary code editing to exploit the evolving hardware. Working with the `Keeneland' NSF Track II machine and our industry partners, the project will create new performance monitoring tools, compiler methods and system-level resource management techniques. The effort is driven by the large-scale codes running on today's petascale machines. Its broader impact is derived from the interactions with technology developers and application scientists as well as from its base in three universities with diverse student populations.","title":"SI2-SSI: Collaborative Research: A Glass Box Approach to Enabling Open, Deep Interactions in the HPC Toolchain","awardID":"1148310","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["523077","556660",501621,501622],"PO":["565247"]},"200159":{"abstract":"We are the victims of our own success. We can now deploy mobile robots in real-world environments and have them operate completely autonomously for extended periods of time. We no longer have to surround our robots with graduate student wranglers to keep them functional, and to keep the general public at a safe distance. These technical successes mean that members of the general public must now interact directly with robots, without the aid of an interpreter. But members of the public are poorly equipped for such interactions, since they are unfamiliar with real robots and how they work. Thus, the interactions often go poorly; the robot is hindered in performing its task, and the human is unhappy. For people to be comfortable interacting with a robot, they must feel that they understand what it's thinking, what it's trying to do, and the actions that it will take. Moreover, people must be able to deduce this information from observing the robot for a short period of time, just as we do with other humans that we encounter. The fundamental problem here is that humans communicate a wealth of information by means of a non-verbal \"vocabulary\" in which body language (how we stand, how we hold our arms, etc.), eye contact, nods, and other subtle cues ostensibly not essential to the task at hand play significant roles. We do this naturally, and without conscious effort. Taken in context, this information allows us to infer another person's state of mind, goals, and intentions with surprising accuracy; this, in turn, allows us to predict how a given interaction will unfold, and gives us some control over it. Because people take this ability for granted, they suffer when it is absent, as is currently often the case when interacting with a mobile robot. The PI intends to address this deficiency in the current project. He argues that to make human-robot interactions as natural as possible, we must equip robots with our physical vocabulary and ensure that they use it appropriately, following social norms. To achieve this goal the PI will turn to the performing arts, where actors are trained to express themselves physically. A good actor can convey a vast amount of information about a character's state of mind, goals, and intentions by simply walking across the stage in a particular way. The actions may be styled, larger-than-life, or subtle, but they are intended to convey information about the character's internal mental state. The techniques that actors employ have been honed and refined for hundreds of years and tested for effectiveness on the general public. In this research, the PI will exploit such insights and skills to develop a physical vocabulary that can communicate beliefs, intentions, and goals to humans interacting with a robot, thereby enabling people to better predict the robot's actions. Finally, the PI will rigorously evaluate these actions to verify that they are actually useful. <br\/><br\/>Broader Impacts: Robots are becoming more and more a part of our lives, and members of the public will be forced to deal with them sooner or later. If we have an understanding of the physical aspects of these interactions, the integration of robots into our everyday lives will be made much less painful and distressing.","title":"HCC: Small: A Physical Vocabulary for Human-Robot Interaction","awardID":"1258213","effectiveDate":"2012-06-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[536564],"PO":["565227"]},"195386":{"abstract":"The 2012 Broadening Participation in Data Mining Workshop (BPDM 2012) will be the first workshop of its kind in data mining designed specifically to foster mentorship, guidance, and connections of underrepresented groups in data mining, while also enriching technical aptitude and exposure. The workshop will be co-hosted with the 2012 SIAM International Conference on Data Mining (SDM 2012), one of the premier conferences in the field of Data Mining. This proposal discusses the attendance and financial support of students from underrepresented groups to the workshop, as well as, to the conference. The conference provides a venue for students and researchers who are addressing data mining problems in areas such as science, engineering, industrial processes, healthcare, business, and medicine, to present their work in a peer-reviewed forum. It also provides an ideal setting for students and others new to the field to learn about cutting-edge research by hearing outstanding invited speakers and attending presentations, tutorials, and focused workshops. The funds will enable the students to attend both the workshop and the remainder of the meeting.","title":"Broadening Participation in Data Mining Workshop","awardID":"1232397","effectiveDate":"2012-06-15","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["560879",523772],"PO":["565136"]},"189622":{"abstract":"Computers with many tens to hundreds of ?cores? are on their way, but programming languages and tools<br\/>that exploit them well have lagged. At the same time, there are emerging programming languages intended<br\/>for writing programs to run on these computers. These languages, such as X10 and Fortress, add support for<br\/>new concepts that make it easier to write many-core programs, but there does not yet exist good compiler and<br\/>run-time support for these languages. Systems that run Java, namely Java virtual machines such as those that<br\/>run on virtually every laptop, desktop, and server today, supply much of what the new languages need, but<br\/>fall short in some important ways. In particular they do not provide for saying in which part of memory to<br\/>place particular objects, on which core to run which computations, easy ways to get all cores busy working<br\/>on different parts of a big piece of data, or for synchronizing and getting right all the data manipulations<br\/>happening at the same time. This project is extending an existing research Java virtual machine (Jikes<br\/>RVM) with support for many ways of doing the things that the new languages need in order to run well<br\/>on many-core computers. The primary goal is to devise extensions to standard Java virtual machines for<br\/>this new world, and to make it possible for many others to experiment with different ways of implementing<br\/>these extensions, thus leveraging the creativity of the whole community of language and virtual machine<br\/>researchers. Secondary goals include offering reasonably good initial implementations of virtual machine<br\/>extensions as a starting point for future research and development, and proposing specific extensions to the<br\/>Java virtual machine specification standard.","title":"CSR: Medium: Collaborative Research: Portable Performance for Parallel Managed Languages Across the Many-Core Spectrum","awardID":"1162246","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550864",508414],"PO":["565255"]},"198246":{"abstract":"The research objective of this project is to create a framework to effectively preserve data generated in sensor network applications that operate in challenging environments. These applications include visual and acoustic sensor networks, ocean seismic or underwater sensor networks, and volcanic and glacial monitoring. In such challenging environments, the data uploading opportunities would be unpredictable and rare, making the network connectivity to the base station inherently intermittent and storing data inside the network necessary.<br\/><br\/>In particular, this project 1) Invents a series of energy- and storage-efficient data preservation algorithms to adaptively overcome all the key causes of data loss, including energy depletion, storage depletion, hardware failure of sensor nodes, and overall storage overflow in the entire network. The proposed data preservation techniques include distributing, redistributing, replicating, and aggregating the sensed data inside the network; 2) Takes a unified storage-energy optimization approach, in which storage space and battery energy, the two most stringent resources in sensor networks, are viewed as two sub-components of the same unified resource in the sensor network. The joint allocation of storage and energy is optimized for data preservation by exploiting their synergies via aforesaid data preservation techniques.<br\/><br\/>The outcomes of this project include basic architectures, theories, algorithms, and protocols for intermittently connected sensor networks. This project would have significant impact on many sensor network-based scientific applications, including natural disaster warning and climate change monitoring, many of which operate in challenging environments while generating large amounts of data over time. The PIs plan to develop graduate\/undergraduate courses on interfacing algorithm design and sensor networks, thus educating students the importance of algorithmic thinking while exposing them the latest networking technologies.","title":"NeTS: Small: Adaptive Data Preservation in Intermittently Connected Sensor Networks: A Unified Storage-Energy Optimization Approach","awardID":"1248315","effectiveDate":"2012-06-08","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[532021],"PO":["565303"]},"187246":{"abstract":"The objective of this research is to investigate how to improve end-user programmer productivity and learning through user interfaces and algorithms for capturing, sharing, and accessing programming expertise. Focus is on the needs of end-user programmers who create graphical user interfaces and build physical computing systems. Fieldwork and data analyese will be conducted to understand current practices around seeking and providing advice online. Informed by this framework, tools will be developind for creating and sharing high-quality examples and tutorials, finding and recommending relevant examples, and integrating found code into new projects. Success of the methods will be evaluated through laboratory experiments and deployment of instrumented software. This work draws on methodology from computer-supported cooperative work, end-user programming, the design of authoring tools, project-based learning, and design of computer-realized scaffolding. Four types of results will be produced: 1) knowledge about the types of problems end-user programmers seek help on; 2) analysis how current systems help and hinder the sharing of expertise; 3) novel techniques to improve expertise sharing within programming environments; and 4) evaluations that quantify the benefits of such techniques. <br\/><br\/><br\/>Programmers increasingly rely on Web resources such as question answering sites, forums, and example repositories to help them prototype, implement, and debug software. This trend is especially prevalent in end-user programmers, who write code but are not professionally trained in Computer Science. They vastly outnumber professional programmers in the United States. Current development tools are largely ignorant of the social exchange of programming advice online: program editors and Web applications are isolated from each other. This lack of specific applications for describing and sharing programming expertise limits the effectiveness of both production and use of knowledge. This work will lower the threshold for programming digital media. The research will increase the quality, scope, and utility of online reference materials. Access to these materials can accelerate learning, improve productivity, increase self-efficacy of programmers, and democratize the production and sharing of programming knowledge.","title":"CAREER: Advancing End-User Programming with Expertise Sharing Tools","awardID":"1149799","effectiveDate":"2012-06-01","expirationDate":"2017-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["514744"],"PO":["562669"]},"199005":{"abstract":"Humankind's knowledge of the world and its ability to manipulate it for the betterment of quality of life and understanding through science, technology, engineering, and mathematics (STEM) is increasingly dependent on the ability to store, access, and manage extremely large persistent data sets representing scientific and process measurements, results from science and engineering simulations, and long-term knowledge. Supercomputers conventionally operate in dual or separate modes: one to do the computations in their temporary (ephemeral)-main memory-and the other to supervise the use of large persistent data storage. As supercomputers get larger, perhaps to the scale of an Exaflops by the end of this decade, the comparable scale and ease of use of mass storage is severely challenged. This research will address the problems of efficiency and scalability of data migration through the vertical memory hierarchy and will unify the way both main memory data objects and persistent storage data are named creating a single, easy to use programming. This will revolutionize data intensive supercomputing and establish a new path towards future Exascale system design and programming. This research is in collaboration with Clemson University to provide a proof-of-concept system to evaluate the new concepts.<br\/><br\/>The semantic and performance barriers between computing in main memory and manipulation of mass storage for persistent data have imposed significant limitations to performance and programmability. Because of uncertainties of access latency times combined with overheads and the need to exploit data access parallelism for high throughput, a new relationship between ephemeral storage and persistent objects is needed to unify their association and manage the asynchrony of operation while achieving high efficiency. This research is deriving an innovative execution model and developing a proof-of-concept experimental system to test and evaluate its underlying concepts for a new generation of persistent mass storage at extreme scale. It will address the challenges and provide the means for the unification of the semantics of ephemeral and mass storage through a single abstraction of data manipulation and the integration of meta-data and synchronization to manage asynchrony and uncertainty of response time as well as logical conflicting accesses while automatically hiding latency. The new model will support dynamic data path management for the asynchronous vertical storage hierarchy, exploiting adaptive runtime event-driven techniques for enhanced efficiency and scalability including management of vertical transport of data, which demands an innovative strategy of dynamic control of the entire data path.","title":"EAGER: Dynamic Data Path Management for Asynchronous Vertical Storage Hierarchy","awardID":"1252358","effectiveDate":"2012-06-01","expirationDate":"2014-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"K155","name":"National Security Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["563331"],"PO":["565136"]},"196750":{"abstract":"This project supports US faculty members and graduate students to attend USA - Sino Summer School in Vision, Learning, Pattern Recognition (VLPR2012). The VLPR summer school has become a mutually beneficial annual event for computer vision researchers and students from both US and China. The impact and reputation of VLPR summer school sequence grows rapidly and VLPR 2012 continues this positive trend by focusing on Computer Vision in Biomedical Image Applications: from Micro to Macro. This topic complements the methodology-centered VLPRs in the past with an application-oriented and human-centered focus on life forms in drastically different scales: from human and animals (macro) to cells (micro). VLPR 2012 aims to illustrate a cross-sectional state of the art computer vision and machine learning methodologies, to broaden the horizon for innovations and creativities, and to address some fundamental issues of high throughput computing on multi-modality, high-dimensional, and high volume image data (Big Data). <br\/><br\/>The theme of this summer school reflects the growing international trend of interdisciplinary research in biomedical image and smart health, and facilitates collaborative efforts between science and technology, computer science and medicine\/biology, and US and China. In addition, this summer school offers a great opportunity for intellectual and cultural exchanges between a group of world-class computer vision researchers and motivated students from the two countries to converse and mingle with each other in an exciting, culturally rich environment during a week-long period.","title":"USA-Sino Summer School in Vision, Learning, Pattern Recognition, VLPR 2012","awardID":"1240450","effectiveDate":"2012-06-01","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["531866"],"PO":["564316"]},"186850":{"abstract":"It is widely recognized that much of science can more effectively be learned if students learn science in ways similar to the ways scientists build new knowledge. Yet classroom implementations of scientific inquiry often convey an inaccurate understanding of the ways scientists learn, as they often fail to give students opportunities to connect data they've collected as evidence to science theory. In addition, a major barrier to effective student inquiry has been inherent difficulties in interpreting data, e.g., finding patterns in data from series of experiments performed under varying conditions. The platform to be developed in this project, called InquirySpace, addresses both of those issues. It integrates three proven technologies that together have capabilities for supporting both authentic scientific inquiry and pattern finding in data -- the versatile modeling environments of NetLogo and the Molecular Workbench, real-time data collection from probes and sensors, and the powerful visual data exploration capabilities of Fathom and TinkerPlots. They are being integrated into a coherent, Web-based environment enabling rich, collaborative scientific inquiry. By adapting the software tools to execute inside browsers, InquirySpace is designed to function in schools where firewalls and inflexible technology setups are often insurmountable barriers, to run on most computer platforms used in schools, and to be extensible to mobile platforms following the project's end, removing major barriers to the use of inquiry across grades and not only in high-performing schools, but also in under-resourced schools in which students often are performing below grade and for whom text-based instruction is decontextualized and difficult. Research will investigate pedagogical practices for integrating software functions in ways that allow students to have the experiences of scientists without being overwhelmed by the proliferation of tools needed to carry out an investigation as well as technological needs in integrating such tools. Products will include a set of design and use principles for creating and integrating technology in support of scientific inquiry.<br\/><br\/>The InquirySpace project provides insight into one of the most difficult problems in science instruction -- supporting authentic scientific inquiry in a way that both promotes deep science learning and conveys an accurate understanding of the practices of science. This project will show how to integrate sophisticated software functions that support science inquiry in ways that allow middle and high school students to have scientific inquiry experiences that have a sophistication similar to the experiences of scientists but without being overwhelmed by the multitude of tools, and resources, and representations available to support their work. Findings from this project have the potential to deepen our understanding of how to help students learn science concepts and scientific inquiry through inquiry activities, and draw attention to the importance of computational tools in supporting this learning.","title":"INDP: InquirySpace: Technologies in Support of Student Experimentation","awardID":"1147621","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":["549142",501314,501315,501316],"PO":["562669"]},"186982":{"abstract":"The Message Passing Interface (MPI) is a very widely used parallel programming model on modern High-End Computing (HEC) systems. Many performance aspects of MPI libraries, such as latency, bandwidth, scalability, memory footprint, cache pollution, overlap of computation and communication etc. are highly dependent on system configuration and application requirements. Additionally, modern clusters are changing rapidly with the growth of multi-core processors and commodity networking technologies such as InfiniBand and 10GigE\/iWARP. They are becoming diverse and heterogeneous with varying number of processor cores, processor speed, memory speed, multi-generation network adapters\/switches, I\/O interface technologies, and accelerators (GPGPUs), etc. Typically, any MPI library deals with the above kind of diversity in platforms and sensitivity of applications by employing various runtime parameters. These parameters are tuned during its release, or by<br\/>system administrators, or by end-users. These default parameters may or may not be optimal for all system configurations and applications.<br\/><br\/>The MPI library of a typical proprietary system goes through heavy performance tuning for a range of applications. Since commodity clusters provide greater flexibility in their configurations (processor, memory and network), it is very hard to achieve optimal tuning using released version of any MPI library, with its default settings. This leads to the following broad challenge: \"Can a comprehensive performance tuning framework be designed for MPI library so that the next generation InfiniBand, 10GigE\/iWARP and RoCE clusters and applications will be able to extract `bare-metal' performance and maximum scalability?\" The investigators, involving computer<br\/>scientists from The Ohio State University (OSU) and Ohio Supercomputer Center (OSC) as well as computational scientists from the Texas Advanced Computing Center (TACC) and San Diego Supercomputer Center (SDSC), University of California San Diego (UCSD), will be addressing the above challenge with innovative solutions.<br\/><br\/>The investigators will specifically address the following challenges: 1) Can a set of static tools be designed to optimize performance of an MPI library during installation time? 2) Can a set of dynamic tools with low overhead be designed to optimize performance on a per-user and per-application basis during production runs? 3) How to incorporate the proposed performance tuning framework with the upcoming MPIT interface? 4) How to configure MPI libraries on a given system to deliver different optimizations to a set of driving applications? and 5) What kind of benefits (in terms of performance, scalability, memory efficiency and reduction in cache pollution) can be achieved by the proposed tuning framework? The research will be driven by a set of applications from established NSF computational science researchers running large scale simulations on the TACC Ranger and other systems at OSC, SDSC and OSU. The proposed designs will be integrated into the open-source MVAPICH2 library.","title":"Collaborative Research: SI2-SSI: A Comprehensive Performance Tuning Framework for the MPI Stack","awardID":"1148424","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["559503","515804"],"PO":["565247"]},"196113":{"abstract":"The symposium covers all areas of bioinformatics research, ranging from comparative genomics and population genetics to structure prediction and protein-protein interaction networks. Accepted extended abstracts will be published as a volume in the Springer Verlag's Lecture Notes in Bioinformatics series, while short abstracts will be published online and on CD-ROM. In addition to contributed abstracts, the technical program will include tutorials, panel discussions, and poster sessions, and will feature invited keynote talks by distinguished researchers in the field. Full versions of selected abstracts presented at the symposium will be invited to peer-reviewed special issues of IEEE\/ ACM Transactions on Computational Biology and Bioinformatics and BMC Bioinformatics. The symposium provides ample opportunities for interaction between researchers with complementary expertise thus fostering new collaborations.","title":"Travel Support: 8th International Symposium on Bioinformatics Research and Applications","awardID":"1237310","effectiveDate":"2012-06-15","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[525686,525687,"558126",525689],"PO":["565136"]},"189601":{"abstract":"Multi-core processors with hundreds of embedded functional blocks are designed to achieve unprecedented performance benefits for a wide variety of applications such as graphics, financial and scientific modeling, networking, multimedia and wireless infrastructure. The Network-on-Chip (NoC) is an enabling methodology to integrate many embedded cores on a single die. However, with growing levels of integration traditional NoCs suffer from high latency and energy dissipation in on-chip data transfer due to conventional metal\/dielectric based interconnects. The wireless NoC (WiNoC) simultaneously addresses the latency, power consumption and interconnect routing problems of conventional NoCs by replacing multi-hop wired links with high-bandwidth single-hop long-range wireless channels. Recent investigations have characterized silicon integrated on-chip antennas operating in the millimeter (mm)-wave range of 50-110 GHz, and this is now a viable technology. Coupled with significant advances in mm-wave transceiver design, this development opens up new research opportunities for designing high bandwidth and low power WiNoCs.<br\/><br\/>The proposed research will develop a cross-layer design methodology for an on-chip wireless micro-network. Suitable physical, data link and network layer protocols will be developed for the WiNoC. The expected contribution of this work is the development and demonstration of broadband and integrable mm-wave WiNoCs. The transformational aspect of this proposal lies in addressing the on-chip interconnect problem from a fundamentally new perspective, namely by developing a broadband millimeter wave wireless network at the micro\/nanoscale, as opposed to pursuing incremental improvements in traditional wired interconnects. By bringing wireless networking to the on-chip environment, the proposed research will introduce a paradigm shift in the design of multi-core chips. <br\/><br\/>The proposed research will facilitate the education of undergraduate and graduate students by allowing them to apply classroom knowledge to a research problem requiring hardware, software and theoretical expertise. Such expertise will be developed in both university and industrial laboratory settings using state-of-the-art test equipment and computing facilities, and will ultimately be necessary to maintain the technological leadership of the United States. Students from various underrepresented groups, including women, African Americans and Hispanics, will be engaged in this project. The project's educational impacts will be complemented by the positive effect that the research outcomes are expected to have on society as a whole.","title":"SHF: CSR: Medium: Collaborative Research: Hierarchical On-Chip Millimeter-Wave Wireless Micro-Networks for Multi-Core Systems","awardID":"1162123","effectiveDate":"2012-06-01","expirationDate":"2016-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[508364],"PO":["366560"]},"196135":{"abstract":"The cost of writing data from a computer's processor to its storage components remains a bottleneck for modern computing systems. The speed of the processor continues to improve, more processing units are packed into a computer chip, but these advances only cause more data to be written to storage per second. The speed of storage subsystems has not kept pace with the processor?s ability to produce data for storage, and this difference in performance is likely to continue. Moreover, the trend in building storage subsystems for computers is to utilize technologies such as flash memories whose contents can be changed a relatively small number of times before the memory wears out. These technologies are cheaper and pack more storage into a given area, but care must be taken to avoid writing to memories made from such technologies at rates usually seen from a processor to memory.<br\/><br\/>This EAGER project aims to discover mechanisms that reduce or eliminate traffic from a processor to the storage subsystem. Elimination of such traffic increases the speed of the overall system and saves wear on storage components. This research finds data that would otherwise be sent to storage from the processor and eliminates such writes to memory. This technique is based on finding that such data cannot subsequently be referenced by an application. This effort focuses on a preliminary study to validate the technical approach, namely investigating the consequences of eliminating stores of data that has been explicitly deallocated by an application.","title":"EAGER: Collaborative Research: Compiler and Architecture Support for Avoiding Writes to Memory-Preliminary Study","awardID":"1237425","effectiveDate":"2012-06-01","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[525751],"PO":["565272"]},"196278":{"abstract":"If properly realized, the data deluge will be a catalyst for new scientific discovery that fuels advances in grand challenge questions such as climate and social-ecological interactions. While federal agencies such as the National Science Foundation have invested very successfully in repositories, infrastructure, and tools for data-intensive science, investing in data solutions is not the same as investing in high performance computing resources because unlike general purpose compute facilities where the facility can be separated from the use, it is difficult to separate data from its semantics, so general purpose solutions only address part of the problem, and a small part at that. Recognizing the opportunities that could be realized through stronger integrated efforts, NSF is encouraging a path towards coordinated efforts that result in satisfying the needs of a broader constituency that strives for interoperability, harmonization of concepts, protocols, and standards nationally and internationally. This proposal is a small but fundamental next step towards building an organization with lasting and significant impact on the broader community engaged in 4th paradigm research and education.","title":"A Data Consortium: Coming Together Around Data","awardID":"1238168","effectiveDate":"2012-06-01","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}}],"PIcoPI":["565242"],"PO":["565292"]},"197004":{"abstract":"With the exponential increase in the size, complexity, and rate of acquisition of diverse types of data, there an urgent need for new techniques for managing and analyzing such data. In this context, there is a critical need for benchmarks to facilitate evaluation of alternative solutions and provide for comparisons among different solution approaches targeted to big data applications. Benchmarks need to capture a variety of characteristics of big data storage, management, and analytics including new feature sets, enormous data size, largescale and evolving system configurations, shifting loads, and the heterogeneous technologies of big-data and cloud platforms. The benchmarks are inadequate for assessing emerging big data platforms, systems and in software such as SQL, NoSQL, and the Hadoop software ecosystem; different modalities or genres of big data, including graphs, streams, scientific data, document collections, and transaction data; new options in hardware including, HDD vs SSD, different types of HDD, SSD, and main memory, and large-memory systems; and, new platform options that include dedicated commodity clusters and cloud platforms.<br\/><br\/>The Workshop on Big Data Benchmarking 2012 represents an important step towards the development of a suite of benchmarks for providing objective measures of the effectiveness of hardware and software systems dealing with big data applications. The objective of this invitation-only workshop is to identify key issues and to launch an activity around the definition of reference benchmarks that can capture the essence of big data application scenarios. The effort aims to arrive at a set of objective measures and benchmark datasets to characterize and compare the performance of and the price\/performance tradeoffs of alternative solutions for big data storage, retrieval, processing, and analysis problems. The workshop brings together a group of about 40 experts from academia and industry with backgrounds in big data, database systems, benchmarking and system performance, cloud storage and computing, and related areas.The industries represented range from hardware, software, analytics, and applications. The group will develop a draft of a report describing a big data benchmark suite that will be widely disseminated on the web and through presentations and oureach activities at the relevant conferences and workshops.<br\/><br\/>Broader Impacts: The availability of the big data benchmark suite will facilitate research and technological advances by providing objective measures for comparing alternative solutions to key big data problems.","title":"WBDB2012: Workshop on Big Data Benchmarking 2012","awardID":"1241838","effectiveDate":"2012-06-01","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["559496"],"PO":["560586"]},"189645":{"abstract":"More and more applications in entertainment, commerce, and government need to process continuous streams of data, and handle ever increasing data volumes at that. For instance, Netflix video streams account for almost 30% of internet traffic during peak hours in North America. High-frequency trading systems already execute over 50% of all trades in the United Sates. And New York City is networking 3,000 video cameras and an unspecified number of license plate readers and radiological detectors to prevent terrorist attacks. But building and running such streaming applications with existing software tools is hard; they only support some applications or do not meet performance requirements. This research is developing reusable software artifacts that make it possible to more easily build and run high-performance streaming applications in general. Thereby, it is directly addressing critical data processing needs of our society.<br\/><br\/>More technically, this research is exploring how to componentize monolithic streaming systems by decoupling streaming languages, in which applications are written; streaming optimizations, which maximize performance and scalability; and streaming runtimes, which manage the low-level aspects of application execution. (1) The investigator is developing an intermediate language for stream processing that serves as the glue for composing language, optimization, and runtime components with each other. (2) The investigator is exploring how to refactor language front-ends and optimizations and then building a library of reusable front-end and optimization components. (3) The investigator is designing a common runtime API and then developing implementations for both multi-processors and clusters, thereby enabling the seamless scaling of streaming systems. If successful, the three research thrusts result in a stream processing platform that simplifies the development of state-of-the-art streaming applications while also facilitating future innovation in stream processing.","title":"SHF:Medium:A Common Stream Processing Platform","awardID":"1162444","effectiveDate":"2012-06-01","expirationDate":"2016-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[508475],"PO":["564588"]},"189304":{"abstract":"Linguists studying endangered languages in the field often ask their informants to describe pictures that illustrate particular characteristics of their language, such as how it uses pronouns or spatial relations or concepts of time. This enables the field linguist to obtain natural language with minimal instruction, exercising minimal influence on what is said, so that accurate information about the language can be recorded. Typically such pictures are prepared in advance, based upon research hypotheses about the language -- but often new hypotheses emerge in the course of sessions with informants. Researchers at Columbia University have proposed to develop an aid to field linguists which makes it possible to test new research questions as they arise in the field. They will adapt existing text-to-scene generation software, WordsEye, which allows users to create 3D scenes from simple English input, to produce a novel tool for fieldwork called WELT, the WordsEye Linguistics Tool.<br\/><br\/>WELT tool will ultimately have two modes of operation: 1) In Phase 1, English input will automatically generate a picture which can be used to elicit a targeted description, 2) In Phase 2, input in the target language will automatically generate a picture representing the meaning of the input, to verify linguistic hypotheses with native speakers. <br\/><br\/>While WELT is intended ultimately for general use, it will initially be developed to study Arrernte, an endangered language spoken by ~6000-8000 Arrernte people in Central Australia. While some aspects of this language are well documented, a number of idiosyncratic lexical and morphological features of the language that relate to describing spatial relations are not well understood. Such features are interesting because they relate directly to how a language is used by its speakers to describe the way their perceive the world. The language group's remote location and insular culture have made it difficult to document by traditional means, so that tools such as WELT should be particularly useful. WELT will be tested in the field as part of an existing cooperation with Dr. Mark Dras and other researchers at Macquarie University, Sydney, Australia.<br\/>The Division of Information & Intelligent Systems of the Directorate for Computer & Information Science & Engineering is [co-]funding this award as part of its commitment to support the development of computational tools and methods for the documentation of endangered languages.","title":"Using Computational Tools to Facilitate Corpus Collection and Language Use in Arrernte (aer)","awardID":"1160700","effectiveDate":"2012-06-01","expirationDate":"2014-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":[507533,"511614"],"PO":["564750"]},"196268":{"abstract":"The International Conference on Intelligent Tutoring Systems (ITS) provides a forum for interchange of ideas around the applications of computer science to education and human learning. Presentations at the conference focus on developments and rigorous research around the design and use of interactive and adaptive learning technologies for learners of all ages, for subject matters that span the school curriculum, and for professional applications in industry, the military, and medicine. The conferences promotes cross-fertilization of information and ideas from several cyberlearning related fields: artificial intelligence, cognitive science, education, learning sciences, human-computer interaction, educational technology, psychology, and STEM disciplines.<br\/><br\/>This project will support travel for advanced graduate students from US universities to attend the 11th International Conference on Intelligent Tutoring Systems (ITS), to be held in Chania, Crete, in Greece, from June 15 to 18, 2012 (http:\/\/its2012.teicrete.gr). Those advanced graduate students will participate in the Young Research Track at the conference. That track is designed to provide young researchers with mentoring beyond what they get at their home institutions that will help them transition from graduate school to a fruitful research career. Young Researcher activities include structured poster sessions in which students present their work and one-on-one mentoring throughout the conference from a senior member of the ITS community who shares research interests with a young researcher and who comes from a different university and has a different approach than the young researcher experiences in his\/her home institution. It is expected that conversations between peers and between mentors and mentees will continue throughout each young researcher's career. <br\/><br\/>This activity supports the mission of NSF to train more advanced professionals in Science, Technology, Engineering, and Mathematics. This conference is unique in its synthesis and cross-fertilization across three STEM capacities: building cutting-edge learning technologies, investigating pedagogical methods that are theoretically grounded in the cognitive, social, and learning sciences, and rigorously testing the learning environments for their effectiveness at promoting learning (in STEM disciplines and other disciplines) among K-12, college, and workplace populations.","title":"CAP: Support for Young Researchers to attend the International Intelligent Tutoring Systems Conference 2012","awardID":"1238095","effectiveDate":"2012-06-15","expirationDate":"2013-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":["552841"],"PO":["560894"]},"196642":{"abstract":"Parallelism is everywhere in computing systems (such as multicore laptops), and in high end supercomputers. To program these machines, Message Passing Interface (MPI), which is a de facto standard of portable application programmer interfaces, was being developed by industry, academia, and government participants since 1993. However, MPI-based parallel programs have traditionally failed to continue to work when hardware faults occur. Hardware faults are becoming a bigger problem for parallel systems as they grow in size and speed. This work introduces a new solution to fault tolerance at scale for MPI-based programs. <br\/><br\/>This research advances current state of fault-tolerant MPI by exploring a possibility of applying transactional parallel programming techniques. The main idea is to explore how MPI-based parallel applications benefit from transactions to achieve fault tolerance. The success of the proposed approach will change the design of middleware, application programmer interfaces, and scalable subsystems that support such parallel programs (such as input-output systems).","title":"EAGER: A Transactional, Fault-Aware MPI Prototype to Enable MPI-3 Standardization","awardID":"1239962","effectiveDate":"2012-06-01","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[527384],"PO":["565272"]},"189658":{"abstract":"I\/O on High-End Computing (HEC) machines is increasingly becoming the killing performance bottleneck. However, conventional execution paradigms for HEC are computing-centric and have inherent limitations in addressing critical I\/O issues of data-intensive applications. There is a great need for developing unconventional execution paradigms to meet the growing I\/O demand of high-end computing.<br\/><br\/>In this project, the PIs propose a decoupled execution paradigm (DEP) to address I\/O bottleneck issues. DEP is the first paradigm enabling users to identify and handle data-intensive operations separately. The objective of the proposed research is three-fold: 1) understanding the execution paradigm requirement from the data-centric point of view, 2) studying the feasibility of the proposed decoupled execution paradigm, and 3) providing a partially implemented prototyping of DEP and its associated system design to support the first two objectives. Several technical hurdles have been identified, which include system architecture, programming model, and runtime system. Solutions are proposed and detailed plans are provided to evaluate the newly proposed decoupled execution paradigm.","title":"CSR: Medium: Collaborative Research: Decoupled Execution Paradigm for Data-Intensive High-End Computing","awardID":"1162540","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["557489","521549"],"PO":["565255"]},"196896":{"abstract":"This project supports workshop travel and dissemination of workshop results for an upcoming workshop on complex engineered networks. Complex engineered networks are everywhere: power grids, Internet, transportation networks, and others. They are being used more than ever before, and yet our understanding about them remains limited. The Internet, wireless networks, and online social networks have shaped the modern society. Increasingly, critical, engineered, large-scale systems, such as transportation networks, power grids, and oil and gas distribution systems, are being enhanced and optimized by state monitoring and dynamic controls through sensor and cyber mechanisms. These networks have evolved into complex systems with behaviors and characteristics that are beyond the characterizations and predictions possible by the traditional modeling, analysis and design approaches.<br\/><br\/>The workshop will bring together experts from the academia, national laboratories, government, and industries to assess the recent trends, state-of-the-art, and impending challenges in modeling, predicting and controlling the behaviors of these complex networks to gain better performance, efficiency, and robustness. The objectives of the workshop include: <br\/><br\/>- Identify transformative research challenges and directions in the field of large-scale, complex engineered networks and interconnected physical systems of sensors and instruments, such as the power grid and communications networks. <br\/>- Assess the state-of-the-art, future trends, and important opportunities and challenges in the theory, design, analysis, tools, and applications of complex interconnected systems research in government, industry, and academia. <br\/>- Identify strategies for inter-agency collaborations at the federal level to enable different communities to carry out joint efforts, leverage ongoing activities, accelerate new discoveries, and enable technology transfers to societal impact in the research field of complex networks and interconnected systems. <br\/><br\/>Broader Impact: Complex systems occupy critical roles in our society but their performance across a full set of operating conditions is usually at best poorly understood. Formal mathematical analysis may give insight into the operation of system components or into the operation of simplified system models, but is seldom capable of exactly modeling actual code. Testing of complex systems often misses unexpected and undesirable behaviors resulting from cross-system interactions. Program module (unit) testing is effective in checking for gross programming errors across a specified set of inputs but often fails for inputs generated by these behaviors. Dynamic whole system behaviors such as oscillations, spreading overloads, and cascading security failures are not discoverable via unit testing. Exhaustive testing is often either not possible or prohibitively expensive in terms of time or resources. Better understanding of how to couple mathematical analysis and testing for the purposes of rapid and rigorous characterization of complex systems would have broad societal impact. The workshop is a joint undertaking between NSF, DoE and AFOSR via the Networking and Information Technology Research and Development (NITRD) Program and the Large Scale Networking (LSN) working subcommittee.","title":"Workshop cost and travel grants for Large Complex Network Workshop","awardID":"1241356","effectiveDate":"2012-06-15","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["561963"],"PO":["564993"]},"194158":{"abstract":"The project funds extended research visits of U.S-based graduate students to selected Asian research groups working in speech and language processing. These students are selected from those attending the annual meeting of Association for Computational Linguistics (ACL), which will be held in Jeju, Korea, July 8-14, 2012. The selected students will work on a research project with researchers in the hosting group they are visiting.<br\/><br\/>This project will provide opportunities for students to be exposed to different culture and new research paradigm in other countries, broaden their horizon and help generate new research ideas, and help make them more competitive in the global market and develop into the scientists that are needed globally in the future. The extended visit also helps build bridges between the Asian hosts and the student's home research group in the U.S. This will facilitate long term collaboration between U.S. and other countries, and advance science and technology in the whole world.","title":"Extended Visit to Asian Research Labs for Selected Students Attending ACL 2012 Student Research Workshop","awardID":"1225629","effectiveDate":"2012-06-15","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["563325"],"PO":["565215"]},"197249":{"abstract":"The Global Environment for Network Innovations 'GENI' is a suite of research infrastructure supported by the NSF that is rapidly emerging in prototype form across the United States. GENI aims to transform experimental research in networking and distributed systems, as well as emerging research into very large socio-technical systems, by providing a suite of infrastructure for 'at scale' experiments in future internets. <br\/><br\/>The GENI Project Office organizes three major GENI Engineering conferences (GEC) per year, in which the entire GENI community meets to review current status, and to decide on subsequent steps in GENI's evolution. These GECs include community-based working groups leading GENI's design and planning, and demonstrating progress with live experiments. <br\/><br\/>MIT is hosting the fourteenth edition of the GENI Engineering conference. This project supports organizing the demo session to be held on the MIT Campus. About 400 leading researchers and Ph.D. students from diverse US institutions will gather at MIT to showcase their ideas and results. The campus venue has an existing 10GB link which will provide access to the National Lambda Rail (NLR) network in addition to MIT's more standard Internet services. Each demo will be provided with 1G wired connection to the GENI infrastructure. Additionally, because MIT and its Computer Science and Artificial Intelligence Laboratory (CSAIL) provide wireless access to all guests, wireless will be available for demonstrations and participants. <br\/><br\/>Broader Impact: The GEC Demo sessions provide graduate students with both an opportunity to demonstrate and explain their work to the GENI community prior to formal publication. It helps new graduate students understand what is being done with GENI and encourages cross-university cooperation by providing a method for students and faculty to discover who amongst their peers at other institutions might be valuable resources. It also supports outreach to new community members, including the emerging US Ignite community.","title":"LIVE DEMONSTRATION EVENT at the14TH GEC in BOSTON","awardID":"1242938","effectiveDate":"2012-06-01","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["125800"],"PO":["564993"]},"190880":{"abstract":"The image processing domain is experiencing rapid increases in data size and algorithm complexity. These increases in data size and algorithm complexity demand large amounts of computing and storage power. However, modern computer architectures have evolved to be extraordinarily complex, and frequently become a challenge rather than a help for general researchers and educators who work in image processing technologies. <br\/><br\/>In order to fill the gap between complicated modern architectures and complex applications, and to support the research and education of image processing, the PIs are developing an integrated image processing research environment within a computing Cloud infrastructure. This infrastructure includes: 1) an open image processing computing Cloud to support researchers and students to conduct image processing research, share knowledge and research results, and stimulate education materials among three universities: Prairie View A&M University, University of Houston, and University of Delaware; 2) a high-level domain specific language designed to provide an abstract and productive programming model for image processing applications; 3) a general compiler optimization framework with the capability to tune into image processing applications at various levels starting from high-level representations to low level transformations in the Cloud environment.","title":"II-NEW: Collaborative Research: Image Processing Cloud (IPC): A Domain-Specific Cloud Computing Infrastructure for Research and Education","awardID":"1205708","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["554349",511735,511736],"PO":["565255"]},"189549":{"abstract":"Parallel programming is in crisis: its difficulty dissuades all but the most determined (and deep-pocketed)<br\/>software vendors, and speedups are often disappointing for all but regular programs. Merely augmenting<br\/>the substantial knowledge-base of parallel computing with incremental ideas in algorithms, programming<br\/>languages, compilers, hardware, power or applications, interesting as they may be, is unlikely to change<br\/>this reality.<br\/>This project advances a powerful idea for drastically improving ease-of-programming within the context of<br\/>a holistic many-core research architecture called XMT. Our contention is that without the co-design of<br\/>language and architecture, one cannot conquer the twin challenges of easy programming and efficient<br\/>parallelization of irregular programs. Therefore we are developing a new easy-to-program language<br\/>called ICE as part of ecosystem consisting of XMT, the PRAM algorithmic model, and ICE, that together<br\/>deliver on this twin goal. The XMT architecture, developed at UMD over the last decade, is capable of<br\/>exploiting fine-grained parallelism in irregular programs. ICE is based on the successful PRAM algorithm<br\/>model, which provides a rich theory for parallel programming, and has led to published parallel algorithms<br\/>for hundreds of problems.<br\/>The broader impact of this project includes (i) much easier parallel programming model leading to more<br\/>succinct and intuitive code; (ii) freeing the programmer of many complex issues in parallel programming,<br\/>leading to greater productivity and acceptance of parallel programming; (iii) the nearness of ICE and<br\/>PRAM means that programmers would instantly have a rich ?library? of parallel algorithms without having<br\/>to write their own; (iv) a language especially suitable to an architecture that has demonstrated<br\/>unprecedented speedups on hard-to-parallelize irregular applications; and (v) a very active outreach<br\/>program that has already seen XMT being used at many research and educational institutions.","title":"CSR: Medium: Easy PRAM-Based High-Performance Parallel Programming with Immediate Concurrent Execution (ICE)","awardID":"1161857","effectiveDate":"2012-06-01","expirationDate":"2016-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[508237,"540124"],"PO":["565255"]},"190770":{"abstract":"This award provides funding for a new Computing Research Infrastructure (CRI) project focused on power- and thermal-aware computing at Wayne State University. PORTAL (the proposed POweR and Thermal Aware computing Laboratory) will support a broad range of research on software-controlled power and thermal optimization of both general-purpose and embedded systems, by providing: 1) a diverse set of hardware test beds, ranging from server-level processors to smart phones; 2) precision power and thermal measurement capabilities permitting the development and verification of accurate power and thermal models; 3) battery power-dissipation measurement capabilities for investigation of systems in a compact environment; and 4) performance evaluation data collection mechanisms used in both research and education settings.<br\/><br\/>Power and heat management are critical concerns for sustainable computing. Progress in this area benefits society through reduction in energy usage and enablement of new portable electronic devices with reduced battery lifetime limitations. The project improves educational opportunities and work-force development at Wayne State University through development of new courses on power and thermal effects in computing, improving coverage of energy and power dissipation in existing courses within the core curriculum, and providing hands-on experience for experimentation by students. The investigators are committed to making use of the new facilities in their efforts to involve more female and under-represented minority students in computing systems research, and their outreach activities to K-12 students.","title":"II-NEW: A Research and Education Infrastructure for Power- and Thermal-Aware Computing","awardID":"1205338","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["511432","563661",511432],"PO":["565272"]},"189616":{"abstract":"Multi-core processors with hundreds of embedded functional blocks are designed to achieve unprecedented performance benefits for a wide variety of applications such as graphics, financial and scientific modeling, networking, multimedia and wireless infrastructure. The Network-on-Chip (NoC) is an enabling methodology to integrate many embedded cores on a single die. However, with growing levels of integration traditional NoCs suffer from high latency and energy dissipation in on-chip data transfer due to conventional metal\/dielectric based interconnects. The wireless NoC (WiNoC) simultaneously addresses the latency, power consumption and interconnect routing problems of conventional NoCs by replacing multi-hop wired links with high-bandwidth single-hop long-range wireless channels. Recent investigations have characterized silicon integrated on-chip antennas operating in the millimeter (mm)-wave range of 50-110 GHz, and this is now a viable technology. Coupled with significant advances in mm-wave transceiver design, this development opens up new research opportunities for designing high bandwidth and low power WiNoCs.<br\/><br\/>The proposed research will develop a cross-layer design methodology for an on-chip wireless micro-network. Suitable physical, data link and network layer protocols will be developed for the WiNoC. The expected contribution of this work is the development and demonstration of broadband and integrable mm-wave WiNoCs. The transformational aspect of this proposal lies in addressing the on-chip interconnect problem from a fundamentally new perspective, namely by developing a broadband millimeter wave wireless network at the micro\/nanoscale, as opposed to pursuing incremental improvements in traditional wired interconnects. By bringing wireless networking to the on-chip environment, the proposed research will introduce a paradigm shift in the design of multi-core chips. <br\/><br\/>The proposed research will facilitate the education of undergraduate and graduate students by allowing them to apply classroom knowledge to a research problem requiring hardware, software and theoretical expertise. Such expertise will be developed in both university and industrial laboratory settings using state-of-the-art test equipment and computing facilities, and will ultimately be necessary to maintain the technological leadership of the United States. Students from various underrepresented groups, including women, African Americans and Hispanics, will be engaged in this project. The project's educational impacts will be complemented by the positive effect that the research outcomes are expected to have on society as a whole.","title":"SHF: CSR: Medium: Collaborative Research: Hierarchical On-Chip Millimeter-Wave Wireless Micro-Networks for Multi-Core Systems","awardID":"1162202","effectiveDate":"2012-06-01","expirationDate":"2016-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["523584","523585"],"PO":["366560"]},"197008":{"abstract":"High Performance Computing is strategically important to national competitiveness. Advances in computational capabilities involve the use of unprecedented levels of parallelism: programming methods that involve billions of concurrent activities. Computational Frameworks allow these parallel programs to be organized in a modular fashion, achieving higher reliability, scalability, and better resource management capabilities.<br\/><br\/>The project develops formally based reliability enhancement mechanisms when Computational Frameworks are developed or optimized in response to the arrival of newer hardware\/software technologies. These mechanisms include a formal specification of the expected behavior of these frameworks, and ways to verify them before deployment and during live operation. Correctness issues addressed in this proactive manner will considerably reduce the time it takes to proceed from idea to science. This project will enable a scientific understanding of which formal methods are likely to work at the scale of millions of cores, and which formal methods are best recommended to capture intended behavior versus those that are best suitable for run-time use. The project will also result in broad impact in terms of: the incorporation of our verification tools and techniques within popular tool-integration frameworks; achieving large-scale case studies on the use of formal methods within a computational framework that is under development; and training of undergraduate and graduate students on advanced correctness verification methods. It will also help build talent pool vital to continued progress in high performance computing with applications to science and engineering, energy\/sustainability, and homeland security.","title":"EAGER: Formal Reliability Enhancement Methods for Million Core Computational Frameworks","awardID":"1241849","effectiveDate":"2012-06-01","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["561775","556612"],"PO":["565264"]},"193532":{"abstract":"Until recently, the speed of a computer processors could be increased<br\/>by packing more transistors into a smaller area and increasing the<br\/>frequency. This trend is now unsustainable because of power<br\/>constraints, with only moderate gains going forward even when putting<br\/>hundreds or thousands of traditional cores onto a chip. Thus, how to<br\/>reduce power consumption while increasing performance is one of the<br\/>core concerns. It is well-accepted that specialization (designing<br\/>parts of the processor for a specific task) and heterogeneity<br\/>(designating different parts of the processor for different tasks) can<br\/>lead to orders of magnitude improvements in both aspects. However,<br\/>the question is whether such efficiency can be maintained while<br\/>providing enough flexibility to implement a broad class of operations.<br\/>Leveraging unique domain expertise, research under this project<br\/>addresses this question for the domain of matrix computations, which<br\/>are at the core of many computational advances, both in scientific<br\/>high-performance computing as well as in the embedded, mobile or<br\/>cyber-physical domains.<br\/><br\/>Observing that the largest benefits can be obtained through<br\/>specialization at the foundations, this project is aimed at<br\/>co-designing algorithms and architectures to directly realize basic<br\/>linear algebra methods in an optimized combination of hardware and<br\/>software. By designing a specialized Linear Algebra Processor (LAP),<br\/>it is possible to achieve one to two orders of magnitude improved<br\/>efficiencies compared to traditional or proposed computer<br\/>architectures. The questions that the project will answer, through a<br\/>combination of analysis, simulation, and prototyping, include: (1) How<br\/>to best design such LAPs that can efficiently execute the full set of<br\/>linear algebra routines; and (2) How LAPs can be scaled, networked<br\/>into clusters and integrated with application software running on one<br\/>or more host processors. The broad goal of this project is to develop<br\/>novel, integrated linear algebra compute fabrics that are co-optimized<br\/>and co-designed across all layers ranging from the basic hardware<br\/>foundations all the way to the application programming support through<br\/>standard linear algebra software packages. This project is expected<br\/>to result in a leap in computational science and discovery<br\/>capabilities, thus enabling novel breakthroughs in industry, for the<br\/>consumer, at the national labs, in education and by scientists in<br\/>academia.","title":"SHF: Small: Algorithm\/Architecture Co-Design of Low Power and High Performance Linear Algebra Compute Fabrics","awardID":"1218483","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["556801","556802"],"PO":["565272"]},"193312":{"abstract":"In order to address the performance and programmability challenges of massively parallel systems new innovative approaches are needed. This research continues earlier work on the Fresh Breeze model of computation for which basic simulation results have demonstrated applicability to linear algebra kernels as well as the Graph500 challenge application with competitive performance. The merits of the programming model developed in the proposed research are demonstrated, and evaluated for usability and performance, using a new distributed simulation tool based on packet communication architecture.<br\/><br\/>This project proposes innovative combination of a general tasking model, a proposal for global virtual memory, and the matching system architecture. The innovations are expected to serve as the basis for systems that are more energy-efficient and resilient. The form and structure of computer programs for massively parallel computation are studied and implementation challenges analyzed and resolved. The three components of the project concern: general support for the major forms of parallelism found in sound and well-structured concurrent programs; structured means for expressing transactions on shared data such as data bases; and demonstration of a global virtual memory based on use of tree structures to represent all data objects. This is expected to reduce development effort and increase performance of software needed to address current and future scientific, environmental and social problems.","title":"SHF:Small:Fine-grain Tasking and Virtual memory for Massively Parallel Computing","awardID":"1217498","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[517820],"PO":["565272"]},"186921":{"abstract":"Parallel computing has entered the mainstream with increasingly large multicore processors and powerful accelerator devices. These compute engines, coupled with tighter integration of faster interconnection fabrics, are drivers for the next-generation high end computing (HEC) machines. However, the computing potential of HEC machines is delivered only through productive parallel program development and efficient parallel execution. This project enables application developers to improve performance on future HEC machines for their scientific and engineering processes. This project challenges the current model for parallel application development via \"black box\" tools and services. Instead, the project offers an open, transparent software infrastructure -- a Glass Box system -- for creating and tuning large-scale, parallel applications. `Opening up' the tools and services used to create and evaluate peta- and exa-scale codes involves developing interfaces and methods that make tool-internal information and available for new performance management services that improve developer productivity and code efficiency.<br\/><br\/>The project will explore the information that can be shared 'across the software stack'. Methods will be developed for analyzing program information, performance data and tool knowledge. The resulting Glass Box system will allow developers to better assess the performance of their parallel codes. Tool creators can use the performance data to create new analysis and optimization techniques. System developers can also better manage multicore and machine resources at runtime, using JIT compilation and binary code editing to exploit the evolving hardware. Working with the `Keeneland' NSF Track II machine and our industry partners, the project will create new performance monitoring tools, compiler methods and system-level resource management techniques. The effort is driven by the large-scale codes running on today's petascale machines. Its broader impact is derived from the interactions with technology developers and application scientists as well as from its base in three universities with diverse student populations.","title":"SI2-SSI: Collaborative Research: A Glass Box Approach to Enabling Open, Deep Interactions in the HPC Toolchain","awardID":"1148052","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["506602","558507"],"PO":["565247"]},"193587":{"abstract":"Despite the ubiquity of data centers, little is known about their effective management. Consolidation of multiple applications with diverse and changing resource requirements is common in data centers as hardware resources are abundant and opportunities for better system usage are plenty, as are opportunities to degrade individual application performance due to unregulated performance interference between applications and system resources. Is it possible to maximize resource usage while respecting individual application performance targets or is it an oxymoron to simultaneously meet such conflicting measures? In this project, a solution methodology to the above difficult problem is proposed using a three-pronged approach.<br\/><br\/>First, a detailed large scale performance study on several thousands of data center servers within a time period that spans two years is going to be conducted. This study provides a micro and macro view of current workload requirements, of workload resource demands on<br\/>basic resource components including CPU, memory, disk, and their temporal evolution. This analysis provides a baseline for the development of scalable and efficient resource management in data centers.<br\/><br\/>Second, extensive experimentation on basic components of data centers is going to quantify performance interference among different classes of applications due to consolidation. This experimentation drives the development of a light-weight profiler that is system- and application-agnostic. The methodology captures application resource demands via non-intrusive low-level measurements that are provided via standard tools.The experimental observations have the potential to drive the development of resource allocation policies in data centers both at the micro level (i.e., at specific hardware components that are used as data center building blocks) and at the macro level (i.e., at the data center as a whole).<br\/><br\/>Third, a queueing-theory based tool is developed that uses as input the resource demands measured by the profiler to accurately predict application scalability under homogeneous and heterogeneous consolidations. The model can be used to predict the application and system performance under virtualized environments at the micro and macro levels, and provide consolidation suggestions such that pre-defined user- or system-specified performance targets are met.<br\/><br\/>The proposed methodologies have the potential to improve the effectiveness of resource allocation in data centers that operate under complex workloads and show excellent potential for allocation solutions that meet pre-defined user and system performance targets. This research will affect the state-of-the-practice via industrial collaborations, especially IBM Research and NEC Research Labs. More broadly, this research has the potential to make a strong impact in management of in-production data centers. Through this project, several students will be prepared to better meet industry demands in the areas of performance modeling and resource allocation in complex environments.","title":"SHF-Small: Robust Methodologies for Effective Data Center Management","awardID":"1218758","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[518455],"PO":["565272"]},"197613":{"abstract":"This is funding to support a doctoral research symposium (workshop) of approximately 8 promising doctoral students from the United States and abroad (no more than one, to broaden the horizons of the U.S. participants), along with about 4 distinguished research faculty. The event will take place in conjunction with and immediately preceding the 25th ACM Symposium on User Interface Software and Technology (UIST 2012), to be held October 6-10 in Cambridge, MA, and sponsored by the Association for Computing Machinery's Special Interest Group on Human Computer Interaction (SIGCHI). The annual UIST conference is the premier international forum for presenting innovative research results as well as implementation experiences in the software and technology of human computer interaction. It brings together researchers and practitioners from diverse areas that include traditional graphical and web user interfaces, tangible and ubiquitous computing, virtual and augmented reality, multimedia, new input and output devices, and computer-supported cooperative work. More information about the conference may be found at http:\/\/www.acm.org\/uist.<br\/><br\/>This year's doctoral research symposium will be just the 10th such workshop associated with the UIST conferences (NSF has offered support for these events from their inception). The three goals of this full-day event are to increase the exposure and visibility of the participants' work within the community, to help establish a sense of community among this next generation of researchers, and to help foster their research efforts by providing substantive feedback and guidance from a group of senior researchers in a supportive and interactive environment. To these ends, student participants will each make formal 20-minute presentations of their work to the group, to be followed by an extensive discussion lasting approximately 30 minutes during which they will receive feedback from a faculty panel; the feedback is geared to helping students understand and articulate how their work is positioned relative to other research, whether their topics are adequately focused for thesis research projects, whether their methods are correctly chosen and applied, and whether their results are appropriately analyzed and presented. The students will also present their research to a wider audience through posters at the conference poster reception, brief overviews during the conference overview session, and short papers in the UIST Adjunct Proceedings. <br\/><br\/>Broader Impacts: The doctoral symposium will help expand the participation of young researchers pursuing graduate studies in the vital field of user interface software and technology, by providing them an opportunity to gain wider exposure in the community for their innovative work and to obtain feedback and guidance from senior members of the research community. It will also foster a sense of community among these young researchers, by allowing them to create a social network both among themselves and with senior researchers at a critical stage in their professional development. Because the students and faculty constitute a diverse group across a variety of dimensions, the students' horizons are broadened to the future benefit of the field. The organizers of the event will make special efforts to attract students from institutions not historically heavily represented at UIST and to foster diversity across under-represented groups. To further increase participant diversity, the organizers will use NSF funds to support no more than one student from any single institution.","title":"Workshop: UIST 2012 Doctoral Symposium","awardID":"1245112","effectiveDate":"2012-06-15","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[530199],"PO":["565227"]},"186976":{"abstract":"Parallel computing has entered the mainstream with increasingly large multicore processors and powerful accelerator devices. These compute engines, coupled with tighter integration of faster interconnection fabrics, are drivers for the next-generation high end computing (HEC) machines. However, the computing potential of HEC machines is delivered only through productive parallel program development and efficient parallel execution. This project enables application developers to improve performance on future HEC machines for their scientific and engineering processes. This project challenges the current model for parallel application development via \"black box\" tools and services. Instead, the project offers an open, transparent software infrastructure -- a Glass Box system -- for creating and tuning large-scale, parallel applications. `Opening up' the tools and services used to create and evaluate peta- and exa-scale codes involves developing interfaces and methods that make tool-internal information and available for new performance management services that improve developer productivity and code efficiency.<br\/><br\/>The project will explore the information that can be shared 'across the software stack'. Methods will be developed for analyzing program information, performance data and tool knowledge. The resulting Glass Box system will allow developers to better assess the performance of their parallel codes. Tool creators can use the performance data to create new analysis and optimization techniques. System developers can also better manage multicore and machine resources at runtime, using JIT compilation and binary code editing to exploit the evolving hardware. Working with the `Keeneland' NSF Track II machine and our industry partners, the project will create new performance monitoring tools, compiler methods and system-level resource management techniques. The effort is driven by the large-scale codes running on today's petascale machines. Its broader impact is derived from the interactions with technology developers and application scientists as well as from its base in three universities with diverse student populations.","title":"SI2-SSI: Collaborative Research: A Glass Box Approach to Enabling Open, Deep Interactions in the HPC Toolchain","awardID":"1148346","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["530888",501636],"PO":["565247"]},"195446":{"abstract":"This project supports students to attend the Ninth Annual IEEE Communications Society<br\/>Conference on Sensor, Mesh, and Ad Hoc Communications and Networks (SECON 2012) to be<br\/>held in Seoul, South Korea in June 2012. SECON is a premier conference in the areas of sensor, ad<br\/>hoc, and mesh networking, serving as a meeting point of researchers from academia and industry,<br\/>as well as practitioners in diverse fields of wireless communications and networking. This project<br\/>supports travel to the conference for US based graduate students who might not otherwise be able<br\/>to attend for financial reasons. Students will be exposed to the conference, a technical forum that<br\/>is critical for their professional maturity and development. Students will also be involved in various<br\/>activities and work as volunteers to support these activities, increasing their level of involvement<br\/>and connection to the conference and the research community.","title":"IEEE Communications Society Conference on Sensor, Mesh, and Ad Hoc Communications and Networks (SECON) 2012: Student Travel Awards","awardID":"1232712","effectiveDate":"2012-06-01","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[523922],"PO":["535244"]},"197328":{"abstract":"The wealth and variety of data generated in modern medical and health-care settings present tremendous research challenges as well as opportunities in artificial intelligence and machine learning. Extensive electronic medical records - with thousands of fields recording patient conditions, diagnostic tests, treatments, outcomes, as well as narrative about the patients and care delivery - provide an unprecedented source of information. Tapping into this data source can bring clues leading to improvements in a wide range of health-care applications, such as disease modeling and early detection, chronic disease management, and efficient design of clinical trials.<br\/><br\/>Intellectual Merit: The Workshop on Machine Learning for Clinical Data Analysis (http:\/\/sites.google.com\/site\/mlclinicaldata) will be held during the International Conference on Machine Learning (ICML), 2012, Edinburgh, Scotland on June 30-July 1, 2012. The workshop aims to bring together machine learning and informatics researchers interested in problems and applications in the clinical domain, with the goal of bridging the gap between the theory of machine learning and the needs of the health informatics applications. The award provides funds to cover the travel costs of invited speakers and graduate students. The Ph.D. student participants will be able to present their work, interact with their peers from other universities as well as hundreds of leading researchers in machine learning from around the world. In addition to attending the workshop, they will attend the technical sessions, plenary talks, and tutorials of their choice at the conference. The invited speakers will present talks covering state-of-the-art research as well as open machine learning research challenges in building predictive models from clinical data. The workshop aims to educate the machine learning research community regarding machine learning research opportunities and challenges in health care applications, especially in connection with recent electronic health record initiatives; identify new machine learning problems not previously addressed by the community; and help build a community of researchers who can advance machine learning informed by the challenges and opportunities presented by clinical data analytics. <br\/><br\/>Broader Impacts. Machine learning is playing an increasingly important role in many emerging data-rich sciences and application domains, such as bioinformatics, computational biology, health informatics, and security informatics. Participation in the workskshop and the ICML and COLT conferences will enrich the education and training of student researchers at early stages in their careers. The travel awards will help broaden the participation of women and members of underrepresented minority groups within the Machine Learning and Health Informatics research communities.","title":"ICML 2012 Workshop on Machine Learning for Clinical Data Analysis","awardID":"1243409","effectiveDate":"2012-06-15","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[529435],"PO":["560586"]},"190794":{"abstract":"This project will support the following development of the Seattle platform for running distributed experiments: 1) building a new virtual machine that executes native code using the Google Native Client (NaCl) sandbox and 2) providing sufficient support to ensure the testbed continues to be useable by the community.<br\/><br\/>Adding native code execution will make it easier for researchers to run legacy code on the Seattle testbed.<br\/>As a result, researchers and students can use code written elsewhere on this testbed via the Google Native Client and Google Native Client toolchain. The resulting code will execute computationally in the NaCl sandbox, but call into Seattle?s Repy V2 sandbox to safely perform system calls. An implementation of a POSIX-like API will be provided that is safe, portable, and adequate to execute most code without modification. Unmodified programs can be compiled and executed and their calls will be re-mapped to use this API. This will allow researchers to have a write-once, run anywhere API across thousands of diverse user devices.<br\/><br\/>The project will also maintain the core software and servers for the Seattle testbed. While new feature requests are outside the scope of the project addressing serious bugs is within scope. In addition four new machines required to maintain reliable service to the Seattle community will be added.<br\/><br\/>The resulting Seattle Testbed will:<br\/> - Have sufficient uptime to continue as a valuable resource for educators and researchers;<br\/> - Allow researchers to write C code in native client for performance critical measurements;<br\/> - Provide facilities for legacy code execution.<br\/><br\/>Broader Impact:<br\/>The Seattle testbed has already had a positive impact in the educational and research communities. It is used to teach undergraduate networking, distributed systems, and security at approximately a dozen universities. Researchers use it as a platform to study networks, mobile devices, cloud environments, and large scale distributed systems under the varieties of access links, configurations, and loads encountered in the real world. This project supports these broader impacts by enhancing the support infrastructure and, via the new sandbox, broadens the range of code that can be used in teaching and experimentation.","title":"CI-ADDO-EN: Enhancing and Supporting a Community Testbed","awardID":"1205415","effectiveDate":"2012-06-01","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["561066"],"PO":["564993"]},"194765":{"abstract":"This project will provide the Phase 2 systems engineering for the Global Environment for Network <br\/>Innovations (GENI) project. GENI, a virtual laboratory for exploring future internet technologies <br\/>and protocols at scale, creates major opportunities to understand, innovate and transform <br\/>global networks and their interactions with society. Via the flexible and dynamic deployment of <br\/>experiments onto common infrastructure, GENI re-imagines the methodology of both network system <br\/>research and of potential early deployments and evaluation. It enables repeatable experiments <br\/>on large, complex, networked systems At scale demonstrations of transformational ideas <br\/>increases the opportunity for significant socio-economic impact. <br\/><br\/>At the start of the GENI program it was not clear that GENI was technically feasible. An early major goal was to show <br\/>its feasibility. To this end, the GPO started a series of rapid, community-created prototypes via ?spiral development? <br\/>so that hands on experience could drive its evolution. Each GENI spiral is 12 months long, and aims to drive down <br\/>specific technical and programmatic risks. This proposal supports the engineering activities of spirals 4, 5 and 6. <br\/>The task categories associated with the proposal are:<br\/>a) Experiment support and direct aid to the research teams attempting to use the GENI prototype, including training <br\/>and tools.<br\/>b) Continued progress towards full Integration and Operations of the current GENI prototype including <br\/>deployment of GENI racks, enhancing the integration with Internet 2 and National Lambda Rail, additional <br\/>WiMax integration, campus expansion with the goal of having between 100 to 200 campuses ?GENI enabled?, and <br\/>transition for 24x7 operations managed by Indiana University.<br\/>c) Formalization and documentation of the GENI architecture.<br\/>d) Systems Engineering work including security analysis of the GENI infrastructure, instrumentation and <br\/>measurement tools and infrastructure, and subcontract technical management.<br\/><br\/>Broader Impact: The engineering process of building GENI has directly engaged the newest generation of <br\/>faculty in students in a large-scale systems project. The experience of building a large-scale system <br\/>is an educational opportunity that is providing direct benefit to the US computer research community. GENI <br\/>is already being used as an instrument for research. This proposal supports and broadens the availability <br\/>and usability of the research instrument.","title":"GENI Engineering Activities, Phase 2","awardID":"1228971","effectiveDate":"2012-06-01","expirationDate":"2016-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[521729],"PO":["564993"]},"197867":{"abstract":"This is funding to cover airfare and ground travel for approximately 40 student participants, as well as certain other expenses associated with, the 5th Young Investigators Summer Institute that is being organized by the PI under the auspices of the Consortium for the Science of Socio-Technical Systems (CSST), and which will be held July 29-August, 2012, at Bishop's Lodge in Santa Fe, New Mexico. The CSST resulted from recognition of the growing importance of research on the interplay of humans and technology. The science of socio-technical systems (SST) is fundamental to the rapidly growing \"virtual organizations\" thematic area, among others, thus the urgent national need for research that is firmly grounded in the SST tradition. Yet this community of scholars, which includes faculty in diverse fields such as social informatics, social computing, CSCW, computational social science, HCI, and information science, remains fractured and largely invisible.<br\/><br\/>The CSST series of Summer Institutes is a critical step toward unifying this diverse community and enhancing its visibility, by providing an immersive experience for the next generation of SST leaders (both advanced doctoral students and pre-tenure faculty) so that they will be well prepared to engage in distributed scientific inquiry. The Summer Institutes build critical intellectual and social capital by fostering creation of a cohort group of new researchers whose work is shaped by hearing experts in socio-technical systems research provide encouragement and give advice on how to advance the field's intellectual basis, methodological approaches, and potential for sustained, meaningful and even transformative impact. <br\/><br\/>The 2012 workshop will adhere to the successful format that has evolved and been refined over the course of the prior Summer Institutes. The workshop will bring together early career researchers selected through a competitive review process with a set of more senior researchers for an intensive five-day research exchange. The event will be residential and located in a semi-isolated locale to encourage the maximum amount of social interaction among participants. Senior faculty, junior faculty, and advanced doctoral students will collectively strive to articulate in more coherent and contemporary forms the basic principles, goals and approaches to doing socio-technical science across a range of relevant intellectual communities. They will explore topics and methods for advancing the science of socio-technical systems, while focusing on intellectual development of individual research that is aligned with core aspects of the socio-technical perspective. <br\/><br\/>Broader Impacts: The diversity of Summer Institute participants across a number of dimensions (e.g., institutional, disciplinary, geographic, gender, minority group status), serves to broaden participants' perspectives at a critical stage in their careers. The immersive intellectual experience during the workshop will facilitate creation of a social network among the participants and the senior researchers who serve as instructors for the Summer Institute. This network will play a major role both in the professional development of the participants and in the evolution of the field of socio-technical systems research.","title":"WORKSHOP: Summer Institute on Sociotechnical Systems and Sciences","awardID":"1246329","effectiveDate":"2012-06-15","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["561666"],"PO":["565227"]},"187319":{"abstract":"The goal of this proposal is a fundamental redesign of wireless networks to systematically exploit interference to increase network capacity. Traditionally interference is considered harmful, hence current designs strive to avoid interference by scheduling concurrent transmissions in separate frequencies\/time slots. Hence the only way to add more capacity is to add more spectrum. However spectrum that can be used for building wireless networks has mostly been allocated and is in use, thus imposing hard limit on the scalability of the current network design. This proposal makes a fundamental shift: instead of avoiding interference, it designs techniques that systematically encourage and exploit interference to increase network capacity. The key insight is that interference is not random noise, but has structure since it is a synthetic signal created by another transmitter. If transmitters and receivers are aware of the interference structure, they can exploit it to actively shape\/code interference and better decode their own transmissions to cancel interference, and thus greatly increase capacity. The proposed research will produce techniques that can each have substantial impact of the design of wireless networks. This project will design single channel full duplex radios, a technical feat that has hitherto been considered impossible. Second, this research will produce rateless codes that can decode constituent packets from collisions, obviating the need for complex scheduling primitives and thus simplify PHY\/MAC design. Finally, it will produce smart radios that can adaptively operate in dense radio neighborhoods and maximize throughput, and thus coexist in environments with a variety of interfering radios.","title":"CAREER: Exploiting Interference in Wireless Networks","awardID":"1150177","effectiveDate":"2012-06-01","expirationDate":"2017-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[502394],"PO":["557315"]},"190872":{"abstract":"There is growing global importance of ocean exploration and monitoring as the oceans play a major role in climate regulation, nutrient production, resource retrieval and transportation, etc. Building and deploying a real-time underwater networked sensing infrastructure is thus needed for desired levels of monitoring and data collection. Despite a wave of research efforts in the area of underwater wireless networks, the lack of a community testbed has so far hampered further advances, as there is no common platform to evaluate and compare various communication and networking algorithms and protocols. Furthermore very few studies can afford to consider real system features due to the high cost of system deployment and maintenance.<br\/><br\/>This project involves the design and deployment of an open underwater testbed suite, accessible to the public at four sites in Connecticut, California, Texas, and Washington States. The testbed will include flexible choices of surface nodes, bottom nodes, and mobile nodes with reconfigurable modems. It will enable the vision of remote controlled and continuous networked node deployments running tests of communication, networking, sensing, and data streaming. In addition, the testbed will enable oceanographers to study scientific research questions, while using the testbed as a prototype for larger real-time monitoring deployments elsewhere. The testbed will also directly impact undergraduate research and student diversity by involving undergraduate students through REU programs, impacting curriculum development by enabling field courses, and engaging K-12 students and teachers, particularly in underserved communities.","title":"Collaborative Research:CI-ADDO-NEW: Ocean-TUNE: A Community Ocean Testbed for Underwater Wireless Networks","awardID":"1205665","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[511703,"546033","526410","550179"],"PO":["565303"]},"190784":{"abstract":"This planning project brings together the community to begin addressing the challenges of using text analysis (i.e., the analysis of the information extracted from the natural language used in software artifacts and program code) in software engineering. A set of workshops will be organized with researchers in the software engineering community interested in the use of text analysis, in order to elicit requirements for the design of the necessary infrastructure for the research community. The common infrastructure of foundational text analyses for the software domain will include software libraries, data, and educational materials.<br\/><br\/>Because the textual information embedded in software artifacts, program code and documentation encodes the software?s domain incepts and developers? knowledge about them, it is critical in supporting developers to effectively maintain today?s software and it is essential to the other stake- holders in the software engineering process, including managers, clients, and users. A study of recent literature shows that over 25 distinct software engineering tasks, ranging from requirements analysis to program comprehension, utilize textual analysis based tools. This project?s outcomes will have a broad impact, enabling researchers to: combine different types of text analysis techniques; transfer results of successful research to industry and facilitate entry for software engineering researchers in applying text analysis techniques; integrate new components for exploration of novel approaches to specific analyses; gain continual user evaluation of text analysis-based software engineering tools; and enable other researchers and practitioners to easily leverage text analysis to solve new software engineering problems. The long-term goal is to create such an infrastructure, which will allow text analysis to integrate seamlessly with current technology and environments used by software engineers. The increase in software size and complexity, as well as larger development teams, have made it significantly more challenging for humans to maintain software without tools to support them.","title":"CI-P: Collaborative Research: Advanced Text Analysis Infrastructure for Software Engineering","awardID":"1205391","effectiveDate":"2012-06-15","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["527984",511464],"PO":["564588"]},"186901":{"abstract":"The Message Passing Interface (MPI) is a very widely used parallel programming model on modern High-End Computing (HEC) systems. Many performance aspects of MPI libraries, such as latency, bandwidth, scalability, memory footprint, cache pollution, overlap of computation and communication etc. are highly dependent on system configuration and application requirements. Additionally, modern clusters are changing rapidly with the growth of multi-core processors and commodity networking technologies such as InfiniBand and 10GigE\/iWARP. They are becoming diverse and heterogeneous with varying number of processor cores, processor speed, memory speed, multi-generation network adapters\/switches, I\/O interface technologies, and accelerators (GPGPUs), etc. Typically, any MPI library deals with the above kind of diversity in platforms and sensitivity of applications by employing various runtime parameters. These parameters are tuned during its release, or by<br\/>system administrators, or by end-users. These default parameters may or may not be optimal for all system configurations and applications.<br\/><br\/>The MPI library of a typical proprietary system goes through heavy performance tuning for a range of applications. Since commodity clusters provide greater flexibility in their configurations (processor, memory and network), it is very hard to achieve optimal tuning using released version of any MPI library, with its default settings. This leads to the following broad challenge: \"Can a comprehensive performance tuning framework be designed for MPI library so that the next generation InfiniBand, 10GigE\/iWARP and RoCE clusters and applications will be able to extract `bare-metal' performance and maximum scalability?\" The investigators, involving computer<br\/>scientists from The Ohio State University (OSU) and Ohio Supercomputer Center (OSC) as well as computational scientists from the Texas Advanced Computing Center (TACC) and San Diego Supercomputer Center (SDSC), University of California San Diego (UCSD), will be addressing the above challenge with innovative solutions.<br\/><br\/>The investigators will specifically address the following challenges: 1) Can a set of static tools be designed to optimize performance of an MPI library during installation time? 2) Can a set of dynamic tools with low overhead be designed to optimize performance on a per-user and per-application basis during production runs? 3) How to incorporate the proposed performance tuning framework with the upcoming MPIT interface? 4) How to configure MPI libraries on a given system to deliver different optimizations to a set of driving applications? and 5) What kind of benefits (in terms of performance, scalability, memory efficiency and reduction in cache pollution) can be achieved by the proposed tuning framework? The research will be driven by a set of applications from established NSF computational science researchers running large scale simulations on the TACC Ranger and other systems at OSC, SDSC and OSU. The proposed designs will be integrated into the open-source MVAPICH2 library.","title":"Collaborative Research: SI2-SSI: A Comprehensive Performance Tuning Framework for the MPI Stack","awardID":"1147926","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["558590"],"PO":["558595"]},"194766":{"abstract":"Workshop: Communication theory and Signal Processing in the Cloud Era<br\/><br\/>Affordable virtualized computing resources have enabled storage and processing of information at a scale never previously imagined possible. Cloud computing is enabling what has been called the industrial revolution of data. Algorithms to store, process, compress and protect this information at a cloud scale are much needed. Much of this infrastructure is currently developed without a good understanding of fundamental principles from information theory and signal processing. <br\/><br\/>The workshop `Communication theory and Signal Processing in the Cloud Era' will take place on June 25 and 26 at University of California, Berkeley. The meeting focuses on bringing together internationally known experts in academia and industry to identify new challenges in cloud computing, coding techniques and content distribution at large scale.","title":"Workshop Proposal: Communication Theory and Signal Processing in the Cloud Era","awardID":"1228976","effectiveDate":"2012-06-15","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[521731,"560870"],"PO":["564898"]},"196603":{"abstract":"GNU Radio is an open source software radio project used extensively in industry, academia, and government for research, development, rapid prototyping, and deployment of wireless services. As an open source project, it has a wide-spread and disparate community of developers and users. Bringing members of this community together for a yearly conference helps to build a strong cohesion of ideas and identify and define the goals of the project. This conference also addresses the issues of increasing the development community of the project by getting to know potential developers and educating them on structure, style, and etiquette of a large, world-wide project used by thousands of people.","title":"Support For Upenn Gnu Radio Conference","awardID":"1239816","effectiveDate":"2012-06-15","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[527253,527254],"PO":["565303"]},"186934":{"abstract":"Linear algebra is a branch of mathematics that provides the foundation for a significant fraction of computations in science and engineering. Historically, the importance of linear algebra is such that highly specialized codes written by computer scientists have been used by the community of scientific programmers as a vital part of their application programs. With the rapid changes in computer architecture during the last several years, it would seem that corresponding modifications in linear algebra routines would be warranted. However, such progress is not in evidence; the development of such routines has been just incremental, involving successive rewrites of routines that had their genesis in the last quarter of the last century. Correspondingly, there is something<br\/>of a disconnect between the current `state-of-the-art' linear algebra libraries, modern computer architectures, and applications that utilize the libraries.<br\/><br\/>The new project will create a new, vertically integrated framework and implementation that revisits every layer of software, from low-level kernels to higher level functionality. The vertical integration is completed with a new generation of software for computational<br\/>chemistry applications, guaranteeing that the developed software, to be freely available to the public, supports sustained innovation in that domain and other sciences. The development builds on the FLAME project, which has been funded by NSF and industry for more than a decade.","title":"Collaborative Research: SI2-SSI: A Linear Algebra Software Infrastructure for Sustained Innovation in Computational Chemistry and other Sciences","awardID":"1148125","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0307","name":"Division of MATERIALS RESEARCH","abbr":"DMR"},"pgm":{"id":"1712","name":"DMR SHORT TERM SUPPORT"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1991","name":"CHEMISTRY PROJECTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["515656","513043","556801",501527,501528],"PO":["563091"]},"193369":{"abstract":"Production codes on supercomputers are struggling to remain scalable<br\/>each time the processor core count increases by a factor of 10, even<br\/>though they run efficiently at smaller scale.<br\/>But root cause diagnosis fails at petascale since (1) symptoms of<br\/>performance problems can be subtle, (2) only few<br\/>metrics can be efficiently collected and (3) tools can only feasibly record<br\/>a small subset of even these metrics.<br\/><br\/>This work addresses these problems by creating a framework that allows<br\/>application developers to focus on data analysis that drives customized<br\/>data extraction combined with on-the-fly analysis specifically geared<br\/>to their individual problems. This is accomplished by combining trace<br\/>analysis and in-situ data analysis techniques at runtime, thereby<br\/>lifting data reduction to a new level where it IS analysis. With this<br\/>approach, modular measurement and analysis components are combined to<br\/>selectively extract representative data from production codes in a<br\/>problem-specific manner, which enables root cause analysis.<br\/><br\/>The work demonstrates the feasibility of customized data<br\/>extraction and analysis at scale for root cause analysis on current<br\/>and forthcoming multi-petascale supercomputers. It thus contributes<br\/>to sustain scalable scientific computing into the future up to the largest<br\/>scales. Results of this work will be contributed as open-source code<br\/>to the research community and beyond as done, allowing other groups to<br\/>not only build tools on top of our framework but also contribute their<br\/>own components.","title":"SHF: Small: Scalable Trace-Based Tools for In-Situ Data Analysis of HPC Applications (ScalaJack)","awardID":"1217748","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["553590"],"PO":["565272"]},"190851":{"abstract":"CI-P:Collaborative Research: The Speech Recognition Virtual Kitchen<br\/><br\/>This project provides a \"kitchen\" environment to promote community sharing of research techniques, foster innovative experimentation, and provide solid reference systems for automatically recognizing speech, as a tool for education, research, and evaluation. The research infrastructure is built around virtual machines (VMs), which can be reconfigured and shared easily. We liken the virtual machines to a \"kitchen\" because they provide the environmental infrastructure into which one can install \"appliances\" (e.g., speech recognition toolkits), \"recipes\" (scripts for creating state-of-the art systems for a toolkit), and \"ingredients\" (spoken language data), along with \"dishes\" (completed experiments with log-files for reference).<br\/><br\/>The planning project engages the community to tackle some of the issues that have previously hampered efforts in cross-community sharing, including distribution methods and intellectual property issues. The project also provides an example architecture, which serves as a focus point for community-wide discussion.<br\/><br\/>In terms of broader impacts, the project engages researchers and educators that typically do not participate in automatic speech recognition (ASR) research by providing travel scholarships to a workshop at INTERSPEECH2012. In a wider scope, the infrastructure may be useable by other data-intensive fields (synthesis, dialog systems, NLP, computer vision, data mining). By providing a permanent, publicly available resource for research, education, and evaluation in ASR research, we can better train the next generation of undergraduates and graduates. The \"kitchen\" gives them easy access to a large number of state-of-the-art implementations, and facilitates deeper analysis of algorithms and better comparisons across systems.","title":"CI-P:Collaborative Research:The Speech Recognition Virtual Kitchen","awardID":"1205589","effectiveDate":"2012-06-01","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["543578"],"PO":["565215"]},"190884":{"abstract":"Reconfigurable hardware has tremendous potential in terms of performance and power efficiency. However, the high cost of tools needed to program such systems, and need to program at a very low level together put such systems out of reach of most researchers. The FAbRIC (FPGA Research Infrastructure Cloud) project will acquire and maintain such systems and their tools in the Texas Advanced Computing Center for open use by all researchers. In addition, the PIs will port our own reconfigurable hardware \"operating systems\" to the platforms to dramatically improve their usability and our own applications to serve as starting points for future work. <br\/><br\/><br\/>Having an open, shared resource of this kind makes some of the highest performance computational power available to all researchers, regardless of their location or their ability to purchase and maintain such systems. The project team will run distributed classes for students and researchers to learn how to use such platforms. In addition, the default usage model of \"open source to play\" enables anyone who agrees to let the team open their source codes to use the facility free of charge. Such a shared platform with free industrial-strength tools and open sourced code finally enables true reproducibility of research results and the ability to leverage other work.","title":"CI-ADDO-NEW: FPGA Accelerator Research Infrastructure Cloud (FAbRIC)","awardID":"1205721","effectiveDate":"2012-06-01","expirationDate":"2016-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["535119"],"PO":["562984"]},"190796":{"abstract":"CI-P:Collaborative Research: The Speech Recognition Virtual Kitchen <br\/><br\/>This project provides a \"kitchen\" environment to promote community sharing of research techniques, foster innovative experimentation, and provide solid reference systems for automatically recognizing speech, as a tool for education, research, and evaluation. The research infrastructure is built around virtual machines (VMs), which can be reconfigured and shared easily. We liken the virtual machines to a \"kitchen\" because they provide the environmental infrastructure into which one can install \"appliances\" (e.g., speech recognition toolkits), \"recipes\" (scripts for creating state-of-the art systems for a toolkit), and \"ingredients\" (spoken language data), along with \"dishes\" (completed experiments with log-files for reference). <br\/><br\/>The planning project engages the community to tackle some of the issues that have previously hampered efforts in cross-community sharing, including distribution methods and intellectual property issues. The project also provides an example architecture, which serves as a focus point for community-wide discussion. <br\/><br\/>In terms of broader impacts, the project engages researchers and educators that typically do not participate in automatic speech recognition (ASR) research by providing travel scholarships to a workshop at INTERSPEECH2012. In a wider scope, the infrastructure may be useable by other data-intensive fields (synthesis, dialog systems, NLP, computer vision, data mining). By providing a permanent, publicly available resource for research, education, and evaluation in ASR research, we can better train the next generation of undergraduates and graduates. The \"kitchen\" gives them easy access to a large number of state-of-the-art implementations, and facilitates deeper analysis of algorithms and better comparisons across systems.","title":"CI-P:Collaborative Research:The Speech Recognition Virtual Kitchen","awardID":"1205424","effectiveDate":"2012-06-01","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["543555"],"PO":["565215"]},"196912":{"abstract":"The Computer Science Department at the University of Texas at El Paso (UTEP), in collaboration with the departments of Biological Sciences, Mathematics, Electrical Engineering, and Psychology, offers an interdisciplinary REU summer program in applied intelligent systems. The program hosts eight students for a period of ten weeks during the summer. It emphasizes interdisciplinary research, where techniques developed in the area of artificial intelligence are applied to real-world problems in science and engineering. This will allow the students to gain a broader overview of science and engineering as a potential career than would be possible in more narrowly-defined research areas. <br\/><br\/>Each student will work on an individual interdisciplinary research project under the co-supervision of a faculty member from the computer science department and a faculty member from one of the collaborating departments. The unifying research theme will be the use of intelligent systems techniques, including machine learning, data mining, optimization, and image analysis, to solve relevant data analysis problems in science and engineering fields. Students will be able to choose from a large list of projects that includes automated analysis of astronomical images, seismic tomography using machine learning, and identifying foreign accents in speech, among many others.<br\/><br\/>To assist the development of each student's oral communication skills and broaden their views of science and engineering beyond their project, each student will informally present the progress of their research project to all other REU participants, including mentors, the REU Program Director, and to their fellow REU students at the REU weekly meeting. In addition to the weekly meetings, there is a seminar series with the main goals of improving students' research skills and increasing their understanding of potential career paths in computing-related fields. The program will conclude with a one-day symposium to highlight the achievements of the REU students.","title":"UTEP Summer Program in Applied Intelligent Systems","awardID":"1241434","effectiveDate":"2012-06-15","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":[528236],"PO":["563751"]},"196923":{"abstract":"This project is engaging partners from universities, industry and government agencies to develop and deploy applications and services for ultra-fast broadband and software defined networks. This nationwide collaboration will nurture U.S. leadership in next-generation networking. To this end, the project is creating a neutral forum for partners to discuss guidelines for implementing next-generation capabilities and interoperability, cataloguing next-generation applications, disseminating news and best practices, and selecting and publicizing compelling applications from competitions for an annual 'Best of the Best' showcase. This project expects to transform people's lives in five national sectors. First, by accelerating breakthroughs in advanced manufacturing technologies, this project provides a foundation for private sector investment and growth. Secondly, this project fosters the next-generation of safer, smarter, more efficient clean transportation technologies. Thirdly, by revolutionizing education and workforce learning tools, this project is helping to create a world-class workforce. By fostering applications that use information and communication technologies to predict disasters, this project can also keep Americans safe and cities better prepared. Finally, this project seeks technologies to shift healthcare paradigms to empower patients through information and medical knowledge to become an active part of their own care and to allow medical experts to use data and technology to prevent medical errors, improve the quality of care, and reduce costs.","title":"EAGER: US Ignite Launch","awardID":"1241484","effectiveDate":"2012-06-01","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["559625"],"PO":["557315"]},"196703":{"abstract":"Proposal #: CNS 12-40171<br\/>PI(s): Matsunaga, Andrea<br\/> Fortes, Jose A.<br\/>Institution: University of Florida<br\/>Title: Rapid: Enabling Continued Operation of IT Services & Infrastructures during Floods & Other Disasters<br\/>Project Proposed:<br\/>Thi RAPID project, studying the effectiveness of virtualized Internet data centers on improving IT service continuity during and after a disaster through virtual machines (VM) live migration and backup\/checkpointing, conducts research on the use of virtualization technologies. These technologies enable mitigating and recovering from the impact of catastrophic events on IT infrastructures and the services they deliver. Working with Thammasat University in Thailand, Internet Data Centers (IDCs) will be leveraged as disaster recovering sites, where government and corporate data can be backed up and operational servers can be temporarily located in order to provide high-availability and resiliency for the organizations? operations and services.<br\/>The recent catastrophic events in the 2011 Thailand flood raised a many issues in the disruption of operation and services provided by various organizations that can contribute in handling other future catastrophic events. Several research questions have arisen: The<br\/>- Need to assess existing infrastructures since suitable solutions have dependencies on the type of disasters and the realities of the IT environments in the disaster locations, and <br\/>- Need to address challenges when migrating VMs across geographic locations, given that existing VM migration technology have been developed with local area network assumptions that do not hold true in disaster recovery scenarios.<br\/>Thus, the work leverages existing infrastructure and experience in machine visualization technologies and cloud computing deployments to conduct realistic experiments, to assess the effectiveness of mechanisms offered by existing visualization technologies to maximize the availability of services and minimize costs to maintain and\/or recover all the services during and after disaster. Research efforts will be developed in the following thrusts:<br\/>- Collection and analysis of data related damaged IT services due to the 2011 Thailand Flood;<br\/>- Studies of the nature of the IT services and their infrastructure design;<br\/>- Studies of the practicality and scalability of VM live migration and backup\/checkpointing in wide-area setting; and<br\/>- Investigation of virtualized-based resilient middleware architectures for service continuity.<br\/>Broader Impacts: <br\/>This project will advance our understanding of how to provide robust middleware for protection and recovery of IT infrastructure that performs well for different types of disasters. It will also inform policy-makers and IT managers in Thailand and the USA on how to evaluate and integrate emerging commercial virtualization solutions for backup and\/or recovery-oriented computing systems under the extreme conditions found during and after a disaster. The research supports a female minority PI and a US graduate student. The project has been submitted for co-funding from the Thailand Research Fund (TRF), which, if successful, would represent a precedent-setting partnership between the NSF and TRF which could be a model for future collaboration.","title":"Enabling continued operation of IT services and infrastructures during floods and other disasters","awardID":"1240171","effectiveDate":"2012-06-15","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["540130",527629],"PO":["557609"]},"193447":{"abstract":"A key challenge in developing multi-threaded applications on modern architectures is correctly synchronizing data shared among the threads while avoiding excessive performance penalties. Unsafe low-level synchronization mechanisms can easily introduce errors (e.g. race conditions and deadlock) that are extremely difficult to debug. At the same time, application performance and scalability are frequently compromised due to inefficient implementations of synchronous operations on shared data. <br\/><br\/>This research develops a library of highly concurrent scalable data containers with associated programming interface and optimization support to significantly enhance the productivity and performance of multi-threaded C\/C++ applications on multicore architectures. The library provides an easy to use and composable interface similar to that of C++ Standard Template Library (STL) and enhances each container type with internal support for non-blocking synchronization of their data accesses, thereby providing better safety and performance than traditional blocking synchronization by eliminating hazards such as deadlock, livelock, and priority inversion, and by being highly scalable in supporting large numbers of threads. A higher level programming interface, similar to that of OpenMP, is supported by a preprocessing compiler associated with the runtime to ease the transition of existing sequential or multi-threaded C\/C++ applications to using the non-blocking synchronous template library and to provide optimization and tuning support for the use of the library abstractions. The developed deliverables are expected to demonstrate a seamless integration of developer input, compiler optimization, and multicore runtimes to support systematic migration of C\/C++ applications to continuously evolving architectures. <br\/><br\/>The scalable template library and the associated programming interface and tuning support is expected to provide an immense productivity and performance boost for developers of high-end scientific and systems applications, including branch and bound, graph analysis, complex scene rendering, and goal propagation in autonomous embedded systems. The developed programming techniques and tools can enable the transformation of such applications into software that is substantially more reliable, efficient, and scalable than existing state of the art. The software techniques is also expected to be employed as an educational toolkit in the teaching of programming languages, compilers, systems software, and parallel programming courses.","title":"SHF: Small: Collaborative Research: Programming Interface And Runtime For Self-Tuning Scalable C\/C++ Data Structures","awardID":"1218100","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}}],"PIcoPI":[518128],"PO":["565272"]},"193337":{"abstract":"Computers directly support arithmetic that is typically limited to 64 bits (about 19 decimal digits) of precision. Applications that need more precision must implement arithmetic through computationally expensive software. Beyond about 256 bits of precision, such calculations become quite costly. The RSA encryption algorithm, for example, can require arithmetic with up to 4096 bits of precision. Applications in areas such as experimental mathematics and number theory can require millions of bits of precision. One multiplication with 10 million bits of precision can take a tenth of a second to compute on a modern processor, which means that matrix arithmetic using such large values can take days to weeks to execute. In previous work the investigators have shown that it is possible to obtain a factor of 20 improvement in performance by utilizing the parallel processing capabilities of a commodity graphics processing unit (GPU) in place of the traditional CPU. However, programming a GPU to achieve this level of performance is quite difficult, and the resulting code requires considerable hand-tuning to move it to new generations of GPU and gain the advantage of their performance, which is scaling up at a rate that exceeds CPU performance scaling.<br\/><br\/>This project is working to develop a framework that automatically generates and tunes multi-precision arithmetic libraries to execute on successive generations of GPUs. The libraries include both scalar and basic matrix arithmetic routines. They support scaling in precision as well as matrix size. The problem is challenging because different parallel algorithms must be automatically selected for different levels of precision, which must be balanced with the exploitation of the alternate dimension of parallelism inherent in matrix arithmetic. In addition, the work seeks to employ distributed parallelism across a cluster of computers enhanced with GPUs, so that the libraries can be used on a new generation of GPU-based supercomputers that is beginning to be deployed at national laboratories. <br\/><br\/>The work is significant because it enables easier exploitation of low-cost commodity graphics processors to achieve more than an order of magnitude increase in performance for multi-precision scalar and matrix arithmetic. One important application is enhancing performance of RSA encryption to support longer, more secure keys, at greater data rates, so that it becomes feasible to encrypt greater volumes of internet traffic. Another important use is experimental mathematics, where computationally expensive functions (e.g., integrals, infinite series) are computed at high precision and compared to other functions and high precision constants to help identify more efficient closed-form solutions. Results from experimental mathematics have found applications in particle physics, chaos theory, and calculation of fundamental constants. The resulting software framework offers a significant performance enhancement for multi-precision arithmetic to systems that range from individual researcher workstations to large supercomputers.","title":"SHF:Small: Solving the Problem of Scalable Multi-Precision Matrix Arithmetic on GPUs","awardID":"1217590","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[517880],"PO":["565272"]},"186935":{"abstract":"High Performance Computing is strategically important to national competitiveness. Advances in computational capabilities involve the use of unprecedented levels of parallelism: programming methods that involve billions of concurrent activities. Multiple styles of concurrency involving shared and distributed memory programming (\"hybrid\") are necessary. Unfortunately, such programs are very difficult to debug using existing methods. This project develops formal (mathematically based) verification tools that can debug hybrid concurrent programs with very high certainty of bug elimination, while consuming only modest computational resources for verification. <br\/><br\/>The project develops execution-based tools that eliminate search over semantically equivalent alternative schedules as well as solver-based techniques that eliminate classes of bugs over single runs. Scalable methods based on non-determinism classification and heuristic execution-space reduction are also being developed. <br\/><br\/>Expected results include: (1) development of tools based on formal algorithmic techniques that verify large-scale hybrid programs; (2) amalgamation of incisive bug-hunting methods developed at other research organizations within formally based tools developed in our group; (3) incorporation of our verification tools and techniques within popular tool-integration frameworks; (4) large-scale case studies handled using our tools; and (5) training of undergraduate and graduate students on these advanced verification methods, building the talent pool vital to continued progress in high performance computing with applications to science and engineering, energy\/sustainability, and homeland security.","title":"SI2-SSE: Correctness Verification Tools for Extreme Scale Hybrid Concurrency","awardID":"1148127","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["542054","561775"],"PO":["558595"]},"190830":{"abstract":"The image processing domain is experiencing rapid increases in data size and algorithm complexity. These increases in data size and algorithm complexity demand large amounts of computing and storage power. However, modern computer architectures have evolved to be extraordinarily complex, and frequently become a challenge rather than a help for general researchers and educators who work in image processing technologies. <br\/><br\/>In order to fill the gap between complicated modern architectures and complex applications, and to support the research and education of image processing, the PIs are developing an integrated image processing research environment within a computing Cloud infrastructure. This infrastructure includes: 1) an open image processing computing Cloud to support researchers and students to conduct image processing research, share knowledge and research results, and stimulate education materials among three universities: Prairie View A&M University, University of Houston, and University of Delaware; 2) a high-level domain specific language designed to provide an abstract and productive programming model for image processing applications; 3) a general compiler optimization framework with the capability to tune into image processing applications at various levels starting from high-level representations to low level transformations in the Cloud environment.","title":"II-NEW: Collaborative Research: Image Processing Cloud (IPC): A Domain-Specific Cloud Computing Infrastructure for Research and Education","awardID":"1205528","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["525208"],"PO":["565255"]},"190764":{"abstract":"This planning project brings together the community to begin addressing the challenges of using text analysis (i.e., the analysis of the information extracted from the natural language used in software artifacts and program code) in software engineering. A set of workshops will be organized with researchers in the software engineering community interested in the use of text analysis, in order to elicit requirements for the design of the necessary infrastructure for the research community. The common infrastructure of foundational text analyses for the software domain will include software libraries, data, and educational materials.<br\/><br\/>Because the textual information embedded in software artifacts, program code and documentation encodes the software?s domain incepts and developers? knowledge about them, it is critical in supporting developers to effectively maintain today?s software and it is essential to the other stake- holders in the software engineering process, including managers, clients, and users. A study of recent literature shows that over 25 distinct software engineering tasks, ranging from requirements analysis to program comprehension, utilize textual analysis based tools. This project?s outcomes will have a broad impact, enabling researchers to: combine different types of text analysis techniques; transfer results of successful research to industry and facilitate entry for software engineering researchers in applying text analysis techniques; integrate new components for exploration of novel approaches to specific analyses; gain continual user evaluation of text analysis-based software engineering tools; and enable other researchers and practitioners to easily leverage text analysis to solve new software engineering problems. The long-term goal is to create such an infrastructure, which will allow text analysis to integrate seamlessly with current technology and environments used by software engineers. The increase in software size and complexity, as well as larger development teams, have made it significantly more challenging for humans to maintain software without tools to support them.","title":"CI-P: Collaborative Research: Advanced Text Analysis Infrastructure for Software Engineering","awardID":"1205310","effectiveDate":"2012-06-15","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[511418],"PO":["564588"]},"193602":{"abstract":"Computer programmers must create software that produces a correct answer while making effective use of the computer hardware. This challenge of combining correctness and efficient hardware use is particularly difficult in scientific research, which often requires novel computing hardware for complex calculations. Different software \"tuning\" techniques are needed for shared-memory multi-core computers, distributed systems such as clusters of workstations, and high-speed graphics processors. Thus, scientific research with a computational element often requires great programming effort, which must be done with care, as performance tuning can introduce errors into a working program. The traditional alternative to manual performance tuning is the use of an automatic optimizing compiler. Such systems have largely replaced human beings for many tuning steps for single-core microprocessors (such as instruction selection and register allocation). More recently, research compilers such as Pluto have shown significant success in organizing the sharing of work within multi-core processors. Programmers using these systems are spared the work of tuning, but lose the ability to explore approaches that were not foreseen or chosen by the designer of the compiler. The AlphaZ system puts the mathematical foundation of the Pluto compiler (the \"polyhedral framework\") under control of the programmer, allowing manual tuning without needless effort or error. Like Pluto, AlphaZ can tune software for single- or multi-core systems. Pluto and AlphaZ are each the subject of ongoing research to support distributed computing by automatically transforming programs to distribute work across a cluster of computers with the MPI library. However, neither research project allows the programmer to explore novel ways to organize the motion of data among the constituent computers of a cluster.<br\/>This RUI project is exploring extensions to the AlphaZ system to allow programmer-directed data transfer with MPI focusing both on the high-level design of these extensions and on anticipating implementation challenges. The envisioned extensions to AlphaZ will facilitate exploration, by both compiler writers and programmers, of strategies for moving data in a distributed computing environment. Furthermore, these extensions will validate a program tuning strategy that could be applied to other new architectures such as graphics processors.","title":"RUI: Distributed Programming with AlphaZ","awardID":"1218827","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[518493,518494],"PO":["565272"]},"196605":{"abstract":"This award supports participation of doctoral students for 12 Ph.D. students in the disciplines of computer science and library and information science in the Doctoral Consortium, June 10, 2012 and the 2012 ACM\/IEEE-CS Joint Conference on Digital Libraries (JCDL 2012), to be held at The George Washington University, June 11-14, 2012 (http:\/\/www.jcdl2012.info). Twelve selected students are in the early stages of their dissertation work and include several international students in order to provide breadth in exchanging ideas. The goal of the consortium is to help these students develop their dissertation proposals and research plans through feedback and guidance from prominent professors and experienced practitioners from the field of digital library research and development. The JCDL Doctoral Consortium provides a forum for Ph.D. students to interact with major figures in the digital library community. These leaders, who come from all over the world, exemplify a broad set of expertise, diversity of perspectives, and wealth of knowledge. The consortium provides students with an opportunity to have broad audience and interact intellectually with professionals who would otherwise be difficult to meet with and discuss their ideas. Participating students will be selected on the basis of a paper describing their research and broaden participation and those selected for the consortium will have approximately 40 minutes to present their research plans and receive feedback from the panel. After the consortium the students will revise their papers based on the consortium's feedback and then they will be published in the IEEE Technical Committee on Digital Libraries publication \"TCDL Bulletin\" (http:\/\/www.ieee-tcdl.org\/mediawiki\/TCDL\/index.php\/IEEE-TCDL). <br\/><br\/>The JCDL 2012 Doctoral Consortium will expose promising Ph.D. students to a larger community, extend their opportunities for intellectual engagement, and encourage scholarly discourse and networking among new entrants into the field. An intended outcome of the workshop is to help shape ongoing and future teaching, research, and development projects in the field of digital libraries by providing wider exposure for the students to innovative ideas which may generate new research questions in the future, and to foster a sense of community among these young researchers at a critical stage in their professional development. The organizers will also take special steps to solicit participation from institutions with underrepresented groups to extend the potential benefits and broaden the horizon of expertise in the field.","title":"Doctoral Consortium at 2012 ACM\/IEEE-CS Joint Conference on Digital Libraries (JCDL 2012)","awardID":"1239821","effectiveDate":"2012-06-15","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[527258],"PO":["563751"]},"193349":{"abstract":"Modern information systems in every area of science and engineering rely critically on some form of knowledge representation and inference. Established fields such as Artificial Intelligence and Software Engineering as well as emerging fields such as Semantic Web, Computational Biology, Software Agents, Social Computing, Bioinformatics, Discovery Informatics, Cyberlearning and many others both rely on and contribute to advances in knowledge representation. Formal representations of knowledge and the associated inference mechanisms provide the basis for encoding, sharing, analyzing, interpreting vast amounts of data from disparate sources as well as deciding and acting upon information in virtually every area of human endeavor. <br\/><br\/>This workshop aims to bring together scientists from all areas of knowledge-representation research and to discuss the new challenges and opportunities that this area faces in addressing the explosion of data and knowledge, increased reliance of scientists on computational data, its heterogeneity, and new modes of delivering, storing, and representing knowledge. This radical shift in the amount of data, in the way that scientists distribute, store, and aggregate this data, presents new challenges for knowledge representation (KR). KR researchers must consider the applicability of their methods for representation and reasoning on data and knowledge at unprecedented complexity, quantity, and heterogeneity. The distributed and open nature of the data-intensive science presents additional challenges and opportunities in KR, with regard to provenance, security, trustworthiness, and privacy. The increased adoption of Semantic Web technologies and the rapid increase in the amounts of structured knowledge that is becoming available on the Semantic Web presents additional challenges (e.g., need for coping with information with different degrees of reliability, information that holds in different contexts, information that changes over time, information that can be conflicting, information that represents beliefs and opinions, etc. The increased use of KR methods in Computer Vision, Robotics, Natural-Language Processing, Discovery Informatics, and others presents an opportunity for fruitful interdisciplinary collaborations that could dramatically alter the KR research landscape. As scientists, as well as laypersons get accustomed to social mechanisms for creating and sharing data and knowledge, it is incumbent upon the researchers in knowledge representation to develop KR mechanisms that support collaborative creation, sharing, and use of knowledge. Against this background, the workshop brings together a diverse group of researchers and practitioners in KR and related areas to identify new KR research challenges and opportunities presented by the recent developments in the world wide web, social networks and social media, collaborative and data-intensive e-science, among others.<br\/><br\/>Broader Impacts: The workshop will identify new areas of research for the Information and the Intelligent Systems at the intersection Knowledge Representation and Inference, Information Integration and Informatics. Given the increasingly central role of formal representations of knowledge and associated tools for inference in virtually every domain of human endeavor, the identification of KR the results of the workshop are likely to impact multiple disciplines. The workshop results, including a report summarizing new KR research challenges and opportunities, as well as publications by workshop participants will be broadly disseminated to the larger scientific community.","title":"Workshop on Research Challenges and Opportunities in Knowledge Representation and Reasoning","awardID":"1217638","effectiveDate":"2012-06-01","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[517909],"PO":["560586"]},"190854":{"abstract":"Together with theory and experimentation, computer simulation now constitutes the ?third pillar? of scientific inquiry, enabling researchers to build and test models of complex phenomena that cannot be replicated in the laboratory. The method of Molecular Dynamics simulation in particular is critical: applications range from the practical, e.g., drug design, to basic research in understanding disease processes. The overall goal is to give the Molecular Dynamics user community the compute capability to conduct transformative research via scalable, cost-effective, high-performance, general-purpose systems built from off-the-shelf components. The objective of this research is to bridge the many orders-of-magnitude gap between the largest current simulations and the potential physical systems to be studied.<br\/><br\/>Three fundamental issues limiting performance are (i) computational efficiency per chip area, (ii) power density, which is reaching the limit of economical cooling methods, and (iii) the bottleneck between processing and communication devices. All three are addressed by Large-Scale Reconfigurable Computing using Field Programmable Gate Arrays (FPGAs). FPGAs are commodity integrated circuits whose circuitry can be configured, or programmed, in the field. Their reconfigurable architecture gives them the ability to obtain maximum efficiency for a particular application while at the same time drawing less than a quarter the power of a conventional processing device. And because FPGAs are the core components in internet routers, they are built to handle flexible high-throughput communication. <br\/><br\/>This planning award is to investigate the novel system design to use the same FPGAs for communication and for computation. This approach has several advantages. First, it mitigates the critical bottleneck caused by the separation of functions among multiple devices. Second, FPGA-based communication gives the flexibility either to use standard protocols, or to use innovative application-aware routing that enables important patterns, such as the Fast Fourier Transform, to be routed congestion-free. Finally, FPGAs are well-suited for Molecular Dynamics computation allowing the hierarchical data-movement to be addressed through innovative routing, load-balancing, and arithmetic.","title":"CI-P: Collaborative Research: Large-Scale FPGA-Centric Computing with Molecular Dynamics","awardID":"1205593","effectiveDate":"2012-06-01","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[511644],"PO":["565272"]},"190887":{"abstract":"There is growing global importance of ocean exploration and monitoring as the oceans play a major role in climate regulation, nutrient production, resource retrieval and transportation, etc. Building and deploying a real-time underwater networked sensing infrastructure is thus needed for desired levels of monitoring and data collection. Despite a wave of research efforts in the area of underwater wireless networks, the lack of a community testbed has so far hampered further advances, as there is no common platform to evaluate and compare various communication and networking algorithms and protocols. Furthermore very few studies can afford to consider real system features due to the high cost of system deployment and maintenance.<br\/><br\/>This project involves the design and deployment of an open underwater testbed suite, accessible to the public at four sites in Connecticut, California, Texas, and Washington States. The testbed will include flexible choices of surface nodes, bottom nodes, and mobile nodes with reconfigurable modems. It will enable the vision of remote controlled and continuous networked node deployments running tests of communication, networking, sensing, and data streaming. In addition, the testbed will enable oceanographers to study scientific research questions, while using the testbed as a prototype for larger real-time monitoring deployments elsewhere. The testbed will also directly impact undergraduate research and student diversity by involving undergraduate students through REU programs, impacting curriculum development by enabling field courses, and engaging K-12 students and teachers, particularly in underserved communities.","title":"Collaborative Research: CI-ADDO-NEW: Ocean-TUNE: A Community Ocean Testbed for Underwater Wireless Networks","awardID":"1205725","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["529904","526295"],"PO":["557315"]},"193637":{"abstract":"As high-performance general-purpose processors advance further into the chip multiprocessor era, with ever increasing core counts, the industry faces two huge challenges. The first is how to effectively use that hardware parallelism when much of the available software does not parallelize easily. The second challenge is managing the power and energy consumed by these processors. Given constrained power, we can only scale performance if we improve the performance delivered per Watt. <br\/>Data-triggered threads (DTT) is a new programming and execution model designed to address both of these issues. Any conventional architecture that exploits parallelism does so by initiating new parallel computation based on control flow ? that is, execution (i.e., the core?s program counter) reaches a fork instruction or maybe a pthread create call. DTT instead spawns a new thread when data in memory is changed. The programmer specifies a function that is not attached to a set of call sites (a place in the program where the function is called), but rather is attached to a variable or even a field in a data structure type. When that variable is modified by the program, a thread in another core (or multithreading context) is automatically spawned to execute the data-triggered thread, containing code that depends on the changed data.<br\/>Data-triggered threads provide two key advantages over traditional mechanisms for describing parallelism. The first is that the dependent computation becomes available immediately, as soon as the source data is modified. The second is that the dependent computation need only be executed if the triggering data is actually modified ? in many cases it is not. This work exploits a huge new opportunity to eliminate redundant computation. In the C SPEC benchmarks, 78% of loads are redundant (meaning the same load fetches the same value as the last time it went to the same address). The computation which operates on those values is often also redundant. Researchers in computer architecture and related areas have been working to reduce the power consumed by each instruction, and have made steady progress. It is far preferable, though, to just not execute those instructions ? no power or energy optimization will beat that.<br\/>This research is exploring a number of opportunities to exploit this new execution model, including: (1) Data triggered threads via architectural support, (2) software-only data triggered threads, (3) data triggered threads to complement existing parallel applications, (4) automatic generation of data triggered threads in the compiler, and (5) programming experience with data triggered threads ? how does DTT code written from scratch differ from programs modified to use DTT, what kind of code will novice programmers produce, and how does that impact the architectural and software runtime implementations.<br\/>Generation-to-generation performance scaling of processors is critically important to the national and world economy ? not just to hardware vendors, but also the software industries that sell products every time someone upgrades their system. The data triggered threads programming and execution model represents solutions to the two key barriers to performance scaling. It addresses the parallelism crisis by giving the programmer a new way to express parallelism. It addresses the power problem in the most effective way possible ? by not executing computation that does not need to be done.","title":"SHF:Small: Data Triggered Threads for Removing Redundant Execution and Increasing Parallelism","awardID":"1219059","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["542069"],"PO":["565272"]},"190888":{"abstract":"There is growing global importance of ocean exploration and monitoring as the oceans play a major role in climate regulation, nutrient production, resource retrieval and transportation, etc. Building and deploying a real-time underwater networked sensing infrastructure is thus needed for desired levels of monitoring and data collection. Despite a wave of research efforts in the area of underwater wireless networks, the lack of a community testbed has so far hampered further advances, as there is no common platform to evaluate and compare various communication and networking algorithms and protocols. Furthermore very few studies can afford to consider real system features due to the high cost of system deployment and maintenance.<br\/><br\/>This project involves the design and deployment of an open underwater testbed suite, accessible to the public at four sites in Connecticut, California, Texas, and Washington States. The testbed will include flexible choices of surface nodes, bottom nodes, and mobile nodes with reconfigurable modems. It will enable the vision of remote controlled and continuous networked node deployments running tests of communication, networking, sensing, and data streaming. In addition, the testbed will enable oceanographers to study scientific research questions, while using the testbed as a prototype for larger real-time monitoring deployments elsewhere. The testbed will also directly impact undergraduate research and student diversity by involving undergraduate students through REU programs, impacting curriculum development by enabling field courses, and engaging K-12 students and teachers, particularly in underserved communities.","title":"Collaborative Research: CI-ADDO-NEW: Ocean-TUNE: A Community Ocean Testbed for Underwater Wireless Networks","awardID":"1205726","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["525859"],"PO":["557315"]},"190899":{"abstract":"There is growing global importance of ocean exploration and monitoring as the oceans play a major role in climate regulation, nutrient production, resource retrieval and transportation, etc. Building and deploying a real-time underwater networked sensing infrastructure is thus needed for desired levels of monitoring and data collection. Despite a wave of research efforts in the area of underwater wireless networks, the lack of a community testbed has so far hampered further advances, as there is no common platform to evaluate and compare various communication and networking algorithms and protocols. Furthermore very few studies can afford to consider real system features due to the high cost of system deployment and maintenance.<br\/><br\/>This project involves the design and deployment of an open underwater testbed suite, accessible to the public at four sites in Connecticut, California, Texas, and Washington States. The testbed will include flexible choices of surface nodes, bottom nodes, and mobile nodes with reconfigurable modems. It will enable the vision of remote controlled and continuous networked node deployments running tests of communication, networking, sensing, and data streaming. In addition, the testbed will enable oceanographers to study scientific research questions, while using the testbed as a prototype for larger real-time monitoring deployments elsewhere. The testbed will also directly impact undergraduate research and student diversity by involving undergraduate students through REU programs, impacting curriculum development by enabling field courses, and engaging K-12 students and teachers, particularly in underserved communities.","title":"Collaborative Research: CI-ADDO-NEW: Ocean-TUNE: A Community Ocean Testbed for Underwater Wireless Networks","awardID":"1205757","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["558959",511786],"PO":["557315"]},"186829":{"abstract":"This project further develops and maintains a set of system and application software to benefit application users of multicores by providing a unified software environment where multicore system utilities can be easily used as common functions in various applications. The project consists of the following three tasks. First, we further improve our cache-partitioning OS utility, and make efforts to add two other critical system utilities: (1) Multicore buffer cache management to prevent the shared cache from thrashing and pollution; (2) multicore-aware synchronization lock management to effectively make process assignments such that the co-running processes would minimize bandwidth consumption within a multicore chip and cross multiple multicore chips. Second, we continue our efforts to develop a software runtime library that enables programmers to explicitly manage and optimize the shared cache usage and memory accesses by allocating proper cache space and memory modules for different data sets of different processes. Finally, we provide a unified software environment for application users. With a set of easy interface functions, the users can access both middleware runtime library and the system utilities without a requirement of knowing architectural and system details. <br\/><br\/>The broader and transformative impact of the project can be significant: (1) Our software will provide effective and accessible solutions for significant performance improvement in multicores for a large scope of application community. (2) Gaining the insights into system interactions among applications, OS, and multicore architecture, we will provide valuable guidance for designs and implementations of application software. (3) The software is online with a maintenance for a public, wide, and sustained usage, which will directly impact open source software, and contribute to application users. (4) The research and software development of the project will train both undergraduate and graduate students for their future technical innovations in academia and industries.","title":"SI2-SSE: A Unified Software Environment to Best Utilize Cache and Memory Systems on Multicores","awardID":"1147522","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["551992"],"PO":["565247"]},"190834":{"abstract":"This Computing Research Infrastructure planning grant addresses two challenges for automatic systems performing deep semantic processing: identifying the context-appropriate sense of polysemous words and interpreting the meanings and interrelations of verbs and nouns in event-denoting phrases. Preliminary steps are taken for aligning and linking four existing widely used lexical resources (WordNet, FrameNet, PropBank and VerbNet) with different but complementary contents and coverage. Methods for completing current cross-resource links and full transitive closure are explored and tested. The resulting infrastructure (LexLink) is designed to make the resources fully interoperable, capitalizing on their particular strengths with respect to word sense disambiguation and Semantic Role labeling.<br\/><br\/>Four activities are carried out in the context of planning LexLink. First, a workshop is held where key representatives of the Natural Language Processing and computational semantics communities articulate needs and requirements for the planned resource and offer advice on algorithms, annotation techniques and evaluation. Second, a subsection of cross-resource links for word senses and Semantic Role labels (Agent, Instrument, etc.) resulting from the automatic transitive closure is evaluated, yielding estimates for the error rate and leading to fine-tuning of algorithms. Third, current best performing mapping algorithms for word senses and Semantic Role labels are evaluated against a human-annotated Gold Standard. Fourth, new Gold Standard data are created for additional training and testing and to refine existing algorithms. As a whole, the work provides a solid foundation for a resource with significant beneficial impact on a range of natural language applications, including machine translation, text summarization and sentiment analysis affecting areas such as health care, marketing, and education.","title":"CI-P: Collaborative Research: LexLink: Aligning WordNet, FrameNet, PropBank and VerbNet","awardID":"1205540","effectiveDate":"2012-06-01","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["561714"],"PO":["565215"]},"190878":{"abstract":"The PI's efforts to conduct original and practical research in socially intelligent computing - an emerging and important paradigm centered on integrating people and computers to create new forms of collaboration, communication, and intelligence previously unachievable by humans or computers alone - have been hindered, in scope, scale and quality, by the lack of a dedicated and realistic infrastructure. This proposal requests funds to set up such an infrastructure at the PI's institution, which will support integrated research and education. The infrastructure requested includes high-end computational and storage servers, desktop machines, laptops, smart phones, sensors, cameras, software and accessories for collecting, processing and extracting knowledge from large scale data arising from the daily interactions of society with the Internet and with mobile phones. The overall goal is to utilize the knowledge gained from social computing data to create a spectrum of practical services and applications benefitting society. In particular, three research projects that emphasize the close integrations of society with technology are identified in the proposal: a) Detection of depressive disorders in college settings by mining Internet usage data; b) Human \"fingerprinting\" by mining Internet and smart phone usage; and c) Tracking humans in the social world by fusing heterogeneous sensor data.<br\/><br\/>Intellectual Merit<br\/>The planned research activities are well described and will likely significantly advance the state of the art in socially intelligent computing. The PI has pioneered the mining of real Internet data to detect depressive behavior in college students. His prior research has identified critical Internet usage features that show strong statistical differences between students with and without depressive symptoms. He next plans to design, using computational intelligence techniques, classifiers which can proactively detect depressive behavior in college students with high accuracy while being transparent and preserving privacy. He is also exploring the feasibility of mining Internet usage patterns to fingerprint humans, with applications to Internet forensics and mitigation of insider attacks. Similar techniques will be applied to mine sensor data from smart phones in order to fingerprint mobility patterns and to lay the foundation for a variety of pervasive services. While conventional tracking algorithms leverage either a network of cameras or physical sensory data or electronic signals, the PI plans to pursue an integrated approach that fuses multiple orthogonal data source and which incorporates novel feature extraction and pattern recognition techniques for human tracking in both outdoor and indoor environments.<br\/><br\/>Broader Impact<br\/>This project has applications in diverse areas including mental health screening, insider attack and fraud prevention, phone and vehicle theft detection, participatory sensing etc. Research outcomes will be shared periodically with diverse stakeholders in psychology, law enforcement, forensics, business, etc. The courses taught by the PI and his team in networking, security and computer vision will be enhanced with content deriving from this project, and the infrastructure will help students learn by practical experience. Research findings, learning materials and team experiences will be disseminated periodically to a wide audience (including educators and students in HBCUs and K-12) via conferences and the Web.","title":"II-New: Infrastructure to Support Integrated Research and Education in Socially Intelligent Computing at Missouri S&T","awardID":"1205695","effectiveDate":"2012-06-01","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[511729,"560279"],"PO":["565227"]},"190768":{"abstract":"This planning project brings together the community to begin addressing the challenges of using text analysis (i.e., the analysis of the information extracted from the natural language used in software artifacts and program code) in software engineering. A set of workshops will be organized with researchers in the software engineering community interested in the use of text analysis, in order to elicit requirements for the design of the necessary infrastructure for the research community. The common infrastructure of foundational text analyses for the software domain will include software libraries, data, and educational materials.<br\/><br\/>Because the textual information embedded in software artifacts, program code and documentation encodes the software?s domain incepts and developers? knowledge about them, it is critical in supporting developers to effectively maintain today?s software and it is essential to the other stake- holders in the software engineering process, including managers, clients, and users. A study of recent literature shows that over 25 distinct software engineering tasks, ranging from requirements analysis to program comprehension, utilize textual analysis based tools. This project?s outcomes will have a broad impact, enabling researchers to: combine different types of text analysis techniques; transfer results of successful research to industry and facilitate entry for software engineering researchers in applying text analysis techniques; integrate new components for exploration of novel approaches to specific analyses; gain continual user evaluation of text analysis-based software engineering tools; and enable other researchers and practitioners to easily leverage text analysis to solve new software engineering problems. The long-term goal is to create such an infrastructure, which will allow text analysis to integrate seamlessly with current technology and environments used by software engineers. The increase in software size and complexity, as well as larger development teams, have made it significantly more challenging for humans to maintain software without tools to support them.","title":"CI-P: Collaborative Research: Advanced Text Analysis Infrastructure for Software Engineering","awardID":"1205321","effectiveDate":"2012-06-15","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["537390"],"PO":["564588"]},"190879":{"abstract":"II-NEW: COLLABORATIVE: Image Processing Cloud (IPC): A Domain-Specific Cloud Computing Infrastructure for Research and Education<br\/><br\/>The image processing domain is experiencing rapid increases in data size and algorithm complexity. These increases in data size and algorithm complexity demand large amounts of computing and storage power. However, modern computer architectures have evolved to be extraordinarily complex, and frequently become a challenge rather than a help for general researchers and educators who work in image processing technologies. <br\/><br\/>In order to fill the gap between complicated modern architectures and complex applications, and to support the research and education of image processing, the PIs are developing an integrated image processing research environment within a computing Cloud infrastructure. This infrastructure includes: 1) an open image processing computing Cloud to support researchers and students to conduct image processing research, share knowledge and research results, and stimulate education materials among three universities: Prairie View A&M University, University of Houston, and University of Delaware; 2) a high-level domain specific language designed to provide an abstract and productive programming model for image processing applications; 3) a general compiler optimization framework with the capability to tune into image processing applications at various levels starting from high-level representations to low level transformations in the Cloud environment.","title":"II-NEW: Collaborative Research: Image Processing Cloud (IPC): A Domain-Specific Cloud Computing Infrastructure for Research and Education","awardID":"1205699","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["554930"],"PO":["565255"]},"190814":{"abstract":"This Computing Research Infrastructure planning grant addresses two challenges for automatic systems performing deep semantic processing: identifying the context-appropriate sense of polysemous words and interpreting the meanings and interrelations of verbs and nouns in event-denoting phrases. Preliminary steps are taken for aligning and linking four existing widely used lexical resources (WordNet, FrameNet, PropBank and VerbNet) with different but complementary contents and coverage. Methods for completing current cross-resource links and full transitive closure are explored and tested. The resulting infrastructure (LexLink) is designed to make the resources fully interoperable, capitalizing on their particular strengths with respect to word sense disambiguation and Semantic Role labeling.<br\/><br\/>Four activities are carried out in the context of planning LexLink. First, a workshop is held where key representatives of the Natural Language Processing and computational semantics communities articulate needs and requirements for the planned resource and offer advice on algorithms, annotation techniques and evaluation. Second, a subsection of cross-resource links for word senses and Semantic Role labels (Agent, Instrument, etc.) resulting from the automatic transitive closure is evaluated, yielding estimates for the error rate and leading to fine-tuning of algorithms. Third, current best performing mapping algorithms for word senses and Semantic Role labels are evaluated against a human-annotated Gold Standard. Fourth, new Gold Standard data are created for additional training and testing and to refine existing algorithms. As a whole, the work provides a solid foundation for a resource with significant beneficial impact on a range of natural language applications, including machine translation, text summarization and sentiment analysis affecting areas such as health care, marketing, and education.","title":"CI-P: Collaborative Research: LexLink: Aligning WordNet, FrameNet, PropBank and VerbNet","awardID":"1205473","effectiveDate":"2012-06-01","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[511536],"PO":["565215"]},"190869":{"abstract":"The mass deployment of smartphones is changing the world around us. Growing numbers of users carry a powerful computing, communication and sensing platform in their pocket, and the growing worldwide network of smartphones already constitutes the most powerful and pervasive distributed system ever built. Today there are two primary methods for performing smartphone experimentation: distributing experiments through an application marketplace, or assembling a group of participants for a single study. Unfortunately, both of these approaches fail to provide the power, scale, realism and density necessary to enable next-generation mobile computing research.<br\/><br\/>PhoneLab is a public testbed enabling smartphone research at a scale not previously possible. PhoneLab provides programmatic access to a large group of participants at SUNY Buffalo. Participants use their PhoneLab smartphone as their primary device, generating high geographic density and representative usage patterns. PhoneLab allows researchers to distribute applications or modify the core smartphone platform, facilitating a broad range of experiments. By providing repeated access to the same participants, results can be validated, competing approaches can be compared, and new experiments can utilize existing data. PhoneLab's capabilities will accelerate smartphone research and lead to advances in wireless networking, distributed and mobile systems, mobile sensing, social networking, and crowdsourcing. PhoneLab will also play a vital role in teaching and learning, enabling both new assignments at the college level and secondary school science projects. By exposing students to the transformative power of smartphones, PhoneLab will excite the next generation of computer scientists.","title":"CI-ADDO-NEW: PhoneLab: A Programmable Participatory Smartphone Testbed","awardID":"1205656","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[511691,511692,"562939",511694,"558513"],"PO":["557315"]},"190848":{"abstract":"Together with theory and experimentation, computer simulation now constitutes the ?third pillar? of scientific inquiry, enabling researchers to build and test models of complex phenomena that cannot be replicated in the laboratory. The method of Molecular Dynamics simulation in particular is critical: applications range from the practical, e.g., drug design, to basic research in understanding disease processes. The overall goal is to give the Molecular Dynamics user community the compute capability to conduct transformative research via scalable, cost-effective, high-performance, general-purpose systems built from off-the-shelf components. The objective of this research is to bridge the many orders-of-magnitude gap between the largest current simulations and the potential physical systems to be studied.<br\/><br\/>Three fundamental issues limiting performance are (i) computational efficiency per chip area, (ii) power density, which is reaching the limit of economical cooling methods, and (iii) the bottleneck between processing and communication devices. All three are addressed by Large-Scale Reconfigurable Computing using Field Programmable Gate Arrays (FPGAs). FPGAs are commodity integrated circuits whose circuitry can be configured, or programmed, in the field. Their reconfigurable architecture gives them the ability to obtain maximum efficiency for a particular application while at the same time drawing less than a quarter the power of a conventional processing device. And because FPGAs are the core components in internet routers, they are built to handle flexible high-throughput communication. <br\/><br\/>This planning award is to investigate the novel system design to use the same FPGAs for communication and for computation. This approach has several advantages. First, it mitigates the critical bottleneck caused by the separation of functions among multiple devices. Second, FPGA-based communication gives the flexibility either to use standard protocols, or to use innovative application-aware routing that enables important patterns, such as the Fast Fourier Transform, to be routed congestion-free. Finally, FPGAs are well-suited for Molecular Dynamics computation allowing the hierarchical data-movement to be addressed through innovative routing, load-balancing, and arithmetic.","title":"CI-P: Collaborative Research: Large-Scale FPGA-Centric Computing with Molecular Dynamics","awardID":"1205573","effectiveDate":"2012-06-01","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["523143","523144"],"PO":["565272"]},"190827":{"abstract":"This award is to design, code, document, test, dissememinate, and maintain Stan,an extensible<br\/>open-source software framework and compiler for efficient and scalable Bayesian statistical modeling.<br\/>Stan is an extensible, open-source, cross-platform software framework for developing Bayesian statistical<br\/>models. The first step in Bayesian modeling is setting up a full probability model for all quantities of<br\/>interest. Stan facilitates this process by providing an expressive and extensible domain-specific<br\/>programming language for specifying probabilistic models. By compiling a model specification into<br\/>executable code, Stan fully automates the second step of Bayesian inference, calculating the probabilities<br\/>of unobserved quantities, such as model parameters and future observations, conditional on observed data.<br\/>The third step involves evaluating the fit of the model to the data and its predictions for unseen data.<br\/>When the model is easy to encode and inferences are fast and automatic to compute, it is easy to iterate<br\/>the specification, fit and evaluation steps in order to refine the scientific model.<br\/>Stan improves on the existing state of the art in both algorithmic and implementation details. Rather than<br\/>being interpreted on the fly like its predecessors, Stan models are compiled to C++ code, which<br\/>dramatically improves both scalability and efficiency. Stan provides a full algorithmic differentiation library for the functions required for statistical modeling. This method applies the chain rule from calculus to the program computing the probability function in order to calculate derivatives efficiently and accurately (a small multiple of the time taken to compute the<br\/>function, independently of dimensionality). This allows Stan to fully automate the model fitting stage<br\/>given only a specification of the probability function in Stan's modeling language.<br\/>To maximize Stan's accessibility to the scientific community, it is being coded using standards-compliant<br\/>C++, so that it will run under Windows, Macintosh, and Unix\/Linux. To make running Stan even easier,<br\/>it is callable from R, MATLAB, and Python, the three most popular platforms for numerical analysis,<br\/>including exploration and plotting.","title":"CI-ADDO-NEW: Stan, Scalable Software for Bayesian Modeling","awardID":"1205516","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"1269","name":"STATISTICS"}}],"PIcoPI":[511572,511573],"PO":["565272"]},"190817":{"abstract":"This Computing Research Infrastructure planning grant addresses two challenges for automatic systems performing deep semantic processing: identifying the context-appropriate sense of polysemous words and interpreting the meanings and interrelations of verbs and nouns in event-denoting phrases. Preliminary steps are taken for aligning and linking four existing widely used lexical resources (WordNet, FrameNet, PropBank and VerbNet) with different but complementary contents and coverage. Methods for completing current cross-resource links and full transitive closure are explored and tested. The resulting infrastructure (LexLink) is designed to make the resources fully interoperable, capitalizing on their particular strengths with respect to word sense disambiguation and Semantic Role labeling.<br\/><br\/>Four activities are carried out in the context of planning LexLink. First, a workshop is held where key representatives of the Natural Language Processing and computational semantics communities articulate needs and requirements for the planned resource and offer advice on algorithms, annotation techniques and evaluation. Second, a subsection of cross-resource links for word senses and Semantic Role labels (Agent, Instrument, etc.) resulting from the automatic transitive closure is evaluated, yielding estimates for the error rate and leading to fine-tuning of algorithms. Third, current best performing mapping algorithms for word senses and Semantic Role labels are evaluated against a human-annotated Gold Standard. Fourth, new Gold Standard data are created for additional training and testing and to refine existing algorithms. As a whole, the work provides a solid foundation for a resource with significant beneficial impact on a range of natural language applications, including machine translation, text summarization and sentiment analysis affecting areas such as health care, marketing, and education.","title":"CI-P: Collaborative Research: LexLink: Aligning WordNet, FrameNet, PropBank and VerbNet","awardID":"1205484","effectiveDate":"2012-06-01","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[511542],"PO":["565215"]},"190828":{"abstract":"The field of supercomputing is experiencing a rapid change in system structure, programming models, and software environments in response to advances in application requirements and in underlying enabling technologies. Traditional parallel programming approaches have relied on static resource allocation and task scheduling through programming interfaces such as MPI and OpenMP. These methods are reaching their efficiency and scalability limits on the new emerging classes of systems, spurring the creation of innovative dynamic strategies and software tools, including advanced runtime system software and programming interfaces that use them. To accelerate adoption of these next-generation methods, a unique environment is being created and operated that provides a comprehensive ensemble of state-of-the-art runtime system software and programming interfaces. Taken from previous research and development projects, some at the host institution, Indiana University, and others from premiere research organizations across the nation, these execution systems are integrated in a single supported Reconfigurable Execution Framework Testbed (REFT) and made available to parallel application algorithm developers as well as researchers in advanced tools for parallel computing. The basic REFT hardware capabilities include a medium- scale heterogeneous Linux cluster with multi-core sockets, high-bandwidth interconnect, and mass storage; field-programmable gate arrays; and instrumentation for power measurement. ParalleX-based HPX-3, ETI SWARM, Berkeley GasNet, Rice University?s Habanero, Illinois? Charm++, Cray Chapel, IBM X-10, and UPC among other programming and execution models comprise the major components of this unique facility.<br\/><br\/>Supercomputing is making a sharp corner turn in form, function, and methodologies. Unfortunately, few in the field are skilled in the use of the emerging execution and programming models that are becoming increasingly critical to effectively utilizing supercomputers to deliver quality science for extreme-scale applications?either those at the highest end of the performance spectrum (Petaflops currently and Exaflops at the end of the decade) or strong-scaled fixed-size problems. REFT serves the NSF computational science community by dramatically lowering the barrier to training, experimentation, and adoption of new dynamic execution methods and systems. It provides full documentation, on-line tutorials, in-house classes, and workshops for skill development and community building for the broad US HPC community to accelerate application, evaluation, and exploitation. As a repository for competing and complementary software environments it provides a single site for conducting comparative studies by end-users to establish best practices. As an NSF resource, it serves to expedite and further goals of computational science by enabling effective application of the next generation Petaflops-class computer systems of millions of cores and eventual Exascale systems with billion-way concurrency.","title":"CI-P: REFT - A Reconfigurable Execution Framework Testbed for data-driven and extreme scale computing","awardID":"1205518","effectiveDate":"2012-06-01","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[511575,"562709","563330","563331","529143"],"PO":["565272"]},"190829":{"abstract":"GridIron is a computing grid resource for the Dartmouth computer science department, enabling cutting-edge research and training in a wide range of projects involving analysis of large quantities of data and search over large, complex spaces. In computational structural biology, researchers are developing and applying methods to search protein conformation spaces, to systematically decompose the protein structure universe, and to model and design protein-protein interactions for specificity. In computer vision, researchers are developing and applying methods to authenticate digital images and to perform large-scale image search. Other significant areas of investigation include large-scale smartphone sensing, latency mitigation, and malware detection. The grid is also an asset for Digital Arts projects and research, including information visualization for large data sets and real-time rendering for motion capture. Finally, the grid supports a number of education and outreach activities, including non-major, undergraduate, and graduate courses and a summer camp for high school students. It provides invaluable practical experience in the use of large-scale computation in solving difficult challenges in the analysis of massive data sets.","title":"II-EN: GridIron","awardID":"1205521","effectiveDate":"2012-06-01","expirationDate":"2017-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[511581,"529645",511583,511584],"PO":["563727"]},"189480":{"abstract":"Optimization is a powerful paradigm for expressing and solving a variety of imaging problems. Modern optimization methods have had considerable success on problems that involve interactions between pairs of pixels. This has lead to important advances, but many imaging problems clearly require explicit modeling of higher-order interactions. This project is addressing this challenge through a close collaboration between researchers with expertise in graph algorithms and computer vision. The project is focused on two core applications: MRI image reconstruction and boundary detection in natural images. Besides their innate interest, these applications are closely related to other important imaging problems such as fMRI distortion correction, super-resolution, angiography and road detection. <br\/><br\/>Optimization problems with high-order interactions are inherently difficult from a computational point of view. The computational complexity can be reduced for problems with specific properties. By identifying common properties in many important imaging problems it is possible to design powerful optimization methods that are broadly applicable. The project is bringing together researchers in computer vision and algorithms. The collaboration is leading to new algorithms that are of broad interest to the computer vision and imaging communities. These algorithms have the potential to transform the way that several important classes of problems are solved. All of the algorithms being developed are being carefully evaluated, with their implementations made widely available on a web repository. Dissemination of the ideas is facilitated by workshops and mini-courses being organized at Brown, Cornell and Rutgers.","title":"RI: Medium: Collaborative Research: Graph Cut Algorithms for Domain-specific Higher Order Priors","awardID":"1161476","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[508076],"PO":["564316"]},"187181":{"abstract":"Anonymity in networked systems refers to protecting the identities of communicating parties and paths of data flow. Exposing such information not only is a violation of user privacy, but also empowers a malicious adversary to launch powerful attacks. While a great deal of attention has been paid to information security and methods of protecting network activity using contents of communication, far less is known about vulnerabilities and risks of a network to adversarial timing analysis and its implications on privacy and social interactions. In this research, a rigorous theoretical foundation is developed for delivering any desired level of anonymity to networked systems with provable guarantees on network quality of service.<br\/><br\/>This research is built on an information theoretic framework to measure anonymity which yields the first quantitative model for anonymity that takes into account the complete information available to an adversary and the resource and topological constraints of a network. While conventional approaches circumvent the interdependence between network and adversary by modeling the adversary as omniscient, the investigators model anonymous networking as games between network nodes and the adversary and study Nash equilibrium behavior of the players, behavior from which none has the incentive to deviate. Using the mathematical framework, the fundamental trade-offs between anonymity and network performance is characterized. Consequently, insights are derived into likely behavior of network adversaries.<br\/><br\/>In a broader context, this rigorous analytical foundation will have significant impact in delivering provable privacy to a range of networked systems including computer networks, healthcare, transportation and smart energy distribution systems. In addition, the programs for middle and high school students and distance learning opportunities broaden the awareness of privacy vulnerabilities of networks in society.","title":"CAREER: CIF: Anonymous Networking with Guaranteed Quality of Service: Towards a Theoretical Foundation","awardID":"1149495","effectiveDate":"2012-06-01","expirationDate":"2017-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[502115],"PO":["564924"]},"197050":{"abstract":"This travel grant supports senior PhD students who are nearing graduation to take part in a doctoral consortium at the 2012 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). The doctoral consortium highlights the work of these up and coming researchers, and pairs each student with a senior member of the computer vision community who serves as their mentor. The mentorship process provides each student with valuable feedback on their research, as well as meaningful career advice as the students move on to the next phase of their professional development. The doctoral consortium event aims to have representation from a diverse group of participants (in terms of gender, ethnic background, academic institution and geographic location). The travel grant ensures participation from a broad range of institutions across the country and gives visibility to a diverse population of students.","title":"CVPR 2012 Conference Doctoral Consortium","awardID":"1242042","effectiveDate":"2012-06-15","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[528661],"PO":["564316"]},"187084":{"abstract":"Consider a function whose arguments are distributed among several parties, making it impossible for any one party to compute it in isolation. Communication complexity theory studies how many bits of communication are needed to evaluate the function. Pioneered by Andrew Yao over thirty years ago, communication complexity has become a central research area in theoretical computer science. First of all, studying communication as a limited resource has a strong practical motivation. Moreover, open problems in many other computational models reduce to questions about communication. To date, communication complexity theory has impacted almost every subject in theoretical computer science, from classical models such as Turing machines and circuits to more recent topics such as data structures, learning theory, and quantum computing.<br\/><br\/>This award takes aim at studying three longstanding open questions in communication complexity theory: (i) the limits of multiparty communication; (ii) the limits of communication with alternating existential and universal quantifiers; (iii) the conjectured equivalence of the combinatorial and matrix-theoretic views of communication. A resolution of these questions would have major consequences in theoretical computer science beyond communication, including lower bounds for ACC circuits and neural networks, efficient learning of DNF formulas, and an equivalence of quantum and classical communication. <br\/><br\/>Progress on the proposed problems will exploit insights from, and contribute new ideas to, other disciplines such as machine learning and matrix theory. This award provides an ample source of research problems at various levels of difficulty and will be used in advising students and teaching new graduate and undergraduate courses. As an integral part of the award, the PI will promote theory research in the Los Angeles area and take an active part in scientific dissemination.","title":"CAREER: Limits of Communication","awardID":"1149018","effectiveDate":"2012-06-01","expirationDate":"2017-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[501915],"PO":["565157"]},"189483":{"abstract":"The objective of the proposed research is to develop the foundations for resource allocation in femtocell networks, and evaluate the performance of the solutions using real testbeds. Wireless resource allocation in femtocell-based networks is particularly challenging due to four main reasons: (1) interference between femtocells and between femto- and macro-cells; (2) variable and unpredictable delays in signaling and data communication between each femtocell and the operator's network; (3) limited bandwidth for signaling over a wireless channel to a large number of femtocells; and, (4) involvement of three parties with differing priorities: the operator, the users, and the femtocell owners. The specific research tasks in this project are: (1) For legacy systems, develop distributed solutions for both downlink and uplink scheduling and handover under co-deployment of macro- and femto-cells that do not require any changes to existing hardware and standards; (2) Develop distributed, adaptive and self-organizing solutions (unconstrained by legacy requirements) for resource allocation by using a powerful tool from statistical physics, called Glauber dynamics; and (3) Design mechanisms to facilitate offline truthful auctions in practical settings involving the end-users, the femtocell owners, and the operator. The solutions will be implemented and evaluated on two testbeds under development at University of Michigan and at Ohio State University. The proposed research has the potential to significantly impact the cellular industry and end-users. Given the high penetration rates of cell-phones worldwide, this research has an immediate and widespread impact.","title":"NeTS: Medium: Collaborative Research: Enabling Cellular Services over Unplanned Femto-Cell Deployments: From Theory to Implementation","awardID":"1161490","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["542039"],"PO":["565303"]},"187074":{"abstract":"The digital age with its widespread availability of cheap computing power has transformed the way we search for information, distribute content and even navigate cities. Computation has also transformed the way we design shapes. Whereas in the past engineers and artists often sculpted objects from clay, today most shapes are designed virtually with computers. Computer-aided design of curves, surfaces and volumetric functions has applications in diverse fields such as industrial design, the entertainment industry and even architectural design. However, in all of these applications the designer is limited by the capabilities of the representations employed. The quality and geometric properties of parametric surface representations such as NURBS and subdivision surfaces are strongly dependent on their parameterization. Yet this is a degree of freedom that few designers use or understand. Furthermore, the connection between parameterization and the geometric properties of these shapes is not well understood. We currently have only rudimentary tools for controlling the parameterization of higher dimensional shapes such as surfaces or volumes. The inability to control this parameterization leads to poor quality shapes and more effort on the part of designers to alleviate these artifacts. In this project, the PI will explore new representations of surfaces and volumes that allow for more geometric freedom in creating the underlying shapes. He will investigate the fundamental connection between parameterization and surface shape\/quality for parametric curves, surfaces and volumes. He will expand upon the concept of non-uniform parameterization of surfaces to show that knot spacing (edge lengths) is not sufficient to completely control the parameterization of surfaces or volumes. And he will design new representations that allow the user to control or automatically adapt the parameterization of these shapes during the design process, and incorporate methods of non-uniform parameterization that are currently not possible. As part of this process, he will develop new higher order barycentric coordinates specifically adapted to this problem. Finally, he will investigate the effect and manipulation of parameterization for the purposes of tessellation and rendering of these parametric surfaces, and develop high quality GPU tessellation algorithms.<br\/><br\/>Broader Impacts: Project outcomes will significantly advance the state of the art not only in computer graphics and geometric modeling, but also in other areas of applied mathematics and computer science where the representation and precise control of smooth freeform shapes play a key role. Approximation theory, architectural design, the entertainment industry and industrial manufacturing will all benefit from the results of this research.","title":"CAREER: Parameterization and Tessellation for Computer Graphics","awardID":"1148976","effectiveDate":"2012-06-01","expirationDate":"2017-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[501894],"PO":["565227"]},"193070":{"abstract":"This proposal requests travel funds from NSF to assist 50 US students to participate in ICRA 2012, which will be held in St. Paul, MN, May 14-18, 2012. The purpose of this Group Travel Grant Proposal is to make it possible for US students and postdocs to attend the conference, present their work, and forge connections with colleagues from around the world. <br\/><br\/>This year marks the 50th anniversary of robotics. In addition to the regular conference, ICRA 2012 will feature interactive presentations, robot demonstrations, thematic plenary sessions on design, bio-robotics, and intelligent transportation, and special-topic symposia celebrating the conference theme of \"Innovation for Tomorrow's Needs.\" As part of this award, students will also have the opportunity to participate in special events and learn more about the field of robotics. Travel funding will be in the form of partial airfare reimbursement and full reimbursement for student registration to approximately 50 U.S. students who plan to present at least one paper at the Conference.<br\/><br\/>Broader Impacts: Most major international robotics conferences were outside of North America this past year, so demand should be very high from American students and professors to attend this major robotics event. The benefit to student learning and mentorship by encouraging attendance of students by direct monetary means brings large dividends in student confidence, knowledge and expertise.","title":"Student Travel Support for 2012 IEEE International Conference on Robotics and Automation","awardID":"1216519","effectiveDate":"2012-06-01","expirationDate":"2013-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["539704"],"PO":["543539"]},"189550":{"abstract":"Optimization is a powerful paradigm for expressing and solving a variety of imaging problems. Modern optimization methods have had considerable success on problems that involve interactions between pairs of pixels. This has lead to important advances, but many imaging problems clearly require explicit modeling of higher-order interactions. This project is addressing this challenge through a close collaboration between researchers with expertise in graph algorithms and computer vision. The project is focused on two core applications: MRI image reconstruction and boundary detection in natural images. Besides their innate interest, these applications are closely related to other important imaging problems such as fMRI distortion correction, super-resolution, angiography and road detection.<br\/><br\/>Optimization problems with high-order interactions are inherently difficult from a computational point of view. The computational complexity can be reduced for problems with specific properties. By identifying common properties in many important imaging problems it is possible to design powerful optimization methods that are broadly applicable. The project is bringing together researchers in computer vision and algorithms. The collaboration is leading to new algorithms that are of broad interest to the computer vision and imaging communities. These algorithms have the potential to transform the way that several important classes of problems are solved. All of the algorithms being developed are being carefully evaluated, with their implementations made widely available on a web repository. Dissemination of the ideas is facilitated by workshops and mini-courses being organized at Brown, Cornell and Rutgers.","title":"RI: Medium: Collaborative Research: Graph Cut Algorithms for Domain-specific Higher Order Priors","awardID":"1161860","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[508240],"PO":["564316"]},"189440":{"abstract":"Computers with many tens to hundreds of ?cores? are on their way, but programming languages and tools<br\/>that exploit them well have lagged. At the same time, there are emerging programming languages intended<br\/>for writing programs to run on these computers. These languages, such as X10 and Fortress, add support for<br\/>new concepts that make it easier to write many-core programs, but there does not yet exist good compiler and<br\/>run-time support for these languages. Systems that run Java, namely Java virtual machines such as those that<br\/>run on virtually every laptop, desktop, and server today, supply much of what the new languages need, but<br\/>fall short in some important ways. In particular they do not provide for saying in which part of memory to<br\/>place particular objects, on which core to run which computations, easy ways to get all cores busy working<br\/>on different parts of a big piece of data, or for synchronizing and getting right all the data manipulations<br\/>happening at the same time. This project is extending an existing research Java virtual machine (Jikes<br\/>RVM) with support for many ways of doing the things that the new languages need in order to run well<br\/>on many-core computers. The primary goal is to devise extensions to standard Java virtual machines for<br\/>this new world, and to make it possible for many others to experiment with different ways of implementing<br\/>these extensions, thus leveraging the creativity of the whole community of language and virtual machine<br\/>researchers. Secondary goals include offering reasonably good initial implementations of virtual machine<br\/>extensions as a starting point for future research and development, and proposing specific extensions to the<br\/>Java virtual machine specification standard.","title":"CSR: Medium: Collaborative Research: Portable Performance for Parallel Managed Languages Across the Many-Core Spectrum","awardID":"1161237","effectiveDate":"2012-06-01","expirationDate":"2015-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["562118"],"PO":["565255"]},"187296":{"abstract":"Algorithms used in computational mathematics are increasingly<br\/>sophisticated and complex; and the modern civilization critically<br\/>dependents on scientific software at all levels from design to<br\/>equipment control. Yet, the programming languages and tools used to<br\/>express algorithms as computer programs do not progress at a matching<br\/>pace, leaving an expanding gap between provably correct published<br\/>algorithms and their realizations in code. Failures in software<br\/>systems can cost human lives and are responsible for billions of<br\/>dollars lost annually. Furthermore, silent failures of simulation<br\/>software can seriously undermine the credibility of a scientific<br\/>model, entailing profound intellectual liabilities. This research<br\/>project will investigate formal-methods-based principles and tools to<br\/>make the practice of programming a more mathematical activity for<br\/>ordinary programmers. The overriding aim is to make dependability a<br\/>common basic property of critical software. <br\/><br\/><br\/>To that end, the PI will design a new programming system that supports<br\/>research in axiomatic programming based on new logical linguistic<br\/>constructs, invent new programming models and tools grounded in formal<br\/>reasoning and methods. The PI will investigate the design of practical<br\/>dependent type systems for mathematics software and their efficient<br\/>compilation to support integrated automated deduction and computer<br\/>algebra systems. The project has synergistic components that build<br\/>bridges between symbolic and algebraic computation, compiler construction,<br\/>proof theory, and education. Insights gained from this project will<br\/>be integrated into new courses, supported by a book on the practical<br\/>implementation of modern type systems and compilers. The PI expects<br\/>to discover basic principles of axiomatic programming, tools, and<br\/>techniques. The results are expected to influence the evolution of<br\/>existing major mainstream programming languages (such as C++) in<br\/>their support for structured generic programming and improvement of <br\/>software reliability. As ever, the PI will involve students both at<br\/>the undergraduate and graduate levels, in hands-on, fully integrated<br\/>research-based classes.","title":"CAREER: Compilers for Dependable Computational Mathematics","awardID":"1150055","effectiveDate":"2012-06-01","expirationDate":"2017-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[502347],"PO":["564588"]}}