{"139337":{"abstract":"The rapidly increasing sizes of the data sets being treated in various applications is starting to render inadequate many of the traditional methods used in data exploration. These methods break down not only because of the increase in the number of observations (size of datasets themselves) but also because the underlying phenomena observed are intrinsically of high dimension, i.e., they involve a large number of variables or parameters. High-dimensional datasets present great mathematical challenges but in practice, the related difficulties are mitigated by the fact that in most cases, not all the measured variables are important for an understanding of the underlying phenomenon. One of the difficulties faced by current dimension reduction techniques is that existing algorithms are often too costly when dealing with very large data sets. To tackle a few of these challenges the research team of this project will focus on the development of computationally efficient methods which blend classical techniques such as PCA or LLE, with other strategies from numerical linear algebra and approximation theory, to reduce problem sizes. Thus, multilevel or divide and conquer techniques are quite common in other areas of scientific computing but received relatively little attention in data mining. The proposed work will put methods of this type at the forefront. The research team will also consider tools borrowed from graph theory, specifically techniques based on hypergraphs, graph partitioning, and kNN graph construction, to help with dimension reduction. Finally, this project will address the complex issue of dimension reduction by means of tensors and the use of multilinear algebra.<br\/><br\/>Society is currently facing an unparalleled surge of exploitable information in scientific, engineering, and economical applications. Typical examples of such applications include face-recognition which has uses in security and commerce for example, and the processing of queries on the world-wide web. The data sets generated in these applications are not only gaining in size (more data samples) but also in their dimension (number of parameters or variables to represent each data sample). For example, in face recognition, where one deals with sets of pictures the size would be the number of pictures and the dimension would be the number of pixels used to represent each picture. Reducing the dimension of data is a vital tool used in applications dealing with large data sets. It is therefore not too surprising that this line of research has gained enormous importance in the last few years. The investigators of this project will explore methods to solve this problem, putting an emphasis on those methods characterized by low computational cost. Among these methods are a class of divide and conquer techniques which divide the sets in smaller ones on which the classical methods are applied independently.","title":"Numerical Linear Algebra and Approximation Theory Methods for Efficient Data Exploration","awardID":"0810938","effectiveDate":"2008-07-15","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7351","name":"THEORETICAL FOUNDATIONS (TF)"}}],"PIcoPI":["550000"],"PO":["565027"]},"144298":{"abstract":"Proposal: ID: CCF - 0836338 <br\/>Title: SGER: Linear Optimization vs. Nonlinear Equilibrium <br\/>PI: Polyak, Roman A.<br\/>Inst: George Mason University <br\/><br\/><br\/>ABSTRACT:<br\/><br\/>An innovative idea for reformulating the standard linear programming problem by taking into account more realistic scenarios from market economics is being considered in this proposal. The standard linear programming formulation of resource allocation problem assumes that the cost of a commodity is independent of the level of production. As one knows this is not the case in reality. By making the cost a function of the production, the PI formulates the problem in more general terms. However, under some natural but simplifying assumptions (which are somewhat technical to describe) on the nature of the cost function, the solution complexity of the problem turns out to be lower than the worst case complexity of the solution to the standard linear programming problem. In fact, there are indications that an O(n^2) solution can be obtained in this nonstandard formulation by the PI. This is paradoxical in some sense (that a more general problem has a simpler solution!), but apparently not so because for the LP formulation the geometry of the feasible set is a polytope, whereas its is a much simpler region under the new formulation of the problem. Also, the new formulation has close ties with the theory of n- person games.","title":"SGER: Linear Optimization vs. Nonlinear Equilibrium","awardID":"0836338","effectiveDate":"2008-07-01","expirationDate":"2010-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":[384746],"PO":["562984"]},"139448":{"abstract":"The emergence of chip multiprocessors (CMPs) is ushering in a new era of high-performance on the desktop. Within several years, desktop computers could have tens to even hundreds of CPUs, leading to petascale performance. However, a problem looms on the horizon: current memory technology will not keep pace with the terabyte size and scales of future application data sets.<br\/><br\/>This project aims to overcome the obstacles of building a terabyte and beyond main memory. Our approach replaces a large main memory constructed with conventional DRAM with an even larger main memory constructed with phase-change memory (PCM). PCM has good scalability, exceptionally low power consumption, and no susceptibility to errors. To use PCM, there are several challenges, including relatively slow performance and poor write endurance. We will develop a new memory architecture, called Tera-PCM, to manage PCM acceess latency and to increase PCM longevity. Our hypothesis is that Tera-PCM can be used to construct a terabyte memory for desktop CMPs that is performance and endurance competitive with DRAM at a lower power cost. The project will impact both undergraduate and graduate students, through research opportunities and industry internships. Students from under-represented groups in computer science and computer engineering will be recruited to participate, furthering diversity.","title":"CPA-CSA: Tera-PCM: A Low Power Terabyte Main Memory using Phase Change Memory","awardID":"0811295","effectiveDate":"2008-07-15","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["560516","533851","554329"],"PO":["559883"]},"141384":{"abstract":"Proposal #: CNS 08-21607<br\/>PI(s): Metaxas, Dimitris N.<br\/> Glenn, Scott M.; Kremer, Ulrich; Parashar, Manish; Schofield, Oscar<br\/>Institution: Rutgers University <br\/> New Brunswick, NJ 08901-8559<br\/>Title: MRI\/Dev.: Dev. of Next Generation Collaborative Underwater Robotic Instrument<br\/>Project Proposed:<br\/>This project, developing the next generation of Collaborative Underwater Robotic Instrument (CURI), targets empirically-anchored investigations based on the deployment of a semi-Langragian network of biologically inspired autonomous robots. This new instrument consists of a collection of new underwater glider robots, a computer cluster, and monitors for Human-CURI interaction (along with novel hardware and software), capable of exhibiting biologically inspired autonomous cooperative behaviors such as swarming, maneuvering efficiently, sensing, and making decisions. Among others goals, the work aims to be able to track and map a water mass over time and to assess how a water column mixing in ocean water drives local primary productivity over time. CURI, developed as a collaborative effort between the institution and Webb Research (manufacturers of current robotics gliders), will exhibit and allow<br\/>- Biologically inspired behaviors such as swarming,<br\/>- Decision making (in uncertain conditions) based on the integration of multi-dimensional, multi-scale, and multi-sensory data,<br\/>- Human-CURI interaction to help guide the mission goals of the large number of underwater robotic vehicles, and<br\/>- Underwater communication among the robots of the CURI based on the implementation of ideas from distributed and adaptive non-fixed topology networks which include middleware, metadata, and low power protocols for underwater communications.<br\/>Leveraging significant NSF, ONR, NOAA, USGS, DHS, and other agency investments, CURI will be tested in the linked ecosystems of the densely populated NY-NJ metropolitan area, the Hudson River watershed and estuary, and the adjacent coastal ocean of the Mid-Atlantic, as well as Polar and Tropical environments. The diverse data gathered will provide foundation for computational analysis and modeling. <br\/>Broader Impacts:<br\/>This development has strong multidisciplinary components that involve control, algorithms, marine science, statistical learning, dynamic systems, human-computer interaction (HCI), and distributed systems. The work is applicable in many areas that involve large-scale, distributed modeling of coordinated behaviors of individual units and their interaction with the environment. Thus, current and future oceanographic applications are expected, including improved modeling of the Coastal Hydrologic Cycle and understanding how a human initiated act such as pollution, global warming, and over-fishing affects the coast, the atmosphere, and ultimately, the quality and security of human life in urbanized environment. CURI will influence the educational program. Courses will be developed and collaboration across disciplines will ensue.","title":"MRI: Development of Next Generation Collaborative Underwater Robotic Instrument","awardID":"0821607","effectiveDate":"2008-07-15","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["493379","522465","421129","558205","528215"],"PO":["557609"]},"135862":{"abstract":"The University of New Mexico has been awarded funding to develop new community capacity and new technologies to support the design, implementation, and deployment of a Virtual Data Center for biodiversity, ecology and the environment. Currently such data is scattered across internet accessible and inaccessible databases and collections. The tools developed in this project will reduce long term costs for gathering and integrating this information, making it more readily available to scientists and policy makers alike. The data center will be broadly accessible via the internet and is to be founded on open standards and protocols for interoperability among existing and new data centers. Semi-annual week-long Technical Working Group meetings will engage information scientists from data centers representing diverse disciplines, information systems developers, and numerous students who will contribute to developing Virtual Data Center prototypes and adopting and adapting basic system interoperability and data exchange standards from the digital library community and various scientific communities. An annual meeting of a Community Engagement Working Group plus an annual External Advisory Committee meeting will address socio-cultural barriers to data preservation and data sharing, as well as data center sustainability. Undergraduate students will participate annually in a summer cyberinfrastructure traineeship as well as in projects during the academic year that are identified by the Working Groups. Outreach will be provided at annual meetings of relevant professional societies, emerging environmental observatories, and research networks. Project results will be incorporated in annual training sessions supported by project partners and through the broad adoption of the interoperability solutions developed as part of this project. In addition to promoting diverse participation in Working Group activities and summer traineeships, results will be freely and openly accessible via the project web site.","title":"INTEROP: Creation of an International Virtual Data Center for the Biodiversity, Ecological and Environmental Sciences","awardID":"0753138","effectiveDate":"2008-07-15","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"7701","name":"DATA INTEROPERABILITY NETWORKS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"1181","name":"ECOSYSTEM STUDIES"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"1195","name":"LONG TERM ECOLOGICAL RESEARCH"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"1165","name":"ADVANCES IN BIO INFORMATICS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["565246","473912","402676","553472"],"PO":["496031"]},"134344":{"abstract":"CAREER: Intuitive Appearance Design<br\/><br\/>F. Pellacini<br\/><br\/>Abstract<br\/><br\/>Synthetic images have reached considerable sophistication, to the point where we can render images indistinguishable from reality. Today the major limiting factor for a ubiquitous use of computer-generated images is the human labor and expertise required to create the shape, materials and lights of synthetic environments. This project is a combined research and education effort that brings us closer to making the creation the synthetic imagery accessible to all. The research component of this project simplifies the design of objects' appearance, which comes from the interaction of materials and lights, to complement recent advances in shape modeling and animation. The goal is to allow users, including novices, to design the appearance of complex scenes in just minutes. On the education side, the project explores the interaction between the conceptual, technical, and aesthetic principles of image synthesis through curriculum development and out-of-classroom experiences. <br\/><br\/>More specifically, the project investigates interfaces that allow designers to intuitively and effectively specify design goals on objects? appearance, algorithms that derive lights and materials parameters robustly from such goals, and representations of appearance that are effective to manipulate. These investigations allow designers to manipulate complex lighting and materials with intuitive user-interface metaphors and to transfer appearance from example images. Qualitative and quantitative user studies guide our investigation and serve as rigorous validation of our results. We focus on novice users, but expect our work to benefit experts as well. The resulting methods allow intuitive and fast modeling, while remaining consistent across all aspects of appearance design, from simple lighting and materials to complex environmental illumination and textured surfaces, in realistic and non-photorealistic renderings of static and dynamic scenes.","title":"CAREER: Intuitive Appearance Design","awardID":"0746117","effectiveDate":"2008-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":[357221],"PO":["532791"]},"134476":{"abstract":"CCF - 0746836 <br\/>Title: CAREER: Adaptive and Built-in Defect and Fault Tolerance for Crossbar Nano-architectures<br\/>PI name:Tahoori, Mehdi B.<br\/>Inst: Northeastern University<br\/><br\/>ABSTRACT:<br\/>Improvements in chip manufacturing technology have propelled an astonishing growth of electronic systems which are integrated into our daily lives. However, this trend is facing serious challenges, making emerging nanotechnologies inevitable for future chip manufacturing. The major challenge for nanotechnologies is reliability. Nanoscale devices are more likely to fail, both at the manufacturing and during the operating lifetime, compared to traditional devices used in today's chips. Elevated number of defects adversely affects the manufacturing yield, causing a severe negative economic impact on the nanoelectronic industry. <br\/><br\/>This project focuses on a set of fully integrated educational and research activities to provide defect and fault tolerance in the presence of high defect densities. To tolerate high defect rates, defect tolerance to improve the manufacturing yield (for fabrication defects) and fault tolerance to ensure the lifetime reliability (for errors during normal operation) are integrated in the design methodologies for nanotechnologies. The target platform is the programmable crossbar nano-architecture built using carbon nanotubes. Adaptive and built-in defect and fault tolerant design flows, fundamentally different from conventional approaches, are developed in which the objective is to ensure high manufacturing yield and runtime reliability of the circuit at extremely low costs. Defect and fault tolerance are built into the circuit, minimizing the communication with expensive and time-consuming off-chip equipments. Moreover, the proposed built-in defect and fault tolerance will automatically adapt to the level of manufacturing and runtime defects, making them optimal for a wide range of fabrication processes, operation environments, and applications.","title":"CAREER: Adaptive and Built-in Defect and Fault Tolerance for Crossbar Nano-architectures","awardID":"0746836","effectiveDate":"2008-07-01","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["359676"],"PO":["562984"]},"148435":{"abstract":"Due to global economy pressures, fabrication of advanced integrated circuits (ICs) is migrating to foreign foundries. It has become a common trend for many fab-less companies and government agencies to ship their designs offshore for low-cost fabrication. These trends have raised serious concerns regarding possible threats or attacks on US military systems, critical sites and even household appliances that rely on high performance chips. There are various potential vulnerabilities to such systems caused by malicious alterations of hardware processes that might make these vital systems inoperable at some future time. Such malicious manipulation of ICs slated for installation in US weapon systems cannot be tolerated.<br\/><br\/>The focus of this research is on the development of automatic test pattern generation (ATPG) and signal analysis techniques for detecting and locating malicious alterations, e.g. the insertion of Trojan circuits, during wafer probe aor package test as a means of improving the level of trustworthiness of the chip. In particular, techniques that significantly improve the resolution of quiescent current and transient current techniques for detecting and locating Trojan circuits are investigated. A second focus of the project is on the development of ATPG methods designed to detect hidden alterations of the chip, e.g., inserted or weakened wires or transistors which cause the chip to fail later in the field.","title":"CT-ISG: Collaborative Research: Detection and Isolation of Malicious Inclusions in Secure Hardware (DIMINISH)","awardID":"0852949","effectiveDate":"2008-07-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["486576"],"PO":["497499"]},"139547":{"abstract":"Abstract<br\/>Wonka (0811790)<br\/><br\/>Recent advances in remote sensing give rise to new data sets that capture detailed facade and urban appearance information. These multi-gigabyte data sets pose new challenges for urban rendering: it is difficult to fit the models into the memory of the graphics card and the memory transfer of large amounts of data is prohibitively slow. Crucial ingredients for success are efficient data representations. In this research project the investigators study three important challenges of massive urban rendering. The research involves mapping computer graphics data representation problems to new factorization problems of higher-order arrays. The research has practical applications in computer graphics (e.g., for driving and traffic simulation systems, virtual reality training systems for first responders, three-dimensional mapping for cell phones and PDAs, computer games, and computer animation). The methodology also contributes to advance related fields, such as image and video processing, computational biology, and medical image analysis.<br\/><br\/>The investigators focus on the following two fundamental research questions: How can we efficiently render massive urban models? and How can we efficiently process higher-order tensors for computer graphics applications? The research is specifically addressing three example rendering techniques that are suitable for massive urban models: displacement mapping of building facades, robust visibility pre-computation, and rendering of aggregated urban appearance information. For these three examples the question of efficient representation of the involved data structures can shown to map nicely to new tensor factorization and reconstruction problems. The factorization problems are novel because of the nature of the data sets (e.g. discrete and binary tensors) and constraints imposed on the factorization (e.g. the entries of the reconstruction have to be equal to or greater than those of the original tensor).","title":"CPA-G&V: Tensor Factory","awardID":"0811790","effectiveDate":"2008-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["455161","456042"],"PO":["532791"]},"139449":{"abstract":"Proposal CCF-0811297<br\/><br\/>New Foundations for Control Flow Analysis<br\/><br\/>Harry Mairson<br\/><br\/>A time-bounded static analyzer can provide information about the runtime behavior of a computation-intensive program. The proposed research will address new foundations for control flow analysis of higher-order programs, including the design and implementation of novel analyzers, and the analysis of known methods and approximation problems. Using principles of linearity derived from linear logic, the researchers want to characterize precisely, in computational terms, the degree to which such static analysis approximates run-time behavior. Scientific software design ought to be founded on an analytical as well as practical and pragmatic understanding of the tradeoffs between the running time of static analyzers, and the accuracy of their computations. The broader impacts of such a program of research include an increased awareness and understanding of the feasibility of such compile-time analysis in the work of software developers. The analytic tools are also amenable to integration in undergraduate courses on programming language pragmatics and implementation.","title":"New Foundations for Control Flow Analysis","awardID":"0811297","effectiveDate":"2008-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":[370683],"PO":["523800"]},"141440":{"abstract":"IEEE DySPAN is a high quality conference in the area of dynamic spectrum access. Current radio technology trends promise to enable \"Dynamic Spectrum Access\" (DSA) networks, using wide-band spectrum sensing, real-time spectrum allocation and acquisition, and infrastructure-less mesh networks. Not only do these trends challenge the existing technologies, they challenge the traditional \"command and control\" methods of allocating and licensing spectrum by government fiat. In 2005, the first DySPAN conference was held to promote analysis, discussion and development of new DSA technologies. Built upon the momentum of the first DySPAN conference, the second DySPAN was held in Apr. 2007. Both conferences succeeded on all accounts, bringing the technologists who design and build these devices together with the spectrum policy experts charged with re-architecting spectrum policy in a manner that accommodates the technologies. The results included substantial and important contributions on technical and policy issues facing this emerging area of research. The third conference will be held in Chicago, IL, USA, in Oct. 2008. Since the travel support in most of the NSF awards is quite limited to students (who are authors), this fund will enable the awardees not to divert research funding for travel.","title":"Travel Grant for DySPAN 2008","awardID":"0821830","effectiveDate":"2008-07-01","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["436918"],"PO":["434241"]},"140043":{"abstract":"Inspiring and enabling more women to choose careers in information technology is a compelling solution for the nation?s innovation, global competitiveness, and workforce sustainability. Yet realizing the contributions of women depends on overcoming the complex of enduring social and cultural processes that limit their participation in computing. Supply-side factors affect the number of girls and women interested in learning about computing or pursuing an IT career. Demand-side factors reduce the effectiveness of organizational efforts to attract and retain women. In addition, the broad influence of cultural stereotypes about gender and technology suggest to women and those who influence them that they are less likely than men to have talent or interest in creating computing technology. These stereotypes lead girls, parents, counselors, and educators to overlook or reject computing as a career and to ignore the educational system that reinforces the problem. The National Center for Women and Information Technology (NCWIT) was formed three years ago to address these issues in an innovative and systematic way.<br\/><br\/>In its first three years, NCWIT has established an alliance-based infrastructure with the goal of uniting all current efforts, accelerating their progress, and extending their reach. NCWIT now seeks extension funding to drive the utilization of this national infrastructure. NCWIT comprises more than 100 prominent corporations, academic institutions, government agencies, and non-profit organizations cooperating to increase women's participation in information technology (IT). Four alliances address IT reform along the entire educational and career pipeline, with programs in K-12 education, college-level outreach and curriculum reform, corporate recruitment and retention, and entrepreneurial ventures. Alliance members share their reform efforts, learn about and pilot best practices, recycle what works and discard what does not, influence policy, participate in IT image and reform campaigns, and serve as local change agents.<br\/>National, bi-annual NCWIT workshops address topics such as innovation, diversity, K-12 education, and promising practices focused on recruiting, retaining, and advancing women in IT. Top-notch materials and resources give people the tools to raise awareness within their organizations, reach out to targeted populations, implement and evaluate reforms, and share their results. NCWIT is also actively collaborating with several other high-profile organizations to improve the public image of computing using a research-driven marketing campaign. Extensive, ongoing internal and external evaluation results in refinement of NCWIT methods and efforts and has resulted in a culture of introspection and self-analysis.<br\/><br\/>This project is uniquely situated for successfully overcoming the complex and lingering conditions that hinder women?s participation in computing. The NCWIT infrastructure is in place, alliances are growing, and alliance members are eager to implement interventions in their local organizations and share results with the national community. NCWIT has built a robust and highly-respected effort that has engaged the broad computing community, forming a culture based on evidence-based practices. NCWIT is the only organization creating a national, capacity-building infrastructure focused on reform of the entire IT educational pipeline, as well as the culture of IT organizations.<br\/>Increasing women?s participation in IT has far-reaching national consequences. Not only do information and computing technologies pervade all aspects of our everyday lives in an unprecedented way, but all engineering and science discovery and innovation are now dependent on computational science. Increasing the pool of qualified computing professionals supports the goals of national initiatives (e.g., nanotechnology, the Cyberinfrastructure Initiative) and our economic, security, defense, and health care systems are computing-centered. Increasing the participation of women not only supports national goals, but improves the development and design of computing systems, applications, and products through the integration of diverse ideas while helping to overcome economic disparities for women.","title":"Special Projects (CNS): National Center for Women and Information Technology","awardID":"0813956","effectiveDate":"2008-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":["425934","510094","510151"],"PO":["560704"]},"141264":{"abstract":"Proposal #: CNS 08-21155<br\/>PI(s): DeFanti, Thomas A.<br\/> Krueger, Ingolf H.; Papadopoulos, Philip M.; Smarr, Larry L.; Vahdat, Amin M.<br\/>Institution: University of California ? San Diego<br\/> La Jolla, CA 92093-0934<br\/>Title: MRI\/Dev.: Development of Instrumentation for Project Green Light<br\/>Project Proposed:<br\/>This project, developing an instrument called GreenLight, measures, monitors, and optimizes the energy consumption of large-scale scientific applications from many different areas. The work enables inter-disciplinary researchers to understand how to make ?green? (i.e., energy efficient) decision for IT computation and storage. Consequently, an experienced team might be able to make deep and quantitative explorations in advanced architecture, including alternative circuit fabrics such as Field Programmable Gate Arrays (FPGAs), direct-graph execution machines, graphics processors, solid-state disks, and photonic networking. The enabled computing and systems research will yield new quantitative data to support engineering judgments on comparative ?computational work per watt? across full-scale applications running at-scale computing platforms, thus helping to re-define fundamentals of systems engineering for a transformative concept, that of green CyberInfrastructure (CI). Keeping in mind that the IT industry consumes as much energy (same carbon footprint) as the airline industry, this project enables five communities of application scientists, drawn from metagenomics, ocean observing, microscopy, bioinformatics, and the digital media, to understand how to measure and then minimize energy consumption, to make use of novel energy\/cooling sources, and employ middleware that automates optimal choice of compute\/power strategies. The research issues addressed include studying the dynamic migration of applications to virtual machines for power consumption reduction, studying the migrations of virtual machines to physical machines to achieve network locality, developing new power\/thermal management policies (closed loop, using feedback from sensors), classifying scientific algorithms in the context of co-processing hardware such as GPUs and FPGAs, and developing algorithms for resource sharing\/scheduling in heterogeneous platforms. The full-scale virtualized device, the GreenLight Instrument, will be developed to measure, monitor, and make publicly available (via service oriented architecture methodology), real-time sensor outputs, empowering researchers anywhere to study the energy cost of at-scale scientific computing. Hence, this work empowers domain application researchers to continue to exploit exponential improvements in silicon technology, and to compete globally. Although the IT industry has begun to develop strategies for ?greening? traditional data centers, the physical reality of modern campus CI currently involves a complex network of ad hoc and suboptimal energy environments in departmental facilities. The number of these facilities increases extremely fast creating campus-wide crisis of space, power, and cooling due to the value of computational and data intensive approaches to research. This project addresses these important issues offering the possibility to improve.<br\/><br\/>Broader Impacts: The project enables researchers to carry-out quantitative explorations into energy efficient CyberInfrastructure (CI) and to train the next generation of energy-aware scientists. It enlists graduate students from five disciplinary projects, involves minority serving institutions, and is likely to have direct impact on commercial components of the nation?s CI.","title":"MRI: Development of Instrumentation for Project GreenLight","awardID":"0821155","effectiveDate":"2008-07-15","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["554382","485593","559498","438188","557607"],"PO":["557609"]},"145400":{"abstract":"The AToL (Assembling the Tree of Life ) is a large-scale collaborative research effort sponsored<br\/>by the National Science Foundation to reconstruct the evolutionary origins of all living things. Currently 31<br\/>projects involving 150+ PIs are underway generating novel data including studies of bacteria, microbial eukaryotes, vertebrates, flowering plants and many more. The data being generated by these projects include and are not limited to: (i) Specimens and their provenance including collection information, voucher deposition, etc.; (ii) Phenotypic descriptions and their provenance; (iii) Genotypic descriptions and their provenance; (iv) Interpretation of the primary measurements including homology ; (v) Estimates of phylogenies and methods employed; and (vi) Post-tree analyses such as character evolution hypotheses.<br\/>While the data collection, storage, and dissemination within each projects are well coordinated, there is a critical need to develop the infrastructure to integrate all ATOL data sources, allowing the individual efforts to become multipliers for global hypotheses. Furthermore, as the projects continue to expand and address diverse corners of the Tree of Life, efficient project management will be greatly aided by workflow and data management tools targeted towards the ATOL problem domain. The project will develop new, compact, abstract data models for phylogenetics, leveraging use cases from a broad survey of empirical projects. The integration system will develop novel mappings between different phylogenetic data domains, and allow individual projects to join a network of integrated databases in an incremental manner. The data provenance system, which allows tracking of how each data object was created, will be unique to<br\/>systematics data management. The provenance system will not only allow tracking of what kinds of decisions were made in producing a particular tree or a particular column of a data matrix, but will also allow tracking of alternative data lineages such that, for example, different opinions on character homology might be tracked. The results of the research will be delivered in robust software tools that can be used by the entire evolutionary biology community. The study will develop a community-based formal model of data objects used in systematics, primarily through a continuing set of workshops. This activity will not only develop new data management tools, but will also have the effect of synthesizing disparate views of the phylogenetics research domains. The results of the system will be extensible to other domains of evolutionary biology, thereby contributing to the broader mission of evolutionary synthesis. The project will also provide training for the general systematics community in latest database technologies. Finally, by leveraging existing outreach efforts at the Penn Center for Bioinformatics, the project will link to other biological database efforts in genomics and biomedical sciences, disseminating phylogenetic information to the broad biomedical research community.","title":"Collaborative Research: Core Database Technologies to enable the Integration of AToL Information","awardID":"0840702","effectiveDate":"2008-07-15","expirationDate":"2010-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}}],"PIcoPI":["424851","433623"],"PO":["565136"]},"144344":{"abstract":"Statistical machine translation (SMT) promises to bridge the language divide in today's multi-cultural and multi-faceted society. Systems capable of converting text from one language into another have the potential to transform how diverse individuals and organizations communicate. Despite recent successes, we see two critical impediments to continued progress in translation technology: (1) the development of systems depends on access to large amounts of data, and the growth of available resources has far outpaced increases in the performance of individual computers; and (2) current systems for the most part do not take the context of what they are translating into account. With few exceptions, systems translate sentence by sentence, and do not differentiate whether the input text is a newswire article or a children's book. This project advances the state of the art in SMT by addressing both issues. Since divide-and-conquer techniques running on multiple processors are currently the only practical solutions to large-data problems, we must develop scalable algorithms that can exploit large computer clusters. MapReduce is an attractive framework for tackling these challenges since it hides low-level distributed processing issues such as synchronization, fault tolerance, etc., allowing the researcher to focus on actually solving the problem. By coupling network analysis with cross-language information retrieval techniques, we can build rich, multilingual contextual models that will guide an SMT system in translating different types of text. We focus on cross-language enrichment of Wikipedia as an application for demonstrating this technology. Although Wikipedia has emerged as a valuable repository of human knowledge, it has yet to transcend the language barrier. For the most part, contributors work in silos defined by languages, without the benefit of knowledge that is being accumulated elsewhere. The potential broader impact of this project is no less than knowledge dissemination across language boundaries, which will serve to enrich the lives of all the world's citizens.","title":"Putting the Clouds in Context: Statistical Machine Translation with MapReduce","awardID":"0836560","effectiveDate":"2008-07-01","expirationDate":"2011-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7782","name":"CLUSTER EXPLORATORY (CLuE)"}}],"PIcoPI":["514912","518100"],"PO":["469867"]},"136611":{"abstract":"This project investigates creativity support tools for architectural design by bringing together two areas: design process and human-computer interaction. Specifically, the project develops a tool that will support procedural modeling using shape grammars using multi-touch interfaces. This kind of creativity support tool facilitates: sharing designs among multiple users and design strategies and changing a design by editing the global shape of a surface using a multi-touch and multi-user interface on a graphical display surface that can track gestures and touches of one or multiple & fingers. The technology enables intuitive sketching operations. Architectural design is the selected application for research in creativity because of its complexity. Modern architectural designs are inherently three-dimensional and the simplest traditional creativity support tools, pen and paper, are too limited. At the same time, current modeling packages have several disadvantages that preclude them from being used as creativity support tools, e.g. a very high learning curve, very limited possibility for multi-user interaction, required programming for complex designs, and the inability to reuse design strategies. The creativity support tool will impact the architectural design process in the following manner: The design process will be intuitive and be accessible to a large audience. Designs can be generated interactively with multiple users participating. Design strategies can be reused and applied to multiple different shapes. Beyond applications in architecture, this work has the potential to influence design in the entertainment industry, designing self assembling structures of DNA in bio-chemistry, landscape architecture, urban planning, and digital art.","title":"Pilot: SOUZOU - Creativity through Procedural Modeling","awardID":"0757623","effectiveDate":"2008-07-01","expirationDate":"2011-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7788","name":"CreativeIT"}}],"PIcoPI":[363016,"455161","455161"],"PO":["424970"]},"139999":{"abstract":"The illicit trafficking and production of special nuclear materials (SNM) is a paramount global concern. Currently, scintillator detectors are used to determine whether SNM are present in incoming vehicles or cargo at border crossings. These detectors are cost effective and fast, but have a relatively poor spectral energy resolution. As a result, they cannot discriminate dangerous materials such as highly-enriched uranium (HEU) from common and innocuous background radiation. Even high purity germanium detectors, the current state of the art for gamma-ray detection, often do not have good enough resolution to clearly separate HEU emissions from background. Cryogenic microcalorimeters are a new class of detectors that provide resolution capable of separating these lines from any interference. The overall goal of this project is to provide the knowledge necessary to make these microcalorimeters an efficient and field usable instrument that will help solve real-world nuclear security and forensics problems. Specifically, we will design and implement measurements on the thermal properties of these low-temperature detectors that will enable faster, more efficient, array-compatible sensors with extremely high spectral resolution. These experiments will be designed and implemented by a team that includes a postdoctoral scholar, graduate and undergraduate student researchers, who will also work collaboratively with scientists at the National Institute of Standards and Technology and Los Alamos National Lab. The broader impacts of the project encompass education and technical training of post-graduate, graduate, and undergraduate students, and strengthening partnerships between the University of Denver, NIST and LANL. In addition, much of our work focuses on development and implementation of novel measurement techniques to probe thermal properties of detectors and their micromachined constituent materials. Many of these new techniques will be useful for a broad range of future experiments, and their development provides opportunities for students to learn techniques relevant to high-tech industry such as silicon micromachining and circuit design and characterization.","title":"Thermal pathways in ultra-high resolution gamma-ray detector materials for nuclear material detection [10U08UDzink]","awardID":"0813777","effectiveDate":"2008-07-01","expirationDate":"2011-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"H187","name":"DEFENSE INTELLIGENCE AGENCY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"H188","name":"DEFENSE INTELLIGENCE AGENCY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"I331","name":"Defense Intelligence Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"J265","name":"Defense Intelligence Agency"}}],"PIcoPI":["391752"],"PO":["565136"]},"141012":{"abstract":"Proposal Number 0820220<br\/><br\/>Title: ORCHID: Harnessing Digital Evolution in Design High-Assurance Adaptive Systems<br\/><br\/>PIs: Betty Cheng, Philip McKinley, Charles Ofria, and Xiaobo Tan<br\/><br\/>A robust cyber-infrastructure must be able to monitor the environment and its own behavior, adapt to changing conditions, and protect itself from component failures. The hallmark of the Orchid project is to introduce the fundamental biological principle, evolution, into the development process for adaptive real-world software systems. The project will use and extend the Avida digital evolution software platform to address three primary tasks: (1) exploiting the automatic generation of software models and search capacity of digital evolution to enable the developer to identify viable system configurations; (2) generating novel strategies to adapt from one system behavior to another in response to changing environmental conditions; and (3) providing assurance for adaptive systems by revealing latent properties within a given configuration in order to distinguish generated configurations and remove unwanted behavior. A prototype system will be developed and used to conduct an experimental case study in the design of self-adaptive aquatic mobile sensor networks for homeland security and environmental monitoring. In addition, an instructional system, Avida-EDAS, will be developed to enable students to evolve models of adaptive software, conduct experiments to assess the impact of adverse environmental conditions, and observe the effects of different adaptation strategies on system execution.","title":"ORCHID: Harnessing Digital Evolution to Design High-Assurance Adaptive Systems","awardID":"0820220","effectiveDate":"2008-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7724","name":"SOFTWARE FOR REAL-WORLD SYSTMS"}}],"PIcoPI":["472159","543568","425363","560245"],"PO":["564388"]},"143564":{"abstract":"Diary Note<br\/><br\/>SGER Abstract<br\/><br\/>0832234<br\/>Jalalabad Fab Lab<br\/>Neil Gershenfeld<br\/>MIT<br\/><br\/>June 9, 2008<br\/><br\/>Fab Labs are portable rapid prototyping facilities that can be deployed<br\/>worldwide to allow local manufacture of physical objects. Over the several<br\/>years that they have been in existence, they have been used for making RF <br\/>components in Norway, copier gears in India, and for education in the inner <br\/>city of Boston. A FabLab network has permitted the individual facilities to<br\/>share ideas and solutions.<br\/><br\/>A Fab Lab has been established in Jalalabad, Afghanistan, both as a base <br\/>for research and an experiment in itself in the impact of providing <br\/>modern means for invention rather than remotely-developed solutions to <br\/>local problems. The initial focus on applications in healthcare is targeting<br\/>some of the most immediate needs, which are currently constrained by the need<br\/>for long supply chains or large local inventories. As solutions are developed<br\/>and tested in the Jalalabad fab lab, they will be shared throughout the global<br\/>fab lab network. The connection with this network, along with access to <br\/>rapid-prototyping capabilities, is also expected to contribute to the regional<br\/>development of educational and economic activity.","title":"Jalalabad Fab Lab","awardID":"0832234","effectiveDate":"2008-07-01","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["560692"],"PO":[382346]},"134599":{"abstract":"Result-Oriented System-Level Modeling for Efficient Design of Embedded Systems<br\/>Rainer Doemer, University of California, Irvine<br\/><br\/>We are surrounded by embedded computing systems, ranging from video-enabled mobile phones over real-time automotive applications to reliable medical devices. Just as the quality of an architectural blue-print determines the quality of the resulting building, the model of an embedded system is the key to its successful implementation.<br\/>This project moves research and education on embedded system design forward in the area of system-level specification and modeling. While traditional work largely has focused on simulation and synthesis from a given system model, this project addresses the creation and optimization of system models for effective use in existing design processes. The results of this project are directly applicable to established system design flows in industry and fit well into existing and new courses in computer engineering education.<br\/><br\/>This project optimizes the modeling of embedded systems by use of four novel techniques. First, it advances a new model of computation, named ConcurrenC, which refines the generic capabilities of common C-based system-level description languages. Second, the creation of the system model is automated by computer-aided re-coding that derives an executable model directly from reference code. Third, the efficiency of the model is optimized using Result-Oriented Modeling (ROM), which, in contrast to traditional Transaction-Level Modeling (TLM), offers gains in simulation speed of multiple orders of magnitude and highest accuracy at the same time. Fourth, this project investigates TLM of computation, an area where it has not been applied before.","title":"CAREER: Result-Oriented System-Level Modeling for Efficient Design of Embedded Systems","awardID":"0747523","effectiveDate":"2008-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[357763],"PO":["561889"]},"134600":{"abstract":"CAREER Project: Analysis and Control of Network Delay<br\/>Michael J. Neely<br\/>University of Southern California<br\/>http:\/\/www-rcf.usc.edu\/~mjneely\/<br\/><br\/>Abstract: <br\/>This research investigates communication strategies for time-varying networks, with the goal of developing a fundamental theory for analysis and control of network delay. While much is known about network throughput optimization, the delay problem is more complex and less understood. Delay-aware algorithms must be designed for very large systems and must be able to optimally adapt to environmentswhere future network traffic, link conditions, and mobile user locations are uncertain. This project seeks to establish mathematical techniques for computing tight delay bounds, and to develop scheduling and routing algorithms that achieve provably high throughput with order-optimal delay. This project also explores intelligent mechanisms for scheduling redundant packet information and for making use of (and controlling) network mobility. Indeed, although redundancy and mobility increase the complexity of decision options, both can be used advantageously to improve network performance.<br\/><br\/>This project also introduces a new topic of mathematical optimization: The study of controlling Lagrange multipliers. Specifically, it is known that network optimization is closely related to convex programming theory, where Lagrange multipliers can play a role analogous to queue backlogs and\/or \"network prices.\" However, there has been little research in the area of controlling the magnitude of the Lagrange multipliers that are used in an optimization problem. A general theory of controlled Lagrange multipliers is thus important to this study of network delay and for related problems of network pricing and economics. Such a theory may also prove useful in other optimization contexts, and may have broader applications to machine learning and online dynamic programming.","title":"CAREER: \"Analysis and Control of Network Delay\"","awardID":"0747525","effectiveDate":"2008-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7351","name":"THEORETICAL FOUNDATIONS (TF)"}}],"PIcoPI":["467823"],"PO":["564924"]},"143356":{"abstract":"Travel Support for Students from U.S. Universities to <br\/>Attend ISWC 2008<br\/><br\/>The ISWC 2008 Travel Fellowships provide funding for students at U.S. <br\/>Universities to attend the 2008 International Semantic Web Conference <br\/>(ISWC) which will be held October 26-30, 2008 in Karlsruhe, Germany. Our <br\/>goal is to encourage students who want to become part of the Semantic Web <br\/>research community, and we expect that participation in ISWC 2008 will be <br\/>a significant event in the graduate careers of the selected students.<br\/><br\/>The doctoral consortium, in particular, creates an opportunity for <br\/>doctoral students to test their research ideas, present their current <br\/>progress and future plans, and to receive constructive criticism and <br\/>insights related to their future work and career perspectives.<br\/><br\/>In selecting applications for travel support, preference is given to <br\/>students selected to participate in the doctoral consortium, followed by <br\/>students who are first author on a paper accepted at the conference, <br\/>followed by students who have other authorship on a conference or related <br\/>workshop paper.<br\/><br\/>Details, including application instructions, can be found at<br\/>http:\/\/ebiquity.umbc.edu\/ISWC08Travel","title":"Funding for U.S. students to Attend the 2008 International Semantic Web Conference","awardID":"0831017","effectiveDate":"2008-07-01","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["563576","502435"],"PO":["563727"]},"134413":{"abstract":"Programming languages research has many techniques for generating efficient, correct implementations from high-level specifications. Recent research on language-based security formulates models of information security in terms of modular, algebraic structures from language semantics. This research combines these threads in novel ways to construct high-assurance secure systems in which techniques from programming language semantics provide both a mathematical basis for formal verification and a flexible, modular organizing principle for system design and implementation. This methodology is illustrated with a case study in which kernels (in particular, separation kernels) with a verified security policy are synthesized directly from formal models of security. <br\/><br\/>There is growing interest within defense and avionics circles in separation kernels as a means of coping with serious concerns for system security, safety and integrity arising from the use of high levels of integration. Multi-level security (MLS) systems can be implemented by physical separation: computations at different security levels are situated on different network nodes. However, for many defense and avionics scenarios, physical separation is infeasible due to tight resource constraints. Because sharing resources introduces potential vulnerabilities, mission- or safety-critical MLS systems require both highly integrated implementations and high-assurance security guarantees. This research will have a direct impact on how separation kernels are designed, implemented and verified. Can the rigorous techniques for constructing modular and robust secure systems be generalized to other systems? The long range goal is to facilitate the construction of systems with high assurance end-to-end guarantees, thereby making high assurance more widely available.","title":"CAREER: Automated Synthesis of High-Assurance Security Kernels","awardID":"0746509","effectiveDate":"2008-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["297854"],"PO":["497499"]},"144335":{"abstract":"This CISE Special Project award provides funding for approximately eighty undergraduate and graduate students to attend the 2008 Grace Hopper Celebration of Women in Computing. The eighth Grace Hopper Celebration will be held on October 1-4, 2008 in Colorado. This special project is funded by the CISE Broadening Participation in Computing Program.<br\/><br\/>The intellectual merit of this project lies in the access to the many technical presentations and researchers at the conference. In addition, students have the opportunity to participate in poster sessions and receive feedback from discipline specialists. The Grace Hopper Celebration provides a unique, supportive environment for intellectual discourse that is particularly appealing for women and other under-represented groups. <br\/><br\/>The broader impacts of this project deal with providing resources and support to students that will help them persist in their programs as well as access to avenues to continue through the IT workforce pipeline. Students who attend the Grace Hopper Celebration will be exposed to women who are creating, improving, and studying computer and information technologies who serve as role models and mentors. This travel scholarship support provides a unique opportunity to directly affect the careers of future computer scientists and increase the representation of women in computing.","title":"Advanced Undergraduate and Graduate Student Scholarship and Travel Grants for the 2008 Grace Hopper Celebration of Women in Computing; October 1-4, 2008; Denver, CO","awardID":"0836530","effectiveDate":"2008-07-15","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}}],"PIcoPI":["529248"],"PO":["564181"]},"137702":{"abstract":"Last Modified Date: 05\/19\/08 Last Modified By: Sheila M. Smith <br\/><br\/>Abstract <br\/>Abstract <br\/><br\/>Many imaging tasks involve ill-posed problems, which require realistic priors. Standard convex optimization techniques use priors that prefer globally smooth images, and thus tend to give poor results. Graph cut methods, which permit edge-preserving priors for a restricted class of ill-posed problems, have proven quite successful over the last decade. <br\/><br\/>This research project will address an important but challenging class of ill-posed problems, namely those arising from rank-deficient linear inverse systems. Such underconstrained problems occur in medical imaging tasks such as MRI&CT image reconstruction and fMRI undistortion, as well as in traditional vision problems such as super- resolution. Currently these applications rely on convex optimization methods, which do not support realistic image priors. Yet existing graph cut methods cannot be applied due to some difficult theoretical issues. <br\/><br\/>To overcome these challenges we propose a collaboration between computer vision researchers and experts in graph algorithms. We will develop new graph constructions to address linear inverse systems, drawing heavily on state-of-the-art techniques from boolean optimization. To simplify our task we will exploit specific properties of the rank-deficient linear inverse systems that arise in the applications of interest. We will focus primarily on sparse structured linear inverse systems, an important subclass which contains all of the applications that drive our work. While our proposed work stresses algorithm development, we will also do a significant experimental evaluation of new algorithms on a range of applications, both to assess their performance and to identify promising new avenues. <br\/><br\/>This project brings together experts in computer vision, medical imaging and graph algorithms to address a problem of broad interest in a novel manner. The linear inverse systems that we are concerned with arise in a wide range of medical applications, as well as in other areas, yet current techniques have significant shortcomings. Our approach draws heavily on methods developed by the investigators over the last decade, which have proven quite successful for related problems. In addition, this project will strengthen the ties between researchers in computer vision and algorithms, which have proven to be quite beneficial to both areas. <br\/><br\/>Publications and additional material resulting from this project will be made available at http:\/\/www.cs.cornell.edu\/~rdz\/graphcuts.html","title":"RI-Medium: Collaborative Research: Graph Cut Algorithms for Linear Inverse Systems","awardID":"0803705","effectiveDate":"2008-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["516907","508240"],"PO":["564316"]},"138758":{"abstract":"Over the past decade, the precipitous drop in the cost of disk storage and the build-up of world-wide high-bandwidth fiber optic communications has made massive amounts of data of different modalities (text, images,<br\/>video) easily available to everyone over the Web. In science, engineering, business, and medicine, high-bandwidth sensors, large-scale simulations, and data collection bots generate immense data sets that need to be analyzed. Making sense of all this disparate data in becoming increasingly challenging and difficult. Unlike traditional databases where data is carefully massaged to adhere to rigid schemata, much of the above data comes unstructured, is often dynamic rather than static, can contain large amounts of noise or even errors, and can be incomplete. This project aims to develop general, rigorous and efficient techniques for analyzing massive and distributed sets of unstructured data. The basic aim is to exploit certain ideas from computational topology and geometry in the study of the global structure of large, distributed data sets -- and especially to develop data representations and transformations that makes this structure more apparent. Topology studies the connectivity of spaces, so it is global by its very nature. It is able to determine certain connectivity invariants in a way that is unaffected by deformations of an object and does not require explicit parameterizations of the object geometry. Its strength lies, in a sense, in its relative insensitivity to geometric properties, which permits it to discern underlying combinatorial information about how the geometric object is constructed, and therefore detect some qualitative properties. <br\/>This type of global analysis can be quite important in understanding the overall structure of data sets. Geometry, though more local by nature, can also be used to study global structure by discovering how parts of an object relate to another, or how parts of different objects can be similar. For example, the Erlanger program of Felix Klein has fueled for over a century mathematicians' interest in invariance under certain group actions as a key principle for understanding geometric spaces. <br\/>Such invariances or symmetries can also be key to understanding and reasoning about data sets.<br\/><br\/>The methods proposed here can be applied in many different settings where massive unstructured data sets arise. In science or engineering, large-scale distributed simulations can produce immense data sets; as an example, consider the Folding@Home project at Stanford that generates protein folding trajectories using hundreds of thousands of CPUs throughout the world. In business, companies such as Google and Yahoo! have to mine billions of web clicks to develop algorithms for matching ads to web page content or to individual users. In medicine 3D imaging is becoming commonplace. Medical imaging diagnostic systems, distributed throughout medical offices nationwide, should be able to efficiently share information about shapes of organs and thereby collectively learn about whether certain variations are associated with different diagnostic outcomes or treatment successes. In all these cases, understanding the global structure of the data can provide valuable scientific, engineering, or medical insights, enabling better business decisions, or leading to more effective medical treatment planning.","title":"Global Structure Discovery on Sampled Spaces","awardID":"0808515","effectiveDate":"2008-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7703","name":"FOUNDATIONS VISUAL ANALYTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"H194","name":"U.S. Department of Homeland Se"}}],"PIcoPI":["521232","521231"],"PO":["565286"]},"139506":{"abstract":"Proposal No: CCF-0811582 <br\/>Title: Nanocrystal Computing <br\/>PI name: Franzon, Paul D. <br\/>North Carolina State University <br\/><br\/>ABSTRACT:<br\/>Semiconductor technology must continue to scale even when ?Moore?s Law? ends sometime next decade. One approach to continue scaling is to work out approaches to extend and enhance the underlying CMOS technology that serves as the cornerstone of Moore?s Law. It is CMOS technology that is used to build the computer and other chips that drive the electronics revolution. In this effort, we propose to extend CMOS technology by including nanocrystal films in the transistors. This enables new types of functions to be designed. We will investigate how to design the computer circuits that would be enabled by this new device.<br\/><br\/>As well as pursuing appropriate involvement with Undergraduates, and integration with coursework, this activity will also help us continue to support the NCSU Physical Design Kit ( www.eda.ncsu.edu ). This kit enables the design of ICs in the MOSIS processes using popular commercial design tools. This kit has been downloaded by over 2,000 organizations, including most major Universities. We are constantly upgrading this kit as new processes become available and other improvements are deemed necessary. Currently, we (with Davis and others) are adding a notional 45 nm kit for classroom use.","title":"CPA-DA: Nanocrystal Computing","awardID":"0811582","effectiveDate":"2008-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["475429"],"PO":["562984"]},"145843":{"abstract":"Dawn Song<br\/>Carnegie Mellon University<br\/>Collaborative Research: CT T Towards Behavior-Based Malware Detection<br\/>0627511<br\/>Panel P060975<br\/><br\/>Abstract<br\/><br\/><br\/>Malware is code with malicious intent that can adversely affect the<br\/>host on which it executes or the network over which they are<br\/>transmitted. A malware detector classifies a program as malware or<br\/>benign. Malware writers continuously test the limitations of malware<br\/>detectors in an attempt to discover techniques to evade<br\/>detection. This leads to an arms race, where malware writers find new<br\/>ways to create malware that are undetected by commercial malware<br\/>detectors, and where researchers working on malware detection respond<br\/>by devising new detection techniques. Attackers create new malware<br\/>using two main approaches: program obfuscation and evolution. There is<br\/>strong evidence that malware writers are using obfuscation and<br\/>evolution because the number of new malware families is growing at a<br\/>much slower rate than the number of malware instances. For example,<br\/>according to Symantec threat reports, in the first half of 2005 there<br\/>were 10,866 new virus and worm variants but only 170 new families of<br\/>malware. This data also indicates that signature-based techniques for<br\/>malware detection will not be able to cope with the increase in the<br\/>number of malware instances. Recent results by one of the PIs also<br\/>suggests that current commercial malware detectors are not resilient<br\/>to obfuscation and evolution techniques used by malware writers. All<br\/>this evidence clearly suggests that we need a new approach to malware<br\/>detection.<br\/><br\/>We propose to explore behavior-based malware detection: our algorithm<br\/>focuses on detecting malicious behavior (such as mass-mailing behavior<br\/>used by certain worms) rather than searching for syntactic<br\/>patterns. We specify malicious behavior in a formal language and then<br\/>perform static analysis on the code to determine whether it contains<br\/>the specified behavior. Prior work by the investigators demonstrated<br\/>that this behavior-based malware detector can detect families of<br\/>malware using a single specification. However, there are challenges<br\/>that need to be addressed in the context of behavior-based malware<br\/>detection. We propose tasks to address these challenges. Solutions to<br\/>the proposed tasks will lead to malware detection techniques that will<br\/>resist evasion techniques used by malware writers better than existing<br\/>malware detectors. Behavior-based malware detectors can also detect<br\/>new malware that are variants of old malware..","title":"Collaborative Research: CT-T: Towards Behavior-Based Malware Detection","awardID":"0842695","effectiveDate":"2008-07-01","expirationDate":"2012-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["526903"],"PO":["497499"]},"135415":{"abstract":"Simulation tools for wireless networks do not accurately <br\/>capture the behavior of wireless protocols in real-world <br\/>deployments. On the other hand, physical testbeds spanning <br\/>large geographic areas are expensive to deploy, manage,<br\/>and reconfigure. We propose to develop a miniaturized <br\/>multi-hop wireless testbed, called Mint, that will provide<br\/>a flexible and high-fidelity platform for protocol development, <br\/>debugging, and testing, while significantly reducing the <br\/>physical space requirement. A key architectural feature of <br\/>Mint is its use of mobile robots to carry wireless network <br\/>nodes, which can be programmatically controlled through a <br\/>serial port based API. The space requirement is \"miniaturized\"<br\/>by attenuating the radio signals in a controlled fashion. <br\/>Additionally Mint will also support automated fault <br\/>injection and analysis testing, remote testbed <br\/>reconfigurability, and autonomic 24x7 operation. The Mint <br\/>testbed will enable experimental investigation in a number <br\/>of research projects, such as, cross layer optimization,<br\/>optimal routing and transmission scheduling, effective <br\/>routing cost metrics, resource management for multi-channel<br\/>mesh networks, energy conservation for sensor networks, <br\/>scalable geographic-based service provisioning, and <br\/>modeling mobile low power wireless links. Our final <br\/>goal is to enable researchers to remotely access Mint <br\/>over the Internet in order to investigate their wireless <br\/>protocols in a miniaturized setting.","title":"Collaborative Research: CRI: IAD A Miniaturized Robotic Testbed for Development, Testing, and Evaluation of Protocols for Multi-Hop Wireless Networks","awardID":"0751161","effectiveDate":"2008-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["550962","451774"],"PO":["543539"]},"134458":{"abstract":"The Web has permeated every facet of human activity. Web 2.0 is bringing a sea-change, both by the amount of user-generated content and by the level of automation for information exchange. The goal of this project is to promote quality on the Web into a first-class citizen, by (1) exposing quality information from Web data sources; (2) empowering users to specify their preferences for the different dimensions of quality (Quality of Service, Quality of Data, Quality of Information) through an intuitive, integrated framework, called Quality Agreements (QAs); and (3) influencing resource allocation decisions according to user preferences.<br\/>Towards this, the project reexamines query processing techniques in order to consider QAs (namely, query and update scheduling, caching and replication, and admission control) and addresses new challenges, stemming from the users' need to adapt QAs over time and their ability to collaborate. Project plans include the validation of the QA framework with a user-study, the evaluation of the proposed algorithms analytically and experimentally, and prototype development. The experimental aspects of this research are directly linked to the educational goals of this project and will generate many opportunities for graduate, undergraduate, and high-school students to participate in the research and development of new technologies. This project will empower users to tailor quality on the Web according to their preferences, which in turn can have great implications on the usability of Web 2.0 applications and on users' experience and satisfaction. Results of this research, including software, data, and publications, will be made publicly available via the project web site (http:\/\/db.cs.pitt.edu\/user-centric).","title":"CAREER: User-Centric Data Management","awardID":"0746696","effectiveDate":"2008-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["532923"],"PO":["563751"]},"137659":{"abstract":"Abstract<br\/><br\/>Many imaging tasks involve ill-posed problems, which require realistic priors. Standard convex optimization techniques use priors that prefer globally smooth images, and thus tend to give poor results. Graph cut methods, which permit edge-preserving priors for a restricted class of ill-posed problems, have proven quite successful over the last decade.<br\/><br\/>This research project will address an important but challenging class of ill-posed problems, namely those arising from rank-deficient linear inverse systems. Such underconstrained problems occur in medical imaging tasks such as MRI&CT image reconstruction and fMRI undistortion, as well as in traditional vision problems such as super- resolution. Currently these applications rely on convex optimization methods, which do not support realistic image priors. Yet existing graph cut methods cannot be applied due to some difficult theoretical issues.<br\/><br\/>To overcome these challenges we propose a collaboration between computer vision researchers and experts in graph algorithms. We will develop new graph constructions to address linear inverse systems, drawing heavily on state-of-the-art techniques from boolean optimization. To simplify our task we will exploit specific properties of the rank-deficient linear inverse systems that arise in the applications of interest. We will focus primarily on sparse structured linear inverse systems, an important subclass which contains all of the applications that drive our work. While our proposed work stresses algorithm development, we will also do a significant experimental evaluation of new algorithms on a range of applications, both to assess their performance and to identify promising new avenues.<br\/><br\/>This project brings together experts in computer vision, medical imaging and graph algorithms to address a problem of broad interest in a novel manner. The linear inverse systems that we are concerned with arise in a wide range of medical applications, as well as in other areas, yet current techniques have significant shortcomings. Our approach draws heavily on methods developed by the investigators over the last decade, which have proven quite successful for related problems. In addition, this project will strengthen the ties between researchers in computer vision and algorithms, which have proven to be quite beneficial to both areas.<br\/><br\/>Publications and additional material resulting from this project will be made available at http:\/\/www.cs.cornell.edu\/~rdz\/graphcuts.html","title":"RI-Medium: Collaborative Research: Graph Cut Algorithms for Linear Inverse Systems","awardID":"0803444","effectiveDate":"2008-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["508076"],"PO":["564316"]},"140025":{"abstract":"Colloidal semiconductor nanocrystal quantum dots (NQDs) for novel<br\/>radiation detectors will be investigated. The team draws upon their expertise in the synthesis of PbSe\/PbS NQDs and their integration in optoelectronic devices to advance the technology of NQD-enhanced radiation detection. Nanostructure hererojunctions containing conductive polymers and PbSe NQDs will be investigated to develop gamma-ray PN-diode detectors. The proposed project will be groundbreaking as it will be the first time that the gamma-ray detection with PbSe QDs is investigated. The high-Z PbSe\/PbS NQDs in the &#947;-ray detector configuration will provide the ultimate solution to the desired sensitive, high resolution, and room-temperature detection of low-level radioactive signals.<br\/>These meta-metal materials do not exist in nature. Overcoming barriers to the growth of sensitive, room-temperature radiation sensor technology by employing colloidal compound QDs in the PN-diode device structure is a major step. A technical breakthrough such as low-level gamma ray detection will have a profound impact on national security and radioactivity-monitoring. The proposed studies will also provide focused research and learning experience to graduate and undergraduate students by involving them in experimental laboratory work, and bridge the fundamental nanoscience and engineering with the real-world applications.","title":"Metamaterial and quantum dots enhanced radiation and trace chemical detection [54U08UAHguo]","awardID":"0813870","effectiveDate":"2008-07-01","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"H188","name":"DEFENSE INTELLIGENCE AGENCY"}}],"PIcoPI":["516439",372089],"PO":["565136"]},"141389":{"abstract":"Proposal #: CNS 08-21622<br\/>PI(s): Fortes, Jose A.<br\/> McIntyre, Lauren M.; Moroz, Leonid L.; Principe, Jose C.; Sanchez, Justin C.<br\/>Institution: University of Florida <br\/> Gainesville, FL 32611-2002<br\/>Title: MRI\/Acq.: Instrumentation for Coupled Experimental-Computational Neuroscience and Biology Research<br\/><br\/>Project Proposed:<br\/>This project, acquiring a virtualized multicomputer instrument with shared-memory subsystems and storage capacity, intends to use this instrument as a shared instrument whose resources can be virtualized, reserved, and configured on demand for different research activities related to neuroscience, computational biology, and cyberinfrastructure. Its configurations can also be dedicated and tightly coupled to in vivo experiments using network connections to in situ instrumentation used for experiments. It can simultaneously support multiple research activities because of its unique capability to support real-time computer-in-the-loop experiments, its ability to run many concurrent computation threads, its shared memory and storage subsystems, and its use of virtualization technology to manage the coexistence of multiple computing environments. To develop and validate autonomic computing nodes and techniques for multiuser virtualized computational systems, the instrument provides traces of performance and other needed monitored data. Research activities in brain-machine interfaces, neurogenesis, genomics, bioinformatics, signal processing, cyberinfrastructure, autonomic computing and other areas include:<br\/>- Brain-machine interfaces where cortex models for motor control are dynamically learned and applied in real-time,<br\/>- Experimental drug discovery through real-time analysis of large amounts of genetic data and many thousands of compounds,<br\/>- Analysis of Terabytes of genetic data captured in real-time as a neuron grows, learns, and remembers, and<br\/>- Online learning algorithms using dynamic filter topologies with online computation requirements that increase over time.<br\/>The activities have transformative goals, including the introduction of real-time, and address the high performance computation into closed-loop experiments and\/or systems whose behavior is driven by complex processing of sensed data. Another goal involves providing off-line computing capabilities to match the unprecedented rate and volume of genetic data produced by massively parallel DNA sequencing technology.","title":"MRI: Acquisition of Instrumentation for Coupled Experimental-Computational Neuroscience and Biology Research","awardID":"0821622","effectiveDate":"2008-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["540130","438490","526138","549967",376147],"PO":["557609"]},"135405":{"abstract":"Simulation tools for wireless networks do not accurately <br\/>capture the behavior of wireless protocols in real-world <br\/>deployments. On the other hand, physical testbeds spanning <br\/>large geographic areas are expensive to deploy, manage, <br\/>and reconfigure. We propose to develop a miniaturized <br\/>multi-hop wireless testbed, called Mint, that will provide <br\/>a flexible and high-fidelity platform for protocol development, <br\/>debugging, and testing, while significantly reducing the <br\/>physical space requirement. A key architectural feature of <br\/>Mint is its use of mobile robots to carry wireless network <br\/>nodes, which can be programmatically controlled through a <br\/>serial port based API. The space requirement is \"miniaturized\" <br\/>by attenuating the radio signals in a controlled fashion. <br\/>Additionally Mint will also support automated fault <br\/>injection and analysis testing, remote testbed <br\/>reconfigurability, and autonomic 24x7 operation. The Mint <br\/>testbed will enable experimental investigation in a number <br\/>of research projects, such as, cross layer optimization, <br\/>optimal routing and transmission scheduling, effective <br\/>routing cost metrics, resource management for multi-channel <br\/>mesh networks, energy conservation for sensor networks, <br\/>scalable geographic-based service provisioning, and <br\/>modeling mobile low power wireless links. Our final <br\/>goal is to enable researchers to remotely access Mint <br\/>over the Internet in order to investigate their wireless <br\/>protocols in a miniaturized setting.","title":"Collaborative Research: CRI: IAD A Miniaturized Robotic Testbed for Development, Testing, and Evaluation of Protocols for Multi-Hop Wireless Networks","awardID":"0751121","effectiveDate":"2008-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[359707,"563568","540553",359710],"PO":["543539"]},"138837":{"abstract":"The proposed research exploits an idea of John Tukey that was never published. Called scagnostics (a Tukey neologism for \"scatterplot diagnostics\"), the original idea leads to a more general characterization of high-dimensional point sets using visually-based geometric and graph-theoretic measures. These measures comprise a canonical set of 9 features of pointwise data typically observed by experienced statisticians. Computing these measures on all possible 2D axis-parallel orthogonal projections in a p-dimensional space results in a p(p- 1)\/2 \u00d7 9 matrix of measures. The objective of the proposed research is to generalize scagnostics to a new approach called Visual-Model-Based Transformations (VMBT). Visually-based transforms, together with multivariate analyses, can reveal visual patterns that are of interest to analysts. When interesting patterns are discovered in transform-space, one can invert the map and infer patterns in the raw data space.<br\/><br\/>Scagnostics exploits an important aspect of visualizations. A visualization can be thought of as a visual representation of an underlying mathematical model. Even simple charts of raw data rest on a model that helps (one hopes) to reveal some interesting aspect of the data. We often take these models for granted when we view familiar graphs. However, understanding mathematical models underlying visualizations can help us to devise more effective models for revealing structure in more complex datasets. Visual-Model-Based Transformations are a class of models that may prove especially effective for this purpose. Such models are motivated by visual structures perceived and processed by analysts. Given this visual motivation behind their design, visual models are likely to reveal features of data that are quite different from those appearing in common statistical and scientific graphics.","title":"Visually-Motivated Characterizations of Point Sets Embedded in High-Dimensional Geometric Spaces","awardID":"0808860","effectiveDate":"2008-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7703","name":"FOUNDATIONS VISUAL ANALYTICS"}}],"PIcoPI":["530054","533353","563293"],"PO":["565286"]},"141005":{"abstract":"NSF Proposals 0820198\/0820138<br\/><br\/>Title: Process-Centered, Analysis-Driven System Development Applied to Human-Intensive Medical Processes<br\/><br\/>PIs: Lori Clarke, Philip Henneman, George Avrunin, Elizabeth Henneman, and Leon Osterweil<br\/><br\/>This project presents a new approach to developing human-intensive systems in which the coordination among human participants, hardware devices, and application software systems are specified in an executable, process-definition language. Process definitions are subjected to rigorous analysis in order to detect defects and evaluate proposed improvements. Such validated process definitions can then be used to drive simulations and train process participants. The proposed approach is to be evaluated by developing a process support environment that is then used to define and analyze medical processes. Medical processes provide a particularly good evaluation domain as they are human-intensive, involve diverse software applications and hardware devices, and are both safety critical and error prone. Separating and rigorously analyzing the coordination aspects of complex, human-intensive systems represent a paradigm shift from current development practices. This approach provides a strong technical and methodological basis for the engineering of human-intensive systems, leading to systems that are scalable, understandable, and able to amplify human efficacy and control. Finally, this process-centered approach has the potential to improve the quality and reduce the cost of medical care.","title":"Collaborative Research: Process-Centered, Analysis-driven System Development Applied to Human-Intensive Medical Processes","awardID":"0820198","effectiveDate":"2008-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7724","name":"SOFTWARE FOR REAL-WORLD SYSTMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["536735","524459","536736","536737"],"PO":["564388"]},"136605":{"abstract":"This project studies creativity in improvisation in both standard theatrical techniques where a script's interpretation, including the physical performance, is improvised by an actor, and \"improv theatre\" where entire scenes are created by actors in real-time through improvisation. This research will increase the state of knowledge about improvisation, creativity, and intelligent agent design, as well as contribute meaningfully to theoretical and academic understanding of creative practice in theatre. In addition to integrating engineering scientific methods with the theory and practice of acting, this research will contribute cognitive and computational models of improvisation, emotion, acting styles, and problem-solving in the context of theatre. These models will pave the way to the development of more sophisticated synthetic characters, virtual humans, and other intelligent autonomous agents that can interact with humans and with each other for purposes of entertainment, education, and training.","title":"MAJOR: Collaborative Research: Modeling Creative and Emotive Improvisation in Theatre Performance","awardID":"0757567","effectiveDate":"2008-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7788","name":"CreativeIT"}}],"PIcoPI":["550869","550870","561204"],"PO":["564456"]},"136528":{"abstract":"When people reformulate a problem space, previously unseen structure emerges. This process can be decomposed into two steps: People must first recognize and then exploit novel structure. We suggest that both of these steps can be improved by experienced application of creative nominalization. Here, nominalization refers to the process of recognizing a novel concept and naming it appropriately. This project demonstrates that experience in nominalization can improve problem solving and that successful training and experience on nominalization has the potential to enhance people?s intrinsic motivation, and thereby effectiveness, with respect to creative aspects of problem solving. In parallel, the project explores the potential for nominalization as a strategy to enhance machine-learning agents in reinforcement learning environments. Inspired by research on animal learning, reinforcement learning is a branch of artificial intelligence research concerned with creating motivated, learning agents. In the reinforcement-learning setting, nominalization has the potential to create a first-class object, something that can be directly manipulated, recorded, analyzed, and composed with other objects to form higher-order structures. In addition, reinforcement-learning researchers have recently begun to consider how learning might be enhanced with intrinsic motivation to explore problem spaces. Thus nominalization can function in reinforcement-learning settings both as a direct strategy and indirectly via intrinsic motivation. The most significant broader impact of this project will be to provide a new intervention that will enhance the creativity and efficacy of problem solvers working alone or in collaborative groups. If successful, the relative simplicity of the intervention and its general applicability would make it a prime candidate for wide dispersal to people in disparate walks of like.","title":"Collaborative Research: Pilot Research on Language-Based Strategies for Creative Problem Solving","awardID":"0757193","effectiveDate":"2008-07-01","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7788","name":"CreativeIT"}}],"PIcoPI":[362801],"PO":["424970"]},"140994":{"abstract":"Proposal 0820133<br\/><br\/>Title: Supporting Software Evolution by the Combined Analysis of Textual and Structural Information<br\/><br\/>PIs: Andrian Marcus and Vaclav Rajlich, Wayne State University<br\/><br\/>Software evolution is a demanding stage of the software lifecycle as it requires extensive knowledge about the application domain and about all the artifacts that have been produced. This includes knowledge about the software components and their dependencies which can be extracted from compiler-centered information. It also includes knowledge about the intent of these components which is human-centered information expressed in textual form in software. This project will investigate how these two kinds of information interact, how they complement each other, and how they can be jointly utilized during software evolution. The research will define and evaluate a new model for the comprehensive static analysis of source code which places textual information on similar footing with the results of classical program analysis. The proposed model will use program dependency analysis and text retrieval techniques. Using the new analysis, novel methodologies for the activities of software change, namely, concept location and impact analysis will be defined and evaluated. The new analysis will help humans increase their knowledge about the software and improve their communication about the intent of the software. It will be specifically useful for the analysis of software built from many heterogeneous components, written and designed by many developers, and operating on various platforms.","title":"SRS-CCF: Supporting Software Evolution by the Combined Analysis of Textual and Structural Information","awardID":"0820133","effectiveDate":"2008-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7724","name":"SOFTWARE FOR REAL-WORLD SYSTMS"}}],"PIcoPI":[374749,"511418"],"PO":["564388"]},"141259":{"abstract":"Proposal #: CNS 08-21132<br\/>PI(s): Girvin, Steve M.<br\/> Basu, Sarbani; Batista, Victor S.; Ismail-Beigi, Sohrab; Smooke, Mitchell D.<br\/>Institution: Yale University <br\/> New Haven, CT 06520-8337<br\/>Title: MRI\/Acq.: Acq. of a High Performance Computational Cluster for Yale University<br\/>Project Proposed:<br\/>This project, acquiring instrumentation for a large-scale computing system, enables research in the physical, biological, and social sciences, as well as engineering, linguistics, statistics, and many other fields, under the umbrella of a High Performance Computing (HPC) Center. The instrumentation complements the Biomedical HPC center. Supported by the Information Technology Services (ITS), these centers are considered a single virtual unit. This work services 52 research projects from faculty in 22 departments including physical sciences, engineering, linguistics, mathematics, ecology, economics, psychology, statistics, and the biological sciences. The very diverse research covers a wide range of topics from cosmological simulations to climate modeling, to neural circuit networks and simulation of internal dynamics, to economic modeling, to name a few. The research is supported by more than 35 current and more than 20 pending projects. Research computational scientists assist with the instrumentation, teach parallel programming techniques, optimize current code, and write new codes to support individual projects. The diverse needs capable of handling both CPU and memory bound tasks along with substantial mass storage and communication infrastructure will most likely be covered by a large CPU cluster consisting of 350 nodes with 16GB of memory shared by 8 cores per node and a large memory cluster consisting of 28 nodes sharing 7,168 GB memory. This 10-fold more CPUs, increased memory, and mass storage are expected to be heavily utilized and have immediate impact in research and education.<br\/><br\/>Broader Impacts:<br\/>The instrumentation leverages individual research of more than 350 faculty, research and postdoctoral staff, and graduate and undergraduate students. The latter will be able to train and learn how to optimally use such a facility. New courses will be developed for undergraduates focusing on HPC for nanoscale and biological systems. The institutional outreach program involves Howard and Xavier universities. Faculty from these universities will be trained via summer internships and allocated time in the HPC facilities.","title":"MRI: Acquisition of a High Performance Computational Cluster for Yale University","awardID":"0821132","effectiveDate":"2008-07-15","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["480606","516135","541653","558546","524186"],"PO":["557609"]},"143118":{"abstract":"Identification and Sensitivity Analysis of Complex Interaction Networks<br\/>Complex networks, consisting of interacting elements linked together with processing units, are ubiquitous across many disciplines of modern science and engineering. Examples include biochemical reaction networks, cellular networks, epidemiological networks, social networks, organizational networks, power distribution networks, as well as internet and mobile cellular networks. However, knowledge of the organizational structure and functional properties of most networks is very limited. Due to high complexity, elucidating the physical principles and structural mechanisms underlying interaction networks is a very difficult task, which requires collection and systematic analysis of large amounts of data. As a consequence, there is a general consensus that the development of a scientifically rigorous approach to studying interaction networks is urgently needed.<br\/>The main goal of this research is to develop a general statistical signal processing methodology for model-based identification and analysis of complex nonlinear interaction networks from incomplete and noisy observations. The investigators study rigorous theoretical and computational techniques for estimating the structural and dynamic properties of interaction networks by state-of-the-art identification and model selection methodologies, and for studying network robustness via probabilistic sensitivity analysis. To achieve computational efficiency, a ?two-phase? approach to network identification is employed, guided by sensitivity analysis. This approach effectively exploits the fact that complex interaction networks are robust to most parameters. The objective of the first phase is to quickly estimate the values of the unknown network parameters from available measurements without much concern for their accuracy. The objective of the second phase is to use sensitivity analysis to accurately estimate the values of a small number of ?influential? parameters by using more informative observations of network behavior obtained by selective perturbations.","title":"Identification and Sensitivity Analysis of Complex Interaction Networks","awardID":"0830128","effectiveDate":"2008-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["517652"],"PO":["564898"]},"139928":{"abstract":"National Science Foundation <br\/>CISE\/CNS<br\/><br\/>Abstract<br\/><br\/>Proposal Number: 0813561<br\/>PI: Romit Roy Choudhury <br\/>Institution: National Science Foundation <br\/><br\/>Title: Student Travel Grant to Attend IEEE Secon 2008<br\/><br\/><br\/>Abstract:<br\/><br\/>The purpose of this grant is to support graduate students towards traveling and attending the 5th IEEE SECON 2008 conference. IEEE SECON is a conference that serves as a meeting point of researchers from academia and industry, as well as practitioners in diverse fields of computer networking. Travel grant opportunities will allow students to participate in this forum, and gain valuable experiences by interacting with senior researchers in this field. Such interactions can positively influence the quality of the students' individual research, in turn shaping the future of wireless networking technology.","title":"Student Travel Grant to Attend IEEE Secon 2008","awardID":"0813561","effectiveDate":"2008-07-01","expirationDate":"2008-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["462630"],"PO":["434241"]},"143944":{"abstract":"The PIs and Co-PIs of grants supported through the NSF-NIH Collaborative Research in Computational Neuroscience (CRCNS) program meet annually. This will be the fourth meeting of CRCNS investigators. The meeting brings together a broad spectrum of computational neuroscience researchers supported by the program, and includes poster presentations, talks and plenary lectures. The meeting is scheduled for June 1-3, 2008 and will be held at the University of Southern California.","title":"CRCNS 2008 P.I. Meeting","awardID":"0834005","effectiveDate":"2008-07-01","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}}],"PIcoPI":["549488"],"PO":["564318"]},"142998":{"abstract":"This CPATH Community Building project creates a framework for incorporating computational thinking principles and learning environments across the Liberal Studies curriculum at DePaul University. It includes outreach to other institutions in the greater Chicago region to build a computational thinking community. The project includes activities to investigate and formalize the use of computational thinking, to evaluate the learning of computational thinking, to disseminate results and resources, and to build an external computational thinking community.<br\/> <br\/>The intellectual merit of the project lies in the importance and currency of the topic and clear need for such changes in computing education to prepare the upcoming generation of computing professionals. The strong interdisciplinary project team has significant experience in educational innovation. The project has the potential to produce a much needed computational thinking framework that can be used for transforming general education content and courses across the nation.<br\/><br\/>The broader impacts of the project lie in the potential to prepare a diverse student population for computational intense courses and curricula where they learn computational thinking methodologies that transfer directly to their professional lives. The project includes dissemination to a broad community and opportunities for sharing of resources. There is potential for national models that can help to develop a computing-savvy workforce which is vital to the nation's continued prosperity and security.","title":"CPATH CB: Computational Thinking Across the Curriculum","awardID":"0829671","effectiveDate":"2008-07-15","expirationDate":"2011-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":[380742,380743],"PO":["564181"]},"134605":{"abstract":"Award Abstract for CAREER proposal 0747541<br\/><br\/>In this project we design efficient secure algorithms for various multi-party protocol tasks. The protocols must be provably secure based on well-understood cryptographic assumptions, they need to satisfy requirements imposed by the real-world applications of these protocols, and they need to be efficient enough to be usable in practice.<br\/><br\/>Among the protocol tasks we address are private authentication schemes, aggregate signature schemes, dynamic group key agreement schemes, and proactive cryptosystems. The challenge in designing such protocols is to achieve efficiency without making assumptions that would impede the adoption of these protocols in practice. For example, protocols that rely on a public key infrastructure cannot assume universally trusted authorities, and they should remain efficient if protocol participants hold certificates from multiple sources. Moreover, to be truly useful a multi-party protocol must remain efficient in realistic communication conditions, e.g. if the participating nodes do not have synchronized clocks, or if the communication mechanism between any two protocol participants can be disrupted.<br\/><br\/>Development of efficient secure multi-party protocols which meet these efficiency goals and operational requirements relies on construction of public key primitives with novel security properties, and on finding new approaches to fundamental questions related to multi-party protocols, e.g. fairness, limitations imposed by trust assumptions, and security under protocol composition.<br\/><br\/>This project can also have an immediate impact on a variety of computer systems, improving their reliability, security, and privacy properties. Examples of prospective applications of our protocols are provision of fault-tolerant security services, and enabling of group-wide security mechanisms in ad-hoc and mobile networks.","title":"CAREER: Secure Multi-Party Protocols","awardID":"0747541","effectiveDate":"2008-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[357777],"PO":["497499"]},"140963":{"abstract":"Proposal Number: 0820004\/0819929<br\/><br\/>TITLE: Abstraction-Based Motion Programs for Complex, Interconnected Systems<br\/><br\/>PIs: Magnus Egerstedt and Todd Murphey<br\/><br\/>Systematic approaches to abstraction-based motion control of complex, physical systems are still largely missing from the control-theoretic foundations of embedded system design. Examples of high-degree of freedom physical systems include humanoids, multi-leg robots, minimally-invasive surgical robotics, and cooperative systems. This work aims at understanding how high-level motion program languages can be made to form a basis for an effective software system for such complex, interconnected mechanical systems. For this, novel tools and techniques are to be developed along the following directions: 1) construction of motion description languages based on optimal control techniques; 2) development of a novel, graph-based representation of mechanical systems that allows for a compact representation of mechanical systems for simulation and analysis; 3) automatic generation of dynamically feasible motion primitives from empirical data; 4) development of an experimental testbed based on autonomous marionette puppets that can execute the developed motion programs--this testbed will also serve as a unique learning environment for students in that it requires an understanding of highly nonlinear dynamic systems, networking architectures for synchronization, hybrid systems, and optimal control.","title":"Collaborative Proposal: Abstraction-Based Motion Programs for Complex, Interconnected Systems","awardID":"0820004","effectiveDate":"2008-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7724","name":"SOFTWARE FOR REAL-WORLD SYSTMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["553540"],"PO":["564388"]},"142988":{"abstract":"This Conceptual Development and Planning project integrates sustainability concepts throughout undergraduate computing education. An interdisciplinary team of faculty from engineering, computer science, and cognitive science plans to test, develop, implement, and evaluate an educational model for sustainability integration into the curriculum. The team plans to develop models, projects and courses for beginning and upper level students, including a new course in green computing. The group envisions a focus on the power consumption of large data centers aspects of sustainability. The goal is to prepare students with the computing competencies, multi-disciplinary knowledge, and computational thinking methodologies to create a sustainable future. <br\/><br\/>The intellectual merit of the project lies in the importance and currency of the topic and clear need for such changes in computing education to prepare the upcoming generation of computing professionals. The cross-disciplinary project team includes researchers with significant expertise in both the computing discipline research that underlies the implementation and in educational innovation. The project has the potential for providing new research models in an emerging field critical for future generations as well as the current one.<br\/><br\/>The broader impacts of the project lie in the potential to address changing demands on computing professionals and to attract a diverse audience of students. The project has the potential to provide innovative models for transforming computing education that are of value to other colleges and universities across the nation.","title":"CPATH CDP: Integrating Sustainability Into Undergraduate Computing Education","awardID":"0829619","effectiveDate":"2008-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["444423","528843","253101",380698,"385325","545821"],"PO":["564181"]},"143989":{"abstract":"This project will fund the development of components and their integration for Spiral 1 of an end-to-end prototype of a suite of network infrastructure that would enable researchers to carry out novel network science and engineering experiments, i.e., to do science that currently can not be done. Spiral 1 will attempt a first, trial integration and operation of components on multiple national backbones. Spiral 1 will be developed as quickly as possible to identify and reduce programmatic and technical risk and to help the research community achieve a shared vision by providing a working prototype. It will stimulate broad community participation and build a strong academic and industrial base. Twenty-nine projects, working in five teams will compete in the design and implementation of the network infrastructure control framework. System engineers will perform top-down integration planning and project guidance. While a well-integrated, orderly system may not be possible until Spiral 2 or 3, Spiral 1 will take the critical first step towards creating this radically new kind of experimental infrastructure with end-to-end, virtualizable, and sliceable capabilities, which are entirely novel. Once this first spiral exists, it will co-evolve with the community?s emerging research and education agenda. The larger impacts are potentially huge, allowing for transformative research in network science and engineering that has never been done before.","title":"Design and Prototyping Risk Reduction","awardID":"0834243","effectiveDate":"2008-07-15","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7917","name":"NetS RESEARCH RESOURCES"}}],"PIcoPI":["521729"],"PO":["564993"]},"142669":{"abstract":"Description<br\/><br\/>Redistricting occurs every 10 years following the decennial census. Ideally, the resulting districts are created to provide fair representation for each citizen. In the current system, however, the redistricting process has been open to manipulation. Although the process will always involve partisan and interested parties, a free and widely accessible computational tool that provides access to all relevant data and enables users to explore the universe of possible redistricting plans would make the process more transparent and would engage a broader array of citizens. Such a tool could also provide a forum for state representatives and decision-makers to use when discussing and negotiating redistricting plans. The long-term goal is to allow for the consideration of multiple objectives and parameter weights when evaluating redistricting plans; plans can be compared based on all these criteria. As a small exploratory grant with a one year life, the work will be limited to the formulation of the redistricting problem as a discrete optimization problem, which is essential to further progress on the broader project. <br\/><br\/>Intellectual Merit<br\/><br\/>The results of this research will provide a quantitative tool for comparing, evaluating, and creating redistricting plans intended to optimize speci&#64257;ed criteria. In this mathematical formulation, powerful tools from computational complexity theory and discrete optimization can be adapted to identify previously unseen or ignored insights into the redistricting process and to identify gerrymanders; these goals would be infeasible otherwise. A cross-disciplinary team will be brought to bear, including a political scientist, a computer scientist, and a mathematician. <br\/><br\/>Broader Impact<br\/><br\/>In the long term, a cyberenvironment developed for redistricting will have a signi&#64257;cant impact on public policy, research, and education. In public policy, there is the potential to fundamentally transform the redistricting process by providing a widely accessible objective tool to open the redistricting process to participation by a broader and more diverse group of interested stakeholders. Such a cyberenvironment will have a clear educational impact, as K?12 students will be able to visualize the redistricting process, providing them with a richer understanding of democracy and allowing them to approach social science in the context of computation.","title":"SGER-III-CXT: A Computational Appraoch to Zoning Analysis","awardID":"0827540","effectiveDate":"2008-07-01","expirationDate":"2009-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["565139","392757"],"PO":["563727"]},"144319":{"abstract":"This SGER project seeks to determine the scalability of computationally intensive, iterative statistical learning algorithms on a MapReduce architecture. Such algorithms underlie much research in natural language processing, yet their scalability to even moderately large training datasets (text corpora) has been under-explored. On the surface, scaling to more data appears to be a good fit for the MapReduce paradigm, and this exploratory project aims to identify whether such algorithms benefit from more data and more complex data than used in prior work. A special emphasis is given to unsupervised learning algorithms, such as the Expectation-Maximization algorithm, which have been widely studied on small problems and rarely studied on large ones. The technique is applicable to many other methods, as well.<br\/><br\/>At the same time, the project seeks to explore how to leverage supercomputers and MapReduce to make these learning algorithms faster, permitting a faster research cycle. Concretely, the \"E step\" (or its<br\/>analogue) is the most computationally demanding part of an iteration, but the standard assumption that the training data are independently and identically distributed permits parallelization. To the extent that this parallelization is affected by network and input-output overhead, each iteration of training may be made faster, perhaps reducing training time from days or weeks to hours. This project explores this tradeoff and others like it.<br\/><br\/>This work leverages a resource donated by Yahoo for use by the PI's research group: a 4,000-node supercomputer running Hadoop (an open-source implementation of MapReduce).","title":"SGER: Scaling up unsupervised grammar induction","awardID":"0836431","effectiveDate":"2008-07-01","expirationDate":"2009-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["563246"],"PO":["565215"]},"144914":{"abstract":"0838746<br\/>Karen Sollins<br\/><br\/><br\/>The 2008 ACM Conference on Communications Architectures, Protocols and Applications will be held in Seattle, WA, August 17-22, 2008. This conference is the premier technical meeting that examines the state-of-the-art in computer networks and communications. This award provides funding to assist approximately 16 United States-based (including Puerto Rico) graduate students as well as approximately 2 U.S.-based under-represented minority (including women) faculty members or faculty members of U.S. institutions that are primarily serving under-represented minorities in attending this meeting. Participation in conferences such as SIGCOMM is an extremely important part of the graduate school experience, as well as an important part of the teaching and research in data networking. It provides the opportunity to interact with more senior researchers and to be exposed to leading edge research in the field. The support requested in this proposal will enable the participation of students and minority or minority serving faculty members who would otherwise be unable to attend AMC SIGCOMM 2008. The Travel Grant committee and SIGCOMM are committed to encouraging the participation of women and under-represented minorities.<br\/><br\/>Intellectual Merit: This project proposes to provide travel support for graduate students and minority and minority-serving faculty members to attend SIGCOMM 2008. This will expose them to new ideas and allow for interaction with other researchers.<br\/><br\/>Broader Impact This project integrates research and education of students through exposure to the premier technical meeting in computer networks and communications. Students and minority faculty will have the opportunity to observe high-quality presentation and interact with senior researchers in the field. The proposed student participation will have positive impact on students? interest and the quality of their research. The faculty participation will have an impact on teaching, the quality of the research and on their own students? research in their home institutions.","title":"Student and Minority Faculty Travel Support for ACM SIGCOMM 2008 Conference; Seattle, Washington; August 17-22, 2008","awardID":"0838746","effectiveDate":"2008-07-15","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["125800"],"PO":["565090"]},"141506":{"abstract":"International Conference on Mobile Ad-Hoc and Sensor Systems (MASS) is an emerging conference in the area of mobile and sensor networks. MASS is fully sponsored by IEEE Computer Society. This conference traditionally brings together researchers in the broad field of wireless and sensor networks. Earlier research on wireless networks and mobile computing has concentrated on single-hop networks, where network nodes communicate directly with a fixed infrastructure, such as cellular or satellite systems. However, multi-hop communication needs to be supported in conferences, hospitals, battlefields, rescue operations, and monitoring scenarios, where network nodes communicate via other network nodes. More recently, wireless community networks (a. k. a. wireless mesh networks) have been proposed as alternatives for providing Internet access in new (business and residential) areas. This conference aims to address multi-hop ad-hoc and sensor networks systems, covering topics ranging from physical issues to the applications aspects. <br\/><br\/>Participation in conferences such as IEEE MASS is an extremely important part of the graduate school experience, providing the opportunity to interact with peers and more senior researchers, thus having the opportunity to be exposed to leading edge work in the field of wireless and sensor networks. The travel support will enable US-based graduate students to attend and present their research results in this important IEEE conference. Since the travel support in most of the NSF awards is quite limited to students (who are authors), this fund will enable the awardees not to divert research funding for travel.","title":"Travel Support for MASS 2008 Conference; Atlanta, GA; September 29 to October 2, 2008","awardID":"0822083","effectiveDate":"2008-07-01","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["402054"],"PO":["564777"]},"144908":{"abstract":"New Mexico State University proposes to explore the potential for an intervention that would increase the numbers of physically disabled persons, specifically those with spinal cord injuries (SCI), who participate in computing-related degree programs and careers. They propose to implement an introductory computer course that is integrated into the context of a rehabilitation (rehab) hospital. By choosing this venue, disabled persons will be introduced to computing rather than leaving the introduction to chance. Further, by focusing on the spinal cord injured population, a large percentage of the target group will be of college and\/or working age. The program will be coordinated with hospital staff and integrated into patient education received during rehabilitation. The course will cover the basic computer use and the use of assistive technology, web development and programming using the Alice programming language. This award will pilot the course three times and will develop a plan to seek further funding in order to improve and scale the program to reach a wider community, including military rehabilitation facilities.","title":"SGER: Project ENABLE: Enabling the Disabled Greater Participation in Computing through Early Intervention","awardID":"0838726","effectiveDate":"2008-07-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}}],"PIcoPI":["557314"],"PO":["561855"]},"138181":{"abstract":"This project will study problems that occur in the design of computer and physical experiments and the analysis of their output. Physical experiments are the gold standard for measuring input-output relationships but these measurements that contain noise and possibly unrecognized sources of bias. Computer codes that model input-output relationships are used increasingly in place of, or in conjunction with, physical experiments because of they can provide decreased lead times in the engineering design of manufactured goods as well as for the assessment of designs in varying field-use conditions and varying conditions of fabrication. In general a deeper understanding of product and process performance can be made by using a combination of computer and physical experiments. However, computer codes provide a biased measurement of input-output relationships because of the inevitably inadequate physics or biology used in their development. This proposal will address the following problems that arise from the challenges sketched above. 1. To increase the computational efficiency of screening methodology for identifying the most important inputs to a computer code. 2. To develop methodology for estimating the upper (or lower) percentile of a computer code output with respect to the distributionof the field inputs. 3. To estimate the set of Pareto optimal input values for multivariate computer output and the corresponding Pareto Frontier of output vectors corresponding to the Pareto optimal inputs. 4. To develop statistical methodology for simultaneous determination of calibration<br\/>parameters and tuning inputs for computer models, including those with mixed quantitative and qualitative inputs.<br\/><br\/>Experimental modeling using computer codes is increasingly prevalent in engineering, in biomechanics, in the physical sciences, in the life sciences, in economics, and other areas of natural science such as the assessment of climate change and cosmology. Over the past twenty years, the use of computer codes as experimental tools has become increasingly sophisticated due to the fact that the number of inputs to such codes has steadily increased as well as the level of detail embodied by the codes. Researchers can now vary both ``engineering'' inputs as well as inputs that describe the operating conditions in the model. In addition, more detailed mathematical models of the input-output relationship as well as more accurate numerical solution of these models often produce codes that require 5-24 hours for a single run. In addition, multiple codes are often used to describe different aspects of the phenomenon being studied. This project will study problems that occur in the design of experiments involving such computer codes including screening the important inputs to such codes to determine important inputs, the efficient use of code output for optimization and other problems, and the calibration of corresponding physical experiments to further improve their prediction accuracy.","title":"Topics in Computer Experiments","awardID":"0806134","effectiveDate":"2008-07-15","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1269","name":"STATISTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["545980","545981"],"PO":["565309"]},"148390":{"abstract":"CBET-0852790<br\/>Lauga<br\/><br\/>This grant addresses the locomotion of swimming microorganisms near deformable and rigid interfaces. Most microorganisms spend much of their lives near interfaces such as soft biological surfaces (e.g. blood vessels, muscle tissue and the epithelium), rigid boundaries, and air-water interfaces. These surfaces may be characterized by complex topography, malleability and complex physicochemical characteristics. In addition to impacting the hydrodynamic stresses encountered by a swimming cell, these boundaries may affect the local concentration of chemical species including nutrients, oxygen levels and pH, consequently modifying the behavior of neighboring organisms. The research addresses a number of unsolved scientific problems through a combination of asymptotic analysis, numerical computations and experiments. Despite its prevalence and importance in a variety of ecosystems and medical applications, the dynamics of self-propelled microorganisms near boundaries remains largely unexplored. The investigators address a number of fundamental questions regarding the physical interactions between swimming cells and their environment. The required interdisciplinary work lies at the frontier of Engineering, Mathematical Sciences and Biology and combines theory, experiment and computation: this is a realm where the fundamental problems addressed herein are closely related to many natural phenomena and technological applications. Small scale locomotion at interfaces has important implications in microbiological applications including control and understanding of surface-associated infections (e.g. the most common hospital-acquired infection, catheter-associated bacteriuria), biofilm formation, and biodegradation (e.g. using bacteria at polluted sites to metabolize undesirable compounds). Knowledge gained through this research has the potential to impact biomedical applications and environmental technologies. For example, bacteria in biofims are more difficult to treat with antibiotics costing the U.S. billions of dollars every year in equipment damage, product contamination and medical infections. The societal benefits associated with the ability to understand and eventually suppress this type of film formation are significant. Educational impact includes the development of a new graduate-level course on biolocomotion, jointly taught by all three investigators, and the interdisciplinary training of graduate students jointly supervised by faculty in the Departments of Mathematics and Mechanical Engineering.","title":"Life at the Interface: Biolocomotion Near Boundaries","awardID":"0852790","effectiveDate":"2008-07-01","expirationDate":"2009-09-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1443","name":"FLUID DYNAMICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"7446","name":"MATH PRIORITY SOLICITATION"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1266","name":"APPLIED MATHEMATICS"}}],"PIcoPI":["511925"],"PO":["525323"]},"139361":{"abstract":"This project has involves research on several fronts in binary trees and algorithms for their efficient use. Rotations are small changes to binary tree structures used in balancing and optimizing search trees for efficient searching. The rotation distance between two trees is the minimal number of such small changes required to transform one tree into another. There are no known algorithms for computing rotation distances effectively, and even precise bounds on rotation distance are difficult to obtain. This project develops methods for improving understanding of rotation distances and algorithms for computing or estimating them. This research involves experiments to understand the general properties of rotation distances, as well as developing abstract methods for describing rotation distances based upon connections between rotation distances and geometric methods in group theory.<br\/><br\/>This project seeks to improve methods and understanding of binary trees and relevant algorithms. Binary trees are a fundamental structure, underlying efficient storage of data sets for quick retrieval of items. The amount of data routinely used in modern scientific and engineering settings is often staggeringly large. Biological data sets, for example, are often gigabytes of data. When working with large data sets, the efficiency of methods used to analyze the data is of crucial importance- many questions which are immediate for small data sets are far beyond the capability of even today's most powerful computers for even moderate-sized data sets. Careful organization of large data sets is essential for productive investigation","title":"Experimental and Theoretical Approaches for Efficient Tree Distance Algorithms","awardID":"0811002","effectiveDate":"2008-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7351","name":"THEORETICAL FOUNDATIONS (TF)"}}],"PIcoPI":["473207"],"PO":["565027"]},"144290":{"abstract":"This Small Grant for Exploratory Research is investigating a framework of learning and unlearning algorithms that can be used for identifying noise robust auditory features.<br\/>Even though most speech based recognition systems deliver robust performance under controlled laboratory conditions, their performance degrades significantly in presence of noise primarily due to mismatch between training and deployment conditions. The proposed exploratory study investigates the possibility of using information embedded in higher-order spectral and temporal manifolds which could remain intact even in the presence of ambient noise. Estimation of these non-linear manifolds in presence of noise, however, poses a significant challenge and is the focus of this study. We are investigating proof-of-concept features based on cooperative learning-unlearning (CLU) algorithms that estimates manifold parameters in a reproducing kernel Hilbert space (RKHS) spanned by speech signals. We are evaluating the robustness of these features in presence of room acoustics and background noise. The broader impact of this exploratory study will be development of enabling technology that can be used in the area of voice based biometrics, where seamless authentication can be performed over the internet, cell phones or other voice based media. The educational impact of the study includes graduate student training and development of public domain software tools for CLU algorithms which will be available to the scientific community.","title":"SGER: Cooperative Learning-unlearning Algorithms for Identification of Robust Auditory Manifolds","awardID":"0836278","effectiveDate":"2008-07-01","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["491679"],"PO":["565215"]},"136590":{"abstract":"When people reformulate a problem space, previously unseen structure emerges. This process can be decomposed into two steps: People must first recognize and then exploit novel structure. We suggest that both of these steps can be improved by experienced application of creative nominalization. Here, nominalization refers to the process of recognizing a novel concept and naming it appropriately. This project demonstrates that experience in nominalization can improve problem solving and that successful training and experience on nominalization has the potential to enhance people?s intrinsic motivation, and thereby effectiveness, with respect to creative aspects of problem solving. In parallel, the project explores the potential for nominalization as a strategy to enhance machine-learning agents in reinforcement learning environments. Inspired by research on animal learning, reinforcement learning is a branch of artificial intelligence research concerned with creating motivated, learning agents. In the reinforcement-learning setting, nominalization has the potential to create a first-class object, something that can be directly manipulated, recorded, analyzed, and composed with other objects to form higher-order structures. In addition, reinforcement-learning researchers have recently begun to consider how learning might be enhanced with intrinsic motivation to explore problem spaces. Thus nominalization can function in reinforcement-learning settings both as a direct strategy and indirectly via intrinsic motivation. The most significant broader impact of this project will be to provide a new intervention that will enhance the creativity and efficacy of problem solvers working alone or in collaborative groups. If successful, the relative simplicity of the intervention and its general applicability would make it a prime candidate for wide dispersal to people in disparate walks of like.","title":"Collaborative Research: Pilot Research on Language-Based Strategies for Creative Problem Solving","awardID":"0757490","effectiveDate":"2008-07-01","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7788","name":"CreativeIT"}}],"PIcoPI":["550488"],"PO":["424970"]},"139451":{"abstract":"Tong, Yiying (0811313)<br\/>Desbrun, Mathieu (0811373) <br\/><br\/>Abstract<br\/><br\/>Basic computational tools to process digital geometry in computer graphics and computational science are crucially needed for a wide range of applications including medical visualizations, atmospheric data analysis, and shape segmentation. Previous attempts to apply signal processing foundations such as the Fast Fourier Transform in order to fulfill these needs have only led to limited success: geometry has distinctive properties such as irregular sampling, topology, and metric, making it not just another signal, but a new challenge that computer scientists must face. Independently of these advances, spectral graph theory has shown surprisingly simple and powerful properties of the Laplacian matrices of arbitrary graphs, demonstrating that eigenvalue problems can robustly handle graph irregularity and help in the development of Internet search engines. Moreover, connections between spectral graph theory and differential geometry have started to appear as not only relevant, but quite insightful in their own rights.<br\/><br\/>This NSF-funded project on ``Eigengeometry?? involves bringing these spectral theoretical developments into the realm of computing. More precisely, the investigators study and develop novel tools for the analysis and processing of not only signals defined over discrete geometric shapes, but of the shapes themselves via spectral theory. These novel tools, naturally robust to non-uniform sampling and irregular connectivity that meshes inherently contain, are tested on a few selected applications (covering CAGD, brain imaging, and analysis of atmospherical features). This research is a truly multidisciplinary and innovative effort drawing upon techniques from graph theory, graphics, numerical linear algebra, applied geometry, and signal processing. Finally, the importance of eigenstructures in mathematical and physical fields promises that the computing tools developed in this project are likely to have a broad impact.","title":"Collaborative Research: CPA-G&V: Eigengeometry: Geometric Spectral Computing for Computer Graphics and Computational Science","awardID":"0811313","effectiveDate":"2008-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["541934"],"PO":["532791"]},"144280":{"abstract":"Proposal #: CNS 08-36228<br\/>PI(s): Fortes, Jose A.<br\/>Institution: University of Florida<br\/> Gainesville, FL 32611-2002<br\/>Title: Workshop on Instrumentation Needs of Computer and Information Science and Engineering<br\/>Project Proposed:<br\/>This proposal, planning a workshop to examine the nature, needs, importance, challenges, and funding mechanisms of instrumentation development, acquisition, utilization, and sharing, for purposes of ongoing and\/or anticipated research in different CISE areas, brings together recognized CISE research leaders to conduct such an assessment and produce a report that can be shared with the CISE community, colleagues, academic administrators, government funding agencies, and industry. CISE research is increasingly concerned with extremely large and complex objects whose behavior cannot be entirely distilled from first principles or investigated using reduction models. Among other factors, scale is a consequence of Moore?s law and pervasive networking. Complexity arises from the embedding of computing into artifacts, interconnection of many components and\/or multiple layers of functionality. Research needed to design and\/or model such objects often requires special instruments to either peer into individual components at very small space\/time granularity or to observe\/emulate\/simulate many objects at large enough scale and during long enough times. <br\/><br\/>Over the last two decades the CISE research instrumentation needs, and mechanisms to address them, have changed as a reflection of the evolution of IT technology, both from the standpoint of the research challenges to be faced and the instruments enabled. The amazing progress of computer and information technologies (IT) has led to the current era of microprocessors with billions of transistors, software environments with millions of lines of code, multi-layered IT systems, and networks of thousands of computers, users, and applications. As a consequence, the objects computer scientists and engineers study often have an unprecedented scale and complexity. CISE instruments often grow by connecting many other artifacts (in some cases, on the fly) leading to complexity that cannot be mastered by any single designer or user of those objects. Thus, an urgent need exists for such assessment.<br\/><br\/>Broader Impact: IT is increasingly being embedded into artifacts which might include non-IT components whose natures include mechanical, electrical, communication, energy production, chemical, transportation, entertainment, medical, and defense. Thus, instrumentation touches society overall.","title":"Workshop on Instrumentation Needs of Computer and Information Science and Engineering Research","awardID":"0836228","effectiveDate":"2008-07-15","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["540130"],"PO":["557609"]},"149692":{"abstract":"The Internet revolution has led organizations worldwide to rely heavily on information sharing over the Internet to conduct their daily business. Information sharing on the Internet usually occurs in broad, highly dynamic network-based environments, and formally accessing the resources in a secure manner poses a difficult challenge. Our focus is on the problems of secure information exchange and secure information access in Internet-based collaborative environments. The research objectives are as follows. <br\/><br\/>Secure group communication. In collaborative work and research environments, group members must be able to set up a reliable, secure information sharing and communication medium among them. Techniques will be developed for setting up secure group communication and providing a set of accesses to group members for a variety of digital data in highly dynamic networks.<br\/><br\/>Security services. Digital information in database systems generally represents sensitive and confidential information that organizations must protect and allow only authorized personnel to access and manipulate them. The research will address the issue of how to advocate selective information sharing in role-based systems while minimizing the risks of unauthorized access proposing a delegation framework. The objective is to demonstrate the feasibility of our framework through policy specification, enforcement, and a proof-of-concept implementation.","title":"Collaborative Research: Secure Information Sharing in Internet-based Collaborative Applications","awardID":"0900970","effectiveDate":"2008-07-01","expirationDate":"2009-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7228","name":"DATA AND APPLICATIONS SECURITY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["492724"],"PO":["563751"]},"139364":{"abstract":"The impact of communication on the performance of computer systems continues to<br\/>grow both at the macro-level for blade servers and clusters of computers, and<br\/>at the micro-level in multi-core processors. Meanwhile the tight on-chip power<br\/>dissipation constraints have forced practically all major semiconductor<br\/>companies to move to multi-core or chip multiprocessor (CMP) architectures. <br\/>The emergence of CMPs has in turn placed increased challenges on the<br\/>communications infrastructure as the growing number of processing cores<br\/>integrated on each chip exacerbates the bandwidth requirements for both<br\/>intra-chip and inter-chip communication. <br\/><br\/>This research aims to harness the recent extraordinary advances in<br\/>nanoscale silicon photonic technologies for developing optical interconnection <br\/>networks that address the critical bandwidth and power challenges of future<br\/>CMP-based system. The insertion of photonic interconnection networks essentially changes the power scaling rules: once a photonic path is established, the data are transmitted end-to-end without the need for repeating, regeneration or buffering. This means that the energy for generating and receiving the data is only expended once per communication transaction anywhere across the computing system. The PIs will investigate the complete cohesive design of an on-chip optical interconnection network that employs nanoscale CMOS photonic devices and enables seamless off-chip communications to other CMP computing nodes and to external memory. System-wide optical interconnection network architectures will be specifically studied in the context of stream processing models of computation.","title":"CPA-CSA: Photonic Interconnection Networks for Chip-Multiprocessor Computing Systems","awardID":"0811012","effectiveDate":"2008-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["477270","518555"],"PO":["366560"]},"139464":{"abstract":"Tong, Yiying (0811313)<br\/>Desbrun, Mathieu (0811373) <br\/><br\/>Abstract<br\/><br\/>Basic computational tools to process digital geometry in computer graphics and computational science are crucially needed for a wide range of applications including medical visualizations, atmospheric data analysis, and shape segmentation. Previous attempts to apply signal processing foundations such as the Fast Fourier Transform in order to fulfill these needs have only led to limited success: geometry has distinctive properties such as irregular sampling, topology, and metric, making it not just another signal, but a new challenge that computer scientists must face. Independently of these advances, spectral graph theory has shown surprisingly simple and powerful properties of the Laplacian matrices of arbitrary graphs, demonstrating that eigenvalue problems can robustly handle graph irregularity and help in the development of Internet search engines. Moreover, connections between spectral graph theory and differential geometry have started to appear as not only relevant, but quite insightful in their own rights.<br\/><br\/>This NSF-funded project on ``Eigengeometry?? involves bringing these spectral theoretical developments into the realm of computing. More precisely, the investigators study and develop novel tools for the analysis and processing of not only signals defined over discrete geometric shapes, but of the shapes themselves via spectral theory. These novel tools, naturally robust to non-uniform sampling and irregular connectivity that meshes inherently contain, are tested on a few selected applications (covering CAGD, brain imaging, and analysis of atmospherical features). This research is a truly multidisciplinary and innovative effort drawing upon techniques from graph theory, graphics, numerical linear algebra, applied geometry, and signal processing. Finally, the importance of eigenstructures in mathematical and physical fields promises that the computing tools developed in this project are likely to have a broad impact.","title":"Collaborative Research: CPA-G&V: Eigengeometry: Geometric Spectral Computing for Computer Graphics and Computational Science","awardID":"0811373","effectiveDate":"2008-07-01","expirationDate":"2011-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["448656"],"PO":["532791"]},"144161":{"abstract":"The PI's propose organising and hosting a workshop to identify the key elements necessary to build an empirical infrastructure that will advance research on one of the key building blocks of science and innovation policy: organizations. This will provide an empirical basis for the scientific study of science and innovation policies that affect innovation, business performance, and change in organizations. <br\/><br\/>The workshop will be held in NSF meeting space in Arlington, Virginia, on July 23, 2008. It will be adjoined by a Pre-Conference for the 2008 Kauffman Symposium on Entrepreneurship and Innovation Data on July 24, 2008<br\/><br\/><br\/>The workshop organization will be in the form of five highly structured sessions lasting a total of one day and with a maximum of 35 participants, with about 20 participants involved in the program in some way (as speaker, panel moderator, or discussion facilitator). All sessions will include a floor discussion. The three organizers will act as both facilitators and rapporteurs<br\/><br\/>Intellectual merit<br\/>The primary intellectual merit of the proposal is that the new data and tools that the workshop seeks to develop would provide an evidence based platform for science policy. It would (1) permit researchers to examine the innovation process ? both successes and failures ? and (2) explore business performance and business dynamics at the level of the appropriate economic entity. <br\/><br\/>Broader Impact<br\/>In terms of broader impacts, the need for better metrics of innovation and business performance was underscored by the America COMPETES Act and the Innovation Metrics report of the Department of Commerce (DOC). By fostering transformative research that would advance the scientific understanding of innovation and its relation to policy and business strategy, the new infrastructure will respond to these high-level concerns.","title":"Workshop on Developing a National Research Infrastructure for the Study of Innovation and Change in Organization, National Science Foundation, Arlington, Virginia, July 23, 2008","awardID":"0835722","effectiveDate":"2008-07-01","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0400","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"7626","name":"SCIENCE OF SCIENCE POLICY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"5376","name":"INNOVATION & ORG SCIENCES(IOS)"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"7603","name":"SCIENCE, TECH & SOCIETY"}}],"PIcoPI":[384294,384295,384296],"PO":["474859"]},"134492":{"abstract":"The PI's goal in this project is to advance the state-of-the-art of haptics research, which has to date centered primarily on the use of point-based force-feedback devices, by exploring and comparing two novel approaches to providing haptic guidance for path following and fine motor tasks. These two approaches are: (1) using tactile shear guidance to provide directional information through the grip of a stylus; and (2) augmenting a traditional stylus-based haptic interface with an active handrest. In the first approach (providing directional information through tactile shear feedback), the PI will investigate using a specialized stylus interface with shear devices embedded in its grip. These devices will transmit shear feedback to the user's thumb and index finger. The second approach (using an active handrest) for executing path following and fine fingertip motions was inspired by the way artists use a baton-like handrest to support fine hand motions during detailed painting. The active handrest will be explored as a supplement or substitute for traditional force feedback and other haptic guidance techniques, such as virtual fixtures. Through modeling and human subjects testing, the PI will investigate two modes of supporting the user's wrist and\/or forearm while gripping a traditional stylus haptic interface. One mode will have the handrest impart forces or motions to the user's wrist\/forearm, providing corrective task intervention. The second control mode will infer the user's optimal handrest position and preemptively move itself to provide continued support based on measured reaction forces. The PI will evaluate and compare the impact tactile shear guidance and the active handrest have on task performance (e.g., accuracy and execution time), versus established approaches. The research will also produce theoretical characterizations of the passive dynamics between the forearm and hand that will form the foundation for controlling active handrest systems. Algorithms for controlling the handrest under multiple modes of operation will be established.<br\/><br\/>Broader Impact: This research will lead to dramatic improvements in the realism of simulations and virtual environments of all kinds. Project outcomes will be applicable across a broad cross-section of domains including neuro- and tele-surgery, hand rehabilitation, guidance systems for the blind, and consumer applications like automotive GPS navigation systems. Imagine if, rather than having to look at your GPS navigation map or listen to its instructions, you received a shearing tactile cue from the steering wheel that told you a turn was coming up; this could significantly reduce driver cognitive load and thereby lead to improved driver safety. A major objective of the PI is to attract women and underrepresented students, especially Native Americans, into the fields of science and engineering. To this end, he will develop haptic learning modules based on his research interests, which can be presented in conjunction with established college-wide outreach activities aimed at junior high and high school students, and that can also be used by the University of Utah Robotics Group (with which the PI is affiliated) as part of its established relationship with Montana State University (which has a large Native American representation in its undergraduate programs). The PI will also develop a course in haptics with innovations such as a Haptics Concept Inventory and hands-on demos.","title":"CAREER: HCC: Haptic Guidance Systems","awardID":"0746914","effectiveDate":"2008-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["536910"],"PO":["565227"]},"144293":{"abstract":"IIS - 0836305 <br\/>International Participation in JCDL and Hypertext 2008<br\/>Larsen, Ronald L. <br\/>University of Pittsburgh<br\/><br\/>This award provides support for travel for several international scholars to attend the Joint Conference on Digital Libraries (JCDL) and in the Hypertext conference, to be held consecutively in Pittsburgh, PA, June 16-21, 2008. The invitees are major figures in their respective digital libraries communities and manage and organize activities in Europe and Africa that have significant bearing on building international interoperable repositories. Their participation both provides valuable information on research and infrastructure agendas in their countries and will extend international dialogue and collaboration.","title":"International Participation in Joint Conference on Digital Libraries (JCDL) and Hypertext 2008","awardID":"0836305","effectiveDate":"2008-07-01","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["464231"],"PO":["433760"]},"139530":{"abstract":"The programmability challenges to general-purpose parallel computing desperately need computer hardware and software researchers to work together on the solutions. However, the unacceptably slow speed of current full-system simulators limits the multiprocessor\/multi-core research.<br\/><br\/>The proposed ProtoFlex project develops an FPGA-accelerated simulation technology to deliver the necessary simulation performance to enable full-scale software research on top of simulated experimental architectures. ProtoFlex simulators are not FPGA prototypes. The ProtoFlex simulation architecture relies on hardware virtualization to achieve full-system fidelity and system scalability, while mitigating the complexities associated with conventional FPGA prototyping. This project will develop a hybrid simulation with transplanting and with interleaving of multiple processor contexts, with the goal to decouple the required complexity of the hardware construction from the complexity of a very large target multiprocessor system. This project will also investigate in-hardware techniques for real-time, deep instrumentation and analysis of simulation events.","title":"CPA-CSA: Accelerating Architectural-level, Full-system Multiprocessor Simulations using FPGAs","awardID":"0811702","effectiveDate":"2008-07-15","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["550978"],"PO":["559883"]},"148374":{"abstract":"Time series of gene expression of gene, protein and metabolite concentrations are becoming available as the result of the rapid development of novel, high-throughput experimental techniques in genomics sciences. Such time series implicitly contain valuable information about the connectivity and regulatory structure of the underlying genetic or biochemical network mechanism. The extraction of this information is a challenging task because it requires the development of new mathematical and computational methods of nonlinear estimation that involve iterative search algorithms. Priming these algorithms with high-quality initial guesses can great accelerate the search process.<br\/><br\/>Even when full genomic sequences for an organism are available, the functions and<br\/>interactions of only a small number of gene components are clear. Presently, the functions of uncharacterized proteins have usually been inferred on the basis of sequence similarities, common structural motifs, gene order, gene fusion events, or similarities in gene expression. The proposal goal is to develop a new method for functional predictions based on the role of the gene in networks. This method allow us to perform functional predictions for proteins independent of homologies in structure or sequence, and provide a way to characterize proteins that have not yet been studied using published biological data from high-throughput technologies.<br\/><br\/>The methodology will be applicable to any organism, including humans, where<br\/>only three to five percent of gene function is known. As we better understand the functions of genes and proteins in a network context, we can better predict and control their responses to internal and external perturbations. For the foreseeable future, the type of modeling predictions will likely be one of the many inputs into the decision making process in the pharmaceutical industry, and biomedical sciences. The research will provide interdisciplinary (biological, mathematical and computational; experimental and theoretical) training to undergraduate and graduate students and postdoctoral researchers, and help produce a generation of scientists comfortable both with biology, mathematics and computation.","title":"SEI: Unraveling the Structure and Kinetics of Biochemical Pathways from Time-Series Analysis","awardID":"0852743","effectiveDate":"2008-07-01","expirationDate":"2010-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["495225"],"PO":["565136"]},"139454":{"abstract":"Enterprise data centers consume an alarmingly-high fraction of the energy produced in the United States. The US Environmental Protection Agency estimates that data center energy consumption will reach over 100 billion kWh by 2011, 2.5% of US power generation, resulting in an estimated annual electricity cost of $7.4 billion. As much as 40% of this energy is wasted because of two key inefficiencies: (1) the substantial energy used by idle equipment that is powered on, but not performing useful work, and (2) inefficiency in data-center cooling infrastructure arising from a poor match between where heat is generated and where cool air is supplied. This project proposes research on a data-center-wide management system that controls IT equipment, power, and cooling infrastructure in real time to save energy in two ways. First, it actively consolidates computing tasks onto fewer systems, allowing idle systems to be powered down. Second, it moves computing tasks to systems that can be cooled most efficiently. The project addresses the key challenge of modeling temperature in large-scale data centers and designing an autonomous system that makes correct decisions on where to place tasks.","title":"CPA-CSA: Virtualization Mechanisms for Zero-Idle-Power and Thermally-Efficient Data Centers","awardID":"0811320","effectiveDate":"2008-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["508097"],"PO":["559883"]},"139476":{"abstract":"Title: CPA-G&V Intelligence Augmented Visualization<br\/>PI: Kwan-Liu Ma, University of California at Davis<br\/><br\/>Abstract:<br\/>Visualization has become an indispensable tool in many areas of science and engineering. Advanced visualization techniques allow scientists to view and explore their computational results, but truly effective systems allow the discovery of unexpected and often subtle aspects of the data. Such discoveries can only be made by those intimately familiar with the generation of the data. Adding to the visualization system the capability to learn from the domain experts in complex data analysis tasks can facilitate similar tasks and increase the utilization and efficacy of the system. This research aims to create such a new visualization technology that is anticipated to significantly lower the cost of visualization.<br\/><br\/>The investigators study how to integrate ?intelligence? into visualization systems to automatically handling simple or repetitive tasks, and to effectively assist users in performing complex tasks involving large, high-dimensional data. Only high-level, goal-oriented decisions need to be made by the user, making cutting-edge visualization technology directly accessible to a wide range of application scientists. One research task is to select suitable machine learning methods for representative visualization tasks. Two demanding visualization applications, turbulent flow analysis and social data analysis, are used in this study. The other critical task is to consult domain experts for understanding the visualization task requirements and visual language, followed by the design of an appropriate user interface for each visualization task. The research results can therefore help realize truly coherent and usable visualization systems and broaden the base of potential users of visualization technology.","title":"CPA-G&V: Intelligence Augmented Visualization","awardID":"0811422","effectiveDate":"2008-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["552243"],"PO":["532791"]},"134471":{"abstract":"The goal of this research is to revolutionize the ability to anticipate tornadoes by developing advanced techniques for statistical pattern discovery in spatially and temporally varying relational data. These models are applied to complete fields of meteorological quantities obtained through data assimilation and simulation. Doppler radar data is limited and, while modern data assimilation techniques allow the unobserved quantities to be estimated, the resulting four- dimensional fields are too complicated for the extraction of meaningful, repeatable patterns by either humans or current data mining techniques. By studying a full field of variables, the models can identify critical interactions among high level features. The models are developed and verified in close collaboration with domain experts.<br\/><br\/>The interdisciplinary research is used to improve retention and recruitment in computer science (CS). This draws on recent evidence that underrepresented groups are not drawn to computing careers because they do not appreciate how computing can be used to solve real world problems. Introducing authentic projects into both early CS and meteorology classes will improve the number of technically trained students in both majors.<br\/><br\/>The primary broader impact of this research is to society, through the <br\/>potential for reduction in loss of human life, property, and money. <br\/>Models will be made available to operational meteorologists as they are verified. Another broader impact will come from increasing the number of computing oriented minors and majors through authentic projects. All data and results will be disseminated through peer reviewed publications and via open source online repositories accessible on the project Web site (http:\/\/www.cs.ou.edu\/~amy\/career\/).","title":"CAREER: Developing Dynamic Relational Models to Anticipate Tornado Formation","awardID":"0746816","effectiveDate":"2008-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"1525","name":"PHYSICAL & DYNAMIC METEOROLOGY"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["538251"],"PO":["563751"]},"145064":{"abstract":"Through this award to the Center for Advanced Computing and Communication, in association with the Friday Institute, the National Science Foundation, NSA, and the participating agencies of the NITRD High Confidence Software and Systems interagency coordinating group seek to advance outcomes from the 2007 National Workshop on Stimulating and Sustaining Excitement and Discovery in STEM (Science, Technology, Engineering, Mathematics) Education. The award supports the exploration of three model programs: a pilot program in on-line computer science curriculum, expansion of the NC State Keenan Fellows program for teacher training and leadership development, and a residential middle grade math and science summer camp to be hosted at the University of Maryland, Eastern Shore.","title":"SGER: Increasing the Pipeline: Research and Education on Stimulating Interest in High Confidence Software and Systems","awardID":"0839220","effectiveDate":"2008-07-01","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"H183","name":"National Security Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"H184","name":"National Security Agency"}}],"PIcoPI":[386978,386979],"PO":["561889"]},"139520":{"abstract":"CPA-G&V: Self-Completion of 4D (Space+Time) Models<br\/>Yang (0811647)<br\/>Abstract<br\/>Digital 2D photos and videos are already ubiquitous in our everyday life. Fueled by new products such as Google Earth and interactive 3D games, the public seems to have a renewed interest in 3D contents. Creating 3D contents beyond simple fixed viewpoint stereoscopic movies has so far remained to be a labor intensive and expensive process. This research investigates new software algorithms that can significantly simplify this modeling process, in particular for dynamic models. <br\/>The use of inexpensive depth sensors (such a stereo camera) will capture a dynamic scene over time from different locations and automatically generate a complete 4D model. The recovered models can be used in many applications such as simulations to create realistic virtual environment, entertainment to render special effect, and perhaps simply to allow everyone to enjoy their cherish moments, such as a baby?s first step, in interactive 3D. <br\/><br\/>From a technical standpoint, from the input sequence of color+depth maps, which provides a partial sampling of the entire 4D (space+time) model, the central research problem is how to fuse these partial samples to form a complete model. Different from all previous hole filling approaches, this research aims to deal with models that exhibit one or more of the following characteristics: large (e.g., several city blocks), dynamic, deforming, yet sparsely sampled (e.g., less than 50% is available), and possibly very noisy. Reconstructing a complete model under these conditions can be very challenging or sometime ill-posed. However, scene structures are usually not stochastic; the same or similar structure element may have appeared in the input set a few times, probably at a different time and location. Therefore, samples from different time or space can be used to fill in the missing data, making model completion possible, without using any external sources.","title":"CPA-G&V: Self-Completion of 4D (Space+Time) Models","awardID":"0811647","effectiveDate":"2008-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["523441","470107"],"PO":["532791"]},"139432":{"abstract":"Within a few years, every laptop\/desktop\/server processor will be a<br\/>multi-core machine. For an application to perform well, it must be<br\/>efficiently parallelized to execute on all the cores on the machine.<br\/>Chip manufacturers must therefore provide architectures that<br\/>make it convenient for programmers to partition an application into<br\/>multiple parallel threads. The Transactional Memory (TM) programming<br\/>model is widely acknowledged to be the best known model for<br\/>concurrency: it eliminates deadlocks, provides high performance in<br\/>the common case, and greatly simplifies programming. It is receiving<br\/>great attention in research conferences and is also being incorporated<br\/>in commercial processors. One of the biggest overheads for such a<br\/>system is the communication required between cores to implement<br\/>transactional semantics. This overhead significantly impacts<br\/>performance and power consumption of future processors. <br\/><br\/>The project explores algorithms to not only reduce the required amount of<br\/>communication, but also explores mechanisms to reduce the overheads<br\/>of communication. The key insight behind the proposed work is that an<br\/>optimal on-chip network and transactional memory implementation will<br\/>emerge by closely studying the interaction between the two. The<br\/>insight developed during this work will lead to better methodologies<br\/>to compute an optimal on-chip network. The simulators and tools<br\/>developed during the research efforts will also support projects in<br\/>graduate and undergraduate courses at the University of Utah.","title":"CPA-CSA: Algorithms and Implementations for Scalable Transactional Memory","awardID":"0811249","effectiveDate":"2008-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["556789"],"PO":["559883"]},"139553":{"abstract":"Abstract<br\/>PI: Meenakshisundaram, Gopi (CCF ? 0811809) <br\/><br\/>Current graphics and visualization systems have to be built such that they can handle gigantic data sets like those from large scientific simulations including nuclear and power simulations, and geometric data sets such as digital models of defense and commercial equipments such as aircraft, ships and power-plants. Such large data sets cannot fit into the main memory of the computers or be rendered interactively in current graphics systems. This project involves fundamental research in designing algorithms for efficient compression of these large data sets that enables fast decompression of the required portion of the data set in the main-memory and efficient interactive rendering of these data sets.<br\/><br\/>This study is exploring three research directions to solve the problem of interactive walkthrough of gigantic data sets: syntactic compression, semantic compression, and access sensitive data layouts. Syntactic compression deals with compressing data bits. In this project, compression algorithms that exhibit properties like random-access decompression and stop-any-time decompression are studied. Semantic compression deals with representing objects with fewer primitives. In this context, this research studies parameterizable semantic compression algorithms that trades-off space for compression efficiency. Finally, optimal data layouts depend on application, and this study explores optimal data layout schemes of the 3D data sets on external memory for interactive walkthrough applications. This includes partitioning of the 3D data set using different metrics like normal vector deviation and spatial distance between objects, and computing the linear layout of these partitions in the external memory using graph algorithms. The research is significantly improving the ability to render large data sets with applications across computer graphics and visualization as well as other application areas such as military and rescue simulations.","title":"CPA-G&V: Compression Techniques for Direct Rendering","awardID":"0811809","effectiveDate":"2008-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[370962],"PO":["532791"]},"143063":{"abstract":"NSF Proposals 0820198\/0820138<br\/><br\/>Title: Process-Centered, Analysis-Driven System Development Applied to Human-Intensive Medical Processes<br\/><br\/>PIs: Lori Clarke, Philip Henneman, George Avrunin, Elizabeth Henneman, and Leon Osterweil<br\/><br\/>This project presents a new approach to developing human-intensive systems in which the coordination among human participants, hardware devices, and application software systems are specified in an executable, process-definition language. Process definitions are subjected to rigorous analysis in order to detect defects and evaluate proposed improvements. Such validated process definitions can then be used to drive simulations and train process participants. The proposed approach is to be evaluated by developing a process support environment that is then used to define and analyze medical processes. Medical processes provide a particularly good evaluation domain as they are human-intensive, involve diverse software applications and hardware devices, and are both safety critical and error prone. Separating and rigorously analyzing the coordination aspects of complex, human-intensive systems represent a paradigm shift from current development practices. This approach provides a strong technical and methodological basis for the engineering of human-intensive systems, leading to systems that are scalable, understandable, and able to amplify human efficacy and control. Finally, this process-centered approach has the potential to improve the quality and reduce the cost of medical care.","title":"Collaborative Research: Process-Centered, Analysis-driven System Development Applied to Human-Intensive Medical Processes","awardID":"0829901","effectiveDate":"2008-07-01","expirationDate":"2011-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7724","name":"SOFTWARE FOR REAL-WORLD SYSTMS"}}],"PIcoPI":[380904],"PO":["564388"]},"136584":{"abstract":"The goal of this project is to develop a new environment for collaboration in creative projects and to promote creativity and innovation in IT problem solving among disadvantaged youth. The new environment is a wiki-based authoring toolkit, called the Briefcase, that will guide students through the use of various software packages and allow them to share and discuss with others locally and over the Internet. The intent of the Briefcase concept is to extend the functionality of the RoboBook product currently under development at Tufts to include the scalability of a Wiki-like backbone. Once the software has been designed, we will develop instructional content for it as well. The idea is to provide students with an authoring environment (like Word or PowerPoint) that helps students <br\/>1. learn how to use various software packages; <br\/>2. keep track of what they are doing through blogs, pictures, and movies; <br\/>3. discuss and team with others (locally and remotely) to problem solve; and <br\/>4. share what they develop with others around the world. <br\/>Further, the Briefcase will allow the Learning Centers to recruit excellent mentors that are not necessarily software experts. The idea is that a user could ?check out a Briefcase? for a project in a software package (e.g., Scratch). She opens the Briefcase to an instruction manual, complete with movies, pictures, and interactive pages. She then starts to move into the open-ended design of her project, with the included design brief providing scaffolding for her design. At this point the tool becomes more of a diary and note-taking environment (where notes can include pictures, voice, and movies). As she completes her design, she creates her final presentation within the Briefcase that is then shared with others on the web.<br\/><br\/>Broader Impact: The hybrid technology being delivered to children in different cities in different socioeconomic conditions, can make a real impact in improving science education opportunities for disadvantaged youth. This work could also inform new directions for textbooks of the future.","title":"Using Wide-Spread Collaboration to Motivate Innovation and Creativity","awardID":"0757455","effectiveDate":"2008-07-01","expirationDate":"2011-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7788","name":"CreativeIT"}}],"PIcoPI":["316342","495544"],"PO":["564456"]},"134296":{"abstract":"To facilitate linguistic communications, natural language processing (NLP) technologies must be applicable to different languages across different domains. A limitation of many NLP systems is that they do not perform as well on data types that diverge from their training examples. The objective of this CAREER project is to increase the robustness and coverage of a fundamental NLP component, the syntactic parser.<br\/><br\/>Specifically, this project explores adaptation methods to extend a standard English parser for processing different domains (e.g., scientific literature, emails) and different languages (e.g., Chinese). Three types of correspondences are considered. First, if coarse-level correspondences are explicit in the data (e.g., bilingual documents), finer-grained correspondences at the word- or phrasal-level may be inferred, and semi-supervised learning may be used to transfer domain knowledge across the inferred correspondence.<br\/>Second, if the correspondences are inexact (e.g., multiple translations of varying quality), the mis-matched portions may be identified and transformed to achieve a closer mapping. Third, if the correspondences are indirect, methods for inducing correspondences from non-parallel corpora may be appropriate.<br\/><br\/>Parser adaptation stands to increase the range of NLP applications; examples include: data mining from medical documents and automatic tutoring for non-English speakers. As the project aims to bring together several strands of research, it offers ample research opportunities to graduate and undergraduate students. The algorithmic aspects encourage forming synthesis from areas of semi-supervised learning, relational data modeling, grammar induction, and machine translation; the empirical aspects afford students an arena to hone their skills in good scientific methodologies.","title":"CAREER: Robust Parsing for New Domains and Languages","awardID":"0745914","effectiveDate":"2008-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[357107],"PO":["565215"]},"139510":{"abstract":"TITLE: Betters Tools for Software Understanding<br\/>PI: Brad A. Myers, Carnegie Mellon University<br\/><br\/>Understanding software is a prerequisite to taking any action to change it, and this remains expensive and error-prone. Research with programmers in the field has identified significant barriers to understanding. Lab and field studies of usability barriers in understanding and using APIs will result in models of how developers understand the design of the objects. These results will lead to new software tools for API exploration and understanding. Work on enabling people to better understand and fix bugs through new visualizations and interaction techniques will allow them to ask \"Why\" and \"Why Not\" questions about their code, with the answer visualizing the responsible code and dataflow. New tools will support understanding code by others during reverse engineering activities, focusing on how data and control can flow through large and complex programs. Using static analysis techniques and a new \"WhatTree\" visualization will allow programmers to investigate the update paths of their programs, while supporting the programmers in collecting and keeping track of facts and hypotheses about how the program operates. The results will improve programmer success and thus their overall productivity.","title":"CPA-SEL: Better Tools for Software Understanding","awardID":"0811610","effectiveDate":"2008-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["548127"],"PO":["564388"]},"147166":{"abstract":"The focus of this project is integrated design and analysis of communication networks in service of coordinated control of multi-vehicle systems. Consider a set of vehicles, equipped with local controllers and wireless radios, that is set to arrange itself, to stabilize, and to control its collective motion. To achieve globally desirable formation behavior, the controller on a given vehicle must respond to the motion and state of others.<br\/><br\/>In fact, there exists a complicated coupling among system components: network architecture, communications protocols, and controller design. The integrated design of these components is the objective of this project. The fundamental challenge in designing networked control systems is that the tasks of communication and control, in general, cannot be considered decoupled from each other without loss of optimality. However, modular solutions can potentially provide significant insights into the nature of efficient solutions. This project addresses the problem of integrated communications and control from a practically viable perspective by decomposing the problem into modular tasks. The introduced degree of modularity, despite its sub-optimality, enables practical and efficient solutions as well as insights into the inherent trade-offs. Because the questions that arise lie at the intersection between communications and controls research, the components of the project bring together expertise in decentralized control, networking, and signal processing through the following specific tasks: 1) Nonlinear coordinated control over dynamic graphs, 2) Crosslayer optimization of wireless networks in service of coordinated control, 3) Physical layer solutions to decentralized communication and control, and 4) Experimental performance evaluation on a 3D autonomous underwater vehicle test-bed at the University of Washington.","title":"Collaborative Research: New Communication Infrastructures For Networked Coordinated Control","awardID":"0848256","effectiveDate":"2008-07-01","expirationDate":"2011-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["550699"],"PO":["564898"]},"139478":{"abstract":"Title: Formal Methods for Multi-core Shared Memory Protocol Design<br\/>PI: Ganesh Gopalakrishnan<br\/>Inst: University of Utah<br\/>NSF Proposal Number: 0811429 <br\/><br\/>ABSTRACT:<br\/>The human society crucially depends on computing devices: from embedded computers in phones to peta-scale computing systems that can perform a million billion multiplications every second, and help simulate everything from car crashes to hurricanes. The performance of a computer must increase each year, without which the information-based human society will cease to advance. Unfortunately, past methods to increase the performance of a computer ? namely increasing the clock frequency and the functional unit complexity -- cease to be effective. These techniques now produce only a miniscule performance increase, while causing huge increases in the energy consumption. Already computing equipments consume more than 5% of the nation's electricity! The only available energy-efficient method of increasing computer performance is through the use of multiple central processing units (CPUs). Unfortunately, such organizations (called \"multi-core CPUs\") require that the accesses to the central memory be extremely efficient - requiring the use of highly complex protocols - called cache coherence protocols. Unfortunately these protocols must be hand-crafted for high performance, and hence are extremely error-prone. Previous methods to verify cache coherence protocols were already at the limits of the capabilities of verification tools. With the advent of multi-core CPUs, the complexity has become out of reach of all published techniques. The PI and his team are the only academic group to have developed techniques to verify, using mathematically sound computer algorithms, hierarchical multi-core CPU cache coherence protocols. Unfortunately, their methods to date have involved expert humans and often cause considerable tedium. The proposed methods in this proposal are expected to: (1) reduce the burden of verifying cache coherence protocols, and (2) help bridge two central abstraction gaps, thus minimizing the chances of errors in microprocessors: (i) high-level to low-level behavioral modeling gap, and (ii) the low behavioral level to hardware implementation level gap. It will help train valuable manpower - including undergraduates and under-represented groups. It will help sustain the technological momentum of the US, as the availability of sustained high performance computing power is no less important to the nation than its other basic needs such as water, clean air, and energy. The verification tools developed in this project are expected to be technology transferred to the computer industry. Last but not least, the students trained in this project will join the national and international high-technology labor force.","title":"CPA-DA: Formal Methods for Multi-core Shared Memory Protocol Design","awardID":"0811429","effectiveDate":"2008-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["561775"],"PO":["562984"]},"141073":{"abstract":"It is well known that in order to communicate effectively, it is not enough to speak in grammatical sentences. One needs to start from what the hearer knows or is interested in and get from there to the new information that one wants to convey. Understanding how human speakers do this is important as a pure research topic but it is also of great practical importance: enabling humans and machines to communicate in natural language will help with a variety of information transfer tasks, including tutoring, search, and translation. To make headway beyond the linguistic studies that are currently underway, a unified, universally accepted coding system for the phenomena that influence this part of language understanding is needed. In computational linguistics, uniform standards for marking text and annotating corpora are increasingly recognized as the key to progress; they allow researchers to make sure that they are consistent in the way they apply categories. They also allow the use of machine learning methods to help researchers to gain new insights and to analyze more texts more efficiently.<br\/><br\/>This workshop project focuses on two aspects of this coding problem, an understanding of the notions of 'discourse status' (is the referent being mentioned new to the discourse or already familiar?) and of 'animacy' (e.g. is the referent a human, a machine, an insect, a building?). The workshop brings together linguists and computer scientists with the goal of creating a gold standard coding procedure for these two important categories of linguistic content. The findings will then be disseminated through the auspices of several large linguistic annotation projects that have ties to key computer science working groups.","title":"Workshop on Animacy and Information Status Annotation","awardID":"0820475","effectiveDate":"2008-07-01","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"1311","name":"LINGUISTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[374983,"456054"],"PO":["564343"]},"144285":{"abstract":"Design creativity plays an essential role for development of new industrial and mission critical products and systems. Yet our understanding of design creativity and our ability to support creative design are very limited. This Design Creativity Workshop creates a forum for the key researchers around the world in the field of design and creativity to present and exchange their broad perspectives, argue about their similarities and differences, and discuss the future directions of both fundamental research on design creativity and practical development of creative IT tools for supporting creative design. The workshop participants present their ideas and research results on the following topics: Creative design and design creativity, Characteristics of creative thinking in design, Cognitive and computational models of design creativity, Collaboration and design creativity, Computational creativity for design, Bio-inspired creative design, Taxonomy of design creativity, IT tools for creative design, Design creativity & education.","title":"Second International Workshop on Design Creativity","awardID":"0836254","effectiveDate":"2008-07-01","expirationDate":"2010-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7788","name":"CreativeIT"}}],"PIcoPI":["508964"],"PO":["424970"]},"138840":{"abstract":"FODAVA-Lead: Dimension Reduction and Data Reduction: Foundations for Visualization<br\/><br\/>The FODAVA (Foundations of Data Analysis and Visualization) Lead research team at the Georgia Institute of Technology provides unified expertise in the critical areas for providing leadership of the FODAVA effort, including machine learning and computational statistics, information visualization, massive-dataset algorithms and data structures, and optimization theory. The team is focused on the fundamental theory and approaches to make breakthroughs in data representations and transformations. The work is directed along the two main axes of scale reduction, data reduction and dimension reduction, to allow human analysts to absorb and penetrate modern large-scale high-dimensional datasets cognitively and visually.<br\/><br\/>In the area of dimension reduction, the team is extending the theory of automatic feature selection by sparse recovery, developing effective methods for manifold dimension reduction in terms of differential operators, developing new scalable manifold methods using convex-concave saddle-point approaches, and creating dimension reduction methods which incorporate constraints that increase their understandability, such as preserving the data's cluster structure. In the area of data reduction, the team is developing multi-resolution data approximation schemes using hierarchical data structures and multipole-like expansions, approaches for analyzing data of heterogeneous data quality using convolution kernel approaches, and approaches for automatic anomaly cleaning and detection using Lp estimation. The results of this research impact the theory and practice of data analysis, as well as that of information visualization, in particular through the Visual Analytics Digital Library, integration of the resulting methodologies into existing visual analytics systems, and a series of workshops. Undergraduates, under-represented groups, and graduate students are educated in this new interdisciplinary area respectively through Georgia Tech's Threads model, FACES effort, and innovative PhD introductory course emphasizing cross-disciplinary research and new PhD program in Computational Science and Engineering.","title":"FODAVA-Lead: Dimension Reduction and Data Reduction: Foundations for Visualization","awardID":"0808863","effectiveDate":"2008-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7703","name":"FOUNDATIONS VISUAL ANALYTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"H194","name":"U.S. Department of Homeland Se"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"I114","name":"U.S. Department of Homeland Se"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"J159","name":"U.S. Department of Homeland Se"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"KX06","name":"U.S. Department of Homeland Se"}}],"PIcoPI":["562362","550876","540935","565104","518447"],"PO":["532791"]},"136574":{"abstract":"This project studies creativity in improvisation in both standard theatrical techniques where a script's interpretation, including the physical performance, is improvised by an actor, and \"improv theatre\" where entire scenes are created by actors in real-time through improvisation. This research will increase the state of knowledge about improvisation, creativity, and intelligent agent design, as well as contribute meaningfully to theoretical and academic understanding of creative practice in theatre. In addition to integrating engineering scientific methods with the theory and practice of acting, this research will contribute cognitive and computational models of improvisation, emotion, acting styles, and problem-solving in the context of theatre. These models will pave the way to the development of more sophisticated synthetic characters, virtual humans, and other intelligent autonomous agents that can interact with humans and with each other for purposes of entertainment, education, and training.","title":"Collaborative Research: Modeling Creative and Emotive Improvisation in Theater Performance","awardID":"0757414","effectiveDate":"2008-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7788","name":"CreativeIT"}}],"PIcoPI":["515830"],"PO":["564456"]},"139522":{"abstract":"This research focuses on developing a new programming methodology to dramatically improve the quality and dependability of software-intensive systems. The key to this effort is an effective integration of domain-specific languages (DSLs) and formal program verification, two well-known technologies that have been used extensively on their own, but mostly in isolation of one another. DSLs make it easier to write complex software for specific application domains, but they often lack rigorous semantics, making it difficult to formally specify and reason about the resulting programs. Existing program verification systems, on the other hand, usually rely on a single unified logic (e.g. Hoare logic) or type system, which cannot support the diversity of components in typical software-intensive systems. By combining the two methodologies, the PI intends to resolve both of these shortcomings. More specifically, the PIs propose to develop a new DSL-centric certified software design methodology that will elevate existing DSL practice into a rigorous software development methodology that allows program verification to scale effectively to large software systems. The proposed research will impact the software engineering community and make it possible to build software more quickly, and with higher assurance of correctness, than previously possible.","title":"CPA-SEL-T: Domain Specific Languages, Logics, and Proofs for Certified Software Design","awardID":"0811665","effectiveDate":"2008-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7724","name":"SOFTWARE FOR REAL-WORLD SYSTMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["541946","550517"],"PO":["523800"]},"139533":{"abstract":"Microprocessor designers have been able to periodically roll out new processors that double the performance of their predecessors, by leveraging underlying technology improvements and fundamentally redesigning the processor?s internal organization. This trend is abating. It is increasingly difficult to tap additional performance from a general-purpose processor by traditional technology and pipeline scaling. Researchers have begun rethinking the notion of general-purpose processor to mean many different processors on a single chip, each processor tailored to an individual application or a class of applications. Such a Heterogeneous Chip Multiprocessor (HCMP) can deliver higher overall performance with lower power consumption by exploiting customization and diversity: customizing processors to specific applications for higher performance and lower power, meanwhile providing enough different processors to broadly cover arbitrary applications.<br\/><br\/>The HCMP concept has great potential but it is currently very impractical. Designing, verifying, and fabricating just one processor takes hundreds of engineers with highly specialized expertise up to five years to develop. An HCMP multiplies this effort by the number of different processor designs.<br\/><br\/>The project addresses this overlooked challenge of HCMP research. The project explores a new approach to designing, verifying, and fabricating arbitrary superscalar processors, called FabScalar. The key idea is to develop a library of prefabricated canonical superscalar pipeline stages, in a wide variety of dimensions and features, enabling the automatic composition of arbitrary superscalar processors at the natural pipeline stage level. FabScalar is a first step for the practical development of true HCMPs. These HCMPs will provide a more efficient bridge between diverse applications and the underlying silicon.","title":"CPA-CSA: FabScalar: A Standard Superscalar Library for Fabricating Heterogeneous Chip Multiprocessors","awardID":"0811707","effectiveDate":"2008-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["518384"],"PO":["559883"]},"139423":{"abstract":"In the electromagnetic simulation of realistic structures, the spatial <br\/>representation of the domain being analyzed depends not only on the <br\/>frequency of interest but also on the need to capture possible fine <br\/>geometric features. Such mixed scales cause havoc in standard integral <br\/>equation based solvers on three fronts; (i) discretized integral <br\/>equations become poorly conditioned as the size of the element becomes <br\/>smaller, (ii) the function spaces used do not optimally represent the <br\/>underlying physics, and (iii) the overall computational burden is <br\/>exceedingly large. This largely limits the applicability of the <br\/>existing methods. The proposed project seeks to develop a demonstrably <br\/>unified, robust and accurate solution methodology that is well conditioned <br\/>over a wide range of frequencies and, at the same time, has the flexibility <br\/>to handle complicated (and possibly near singular) geometries. This is <br\/>achieved by (i) developing a well conditioned integral equation scheme <br\/>(that are Fredholm equations of the second kind) with provable bounds on <br\/>convergence rates and accuracy to solve for electromagnetic quantities <br\/>over a large range of spatial frequencies; (ii) enlarging the approximation <br\/>space used for representing the unknown quantity so as to include the local <br\/>physics; (iii) designing a scheme that permits seamless interplay between <br\/>a variety of basis functions to model the unknown quantities to be used <br\/>with the above integral equation scheme; (iv) deriving error bounds and <br\/>convergence estimates on these schemes to demonstrate clear and easy user<br\/>control over the error, and (iv) developing a domain decomposition framework <br\/>so that these schemes can be integrated seamlessly with classical integral <br\/>equation and finite element methods to solve electrically large problems. <br\/>The educational objective is to develop a publicly available set of <br\/>tutorials\/teaching modules based on this research. <br\/><br\/>The rapid progress in simulation methods in concert with the Moore's law has made the analysis of electrically large problems possible on simple desktop machines in reasonable computational times. So much so that fullwave or rigorous simulation of realistic devices are within the realm of possibility. However, as one tends towards this goal, new and more challenging problems arise. In modeling mixed scale physics, it is necessary to correctly represent local physics, develop methods to overcome conditioning issues, and develop means to accelerate computation over multiple scales. This project addresses the resolution of these problems. The methods developed herein will have a wide footprint ranging from national security (design of conformal antennas) to sensor technology (surface enhanced raman and plasmonics) to metamaterials to nanotechnology (nano-structure crystal growth dynamics) to molecular dynamics. In addition to training graduate students in engineering and mathematics, existing channels are utilized to recruit women and minorities and undergraduate students are involved through senior design projects and potential REU<br\/>supplements.","title":"Fast and Accurate Integral Equation Solvers for Mixed-scale Electromagnetic Simulation","awardID":"0811197","effectiveDate":"2008-07-15","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7351","name":"THEORETICAL FOUNDATIONS (TF)"}}],"PIcoPI":["532976"],"PO":["565027"]},"139468":{"abstract":"The rapid trend toward multi-core architectures promises faster execution of computer programs but poses significant difficulties for software development due to the lack of good programming models for exploiting the parallelism in such architectures. This situation is a significant opportunity for programming-language research to supply effective languages and tools for writing desktop applications while exploiting the performance of multi-core hardware. It is well known that functional-programming languages provide a good semantic base for concurrent and parallel programming, but for such languages to be successful, they need to provide competitive performance. The research focuses on the technical challenges in the efficient implementation of parallel functional languages. The characteristics of multi-core and many-core architectures demand that implementations preserve sequential semantics in parallel constructs, manage the granularity and scheduling of parallel threads, and be aware of the locality of data. The research explores a collection of techniques that combine static program analyses, compiler transformations, and dynamic runtime policies. Empirical analysis of both traditional parallel benchmarks and small applications is used to evaluate the effectiveness of the techniques developed by this research. By addressing performance concerns, the research will enable the practical use of parallel functional programming languages for a broad range of applications.","title":"Collaborative Research: CPA-SEL : Implementation Techniques for High- level Parallel Languages","awardID":"0811389","effectiveDate":"2008-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["523800","475199"],"PO":["551712"]},"134210":{"abstract":"There is a growing need for (semi-)automated tools to analyze and organize large collections of electronic information. In response, there is a surge of research on machine learning of probabilistic topic models, which automatically discover the hidden thematic structure in a large collection of documents. Once made explicit, this hidden structure facilitates browsing, searching, organizing, and summarizing vast amounts of information.<br\/><br\/>This research program will significantly build on the current state-of-the-art in topic modeling.<br\/><br\/>1. We will develop topic modeling algorithms that discover trends in document streams. Modeling evolutionary and revolutionary change of topics over time will be an important new capability for corpora analysts, providing methods of forecasting and understanding the changing patterns in serial collections such as news feeds, scientific publications, or web blogs.<br\/><br\/>2. Many modern corpora, such as Wikipedia, contain important links between the documents. We will develop topic models of such interconnected collections that explicitly represent and generalize inter-document and\/or inter-topic relationships. Such relationships may be hyper-links, scholarly citation, shared authorship, or statistical correlations. Capturing the patterns in these connections, and understanding their relationship to the texts, will have important implications for a great variety of scholarly, commercial, and personal 'recommender' systems.<br\/><br\/>3. Very often, analysts and other users approach a corpora with particular questions in mind. To facilitate focused, personalized exploration, we will develop supervised methods for discovering topic models that predict document-specific variables -- notably forms of relevance -- of online material such as scholarly papers, legal briefs, media sources, and product specifications.<br\/><br\/>This project addresses significant current limitations of topic modeling, and will provide practical new research and education tools for understanding and organizing modern repositories of information. We will make these tools available as open-source software to support and encourage their application to real-world problems, and we will fold the results of our research into ongoing education and outreach programs.","title":"CAREER: New Directions in Probabilistic Topic Models","awardID":"0745520","effectiveDate":"2008-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["531640"],"PO":["562760"]},"134573":{"abstract":"Proposal number: CCF-0747390 <br\/>TITLE: CAREER: Scalable Automated Software Testing and Repair <br\/>PI: Koushik Sen <br\/>Abstract: <br\/>Today's software systems suffer from poor reliability, with software errors costing the U.S. economy upwards of $60 billion annually. Testing is the predominant technique in industry to ensure software quality. Existing test generation techniques, such as random testing and symbolic execution based test generation, are either not effective or not scalable. This project investigates techniques to make automated test generation and automated bug fixing fast, scalable, and exhaustive by bridging the gap between practical techniques, such as testing, and mathematically rigorous techniques, such as model checking and symbolic analysis. Specifically, the project integrates ideas from randomized algorithms, symbolic analysis and model checking, and computational machine learning and develops novel ideas in three research efforts: (1) develop techniques for fast and exhaustive unit test generation; (2) scale automated testing to large software through compositional reasoning; and (3) investigate techniques for automated repair advice generation where automated test generation is used to automatically generate candidate program variants that could potentially fix the bugs discovered during testing. This project will immediately benefit the software industry where testing and bug fixing consume more than half of the total software development cost.","title":"CAREER: Scalable Automated Software Testing and Repair","awardID":"0747390","effectiveDate":"2008-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["451873"],"PO":["565264"]},"134474":{"abstract":"Traditional search engines like Google typically ignore a large amount of information behind the search engines of many online text information sources. Federated text search provides one-stop access to the hidden information via a single interface that connects to multiple search engines of text information sources. Existing federated search solutions only focus on content relevance and ignore a large amount of valuable information about users and information sources. This project includes novel research on: (1) Multiple Type Resource Representation: model important information of text information sources such as search response time and search engine effectiveness; (2) Utility-Centric Resource Selection: satisfy a user's search criteria by considering multiple types of evidence such as content relevance, search results from past queries, personal information needs, and search response time; (3) Effective and Efficient Results Merging: produce accurate merged ranked results with little cost of acquiring the content information of the returned documents; (4) System Adaptation by Results Analysis: analyze the search results from past queries for more accurate federated search solutions; (5) System Development and Evaluation: build and test algorithms within research environments as well as a new FedLemur system for a real world application. The project advances the state-of-the-art of research in federated search. It will have broad impacts for other applications such as peer to peer search. The project Web site (http:\/\/www.cs.purdue.edu\/~lsi\/Federated_Search_Career_Award.html) will be used for results dissemination.<br\/><br\/>The education component of the project will expand information retrieval instruction to address multi-disciplinary requirements, improve the education of information technology workforce, and arouse interests of K-12 students for search technologies.","title":"CAREER: An Integrated and Utility-Centric Framework for Federated Text Search","awardID":"0746830","effectiveDate":"2008-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["548255"],"PO":["563751"]},"144286":{"abstract":"The 17th IEEE International Conference on Computer Communications and Networks<br\/>(ICCCN?08) will be held in St. Thomas, U.S. Virgin Islands, USA from August 3 to<br\/>August 7, 2008. This preeminent technical conference is the primary venue for presenting<br\/>new research results in the area of computer communications and is widely attended by<br\/>researchers and practitioners in the field. Attending conferences such as ICCCN is highly<br\/>valuable for graduate students? research and career development. Participants have the<br\/>opportunity to present their work, attend panel and keynote speech sessions, and interact<br\/>with many others performing state-of-the-art research in the field.<br\/><br\/>This proposal requests funding to support approximately eight graduate students in the<br\/>United States to attend ICCCN?08. The travel awards will target graduate students, in<br\/>particular female and under-represented minority students, since they often have limited<br\/>travel funds to attend conferences, which is an important part of their educational<br\/>experience.","title":"NSF Travel Grant Support for IEEE ICCCN 2008; St. Thomas, U.S. Virgin Islands; August 3 - 7, 2008","awardID":"0836255","effectiveDate":"2008-07-01","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["423741"],"PO":["564777"]}}