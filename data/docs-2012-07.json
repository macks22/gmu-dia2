{"189420":{"abstract":"In the past ten years the theoretical computer science, applied math and electrical engineering communities have extensively studied variants of the problem of ``solving\" an under-determined linear system. One common mathematical feature that allows us to solve these problems is sparsity; roughly speaking, as long as the unknown vector does not contain too many non-zero components (or has a few dominating components), we can ``solve'' the under-determined system for the unknown vector. These problems are referred to as sparse approximation problems and have applications in diverse areas such as signal and image processing, biology, imaging, tomography, machine learning and others.<br\/>The proposed research project aims to develop a comprehensive, rigorous theory of sparse approximation, broadly defined. The research proposal entails two complementary research directions: <br\/>(1) a robust and more complete view of the combinatorial, algorithmic, and complexity-theoretic foundations of sparse approximations (including its generalization to functional sparse approximation where we want to ``solve\" for some function of the unknown vector instead of the vector itself),<br\/>(2) coupled with either its interactions or direct applications in other areas of theoretical computer science, from complexity theory to coding theory, and of electrical engineering, from signal processing to analog-to-digital converters.<br\/>A general theory of sparse approximation that concentrates both on the optimal tradeoffs between competing parameters and the computational feasibility of attaining such tradeoffs will not only help explore the theoretical limits and possibilities of sparse approximations, but also feed algorithmic techniques and theoretical benchmarks back to its application areas. Sparse approximation already has been shown to have impact in a variety of fields, including imaging and signal processing, Internet traffic analysis, and design of experiments in biology and drug design.","title":"AF: Medium: Collaborative Research: Sparse Approximation: Theory and Extensions","awardID":"1161151","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[507886],"PO":["565251"]},"189673":{"abstract":"The information technology (IT) industry is confronting an acute problem in the form of increasing power and energy consumption by electronic products, which is projected to have dramatic impact on the global energy crisis. This is partly due to the fact that a significant fraction of the energy consumption in the IT industry results from the computing components? (such as servers) energy need, which in turn, depends on the power consumption of the various integrated circuits in these components. Hence, designing low-power and energy-efficient integrated circuits or Green Electronics constitutes a key area for sustaining the irreversible growth of the global IT industry. Achieving energy-efficiency is also of critical importance for all electronic circuits used in mobile applications for increasing the battery life. <br\/><br\/>Energy-efficiency can be achieved by lowering both dynamic and leakage power consumption. However, lowering of power using traditional techniques becomes increasingly difficult beyond the 22 nanometer technology node. This is due to the fact that in such nanoscale devices, the most effective knob used for lowering power, namely the power supply voltage, cannot be scaled as rapidly as in earlier technology generations without incurring significant performance penalty arising from the inability to simultaneously reduce the threshold voltage. Simultaneous scaling of threshold voltage, which is essential for maintaining a certain ON to OFF ratio of the device currents (that is essential in digital circuits where the transistors are used as switches), leads to a substantial increase in the sub-threshold leakage (OFF state) current, owing to the non-abrupt nature of the switching characteristics of MOSFETs, thereby making the devices very energy inefficient. <br\/><br\/>This project aims to address this critical issue at the most fundamental level by designing circuits and systems enabled by novel electronic devices whose switching behaviors are near-ideal, that is, they can move from ON to OFF state and vice-versa, almost instantly. In particular, the PIs plan to design and fabricate ultra energy-efficient heterojunction Tunneling Field-Effect Transistors (T-FETs) that employ a fundamentally different injection mechanism in the form of band-to-band tunneling (BTBT) to achieve near ideal switching. They also plan to develop necessary modeling\/simulation, and optimization techniques for these devices, and explore circuits and systems specifically enabled by these devices to demonstrate unprecedented power and energy savings in electronic products. <br\/><br\/>This collaborative four-year project brings together an outstanding team of scientists for addressing one of the fundamental limitations of MOSFETs and is expected to have wide implications for the semiconductor and electronics industries. The project is expected to help digital switches and circuits (including high-performance microprocessors) to attain their ultimate limits (in terms of density and performance) and also open new opportunities in embedded memories (including DRAMs and Flash) and remote sensors, thereby maintaining U.S. competitiveness in the worldwide semiconductor market. Broader impact of the proposed research is also well recognized, particularly in the light of emerging 3-D ICs, where integration of low leakage and relatively temperature insensitive T-FETs could be exploited to build next-generation high-performance and low-power integrated circuits. The overall program also ties research to education at all levels (K-12, undergraduate, graduate, continuing-ed) partly via participation in programs designed by education professionals, besides focusing on recruitment and retention of underrepresented groups in nanoscience and engineering.","title":"SHF: Medium: A Collaborative Framework for Developing Green Electronics for Next-Generation Computing Applications","awardID":"1162633","effectiveDate":"2012-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1517","name":"ELECT, PHOTONICS, & MAG DEVICE"}}],"PIcoPI":[508554,508555,508556],"PO":["562984"]},"197054":{"abstract":"This project provides student travel support for the IEEE International Conference on Network Protocols (ICNP)held in Austin, TX on Oct 30 to Nov 2, 2012. The project allows a selected set of US students interested in network protocols to travel to this conference and benefit from the talks and other events. ICNP is a premier conference in this area and exposure to students of cutting edge research is essential.","title":"Student Travel Support for the 20th IEEE International Conference on Network Protocols (ICNP)","awardID":"1242057","effectiveDate":"2012-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["561708"],"PO":["565090"]},"189596":{"abstract":"This project, developing advanced mathematical and computational methods for the online calibration of ultrasound probes that takes into account a probabilistic version of the well-known AX = XB sensor-calibration problem that has been overlooked in the robotics and computer vision literature, will advance current capabilities in computer-integrated surgical interventions, leading to lower radiation exposure to patients and better outcomes for minimally-invasive surgery.<br\/><br\/>Ultrasound has many benefits for minimally-invasive surgical procedures, including cost, ease-of-use, and patient\/doctor radiation exposure. But ultrasound images are fuzzy and require extensive training for proper use during surgical procedures. As a result, outcomes are heavily dependent on an individual surgeon's skill with the device. <br\/><br\/>Broader Impacts: Beyond the potential benefits to surgical procedures, the Laboratory for Computational Sensing and Robotics (LCSR) at JHU has an established summer program for visiting undergraduate students that will facilitate involvement of undergraduates in the proposed research. In addition, the PI continues to mentor high school students from Baltimore Polytechnic High School through research experiences both during the academic year and the summer. The hands-on and visual nature of ultrasound image acquisition together with the mathematical problems of registration and calibration make this an ideal project to introduce students to the importance of mathematics.","title":"RI: Medium: Automated Calibration of Ultrasound for Image-Guided Surgical Procedures","awardID":"1162095","effectiveDate":"2012-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[508352,"531057"],"PO":["564069"]},"187198":{"abstract":"Cheap sensors, high-speed wireless networks, and mobile device technologies are opening up new possibilities for human-computer interaction and are enabling important applications in areas such as health care, collaborative work, and sustainable resource use. Yet we still lack appropriate tools and methods for the design and development of applications that take advantage of these capabilities, hampering our ability to realize the technology's potential. When working with \"context-aware\" systems -- i.e., systems that sense and respond to the situations in which they are used, such as the user's current location, concurrent activities, or social setting -- it can be especially challenging to evaluate early-stage prototypes due to the difficulty of re-creating the anticipated context of use during development time. As a result, designers are forced to invest excessive effort into building robust, deployable prototypes early in the development process, resulting in premature commitment to inadequately explored design choices and an inability to apply best practices for user-centered design. <br\/><br\/>The goal of this CAREER project is to improve user-centered software development practices for context-aware applications by providing support for the systematic capture and reuse of contextual data throughout the development process. While previous efforts to support context-aware development have sought to make it easier to take prototypes into the field for testing, this approach seeks to \"bring the field into the lab\" by providing continuously available representations of an application's anticipated context of use. Such representations can be used for exploring and validating design alternatives with as little effort as possible. <br\/><br\/>The PI's RePlay system provides baseline support for the capture and playback of sensor traces representing an application's context, and will be extended through this research to include support for the capture and use of large sensor trace datasets; rapid, parallel prototyping of both interactive and infrastructure components of context-aware systems; and the ability to re-create complex contextual conditions during controlled user tests to an extent not currently possible. <br\/><br\/>Broader impacts: The PI's educational mission is to prepare rising HCI professionals for the constantly changing world of technology they will face throughout their career. As part of this project, he will develop teachable methods for integrating data capture, context representation, and novel forms of user testing into software design and development practice. These methods will be incorporated into existing design and evaluation courses at the graduate and undergraduate levels. Broader impacts will be obtained by sharing course materials, along with the tools described above, with educators and practitioners via the web. The PI also plans to present tutorials and workshops on the use of capture and playback tools during design at meetings and conferences hosted by professional design organizations.","title":"CAREER: Improving the Development Process for Context-Aware Systems with Integrated Capture and Playback","awardID":"1149601","effectiveDate":"2012-07-01","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[502149],"PO":["565342"]},"197561":{"abstract":"This is funding to support a Doctoral Colloquium (workshop) of about 12 dissertation stage doctoral students, in a variety of visualization subfields, for a day of discussions and interactions with 6 distinguished research faculty, to be held in conjunction with this year's IEEE VisWeek meeting, which will take place during the week of October 14-19, 2012, in Seattle. Visualization, or the use of interactive graphics to support data analysis and understanding, has become an integral part and critical component of many application areas. IEEE VisWeek is the premier forum for visualization advances in science and engineering for academia, government, and industry, now bringing together about 900 researchers and practitioners from around the world with a shared interest in techniques, tools, and technology. VisWeek consists this year of the 23rd annual IEEE Scientific Visualization Conference (SciVis), the 18th annual IEEE Information Visualization Conference (InfoVis), and the 7th annual IEEE Visual Analytics Science and Technology Symposium (VAST). Co-located symposia this year include the IEEE Symposium on Large-Scale Data Analysis and Visualization (LDAV), the IEEE Symposium on Biological Data Visualization (BioVis), and the International Symposium on Visualization for Cyber Security (VisSec). The papers published in the special conference issue of IEEE Transactions of Visualization and Computer Graphics are rigorously refereed and widely cited. More information is available online at http:\/\/www.visweek.org. <br\/><br\/>The Doctoral Colloquium at IEEE VisWeek is a research-focused meeting which has taken place annually at the Visualization conference since 2006, and has helped launch the careers of a number of outstanding young researchers. In 2012 the workshop will convene on Sunday, October 14 or on Monday, October 15, with follow-up events during the VisWeek technical program. A primary goal of the Doctoral Colloquium is to allow students to discuss their research directions in a supportive atmosphere with a panel of distinguished leaders and with their peers, who will provide helpful feedback and fresh perspectives. The workshop supports community building, by connecting beginning and advanced researchers, one of the objectives being to build a cohort group of new researchers who will then have a network of colleagues across the world. Student research will be disseminated via posters during the VisWeek technical program, and via publication in the VisWeek Extended Abstracts. Feedback about the Doctoral Colloquium will be provided to future conference committees. <br\/><br\/>Broader Impacts: The VisWeek Doctoral Colloquium brings together the best of the next generation of visualization researchers and allows them to create a social network both among themselves and with senior researchers, which plays a major role in their enculturation into the profession. Since the students and faculty are a diverse group on several dimensions (nationality, scientific discipline, research specialization), the students' horizons are broadened at a critical stage in their professional development. The PI has affirmed that in managing this event the organizers, while trying to identify and include the broadest possible group of highly qualified participants, will also make an effort to encourage participation by women, racial\/ethnic minorities, and persons with disabilities. They will furthermore ensure that NSF funds are used chiefly to support participation by students enrolled in graduate programs in the United States.","title":"Workshop: Doctoral Colloquium at IEEE VisWeek 2012","awardID":"1244831","effectiveDate":"2012-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[530054,"559568",530056],"PO":["565227"]},"189531":{"abstract":"Reports estimate that regression testing, which is the activity of retesting a software system after it has been modified, can consume up to 50% of the cost of software development and maintenance. Although there are many techniques that can reduce the cost of regression testing, most of them do not account for important characteristics of modern systems, such as product lines, web applications, service-oriented architectures, and cloud-based applications. These systems are increasingly heterogeneous: they may come from different sources, may be written in different languages, and may be accessible in different formats (e.g., source code, binary code, or through remote interfaces). Moreover, modern software is often environment dependent: its behavior can be affected not only by changes in the code, but also by changes in its complex environment (e.g., databases, configuration files, and network layouts). Because most existing regression-testing techniques do not account for these characteristics, the application of these techniques can result in inadequately tested software, problems during maintenance, and ultimately poor software quality.<br\/><br\/>The overall goal of this research is to go beyond the state of the art in regression testing by defining novel approaches that can be applied to modern, real-world software and account for its characteristics and complexity. To achieve this goal, the research will first extend analysis techniques on which regression-testing approaches rely, such as system modeling, version differencing, coverage analysis, and impact analysis. The research will then leverage these fundamental techniques to develop, evaluate with industrial partners, and make available a family of regression testing techniques and tools that can (1) build comprehensive models of heterogeneous, environment-dependent software systems, (2) evolve these models throughout the systems' lifetimes, and (3) analyze the changes across models to understand their effects on the systems' behavior and retest them effectively and efficiently. The impact of the research will be manyfold. First, the rigorous, transformative, and highly automated techniques developed will help improve the quality of today's large, complex software systems, thus benefitting all segments of society that depend on software. Second, the release of the produced tools and infrastructure will let other researchers and practitioners build on our results, advancing knowledge and understanding. Finally, the research findings will be integrated in curriculum materials that will be made available to the broader scientific community, which will help prepare a globally competitive workforce and further benefit society.","title":"SHF: Medium: Collaborative Research: Regression Testing Techniques for Real-world Software Systems","awardID":"1161767","effectiveDate":"2012-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["511534"],"PO":["564388"]},"189586":{"abstract":"The central theme of this project is to investigate methodologies and theories to enhance throughput, delay, and fairness of cognitive radio networks via integrated dynamic spectrum access. The research will develop new methods to:<br\/>1) Extend spectrum sensing beyond just the presence and absence of the primary spectrum users' activities at certain spectrum bands\/channels, but also their locations and transmit powers <br\/>2) Predict the primary spectrum user's activity and its interval using game theoretic and statistical learning approaches<br\/>3) Perform delay-aware spectrum management with a very comprehensive delay model considering all the factors that may affect the delivery latency of a packet, including the spectrum sensing delay, the transmission delay, the queuing delay, and the spectrum negotiation and scheduling delay <br\/>4) Share spectrum in a fair manner considering the tradeoff between fairness and throughput<br\/>5) Propose a delay-aware fair routing protocol for throughput optimization which jointly considers throughput, delay, and fairness along with dynamic spectrum management.<br\/><br\/>The project's focus on dynamic spectrum access is of high national interest and can create significant impact on spectral usage policies and related industries in the telecommunication and information technology sectors. The project will also encourage and include under-represented and minority students to be part of this activity, while extending education and outreach plans to undergraduates and K-12 students.","title":"NeTS: Medium: Collaborative Research: Integrated Dynamic Spectrum Access for Throughput, Delay, and Fairness Enhancement","awardID":"1162057","effectiveDate":"2012-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["531651","560587"],"PO":["565303"]},"187287":{"abstract":"Visualization plays a crucial role in research and industry by offering users a graphical interface to their data that affords them an intuitive basis for interpretation, assessment and decision making. Yet, the rapidly growing size, dimensionality, and multi-scale complexity of the produced scientific data create a pervasive analysis challenge that is not properly addressed by existing visualization technology. In particular, the investigation of inherently multivariate and multifield physical problems is typically reduced to the visualization of a single scalar or vector field, thereby neglecting a wealth of important information.<br\/><br\/>The PI will address the limitations of the current state of the art by pioneering a comprehensive approach for the efficient visual analysis of large-scale datasets. Central to the proposed approach is a novel definition of geometric saliency that will permit the automatic identification of remarkable manifolds in scientific data. To that end, the PI will unify and subsume a variety of concepts from mathematics and computer vision to create a principled and versatile model for the structural analysis and visual representation of multifield problems. Innovative data structures and sparse sampling strategies leveraging parallel architectures will be devised to enable the efficient processing of large and multivariate datasets at scale. Lastly, these computational foundations will power a user-centric visual analysis framework that the PI will assess in the context of multidisciplinary collaborations spanning fluid dynamics, materials engineering, high-energy physics, and cardiovascular research.<br\/><br\/>This research effort will benefit the scientific community by contributing a rigorous and scalable framework for the effective analysis and visualization of computational or measured datasets across a broad range of scientific problems. The PI will distribute the created software artifacts through an open source web portal and integrate them in leading visualization tools to facilitate their dissemination. The PI will organize tutorials and workshops at premier conferences to raise the awareness of the user community about the developed technology and he will provide benchmark datasets and sample results to promote a collaborative effort in the visualization community. Beyond research, the PI will create new courses at both the undergraduate and graduate levels to expose students to the critical importance of data analysis in science and engineering and to the role of advanced visualization in this context. Finally, these education activities will naturally complement an outreach effort toward underrepresented minorities and local K-12 programs.","title":"CAREER: Efficient Structural Analysis of Multivariate Fields for Scalable Visualization","awardID":"1150000","effectiveDate":"2012-07-01","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0302","name":"Division of ASTRONOMICAL SCIENCES","abbr":"AST"},"pgm":{"id":"1045","name":"CAREER: FACULTY EARLY CAR DEV"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[502328],"PO":["565247"]},"187298":{"abstract":"Combinatorial optimization problems are of great importance to numerous applications. They arise in operations research, machine learning, VLSI design, computational biology and many other areas. Many optimization problems however are NP-hard and thus cannot be solved exactly in polynomial time unless P=NP. It is natural therefore to look for approximation algorithms, efficient algorithms that find only approximate solutions. Design and analysis of approximation algorithms is a very active research area. Various approaches for solving combinatorial optimization problems have appeared in the last three decades. However, despite significant progress, many important problems are still open. <br\/><br\/>This research project aims to advance the application of metric geometry techniques for solving combinatorial optimization problems, investigate new methods for designing approximation algorithms, and develop tools for analyzing the performance of approximation algorithms on real-life instances. This research project will be both theoretically important and practically relevant and it will lead to development of approximation algorithms for important applied problems that occur in many fields of science and engineering. Specifically, the PI will work on the following problems.<br\/><br\/>* Traditionally most research has focused on analyzing the worst case performance of approximation algorithms. However, practitioners observe that instances of combinatorial optimization problems that arise in practice are often not as hard as worst case instances. The PI will study semi-random models for various combinatorial optimization problems, and develop approximation algorithms that perform well on semi-random instances. This can perhaps explain what we see in practice.<br\/><br\/>* Recent research in the hardness of approximation initiated by Khot identified Unique Games Problem as a combinatorial obstacle to the development of approximation algorithms for many problems. The PI will study algorithmic techniques for solving the Unique Games Problem.<br\/><br\/>* The PI will study lift-and-project hierarchies of linear programming (LP) and semi-definite programming (SDP) relaxations, analyze their integrality gaps, and design subexponential approximation algorithms that use these hierarchies.<br\/><br\/>* There is a close connection between some areas of theoretical computer science and pure mathematics. To settle down some problems in combinatorial optimization, we need to resolve closely connected open problems in analysis. The PI will explore several problems with deep ties to computer science and mathematics.","title":"CAREER: Metric Geometry Techniques for Approximation Algorithms","awardID":"1150062","effectiveDate":"2012-07-01","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["542051"],"PO":["565251"]},"193392":{"abstract":"Cryptography provides a means of securing communications and authentication, e.g., between you and a bank, which has great utility in everyday life in both the physical and virtual world. An important underlying principle in cryptography is that an attacker must perform disproportionately more work than a legitimate user to achieve access to a resource. However, the threat of online fraud and the insecurity of weak passwords have grown to become a serious problem. This project will study methods for building secure, physical token-based systems from self-assembled nanostructures that are physically unclonable, yet practical for use in protecting digital communications channels. The goal of this research is to understand the fundamental science behind the operation of these devices and how to engineer more secure cyber-physical systems.<br\/><br\/>The broader impact of this project includes three aspects: (1) the development of system-level modeling tools, (2) exploration of various approaches for informal science education based on the theme of self-assembly and cryptography, and (3) several supplemental lecture modules at the high school, undergraduate, and graduate level on this subject enhanced by recent research results.","title":"SHF: Small:Enabling Practical, Secure, and Physically Unclonable Cryptographic Systems","awardID":"1217866","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[518001],"PO":["562984"]},"194064":{"abstract":"Performing financial transactions on a smartphone raises a number of security concerns. How can a bank be certain that a request is authentic? How do we prevent the same transaction to be unintentionally repeated? How can we ensure your sensitive information cannot be copied even if a phone is lost? Strong hardware security functions such as device fingerprints and true random number generators are essential in addressing these questions. However, traditional hardware security functions are difficult and expensive to build. This project investigates using off-the-shelf Flash memory, which is already in most digital systems today, to provide security functions like device fingerprints, random number generators, and secure information storage. These security functions will be extracted in a plug-and-play fashion from today's Flash without any customized modification, enabling hardware-based security in virtually all electronic devices. Therefore, this project will greatly enhance security and privacy in an era where computing devices are everywhere. Also, the project will train and educate a new generation of interdisciplinary engineers who can understand both security and semiconductor device.<br\/><br\/>To enable the proposed security functions, this project taps into inherent analog behaviors of Flash memory such as hidden variations, noises, aging, etc. For example, random numbers can be generated from thermal or quantum noise in Flash memory. The device fingerprints can be extracted from program\/erase timing variations of each memory cell, which cannot be predicted or controlled even by the Flash memory manufacturer. Information hiding can be achieved through selective stressing of bits to create probabilistic differences. Such hidden information will be very difficult to copy or even detect unless a specific secret key is known. These analog behaviors can be observed through the standard Flash memory interface without interfering with normal memory functions. Therefore, the proposed security functions will be broadly applicable to electronic systems with Flash memory.","title":"TWC: Small: Flash Memory for Ubiquitous Hardware Security Functions","awardID":"1223955","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[519714,519715],"PO":["565264"]},"189543":{"abstract":"Reports estimate that regression testing, which is the activity of retesting a software system after it has been modified, can consume up to 50% of the cost of software development and maintenance. Although there are many techniques that can reduce the cost of regression testing, most of them do not account for important characteristics of modern systems, such as product lines, web applications, service-oriented architectures, and cloud-based applications. These systems are increasingly heterogeneous: they may come from different sources, may be written in different languages, and may be accessible in different formats (e.g., source code, binary code, or through remote interfaces). Moreover, modern software is often environment dependent: its behavior can be affected not only by changes in the code, but also by changes in its complex environment (e.g., databases, configuration files, and network layouts). Because most existing regression-testing techniques do not account for these characteristics, the application of these techniques can result in inadequately tested software, problems during maintenance, and ultimately poor software quality.<br\/><br\/>The overall goal of this research is to go beyond the state of the art in regression testing by defining novel approaches that can be applied to modern, real-world software and account for its characteristics and complexity. To achieve this goal, the research will first extend analysis techniques on which regression-testing approaches rely, such as system modeling, version differencing, coverage analysis, and impact analysis. The research will then leverage these fundamental techniques to develop, evaluate with industrial partners, and make available a family of regression testing techniques and tools that can (1) build comprehensive models of heterogeneous, environment-dependent software systems, (2) evolve these models throughout the systems' lifetimes, and (3) analyze the changes across models to understand their effects on the systems' behavior and retest them effectively and efficiently. The impact of the research will be manyfold. First, the rigorous, transformative, and highly automated techniques developed will help improve the quality of today's large, complex software systems, thus benefitting all segments of society that depend on software. Second, the release of the produced tools and infrastructure will let other researchers and practitioners build on our results, advancing knowledge and understanding. Finally, the research findings will be integrated in curriculum materials that will be made available to the broader scientific community, which will help prepare a globally competitive workforce and further benefit society.","title":"SHF: Medium: Collaborative Research: Regression Testing Techniques for Real-world Software Systems","awardID":"1161821","effectiveDate":"2012-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["550999","530729"],"PO":["564388"]},"193371":{"abstract":"Three-dimensional integrated circuits (3D-ICs) using through-silicon vias (TSVs) is an important new technology that overcomes barriers in interconnect scaling. It provides significant advantages including increased functional density, higher performance, and lower power. This research project will explore new ideas, concepts, and directions for test and repair of 3D-ICs which hold promise to significantly reduce test costs and improve yield. The ability to select which dies\/wafers are stacked together and in what order and with what rotational symmetry are degrees of freedom in constructing 3D-ICs that can be exploited. New strategies for using this to reduce the cost and increase the effectiveness of defect tolerance techniques will be investigated. To reduce test costs, new distributed test compression architectures will be developed which create a new paradigm for test scheduling enabling much greater flexibility and efficiency to shorten test time and improve product quality.<br\/><br\/> This research project will generate new theory, concepts, and techniques for significantly improving test costs and yield for 3D-ICs. This is a key factor for keeping down the manufacturing costs of 3D chips and allowing them to penetrate new markets and benefit society. Knowledge and experience generated from this project will be incorporated into courses in VLSI design and test. Students will be trained and prepared for the next generation semiconductor workforce. Undergraduate students will be involved in the project, including those from underrepresented groups, through undergraduate research projects, senior design projects, and course projects based on this research.","title":"SHF: Small: Efficient Test and Yield Enhancement Techniques for 3D Integrated Circuits","awardID":"1217750","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[517957],"PO":["562984"]},"193294":{"abstract":"Modern machine learning algorithms often encounter a trade off between scalability and modeling power. For the problem of data clustering, Bayesian approaches enjoy numerous modeling advantages over classical methods, but hard clustering methods such as k-means are often preferred in practice due to their simplicity and scalability.<br\/><br\/>This project explores bridging the gap between classical hard clustering methods and clustering models based on Bayesian nonparametrics. The first step is an asymptotic result connecting the Dirichlet process Gaussian mixture model with a k-means-like algorithm that does not fix the number of clusters in advance. Using this key result, the PI and his team will explore four related research directions which collectively demonstrate the utility of this asymptotic approach: (1) extensions of the analysis to hierarchical Bayesian models, leading to scalable hard clustering methods over multiple data sets; (2) connections to spectral methods and graph clustering, leading to novel and flexible graph clustering methods; (3) extensions beyond the Gaussian setting, leading to new approaches to topic modeling and other discrete-data clustering problems; and (4) extensive experiments in both the computer vision and text domains.<br\/><br\/>Given that k-means is truly a workhorse of machine learning, these four directions have the potential to impact a wide array of large-scale applications including computer vision, bioinformatics, social network analysis, and many other domains. Furthermore, the research will benefit the broader community through released software and integration into coursework at Ohio State University.","title":"RI: Small: Hard Clustering via Bayesian Nonparametrics","awardID":"1217433","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[517776],"PO":["562760"]},"197376":{"abstract":"This is funding to support a Doctoral Consortium (workshop) of approximately 8 promising graduate students from the United States (with perhaps some international attendees as well), along with a panel of about 5 distinguished research faculty mentors. The event will take place immediately preceding and in conjunction with the 8th International ACM Symposium on Wikis and Open Collaboration (Wikisym 2012), which will be held August 27-29 in Linz, Austria. Wikisym is the leading international forum for bringing together researchers, practitioners, and entrepreneurs working on open collaboration and wiki-style socio-technical systems. The topic of open collaboration is the study of the forms of collaboration found in open source software and communities such as Wikipedia, Yahoo! Answers, Slashdot, and Digg. Such systems have shown the power to be gained from creating technologies that enable large distributed groups of people to collaboratively create artifacts of lasting value. Wikisym is attended each year by approximately 100 people from around the world; research presented at this conference is archived in the ACM Digital Library, and has been increasingly cited in recent years when referring to work in this area.<br\/><br\/>The goals of the Wikisym Doctoral Consortium are: to build a cohort group of new researchers who will then have a network of colleagues spread out across the world; to guide the work of the new researchers through advice from experts in their research field; to provide encouragement and support for the selection of research topics; to illustrate the interrelationship and diversity of research in the open collaboration area, and identify suitable opportunities for deployment and field evaluation; and to make it possible for promising newcomers to participate in the leading research conference in their field and to have an enjoyable and rewarding experience, thereby encouraging them to attend the conference in the future.<br\/><br\/>Broader Impacts: The WikiSym Doctoral Consortium has been successful in past years in attracting an international and interdisciplinary student constituency, bringing together the best of the next generation of researchers in open collaboration and allowing them to create a social network both among themselves and with senior researchers, who provide mentorship and expert feedback at a critical stage in their professional development (during the Consortium each student makes a formal presentation about his or her doctoral research). Student participants typically come from a wide range of programs and disciplines, including computer science, information, communication and sociology. They build ties to mentors that are often helpful beyond the time of the event; their diversity allows them to share broad research perspectives and learn about heterogeneous approaches to research under a shared topic of interest. The organizers will try explicitly to identify and include the broadest possible group of highly qualified participants, so that the student and faculty participants will constitute a diverse group across a variety of dimensions, which will help broaden the students' horizons to the future benefit of the field. In accordance with CISE policy relating to funding of events held abroad, the PI has provided assurance that NSF funds will be used solely to support participation by students enrolled in graduate programs in the United States.","title":"Workshop: Wikisym 2012 Doctoral Research Consortium","awardID":"1243651","effectiveDate":"2012-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[529586],"PO":["565227"]},"187124":{"abstract":"Animal social behavior occurs in many species, often with spectacular visual results. In the past, studies have either focused on (1) why animals join groups, or (2) the \"traffic rules\" animals use to position themselves within groups. However, there is currently no theory to describe how one would go about connecting these two ideas. This project will create a single theoretical system that explicitly integrates the two concepts by combining existing models of animal social behavior and will generate a new computer toolkit to allow the development of the new model. The primary results of this project will be a new, unifying theory of animal social behavior and a new user-friendly toolkit to conduct behavioral analysis. By developing new theory and providing new tools to study social behavior, this project will integrate research and education and transform the way students learn about science. To make the new toolkit available to the widest possible audience, all computer programs and data will be stored in the WSSU library digital archive at http:\/\/www.wssu.edu\/cg-okelly-library\/archives\/digitalcollection.aspx.<br\/><br\/>This project will have broader impact on the scientific community by providing a new framework for future investigators, and by providing them with a user-friendly computer toolkit. This project will have broader impact in education because it will popularize the science of behavioral ecology, and broaden participation in science by under-represented groups. A new seminar course and independent student projects will help increase the popularity of behavioral ecology on campus. Students will also maintain a project web site and develop \"smartphone\" applications based on the research toolkit. These student-led projects will serve as portals to incite interest in behavioral ecology by the general population, allowing the project's content to reach thousands.","title":"CAREER: Creating a Unified Framework for the Quantitative Study of Animal Aggregations","awardID":"1149302","effectiveDate":"2012-07-01","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"7659","name":"ANIMAL BEHAVIOR"}}],"PIcoPI":[501997],"PO":["563601"]},"200984":{"abstract":"This collaborative research investigates a new class of dialog-based, home robotic healthcare assistants to facilitate a new level of in-home, real-time care to elderly and depressed patients, providing lower total costs and higher quality of life. An emotive, physical avatar, called a companionbot, which possesses the ability to engage humans in a way that is unobtrusive and suspends disbelief will be built in this project. The companionbot will be an integration of human language technology, vision, other sensory processing and emotive robotic technology to proactively recognize and dialog with isolated and elderly patients suffering from depression. The companionbot will utilize proactive or companionable dialog based on the context with users suffering from depression. This will require the first multimodal integration of a user model, environment model, and temporal processing with spoken dialog understanding and generation to produce dynamic dialog and emotive interaction, beyond the traditional scripted dialog and emotion. Object recognition, facial expression recognition, and human activity recognition will augment natural language processing to provide current and historical context important to dynamic dialog. <br\/><br\/>A team of skilled researchers, assembled from the University of Colorado Boulder, University of Denver, CU Anschutz Medical Campus, and Boulder Language Technologies, will work together to achieve the project goals. The investigators will use the companionbots as a tool to run clinical trials to monitor and dialog with their partners to detect signs of physical and emotional deterioration. The companionbots can then notify remote caregivers, as necessary, provide warnings, reminders, life coaching and therapeutic dialog, extending independence and quality of life, and even saving lives. The other benefits of such a system include continuous, annotated data to improve doctor-patient interaction and analysis, real-time monitoring of mental state for remote healthcare providers and, ultimately, real-time intervention as part of a comprehensive treatment strategy.<br\/><br\/>In addition, this research will promote both STEM practice and research education at the graduate and the undergraduate levels of the affiliated institutions. The companionbots are ideal for teaching the next generation of engineers and scientists in critical emerging technologies, as they permit either a deep focus on specific topics or an interdisciplinary perspective while providing a simple high-level interface to manage everything else. Furthermore, the project will develop related educational material to support others and will provide public outreach to K-12 classes in the area.","title":"SHB: Large: Collaborative Research: Companionbots for Proactive Therapeutic Dialog on Depression","awardID":"1262860","effectiveDate":"2012-07-01","expirationDate":"2015-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[538846],"PO":["565136"]},"193592":{"abstract":"As computation devices are becoming increasingly ubiquitous, they are running software from a variety of domains ranging from the mobile and graphics space all the way to high-performance, large-data server domains. This software must achieve high performance, while consuming minimal power for environmental reasons. As a result, computing systems are becoming increasingly heterogeneous, accommodating diverse hardware structures conducive to different software domains on a single platform. While processors in computing systems have traditionally been the focal point for this proliferation of heterogeneity, memory systems continue to be architected using traditional means. As such, a major challenge in forward-looking heterogeneous computing systems is how best to design memory systems to support this heterogeneity. These designs are crucial to ensure that computing systems continue to adapt to their varied software, performance, and energy requirements.<br\/><br\/>This research provides the foundation to construct memory systems using a variety of architectures and technologies to run software from a variety of domains in a high-performance, yet energy-efficient manner. This work focuses on (1) constructing a systematic design methodology, software characterizations, and analytical models that guide how diverse current and future memory technologies should be combined to best support heterogeneous computing systems software, and (2) designing a range of detailed, yet flexible experimental platforms to test such studies. This project impacts society in a number of ways, most keenly by (1) reducing the energy consumption of current and future heterogeneous computing systems without sacrificing their high performance; (2) providing a systematic and rigorous scientific means to match different memory technologies and components to different software requirements; and (3) creating the evaluation tools necessary to accommodate a host of future memory subsystem research.","title":"SHF: Small: Heterogeneous Memory Architectures for Future Many-core Systems","awardID":"1218794","effectiveDate":"2012-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["556616","556617"],"PO":["366560"]},"193372":{"abstract":"The presence of salient features or anomalous behavior is a characteristic shared in many modern application domains. For example, an anomalous region in an MRI image could indicate the presence of a tumor or lesion; accurately locating conspicuous features in perhaps very high-dimensional images is a critical step in automated surveillance; and identification of anomalies in network traffic is a crucial step in detecting various attacks. Each of these applications is illustrative of an underlying theme, where subsets of data or image sub-regions are deemed interesting based on their relationship with (or, more precisely, their deviation from) typical behavior exhibited by the bulk of the data. In this sense, saliency can be understood as a natural generalization of the notion of sparsity, but one that is intrinsic to the data itself.<br\/><br\/>Recent developments in compressive and adaptive sensing have demonstrated that tremendous improvements in sensing resource efficiency can be realized when inferring high-dimensional data or objects that possess simple, low-dimensional representations. This research develops new theory and methods extending resource-efficient compressive and adaptive sensing techniques, which exploit sparsity as a model for data parsimony, to procedures that exploit saliency as a low-dimensional model for certain high-dimensional data. In particular, this effort (1) advances the current state-of-the-art theory and methods in compressive and adaptive sensing by developing a novel set of efficient saliency-based sensing methods, (2) demonstrates the robustness of these methods to uncertainties and noise, (3) integrates these new developments into the curriculum at the University of Minnesota, and (4) leverages emerging mobile device technologies as a novel vehicle for demonstrating and broadly disseminating the results of this effort to potentially new and diverse audiences.","title":"CIF: Small: Beyond Sparsity - Exploiting Saliency in Compressive and Adaptive Sensing","awardID":"1217751","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["531736"],"PO":["564898"]},"193295":{"abstract":"The past decade has redefined the path of computer design in all aspects of computing. Whether the application is high-performance or general-purpose processors, the push is for improved performance through parallelism in the face of device constraints, bandwidth constraints, and power constraints. Area on chip is now \"virtually free,\" while power and bandwidth are precious commodities. Recent research has proposed many approaches to tackling this problem, including heterogeneous architectures, specialized function units, reconfigurable cores and 3D-integration. However, this decade, computer designers must work within the design constraints wherein not all of the chip can be turned on simultaneously. Computer designers must find a way to classify programs by their architectural needs, and find the best configurations for each classification. This need, combined with the increased diversity in parallel algorithms, presents a challenge: finding \"shapes\" of computation that are meaningful both to the programmer and architect. It also presents the challenge of designing architectures for each computational classification. <br\/><br\/>This project will tackle this important problem by detecting algorithmic level parallel programming patterns, exploring a classification system using these patterns, and proposing computer features that are beneficial for each pattern. We will design a pattern-based dynamic architecture that includes pattern-specific hardware optimizations that are in turn enabled only when needed. For detection, we will investigate both programmer supplied inference detection as well as online dynamic detection. <br\/><br\/>This activity will promote teaching, training, and learning. It will be a goal of this project to involve the participation of underrepresented groups both through REU activities and through the selection of the graduate student involved in this project. The results of this research will be disseminated broadly via high-profile conference proceedings, scientific journals and via the Internet. Since we believe strongly that parallel patterns will drive computer design in the future, we propose developing PatternBench, a benchmark suite that encapsulates the space of all possible parallel patterns. Our plan is to make this benchmark suite available to aid in dissemination of this research. The broader impact to society of this work is to make future computers more power-efficient and to allow for continued performance scaling in the new era.","title":"SHF: Small: Parallel Pattern Driven Adaptive Manycore Computer Architectures","awardID":"1217434","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[517778],"PO":["366560"]},"189633":{"abstract":"Software is remarkably important to modern life. The correct and secure behavior of software that controls nearly all major machines and communications systems, from aircraft and cars to medical records and financial transactions, is mission-critical and often can be a matter of life and death. The current industry-standard method for assessing correctness of software, known as \"software testing\", is not foolproof. This research project will combine the interdisciplinary expertise of the investigators in software engineering and mathematical logic to support a paradigm shift toward \"verified software\": programs that have been entirely and mechanically proved, using formal mathematical logic, to be correct relative to full behavioral specifications of what they are supposed to do and what they are not supposed to do. Given the broad benefits of correct software to society and its impact on national competitiveness, a strong U.S. presence in verified software research and education must be a national priority.<br\/><br\/>While transition of research ideas to practice will take time, the idea of a verifying compiler for sequential, object-based software is tantalizingly close to reality. In what can be properly described as the \"end game\", extensive empirical studies of Verification Conditions (VCs) for correct software already have been undertaken. VCs are assertions that establish that a program is correct if and only if they can be proved. It has been observed that when VCs are not provable mechanically, the obstacles lie in proving VCs that are \"obvious\" to mathematicians, and in engineering specifications and supporting mathematics so they lead to VCs that are also \"obvious\" to automated provers. The expected results of this project are programming language- and tool-independent improvements in automated software verification that will be widely applicable. Another key project goal is integration of new concepts and tools supporting verified software into undergraduate and graduate Computer Science courses. These efforts will contribute to development of a superior next-generation software engineering workforce.","title":"SHF: Medium: Collaborative Research: Specification and Mathematics Engineering for the Verified Software End-Game","awardID":"1162331","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[508443,508444],"PO":["565264"]},"198466":{"abstract":"Efficient signal representation is critical in virtually all disciplines of science. Sparse representations have recently drawn much attention from the signal processing community. The basic model consists of considering that natural signals admit a sparse decomposition as a combination of very few atoms in some redundant dictionary. Recent results have shown that learning overcomplete non-parametric dictionaries for image representation, instead of using classical off-the-shelf ones, significantly improves numerous image and video processing tasks. This research aims at developing a comprehensive theoretical, computational, and practical framework for learning sparse representations for numerous signal analysis tasks.<br\/><br\/>First, the research concentrates on learning sparse representations for global and local robust image classification tasks, proposing formulations with both sparse reconstruction and class discrimination components, jointly optimized during dictionary learning. Multiscale dictionary learning and investigating a number of critical optimization challenges are integral components of this project as well. The framework of learning multiscale sparse representations is then extended to multimodal data. As in the work with images and video, the energies proposed for multimodality consider both reconstructive and discriminative terms, learning the optimal representations both for the given data and the given tasks. In addition to image, video, and audio, other signal modalities studied include tensors, which are critical in diffusion MRI, and bring the additional challenge of developing sparse representations for non-flat data. The proposed work is also extended to learning to sense, where combined with the learning of the optimal dictionaries the learning of the best linear sensing procedures is studied.","title":"Learning sparse representations for restoration and classification: Theory, Computations, and Applications in Image, Video, and Multimodal Analysis","awardID":"1249263","effectiveDate":"2012-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["549760"],"PO":["564898"]},"189666":{"abstract":"Submodularity is an intuitive diminishing returns property, stating that adding an element to a smaller set helps more than adding it to a larger set. Submodularity allows one to efficiently find provably optimal or near-optimal solutions to discrete problems. Submodular minimization has found use, e.g., in graphical model inference and clustering, whereas maximization has been applied, e.g., to variable\/feature selection and active learning. Submodularity, however, is still only beginning to show applicability in machine learning and its applications. Moreover, work on submodular optimization in the combinatorics and operations research literature has been primarily unaware of unique problems arising in machine learning. Therefore, existing standard algorithms do not exploit certain structures or variants of the submodular problems arising in machine learning. Studying novel machine learning problems involving submodular objectives can thus lead to advances in the pure combinatorics literature. We propose to pursue activities that bring together research in machine learning and combinatorial optimization to solve problems which neither of the communities can solve alone.<br\/><br\/>In particular, we propose to use insights from machine learning to enable scaling up typical submodular optimization problem sizes (by focusing on problem instances arising in learning). We also propose to further chart the territory that submodularity plays in machine learning. In this grant, we will introduce new submodular structures specifically related to submodularity. We will introduce submodular learning problems for machine learning. We will introduce new submodular optimization problems with constraints. And lastly, we will apply these submodular instances to real-world applications in computer vision, speech recognition, and natural language processing.","title":"RI: Medium: Advances and Applications in Submodularity for Machine Learning","awardID":"1162606","effectiveDate":"2012-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[508528],"PO":["562760"]},"193560":{"abstract":"Custom domain-specific architectures have great promise for achieving energy-efficient flexible designs for a suite of applications. For practical deployment, however, there is a great need to develop smart algorithms for mapping applications of interest onto these architectures. The main thrust of this research is to discover novel mapping algorithms by making use of human intuition and ability to recognize patterns and opportunities even in complex problems. Participants are presented with successively more difficult mapping problems in a game environment, and the vast dataset of participants' moves is analyzed to recognize common patterns used by successful game participants. The insights gained from strategic moves humans make while solving problems based on their visual intuition and experience can be used to discover new mapping approaches that are beyond what can be conceived with traditional algorithms. For broad scope and impact, this research places particular attention on multiple architectural designs, highly constrained (and thus very difficult) mapping problems, and engaging a broad community of contributors through crowdsourcing.<br\/><br\/>Fast and effective mapping techniques, and a methodology for developing new such techniques as needed has the potential to inspire architectural innovation and result in production of devices that are faster, cheaper, and smarter. Results from this research can advance next generation portable\/wearable devices critical to health, safety and security, personal multimedia, and aerospace.","title":"SHF: Small: Harnessing human intelligence for mapping on custom reconfigurable architectures","awardID":"1218656","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}}],"PIcoPI":[518393],"PO":["565272"]},"193351":{"abstract":"With the growth of cloud computing and the changing manner in which individuals and businesses interact with data, it is increasingly important to manage data efficiently and reliably. The RESAR project tackles the problem of building ever-larger data stores, and offers a novel approach to reducing the energy impact of such increases in scale while allowing easier management and adaptation of the system as it ages. In other words, RESAR offers a means to gracefully adapt a storage system to offer increased reliability or performance as demanded by the systems' age or administrator's requirements. This project develops, studies, and optimizes reliable, energy-efficient storage needed in modern data centers and large-scale data storage environments, and allows such storage systems to gracefully increase its performance and reliability while efficiently scaling to millions of storage devices.<br\/><br\/>For storage systems to be feasible and manageable at increasing scales, need to be self-healing and self-optimizing, able to adapt to aging and new components whilst dynamically recovering from inevitable component failures. Cloud computing promises savings in staffing as the volume of work in a data center would be distributed over fewer, but better trained staff. While the increasing scale of such data centers offers greater opportunities for energy-saving measures to become more effective, such scales rapidly increase fears of individual components failing. This demands that such large scale storage systems be arranged in such a way as to offer an ability to survive the failure of multiple components, and to do so with minimal management overheads.<br\/><br\/>To survive the increasingly likely component failures (brought about by the increasing numbers of components in ever-growing data warehouses), storage systems typically employ some form of data replication or redundancy scheme. This strategy not only protects data against loss, but also allows faster access. Unfortunately, doubling or tripling the number of storage devices (or entire data centers) comes at a considerable cost. Alternatively, a site could use erasure correcting codes that provide protection against device failures while only increasing hardware demands by a smaller increment. But such erasure correcting schemes offer limited scalability and can complicate the implementation and self-management of a system considerably. The RESAR approach is to employ novel erasure codes that allow faster layout restructuring, while offering increased scalability, and improved reliability over competing schemes. RESAR allows for restructuring on the fly, and as such, has the added benefit of being complementary to data relocation tasks necessary for routine maintenance and optimization.<br\/><br\/>Cloud computing and data centers are taking hold as technologies with great promise for cheaper, more flexible, and more energy-efficient information processing. RESAR enables cheaper, more reliable, automated and more easily scaled storage systems. RESAR offers a novel graph representation of a failure tolerance scheme that allows the construction of flexible, dynamically reconfigurable, parity-based redundancy schemes that are well-suited for cloud storage infrastructure. By offering the benefits of more highly-convolved erasure coding schemes, whilst remaining simple and efficient, RESAR offers a new path to self-organizing large-scale storage systems. The resulting systems are more maintainable, easily reconfigured for increasing levels of reliability on-demand, and more cost effective. This efficiency further extends to reduced maintenance and energy demands.","title":"SHF: AF: Small: Collaborative Research:RESAR: Robust, Efficient, Scalable, Autonomous Reliable Storage for the Cloud","awardID":"1217648","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[517914],"PO":["565272"]},"193494":{"abstract":"The early 21st century finds power and energy as the central challenges to continued improvements in computer system performance and cost. From handheld mobile devices to the data centers that support them, computer architects must invent new energy-efficient techniques to facilitate future innovations in science, education, government and commerce. In current systems, the memory hierarchy-which stores and moves the data values used and produced by the computation-consumes more energy than the computation itself. For example, obtaining operands for a double-precision multiply-add can consume 1.7 to 200 times the operation's energy depending on where in the memory hierarchy the values are stored. Improving the energy-efficiency of memory hierarchies can not only enable advances in future computer systems, but also reduces the emission of greenhouse gases.<br\/><br\/>This project seeks novel memory hierarchy designs that minimize power and energy, rather than the classical focus on reducing latency and\/or bandwidth. These designs build on three key hypotheses: (1) cache memories can reduce energy more than either latency or bandwidth, (2) optimizing latency becomes less important when it can be tolerated, and (3) overlapping activity does not save power, but can save energy due to static power dissipation. Initial research directions include (1) a technique to reduce address translation energy using a hybrid virtual\/physical cache that eliminates the need to access a highly-associative TLB on every memory access and (2) energy-efficient cache hierarchies that use data compression techniques to replace the high energy cost of misses with lower compression and decompression overheads. This research will also extend the widely-used open-source gem5 simulation infrastructure to more accurately model the power and energy of emerging memory hierarchies.","title":"SHF: Small:Energy-Optimized Memory Hierarchies","awardID":"1218323","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["541915","541916"],"PO":["366560"]},"196245":{"abstract":"The unobtrusive monitoring of individuals with in-home sensors offers enormous potential for detecting early health problems-before they become big problems--so timely interventions can be provided to improve the health trajectory. The result is continued high functional ability, independence, and better health outcomes. Early detection of health changes is the key to this approach. This project leverages ongoing work at the University of Missouri in Health Alert Systems with sensor technology. A scaled-up version of the Health Alert System is being tested in senior housing in Cedar Falls, Iowa, using in-home sensors and remote video conferencing for nurse care coordination. Fiber networking provides the bandwidth and latency essential for the project. The Health Alert System includes motion sensors for activity monitoring and Kinect depth images for gait analysis, and integrates a new hydraulic bed sensor that captures quantitative pulse, respiration, and restlessness. Pattern recognition algorithms are used to look for changes in the sensor data patterns and generate health alerts to clinicians, who provide further diagnosis and determine appropriate interventions. The usability and effectiveness of the remote Health Alert System will be evaluated for managing chronic health conditions. Testing the Health Alert System at a remote site from the healthcare providers will provide important information about how the approach scales up into other settings with high speed video conferencing and transfer of sensor data. This will provide an important next step towards moving the approach into independent housing where seniors want to be and offers potential healthcare cost savings.","title":"EAGER: An In-Home Health Alert System with Remote Care Coordination","awardID":"1237970","effectiveDate":"2012-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["561792","561794",526107],"PO":["557315"]},"190580":{"abstract":"Over the last several years, Georgetown University has espoused a<br\/>policy of growth for its science departments. This project supports<br\/>Georgetown University's growth goals by positing a multifaceted<br\/>research program that explores new techniques for processing large<br\/>collections of text data.<br\/><br\/>The project examines how both new and existing text processing methods<br\/>may be applied to a variety of open problems across different<br\/>disciplines within computer science. Research activities include text<br\/>mining for large-scale document collections; machine learning<br\/>techniques for detecting malicious executables; information retrieval<br\/>methods for performing proactive digital forensic investigations; text<br\/>processing approaches for preventing privacy breaches in encrypted<br\/>voice-over-IP (VoIP) communication; and data mining and sentiment<br\/>detection methods for automated content analysis of large quantities<br\/>of political science texts.<br\/><br\/>To support these goals, the project includes the creation of a<br\/>next-generation infrastructure for large-scale text processing.<br\/>Data-intensive tasks will use interconnected front-end systems,<br\/>connected via high-speed networking to scalable back-end storage<br\/>solutions. The infrastructure supports the development and testing of<br\/>novel text processing algorithms on very large corpora.<br\/><br\/>The project's themes of text processing and information assurance have<br\/>been integrated into the undergraduate and graduate curricula at<br\/>Georgetown University. More broadly, the project benefits society by<br\/>improving the ability to (1) process large quantities of information,<br\/>(2) identify malicious applications, and (3) improve the resiliency of<br\/>digital communication networks to eavesdropping attacks. The project<br\/>broadens the participation in research through the University's Summer<br\/>Programs for High School Students and the Center for Multicultural<br\/>Equity and Access.","title":"II-NEW: Infrastructure for Change: From a Teaching Department to National Prominence","awardID":"1204347","effectiveDate":"2012-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["517717",510838,"559163",510840,"519691"],"PO":["563751"]},"193660":{"abstract":"More and more devices are being designed to process data in digital form including TVs, phones, cameras, music, computers, software, avionics, and encryption devices. Verification is the process of ensuring that designs are correct and that the devices do what is intended. A design error can have important consequences, from having to recall millions of devices resulting in the loss of time and money, to a failure in a mission or safety critical application, possibly causing loss of life. Simulation is the most easily applied method of verification, but it is inherently incomplete and cannot give strong guarantees for correctness. Formal verification is a powerful supplement, or sometimes alternative, to simulation-based approaches. It can produce a mathematical proof of correctness, or expose subtle bugs in a design not uncovered by simulation. Formal methods have seen great progress in the last decade, allowing them to scale up to larger problems where they can replace simulation. Similar progress in the next decade would have a significant impact in not only keeping design costs down and better guarantying safety in critical applications, but also in improving design reliability and enhancing quality by allowing aggressive logic optimization techniques to be applied and successfully verified, a current stumbling block in power optimization. This project proposes to research the fundamental algorithms of formal verification with the goals of (i) innovating new methods in formal verification, including new algorithms and better data structures; (ii) implementing and evaluating these in a common, industrial-strength system, and (iii) promoting the results to the academic, governmental, and industrial communities. <br\/><br\/>Although, the focus of this proposal is on the formal verification of micro-electronic systems and software, the core techniques used in formal verification are very general and can immediately impact many other application areas, such as cryptographic, biologic and health-care systems. Improved scalability of the techniques may well open up wider applicability in new domains such as synthetic biology, software synthesis and areas where safety is a critical issue such as automotive and aviation control systems. In addition, the enhanced ability to verify equivalence of hardware and software systems encourages the use of advanced synthesis techniques, resulting for example in improved speed, power, and area utilization in micro-chips.","title":"SHF: Small: Bit-level Formal Verification: Keeping Pace with Industrial Needs","awardID":"1219154","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[518632],"PO":["562984"]},"193550":{"abstract":"Integrated circuits (ICs) are pervasive in all aspects of our lives, used in everything from computers to mobile phones to automobiles. However, fabricating ICs that both work and are reliable is becoming extremely difficult due to the significant complexity inherent in the underlying fabrication processes. It is therefore extremely important to understand the reasons why some ICs fail to operate properly. In this NSF project, new methodologies for locating and characterizing the root cause for IC failure will be developed. Existing approaches typically produce uncertain results because they rely on limited information about the IC design. In this work, additional design information and data extracted from other failing ICs will be holistically used to efficiently derive the reason for IC failure from data measured from failing ICs. Efficiently discovering the root-cause of failure for an IC will enable the design, the fabrication and even the testing of ICs to be significantly improved, helping to ensure the continued advancement of the electronics industry.<br\/><br\/>The principal investigator (PI) is committed to having a broader impact through training a diverse group of undergraduate and graduate researchers. His research group has members from under-represented groups that include women, African Americans, Hispanic Americans, and Native Americans. In addition, as director of the Center for the Silicon System Implementation (CSSI) at Carnegie Mellon University, the PI manages a program that recruits undergrads researchers from various universities (including minority-serving institutions), and the annual convention of the National Society of Black Engineers. This program has been very successful, resulting in the recruitment of many undergraduate researchers, including both women and African-Americans. In the last few years, the PI himself has supervised nine undergraduate researchers, three of which were African-American (two male and one female). In addition, the preliminary work undertaken by this NSF contract is now published and was actually accomplished by one of our African-American researchers. The PI will continue to recruit a diverse group of students, both at the graduate and undergraduate levels, for participation in this project.","title":"SHF:Small:Test Data Learning for Ultra High Dignostic Resolution","awardID":"1218576","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["548338"],"PO":["562984"]},"193341":{"abstract":"This proposal seeks to perform fundamental cross-disciplinary cross-layered research into the design of a network stack for sensor devices that use backscatter communication. Backscatter communication is particularly attractive for single-hop sensor network deployments since communication is powered by the reader, thereby resulting in tremendous reduction in power consumption compared to devices with active radios (e.g. 802.15.4). Despite these benefits, protocols designed for backscatter are ill-designed for sensor workloads. The existing backscatter communication stack, EPC Gen 2, is optimized for supporting<br\/>large numbers of simple passive tags, that each need to transfer a small amount of data (their unique identifier). While such a model may be appropriate when RFIDs are deployed in retail stores, sensors require a different model where there are a few or moderate number of tags which need to transfer a significant amount of sensed data during contact events with a reader.<br\/><br\/>This proposes outlines a fundamentally new backscatter communication stack that is designed for next-generation sensors that use passive rather than active radios. The stack will be build on an extensive measurement-driven study of backscatter communication including an understanding of channel quality metrics, link asymmetry, spatial and temporal propagation, and harvesting characteristics. Based on this study, we will design a network stack for backscatter communication that replaces the EPC Gen 2 stack with novel methods for mobility detection, rate adaptation, channel selection, bulk transfer, and energy management.<br\/><br\/>Our research will directly impact the design, development, and deployment of next-generation sensor networks that can operate for longer durations or use smaller power sources. This can directly translate into lower total operational costs by lowering the overhead of replacing batteries. The research and teaching that will flow from the project will impact students across the Five Colleges, of which UMass Amherst is a part. The Five Colleges includes two all-women's colleges, Smith and Mount Holyoke, whose students can enroll in courses taught at UMass because of the consortium's cross-registration policy.","title":"NeTS: Small: Design of an Efficient Backscatter Communication Stack for Sensor Devices","awardID":"1217606","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["526997"],"PO":["565303"]},"193199":{"abstract":"The goal of this project is to develop foundations for message-passing algorithms, in the realm of probabilistic graphical models. The project will focus on three classes of problems in graphical models: (a) learning graphical models from observed data, (b) computing the mode of a graphical model, and (c) computing marginals of variables in a graphical model. The project will identify the strengths and limitations of the popular belief propagation algorithm for all three problems. In addition, the project will develop new class of efficient message-passing algorithms with provable performance guarantees by means of exploiting the geometry of the graphical model.<br\/><br\/>Probabilistic graphical models have become a standard way to represent uncertainty succinctly in a wide variety of applications: communication and signal processing, computation, vision and image processing, bioinformatics, natural language processing, and more. The problems faced in these applications are largely <br\/><br\/>The research outcome of this project will be folded in the course titled \"Algorithms for Inference (6.438)\" taught by the PI. The course is a popular entry level graduate course which also disseminates material online through MIT Open CourseWare and going forward, it may explore possibility of wider dissemination through MITx\/EdX.","title":"CIF: Small: Message Passing Networks","awardID":"1217043","effectiveDate":"2012-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["532110"],"PO":["564924"]},"187303":{"abstract":"Scalability is crucial for cloud computing to be widely adopted. Failure to scale has resulted in the demise of the social networking giant MySpace, the inability to support a user load greater than 10% of system capacity, a $4.5 billion annual power expenditure on data centers and a lack of any sophisticated measurement and monitoring systems in the cloud. The size of a cloud, which often consists of tens of thousands of machines, compels the use of low-complexity algorithms, which, when naively designed, cause significant performance degradation as the system grows large. Existing algorithms are often designed for exact, optimal solutions for smaller in-house systems and do not scale due to their centralized high-complexity nature.<br\/><br\/>This research overcomes the limitation of existing work by designing a suite of low-complexity algorithms for web services, data management, and measurement and monitoring in the cloud, which are exactly optimal only as the system size grows to infinity, but very close to optimal in finite and large systems. The algorithms are designed to address the challenges with dynamic scaling, multi-tenancy and data-intensiveness in the cloud, and for different application workloads including search, social networks and map-reduce. The research draws upon and contributes to the fields of graphical models and randomized algorithms, both of which exchange sparse information locally to achieve complex global objectives in large systems. The project also includes significant outreach programs in the form of workshops and lab open-houses, to promote undergraduate research, and the participation of women and under-represented minorities.","title":"CAREER: Scheduling and Resource Allocation in the Cloud using Graphical Models and Randomized Algorithms","awardID":"1150080","effectiveDate":"2012-07-01","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["415263"],"PO":["565255"]},"193661":{"abstract":"With the growth of cloud computing and the changing manner in which individuals and businesses interact with data, it is increasingly important to manage data efficiently and reliably. The RESAR project tackles the problem of building ever-larger data stores, and offers a novel approach to reducing the energy impact of such increases in scale while allowing easier management and adaptation of the system as it ages. In other words, RESAR offers a means to gracefully adapt a storage system to offer increased reliability or performance as demanded by the systems' age or administrator's requirements. This project develops, studies, and optimizes reliable, energy-efficient storage needed in modern data centers and large-scale data storage environments, and allows such storage systems to gracefully increase its performance and reliability while efficiently scaling to millions of storage devices.<br\/><br\/>For storage systems to be feasible and manageable at increasing scales, need to be self-healing and self-optimizing, able to adapt to aging and new components whilst dynamically recovering from inevitable component failures. Cloud computing promises savings in staffing as the volume of work in a data center would be distributed over fewer, but better trained staff. While the increasing scale of such data centers offers greater opportunities for energy-saving measures to become more effective, such scales rapidly increase fears of individual components failing. This demands that such large scale storage systems be arranged in such a way as to offer an ability to survive the failure of multiple components, and to do so with minimal management overheads.<br\/><br\/>To survive the increasingly likely component failures (brought about by the increasing numbers of components in ever-growing data warehouses), storage systems typically employ some form of data replication or redundancy scheme. This strategy not only protects data against loss, but also allows faster access. Unfortunately, doubling or tripling the number of storage devices (or entire data centers) comes at a considerable cost. Alternatively, a site could use erasure correcting codes that provide protection against device failures while only increasing hardware demands by a smaller increment. But such erasure correcting schemes offer limited scalability and can complicate the implementation and self-management of a system considerably. The RESAR approach is to employ novel erasure codes that allow faster layout restructuring, while offering increased scalability, and improved reliability over competing schemes. RESAR allows for restructuring on the fly, and as such, has the added benefit of being complementary to data relocation tasks necessary for routine maintenance and optimization.<br\/><br\/>Cloud computing and data centers are taking hold as technologies with great promise for cheaper, more flexible, and more energy-efficient information processing. RESAR enables cheaper, more reliable, automated and more easily scaled storage systems. RESAR offers a novel graph representation of a failure tolerance scheme that allows the construction of flexible, dynamically reconfigurable, parity-based redundancy schemes that are well-suited for cloud storage infrastructure. By offering the benefits of more highly-convolved erasure coding schemes, whilst remaining simple and efficient, RESAR offers a new path to self-organizing large-scale storage systems. The resulting systems are more maintainable, easily reconfigured for increasing levels of reliability on-demand, and more cost effective. This efficiency further extends to reduced maintenance and energy demands.","title":"SHF:AF:Small:Collaborative Research:RESAR: Robust, Efficient, Scalable, Autonomous Reliable Storage for the Cloud","awardID":"1219163","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["540846"],"PO":["565272"]},"192462":{"abstract":"Most of the traditional High-End Computing (HEC) applications and<br\/>current petascale applications are written using the Message Passing<br\/>Interface (MPI) programming model. Some of these applications are run<br\/>in MPI+OpenMP mode. However, it can be very difficult to use MPI or<br\/>MPI+OpenMP and maintain performance for applications which demonstrate<br\/>irregular and dynamic communication patterns. The Partitioned Global<br\/>Address Space (PGAS) programming model presents a flexible way for<br\/>these applications to express parallelism. Accelerators introduce<br\/>additional programming models: CUDA, OpenCL or OpenACC. Thus, the<br\/>emerging heterogeneous architectures require support for various<br\/>hybrid programming models: MPI+OpenMP, MPI+PGAS, and MPI+PGAS+OpenMP<br\/>with extended APIs for multiple levels of parallelism. Unfortunately,<br\/>there is no unified runtime which delivers the best performance and<br\/>scalability for all of these hybrid programming models for a range of<br\/>applications on current and next-generation HEC systems. This leads<br\/>to the following broad challenge: \"Can a unified runtime for hybrid<br\/>programming model be designed which can provide benefits that are<br\/>greater than the sum of its parts?\"<br\/><br\/>A synergistic and comprehensive research plan, involving computer<br\/>scientists from The Ohio State University (OSU) and Ohio Supercomputer<br\/>Center (OSC) and computational scientists from the Texas Advanced<br\/>Computing Center (TACC) and San Diego Supercomputer Center (SDSC),<br\/>University of California San Diego (UCSD), is proposed to address the<br\/>above broad challenge with innovative solutions. The investigators<br\/>will specifically address the following challenges: 1) What are the<br\/>requirements and limitations of using hybrid programming models for a<br\/>set of petascale applications? 2) What features and mechanisms are<br\/>needed in a unified runtime? 3) How can the unified runtime and<br\/>associated extension to programming model APIs be designed and<br\/>implemented? 4) How can candidate petascale applications be<br\/>redesigned to take advantage of proposed unified runtime? and 5) What<br\/>kind of benefits (in terms of performance, scalability and<br\/>productivity) can be achieved by the proposed approach? The research<br\/>will be driven by a set of applications from established NSF<br\/>computational science researchers running large scale simulations on<br\/>Ranger and other systems at OSC, SDSC and OSU. The proposed designs<br\/>will be integrated into the open-source MVAPICH2 library. The<br\/>established national-scale training and outreach programs at TACC,<br\/>SDSC and OSC will be used to disseminate the results of this research.","title":"SHF: Large: Collaborative Research: Unified Runtime for Supporting Hybrid Programming Models on Heterogeneous Architecture.","awardID":"1213056","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["558590","520355"],"PO":["565272"]},"193562":{"abstract":"In today's computing systems workload schedulers target best performance, but are unaware of thermal and power realities of the system. Similarly, the cooling subsystem controllers take only data from thermal sensors as their input and are thus totally oblivious to workload scheduling and power management decisions. Even though these systems all share a single computer infrastructure, their operation is optimized separately, resulting in inefficiencies. <br\/><br\/>This proposal goes well beyond previous work on optimizing thermal problems in CPUs separately from memory by largely neglecting the rest of the system, to solutions that understand the complex interplay between CPUs, HW accelerators such as GPUs, memory and hard disks with their related cooling subsystems. The PIs propose to develop joint control policies for such systems and to quantify the respective benefits and disadvantages. The project plans to study and design control policies for various ways of implementing cooling, using both fans and liquid cooling systems (e.g micro-channel vs. channels in a heat sink with external pump). The project will also test ideas on computing systems available in a modular data center container obtained at UCSD as a part of recently awarded NSF MRI (GreenLight) grant. <br\/><br\/>Graduate and undergraduate students will be involved in various parts of the proposed research and help in connecting this work with other NSF sponsored projects. The results of research, tools and coursework materials developed will be freely and easily distributed to engineering community at large. In addition, the PI has created a new program affiliated with the Computer Science and Engineering department at the UCSD whose target is to ensure seamless transfer of ideas, funds and people between academic and industrial settings.","title":"SHF: Small: Cooling, energy and performance management in computing systems","awardID":"1218666","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["560640"],"PO":["562984"]},"193683":{"abstract":"The ability of scientists and engineers to organize and control matter at the nanoscale is rapidly improving as ever more complicated molecular systems are being built. It is becoming clear that a systematic approach is needed to guide molecular engineers as to the kinds of systems that are useful to construct and are capable of interesting behavior. Consider the state of computer science in the 1940's, at the dawn of the information revolution. A handful of special-purpose, error-prone computers had been built. Alan Turing and others had just initiated the theoretical study of computability theory, which tells us what computers can do given unlimited resources. It was to be 20 years before the advent of computational complexity theory, the study of what computers can do given limited resources. Researchers find themselves in a similar position today in molecular computing. Experimental work in this area is becoming more and more sophisticated. DNA strand displacement has been used to construct a logic circuit, whose components are free-floating DNA strands and complexes, capable of computing square roots. DNA tile assembly has been used to implement cellular automata capable of growing into fractal patterns and counting in binary. DNA origami is enabling precise control and placement of a variety of molecular structures and systems. The PIs believe that molecular programming will ultimately allow fabrication and control of nanoscale and macroscopic artifacts whose nanoscale parts are arranged with nanoscale precision, that these artifacts will have complexity comparable to that of biological organisms, and that molecular fabrication paradigms will be inspired by biological growth and development.<br\/><br\/>Investigation of precisely what feats are possible and impossible to implement with molecular systems, using rigorous mathematical models, is a primary aim in this proposal. Work will focus on the tradeoffs between various resource bounds that arise uniquely from molecular programming. These include number of distinct molecular species, number of bond types, amount of fuel molecules consumed, and time or volume required for assembly\/computation. Molecular resources such as molecular motion, rigidity, randomness and nondeterminism will be studied. Today, a proper understanding of which tasks are efficiently executable by chemistry is totally absent. The major goals of this project are to develop this understanding and provide a theoretical foundation for the systematic development of molecular programming.<br\/><br\/>The project includes funding for summer undergraduate students, and the PIs will act as advisees for senior-year undergraduate projects. Additionally, the PIs will be involved in teaching students that are not traditionally associated with computer science so that future molecular engineers can be exposed to methods and practices needed for designing complex nanoscale chemical systems. Students will learn the theory of molecular programming and be part of a new generation to work in this exciting field. The proposed research will be complemented by educational and outreach activities with underrepresented minorities from local K-12 schools.","title":"AF: Small: Theory of Molecular Programming: Computability and Complexity","awardID":"1219274","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[518688,518689],"PO":["565223"]},"193474":{"abstract":"Electronics has enabled substantial computational capabilities in small-scale devices; this means that signals from physical systems can be presented to these devices to derive high-value outputs. The challenge is that although immense computational capacity can be realized in embedded devices, the ability to acquire a large number of signals that are distributed across a physical system, and to then communicate information over the associated distances, remains disproportionately small. Technologies are emerging, however, that enable transformational possibilities for creating communication channels and large-scale physical interfaces to electronics. Large-area electronics is a technology that enables the fabrication of interconnects as well as expansive arrays of diverse sensors on flexible, low-cost sheets. When combined with high-performance silicon integrated circuits (ICs), this technology can lead to systems where computation can be applied to physical signals on a much larger scale than that possible today. The resulting design space for the systems covers two technology domains. To create efficient and scalable systems, the platform components and hardware architectures must be analyzed rigorously, and methodologies for understanding and optimizing design trade-offs must be developed. The objective of this research is to analytically model the platform components and architectures for sensing and communication, and then to synthesize these into system design methodologies. The platform architectures include interfaces for digital and analog signaling, control circuits for sensing, and communication networks scalable to many nodes. The methodologies span analysis at the device, architecture, and system-protocol levels. <br\/><br\/>Some of the compelling applications that require large-scale interfacing of electronics with physical systems include detection of early-stage structural degradation in bridges and buildings through centimeter-resolution strain sensing, interactive surfaces for visually-rich computing via high-resolution displays and input sensors, etc. Large-area electronics and high-performance ICs, used synergistically, have the potential to enable such applications. By developing analytical models and methodologies for system design, this research aims to unite the efforts from both the technology-development and computer-systems domains. The outcomes of this study will help coordinate and focus research and engineering efforts in these areas towards the creation of optimal systems. This research will also engage a new generation of engineers, particularly from underrepresented groups, through the unique opportunity to develop systematic principles for the design of computing systems that interact extensively with physical systems. The broadened focus and new form-factors possible for computing systems will be illustrated to students through undergraduate projects and special-topic courses, as well as through Princeton outreach programs such as the Science and Engineering Expo for middle-school students, the Materials Camp for teachers, and the Princeton University Materials Academy for under-represented high-school students.","title":"SHF: Small: Analytical Modeling and Design Methodology for Large-scale Computational Systems Employing Flexible Electronics for Extensive Physical Interfacing","awardID":"1218206","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[518190,"534384",518192],"PO":["562984"]},"193243":{"abstract":"Many natural and man-made systems of interest to scientists and engineers are composed of groups of individual elements interacting with each other, through specific channels, to produce and regulate appropriate responses. Examples include chemical reaction networks, cellular (signaling, transcriptional, and metabolic) networks, pharmacokinetic networks, epidemiological networks, ecological networks, social networks, neural networks, multi-agent networks, etc. Understanding the fundamental properties and design principles of such networks is an exciting and challenging research problem whose solution requires development of new theoretical and computational approaches. To complicate matters, the dynamics of most interaction networks are inherently nonlinear and stochastic. A unifying approach is thus needed to concurrently encompass the deterministic and stochastic aspects of networks that can lead to common approaches and methods for the modeling and analysis of a diverse body of interaction networks.<br\/><br\/>The main goal of this research is to develop a general theoretical and computational approach for characterizing and analyzing complexity in nonlinear interaction networks with Markovian dynamics. While complexity may be difficult to characterize directly, this research rigorously pursues and quantifies the prevalent hallmarks of complexity: self-organization, functional stability, robustness, and evolutionary behavior. The investigators study a potential energy landscape perspective that relates topographic features of the landscape to these fundamental network properties. To achieve feasibility and computational efficiency of the main goals of this effort, new tools are being developed for computing the time evolution of the probability distribution of the underlying stochastic population dynamics. Rigorous mathematical, algorithmic, and computational approaches are then proposed for modeling the emergent behavior and complexity of Markovian interaction networks as well as for studying their functional stability and thermodynamic robustness by probabilistic sensitivity analysis techniques.","title":"CIF: Small: Understanding Complexity in Markovian Interaction Networks: Self-Organization, Functional Stability, Robustness, and Evolutionary Behavior","awardID":"1217213","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[517652],"PO":["564898"]},"195246":{"abstract":"The Workshop on Logic and Systems Biology is affiliated with the 2012 Logic in Computer Science (LICS) Conference in Dubrovnik, Croatia and is scheduled for June 29. It will consist of one day of invited lectures. The talks will cover a variety of connections between computer science and biology, with emphasis on the uses of formal logic in modeling biomolecular interaction systems.<br\/>INTELLECTUAL MERIT<br\/>The LICS organizing committee believes that logic will have an important role in systems biology, and invited a proposal for a workshop to explore current and future applications of logic to system biology. Since systems biology is a new field of study which is still unfamiliar to most LICS attendees, the organizers decided to restrict the lectures to invitation only, with an open session for discussion of future research. The lectures are intended to be accessible to computer scientists who have some knowledge about the use of formal methods for analyzing software and hardware, but who may not have much experience with biology. The speakers will also be invited to submit more technical versions of their talks to a refereed proceedings.<br\/>BROADER IMPACT<br\/>The lectures will explore connections between biology, computer science, and mathematics, with the goal of encouraging collaborations between researchers in the different groups, leading to new applications of logic and raising interesting theoretical questions. It is also expected that graduate students and recent Ph. D.s in computer science will attend the workshop. Since the talks will be partly expository, this will be an opportunity for them to broaden their perspective, with future benefits to their research and teaching.","title":"Workshop on Logic and Systems Biology","awardID":"1231446","effectiveDate":"2012-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[523415],"PO":["565223"]},"198524":{"abstract":"An issue of growing concern in the United States is the prevalence of sexual violence for women on college campuses, where up to one in four women report experiencing an attempted or completed rape while a student. It is important for these women to obtain therapeutic counseling to help them cope with the aftermath of these traumatic events. Research indicates that traditional therapy is beneficial in some instances, and additional benefits have been discovered with the use of animal-assisted therapy (AAT); however, there are limitations to AAT (e.g., training costs, availability, phobias, and allergies). <br\/><br\/>In this project the PI will explore an alternative called the Therabot, a lightweight socially assistive robotic support system. The goal is to design, implement and evaluate the efficacy of a prototype, which will improve upon the benefits discovered with AAT. To this end, the Therabot will have the appearance of a stuffed animal\/toy and will exhibit affective behaviors (including head and arm movements, and animal-like or rhythmic sounds), to provide comfort and support during therapeutic interventions for the trauma associated with sexual violence. It will be convenient and easy for patients to use, not only in the clinic or lab but also in the home to provide support and encourage home therapy practices, something which is not offered by current forms of supplemental therapy support such as therapy animals.<br\/><br\/>This preliminary research will have three phases: design and construction of the Therabot system; validation that the system works as intended with human participants; and field testing with patients at the Department of Outreach and Sexual Assault Services at the PI's institution. Three hypotheses will be evaluated as part of this exploratory research: that patients who use the Therabot in counseling will be more likely to communicate with the therapist, and will feel more supported and comfortable during counseling, compared to patients who do not use the Therabot or who use an identical-looking but non-robotic Therabot in counseling; that patients will be more likely to perform home therapy practice using the Therabot than patients who do not use the Therabot or who use an identical non-robotic Therabot in home therapy practice; and that patients using the Therabot will experience improved therapeutic outcomes compared to those who are not using the Therabot or who use an identical non-robotic Therabot.<br\/><br\/>Broader Impacts: If the PI's hypotheses are supported, this research will not only impact survivors of sexual violence but will also be applicable to other therapeutic situations such as soldiers returning from the battlefield with PTSD and survivors of natural and man-made disasters. The PI expects that a lightweight socially assistive technology system like the Therabot will provide beneficial support and companionship to patients in hospitals, hospice facilities, and long-term care environments. It will be easy to incorporate the Therabot into the curricula of both undergraduate and graduate computer science, mechanical engineering, and clinical psychology courses, and also to use it for class projects. The many expected practical applications and potential societal impacts of the Therabot will make it a tremendous resource for K-12 outreach activities whose goal is to encourage interest in science and technology careers.","title":"EAGER: Therabot - A Robotic Therapy Support System","awardID":"1249488","effectiveDate":"2012-07-15","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[532672],"PO":["565227"]},"187117":{"abstract":"The Internet is undoubtedly one of the most significant innovations of our era. Beyond serving as a medium of communication, it also enables huge opportunities for new markets and business. The study of the Internet and e-commerce has been one of the most exciting and challenging research areas in computer science during the past few decades. Recently, concepts and methodologies from game theory and economics have found numerous successful applications in this area. <br\/><br\/>The main goal of this proposal is to bridge the algorithmic gap between game theory, economics and computer science. While computational efficiency has always been a critical issue in the design of any computer system, the study within game theory and economics has been almost entirely non-algorithmic. The PI will work to develop efficient algorithms for some of the fundamental models and solution concepts and to understand the computational difficulties inherent within them, with the aim to inspire and enable the next-generation e-commerce systems.<br\/><br\/>For this purpose, the PI will perform a systematic study of both algorithmic and complexity-theoretic questions related to Nash equilibria and market equilibria. This includes the search of a polynomial-time approximation scheme for two-player Nash equilibria and the development of new techniques to understand the computation of market equilibria with various utility functions and with social influence. The PI will also work to improve our current understanding of PPAD and FIXP, two complexity classes for (discrete and continuous) fixed point computation, on which many of the hardness results of equilibrium computation rely. As two of the most fundamental solution concepts, the proposed research on Nash and market equilibria will contribute to a more solid algorithmic and complexity-theoretic foundation for the interdisciplinary field of Algorithmic Game Theory. Finally, the PI will tightly integrate education with the research activities by, e.g., developing new (introductory and advanced) courses on Algorithmic Game Theory and on its use in analyzing social networks; mentoring Ph.D. students; and promoting undergraduate research.","title":"CAREER: Bridging Game Theory, Economics and Computer Science: Equilibria, Fixed Points, and Beyond","awardID":"1149257","effectiveDate":"2012-07-01","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["93200"],"PO":["565251"]},"190780":{"abstract":"The objective of this proposal is to adapt computer architecture simulation infrastructure to model power and thermal issues for future multicore systems. The main concern addressed by this proposal is simulation speed when power and thermal estimations are also considered. <br\/>To accelerate simulation times, engineers employ sampling. The problem is that adding modern multicores and thermal simulation breaks existing sampling techniques. The research community needs performance, power, and thermal simulation results at least one order of magnitude faster than currently available. This proposal provides support to build such system.<br\/><br\/><br\/>The simulation infrastructure will have a significant impact on the computer architecture community. We expect an increase in the number of publications by third parties. We also expect a larger, multi-university, class curriculum impact due to make this simulator available to class projects. Combining the two previous impacts, we expect a larger proportion of the graduate and undergraduate students to learn and research about future multicores, mobile systems, and clouds with a focus on power and thermal issues.","title":"II-EN: Fast Thermal-Aware Sampling for Multiprocessors","awardID":"1205377","effectiveDate":"2012-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["556721"],"PO":["562984"]},"193673":{"abstract":"This proposal provides a systematic approach to combining existing electrical energy storage technologies and power conversion circuit designs with sophisticated runtime management policies to create a hybrid electrical energy storage (HEES) system with performance metrics that would be superior to those for any of its constituent components. In particular, the proposed research focuses on: (i) Architecture design and charge management, including charge allocation, migration, and replacement policies in HEES systems; (ii) Application driver and customization, including application to portable systems, and (iii) System prototyping and evaluation, including HEES system deployment studies. <br\/><br\/>This research claims to produce unprecedented benefits in terms of energy availability and efficiency in electronic systems as well as significant reductions in cost of operating these systems. In particular, the proposed work aims to achieve 2x cost reduction and 10x cycle life improvement over conventional electrical energy storage systems. This will in turn enable the design of integrated products and platforms that deliver a wide range of new capabilities based on efficient power delivery and local energy storage. Another expected benefit of this proposal is the training of students, who will acquire knowledge in the development of new means and methods for electrical energy storage, conversion and delivery.","title":"SHF: Small:Technology Development and Design Optimization of Hybrid Electrical Energy Storage Systems","awardID":"1219235","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["535238",518663],"PO":["562984"]},"192463":{"abstract":"Most of the traditional High-End Computing (HEC) applications and<br\/>current petascale applications are written using the Message Passing<br\/>Interface (MPI) programming model. Some of these applications are run<br\/>in MPI+OpenMP mode. However, it can be very difficult to use MPI or<br\/>MPI+OpenMP and maintain performance for applications which demonstrate<br\/>irregular and dynamic communication patterns. The Partitioned Global<br\/>Address Space (PGAS) programming model presents a flexible way for<br\/>these applications to express parallelism. Accelerators introduce<br\/>additional programming models: CUDA, OpenCL or OpenACC. Thus, the<br\/>emerging heterogeneous architectures require support for various<br\/>hybrid programming models: MPI+OpenMP, MPI+PGAS, and MPI+PGAS+OpenMP<br\/>with extended APIs for multiple levels of parallelism. Unfortunately,<br\/>there is no unified runtime which delivers the best performance and<br\/>scalability for all of these hybrid programming models for a range of<br\/>applications on current and next-generation HEC systems. This leads<br\/>to the following broad challenge: \"Can a unified runtime for hybrid<br\/>programming model be designed which can provide benefits that are<br\/>greater than the sum of its parts?\"<br\/><br\/>A synergistic and comprehensive research plan, involving computer<br\/>scientists from The Ohio State University (OSU) and Ohio Supercomputer<br\/>Center (OSC) and computational scientists from the Texas Advanced<br\/>Computing Center (TACC) and San Diego Supercomputer Center (SDSC),<br\/>University of California San Diego (UCSD), is proposed to address the<br\/>above broad challenge with innovative solutions. The investigators<br\/>will specifically address the following challenges: 1) What are the<br\/>requirements and limitations of using hybrid programming models for a<br\/>set of petascale applications? 2) What features and mechanisms are<br\/>needed in a unified runtime? 3) How can the unified runtime and<br\/>associated extension to programming model APIs be designed and<br\/>implemented? 4) How can candidate petascale applications be<br\/>redesigned to take advantage of proposed unified runtime? and 5) What<br\/>kind of benefits (in terms of performance, scalability and<br\/>productivity) can be achieved by the proposed approach? The research<br\/>will be driven by a set of applications from established NSF<br\/>computational science researchers running large scale simulations on<br\/>Ranger and other systems at OSC, SDSC and OSU. The proposed designs<br\/>will be integrated into the open-source MVAPICH2 library. The<br\/>established national-scale training and outreach programs at TACC,<br\/>SDSC and OSC will be used to disseminate the results of this research.","title":"SHF:Large:Collaborative Research:Unified Runtime for Supporting Hybrid Programming Models on Heterogeneous Architecture","awardID":"1213057","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[515803,515804],"PO":["565272"]},"201417":{"abstract":"This research is motivated by the need for robust and intelligent clinical procedure of 'catheterization' which is widely used in medical communities. In this research, the fundamental framework to develop active catheters using an electro-active polymer called Ionic Polymer-Metal Composite (IPMC). The research work includes the design and fabrication methodologies of robotically controlled IPMC catheters as well as shape controls needed for use in complex passages. The research results will be disseminated in technical conferences and workshops as well as prototype demonstration. Knowing that the catheter based medical therapy\/diagnosis is one of important medical technologies and all existing catheters in the market are based upon human operations, this active catheter technology will pave the way to a new biorobotic medical tool that can significantly contribute to improving quality of life.","title":"II-NEW: Collaborative Research: Robotic Catheterization Using Ionic Polymer-Metal Composite Actuator","awardID":"1265123","effectiveDate":"2012-07-01","expirationDate":"2014-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["441459"],"PO":["543539"]},"196401":{"abstract":"Supporting U.S.-Based Students to Attend the 2011 IEEE International Conference on Data Mining (ICDM 2012)<br\/>PI: Ding, Wei, University of Massachusetts Boston <br\/><br\/>The project provides NSF Student Travel Fellowships to graduate students enrolled in Ph.D. programs in data mining or closely related areas to attend and participate in the 2012 IEEE International Conference on Data Mining in Brussels, Belgium, from December 10-13, 2012. Special efforts will be made to attract women and members of groups that are underrepresented within the data mining research community. The NSF student travel award recipients will be able to attend the plenary and contributed talks, workshops and tutorials that are part of SDM 2012, as well as a Doctoral Forum. The Doctoral Forum is designed to allow doctoral students who are at an early stage in their research careers to present their work, interact with their peers from other universities as well as receive one-on-one mentoring from leading data mining researchers. <br\/><br\/>Intellectual Merit. Participation in premier research conferences is an essential component of research-based advanced training of Ph.D. students in data mining. The ICDM 2012 Doctoral Student Forum provides an opportunity for Ph.D. candidates to receive constructive feedback and mentoring from established researchers in data mining. Such interactions serve to broaden the training of students, enhance the quality of the dissertation research performed by the students at their home institutions, and ultimately, help them make informed decisions that advance their long-term career objectives. <br\/><br\/>Broader Impact. Data mining is playing an increasingly important role in many emerging data-rich applications ranging from computational biology to computer-assisted discovery and counterterrorism efforts. The award will help broaden the representation of women and members of underrepresented minority groups within the Data Mining research community. It also contributes to the training of a cadre of new generation scientists equipped with sophisticated tools to extract knowledge from data in areas that are growing in importance in our increasingly digital, interconnected world.","title":"Supporting U.S.-Based Students to Attend the 2012 IEEE International Conference on Data Mining (ICDM 2012)","awardID":"1238718","effectiveDate":"2012-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["541893",526618,"476108"],"PO":["560586"]},"196643":{"abstract":"The Machine Learning Summer Schools (http:\/\/mlss.cc) were established in 2002 with the aim of bringing together world class speakers from academia, the national labs, and industry to deliver tutorial-style lectures over a two week period. This project supports the two week long Machine Learning Summer School (MLSS) at UC Santa Cruz, CA during July 9-20 2012. <br\/><br\/>Intellectual Merits: Machine learning has many important applications in science and industry. Modern machine learning uses a mix of insights from different disciplines, most notably artificial intelligence, statistics and optimization - areas that traditionally have not had much overlap. The participants will take part in tutorials given by experts from several different areas of machine learning - an opportunity that many students do not have at their home institutions. There is substantial integration of research and education in this activity. Furthermore, the participants will be able to interact with the tutorial speakers and with other students. <br\/><br\/>Broader Impact: The Machine Learning Summer School is designed to enable participants with different backgrounds to gain in-depth knowledge of the current state of the art in machine learning. The participants will interact with leading machine learning experts from academia and industry. It contributes to the creation of a diverse cadre of machine learning researchers and practitioners by offering unique training opportunities for undergraduate and graduate students from under-represented groups through personalized mentoring and scholarships.","title":"The 2012 Machine Learning Summer School at UC Santa Cruz","awardID":"1239963","effectiveDate":"2012-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[527386],"PO":["565136"]},"193387":{"abstract":"The objective of this proposal is to thoroughly investigate the deployment of non-isotropic sensors for smart building applications. Various sensing and control applications in smart building require accurate and efficient localization and tracking of human and activities. To achieve this goal, the non-isotropic networked sensor deployment is essential.<br\/><br\/>This proposal addresses a new set of problems arising from the deployment of four types of sensors: cameras, tripwire, motion sensors and microphones. The set of deployment problems would strive for full sensor coverage and wireless connectivity with a complex floor plan, and involve one or more of the following constraints: (i) Non-isotropic model using visibility (cameras and tripwires), (ii) Non-overlapping sensing range, (iii) Robust 2-coverage for accurate localization. The sensor deployment problem will heavily involve the geometric properties of the environment (building layout), as well as the geometric properties of the sensors (non-isotropic sensing ranges). Ideas from computational geometry will be applied to tackle these problems and approximation algorithms with worst-case guarantee for theoretical rigor as well as practical algorithms suitable for implementations will be developed.<br\/><br\/>A clear understanding on how to deploy sensors for smart building systems will allows for efficient planning and effective practice of networked sensor deployment to achieve the high quality sensing desired by various indoor applications. For developers, this work will significantly reduce the design and development costs for designing and building smart building systems. For end users, the resultant testbed will lead to exciting applications that will significantly improve the quality of life. It also enriches engineering curriculum to integrate the theory of computational geometry with the system building practice. The PIs are committed in improving female presence in computer science and exposure of research for high school students.","title":"NeTS: Small: Collaborative: Non-Isotropic Networked Sensor Deployment for Smart Buildings","awardID":"1217823","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["519259"],"PO":["565303"]},"195148":{"abstract":"Datacenters have enriched the planet, making services like e-commerce and web search available to billions. However, the growing carbon footprint of datacenters adds to climate change and, in the long term, could harm society's perception of the whole field. Our ongoing work builds mechanisms for sustainable datacenters, i.e., datacenters that profit while maintaining low carbon footprints. Intellectually, the work contributes new analytic models that relate a datacenter's carbon footprint to its utilization and energy costs. These models must consider complicated issues like solar- and wind-energy outages, heavy-tail and diurnal e-commerce workloads, and workload and energy balancing within datacenters (e.g., dynamically powering servers off and DVFS). Further, the models must be holistic, explaining these factors in terms of profit. In terms of broad impacts, this work will improve the economic competitiveness and sustainability of datacenter-driven computing.","title":"EAGER: Design and Implementation of a Renewable Adaptive Cluster","awardID":"1230776","effectiveDate":"2012-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["563444"],"PO":["565255"]},"189439":{"abstract":"In the past ten years the theoretical computer science, applied math and electrical engineering communities have extensively studied variants of the problem of ``solving\" an under-determined linear system. One common mathematical feature that allows us to solve these problems is sparsity; roughly speaking, as long as the unknown vector does not contain too many non-zero components (or has a few dominating components), we can ``solve'' the under-determined system for the unknown vector. These problems are referred to as sparse approximation problems and have applications in diverse areas such as signal and image processing, biology, imaging, tomography, machine learning and others.<br\/><br\/>The proposed research project aims to develop a comprehensive, rigorous theory of sparse approximation, broadly defined. The research proposal entails two complementary research directions: <br\/>(1) a robust and more complete view of the combinatorial, algorithmic, and complexity-theoretic foundations of sparse approximations (including its generalization to functional sparse approximation where we want to ``solve\" for some function of the unknown vector instead of the vector itself),<br\/>(2) coupled with either its interactions or direct applications in other areas of theoretical computer science, from complexity theory to coding theory, and of electrical engineering, from signal processing to analog-to-digital converters.<br\/>A general theory of sparse approximation that concentrates both on the optimal tradeoffs between competing parameters and the computational feasibility of attaining such tradeoffs will not only help explore the theoretical limits and possibilities of sparse approximations, but also feed algorithmic techniques and theoretical benchmarks back to its application areas. Sparse approximation already has been shown to have impact in a variety of fields, including imaging and signal processing, Internet traffic analysis, and design of experiments in biology and drug design.","title":"AF: Medium: Collaborative Research: Sparse Approximation: Theory and Extensions","awardID":"1161233","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[507958,507959],"PO":["565251"]},"192970":{"abstract":"The control of epidemics, broadly defined to range from human diseases such as influenza and smallpox to malware in communication networks, relies crucially on interventions such as vaccinations and anti-virals (in human diseases) or software patches (for malware). These interventions are almost always voluntary directives from public agencies; however, people do not always adhere to such recommendations, and make individual decisions based on their specific \"self interest\". Additionally, people alter their contacts dynamically, and these behavioral changes have a huge impact on the dynamics and the effectiveness of these interventions, so that \"good\" intervention strategies might, in fact, be ineffective, depending upon the individual response. <br\/><br\/>The goal of this project is to study the foundations of policy design for controlling epidemics, using a broad class of epidemic games on complex networks involving uncertainty in network information, temporal evolution and learning. Models will be proposed to capture the complexity of static and temporal interactions and patterns of information exchange, including the possibility of failed interventions and the potential for moral hazard. The project will also study specific policies posed by public agencies and network security providers for controlling the spread of epidemics and malware, and will develop resource constrained mechanisms to implement them in this framework.<br\/><br\/>This project will integrate approaches from Computer Science, Economics, Mathematics, and Epidemiology to give intellectual unity to the study and design of public health policies and has the potential for strong dissertation work in all these areas. Education and outreach is an important aspect of the project, and includes curriculum development at both the graduate and under-graduate levels. A multi-disciplinary workshop is also planned as part of the project.","title":"ICES: Large: Collaborative: The Role of Space, Time and Information in Controlling Epidemics","awardID":"1216038","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":["518070",516944],"PO":["565251"]},"192882":{"abstract":"The control of epidemics, broadly defined to range from human diseases such as influenza and smallpox to malware in communication networks, relies crucially on interventions such as vaccinations and anti-virals (in human diseases) or software patches (for malware). These interventions are almost always voluntary directives from public agencies; however, people do not always adhere to such recommendations, and make individual decisions based on their specific \"self interest\". Additionally, people alter their contacts dynamically, and these behavioral changes have a huge impact on the dynamics and the effectiveness of these interventions, so that \"good\" intervention strategies might, in fact, be ineffective, depending upon the individual response. <br\/><br\/>The goal of this project is to study the foundations of policy design for controlling epidemics, using a broad class of epidemic games on complex networks involving uncertainty in network information, temporal evolution and learning. Models will be proposed to capture the complexity of static and temporal interactions and patterns of information exchange, including the possibility of failed interventions and the potential for moral hazard. The project will also study specific policies posed by public agencies and network security providers for controlling the spread of epidemics and malware, and will develop resource constrained mechanisms to implement them in this framework.<br\/><br\/>This project will integrate approaches from Computer Science, Economics, Mathematics, and Epidemiology to give intellectual unity to the study and design of public health policies and has the potential for strong dissertation work in all these areas. Education and outreach is an important aspect of the project, and includes curriculum development at both the graduate and under-graduate levels. A multi-disciplinary workshop is also planned as part of the project.","title":"ICES:Large:Collaborative Research: The Role of Space, Time, and Information in Controlling Epidemics","awardID":"1215682","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":[516738],"PO":["565251"]},"193630":{"abstract":"The organization of complex heterogeneous digital systems looms as one of the fundamental research problems of the next decade and beyond. One recent promising strategy is the use of structured communication, in the form of interconnection networks or networks-on-chip (NoCs). Such NoCs have been recently used in many systems, ranging from embedded systems-on-chip for consumer applications to memory interfaces for high-end parallel processors. A number of advances have been made in the design and capabilities of synchronous (i.e. clocked) NoCs, but the increased need to support design reuse, mixed clock domains, and dynamic voltage and frequency scaling (DVFS, to improve system power), have highlighted the inherent rigidity of a single-clock framework. While a number of asynchronous and globally-asynchronous locally-synchronous (GALS) NoCs have been developed, and demonstrated benefits in some cost metrics, most have major performance and area overheads and are not competitive for a range of critical applications, while others aiming at high performance require the use of advanced circuit techniques. This proposal aims to bridge the gap, developing medium- to high-end asynchronous\/GALS NoCs, using mostly standard hardware components, with significantly improved cost metrics over comparable single-clock designs: dynamic power, system latency, throughput, area and reliability. A novelty of the approach will be to explore the use of fine-grain dynamic adaptivity, at the individual router node level, where, opportunistically, nodes can reconfigure themselves to ``scavenge'' improvements in latency, throughput and static power, based on observed ambient traffic. A direct comparison will be made with state-of-the-art clocked systems, using a promising multi-synchronous approach (with a single clock rate, but tolerating phase misalignment, called ``mesochronous''). Detailed simulation and synthesis tools and support flows will also be developed.<br\/><br\/>The broader impact of the proposed framework will be to provide a new level of advancement for the competitive viability of asynchronous design in overcoming key system bottlenecks. It is anticipated that this work will play a role in advancing a paradigm shift in organizing complex systems, through use of asynchrony. The results are also expected to provide a major advance in designing next-generation NoCs.","title":"SHF:Small:Designing Low-Latency and Robust Interconnection Networks with Fine-Grain Dynamic Adaptivity Using Asynchronous Techniques","awardID":"1219013","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[518562],"PO":["562984"]},"193641":{"abstract":"Hardware and software computer systems are integrated into many aspects of our society, including medicine, transportation, financial markets, and communication. Thus, the correctness of a computer system can be critical for financial or even human safety reasons. Formal verification is a methodology for finding errors and certifying that a system is free of errors. It complements testing, which in practice can neither cover every possibility nor declare the absence of errors. Because of the increasing complexity and prevalence of computer systems in recent years, significant improvements in algorithms for formal verification now have an immediate impact in computer system development, which in turn decreases design costs, accelerates development, and results in safer equipment.<br\/><br\/>This project builds on the success of the IC3 algorithm for verifying invariance properties of digital hardware. IC3, introduced only two years ago, is already used widely by hardware manufacturers and electronic design automation companies. It is reported that it can, in practice, find deep bugs that are difficult to find with testing, or obtain proofs that no other algorithm can find. But achieving the next significant gain in performance requires moving beyond the bit-level analysis that IC3 performs and instead considering designs at the word level, that is, at a level in which whole registers are sometimes considered rather just than their component latches. This project addresses this challenge by developing a multi-domain version of IC3, as well as abstract domains, for reasoning about equality, uninterpreted functions, and arithmetic properties of circuits. A second component of this project is to extend the incremental, inductive verification (IIV) methodology, of which IC3 was the first instance, to analyze properties expressed in CTL and CTL*, which are logics for expressing branching-time behavior. Increased expressiveness allows analyzing more aspects of a design. A final component is to exploit the natural parallelism of IIV algorithms through a distributed implementation.","title":"SHF: Small: Incremental Inductive Verification: A New Direction for Model Checking","awardID":"1219067","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[518587,518588],"PO":["565264"]},"188702":{"abstract":"Studying some of the most fundamental scientific problems requires the development of novel computational methods and their application to very large datasets. The computing facility is a significant addition to the current computing resources of the Computer Science program at Lawrence Technological University, and supports interdisciplinary computer science research in a fashion that allows to practically apply the computational methods developed at Lawrence Technological University to scientific questions in various disciplines such as Astronomy, Biology, Medical and clinical research, Scientific Computing, Biometrics, Remote sensing, Robotics, Fine Art, and more.<br\/>The computing facility also allows involving more Computer Science undergraduate and graduate students in interdisciplinary Computer Science research. The ability of Computer Scientists to work in collaboration with other scientists in an interdisciplinary environment and understand problems in other disciplines is crucial for the development of the computational methods that can effectively solve problems in science and engineering. Therefore, interdisciplinary research experience provides undergraduate and graduate students with the training they need for effective real-life industry or academic research.","title":"A computing facility for interdisciplinary Computational Science research","awardID":"1157162","effectiveDate":"2012-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[506005,"560828"],"PO":["543481"]},"197206":{"abstract":"The past decade has seen tremendous advances in the theory and practice of software verification, and several success stories in the transition of verification techniques from the research lab to development tools. However, despite these advances, much work remains in several directions. These include determining the best ways to applying these advances to broader, higher-level issues like reliability, and privacy in new domains like cyber-physical systems and medicine; in finding the best ways to reach out to practitioners, and to train engineers to use formal methods principles, methodologies and tools; and in finding ways for to multiply the effectiveness of researchers through the use of shared platforms and infrastructure.<br\/><br\/>The goal of this workshop is to identify the future directions in research in formal methods and its transition to industrial practice. The workshop will bring together researchers from academia, industry, and government research labs working in the area of formal methods and verification, and identify primary challenges in the field, both foundational, infrastructural, and in transitioning ideas from research labs to developer tools.","title":"WORKSHOP: Future Directions For Formal Methods","awardID":"1242686","effectiveDate":"2012-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[529115],"PO":["565264"]},"189627":{"abstract":"The central theme of this project is to investigate methodologies and theories to enhance throughput, delay, and fairness of cognitive radio networks via integrated dynamic spectrum access. The research will develop new methods to:<br\/>1) Extend spectrum sensing beyond just the presence and absence of the primary spectrum users' activities at certain spectrum bands\/channels, but also their locations and transmit powers <br\/>2) Predict the primary spectrum user's activity and its interval using game theoretic and statistical learning approaches <br\/>3) Perform delay-aware spectrum management with a very comprehensive delay model considering all the factors that may affect the delivery latency of a packet, including the spectrum sensing delay, the transmission delay, the queuing delay, and the spectrum negotiation and scheduling delay <br\/>4) Share spectrum in a fair manner considering the tradeoff between fairness and throughput<br\/>5) Propose a delay-aware fair routing protocol for throughput optimization which jointly considers throughput, delay, and fairness along with dynamic spectrum management.<br\/><br\/>The project's focus on dynamic spectrum access is of high national interest and can create significant impact on spectral usage policies and related industries in the telecommunication and information technology sectors. The project will also encourage and include under-represented and minority students to be part of this activity, while extending education and outreach plans to undergraduates and K-12 students.","title":"NeTS: Medium: Collaborative Research: Integrated Dynamic Spectrum Access for Throughput, Delay, and Fairness Enhancement","awardID":"1162296","effectiveDate":"2012-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[508426],"PO":["565303"]},"193620":{"abstract":"For point-to-point communications, channel capacity is very well<br\/>understood, and there are schemes that approach the capacity for<br\/>most useful channel models. In contrast, the multi-user communication channels<br\/>are not as well understood. The channel models are more complicated, there are<br\/>more varieties, and many important problems remain open. As one well-known<br\/>example, the capacity problem for discrete memoryless broadcast channel is<br\/>still unsettled. As another example, the interference channel capacity region<br\/>is known only in certain special cases (such as strong interference). What is<br\/>clear from the recent studies of such channels is that in a multi-user<br\/>wireless network, the key performance limiting factor is often the interference rather <br\/>than the noise, especially at high signal-to-noise ratio.<br\/><br\/>To alleviate this difficulty, the notion of degrees of freedom has been used as<br\/>a first order characterization of the system throughput as normalized by the<br\/>logarithm of the signal to noise ratio. The total degrees of freedom of<br\/>several interference networks have been quantified. On the other hand, the<br\/>degrees of freedom region, which is more revealing than the total degrees of<br\/>freedom, is much less well understood. For most of the interference networks,<br\/>the regions remain unknown.<br\/><br\/>This project seeks to quantify the degree of freedom regions of a<br\/>class of general interference networks with multiple transmit nodes and<br\/>multiple receive nodes, possibly equipped with multiple antennas, and with<br\/>general message demands. In particular, we will study the X interference<br\/>network, which include interference channels, broadcast channels, multiple<br\/>access channels, as special cases. Through interference alignment design based<br\/>on vector and rational independence, we will bound tightly the degrees of<br\/>freedom region and devise schemes that are optimal (or near-optimal) in the<br\/>degree-of-freedom sense.<br\/><br\/>Broader Impact: The project will advance significantly our understanding of<br\/>interference networks, and positively impact the design, architecture, and<br\/>signal design and processing for next generation wireless networks. The<br\/>project will also help train the next generation of researchers and engineers<br\/>in the field of signal processing and communication networks.","title":"CIF: Small: Degree of Freedom Region of Interference Networks","awardID":"1218951","effectiveDate":"2012-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["545075"],"PO":["564924"]},"192410":{"abstract":"Successful software constantly evolves. Most programmers work on projects they did not start. Most companies spend more on maintaining old systems than on building new ones. This is good, because it shows that companies build software that is worth keeping and maintaining, but it also means that change is the heart of software development. Most programming tools treat change at a very low level: programmers make most changes with text editors, and tools tend to focus on changes to lines of text, and although programming is predominantly about change, contemporary tools do not provide direct support for understanding or facilitating change. This makes programming more expensive, time-consuming, and error-prone than it should be. This research project will develop a change-oriented programming environment (COPE) that supports change by putting transformations at the center of software development. COPE will enable both average and expert programmers to write, script, modify, and replay their own transformations. COPE will enable programmers to think about programs as compositions of transformations, and to automate as many of these transformations as possible. Characterizing software development in terms of transformations is an essential step to take software engineering from manual development to automated (or semi-automated) development of software.<br\/><br\/>By enabling programmers to express their programming tasks as program transformations, COPE will This alter the way programmers think about, teach, create, reuse, and understand programs. Specifically, COPE considers five activities: (1) analyze what changes programmers typically make and how they perceive, recall, and communicate changes, (2) automate transformations to make it easier to apply and script changes, (3) develop tools that compose and manipulate transformations to make it easier to reuse them, (4) integrate transformations with version control to provide better ways for archiving and understanding changes, and (5) develop tools that infer higher-level transformations from lower-level changes. COPE will deliver a rich transformation-aware toolset that synergistically integrates all these activities. COPE aims to (a) change the way people program, (b) create a platform for research for future research, and (c) produce results that ultimately will become standard software development practice. The PIs will disseminate the results through presentations, books, publications, open-source code, industrial collaborations, and educational activities. A version of COPE will be used to revamp the software engineering curriculum at the University of Illinois and the University of Texas to emphasize the science of change in large code bases.","title":"SHF: Large: Collaborative Research: Science and Tools for Software Evolution","awardID":"1212683","effectiveDate":"2012-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[515656],"PO":["564388"]},"193653":{"abstract":"A new class of non-volatile, solid-state memories (e.g., phase-change memory, spin-torque MRAMs, and the memristor) are emerging that promise to revolutionize the way that computer systems store and access data. While these memory offer significant promise they will also require us to re-engineer many parts of existing computing systems. No where is this more critical than in database systems, where overall throughput (in terms of transactions per seconds) is closely tied to the performance of the underlying storage system and the optimizations that have been applied in software. This project is analyzing the implications for these new memories on database systems and devising now hardware and software mechanisms to improve performance, reduce energy consumption, and improve reliability.<br\/><br\/>The potential impacts of these optimizations is wide-reaching. Database (in various forms) constitute the heart of the cloud computing infrastructure that supports many of the \"killer apps\" that are driving technologies forward. Leveraging these new technologies, will make it cheaper, easier, and greener to implement existing applications and will enable new applications that are not currently possible.","title":"SHF: Small: Reengineering Database Systems for Fast SSDs","awardID":"1219125","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["525612",518615],"PO":["565272"]},"192476":{"abstract":"Meta-algorithms are algorithms that take other algorithms as input.<br\/>Meta-algorithms are important in a variety of applications, from<br\/>minimizing circuits in VLSI to verifying hardware and software to<br\/>machine learning. Lower bound proofs show that computational problems<br\/>are difficult in the sense of requiring a prohibitive<br\/>amount of time, memory, or other resource to solve.<br\/>This is particularly important in the context of cryptography,<br\/>where it is vital to ensure that no feasible adversary can break<br\/>a code. Surprisingly, recent research by the PIs and others<br\/>shows that designing meta-algorithms is, in a formal sense, <br\/>equivalent to proving lower bounds. In other words, one can prove a <br\/>negative (the non-existence of a small circuit to solve a problem) by <br\/>a positive (devising a new meta-algorithm). This was the key to a <br\/>breakthrough by PI Williams, proving lower bounds on constant <br\/>depth circuits with modular arithmetic gates.<br\/><br\/>The proposed research will utilize this connection both to<br\/>design new meta-algorithms and to prove new lower bounds.<br\/>A primary focus will be on meta-algorithms for<br\/>deciding if a given algorithm is 'trivial' or not, such as algorithms<br\/>for the Boolean satisfiability problem. The proposed research will devise new<br\/>algorithms that improve over exhaustive search for many variants<br\/>of satisfiability. On the other hand, it will also explore<br\/>complexity-theoretic limitations on how much improvement is<br\/>possible, using reductions and lower bounds for restricted<br\/>models. Satisfiability will provide a starting point for a more<br\/>general understanding of the exact complexities of other NP-complete<br\/>problems such as the traveling salesman problem and k-colorability.<br\/>The proposal addresses both worst-case performance and the use<br\/>of fast algorithms as heuristics for solving this problem.<br\/><br\/>This exploration will be mainly mathematical. However, when<br\/>new algorithms and heuristics are developed, they will be<br\/>implemented and the resulting software made widely available.<br\/>This research will be incorporated in courses taught by<br\/>the PI's, at both graduate and undergraduate levels.<br\/>Both graduate and undergraduate students will perform research<br\/>as part of the project.","title":"AF: Large: Collaborative Research: Exploiting Duality between Meta-Algorithms and Complexity","awardID":"1213151","effectiveDate":"2012-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[515840,515841,515842],"PO":["565251"]},"193576":{"abstract":"This project is motivated by the lack of theoretical understanding of distributed control strategies to jointly optimize cognitive radio network functionalities at multiple layers of the networking protocol stack. When physical layer parameters are considered, the resulting optimization problem is often nonconvex, and therefore cannot be solved efficiently in general even through centralized algorithms. The objective of this project is then to look at the cross-layer design of cognitive radio multi-hop networks from a different and novel perspective. The problem of jointly optimizing the sensing parameters, multiple-access scheme, routing, and rate control is formulated as a bi-level equilibrium problem, which can be solved efficiently and in a distributed way. Successful completion of this research will provide the community with a family of novel distributed algorithms that naturally implement vertical and horizontal decompositions across the network. This would represent a major departure from well-understood decomposition algorithms for network utility maximization problems that are known to suffer from slow convergence speed.<br\/><br\/>The project will contribute to the development of novel algorithms and tools that will lay the foundation for the next generation of cognitive networking technology. The impact of the proposed technology to today's society can be as broad and as strong as the potential applications of ad hoc networks; for example, search-and-rescue operations, on-demand communications infrastructure deployment, and intelligent transportation highways and vehicles. The proposed research is integrated with an educational plan designed to train the next-generation of networking professionals, as well as promote cross-fertilization of academic research with industry needs.","title":"NeTS: Small: Toward Distributed Decision Making in Cognitive Radio Ad-hoc Networks Based on Bilevel Equilibrium Programming","awardID":"1218717","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["555021","534757"],"PO":["557315"]},"189606":{"abstract":"This project is developing efficient solid-state data storage device and system design solutions. Although solid-state data storage has shown a high potential to significantly advance storage systems to achieve ultra-high performance with low energy consumption, continuous semiconductor technology scaling makes it increasingly challenging to realize efficient and reliable solid-state data storage devices and systems for the storage hierarchy in large-scale systems, such as data centers and cloud systems. <br\/><br\/>The intellectual merit of this proposal lies in the theme of developing solid-state data storage design techniques from both software and hardware. Major solid-state data storage device architecture functions, including error correction coding, wear-leveling and garbage collection algorithms, are being developed. Workload and device-aware solid-state data storage system design solutions are also being developed for large data center applications. Design solutions will be evaluated using an experimental hardware platform and the Linux operating system.<br\/><br\/>The broader impact of the proposed research is that it will enable the development of highly reliable and low-cost solid-state data storage devices and systems for large-scale computing and storage systems. The adoption of the design methodology by solid-state data storage architects, system designers, and data-intensive practitioners may provide a direct benefit to this strategically important high technology sector critical to the economic health of the nation. This team will also introduce new research results into courses.","title":"CSR: Medium: Collaborative Research: On Closed-Loop and Cross-Layer Design and Implementation of Data Storage Systems Utilizing Extremely Scaled NAND Flash Memory Technologies","awardID":"1162152","effectiveDate":"2012-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["360575"],"PO":["551712"]},"193632":{"abstract":"The massive growth in the number of images being generated today has fostered a new direction in computer vision research. Images today are almost never generated independently, rather manifest as collections. Therefore, instead of thinking of images as individual entities, we now need to consider images within a group that may have significant correlational structure. Yet, formalizations of several fundamental image analysis tasks such as image segmentation, for the most part, still consider one image at a time. This project makes the case for exploiting this shared structure for understanding content in images. It develops an efficient framework which permits the segmentation of images at a group level and therefore is applicable to various scenarios in which visual data typically presents itself. The primary objective is to design a comprehensive system that addresses all aspects of this problem -- from preconditioning the input using training data, to providing powerful segmentation models that take the group structure into account, to building dictionaries which can then be used to effectively segment a set of related images. <br\/><br\/>This project provides a vehicle for engaging undergraduates to become immersed in research during the semesters and full-time in summers. Students are exposed to and participate in state-of-the-art research in computer vision which furthers their understanding of these topics and stimulate their intellectual curiosity. This can significantly increase the possibility of these students choosing to pursue higher studies in computer science.","title":"CGV: Small: RUI: Analyzing subspace structure for group level image understanding","awardID":"1219016","effectiveDate":"2012-07-15","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[518567],"PO":["564316"]},"193412":{"abstract":"Emerging memory technologies such as Magnetoresistive random-access memory (MRAM), Phase-change memory (PCRAM), and Resistive random-access memory (RRAM) are being explored as potential alternatives for future computing systems. However, traditional memory design methodologies are not sufficient to address probabilistic behaviors, which are caused by process variations and the intrinsic randomness in the physical mechanisms (e.g., thermal fluctuations) of these emerging technologies. <br\/><br\/>The objective of this research is to develop a design methodology called STatistical Emerging Memory Simulator (STEMS) for circuit\/architecture designs with such emerging memory technologies. The intellectual merits include the following: (1) developing a generic statistical characterization formalism to link the emerging memory cell design specifications with design variables, process variations and environmental fluctuations, (2) deriving a variation-aware compact memory cell model to fulfill the demands of the statistical design optimizations at cell and array levels, and (3) investigating a statistical memory design methodology to explore the tradeoffs among memory structure, implementation cost, and design specifications for various system requirements. The proposed research will fundamentally change the design methodologies for future memory technologies, initiate an innovative direction in memory designs, and optimize and balance the new design characteristics of emerging memories under architectural considerations, inspiring the transition of design philosophy from the deterministic era to the probabilistic era. The proposed techniques provide a complementary perspective to the existing probabilistic system and architectural research while emphasizing the yield and probabilistic properties of memory designs. <br\/><br\/>This project will facilitate further advances and wider adoption of the emerging memory technologies by the semiconductor industry. Innovations in design methods and memory modeling will have an impact on the way in which semiconductor memory chips are designed and fabricated. Undergraduate and graduate students involved in this research will be trained for the next-generation semiconductor industry workforce.","title":"SHF:Small: Collaborative Research: STEMS: STatistic Emerging Memory Simulator","awardID":"1217947","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["556667"],"PO":["366560"]},"193533":{"abstract":"With the ever increasing popularity of smartphone and mobile devices, the past few years have witnessed a tremendous growth of wireless video\/audio applications, including VoIP, video streaming, real-time surveillance. Meeting the deadline of such real-time wireless traffic is particularly challenging since wireless transmissions are often unreliable. Serving real-time traffic is also a key component of many cyber-physical systems (CPS) - the smart grid is one archetypal example of such CPS systems. Under one common theme of meeting the deadlines of real-time traffic, this project is centered around two emerging applications, namely wireless multimedia applications and smart electric vehicles (EV) charging. Since the optimal solution to such deadline scheduling problems requires to explicitly take into account the coupling in the deadlines and the stochastic characteristics of the traffic, this project is focused on developing low-complexity MDP-based scheduling algorithms for real-time wireless scheduling and smart charging, and is organized in three well-coordinated thrusts: 1) joint scheduling and adaptive network coding for real-time traffic over memoryless channels; 2) downlink scheduling for real-time traffic flows over Markovian channels; and 3) risk-aware deadline scheduling for smart EV charging.<br\/><br\/>This project will significantly advance the state-of-the-art of deadline scheduling for wireless multimedia applications and EV charging, and open up new interdisciplinary research directions. The research findings will significantly enhance wireless multimedia transmissions and contribute to the electrification of transportation. The broader impacts also include educational elements, such as promoting diversity by providing research opportunities to woman and underrepresented students.","title":"NeTS: Small: Meeting Hard Deadlines of Real-Time Traffic: From Wireless Scheduling to Smart Charging","awardID":"1218484","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[518327,518328],"PO":["557315"]},"193302":{"abstract":"Intellectual Merit: Error-correction is a fundamental challenge for all types of computation, and it is a particularly essential challenge for molecular-scale computation. DNA computation is molecular computation using DNA as the computational hardware. Current methods for DNA computations are beset by a high error rate. Error-handling techniques are the key to achieving robust DNA computation in the laboratory. Indeed, a look at the successes in the field of DNA computation clearly demonstrates the role played by error-handling techniques. Winfree's group at Caltech recently made successful laboratory implementations of Boolean DNA circuits of impressive complexity, using a type of chemical logical gate known as a seesaw gate. Their work made use of two types of error-correction (i) inbuilt signal restoration at the circuit network level, and (ii)clamps, a method of error-suppression at the DNA gate design level. Error-correction remains the single largest challenge to further scaling these molecular computations. A particularly difficult type of error is leaks where an output signal is eventually produced even in the absence of an input signal. Due to leaks, logical gates in DNA circuits generally only correctly operate for a limited time interval, and afterwards provide erroneous outputs. The central goal of the proposed work is methods for error-correction of ?leaks? in DNA computations. Proposed work will develop novel network level designs and gate level designs that suppress leaks using a family of innovative techniques, shadow networks and error-modulation gates. A key application is to DNA amplifiers, which take as input a DNA strand at some concentration and produce an output signal DNA strand. DNA amplifiers are leaky, producing signal DNA even in the absence of input, albeit at a slower rate. The difference between signal and noise decides the sensitivity of an amplifier. Enzyme-free DNA exponential amplifiers have high leak rates that limit their sensitivity to detecting small amounts of signal. This proposal describes both network level designs and gate level designs that suppress leaks in such amplifiers. As a concrete and challenging test case, error-suppression in an exponential cross-catalytic DNA amplifier will be demonstrated as a major goal. A well-balanced combination of modeling, software simulation, and experimental tests to verify the error-correction methods will be used. Proposed error-handling techniques are modeled as chemical reaction networks and such networks are then simulated. This exponential amplifier is based on seesaw gates and is hence well modeled as a chemical reaction network.<br\/><br\/>Broader Impact: The designs outlined in the proposal are modular, allowing the various error-correcting components to be used almost as black boxes. The error-suppression techniques are general and translate to a wide variety of other DNA amplifier designs and DNA computing applications involving amplification or restoration of a signal. An ability to systematically identify, at the design stage, possible errors in experimental DNA systems and methods to suppress and\/or correct them is essential for designing scalable and intricate DNA nanosystems. As an educational effort, an advanced undergraduate and beginning graduate level course is planned that teaches error-handling as an integral part of designing DNA systems. The course will introduce students to modeling tools and sequence design tools. The students will develop error-correcting schemes for some common DNA systems like amplifiers, oscillators and switches. They then model their techniques and the ones that work best in simulation will be given an opportunity to implement them in the laboratory.","title":"SHF: Small: Error Correction for Biomolecular Computations","awardID":"1217457","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["550822"],"PO":["565223"]},"193445":{"abstract":"A (disjoint) NP-pair is a pair of disjoint, nonempty sets in the complexity class NP. The study of disjoint NP-pairs is motivated by their relations to public-key cryptosystems and to propositional proof systems. In particular, answers to questions about existence of NP-hard or P-inseparable NP-pairs informs us about the question of whether secure public-key cryptosystems exist; existence of complete NP-pairs is implied by existence of optimal propositional proof systems. This project will investigate P-inseparable and complete NP-pairs further, in particular whether they can be derived from a hypothesis that is weaker than any of the known ones, and whether existence of these NP-pairs have strong consequences that are unknown before. PI will examine commonly (dis)believed hypotheses in complexity theory such as that NP!=coNP and that PH collapses, and research on their relations to the existence of P-inseparable and complete NP-pairs.<br\/><br\/>It is important to study structural properties of complete sets because they gives us a better understanding of the computational power of various complexity classes, and also might lead to proofs of separation results in complexity theory. The proposed project will focus on the following structural properties of complete sets: <br\/>- Robustness: does a complete set remain complete if certain amount of elements are taken away from the set? <br\/>- Autoreducibility: does a complete set reduce to itself via a reduction that does not query on the input string? <br\/>- Mitoticity: can a complete set be split into two complete sets? <br\/>The proposed project aims to address the remaining open questions regarding these properties especially those having major impact in complexity theory if settled. For example, are EXP-complete sets autoreducible for the truth-table reductions? Solving this problem would either separate EXP from PH, or PSPACE from P.<br\/><br\/>The proposed project will be implemented at a Hispanic-serving institution and will promote interest among students, especially Hispanic minorities, for research and study in theoretical computer science and for computer science and engineering at large. The project will be part of the ongoing effort in the computer science community to understand the computation limits of computers. All results from the project will be disseminated broadly through conferences and journal publications.","title":"AF: Small: Disjoint NP-Pairs and Structural Properties of Complete Sets","awardID":"1218093","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[518124],"PO":["565157"]},"193577":{"abstract":"The objective of this proposal is to thoroughly investigate the deployment of non-isotropic sensors for smart building applications. Various sensing and control applications in smart building require accurate and efficient localization and tracking of human and activities. To achieve this goal, the non-isotropic networked sensor deployment is essential.<br\/><br\/>This proposal addresses a new set of problems arising from the deployment of four types of sensors: cameras, tripwire, motion sensors and microphones. The set of deployment problems would strive for full sensor coverage and wireless connectivity with a complex floor plan, and involve one or more of the following constraints: (i)Non-isotropic model using visibility (cameras and tripwires), (ii) Non-overlapping sensing range, (iii) Robust 2-coverage for accurate localization. The sensor deployment problem will heavily involve the geometric properties of the environment (building layout), as well as the geometric properties of the sensors (non-isotropic sensing ranges). Ideas from computational geometry will be applied to tackle these problems and approximation algorithms with worst-case guarantee for theoretical rigor as well as practical algorithms suitable for implementations will be developed.<br\/><br\/>A clear understanding on how to deploy sensors for smart building systems will allows for efficient planning and effective practice of networked sensor deployment to achieve the high quality sensing desired by various indoor applications. For developers, this work will significantly reduce the design and development costs for designing and building smart building systems. For end users, the resultant testbed will lead to exciting applications that will significantly improve the quality of life. It also enriches engineering curriculum to integrate the theory of computational geometry with the system building practice. The PIs are committed in improving female presence in computer science and exposure of research for high school students.","title":"NeTS: Small: Collaborative Research: Non-Isotropic Networked Sensor Deployment for Smart Buildings","awardID":"1218718","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["541635"],"PO":["565303"]},"192940":{"abstract":"The goal of this project is to develop statistical methods to enable ecologists to address critical problems in biodiversity modeling. The research will advance a general semi-parametric methodology that applies to species distribution models (SDMs) of species occupancy, abundance, demographics, and dynamics. The approach will address two major challenges for SDMs: 1) statistically correcting for missed detections in field observations of the species to attain unbiased estimates of ecological quantities of interest, and 2) capturing complex relationships between environmental inputs and model variables. While current techniques in SDMs include parametric models that address the first challenge and nonparametric methods that address the second challenge, the proposed methodology will be the first to simultaneously address both. Hierarchical models are one important class of species distribution models, which often contain unobserved variables of ecological interest. These models have parameters with biological meaning (e.g. extinction probability, etc.) that can be linked to a set of input variables describing various environmental characteristics (e.g. habitat, land use, climate, etc.). Once fit, the models can be examined to understand the effects of the inputs on the parameters. However, this fitting process is often difficult due to the need to carefully select which inputs to include in the model and what to assume about the functional form of their effects. The methods to be developed will incorporate flexible nonparametric methods into these hierarchical models. The resulting methodology will retain the semantics of the hierarchical model but allow the input effects to be fitted flexibly, automatically capturing nonlinearities and interactions without extensive model selection.<br\/><br\/>Rapid declines in habitat for native species are a global problem due to increasingly human-dominated land-use, habitat fragmentation, and climate change. To design reserves, conservation easements, and similar policy measures, there is a need to understand habitat requirements and population dynamics of threatened species across time and space. Hence, accurate models of the demographics and distribution of species are needed. The methodology to be developed by this project will advance understanding of key aspects of species distributions that can guide conservation efforts. Modeling methodologies will be applied to a variety of ecological frameworks, and feedback from collaborators in ecology will help ensure usability by decision-makers. Moreover, the interdisciplinary research efforts of this project will be highlighted in outreach programs to elementary, middle, and high school students.<br\/><br\/>This project is supported under the NSF Science, Engineering and Education for Sustainability Fellows (SEES Fellows) program, with the goal of helping to enable discoveries needed to inform actions that lead to environmental, energy and societal sustainability while creating the necessary workforce to address these challenges. With SEES Fellows support, this project will enable a promising early career researcher to establish themselves in an independent research career related to sustainability.","title":"SEES Fellows: Developing Semi-parametric Models, Algorithms, and Tools for Ecological Analysis of Species Biodiversity","awardID":"1215950","effectiveDate":"2012-07-15","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8055","name":"SEES Fellows"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"7978","name":"Global Systems Science"}}],"PIcoPI":[516871],"PO":["565272"]},"193424":{"abstract":"The demand for wireless bandwidth has been growing at a rapid pace every year and is expected to continue. Estimates of annual growth in demand range from 71% in Japan to over 117% in the U.S. Projecting this ahead a decade implies per-user wireless bandwidth needs of tens of gigabits per second, which is at least two orders of magnitude greater than what most users see today.<br\/><br\/>Applications driving such a relentless thirst for bandwidth are quite diverse. From a consumer standpoint, key drivers include the evolution of applications such as ultra high-definition television while in the business domain applications include networking hundreds of thousands of computers together in data centers or delivering very high quality multimedia for medical and other similar applications. This project seeks to exploit a relatively unexplored part of the wireless spectrum to deliver data at rates of terabits\/sec. The spectrum in question is called the terahertz spectrum and extends in frequency from 300 GHz to 3.1 THz.<br\/><br\/>The challenges of delivering terabit data rates over the terahertz spectrum are many and range from a limited understanding of communication at these frequencies to utilizing the vast bandwidth available for establishing communication links to understanding networking at these frequencies. This project will provide answers to some of the larger open questions including channel characterization and modulation for achieving terabit rates. Techniques used for high speed communications today cannot be logically extrapolated to the terahertz band due to the massive amount of bandwidth involved which constrains devices and has complex unknown propagation properties. This project proposes an innovative way of exploiting the terahertz bandwidth to manufacture pulses, each of which carry large amounts of data. As a result, a terabit of information can be transmitted per second while using a relatively slow clock and inexpensive devices. The feasibility of this technique will be studied in a systematic way by first performing detailed terahertz channel measurements followed by the development of channel impulse response models at these frequencies. The measurements will consider distances of up to the dimensions of a small room and will serve as input to a terahertz simulator that will be built as part of this work. Using the measurements in conjunction with detailed simulations, the project will answer questions about the expected channel capacity when using these types of pulses. In parallel with these studies, the project will experimentally characterize pulse behavior over varying distances and environmental conditions. The project thus seeks to fill in important holes in our understanding of terahertz communications and will pave the way for future development of terahertz communication systems.<br\/><br\/>The broader impact of this work ranges from fundamentally influencing research directions in wireless communications to enabling the development of novel technologies for future generation communications. Furthermore, the terahertz measurement database developed as part of this project will be made public and will serve as a valuable resource to the broader scientific community. The project will also enhance the training of the future workforce via the development of new classes and including students in hands on measurement. Finally, the outcome of this work (terabit\/sec data delivery) will ultimately influence the way information is delivered in the home and in the workplace.","title":"NeTS: Small: Networking at Terahertz Frequencies","awardID":"1217994","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["518079"],"PO":["565303"]},"194645":{"abstract":"Health information technologies (IT), including electronic health records (EHRs) and mHealth technologies, are expected to play a key role in improving the quality of health care delivery for Americans and improve the performance of health care delivery. The federal government has committed $27 billion dollars over the coming decade, to fund the implementation of EHRs through an incentive-based program for organizations that demonstrate \"meaningful use\" of certified EHR technology. Though the potential for EHRs to improve the quality of health care is generally understood, researchers suggest that concerns about the confidentiality and privacy of EHRs present significant barriers to their effective use. As health IT becomes more widespread, health information breaches are increasing, as is public attention to such breaches, as are general concerns about the privacy and security of health information. The objectives of this workshop, the second iteration of the Securing Information Technology in Healthcare (SITH) workshop, are to: advance our understanding of the causes and consequences of security breaches; and promote the security and privacy of health information. feedback from workshop participants to a focused post-workshop survey, and a short after-action report. These products will provide the basis for an article summarizing the key ideas of the workshop for a relevant journal (e.g., IEEE Security & Privacy).","title":"Workshop: Securing Information Technology for Healthcare","awardID":"1228475","effectiveDate":"2012-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["553543",521358],"PO":["565136"]},"196834":{"abstract":"As computing systems move to exascale, they will be dominated by energy-efficiency. This project investigates three aspects related to enabling graphics procesing units (GPUs) to do general purpose computing under this energy-dominated regime. First, simple architectural innovations allow inter-processor communication. Second, this mechanism is exposed to the programming API. Finally, we address domain specific compilation of dense stencil computations. The project advances architecture, programmability and compilation for energy constrained computation, and also contributes to the foundations of compiling domain specific languages (DSLs) for these platforms through the mathematically rigorous program transformation techniques known as the polyhedral model. The research also makes secondary contributions to other broad areas relevant to exascale: end-user programmer productivity through the use of DSLs, impacting the future architecture of exascale computers, and exploration of the tradeoff between special-purpose vs general purpose computing.","title":"Co-Design for Exascale General Purpose computing on Graphics Processing Units (GPGPU)","awardID":"1240991","effectiveDate":"2012-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[528018],"PO":["565255"]},"193325":{"abstract":"Trends in computing have favored moving computation into centralized locations, called data centers. This centralization is occurring because the aggregation of computing allows better amortization of personnel managing the computers, economies of scale in computing equipment purchasing, and improved economies of scale in power delivery, buildings, and cooling. Coupled with these benefits, companies that run large data centers have begun leasing spare computational capacity to smaller companies, thereby enabling small companies to experience the benefits of high quality and high availability computing. Small companies can leverage these resources to have explosive growth on the Internet without the need to deploy data centers of their own. Current data centers commonly use commodity computer chips designed for desktop and laptop computers. This research, in contrast, explores how to optimize computer chips specifically for the data center. In addition, this research examines how the computer chip itself can be modified to enable more efficient sharing of resources between different customers of large data center providers and how computer chip architecture can be modified to support new economic models such as leasing of computer resources. This work is important because it will decrease the cost of creating large data centers, enable better transparency in billing for computational resources in large-scale shared data centers, and allow data centers to be more energy efficient.<br\/><br\/>This research attacks several of the key challenges in building manycore processors optimized for Infrastructure as a Service (IaaS) Cloud computing systems. This work breaks down arbitrary boundaries between cores in a manycore system by allowing resources from one processor core to be utilized by another processor core. This can enable the hardware resources provided to a particular virtual machine to be matched to the needs of that particular virtual machine. In addition, this work is investigating how to optimize cache hierarchies for thousands of independent data and instruction streams to enable more efficient memory hierarchies, and this work is characterizing how different architectural resources are utilized when shared between multiple Cloud-specific applications.","title":"SHF: Small: Redesigning Manycore Computer Architecture for the Mega-core Data Center","awardID":"1217553","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["559770"],"PO":["366560"]},"193446":{"abstract":"Biologists and engineers are working together to develop the field of synthetic biology. These researchers are attempting to design synthetic genetic circuits that enable bacteria to consume toxic waste, destroy tumors, and produce drugs and bio-fuels. While experimental methods for genetic engineering have existed for a long time, synthetic biology adds a principled design methodology that is supported by repositories of standard parts, high-level model abstractions, and an automated construction process. Since these are the cornerstones of electronic design automation (EDA) which has enabled the design of more complex computer chips each year, it is logical that experiences with EDA will be leveraged during the development of genetic design automation (GDA). <br\/><br\/>Intellectual merit: This project will develop a comprehensive and integrated suite of GDA tools to support efficient analysis and design of synthetic genetic circuits. These tools will leverage and extend standards, such as the Systems Biology Markup Language (SBML) and Synthetic Biology Open Language (SBOL), to allow for the exchange of models and designs with other researchers. Our research will develop new modeling, analysis, and visualization methods that enable the study of the dynamic behavior of bacterial populations. The efficiency of these tools will be enhanced using automated model abstraction and parallel computer algorithms. PI's design tools will exploit techniques developed for asynchronous (clock-less) integrated circuits. PI will work with experimental collaborators to validate the research results.<br\/><br\/>Broader Impacts: Due to the wide applications being proposed for synthetic biology ranging from drug production and gene therapies to biofuels, the potential impact of this research is significant. This research will bring together people in theory and modeling with those doing experimental work. This project will also support the development of extensions to standards enabling the development of ever more complex systems. These standards as well as all software developed in this project will be released into the public domain. The PI is committed to the integration of research with education through the development of course materials and working with undergraduates.","title":"AF: SHF: BCSP: Small: Genetic Design Automation","awardID":"1218095","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7946","name":"BIO COMPUTING"}}],"PIcoPI":["448038"],"PO":["565223"]},"186824":{"abstract":"Electronic corpora annotated with linguistic information play a crucial role in natural language processing (NLP) and in linguistic research. Treebanks (corpora annotated with syntactic information) are especially important since they mark the grammatical structure necessary for understanding sentence and discourse meaning. For NLP, treebanks provide testbeds for developing language understanding systems. For linguistic research, they provide the basis for precise and replicable studies of the patterns of use of syntactic forms. Unfortunately, accurate annotation is difficult. Automatic parsers have relatively high error rates and the correction of these errors by human annotators is both slow and itself error-prone. Based on recent advances that Dr. Kroch and his collaborators have made in the creation and quality control of three large treebanks for different languages, Dr. Kroch proposes a major effort to improve corpus construction through the creation of a two-million-word English treebank. Along with this useful and substantial result, the project will develop and test hypotheses on speeding up treebank construction. The work will be guided by two complementary strategies. The first aims to reduce the parser's error rate by enhancing the part-of-speech (POS) tagged input to the parser while the second aims to make the correction of residual errors more efficient by shifting some of the burden from human to automatic error detection and correction. Speeding up the construction of accurate, consistent treebanks will improve the size and quality of training data for parsers, leading to improved performance in real-world NLP applications that rely on parsing. The availability of larger treebanks and of better methods for constructing them will also improve linguistic research. Moreover, as treebanks grow in size, they will become more useful in literary and historical studies, where the rhetorical structure of texts will become investigable in a more precise way than is currently possible.<br\/><br\/>In addition to the intellectual merit of the proposed research and the impact it can be expected to have on text-based research that relies on automated processing techniques, the project will provide valuable training opportunities for graduate and undergraduate students. In contributing to improvements in automated techniques for language processing, this project may also benefit the analytic needs in industry and government security.","title":"Testing and improving methods for efficient annotation through the construction of a large parsed corpus","awardID":"1147499","effectiveDate":"2012-07-15","expirationDate":"2014-12-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"1311","name":"LINGUISTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[501245,501246],"PO":["564343"]},"186769":{"abstract":"A collaborative award has been made to the University of Arizona and the University of California at Davis to develop novel ways of tying scientific names directly to published biological characteristics of organisms, and to implement a new user-friendly program, the Explorer of Taxon Concepts (ETC), to assist with the disambiguation of the scientific names of species at all taxonomic ranks. Prototypes from several successful NSF-funded projects are integrated through ETC to enable: (i) text-mining extraction of taxonomic knowledge from scientific literature, (ii) analysis and integration of this knowledge using logic-based reasoning and information theoretic methods, and (iii) result visualization. The results shed light on similarities and differences among various scientists' understanding of a particular species, as well as relations between the terminology used by different scientists, allowing for more accurate integration of data gathered by different investigators. A component of the ETC project is computer science research aimed at a novel integration of state-of-the-art logic inference and information theoretic approaches to taxonomic science.<br\/><br\/>Scientific names are the primary identifiers for organisms and the anchor for the communication and comparison of biological knowledge. However, there is constant revision of the definition of taxa by experts, making interpretation of the names through time challenging. This project will produce and demonstrate the use of ETC software on descriptive scientific literature from the Rosaceae (the Rose family) and Apoidea (the Bee super-family) to facilitate research into critical pollination systems. These pollination systems are currently of great concern due to reductions in bee populations globally with the potential to reduce yield of many staple food crops. ETC's components support scientific knowledge value added to its inputs, making them useful in many other biodiversity information applications. Character and anatomy ontologies built and enhanced by the ETC project will benefit all knowledge-based applications in biology. The project adopts the following strategies to broaden its accessibility: The integration of ETC components with existing biological computing infrastructure such as DataONE and iPlant will make the tools broadly available. The partnership with iPlant's successful Education, Outreach, and Training (EOT) group will document the software for instructional use and encourage its adoption in the classroom. Components of the research and the final products will also be packaged into learning modules for college and graduate level courses at University of Arizona, the University of California at Davis, and other universities. Project outcomes will be accessible via the link provided at: http:\/\/sirls.arizona.edu\/node\/684.","title":"BCSP: Collaborative Research: ABI Development: Exploring Taxon Concepts (ETC) through analyzing fine-grained semantic markup of descriptive literature","awardID":"1147266","effectiveDate":"2012-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"1165","name":"ADVANCES IN BIO INFORMATICS"}}],"PIcoPI":[501113,"243951"],"PO":["561151"]},"189608":{"abstract":"The central theme of this project is to investigate methodologies and theories to enhance throughput, delay, and fairness of cognitive radio networks via integrated dynamic spectrum access. The research will develop new methods to:<br\/>1) Extend spectrum sensing beyond just the presence and absence of the primary spectrum users' activities at certain spectrum bands\/channels, but also their locations and transmit powers <br\/>2) Predict the primary spectrum user's activity and its interval using game theoretic and statistical learning approaches <br\/>3) Perform delay-aware spectrum management with a very comprehensive delay model considering all the factors that may affect the delivery latency of a packet, including the spectrum sensing delay, the transmission delay, the queuing delay, and the spectrum negotiation and scheduling delay<br\/>4) Share spectrum in a fair manner considering the tradeoff between fairness and throughput<br\/>5) Propose a delay-aware fair routing protocol for throughput optimization which jointly considers throughput, delay, and fairness along with dynamic spectrum management.<br\/><br\/>The project's focus on dynamic spectrum access is of high national interest and can create significant impact on spectral usage policies and related industries in the telecommunication and information technology sectors. The project will also encourage and include under-represented and minority students to be part of this activity, while extending education and outreach plans to undergraduates and K-12 students.","title":"NeTS: Medium: Collaborative Research: Integrated Dynamic Spectrum Access for Throughput, Delay, and Fairness Enhancement","awardID":"1162159","effectiveDate":"2012-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["194325"],"PO":["565303"]},"187309":{"abstract":"This project investigates social multimedia for geographic discovery. Specifically, community-contributed ground-level images and videos are used to map what-is-where on the surface of the Earth in much the same way that overhead images taken from air- or space-borne platforms have been used for decades in the traditional field of remote sensing. The overarching premise is that georeferenced social multimedia data can be considered a form of volunteered geographic information. Further, it can enable geographic discovery not possible through traditional means. The framework, termed proximate sensing, is applied to two challenging geographic discovery problems: 1) land-use classification, and 2) mapping public sentiment such as how scenic a particular geographic location is. Land-use classification is an important problem but is often not possible using overhead images since remote sensing does not record activities. This project instead applies and extends state-of-the-art techniques in image understanding to ground-level images and videos to map land-use. The motivation is similar for mapping public sentiment.<br\/><br\/>The broader impacts include developing K-12 spatial literacy curricula through an Engineering Projects in Community Service team whose client is the Merced County Office of Education. University of California-Merced was recently classified as an Hispanic Serving Institution, making it one of only a handful of research universities with this designation nationwide. Undergraduate students from underrepresented groups will be involved in developing a GeographUSA project whereby volunteers can upload geographically representative photos of the United States. Results, datasets, and other project artifacts will be made available through the project website (http:\/\/vision.ucmerced.edu\/projects\/socialmultimedia\/).","title":"CAREER: Social Multimedia as Volunteered Geographic Information: Crowdsourcing What-Is-Where on the Surface of the Earth Through Proximate Sensing","awardID":"1150115","effectiveDate":"2012-07-01","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[502374],"PO":["563751"]},"193612":{"abstract":"Advancing lithography patterning, which enables feature size scaling, has been a holy grail for the semiconductor industry. There are several leading nanolithography technologies for 14nm, 11nm, 7nm and 1x nm for extreme scaling, including multiple patterning lithography (MPL), extreme ultraviolet lithography (EUVL) and e-beam lithography (EBL). This project aims at developing novel design for manufacturability algorithms, tools, and methodologies for nanometer integrated circuits (IC) manufactured through these emerging nanolithography technologies. The proposed research will synergistically link nanolithography process modeling\/abstraction with multi-scale layout optimization. For MPL, robust and scalable multi-objective layout decomposition algorithms and MPL-aware physical design tools will be developed. For next-generation nanolithography such as EUVL and EBL, new design and process integration issues will be studied. Hybrid nanolithography (e.g., combining MPL with EBL) will also be explored to shed light on ultimate nano-patterning for future IC layout design. The proposed solutions will span multiple technology layers and bring together experts from both academia and industry.<br\/><br\/>This proposed project addresses fundamental challenges to bridge the gap between IC design and manufacturing in extreme scaling. Thus its potential impacts to the semiconductor industry and associated information and high-tech industries cannot be overstated. The academia-industry collaboration between University of Texas and IBM promises innovative and high-risk academia research coupled with realistic industry data\/benchmarks and timely technology transfer through IBM and its global partners to benefit the overall industry. The highly interdisciplinary nature of this research will be tightly integrated into a variety of curriculum development and diverse student mentoring programs.","title":"SHF: SMALL: GOALI: Design for Manufacturability in Extreme Scaling with Emerging Nanolithography","awardID":"1218906","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"1504","name":"GRANT OPP FOR ACAD LIA W\/INDUS"}}],"PIcoPI":["535167"],"PO":["562984"]},"192468":{"abstract":"Most of the traditional High-End Computing (HEC) applications and<br\/>current petascale applications are written using the Message Passing<br\/>Interface (MPI) programming model. Some of these applications are run<br\/>in MPI+OpenMP mode. However, it can be very difficult to use MPI or<br\/>MPI+OpenMP and maintain performance for applications which demonstrate<br\/>irregular and dynamic communication patterns. The Partitioned Global<br\/>Address Space (PGAS) programming model presents a flexible way for<br\/>these applications to express parallelism. Accelerators introduce<br\/>additional programming models: CUDA, OpenCL or OpenACC. Thus, the<br\/>emerging heterogeneous architectures require support for various<br\/>hybrid programming models: MPI+OpenMP, MPI+PGAS, and MPI+PGAS+OpenMP<br\/>with extended APIs for multiple levels of parallelism. Unfortunately,<br\/>there is no unified runtime which delivers the best performance and<br\/>scalability for all of these hybrid programming models for a range of<br\/>applications on current and next-generation HEC systems. This leads<br\/>to the following broad challenge: \"Can a unified runtime for hybrid<br\/>programming model be designed which can provide benefits that are<br\/>greater than the sum of its parts?\"<br\/><br\/>A synergistic and comprehensive research plan, involving computer<br\/>scientists from The Ohio State University (OSU) and Ohio Supercomputer<br\/>Center (OSC) and computational scientists from the Texas Advanced<br\/>Computing Center (TACC) and San Diego Supercomputer Center (SDSC),<br\/>University of California San Diego (UCSD), is proposed to address the<br\/>above broad challenge with innovative solutions. The investigators<br\/>will specifically address the following challenges: 1) What are the<br\/>requirements and limitations of using hybrid programming models for a<br\/>set of petascale applications? 2) What features and mechanisms are<br\/>needed in a unified runtime? 3) How can the unified runtime and<br\/>associated extension to programming model APIs be designed and<br\/>implemented? 4) How can candidate petascale applications be<br\/>redesigned to take advantage of proposed unified runtime? and 5) What<br\/>kind of benefits (in terms of performance, scalability and<br\/>productivity) can be achieved by the proposed approach? The research<br\/>will be driven by a set of applications from established NSF<br\/>computational science researchers running large scale simulations on<br\/>Ranger and other systems at OSC, SDSC and OSU. The proposed designs<br\/>will be integrated into the open-source MVAPICH2 library. The<br\/>established national-scale training and outreach programs at TACC,<br\/>SDSC and OSC will be used to disseminate the results of this research.","title":"SHF: Large: Collaborative Research: Unified Runtime for Supporting Hybrid Programming Models on Heterogeneous Architecture","awardID":"1213084","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["561947",515816],"PO":["565272"]},"189609":{"abstract":"This project is developing efficient solid-state data storage device and system design solutions. Although solid-state data storage has shown a high potential to significantly advance storage systems to achieve ultra-high performance with low energy consumption, continuous semiconductor technology scaling makes it increasingly challenging to realize efficient and reliable solid-state data storage devices and systems for the storage hierarchy in large-scale systems, such as data centers and cloud systems. <br\/><br\/>The intellectual merit of this proposal lies in the theme of developing solid-state data storage design techniques from both software and hardware. Major solid-state data storage device architecture functions, including error correction coding, wear-leveling and garbage collection algorithms, are being developed. Workload and device-aware solid-state data storage system design solutions are also being developed for large data center applications. Design solutions will be evaluated using an experimental hardware platform and the Linux operating system.<br\/><br\/>The broader impact of the proposed research is that it will enable the development of highly reliable and low-cost solid-state data storage devices and systems for large-scale computing and storage systems. The adoption of the design methodology by solid-state data storage architects, system designers, and data-intensive practitioners may provide a direct benefit to this strategically important high technology sector critical to the economic health of the nation. This team will also introduce new research results into courses.","title":"CSR: Medium: Collaborative Research: On Closed-Loop and Cross-Layer Design and Implementation of Data Storage Systems Utilizing Extremely Scaled NAND Flash Memory Technologies","awardID":"1162165","effectiveDate":"2012-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["551992"],"PO":["551712"]},"190775":{"abstract":"Vision and language provide fundamental means to interpret, learn, and communicate about the world around us. A primary goal of computer vision and natural language processing research is therefore to automatically uncover and analyze the information that images and video, or text and speech, convey about the world. Both communities are concerned with tasks that require increasingly deeper understanding, including the ability to reason with and draw inferences from this information. Since vision and language are complementary modalities, there is now also an increasing amount of work at the interface of both fields. However, progress in multimodal analysis requires a tighter collaboration between the two communities, since each currently relies on its own set of techniques, datasets and evaluation criteria. <br\/><br\/>This community planning grant explores the need for, feasibility, and usefulness of a \"visual entailment\" corpus and associated visual entailment recognition task. In natural language, entailment recognition is the problem of determining whether a particular statement can be inferred from a text document. This project explores a novel related problem - visual entailment - where the goal is to determine whether a statement in natural language can be inferred from an image or video. The outcomes of the project include a novel dataset and prototype research challenge, as well as increased collaboration between the vision and language communities.","title":"CI-P:Collaborative Research: Visual entailment data set and challenge for the language and vision communities","awardID":"1205354","effectiveDate":"2012-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[511442],"PO":["564316"]},"190896":{"abstract":"This project supports the research focused on computational stereoscopic imaging for enhanced visualization at Portland State University. Stereoscopic 3D enabled devices are becoming more ubiquitous, providing their users with a more immersive experience. However, there exists a gap between the increasing demand of stereoscopic content and the limited capability of stereoscopic content production. Stereoscopic content needs to be carefully produced to avoid 3D fatigue. This project enables research to bridge this gap by establishing a stereoscopic imaging, displaying, and system infrastructure to support the research on computational stereoscopic photography and cinematography, stereoscopic systems support, and next-generation multi-lens stereoscopic imaging. This infrastructure consists of a comprehensive spectrum of stereoscopic imaging equipment and a range of stereoscopic displays. The stereoscopic imaging equipment includes both the state-of-the-art commercial cameras and the development of a platform to mimic next-generation multi-lens imaging devices. A particularly important component of this project is to develop a large, diverse set of conventional stereoscopic videos and multi-lens stereoscopic imaging data that will be shared with the community to promote computational research on stereoscopic 3D. <br\/><br\/>This project helps to better understand the relation between capture, compression, and display, and to facilitate the production of high-quality stereoscopic content to reduce the side effects such as 3D fatigue and headaches that people have from viewing low-quality stereoscopic content. The research results are disseminated through conference and journal publication and the research data, particularly the stereoscopic video library, is shared online.","title":"II-NEW: An Infrastructure to Support Advanced Computational Stereoscopic Cinematography and System","awardID":"1205746","effectiveDate":"2012-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["518376","551135"],"PO":["564316"]},"193547":{"abstract":"This project aims to improve and develop electromagnetic (EM) analysis tools to meet the demand of the computer chip industry. The modeling of EM effects in computer integrated circuits (IC) has in recent years become increasingly important, due to the increased transistor density and switching clock rate of CPU?s in a computer. For this reason, EM effect is a challenge identified by the International Technology Roadmap for Semiconductors (ITRS) as an area of priority. But the exorbitant computational cost and complexity of such EM modeling problems have precluded their precise solution so far. Commercial simulation tools for multi-function broadband ICs, which trade accuracy for efficiency, cannot fully meet the stringent demands for broad bandwidth and complexity of next generation applications. However, fast algorithms for EM simulations have potentials when stabilized with appropriate techniques for broadband applications to capture both circuit physics and wave physics. Fast, efficient, and highly stable algorithms will be developed for seeking broadband, multi-scale solutions of IC problems. The solutions will be integrated with existing Electronics Design and Automation (EDA) tools, and co-design will be studied at chip and package levels. The work will be connected to real-world problems and models will be validated with measurements. <br\/><br\/>The potential impact of fast and efficient modeling technique for electronic ICs can alter how computers are designed. It will remove bottlenecks caused by EM effects due to increased transistor density and switching clock rates, and allow the accurate virtual prototyping of circuit design over a broad frequency range. It will also encourage IC designers to use more microwave engineering paradigms in future IC designs. Hence, it will expand the design space of IC and circuit designers, increase their repertoire of toolboxes, and enrich new possibilities for future IC designs. Due to the lack of high-quality computer-aided design (CAD) design tools that incorporate EM effects efficiently and accurately, IC designers face bottlenecks due to signal and power integrity issues in 3D IC designs. By precise and efficient electromagnetic modeling, CAD IC characterization will be improved and the design barriers faced by IC designers will be pushed back. <br\/><br\/>In addition, this project will train students, at various levels ranging from undergraduates to graduates, to be well versed in electromagnetic physics, applied mathematics, computer science, and measurements (with a keen focus on the science of IC simulation and design). Students schooled in this cross-disciplinary field generally adapt easily to adjacent areas of research in academia and industry. Hence, this project will train badly needed human resource in computational science and engineering and adjacent fields for the advancement of high tech. EM physics, valid over a vast length scale, is fundamental to many electrical engineering technologies. Fast, broadband computational electromagnetics (CEM) algorithms for complex structures are applicable to a large variety of other applications including micro- and nano-technologies, ranging from meta-material modeling, to nano-optics and nano-lithography. It can help in the design of super-resolution lithography, and improve the modeling of EM effects in N\/MEMS, sensors and actuators, interconnects in computers at the package level, as well as at the board level. It will enable the modeling of small, complex, smart, and reconfigurable antennas, RF integrated circuits, as well as greatly impacting terahertz modeling, biotech, and homeland security technology development.","title":"SHF: Small: INTEGRATED CIRCUITS BROADBAND MULTISCALE ANALYSIS WITH FAST ALGORITHMS","awardID":"1218552","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[518361,518362],"PO":["562984"]},"196704":{"abstract":"Igbo is a language spoken by twenty million people, mostly in southern Nigeria. This EAGER project makes use of a corpus of spoken Igbo, which will cover all of the dialects of the language. The corpus is to be used for explorations in which statistical machine learning (ML) programs are created to learn an \"inter-Igbo'' consisting cognate sets (Igbo words pronounced differently in different locations but having the same meaning) that enable the corpus to be treated as if it were spoken as a single language, even though the dialects are, at extreme ends of the Igbo homeland, mutually unintelligible. Another aspect of our work is the extension of the existing corpus to fill in gaps in dialect coverage where there currently are recordings from locations that have no near geographical neighbors. The need for this stems from the fact that the closer a dialect's neighbors the more similar they are, and the easier for programs to locate words which differ systematically.<br\/><br\/>Achieving goals of this exploratory project is of considerable interest for computational linguistics. As opposed to language change over time, there is little computational work on language change over geography, and finding the appropriate ML models for the latter aspect of language variation is a considerable challenge.","title":"EAGER: Construction of Inter-Igbo","awardID":"1240178","effectiveDate":"2012-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[527631],"PO":["565215"]},"193558":{"abstract":"Due to increasing design complexity coupled with shrinking time-to-market constraints, it is not possible to detect all design flaws during pre-silicon validation of System-on-Chip (SoC) designs. Post-silicon validation needs to capture these escaped functional errors as well as electrical faults. Various studies suggest that post-silicon validation consumes almost half of the overall SoC design effort (total cost). A major concern during post-silicon debug is the observability of internal signals since the chip has already been manufactured. Design overhead considerations limit the number of signals that can be traced or stored in a trace buffer. The central objective of this project is to develop automated tools and techniques for efficient post-silicon validation and debug of integrated circuits. To achieve this goal, this project will investigate the synergistic integration of four innovative concepts: i) debug-friendly trace signal selection, ii) efficient trace hardware design, iii) observability-aware directed test generation, and iv) high-level debug to reproduce post-silicon errors. A successful implementation of this research is expected to reduce the post-silicon validation and debug effort by several orders of magnitude.<br\/><br\/>This project will make significant broader impact in several fronts. The tools and techniques resulted from this project will empower designers to reuse pre-silicon verification efforts for post-silicon validation in order to reduce overall validation cost and improve design quality. The outcome of this research has direct impact on everyday life. Improved validation techniques will have double impact: (i) low-cost and high-quality embedded systems (e.g., everyday appliances) for the public and (ii) improved accuracy of the safety-critical devices. Going beyond integrated circuits and systems, some of the analysis and validation techniques resulting from this work can be applied to other areas of science and engineering including validation of embedded software and dynamic monitoring of autonomous systems. This project will integrate research and educational activities through development of courses on post-silicon validation as well as dissemination of research results through publications, seminars, and tutorials. The PI will involve minority undergraduate students in this project through UMMP and SEAGEP programs at University of Florida.","title":"SHF: Small: Automated Techniques for Efficient Post-Silicon Validation and Debug of Integrated Circuits","awardID":"1218629","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[518389],"PO":["562984"]},"192348":{"abstract":"Meta-algorithms are algorithms that take other algorithms as input. <br\/>Meta-algorithms are important in a variety of applications, from <br\/>minimizing circuits in VLSI to verifying hardware and software to <br\/>machine learning. Lower bound proofs show that computational problems <br\/>are difficult in the sense of requiring a prohibitive <br\/>amount of time, memory, or other resource to solve. <br\/>This is particularly important in the context of cryptography, <br\/>where it is vital to ensure that no feasible adversary can break <br\/>a code. Surprisingly, recent research by the PIs and others <br\/>shows that designing meta-algorithms is, in a formal sense, <br\/>equivalent to proving lower bounds. In other words, one can prove a <br\/>negative (the non-existence of a small circuit to solve a problem) by <br\/>a positive (devising a new meta-algorithm). This was the key to a <br\/>breakthrough by PI Williams, proving lower bounds on constant <br\/>depth circuits with modular arithmetic gates. <br\/><br\/>The proposed research will utilize this connection both to <br\/>design new meta-algorithms and to prove new lower bounds. <br\/>A primary focus will be on meta-algorithms for <br\/>deciding if a given algorithm is 'trivial' or not, such as algorithms <br\/>for the Boolean satisfiability problem. The proposed research will devise new <br\/>algorithms that improve over exhaustive search for many variants <br\/>of satisfiability. On the other hand, it will also explore <br\/>complexity-theoretic limitations on how much improvement is <br\/>possible, using reductions and lower bounds for restricted <br\/>models. Satisfiability will provide a starting point for a more <br\/>general understanding of the exact complexities of other NP-complete <br\/>problems such as the traveling salesman problem and k-colorability. <br\/>The proposal addresses both worst-case performance and the use <br\/>of fast algorithms as heuristics for solving this problem. <br\/><br\/>This exploration will be mainly mathematical. However, when <br\/>new algorithms and heuristics are developed, they will be <br\/>implemented and the resulting software made widely available. <br\/>This research will be incorporated in courses taught by <br\/>the PI's, at both graduate and undergraduate levels. <br\/>Both graduate and undergraduate students will perform research <br\/>as part of the project.","title":"AF: Large: Collaborative Research: Exploiting Duality between Algorithms and Complexity","awardID":"1212372","effectiveDate":"2012-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[515483],"PO":["565251"]},"192469":{"abstract":"Successful software constantly evolves. Most programmers work on projects they did not start. Most companies spend more on maintaining old systems than on building new ones. This is good, because it shows that companies build software that is worth keeping and maintaining, but it also means that change is the heart of software development. Most programming tools treat change at a very low level: programmers make most changes with text editors, and tools tend to focus on changes to lines of text, and although programming is predominantly about change, contemporary tools do not provide direct support for understanding or facilitating change. This makes programming more expensive, time-consuming, and error-prone than it should be. This research project will develop a change-oriented programming environment (COPE) that supports change by putting transformations at the center of software development. COPE will enable both average and expert programmers to write, script, modify, and replay their own transformations. COPE will enable programmers to think about programs as compositions of transformations, and to automate as many of these transformations as possible. Characterizing software development in terms of transformations is an essential step to take software engineering from manual development to automated (or semi-automated) development of software.<br\/><br\/>By enabling programmers to express their programming tasks as program transformations, COPE will alter the way programmers think about, teach, create, reuse, and understand programs. Specifically, COPE considers five activities: (1) analyze what changes programmers typically make and how they perceive, recall, and communicate changes, (2) automate transformations to make it easier to apply and script changes, (3) develop tools that compose and manipulate transformations to make it easier to reuse them, (4) integrate transformations with version control to provide better ways for archiving and understanding changes, and (5) develop tools that infer higher-level transformations from lower-level changes. COPE will deliver a rich transformation-aware toolset that synergistically integrates all these activities. COPE aims to (a) change the way people program, (b) create a platform for research for future research, and (c) produce results that ultimately will become standard software development practice. The PIs will disseminate the results through presentations, books, publications, open-source code, industrial collaborations, and educational activities. A version of COPE will be used to revamp the software engineering curriculum at the University of Illinois and the University of Texas to emphasize the science of change in large code bases.","title":"SHF: Large: Collaborative Research: Science and Tools for Software Evolution","awardID":"1213091","effectiveDate":"2012-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["561355","518573","518574",515821],"PO":["564388"]},"190864":{"abstract":"Vision and language provide fundamental means to interpret, learn, and communicate about the world around us. A primary goal of computer vision and natural language processing research is therefore to automatically uncover and analyze the information that images and video, or text and speech, convey about the world. Both communities are concerned with tasks that require increasingly deeper understanding, including the ability to reason with and draw inferences from this information. Since vision and language are complementary modalities, there is now also an increasing amount of work at the interface of both fields. However, progress in multimodal analysis requires a tighter collaboration between the two communities, since each currently relies on its own set of techniques, datasets and evaluation criteria. <br\/><br\/>This community planning grant explores the need for, feasibility, and usefulness of a \"visual entailment\" corpus and associated visual entailment recognition task. In natural language, entailment recognition is the problem of determining whether a particular statement can be inferred from a text document. This project explores a novel related problem - visual entailment - where the goal is to determine whether a statement in natural language can be inferred from an image or video. The outcomes of the project include a novel dataset and prototype research challenge, as well as increased collaboration between the vision and language communities.","title":"CI-P:Collaborative Research: Visual entailment data set and challenge for the Language and Vision Community","awardID":"1205627","effectiveDate":"2012-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[511678],"PO":["564316"]},"190875":{"abstract":"Project Shelob is a major effort to support the computational science research, education and training requirements of investigators using modern high performance computing systems equipped with graphical processing units, or GPUs. GPUs are nearly identical to the high-end graphics cards found in personal computers dedicated to gaming applications. The same capabilities that support games with highly realistic real-time animations can be adapted to vastly improve the speed of getting answers on complex science problems. This comes at a cost, however, as the programming becomes more difficult, a burden considering that programming modern parallel computing systems is already a difficult task. The Shelob system provides a dedicated platform to allow experimenting on a production grade system, allowing new methods to be worked out, and providing a platform that can be used for teaching which does not interrupt the critical workflow on other research production systems.<br\/>The Shelob system is a compute cluster that allows for parallel programming using distributed memory methods, and adds the ability for nodes to incorporate GPU processing. Such heterogeneous systems require programmers to understand both conventional message-passing (i.e. MPI) programming methods, and the methods specific to GPU programming. The only way researchers can determine how to mix the methods for best performance is to have system-level access to modify and adjust settings as necessary.<br\/>There are high expectations for Shelob, not the least of which is instilling excitement in high school and undergraduate students over the possibilities presented for work and research in high performance computing. Programs such as Research Experiences for Undergraduates and the Beowulf Bootcamp, provide unique opportunities to students. Multi-institutional research groups, such as Cactus and Pluto, hope to develop easier ways to make use of the power promised by the Shelob system hardware. Other groups, such as the Louisiana-wide LA-SiGMA project, hope to develop the next generation of codes to support material science research and the development of novel materials for industrial applications.","title":"II-NEW: Shelob - A Heterogeneous Computing Platform to Enable Transformation of Computational Research and Education in the State of Louisiana","awardID":"1205682","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["558252","540196","557463","527880","557461"],"PO":["565272"]},"193603":{"abstract":"Recently, nano-enabled thermoelectric devices have attracted much attention for cost-effective embedded (hot spot) and portable cooling applications such as in high-performance integrated circuits, lasers, and medical and food chillers. However, efficiency of this novel technology, to a large extent, relies on: (i) Fine-tuning the basic material parameters (Seebeck coefficient, electrical conductivity, and thermal conductivity) that are strong function of coupled structural-electronic processes at the nanoscale; and ii) System-level optimization considering the geometry, substrates, and contacts. These critical and challenging tasks have not yet been fully addressed and assessed experimentally and, therefore, demand a careful numerical investigation. As a response to this need, the goal of this research is to design nano-enabled embedded thermoelectric cooling modules offering improved efficiency and the ability to be operated at high temperature. For this purpose, a multiscale simulator will be integrated, where the material and device parameters will be obtained atomistically using first-principles and molecular dynamics simulations and will eventually be used in the system level design and optimization. The multiscale simulation platform will expose new degrees-of-freedom available at nanoscale (such as engineering density-of-states, effective mass, structural relaxation, localized disorder, surface-to-volume ratio, internal polarization, and non-degeneracy) and create transformative design routes for boosting efficiency and reliability of thermoelectric systems.<br\/><br\/>Thermoelectric technology offers high power density and fast response, is vibration and noise free, small and lightweight, and environmentally safe. Besides applications in embedded and potable coolers, thermoelectric devices are used as power sources for remote telecommunication, navigation, and radioisotope generator for space vehicles, and has potential promise in heat scavenging in vehicle exhaust system. Solid-state thermoelectrics will thus diversify and help sustain the growth in the global semiconductor market. The project also encompasses significant education and outreach activities. Graduate students will be engaged in software development, integration, and data analysis. In addition, senior design projects will be developed for undergraduate students. The simulator, along with the documentation, tutorials, case studies, will be freely distributed under the GNU public use license and an educational version (with a graphical user interface) will be deployed on NSF?s nanoHUB.org for the broader community for use in research and class-room teaching activities.","title":"SHF: SMALL: Embedded Cooling of High-Performance ICs Using Novel Nanostructured Thermoelectrics: Multiscale Software Development and Device Optimization","awardID":"1218839","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[518496],"PO":["562984"]},"196606":{"abstract":"Research and Education (R&E) Networks are a foundational element of cyberinfrastructure for research and education. This exploratory project will engage the Pacific R&E community, scientists, service providers and other stakeholders to develop concepts and approaches for R&E networking in the Pacific Islands. While focusing on the Pacific, this work will study the O3b (www.o3bnetworks.com) satellite network, which will have broad applicability for R&E networking in other regions, particularly addressing locations in Africa and Latin America, as well as for ship-based research around the world. An intermediate report will focus on locations and technologies and be sufficient to support specific actions focused on connecting specific locations. A more complex roadmap for R&E Networking in the Pacific, which will require greater socialization, will be produced as a final report. <br\/><br\/>This project will provide the first systemic study of the challenges and opportunities of R&E networking in the Pacific region. However, the greater intellectual merit of this project will lie in the advancement of some of the most compelling research activities in earth, atmospheric and environmental sciences. These include: work at the Coral Reef LTER and CREON programs at the Gump Station on Moorea; work on biodiversity and ecology, the terrestrial\/marine Interface, and marine biology, climate change, and biogeochemical structure at Palmyra Atoll; support for 30 active NSF programs at the Charles Darwin Research Station in the Galapagos Archipelago; and AfricaArray's network of geophysical observatories across southern Africa. Broader impacts will result from the introduction of R&E networking as a key tool to engage Pacific Islanders, who are highly under-represented in STEM fields The networks being planned will support collaborative education, research and training that will help communities chart culturally appropriate paths to an environmentally and economically sustainable future that bridges modern science and technology with their own cultures, values, goals, challenges and opportunities.","title":"EAGER: Research and Education Networking in the Pacific Islands and Beyond: Exploring and Developing Approaches","awardID":"1239824","effectiveDate":"2012-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7369","name":"INTERNATIONAL RES NET CONNECT"}}],"PIcoPI":["559160",527261],"PO":["564246"]},"196617":{"abstract":"This is funding to support a workshop for 40 promising graduate students from the United States whose research covers aspects of Technology-Mediated Social Participation (TMSP). Technology-mediated social participation is generated when social networking tools, blogs and microblogs, user-generated content sites, discussion groups, problem reporting, recommendation systems, and other social media are applied to national priorities such as health, energy, education, disaster response, environmental protection, business innovation, or community safety. Although social media are transforming society, many universities have been slow to integrate these novel technologies and social structures into their curricula and research. Two previous NSF-supported TMSP Workshops have outlined an agenda for research and education in this area, which was published in a serious of journal articles appearing in a special issue of IEEE Computer. To increase research and education in TMSP, this workshop brings together an interdisciplinary group of graduate students to listen to presentations by leaders in the field, learn new research skills, and learn from each other by sharing the diverse research streams that focus on social media.<br\/><br\/>The TMSP \"webshop\" will include 40 graduate students from such fields as sociology, anthropology, communications, psychology, journalism and humanities as well as from information studies, information systems, human-computer interaction and computer science. Effort will be taken to ensure gender balance, strong representation from ethnic minority groups, and cross-disciplinarity. Students will apply by submitting a one-page statement of why they wish to attend the workshop along with their curriculum vitae. During the three-day workshop, students will attend presentations from an interdisciplinary group of distinguished leaders in the field and engage in other research and community-building activities. <br\/><br\/>Intellectual Merit: There is a growing recognition that social media technologies can bring profound benefits for national priorities such as disaster response, community safety, health\/wellness, energy sustainability, and environmental protection. However substantial research is needed to scale up participation, raise motivation, control malicious attacks, limit misguided rumors, and protect privacy. The TMSP workshop will foster new ideas, tools and theories in this area through intense multidisciplinary discussion. Topics to be covered share (1) a close linkage to compelling national priorities; (2) a scientific foundation based on established theories and well-defined research questions (privacy, reciprocity, trust, motivation, recognition, etc.); and (3) computer science research challenges (security, privacy protection, scalability, visualization, end-user development, distributed data handling, network analysis of community evolution, cross network comparison, etc.). <br\/><br\/>Broader impacts: The workshop will raise awareness of the importance of technology-mediated social participation as a distinct area of study, foster new interdisciplinary projects, raise the prominence of researchers and educators who are invited to speak, and promote greater understanding of the discipline among leading graduate students across the United States. The workshop will also help new researchers develop relationships with peers and experienced researchers and practitioners. Specific outcomes will include resources such as bibliographies, links to websites, video and slides sets from speakers and carefully crafted lists of courses, conferences, and journals. These resources will be helpful to researchers and educators who seek to expand their work in Technology-Mediated Social Participation.","title":"Summer Social Webshop 2012: Technology-Mediated Social Participation","awardID":"1239863","effectiveDate":"2012-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["560696",527290,527291,527292],"PO":["564456"]},"192944":{"abstract":"Mechanism design studies problems where the preferences of self-interested participants --- such as a value of a good or a cost of performing a task --- are a priori unknown to the decision-maker. The high-level goal is to design a protocol, or \"mechanism,\" that interacts with participants so that self-interested behavior yields a desirable outcome.<br\/><br\/>Computer science has brought new ideas and techniques to the classical economic theory of mechanism design. A primary signature of the computer science approach is approximation --- the idea of building credibility for a proposed solution by proving that its performance is always within a small factor of an ideal (and typically unimplementable) solution. Approximation guarantees are a fundamental tool for measuring suboptimality, which can arise in mechanism design because of computational tractability constraints, the inefficiency of game-theoretic equilibria, or information-theoretic barriers to obtaining full optimality. The goals of the proposed research are: to further the theory of prior-independent and prior-free auctions for revenue maximization; to apply the concept of approximation to auctions with interdependent values; to pursue equilibrium performance guarantees for auctions with low-dimensional bid spaces; and to seek new results on tractable combinatorial auctions.<br\/><br\/>The broader significance and importance of the project are as follows. First, mechanism design has several applications highly relevant to<br\/>the computing industry, such as combinatorial auctions for wireless spectrum, search keyword auctions, and the real-time allocation of both online and more traditional advertising. The proposed research applies concepts and techniques from theoretical computer science to obtain new insights about fundamental models in mechanism design, and to produce new models and results that may be more germane for computer science applications. Second, the project funding will enable the mentoring of PhD students, innovation in graduate teaching, the dissemination of technical surveys and educational materials, and the recruitment of undergraduates into research.","title":"ICES: Small: Frontiers in Mechanism Design","awardID":"1215965","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":[516879],"PO":["565251"]},"192955":{"abstract":"The control of epidemics, broadly defined to range from human diseases such as influenza and smallpox to malware in communication networks, relies crucially on interventions such as vaccinations and anti-virals (in human diseases) or software patches (for malware). These interventions are almost always voluntary directives from public agencies; however, people do not always adhere to such recommendations, and make individual decisions based on their specific \"self interest\". Additionally, people alter their contacts dynamically, and these behavioral changes have a huge impact on the dynamics and the effectiveness of these interventions, so that \"good\" intervention strategies might, in fact, be ineffective, depending upon the individual response. <br\/><br\/>The goal of this project is to study the foundations of policy design for controlling epidemics, using a broad class of epidemic games on complex networks involving uncertainty in network information, temporal evolution and learning. Models will be proposed to capture the complexity of static and temporal interactions and patterns of information exchange, including the possibility of failed interventions and the potential for moral hazard. The project will also study specific policies posed by public agencies and network security providers for controlling the spread of epidemics and malware, and will develop resource constrained mechanisms to implement them in this framework.<br\/><br\/>This project will integrate approaches from Computer Science, Economics, Mathematics, and Epidemiology to give intellectual unity to the study and design of public health policies and has the potential for strong dissertation work in all these areas. Education and outreach is an important aspect of the project, and includes curriculum development at both the graduate and under-graduate levels. A multi-disciplinary workshop is also planned as part of the project.","title":"ICES: Large: Collaborative Research: The Role of Space, Time and Information in Controlling Epidemics","awardID":"1216000","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":[516909,516910],"PO":["565251"]},"193406":{"abstract":"The growth of the microprocessor industry has led to progress in diversified computing applications, such as health care, education, security, and communications. However, energy consumption has emerged as a barrier to the continued success of the American semiconductor industry. The inability to scale chip voltages at the historic rate has created a difficult design dilemma referred to as dark silicon: more transistors can fit on a chip, but a growing fraction will not be able to be used due to power dissipation limits. To scale performance in this landscape, fundamental increases in the computational efficiency of processors is required to get much more performance for much less energy. To scale computational efficiency, this work develops an architectural approach referred to as Composite Cores. The proposed architecture brings the notion of heterogeneity from between different cores in a processor to within a core. <br\/><br\/>Each composite core will consist of several energy efficient engines that have been customized to particular execution scenarios found in general-purpose applications. A dynamic management system will perform fine-grain mapping of application segments to the most efficient engine. Hardware mechanisms to ensure delay-free migration of program state provide smooth transitions from engine to engine. By dynamically partitioning an application across a set of customized engines, a large portion of the efficiency gains afforded by hardware accelerators on regular codes can be realized on general-purpose applications. The broader impact of this work is that green computing is recognized as one of the most important challenges in the semiconductor industry and more broadly in Computer Science. Composite cores enable general-purpose processors to reach new levels of energy efficiency while not sacrificing the ability to execute arbitrary code.","title":"SHF: Small: Scaling the Compute Efficiency of General-Purpose Processors","awardID":"1217917","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[518034,"535405"],"PO":["366560"]},"192317":{"abstract":"This award supports the partnership between the National Society of Hispanic Physicists (NSHP) and the Society for the Advancement of Chicanos and Native Americans in Science (SACNAS). The aim of the partnership is to increase the presence of physics, broadly defined, at the SACNAS National Conference. This annual conference is an opportunity for a talented group of predominantly Hispanic and Native-American students to interact with students and professionals in their disciplines, to present their research results, to learn about cutting-edge research, and to attend a variety of professional development sessions. This award will support the travel of a total of approximately forty students over three years to the conference. The award will also support the attendance of four professionals per year; these will be NSHP members who participate in the NSHP sessions and judge the physics and physics-related presentations. The award is supported by the Division of Physics, the Division of Materials Research, and the Division of Astronomical Sciences.","title":"SACNAS Minority Physicists Support Project; NSHP\/SACNAS National Conference Sept\/Oct 2012-2014 at Southeastern Universities Research Association","awardID":"1212283","effectiveDate":"2012-07-15","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"9134","name":"PHYSICS EDUC & INTERDISCIP RES"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0302","name":"Division of ASTRONOMICAL SCIENCES","abbr":"AST"},"pgm":{"id":"1219","name":"SPECIAL PROGRAMS IN ASTRONOMY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1710","name":"CONDENSED MATTER PHYSICS"}}],"PIcoPI":[515404,"538973","534986",515407],"PO":["561720"]},"193417":{"abstract":"The objective of this research is to create a new stochastic computing paradigm to reap the full benefits of emerging memristor devices for the next generation of energy-limited and high-performance applications. The computing paradigm takes advantage of the nondeterministic memristors for native stochastic computing, where the randomness required by stochastic computing will be intrinsic to the system without resorting to expensive stochastic number generation. The native stochastic computing system consists of memristor memory and stochastic computing elements that are seamlessly integrated. To evaluate the approach, test vehicles including a stochastic calculator and a clustering processor are created by the hybrid integration of memristor memory and stochastic computing circuits. The native stochastic computing based on memristors demonstrates key advantages in energy and speed over a competitive CMOS baseline, and is best positioned for compute-intensive, data-intensive and probabilistic applications.<br\/><br\/>The interdisciplinary nature of this research encourages a tight integration of device and computer hardware research areas and provides excellent training to students in cutting-edge nanoelectronics, integrated circuit design, and computer architecture. The graduates of this research program possess skill sets of critical need in both industry and academia. The research contributes to the undergraduate and graduate curriculum, in the forms of updated undergraduate courses and special topics offered in graduate courses. The research outcomes, along with two test vehicles, are disseminated through professional seminars, workshops, and as part of high school outreach programs. An emphasis on undergraduate and minority mentoring helps draw a broad and diverse participation over the course of this research project.","title":"SHF: Small: Native Stochastic Computing Based on Memristors","awardID":"1217972","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["434309","550682"],"PO":["562984"]},"190822":{"abstract":"Recent declines in the cost of DNA sequencing have enabled biologists to conduct experiments that produce very large DNA and protein sequence data sets. Understanding this data requires computational analyses to recognize known sequences and group new ones by similarity. As data sets grow, these analyses become a serious bottleneck to progress. Computer scientists have therefore tried to accelerate sequence analysis using hybrid computing architectures that combine multicore CPUs with accelerators, such as field-programmable gate arrays and graphics engines, whose performance equals that of tens or hundreds of CPU cores. To more effectively accelerate biosequence analysis tasks, new infrastructure is needed to facilitate both development of accelerated analytical tools and their deployment to biologists. <br\/><br\/>This project is a planning effort to create development and deployment infrastructure for accelerated biosequence analysis applications. The PIs are developing design criteria for a preferred hardware platform and set of software tools to speed the creation, validation, and deployment of biosequence accelerators. Key activities include qualifying hardware platforms, developing prototype software and firmware, and consulting developer and user communities for accelerated sequence analysis tools to guide the planning effort. In particular, the PIs are organizing a special track at a major accelerator design conference to solicit input on proposed infrastructure. <br\/><br\/>Developing the proposed infrastructure will stimulate creation of biosequence analysis accelerators with low cost, rapid deployment, and a large supporting developer and user community. More agile development will boost adoption of accelerators by biologists, empowering labs to analyze massive biosequence data sets and speeding discovery.","title":"CI-P: A flexible platform for accelerating biological sequence analysis","awardID":"1205498","effectiveDate":"2012-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[511555,511556,511557],"PO":["565255"]},"190833":{"abstract":"Our society has greater need than ever before for people to collaborate effectively, whether they be teams of employees, patients and their doctors, large virtual communities, neighborhoods or family groups. Collaboration is involved in many societal problems including energy use, law enforcement, disaster relief, and scientific research. Researchers in human-computer interaction and computer-supported cooperative work have an impressive record of developing technology to support interpersonal communication and group interaction in a range of problem areas such as medical team coordination, disruption of family schedules, multi-tasking and interruptions in the workplace, energy use in households, collaborative intelligence analysis, virtual organization, and collaborative learning. Despite such efforts, the deep structure of collaboration is not well understood. The goal of this project is to acquire instrumentation that will enable the PI and her colleagues to leverage advances in other disciplines such as neuroscience and engineering to advance our knowledge of how details of brain and behavior are related to the underlying meaning, processes, and outcomes of collaboration, that is, its deep structure.<br\/><br\/>Intellectual Merit<br\/>The requested research infrastructure will allow future projects to include a focus on the fine details of human behavior, including brain responses, facial expressions, body positions, gestures, and movements. The PI argues that in-depth analysis of behavior is necessary for understanding the mechanics of face-to-face interaction, for identifying those aspects of face-to-face interaction that are key to successful remote collaboration, for increasing the benefits of social media online, and for programming intelligent collaborative systems. Availability for interaction in the home environment, for example, might be indicated by a combination of posture and facial expression; detailed knowledge of these indicators could then help us design systems that deliver notifications to families at appropriate times. Similarly, remote experts collaborating around shared visualizations may benefit from camera systems that understand when partners have a shared understanding, as evidenced by their facial expressions and movements. Human-robot interaction might be refined by a fine-grained analysis of human-human interactions such as handoffs and greetings. And home health care and remote health delivery could be improved with better feedback about patient emotion and cognition during and after consultations. The infrastructure to be acquired with this funding will provide a platform for exploring ways to achieve these goals.<br\/><br\/>Broader Impact<br\/>The ability to understand the deep structures underlying collaboration has the potential to radically transform science and engineering in general, by furthering our ability to analyze contributors to effective team performance across many domains, and by laying the foundation for new collaborative interfaces that support interaction through gesture, facial expression, eye gaze and brain activity. More specifically, there is a potential for direct broader impact in the domains of health and education. In the domain of health, the new techniques will enhance ongoing work at the PI's institution on chronic illness management and home-health care, supporting better collaboration between parents and children with chronic illnesses, and patients and therapists through high fidelity patient observation. In education, computer-supported and collaborative learning will advance by computer tutors understanding student attention and knowledge sharing in groups. The instrumentation will also have local impact in the CMU HCI Institute, allowing faculty and student projects to include a focus on understanding the dynamics of collaboration and on the development of new tools to enhance people's ability to collaborate in diverse settings.","title":"II-EN: Laboratory for Research on Deep Structures of Collaboration","awardID":"1205539","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["561942","518043"],"PO":["565227"]},"193627":{"abstract":"A System-on-Chip (SoC) is the emerging computing platform that lies at the core of a variety of systems from computer servers in data centers to embedded systems and mobile devices. As semiconductor technology progresses, in order to deliver higher performance under tighter power constraints, SoCs increasingly combine various programmable cores, which provide precious flexibility through software, with many specialized accelerators, hardware modules optimized to execute only specific functions without dissipating too much power. The result is a heterogeneous system that is energy efficient but also very difficult to design. Indeed, the growth of SoC complexity has been outpacing progress in the computer-aided design (CAD) tools which are available to computer engineers. This design-productivity gap is a gloomy trend for the entire semiconductor industry. The PI will address this challenge by establishing Supervised Design-Space Exploration as the foundation for a new component-based design environment in which hardware-accelerator developers, software programmers and system architects can interact effectively while they each pursue their specific goals. In particular, the PI will develop CAD methodologies and tools that: (1) at the component-level, assist developers and programmers in the cost\/performance modeling and optimization of accelerators to enable architectural exploration and to increase their reusability across many potential SoC designs; and (2) at the system-level, assist architects in the automatic integration of accelerators and other heterogeneous components to obtain an optimal implementation of a given SoC.<br\/><br\/>This proposal will allow the PI to train graduate and undergraduate students in the design and programming of innovative SoC platforms for a variety of application domains from computer vision to security and networking. A core part of the proposal is the development of a new capstone course that is aimed at breaking the historical boundaries between software programming and hardware design which are still present across many electrical engineering and computer science curricula.","title":"SHF: Small: Synthesis-Driven Methods for Reuse, Integration, and Programming of Specialized Accelerators in Systems-on-Chip","awardID":"1219001","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[518555],"PO":["562984"]},"193407":{"abstract":"Processor designs are predicted to continue the many-core trend, often with heterogeneous computational components. While the raw compute power may increase roughly linearly with the core count, unfortunately, realizing the available computational power at the application level remains a challenge. The gap between CPU and memory speeds continues to widen, resulting in the memory system often being unable to feed the computational demands. Parallel application developers and users alike must be aware of the details of the underlying hardware and runtime details in order to extract the most benefit from the system, compromising performance portability. Programmers are also increasingly exploiting concurrency via the use of pre-parallelized libraries, resulting in poor composability. The proposed research aims to address these issues by improving the ease of use, scalability, and energy efficiency of multicore and multiprocessor systems, with impact on environments ranging from smart phone to servers.<br\/><br\/>As part of this research, a \"pay-as-you-use\" application-adaptive approach is used to develop a novel on-chip memory system. The key observation leveraged is that high-level modular application structure has predictable spatial locality. Rather than use a rigid parameter for the cache line granularity as in current designs, the underlying cache design adapts to match existing access granularity. Additionally, this research aims to develop runtime techniques that map application tasks to hardware compute resources by a) respecting the dependencies across tasks, b) matching task needs with the computational and memory capabilities of the resource, and c) determining the appropriate degree of parallelism at each level to minimize execution time and energy consumption. The new memory system design will improve on-chip storage utilization, eliminate energy wasted in transferring unused bytes of data, and reduce the pressure on off-chip memory bandwidth. The new runtime techniques will improve the ease of use and scalability of computational utilization by the increasingly innovative applications of the future.","title":"SHF: Small:Scalable Support for Concurrency in Multicore Systems","awardID":"1217920","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["556692"],"PO":["366560"]},"193429":{"abstract":"Energy impacts all aspects of society. Much of the U.S. electrical energy consumption occurs unnoticed due to the ubiquitous nature of electronics that improves and enhances our standard of living. For example, according to the US EPA Report to Congress, the electricity costs of data centers used by our cell phones and computers amounted to $4.5 billion dollars in 2006 -- the equivalent of 15 power plants. This proposal develops a transformative technology that reduces the power consumption of electronics by a factor of three. The core of the technology is based on a theory applied to the timing of logic and communication elements on an integrated circuit, where signals can travel up to the speed-of-light in the given medium. The primary result of this funding will be to develop circuit, software (computer-aided design), and design technology that will enable this low power technology to be moved from scientific laboratories into commercial products. The relative timing theory will be mapped onto the current commercial design and validation flow, using formal proofs of correctness for the translation. This is what will enable fast commercialization of the technology. A new ultra low power circuit family will be developed based on exhaustive behavioral investigations. This family can likewise be technology mapped to current fabrication libraries used by the foundries. Finally, a factor of three reduction in power as well as the ability to rapidly build commercial products will be demonstrated through the design and fabrication of a complex system-on-chip.<br\/><br\/>The primary impact of the work is the reduction of energy used by our ubiquitous electronics. The impact of energy usage has worldwide ramifications. Electronics have had an exponential growth in energy consumption over the last decade. The energy consumed by integrated circuits already pose a considerable impact on the economy and environment in terms of CO_2 emissions. The research performed by this grant will continue to improve U.S. technology leadership and competitiveness. The technology transfer to industry will also create hundreds of jobs and provide taxable revenue. This research has significant collaboration and support from industry, including direct interactions with Texas Instruments, Intel, Mentor Graphics, and ON Semiconductor. This work builds on the strong research foundation of the University of Utah. The University has a strong record of outreach to increase the engineering student population.","title":"SHF: Small: Low Power System-on-Chip Circuits and CAD","awardID":"1218012","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["354558"],"PO":["562984"]},"196707":{"abstract":"This is funding to support a doctoral consortium (workshop) of approximately 10 promising graduate students from the United States and abroad, along with 5 distinguished research faculty. The event will take place on Sunday, October 21, immediately preceding and in conjunction with the 14th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS 2012), to be held Monday-Wednesday, October 22-24, in Boulder, CO. The ASSETS conferences are the premier forum for presenting innovative research on the design and use of both mainstream and specialized assistive technologies. This includes the use of technology by and in support of: individuals with hearing, sight and other sensory impairments; individuals with motor impairments; individuals with memory, learning and cognitive impairments; individuals with multiple impairments; older adults; and professionals who work with these populations. Researchers and developers from around the world in both academia and industry will meet to exchange ideas and present their latest work. More information about the conference may be found at http:\/\/www.sigaccess.org\/assets12. <br\/><br\/>A key component of building this community is through its youth. The ASSETS 2012 doctoral consortium will provide an opportunity for graduate students from diverse backgrounds (computing, engineering, psychology, architecture, etc.) to come together and explore their research interests in an interdisciplinary workshop, under the guidance of the PI and a panel of other distinguished experts in the field, so that they can appreciate the broader spectrum of research and development approaches to assistive technologies and universal usability, and also experience the community in which they can pursue their endeavors. Student participants will make formal presentations of their work during the consortium, and will receive constructive feedback from the faculty panel. The feedback is designed to help students understand and articulate how their work is positioned relative to related research, whether their topics are adequately focused for thesis research projects, whether their methods are correctly chosen and applied, and whether their results are appropriately analyzed and presented. Thus, the consortium will help shape ongoing and future research projects aimed at assistive technologies and universal access, will promote scholarship and networking among new researchers in this emerging interdisciplinary area, and will also expose these promising young researchers to a larger community. In an effort to further integrate doctoral consortium participants into the conference itself, a poster session has been set aside in the technical program to allow all doctoral consortium participants to present their research to the full conference. In addition, one student from the doctoral consortium will be selected to deliver the closing plenary presentation. An evaluation of the consortium will be conducted and the results made available to the organizers of future such events. <br\/><br\/>Broader Impacts: The doctoral consortium will help expand the participation of young researchers pursuing graduate studies in this field, by providing them an opportunity to gain wider exposure in the community for their innovative work and to obtain feedback and guidance from senior members of the research community. It will further help foster a sense of community among these young researchers, by allowing them to create a social network both among themselves and with senior researchers at a critical stage in their professional development. Because the students and faculty constitute a diverse group across a variety of dimensions, including nationality\/cultural and scientific discipline, the students' horizons are broadened to the future benefit of the field. The organizers will take special steps to promote participation from institutions with relatively large numbers of students from under-represented groups; to further increase diversity, participation will be limited to at most one male and one female student from the same institution.","title":"Workshop: Doctoral Consortium for ASSETS 2012","awardID":"1240198","effectiveDate":"2012-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["557943"],"PO":["565227"]},"193319":{"abstract":"Microprocessors form the heart of most electronic systems that pervade our daily life and they are responsible for the bulk of the power consumption of those electronics. In this research, the PIs propose a promising method to significantly reduce that power consumption, using an approach called Razor. One of the issues with modern chips manufactured using silicon semi-conductor processes is that the performance of the electronic components (such as transistors, gate, etc) on these chips has become very unpredictable in terms of their computational speed. This means some chips will run fast while others will run slow. Currently, we address this performance uncertainty by operating all chips at a slow speed that is considered safe for all possible chips. However, this is hugely wasteful for most chips which can operate at a much faster performance. We harness the performance margin of these chips by lowering their operating voltage, such that they still meet the same safe performance constraint, but operate significantly more energy efficiently. It has been demonstrated that this approach can save as much as 50% of the power consumption of an electronic circuit. The proposal suggests new ways for the chip to automatically determine its lowest possible operating voltage while still meeting the needed performance. It does so by progressively lowering the supply voltage till the chip start to fail. These failures are then detected and corrected and tell the voltage control that it has reached the limit of voltage reduction. In this proposal, the PIs outline a new method to perform this error detection and correction in a more efficient manner. <br\/><br\/>The proposed methods, if successful and transferred to industry, could significantly reduce energy consumption of processors and other electronic circuits. The significantly larger energy efficiency of the proposed techniques could bring about a number societal benefits. These technique will enable more effective usage of energy for electronic circuits. Power consumption of electronic circuits (computers, handhelds, servers farms etc.) is currently the fastest growing component of the nation?s overall energy demand. Hence, reducing power consumption of electronics is a critical concern for energy policy and could reduce our dependence on oil and other non-renewable energy sources. In addition, the proposed method will address a critical need to design circuits that are immune to the increasing uncertainty in chips as we scale the silicon technology further. This could play an important role in extending Moore's law of scaling and have significant benefits for the semiconductor industry and the nation?s economy. As part of this research, the PIs will expand our recent practices of engaging with high school students through lab demonstrations and tours to prepare these students for low power computing.","title":"SHF: Small: Minimally Invasive Error Detection\/Correction for Runtime Margin Elimination","awardID":"1217519","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":[517834,517835],"PO":["562984"]},"193209":{"abstract":"Due to the severely degraded short-channel behavior of MOSFETs, Intel and TSMC have announced their switch to multi-gate FETs at the upcoming technology nodes. Hardware experiments with multi-gate devices and larger circuits entail very high cost and turnaround time. Thus, efficient predictive 3D-Technology CAD (3D-TCAD) based process\/device characterization methods for such devices\/circuits are urgently needed. A lack of such methods currently poses a significant impediment to rapid progress in this area. Though 3D-TCAD based exploration is essential for accurate predictive modeling, it is beset with major challenges which makes it necessary to develop a seamless set of methodologies\/algorithms integrated with 3D-TCAD eco-systems for resolving process, layout, and device level issues quickly. The main aim of the proposed work is to develop efficient and accurate methodologies for unifying the layout, 2D\/3D device simulation, and process simulation worlds, thereby, for the first time, expanding the horizon of predictive modeling for multi-gate devices beyond the many-device TCAD barrier, which is a major showstopper at lower technology nodes. The project aims to develop a set of versatile methodologies for synthesizing contiguous 2D\/3D device-simulation-ready structures corresponding to given layouts, without the need for repetitive and expensive 3D process simulations on each layout. These methodologies are expected to yield several orders of magnitude speedup in TCAD structure generation for large layouts, with run-time reduction from days\/weeks to a few hours per design and decreased memory footprints. The project will also develop fast cache-extrapolate-update techniques to alleviate the problem of obtaining convergence with iterative linear solvers for both mixed-mode and contiguous 3D device simulation.<br\/><br\/>The methodologies developed in this research will break the many-device TCAD barrier and, by unifying layout with process\/device simulation, make accurate and efficient predictive 3D-TCAD possible. The methodologies\/tools that are developed will be disseminated through the web, conferences and journals. The material will be included in a course on Design with Nanotechnologies that the PI teaches at Princeton University. Princeton has a tradition of undergraduate independent research. Many senior students are expected to do their research project on this topic. Female and minority students will be attracted to this research through Princeton's Fellowship Program. Further outreach activities are also planned for high-school students.","title":"SHF: Small: Efficient and Accurate Methodologies for Unifying the Layout, Device Simulation, and Process Simulation Worlds","awardID":"1217076","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["550002"],"PO":["562984"]},"193606":{"abstract":"Emerging memory technologies such as Magnetoresistive random-access memory (MRAM), Phase-change memory (PCRAM), and Resistive random-access memory (RRAM) are being explored as potential alternatives for future computing systems. However, traditional memory design methodologies are not sufficient to address probabilistic behaviors, which are caused by process variations and the intrinsic randomness in the physical mechanisms (e.g., thermal fluctuations) of these emerging technologies. <br\/><br\/>The objective of this research is to develop a design methodology called STatistical Emerging Memory Simulator (STEMS) for circuit\/architecture designs with such emerging memory technologies. The intellectual merits include the following: (1) developing a generic statistical characterization formalism to link the emerging memory cell design specifications with design variables, process variations and environmental fluctuations, (2) deriving a variation-aware compact memory cell model to fulfill the demands of the statistical design optimizations at cell and array levels, and (3) investigating a statistical memory design methodology to explore the tradeoffs among memory structure, implementation cost, and design specifications for various system requirements. The proposed research will fundamentally change the design methodologies for future memory technologies, initiate an innovative direction in memory designs, and optimize and balance the new design characteristics of emerging memories under architectural considerations, inspiring the transition of design philosophy from the deterministic era to the probabilistic era. The proposed techniques provide a complementary perspective to the existing probabilistic system and architectural research while emphasizing the yield and probabilistic properties of memory designs. <br\/><br\/>This project will facilitate further advances and wider adoption of the emerging memory technologies by the semiconductor industry. Innovations in design methods and memory modeling will have an impact on the way in which semiconductor memory chips are designed and fabricated. Undergraduate and graduate students involved in this research will be trained for the next-generation semiconductor industry workforce.","title":"SHF: Small: Collaborative Research: STEMS: STatistic Emerging Memory Simulator","awardID":"1218867","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["556667",518504,"528208"],"PO":["366560"]},"193529":{"abstract":"Dennard's scaling, which governs the growth of power, voltage and frequency of CMOS integrated chips, has been as instrumental as Moore's law in enabling the exponential growth of the number of active transistors on a chip. Unfortunately, the recent slowing down of Dennard's scaling of the supply voltage in future multicores may result in dark silicon where an increasing number of cores must be kept powered down due to lack of power. One alternative is to improve power efficiency by customizing the cores for specific functionalities. While the dark silicon option obviously degrades performance, the customization option puts multicores on a potentially arduous path of increased effort for hardware design, verification, and test, and degraded programmability. The challenge that architects face is to design around the reality of the slowing of Dennard's scaling while avoiding either of the two harsh consequences (dark silicon, or the increased cost\/effort of customized core design).<br\/><br\/>This project addresses the above challenge by pursuing an alternative, gentle (i.e., non-arduous) path for multicore scaling, while remaining within the power envelope imposed by the slowing of Dennard's scaling. The design employs successive frequency unscaling, where all the cores are kept powered and run at successively slower clocks every generation to stay within the power budget. An analytical model (developed as part of this project) for the performance of systems with and without successive frequency unscaling makes the surprising prediction that despite considerably slower clocks in later generations (e.g., sub-GHz), successive frequency unscaling would exceed the dark silicon performance limit. The key research goal of this project is to validate the predictions of the model with real applications and detailed system simulation. Validating an alternative, gentle path for multicore scaling has the potential to offer significant benefits for the microprocessor and computer industry. Beyond the research impacts, the project's integration of education components in both graduate and undergraduate curricula helps expand its educational impact.","title":"CCF: SHF Small: Coping with the Slowing of Dennard's Scaling","awardID":"1218473","effectiveDate":"2012-07-15","expirationDate":"2014-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[518316,"550778"],"PO":["366560"]},"192936":{"abstract":"This interdisciplinary project will leverage high-performance computing to assess key challenges of climate change vulnerabilities, impacts, and adaptations by applying an economic modeling and analysis framework using biophysical and statistical models. The overall goal is an improved understanding of the interactions of climate and socio-economic changes on: 1) the supply and demand of agricultural commodities, 2) local land-use and land-cover, and 3) regional and global food sustainability. A number of research efforts and technologies are anticipated, including a new framework for massively parallel simulations of impact models, a methodology and software suite for scaling the resulting measures to arbitrary spatial scales, a set of validation experiments, and a set of scenario based adaptation experiments to evaluate socio-technical and environmental pathways to sustainable food and climate futures. The project will use a new high-performance information technology system (Framework to Advance Climate, Economic, and Impact Investigations with Information Technology, or FACE-IT) that is designed to enable, record, share, and distribute data products and software between different communities. The project will also develop new tools for delivering information directly to decision-makers operating at various scales from international policy-makers to local watershed managers and agricultural development authorities.<br\/><br\/>The primary way in which humans interact with their physical environment is through the possession and management of land. Accommodating increasing demands for agricultural commodities, forest products, mining resources, and urban sprawl with limited nutrient reserves, water resources, soil depletion, and changing climates is a constant struggle. The primary drivers of changes in land use continue to be economic, social, and technological and the primary decision makers continue to be individual farmers, corporations, and developers operating in a highly complex socio-technical, political, and environmental landscape. In the coming decades, policymakers and stakeholders at every scale and level of government and industry will be required to make multi-billion dollar decisions around agricultural production and food supply. Models developed in this project will be applied to various regional, national, and global sustainability and climate vulnerabilities, impacts, and adaptations assessments. The information products and interactive web applications on the impacts of climate change, growing populations, and changing diets and demographics on global food sustainability will better enable science-based decisions related to these critical sustainability issues.<br\/><br\/>The project will also make information about food sustainability available to the general public, and will engage high school students and teachers in sustainability science activities. <br\/><br\/>This project is supported under the NSF Science, Engineering and Education for Sustainability Fellows (SEES Fellows) program, with the goal of helping to enable discoveries needed to inform actions that lead to environmental, energy and societal sustainability while creating the necessary workforce to address these challenges. With SEES Fellows support, this project will enable a promising early career researcher to establish themselves in an independent research career related to sustainability.","title":"SEES Fellows: Socio-technical and Environmental Pathways to Sustainable Food and Climate Futures","awardID":"1215910","effectiveDate":"2012-07-15","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8055","name":"SEES Fellows"}}],"PIcoPI":["554548"],"PO":["535244"]},"193629":{"abstract":"Proteins are the main building blocks and functional molecules of the cell, yet the biological function of most proteins encoded in genomes are not well characterized. Recent advances in structural genomics have generated a wealth of data regarding the three-dimensional structure of individual proteins. At the same time, proteins rarely act alone in the cell; rather, they form complex networks of protein-protein interactions and other types of biomolecular interactions from which intricate yet robust cellular behavior emerges. Identifying amino acid sites that are involved in these biomolecular interactions is an essential first step towards understanding the molecular basis of protein function. Despite their biological significance, these amino acid sites mediating protein-protein interactions are difficult to elucidate experimentally. Computational algorithms are needed to accurately predict these sites.<br\/><br\/>Intellectual Merit. The objective of this proposal is to develop novel computational algorithms that integrate a wide spectrum of publicly available protein sequence, structure, and network data to accurately predict amino acid sites mediating protein interaction. In particular, two new algorithms will be developed to accurately and efficiently identify amino acid residues on the surface of proteins that evolve more slowly than expected, as well as short sequence motifs that are enriched among non-homologous proteins with a common interacting partner. These amino acid residues and sequence motifs are strong candidates for mediating protein interactions. An innovative and unifying feature of this proposal is that both algorithms will take into account the powerful spatial constraints on these amino acid sites imposed by the three-dimensional structure of proteins.<br\/><br\/>The proposed work is significant in that it addresses a fundamental question in molecular systems biology: identifying amino acid residues and sequence motifs that mediate biological networks. The execution of this proposal will provide a set of algorithms, tools, and datasets that maximize the impact of high-throughput approaches on systems and network biology research, which can be used by researchers to address a wide variety of questions ranging from biomedical to evolutionary. Finally, this proposal develops a novel computational paradigm that integrates a wide spectrum of biological data (protein sequences, protein-protein interaction network graphs, and protein three-dimensional structures) to predict amino acid sites mediating protein interaction with high accuracy. These novel algorithms for fundamental problems in computational biology contribute directly to the core mission of the NSF CISE\/CCF program.<br\/><br\/>Broader Impacts. The proposed research will further strengthen the interdisciplinary ties between the PI in the Boston University Bioinformatics Program and the collaborating experimentalists in the Boston University School of Medicine. These ties provide invaluable opportunities for cross-disciplinary research experiences for both graduate and undergraduate trainees.<br\/><br\/>The educational plan aims to bridge traditional teaching and mentoring methods between biology, chemistry, and computer science at the K-12, undergraduate, and graduate levels, and to bring the latest research findings and methods to the classroom. He will continue to play a key role in the curriculum development and improvement of the Bioinformatics Program at Boston University.","title":"AF: Small: Algorithms for Accurate Prediction of Protein Interaction Sites by Integrating Sequence, Structure, and Network Data","awardID":"1219007","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["557236"],"PO":["565223"]},"193608":{"abstract":"Nowadays, an increasing number of objects can be represented by their wireless electronic identifiers. For examples, people can be recognized by their cellular phones' or laptops' MAC addresses and products can be identified by their RFID numbers. Localizing objects with electronic identifiers is more and more important as our society is becoming increasingly \"digitalized\". However, traditional wireless localization techniques cannot meet the rapidly mounting requirements of accurate and cost-effective localization. Some of them need expensive hardware to achieve high accuracy, which is impractical for massive deployments, while others such as WiFi RSSI based localization are inaccurate and not robust to environmental noise. <br\/><br\/>This project designs a novel localization methodology called EVLoc. In EVLoc, visual signals (V signals) are used to improve the accuracy of electronic localization, as the accuracy of visual localization is around 0.1-0.5 meter. This technique fully leverages V signals' high accuracy and the pervasiveness of electronic signals (E signals). The project conducts three main research tasks: (1) perform object localization given complete and distinct E and V signals, (2) perform object localization in practical settings when the E and V signals are not complete and distinct, and (3) implement the E-V approach to validate its accuracy and efficacy. This pioneering research develops a transformative approach that integrates E and V signals for accurate localization. The approach can be applied to many emerging applications such as epidemic control and tracking of elderly people, children, and those exhibiting at-risk behaviors for healthcare purposes.","title":"NeTS: Small: Integrating Electronic and Visual Signals for Accurate Localization","awardID":"1218876","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["523431",518511],"PO":["557315"]},"192927":{"abstract":"This interdisciplinary project will explore the design of a new generation of policy incentives for sustainable modernization and expansion of U.S. electric power infrastructure systems in order to ensure a climate resilient infrastructure that can meet society's projected future energy demands. The research will contribute to: 1) quantifying risks posed to power systems by climate hazard under different climate scenarios and policy responses, 2) developing electric power infrastructure reliability models, both economic and engineering, for the Gulf Coast and East Coast regions of the United States, 3) assessing macroeconomic consequences of climate extremes on power systems infrastructure under different climate scenarios, and 4) devising policy incentives for sustainably expanding electric generation and transmission capacity to ensure climate resilience.<br\/><br\/> Ensuring the sustainability and resilience of the U.S. electric power infrastructure is one of the grand challenges facing the nation. Due to the complex interdependencies that exist between energy infrastructure and other critical lifelines, disruption in the electric sector can adversely affect national security, digital economy, public health, and the environment, and have debilitating socio-economic impacts on society. Energy infrastructure is in urgent need of modernization to meet projected future demands securely and safely. While this modernization should be done in a sustainable manner that ensures resilience of the power systems in the face of changing climate, current energy system planning does not fully account for and integrate the multi-disciplinary aspects of the problem and fails to provide incentive mechanisms capable of successfully fostering the needed transition. This study is intended to provide a framework for the required planning effort.<br\/><br\/>The project will involve collaborations among government, academic and industry organizations, both domestically and internationally, and will include development of a university course on energy infrastructure sustainability and outreach to high school students.<br\/><br\/>This project is supported under the NSF Science, Engineering and Education for Sustainability Fellows (SEES Fellows) program, with the goal of helping to enable discoveries needed to inform actions that lead to environmental, energy and societal sustainability while creating the necessary workforce to address these challenges. With SEES Fellows support, this project will enable a promising early career researcher to establish themselves in an independent research career related to sustainability.","title":"SEES: Sustainable Energy Infrastructure Planning","awardID":"1215872","effectiveDate":"2012-07-15","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"8055","name":"SEES Fellows"}}],"PIcoPI":[516842],"PO":["565364"]},"192929":{"abstract":"For millennia thinkers have struggled with a seemingly simple question: how does one fairly divide goods among several people? The 20th century has seen a shift towards mathematically rigorous approaches to fairness; economists, mathematicians, and political scientists have all contributed to the large body of literature on fair division. In contrast, to date there is little work in algorithmic economics on fair division, relative to this field's weight in microeconomic theory. In particular, computational work on the fair allocation of divisible goods (such as land, time, or computer memory) is rather sparse. <br\/><br\/>The theme of this proposal is that computational thinking can transform research on the fair allocation of divisible goods, while novel research on the fair allocation of divisible goods can find compelling applications in computer science. This theme is explored in two domains: (i) in cake cutting --- a metaphor for the allocation of a heterogeneous divisible good --- the proposed research focuses on issues such as complexity, representation, and optimization; (ii) in cloud computing, where one needs to allocate multiple homogeneous divisible goods (e.g., CPU, RAM), the proposed research aims to design and validate algorithms that exhibit superior performance in practice. <br\/><br\/>This proposal focuses the attention of the algorithmic economics community on fair division via four main activities: a book, a summer school, magazine articles, and tutorials. In turn, the increased computational attention can lead to a surge of deployed applications of fair division methods.","title":"ICES: Small: Computational Fair Division: From Cake Cutting to Cloud Computing","awardID":"1215883","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"8052","name":"Inter Com Sci Econ Soc S (ICE)"}}],"PIcoPI":["562905"],"PO":["565251"]},"190818":{"abstract":"Unmanned aerial vehicles (UAVs) are often used for surveillance and reconnaissance missions. They typically fly high above the ground to avoid obstacles. As such, they execute such missions passively. This project adds dexterous arms to a UAV. This would yield paradigm-shifting missions; the arms could then be used for near-Earth environment tasks like infrastructure repair, agricultural crop handling and border inspection. The critical gap preventing the realization of such UAVs is the lack of data on reaction forces and torques. When the arms on such vehicles (dubbed Mobile Manipulating UAVs or MM-UAV) interact with objects like building edifices, trees and common objects on the ground, these reactions can upset vehicle stability. The new infrastructure built by this project fills this gap. Robotic arms\/hands is retrofitted and on existing 6-DOF gantry that is configured to mimic the UAV?s lateral and longitudinal dynamics. The net effect is a hardware-in-the-loop system that enables capture and study of reaction forces and torques. <br\/><br\/>Broader impacts resulting from such infrastructure include: data to analytically design MM-UAV to yield a new class of unmanned aircraft suitable for near-Earth missions; international collaborations that spinout results to industrial partners; hands-on lab components to complement robotics courses; and Girl Scouts outreach programs to inspire and motivate young girls to science and engineering. Dissemination includes the open sharing of data and publishing in the literature. The outcome of the project is a new class of UAV for field and service robotics with a wide range of missions.","title":"CRI II-NEW: MM-SISTR - Infrastructure for Enabling Mobile-Manipulation Unmanned Aerial Vehicle (MM-UAV) Research and Design","awardID":"1205490","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["403839","551322",511546,"400052"],"PO":["564316"]},"199073":{"abstract":"This research investigates a new approach to protecting the reliability of digital communication and digital storage systems. This approach takes advantage of recent work (by the research team and others) that formulates the \"encoding\" and \"decoding\" of data in terms of a novel graphical representation; this formulation has several advantages over existing techniques for insuring data integrity, including better performance at very low power and the absence of an 'error floor', i.e., the ability to consistently (and significantly) lower the decoded error probability with incremental expenditures of power. The ultimate goal of the research is more reliable delivery of digital data, text, computer files, speech and audio signals, video, etc. - using devices that require less power (and thus have longer battery life) and shorter processing delay.<br\/><br\/>More specifically, the research investigates the use of spatially coupled sparse codes - channel (error control) codes with a sparse parity check representation formed by coupling together a chain of small \"protographs\". This approach, which was pioneered by the research team in the context of terminated low-density parity check convolutional codes, has recently been shown to possess a unique combination of properties - iterative decoding performance that approaches channel capacity and minimum distance that grows linearly with block length - as the code size gets large. The research follows four tracks: (1) the design and analysis of low latency\/memory decoding strategies; (2) decoded error probability performance guarantees; (3) the development and analysis of spatially coupled sparse codes with algebraic structure; and (4) the application of spatial coupling outside the immediate domain of channel coding, including cooperative diversity, compressed sensing, and multi-terminal source\/channel coding.","title":"CIF: Medium: Collaborative Research: Spatially Coupled Sparse Codes on Graphs - Theory, Practice, and Extensions","awardID":"1252788","effectiveDate":"2012-07-01","expirationDate":"2015-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["547544"],"PO":["564924"]},"197040":{"abstract":"Most digital systems operate on a positional representation of data, such as binary radix. This project advocates an alternative representation: random bit streams where the signal value is encoded by the probability of obtaining a one versus a zero. This representation is much less compact than binary radix. However, complex operations can be performed with very simple logic. In particular, arithmetic functions, consisting of operations like addition and multiplication can be implemented very efficiently. Complex functions, such as exponentials and trigonometric functions, can be computed through polynomial approximations. Because a stochastic representation is uniform, with all bits weighted equally, it is highly tolerant of soft errors (i.e., bit flips). Computation on stochastic bit streams offers tunable precision: as the length of the stochastic bit stream increases, the precision of the value represented by it also increases. Thus, without hardware redesign, one has the flexibility to tradeoff precision and computation time. In contrast, with a conventional binary-radix implementation, when a higher precision is required, the underlying hardware has to be redesigned. This project will develop and apply a unified framework for synthesizing such computation from the circuit level to the architectural and system level. Techniques for transforming probability values with combinational logic will be developed. <br\/><br\/>As part of this grant, a new course on \"Circuits, Computation, and Biology\" offered jointly through the ECE Department and the new Biomedical Informatics and Computational Biology Program at the University of Minnesota. The researchers will try to incorporate stochastic ideas in computer design curriculum, The PIs will focus on building upon current research efforts that include female and underrepresented students.","title":"EAGER: Digital Yet Deliberately Random -- Synthesizing Logical Computation on Stochastic Bit Streams","awardID":"1241987","effectiveDate":"2012-07-01","expirationDate":"2014-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":[528634,528635,528636,528637],"PO":["562984"]},"189593":{"abstract":"The dramatic improvements in electronic devices in the last 40 years have substantially drawn on Moore's law which predicts a steady increase in transistor density in semiconductor chips, with implied improvements in cost and power. But Moore's law is now slowing, while cost improvements now rely on very large production volumes to justify billion-dollar in investments in manufacturing infrastructure. Among alternative chip design methodologies, three-dimensional chip design currently shows significant momentum and promise for commercial products. Three-dimensional chips can be produced by vertical stacking of conventional two-dimensional chips and connecting them with through-silicon vias. Despite a number of unsolved technical problems, such three-dimensional chips reduce the form-factor and interconnect, while improving yield. This research explores heterogeneous 3D chip design seeking the flexibility to combine different types of two-dimensional chips (different types of memories, fast logic, low-power logic, FPGAs, analog circuits, micro- and nano-electromechanical components, etc.), which cannot be reliably manufactured on a single conventional die. This research will reduce cost of 3D designs and make them more practical by exploiting heterogeneity in all its aspects: (1) from dies fabricated in different process nodes to interconnects realized with TSVs, silicon interposers and wire bonds; (2) from system performance (macro blocks with different frequency requirements) to system activity (blocks that are standby-dominant vs. actively-switching); and (3) at the physical design level, from criticality (performance slack) to connectivity (bisection bandwidths or netcuts) across the physical hierarchy from block-level down to gate-level. Our research scope spans three main axes -- 3D IC implementation architectures, technology and design aspects of heterogeneity, and algorithmic optimizations. <br\/><br\/>Being able to combine heterogeneous semiconductor dies in a working electronic system promises significant competitive advantage in price, performance and functionality. Such ability facilitates new types of electronic products, with clear benefits to design and manufacturing companies, as well as to the society. An example application here is a cellular phone, which integrated several micro-processors, analog circuit components and antennas, signal-processing units, accelerometers etc. Being able to revise one of these blocks without altering the supply chain for other blocks reduces the risk and cost of improvements to successful designs. Students will be trained to contribute to the design and revision of such designs, and to perform further research on alternative chip design techniques.","title":"SHF: Medium: Collaborative Research: 3D Integration of Heterogeneous Dies","awardID":"1162085","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["522496"],"PO":["562984"]},"187294":{"abstract":"Most of the today's computers are parallel machines. For example, multicore processors<br\/>on personal computers and cell phones, graphics processors, cloud<br\/>computers, and clusters all have more than one processing unit. <br\/>Many modern applications are data intensive; examples include digital signal processing, audio and video<br\/>processing, networking, scientific and biological computations.<br\/>Streaming is an increasingly popular paradigm for applications that process <br\/>large amounts of data in parallel. A streaming concurrency platform is responsible for<br\/>correctly and efficiently executing streaming applications on a given parallel machine.<br\/><br\/>The goal of this research is to design streaming concurrency platforms<br\/>that provide guarantees of forward progress and efficiency. This<br\/>research will fundamentally advance the technology by addressing <br\/>the following important questions: <br\/>(1) How to guarantee that applications will make forward progress (not<br\/>deadlock)? <br\/>(2) How to guarantee that the streaming applications will run efficiently<br\/>on modern parallel machines with deep and complex memory hierarchies?<br\/>and<br\/>(3) How to support more general and expressive streaming models while<br\/>still providing correctness and performance guarantees? <br\/><br\/>In modern machines cache locality can have a significant impact on<br\/>performance. This research has the potential to make fundamental<br\/>contributions to both design and analysis techniques for steaming<br\/>schedulers that guarantee good cache performance to streaming applications.<br\/>This work will enable programmers to express a larger class of applications more<br\/>easily in the streaming model. While this research project is a primarily theoretical undertaking<br\/>aimed towards designing algorithms and proving asymptotic bounds on<br\/>their performance, the overall goal is to enable practical and<br\/>efficient concurrency platforms that can run high-performance,<br\/>high-throughput streaming computations on real parallel machines.<br\/>Therefore, one of the primary objectives will be to design low overhead<br\/>and simple algorithms that can be implemented in production-level<br\/>streaming concurrency platforms.","title":"CAREER: Provably Good Concurrency Platforms for Streaming Applications","awardID":"1150036","effectiveDate":"2012-07-01","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["556689"],"PO":["565251"]},"189065":{"abstract":"Written language data play a critical role in both linguistic research and in the development of modern software tools for language processing. Traditionally, data of this kind have been expensive to produce, involving either linguistic fieldwork, digitization of printed materials, or cooperation with commercial publishers. Over the last fifteen years, however, the vast quantities of text available on the web have made it possible to assemble \"disposable\" language databases quickly and easily for many languages. The relative ease with which indigenous and minority language groups can publish material online, through blogs, social media sites, and online newspapers, has brought the benefits of modern language processing to a much wider range of languages than was ever thought possible.<br\/><br\/>This project involves the collection and dissemination of language data (in the form of word frequency lists, sample texts, etc.) for over 1200 languages. The data are gathered by a web crawler that uses statistical methods to identify the language of documents automatically. The data will be made freely available in convenient formats to linguists, to support research on endangered languages; to software developers, to help in producing computational tools that make it easier for endangered language communities to use their languages online; and to local communities, to assist in grassroots language revitalization projects.<br\/><br\/>One of the scientific challenges will be the development of language identification techniques that scale up to thousands of languages, and that work effectively with limited training data.<br\/><br\/>Finally, while the primary focus of the project is the production of useful linguistic data, it will incidentally provide the best answer to date to the fundamental question \"How many languages are represented on the web?\" which has been the subject of research by academics and public-benefit organizations like UNESCO since the early days of the web. The project involves collaboration with local language groups to develop tools such as spell checkers and grammar checkers. The research involves collaboration with community members, with capacity building.<br\/><br\/>The Division of Information & Intelligent Systems of the Directorate for Computer & Information Science & Engineering is [co-]funding this award as part of its commitment to support the development of computational tools and methods for the documentation of endangered languages.","title":"Web corpora and computational resources for endangered languages","awardID":"1159174","effectiveDate":"2012-07-01","expirationDate":"2014-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":[506872],"PO":["564750"]},"193092":{"abstract":"Elliptical single-domain nanomagnets with two stable magnetization orientations are far more energy-efficient as logic switches than traditional transistors. However, the method employed to switch them must be energy-efficient as well in order to build ultra-low-power nanomagnetic logic and memory paradigms. It has been theoretically shown that using multiferroic (magnetostrictive-piezoelectric) nanomagnets, whose magnetization can be flipped with strain generated by a tiny electrostatic potential applied across the piezoelectric layer, results in a remarkably energy-efficient switching scheme. It reduces the dissipation in the switching\/clocking circuit by four orders of magnitude at a clock rate of ~ 1 GHz compared to other nanomagnet switching schemes. While this is attractive, an unattractive trait of nanomagnetic logic chains is that in order to build a pipelined architecture and hence retain an acceptable bit transfer rate, each magnet must be clocked individually. This necessitates contacting each magnetic with a contact line, which imposes a Herculean lithographic burden. The PIs propose to overcome this problem completely by designing and fabricating a novel acoustic scheme for clocking that allows pipelining and at the same time does not require contacts to every magnet, thereby completely lifting the lithography burden. A surface acoustic wave (SAW) launched in the substrate, and slowed down with periodically placed masses, generates strain in an array of magnets in the correct sequence for bit transfer, as long as the spacing between the magnets is one quarter of the SAW?s wavelength. With this scheme, the energy dissipation in a gate operation at room temperature can be very low. This project will: (i) design combinational and sequential logic based on acoustically clocked magnetostrictive nanomagnets acting as logic switches, as well as perform extensive simulations using the stochastic Landau-Lifshitz-Gilbert (LLG) equation to understand and optimize reliability and fault tolerance in the presence of thermal noise; (ii) experimentally demonstrate pipelined unidirectional logic flow, and (iii) develop comprehensive coupled models for the switching dynamics of nanomagnets stressed by surface acoustic wave (SAW). <br\/><br\/>This research will result in a novel computational paradigm whose astonishing energy efficiency combined with very little lithographic burden could enable the production of cheap, high yield and extremely low power processors. Such processors would consume so little energy that they can be run off the energy harvested from the environment. This could open up hitherto unimaginable applications such as medically implanted processors powered only by the motion of the patient's body, or processors that monitor the structural health of bridges and buildings while being powered by vibrations caused by wind or traffic. Integration of this research with education and mentoring will result in traditional training activities such as guiding two doctoral students who will gain multidisciplinary skills in advanced nanofabrication, nanocharacterization and modeling, as well as undergraduate projects on SAW devices and nanofabrication of magnetostrictive nanomagnets that will be mentored by the PI and co-PI?s doctoral students. Other innovative outreach programs will include holding workshops on nanomagnets and computing for high school students through the Math Science Innovation Center (MSIC) and incorporating diversity into outreach programs by hosting under-represented K-12 students in summer with the help of VCUs Richmond Area Program for Minorities in Engineering (RAPME) program. These students will perform nanolithography under supervision and study the magnetic structures they create with MFM.","title":"SHF: Small: Pipelined and wireless ultra-low power straintronics: An acoustically clocked combinational and sequential nanomagnetic architecture","awardID":"1216614","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["541220","541221"],"PO":["562984"]},"187251":{"abstract":"Protein-protein interactions (PPIs) play fundamental roles in all biological processes including the maintenance of cellular integrity, metabolism, transcription\/translation, and cell-cell communication. High-throughput experimental approaches have been developed to systematically identify PPIs. However, these methods cannot produce atomic 3D models of PPIs, which hinder studying PPI molecular mechanisms at atomic level and understanding cellular processes at molecular level. Atomic structures of PPIs are also important for rational drug design. High-resolution methods for PPI 3D structure determination such as X-ray or NMR are time-consuming and sometimes technically challenging, so computational method is urgently needed for PPI structure modeling. <br\/><br\/>Intellectual Merit: This proposal studies exact\/approximate algorithms for 3D structure modeling of PPIs, with the ultimate goal to enrich large-scale PPI networks with high-resolution 3D structure models. The proposal will study 1) simultaneous threading of all sequences of a target PPI to a complex template; 2) protein complex side-chain packing with a very large rotamer library and more realistic energy functions; and 3) simultaneous interface threading and side-chain packing to align distantly-related protein complexes. This proposal will apply several elegant and powerful techniques such as graph minor theory, probabilistic graphical models, dual relaxation and decomposition, which are not well-known in the field, to understanding the mathematical structure of the problem with more realistic and challenging settings and designing efficient algorithms. <br\/><br\/>The expected outcome includes theoretical analysis of protein interfaces and complexes by graph theory, efficient algorithms for PPI structure modeling and publicly available software and servers. The resulting software can be used to verify experimental PPIs and even predict novel PPIs missed by experimental approaches. The software will benefit a broad range of biological and biomedical applications, such as gene functional annotation, better understanding of disease processes, design of novel diagnostics and drugs, personalized medicine and even bio-energy development. The resulting algorithms and software will be communicated to the broader community and also be further developed and disseminated to industry by two companies.<br\/><br\/>Broader Impact: This work is expected to enrich and disseminate knowledge on systems biology and structure bioinformatics, machine learning, graph theory and optimization and further enrich the pedagogical literature. Contributions from this work to computer science are: understanding of protein graphs using graph minor theory and graph transformations and solving several computationally challenging problems by combining techniques from graph theory and continuous optimization. This research work will train minority students from two HBCU schools, future K-12 science teachers and students attending the first online bioinformatics program in Illinois. Students will receive training at the intersection of biology and computer science. The proposed course materials and book chapters will be freely available to the public.","title":"CAREER: Exact and Approximate Algorithms for 3D Structure Modeling of Protein-Protein Interactions","awardID":"1149811","effectiveDate":"2012-07-01","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0302","name":"Division of ASTRONOMICAL SCIENCES","abbr":"AST"},"pgm":{"id":"1045","name":"CAREER: FACULTY EARLY CAR DEV"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["538687"],"PO":["565223"]},"189561":{"abstract":"Software is remarkably important to modern life. The correct and secure behavior of software that controls nearly all major machines and communications systems, from aircraft and cars to medical records and financial transactions, is mission-critical and often can be a matter of life and death. The current industry-standard method for assessing correctness of software, known as \"software testing\", is not foolproof. This research project will combine the interdisciplinary expertise of the investigators in software engineering and mathematical logic to support a paradigm shift toward \"verified software\": programs that have been entirely and mechanically proved, using formal mathematical logic, to be correct relative to full behavioral specifications of what they are supposed to do and what they are not supposed to do. Given the broad benefits of correct software to society and its impact on national competitiveness, a strong U.S. presence in verified software research and education must be a national priority.<br\/><br\/>While transition of research ideas to practice will take time, the idea of a verifying compiler for sequential, object-based software is tantalizingly close to reality. In what can be properly described as the \"end game\", extensive empirical studies of Verification Conditions (VCs) for correct software already have been undertaken. VCs are assertions that establish that a program is correct if and only if they can be proved. It has been observed that when VCs are not provable mechanically, the obstacles lie in proving VCs that are \"obvious\" to mathematicians, and in engineering specifications and supporting mathematics so they lead to VCs that are also \"obvious\" to automated provers. The expected results of this project are programming language- and tool-independent improvements in automated software verification that will be widely applicable. Another key project goal is integration of new concepts and tools supporting verified software into undergraduate and graduate Computer Science courses. These efforts will contribute to development of a superior next-generation software engineering workforce.","title":"SHF: Medium: Collaborative Research: Specification and Mathematics Engineering for the Verified Software End-Game","awardID":"1161916","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[508269],"PO":["565264"]},"189572":{"abstract":"On any given day in America, there are at least one thousand children fighting for their lives in Pediatric Intensive Care Units (PICUs). In the PICU the patient's condition is carefully monitored with automatic sensors. Most of this data is shown in a five-minute \"sliding window\" display, so a doctor summoned to a patient's bedside always has her most recent history to consider. However what happens to the data that \"falls off\" this sliding window? In most PICUs, a tiny fraction of it is coarsely aggregated and recorded, but surprisingly, most of this data is simply discarded. Even if most or all the data is recorded, its sheer volume simply overwhelms researchers and analysts; very few tools exist to help them make sense of and learn from this data. This currently discarded data is a potential goldmine of actionable knowledge that could improve outcomes (decreased mortality\/morbidity, reduce pain, etc.), and reduce costs (implicit in reduced length of stay). However, the very nature of this data - multivariate, heterogeneous, high dimensional, temporal, noisy, biased, and high frequency - poses significant challenges for traditional analytical techniques from statistics and data mining.<br\/><br\/>In this project, an interdisciplinary team of investigators is developing: (a) xcalable machine learning algorithms for mining archives of annotated PICU data to find regularities and patterns that can be used to aid in diagnostics and prediction of outcomes; and (b) techniques for monitoring ICU telemetry in real time to detect whether the patterns and rules discovered in the offline step have occurred and can be used to guide interventions (actions by the doctor).<br\/><br\/>The project brings together experts in data mining (Keogh, Tsotras), high performance computing (Najjar), and medicine (Wetzel) to investigate holistic solutions to the above problems. The project contributes to research-based advanced training of graduate and undergraduate students at the University of California Riverside. The findings, datasets, software, and teaching materials created by this project will be archived in perpetuity at www.cs.ucr.edu\/~eamonn\/UCRPICU\/","title":"III: Medium: Hardware\/Software Accelerated Data Mining for Real-Time Monitoring of Streaming Pediatric ICU Data","awardID":"1161997","effectiveDate":"2012-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":["518640",508296,"543515"],"PO":["565136"]},"187284":{"abstract":"Efficient spectrum sharing among disparate wireless systems without inter-system communication is the central problem in expanding existing and developing future wireless technologies. This proposal explores an integrated physical and network layer approach for spectrum sharing by developing algorithms and protocols that will allow heterogeneous networks to co-exist and maintain required interference constraints. The proposed framework is based on the novel idea of incorporating detailed real-time measurements and prediction of spectrum usage, including traffic parameters and network topology, into the design of cognitive protocols that respond to the actual spectrum occupancy in time, frequency, and space. The following critical enabling technologies of this framework are being developed: (i) identification of non-cooperative spectrally-overlapped transmitters based on location and modulation parameters; (ii) analysis and tracking of spectrum usage based on traffic estimation and prediction; (iii) cognitive co-existence protocols for spectrum sharing with combined traffic and location awareness. The objective of this research is to comprehensively analyze performance gains achieved by exploiting traffic and location awareness while taking into account estimation and prediction errors, physical limitations, and protocol overhead. The research approach is based on a closed loop between theoretical analysis, implementation, and experimental verification on the reconfigurable wireless testbed and network simulation tools. The algorithms, protocols and tools developed by this research will have practical impact on a broad range of wireless systems that share same spectrum resources including: current and future unlicensed bands, vehicular and safety networks, cellular infrastructure and femto cells, emergency and defense networks.","title":"CAREER: Cognitive Co-Existence in Heterogeneous Wireless Networks","awardID":"1149981","effectiveDate":"2012-07-01","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560230"],"PO":["557315"]},"189594":{"abstract":"The dramatic improvements in electronic devices in the last 40 years have substantially drawn on Moore's law which predicts a steady increase in transistor density in semiconductor chips, with implied improvements in cost and power. But Moore's law is now slowing, while cost improvements now rely on very large production volumes to justify billion-dollar in investments in manufacturing infrastructure. Among alternative chip design methodologies, three-dimensional chip design currently shows significant momentum and promise for commercial products. Three-dimensional chips can be produced by vertical stacking of conventional two-dimensional chips and connecting them with through-silicon vias. Despite a number of unsolved technical problems, such three-dimensional chips reduce the form-factor and interconnect, while improving yield. This research explores heterogeneous 3D chip design seeking the flexibility to combine different types of two-dimensional chips (different types of memories, fast logic, low-power logic, FPGAs, analog circuits, micro- and nano-electromechanical components, etc.), which cannot be reliably manufactured on a single conventional die. This research will reduce cost of 3D designs and make them more practical by exploiting heterogeneity in all its aspects: (1) from dies fabricated in different process nodes to interconnects realized with TSVs, silicon interposers and wire bonds; (2) from system performance (macro blocks with different frequency requirements) to system activity (blocks that are standby-dominant vs. actively-switching); and (3) at the physical design level, from criticality (performance slack) to connectivity (bisection bandwidths or netcuts) across the physical hierarchy from block-level down to gate-level. Our research scope spans three main axes -- 3D IC implementation architectures, technology and design aspects of heterogeneity, and algorithmic optimizations.<br\/><br\/>Being able to combine heterogeneous semiconductor dies in a working electronic system promises significant competitive advantage in price, performance and functionality. Such ability facilitates new types of electronic products, with clear benefits to design and manufacturing companies, as well as to the society. An example application here is a cellular phone, which integrated several micro-processors, analog circuit components and antennas, signal-processing units, accelerometers etc. Being able to revise one of these blocks without altering the supply chain for other blocks reduces the risk and cost of improvements to successful designs. Students will be trained to contribute to the design and revision of such designs, and to perform further research on alternative chip design techniques.","title":"SHF: Medium: Collaborative Research: 3D Integration of Heterogeneous Dies","awardID":"1162087","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[508348],"PO":["562984"]},"189484":{"abstract":"There are an estimated 45 million inpatient surgical procedures per year in the U.S., where critical incidents account for 832,500 deaths and between 1,350,000 and 7,650,000 cases of significant harm to the patient. Of these errors, teamwork failures (e.g. misunderstanding procedural instructions and not acknowledging and repeating back drug dosage levels) are a significant factor - up to 70% for medical operations such as surgery. Reducing teamwork failures requires team training using effective protocols; however, few team training opportunities on these protocols exist. <br\/><br\/>Intellectual merit: To address this deficiency in training, the project will substitute unavailable human team members with mixed reality humans (MRH). MRHs will plug into roles of unavailable human team members to facilitate training in multi-party scenarios. The research team will first develop systems capable of having MRH inhabit training environments alongside human trainees. Then, they will develop novel conversational modeling techniques to support a training experience to be conducted with any combination of human trainees and virtual human teammates. Finally, the team will conduct a set of user studies with the system to explore the effect of mixed reality humans, the impact of mixed reality humans on team dynamics, and the efficacy of team training with mixed reality humans. The result of this work will be effective self-contained, portable MRH systems that integrate into clinical training environments.<br\/><br\/>Broader impacts: The project will result in important educational tools for team training that will ultimately lower the high social and financial costs of team errors in medicine. Better trained teams make fewer and less serious mistakes, thereby improving patient outcomes. The tools and findings will be integrated into the curriculum of continuing medical education and new hire orientation at the University of Florida. While initially applied and evaluated in a clinical setting, the investigators anticipate that mixed reality human team training will be applicable to other multiparty scenarios in aviation, the military, education, and crisis response.","title":"HCC: Medium: Plug and Train: Mixed Reality Humans for Team Training","awardID":"1161491","effectiveDate":"2012-07-01","expirationDate":"2016-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[508084,508085,508086,"553729"],"PO":["564456"]},"193290":{"abstract":"The off-chip memory subsystem is a significant performance and power bottleneck in modern computer systems, necessitating a memory controller that can overcome memory timing and resource constraints by carefully orchestrating data movement between the processor and main memory. The goal of this project is to address this need by enabling application-specific memory system optimizations using a programmable main memory controller, thereby improving the performance, energy-efficiency, and quality-of-service of future computer systems. To realize this vision of programmable main memory controllers, the project addresses challenges all the way from the hardware design of programmable processing units to the firmware implementation of novel memory management algorithms. Automated machine learning and search techniques are employed to quickly arrive at high-performance control algorithms customized to different applications, and to different phases of a single application. Application-specific memory management algorithms ranging from address mapping, command scheduling, and DRAM power management to error-correcting codes and memory compression are developed.<br\/><br\/>The flexibility of the resulting application-specific memory systems is expected to have a direct impact on the performance and energy-efficiency of future computer systems, with tremendous positive fallout to science, technology, and society as a whole. Architecture and software innovations are disseminated to the broader research community through published papers, as well as tutorials on programmable controllers and application-specific memory controller algorithms at major conferences. The educational component of the project involves (1) training both graduate and undergraduate students in computer architecture, (2) a memory systems course that integrates programmable memory controllers and next-generation memory systems into the syllabus, and (3) a memory controller design experience for undergraduates as part of the existing computer architecture curriculum.","title":"Application-Specific Memory System Optimizations using Programmable Memory Controllers","awardID":"1217418","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":[517764],"PO":["366560"]},"197570":{"abstract":"The IEEE International Symposium on Information Theory (ISIT) is the biggest annual conference of the information theory society. It has been held continuously since 1954. It covers almost all the topics related to the studies on information theory, including coding, compression, statistics, complexity, inference, cryptography, as well as many innovative directions such as networking, quantum computing, and other emerging applications of information theory. It is considered the highest standard of IEEE conferences. It has been supported by US Funding Agencies, especially NSF, to facilitate the participation by students and young researchers.<br\/><br\/>This year, ISIT will be held at Cambridge, Massachusetts, on the campus of the Massachusetts Institute of Technology (MIT). The location is chosen not only because it is one of the birth places of information theory, but also an on-campus conference is aimed at reducing the travel costs of attendees. We expect the size of the conference to be larger than in recent years, and thus travel support is more crucial for this conference. ISIT has a well established method of allocating the requested travel funds by selecting<br\/>the most meritorious and needy students to present their papers at the symposium. This year, the travel support is combined with other forms of local arrangement including the use of MIT dorm rooms, organized child care, etc., to encourage more student attendance.","title":"CIF: Travel Grant for the IEEE International Symposium on Information Theory, July 1 to 6, 2012","awardID":"1244885","effectiveDate":"2012-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":[530080],"PO":["564924"]},"197372":{"abstract":"This project supports travel grants to US students and junior faculty to participate in the 31st IEEE Symposium on Reliable Distributed Systems (SRDS)(http:\/\/web.mst.edu\/~cswebdb\/srds2012\/)being held in Irvine, CA, USA, October 8-11, 2012. This is a high quality technical conference for researchers and practitioners who are interested in reliability, security, availability, privacy, and safety of distributed systems. It typically attracts 100-125 papers, 25-30 accepted papers, and 75 to 100 attendees. In addition, the conference also has workshops and PhD forum activities. The middle-sized nature of this conference makes it suitable for extended technical discussions among participants. Being held in the US to enable participants from the US to learn about the computing profession and research environment around the world will likely to have an enriching effect on the fledgling research careers of the awardees and start off discussions between them and the academic and industrial participants from US, Europe and Asia in general.","title":"Travel Grant for Attending 31st IEEE Symposium on Reliable Distributed Systems (SRDS)","awardID":"1243626","effectiveDate":"2012-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["554583"],"PO":["565255"]},"189430":{"abstract":"In the past ten years the theoretical computer science, applied math and electrical engineering communities have extensively studied variants of the problem of ``solving\" an under-determined linear system. One common mathematical feature that allows us to solve these problems is sparsity; roughly speaking, as long as the unknown vector does not contain too many non-zero components (or has a few dominating components), we can ``solve'' the under-determined system for the unknown vector. These problems are referred to as sparse approximation problems and have applications in diverse areas such as signal and image processing, biology, imaging, tomography, machine learning and others.<br\/>The proposed research project aims to develop a comprehensive, rigorous theory of sparse approximation, broadly defined. The research proposal entails two complementary research directions: <br\/>(1) a robust and more complete view of the combinatorial, algorithmic, and complexity-theoretic foundations of sparse approximations (including its generalization to functional sparse approximation where we want to ``solve\" for some function of the unknown vector instead of the vector itself),<br\/>(2) coupled with either its interactions or direct applications in other areas of theoretical computer science, from complexity theory to coding theory, and of electrical engineering, from signal processing to analog-to-digital converters.<br\/>A general theory of sparse approximation that concentrates both on the optimal tradeoffs between competing parameters and the computational feasibility of attaining such tradeoffs will not only help explore the theoretical limits and possibilities of sparse approximations, but also feed algorithmic techniques and theoretical benchmarks back to its application areas. Sparse approximation already has been shown to have impact in a variety of fields, including imaging and signal processing, Internet traffic analysis, and design of experiments in biology and drug design.","title":"AF: Medium: Collaborative Research: Sparse Approximation: Theory and Extensions","awardID":"1161196","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":["550386","550387"],"PO":["565251"]},"187087":{"abstract":"Critical applications involving very large data sets require algorithms that run fast and provide strong performance guarantees. Among the numerous examples are the analysis of medical scans and the acquisition -via imaging- of connectivity in neural systems, an important task in current computational neuroscience. These problems are very often approached by first modeling the data as networks -also called graphs- and then applying graph-specific algorithms to solve them. Among many possibilities, algorithms that rely on certain algebraic representations of graphs have become very appealing due to recent theoretical progress that renders them very time-efficient. However, efficiency appears to come at the cost of an occasionally inferior quality in the generated solutions. Via the proposed extensions of the theory studying these algebraic representations, the project will design new algorithms with strong guarantees and wide applicability.<br\/><br\/>Spectral graph theory studies the connections between algebraic and combinatorial properties of graphs. It is well known that these connections can be far from tight. For example, two given graphs may have approximately the same cuts, but significantly different eigenvalues and eigenvectors. As a result, spectral algorithms for cut problems on graphs, albeit very fast, do not provide good approximation guarantees. This project will extend aspects of spectral graph theory to a spectral theory for cut structures, defined as sets of graphs with approximately prescribed cuts. The central question of the new theory is: What kind of spectral properties can be realized by graphs within a given cut structure?<br\/><br\/>A goal of the project is to show that any cut structure contains graphs whose eigenvectors provide tight information about its cuts. The project will also study algorithms for the efficient computation of these special graphs, by essentially modifying the spectrum of an input graph without significantly altering its cuts. Then, the combination of spectral modification and classical spectral algorithms will yield fast algorithms with enhanced approximation guarantees. The project will draw from connections of spectral graph theory with graph decompositions discovered in the context of oblivious routing algorithms. In turn, it is expected that the project will have an impact on routing problems too. In later stages the project will study the theoretical limits of spectral modification. It will also examine the descriptive quality of the developed theory in the performance of algorithms and other phenomena on interesting classes of graphs, such as social or biological networks.<br\/><br\/>The project will freely disseminate prototype implementations of the new algorithms and will apply them to computer vision and machine learning problems in industry and academia. Applications will be pursued via selected interdisciplinary collaborations. The balance between theoretical and applied work will serve a broader educational effort at both the undergraduate and graduate level, which will also include the introduction of new courses. A significant part of the research will be carried out at the University of Puerto Rico, and so the project is expected to have a significant impact in the education of underrepresented minorities.","title":"CAREER: Fast algorithms via a spectral theory for graphs with a prescribed cut structure","awardID":"1149048","effectiveDate":"2012-07-01","expirationDate":"2017-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}}],"PIcoPI":[501921],"PO":["565251"]},"192070":{"abstract":"Many of the challenges facing contemporary society, such as emission reductions or vaccination for infectious diseases, are collective action problems. To address these challenges, new approaches are needed to understand, stimulate and sustain collective action in large heterogeneous populations. To promote cooperative behavior at large scales, this project will develop computational tools to facilitate the context for cooperation - homogeneity, effective communication - observed in smaller scale case studies and field experiments. The investigators will test new ways to increase collective action using mobile applications and social media.<br\/><br\/>The project will use controlled decision-making experiments to test whether contributions to collective action can be increased by providing the right messages to the right people, such that cooperative behavior can cascade through a social network. Empirical research has shown that individuals are more likely to participate in collective action if they expect others like them to participate. Experiments will be performed in online social networks of students at Arizona State University to test the proposed approach to actualizing collective action within the university community. Data from the experiments will be used to develop mathematical models of collective action in social networks. <br\/><br\/>Broader impacts: The research will lead to new theoretical frameworks for understanding collective action and provide concrete tools to apply these insights. Insights about what kind of feedback to whom is most effective for increasing collective action may make social media a potential effective policy tool for organizations. Potentially, the project will have societal impact by promoting collective action in important areas such as healthcare, voter participation, and energy conservation.","title":"SoCS: Tipping Collective Action in Social Networks","awardID":"1210856","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7953","name":"SOCIAL-COMPUTATIONAL SYSTEMS"}}],"PIcoPI":["551811",514755],"PO":["565342"]},"193060":{"abstract":"In this research, we study a new problem setting in transmitting information over networks, which we call the linear information coupling problem. Instead of asking how many information bits can be conveyed through a given channel, we ask how can one efficiently send a thin layer of information. Aside from its operational implications, and the new applications it addresses, we point out that this new formulation is a generic and fundamental simplification to the network capacity problem, which has remained open for decades. We observe that the main difficulties in many network information theory problems are essentially the same: the high dimensional optimization problems over probability distributions do not have sufficient structure. The key step of the linear coupling problems is a local quadratic approximation of the Kullback-Leibler divergence, from where a geometric structure for the space of probability distributions is defined. This helps us to visualize the information transitions as simpler geometric operations such as projections and expansion with respect to orthonormal bases, and thus identify efficient ways to convey information.<br\/><br\/>Equipped with this new analysis tool, this project studies two classes of problems. First, as demonstrated with our preliminary results, the local approximation is particularly powerful in solving some open network communication problems. We generalize these results to construct a new network model, where each connection is linearized and characterized by the corresponding singular value decomposition (SVD) structure. With this model, the optimal network operations and the corresponding performance can often be solved explicitly. Secondly, we extend this approach to study more general information exchanges including real-time, dynamic, and error-prone systems. This allows us extend the principle of information theory to a much broader context than conventional coded digital applications.","title":"CIF: SMALL: The Linear Information Coupling Problem","awardID":"1216476","effectiveDate":"2012-07-01","expirationDate":"2015-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["530080"],"PO":["564924"]}}