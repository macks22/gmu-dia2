{"205876":{"abstract":"Although the real world is dynamic, many techniques used to image\/capture it are fundamentally sequential in nature. For example, capturing a high-dynamic range (HDR) image of a scene (which contains a wide range of illumination) without special hardware involves taking a set of sequential images at different exposures, each one measuring a small range of illumination. However, this approach has problems when reconstructing the HDR image of dynamic scenes with moving subjects, since the individual frames are not registered correctly. Problems like this appear in many research areas, from medical imaging to computer vision.<br\/><br\/>In this project, the PI and his team are developing a common framework that addresses artifacts from motion for a variety of different applications. Their key insight is that patch-based optimization can be used to handle motion inconsistencies without explicitly solving the challenging problem of accurate motion estimation. This produces results that are reconstructed from different inputs in a consistent manner without motion artifacts. The PI is exploring how this framework can be applied to several important research areas, from high-quality imaging to computer vision applications such as the reconstruction of dynamic scenes.<br\/><br\/>Improved capture of dynamic scenes has the potential to transform the way certain imaging procedures (such as medical imaging) are done. Scientific results of this work are disseminated through technical publications at top venues in the graphics\/vision communities, and the PI plans to release the algorithms developed online. Finally, this project involves high school and under-represented students into the research effort.","title":"CGV: Small: A Patch-based Framework for Capturing a World in Motion","awardID":"1321168","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["559993"],"PO":["564316"]},"206624":{"abstract":"This work will advance human-robot partnerships by establishing a new concept called complementary situational awareness (CSA), which is the simultaneous perception and use of the environment and operational constraints for task execution. The proposed CSA is transformative because it ushers in a new era of human-robot partnerships where robots act as our partners, not only in manipulation, but in perception and control. This research will establish the foundations for CSA to enable multifaceted human-robot partnerships. Three main research objectives guide this effort: 1) Real-time Sensing during Task Execution: design low-level control algorithms providing wire-actuated or flexible continuum robots with sensory awareness by supporting force sensing, exploration, and modulated force interaction in flexible unstructured environments; 2) Situational Awareness Modeling: prescribe information fusion and simultaneous localization and mapping (SLAM) algorithms suitable for surgical planning and in-vivo surgical plan adaptation; 3) Telemanipulation based on CSA: Design, construct, and integrate robotic testbeds with telemanipulation algorithms that use SLAM and exploration data for online adaptation of assistive telemanipulation virtual fixtures. This research also includes investigation of previously unaddressed questions on how sensory exploration and palpation data can be used to enable online-adaptation of assistive virtual fixtures based on force and stiffness data while also taking into account preoperative data and intraoperative correction of registration parameters.<br\/><br\/>The proposed work will restore the situational awareness readily available in open surgery to minimally invasive surgery. This will benefit patients by enabling core technologies for effective and safe natural orifice surgery or single port access surgery. The societal impact of the proposed work on these two surgical paradigms is reduced pain for patients, shorter hospital stay, improved cosmesis and patients' self image, and lower costs. We also believe that CSA will impact manufacturing where its future will require people and robots working together in a shared space on collaborative tasks. Also, the same concepts of CSA apply to telemanipulation in constrained and unstructured environments and the proposed research has direct relevance to robot-human partnerships for space exploration. To ensure this broader impact will be achieved, an advisory board has been assembled with experts from medicine, manufacturing and aerospace. Finally, the PIs will facilitate collaboration in the medical robotics research community by making our software and hardware designs available on-line and using commercial-grade hardware available at multiple institutions.","title":"NRI: Large: Collaborative Research: Complementary Situational Awareness for Human-Robot Partnerships","awardID":"1327566","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":[553211],"PO":["564069"]},"206745":{"abstract":"Processors in cyber-physical systems are increasingly being used in applications where they must operate in harsh ambient conditions and a computational workload which can lead to high chip temperatures. Examples include cars, robots, aircraft and spacecraft. High operating temperatures accelerate the aging of the chips, thus increasing transient and permanent failure rates. Current ways to deal with this mostly turn off the processor core or drastically slow it down when some part of it is seen to exceed a given temperature threshold. However, this pass\/fail approach ignores the fact that (a) processors experience accelerated aging due to high temperatures, even if these are below the threshold, and (b) while deadlines are a constraint for real-time tasks to keep the controlled plant in the allowed state space, the actual controller response times that will increase if the voltage or frequency is lowered (to cool down the chip) are what determine the controlled plant performance. Existing approaches also fail to exploit the tradeoff between controller reliability (affected by its temperature history) and the performance of the plant. This project addresses these issues. Load-shaping algorithms are being devised to manage thermal stresses while ensuring appropriate levels of control quality. Such actions include task migration, changing execution speed, selecting an alternative algorithm or software implementation of control functions, and terminating prematurely optional portions of iterative tasks. Validation platforms for this project include automobiles and unmanned aerial vehicles. These platforms have been chosen based on both their importance to society and the significant technical challenges they pose.<br\/><br\/>With CPS becoming ever more important in our lives and businesses, this project which will make CPS controllers more reliable and\/or economical has broad potential social and economic impacts. Collaboration with General Motors promotes transition of the new technology to industry. The project includes activities to introduce students to thermal control in computing, in courses spanning high-school, undergraduate and graduate curricula.","title":"CPS: Synergy: Collaborative Research: Thermal-Aware Management of Cyber-Physical Systems","awardID":"1329702","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[553549,553550,553551],"PO":["564778"]},"206756":{"abstract":"Design of cyber-physical systems today relies on executable models. Designers develop models, simulate them, find defects, and improve their designs before the system is built, thus greatly reducing the design costs. However, current model-based design methods lack support for model libraries (creating and exchanging models as \"black boxes\"), tool interoperability (allowing models to be co-simulated by multiple tools), and multi-view modeling (allowing to combine models that \"live in different worlds\", for instance, a control-logic model with an energy-consumption model). This project seeks to remedy this by developing a compositional modeling framework based on interfaces. Interfaces allow submodels to be treated as black boxes, exposing relevant information while hiding internal details. <br\/>Success of the project will provide a solid theoretical foundation for compositionality in cyber-physical systems. Compositionality is a key property in system design, allowing to build systems in a scalable and modular manner. This project will enable the construction of model libraries, allowing the exchange of models developed by different teams, potentially coming from different disciplines and using different modeling languages and tools.<br\/><br\/>Besides the considerable economic and societal impact of cyber-physical systems in general, the proposed project will have considerable impact on engineering and computer science education. Its focus on a rigorous and unified modeling theory will erode the boundaries between the currently separated cyber-physical system sub-disciplines that hamper competitiveness of our students. Finally, the project is strategically important for the competitiveness of the United States as it strengthens its presence in international standardization efforts for model exchange and co-simulation.","title":"CPS: Breakthrough: Compositional System Modeling with Interfaces (COSMOI)","awardID":"1329759","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["71498",553584],"PO":["561889"]},"205546":{"abstract":"Years of effort to develop algorithms capable of learning from reward signals have resulted in a plethora of techniques that can leverage numerical signals that vary in value based on performance. Recent efforts to use these techniques to learn from humans providing rewards have been slower to progress, in part, because humans give feedback discretely rather than numerically. This project contributes new learning algorithms designed specifically to leverage the information contained in the choices humans make to provide such discrete feedbacks. The algorithms are inspired by the human-canine partnership, and the incredible things that humans are able to teach dogs using only discrete feedback and carefully constructed sequences of tasks. The Bayesian learning framework being developed in this project will leverage the pragmatic implicatures contained in the feedbacks and tasks sequences to learn more quickly from human feedback. <br\/><br\/>The ultimate goal of this work is to provide a more natural paradigm for humans to tell computers what they would like for them to do. To that end, project efforts will result in a teaching module for Brown University?s Learning Exchange (LE). The LE involves undergraduates working with underserved minority middle school students to engage them in STEM. They are a perfect audience to demonstrate the broader impacts of this work. LE participants learn to instruct computers using a combination of programming with the Scratch environment and the feedback paradigm, which shows how powerful the algorithms are.","title":"RI: Small: Collaborative Research: Speeding Up Learning through Modeling the Pragmatics of Training","awardID":"1319412","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["562335"],"PO":["565035"]},"204699":{"abstract":"OpenSSH reveals excerpts from encrypted login sessions. TLS (HTTPS) reveals encrypted PayPal account cookies. DTLS is no better. EAXprime allows instantaneous forgeries. RFID security has been broken again and again. All of these failures of confidentiality and integrity are failures of authenticated ciphers: algorithms that promise to encrypt and authenticate messages using a shared secret key.<br\/><br\/>It is easy to blame many of these security problems on a lack of education: much stronger authenticated ciphers have been in the literature for many years. However, in many cases these stronger authenticated ciphers fail to meet the performance requirements of the applications. Performance is exactly the motivation for RC4 in WEP; EAXprime in the \"Smart Grid\"; HB in RFID; and \"IPsec\" continuing to support unauthenticated encryption.<br\/><br\/>This project is building a new generation of authenticated ciphers that improve efficiency without compromising security and that improve security without compromising efficiency. This work spans seven main topics: more efficient ciphers; more efficient MACs; more efficient forgery rejection; improved protection against side channels; improved protection against misuse and bad luck; improved quantitative security; and improved security proofs. The ultimate objective is to obtain the best possible security subject to a variety of performance constraints specified by cryptographic users.<br\/><br\/>The high-security high-performance authenticated ciphers produced in this project will be directly and straightforwardly usable in cryptographic applications, avoiding the disasters in current applications and finally bringing secure secret-key cryptography from theory to practice.","title":"TWC: Option: Medium: Collaborative: Authenticated Ciphers","awardID":"1314540","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[548184,548185],"PO":["565239"]},"206767":{"abstract":"Processors in cyber-physical systems are increasingly being used in applications where they must operate in harsh ambient conditions and a computational workload which can lead to high chip temperatures. Examples include cars, robots, aircraft and spacecraft. High operating temperatures accelerate the aging of the chips, thus increasing transient and permanent failure rates. Current ways to deal with this mostly turn off the processor core or drastically slow it down when some part of it is seen to exceed a given temperature threshold. However, this pass\/fail approach ignores the fact that (a) processors experience accelerated aging due to high temperatures, even if these are below the threshold, and (b) while deadlines are a constraint for real-time tasks to keep the controlled plant in the allowed state space, the actual controller response times that will increase if the voltage or frequency is lowered (to cool down the chip) are what determine the controlled plant performance. Existing approaches also fail to exploit the tradeoff between controller reliability (affected by its temperature history) and the performance of the plant. This project addresses these issues. Load-shaping algorithms are being devised to manage thermal stresses while ensuring appropriate levels of control quality. Such actions include task migration, changing execution speed, selecting an alternative algorithm or software implementation of control functions, and terminating prematurely optional portions of iterative tasks. Validation platforms for this project include automobiles and unmanned aerial vehicles. These platforms have been chosen based on both their importance to society and the significant technical challenges they pose.<br\/><br\/>With CPS becoming ever more important in our lives and businesses, this project which will make CPS controllers more reliable and\/or economical has broad potential social and economic impacts. Collaboration with General Motors promotes transition of the new technology to industry. The project includes activities to introduce students to thermal control in computing, in courses spanning high-school, undergraduate and graduate curricula.","title":"CPS: Synergy: Collaborative Research: Thermal-Aware Management of Cyber-Physical Systems","awardID":"1329831","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[553614,553615],"PO":["564778"]},"205205":{"abstract":"The human vision system understands and interprets complex scenes for a wide range of visual tasks in real-time while consuming less than 20 Watts of power. This Expeditions-in-Computing project explores holistic design of machine vision systems that have the potential to approach and eventually exceed the capabilities of human vision systems. This will enable the next generation of machine vision systems to not only record images but also understand visual content. Such smart machine vision systems will have a multi-faceted impact on society, including visual aids for visually impaired persons, driver assistance for reducing automotive accidents, and augmented reality for enhanced shopping, travel, and safety. The transformative nature of the research will inspire and train a new generation of students in inter-disciplinary work that spans neuroscience, computing and engineering discipline.<br\/><br\/>While several machine vision systems today can each successfully perform one or a few human tasks ? such as detecting human faces in point-and-shoot cameras ? they are still limited in their ability to perform a wide range of visual tasks, to operate in complex, cluttered environments, and to provide reasoning for their decisions. In contrast, the mammalian visual cortex excels in a broad variety of goal-oriented cognitive tasks, and is at least three orders of magnitude more energy efficient than customized state-of-the-art machine vision systems. The proposed research envisions a holistic design of a machine vision system that will approach the cognitive abilities of the human cortex, by developing a comprehensive solution consisting of vision algorithms, hardware design, human-machine interfaces, and information storage. The project aims to understand the fundamental mechanisms used in the visual cortex to enable the design of new vision algorithms and hardware fabrics that can improve power, speed, flexibility, and recognition accuracies relative to existing machine vision systems. Towards this goal, the project proposes an ambitious inter-disciplinary research agenda that will (i) understand goal-directed visual attention mechanisms in the brain to design task-driven vision algorithms; (ii) develop vision theory and algorithms that scale in performance with increasing complexity of a scene; (iii) integrate complementary approaches in biological and machine vision techniques; (iv) develop a new-genre of computing architectures inspired by advances in both the understanding of the visual cortex and the emergence of electronic devices; and (v) design human-computer interfaces that will effectively assist end-users while preserving privacy and maximizing utility. These advances will allow us to replace current-day cameras with cognitive visual systems that more intelligently analyze and understand complex scenes, and dynamically interact with users.<br\/><br\/>Machine vision systems that understand and interact with their environment in ways similar to humans will enable new transformative applications. The project will develop experimental platforms to: (1) assist visually impaired people; (2) enhance driver attention; and (3) augment reality to provide enhanced experience for retail shopping or a vacation visit, and enhanced safety for critical public infrastructure. This project will result in education and research artifacts that will be disseminated widely through a web portal and via online lecture delivery. The resulting artifacts and prototypes will enhance successful ongoing outreach programs to under-represented minorities and the general public, such as museum exhibits, science fairs, and a summer camp aimed at K-12 students. It will also spur similar new outreach efforts at other partner locations. The project will help identify and develop course material and projects directed at instilling interest in computing fields for students in four-year colleges. Partnerships with two Hispanic serving institutes, industry, national labs and international projects are also planned.","title":"Collaborative Research: Visual Cortex on Silicon","awardID":"1317407","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[549477],"PO":["565227"]},"206778":{"abstract":"This project focuses on the problem of information acquisition, state estimation and control in the context of cyber physical systems. In our underlying model, a (set of) decision maker(s), by controlling a sequence of actions with uncertain outcomes, dynamically refines the belief about stochastically time-varying parameters of interest. These parameters are then used to control the physical system efficiently and robustly. Here the cyber system collects, processes, and acquires information about the underlying physical system of interest, which is used for its control. The proposed work will develop a new theoretical framework for stochastic learning, decision-making, and control in stochastically-varying cyber physical systems. <br\/><br\/>In order to obtain analytical insights into the structure of efficient design, we first consider the case where the actions of the cyber system only affect the estimate of the underlying physical system. This class of problems arises in the context of (distributed) sensing\/tracking of a physical system in isolation from cyber system control of the physical system's state. Joint state estimation and control for cyber-physical systems will then be considered. Here the most natural first step is to obtain sufficient conditions and\/or special classes of systems where a separated approach to the information acquisition and efficient control is (near) optimal. To demonstrate its utility in practice, our theoretical framework will be applied in the specific context of energy efficient control of data centers and robust control of the smart grid under limited sensing.<br\/><br\/>The intellectual merit of this work will be to develop a theoretical framework for the design of cyber-physical systems including information acquisition, state estimation, and control. In addition, separation theorems for the optimality of separate state estimation and control will be explored.<br\/><br\/>In terms of broader impacts, significant performance improvement of control systems closed over communication networks will impact a wide range of applications for societal benefit, including smart buildings, intelligent transportation systems, energy-efficient data centers, and the future smart-grid. The PIs plan to disseminate the research results widely through conferences and journals, as well as by organizing specialized workshops and conference sessions related to cyber physical systems. The proposed project will train Ph.D. students as well as enrich the curriculum taught by the PIs in communications, stochastic control, and networks. The PIs have a strong track record in diversity and outreach activities, which for this project will include exposure and involvement of high school and undergraduate students, including under-represented minorities and women.","title":"CPS: Synergy: Collaborative Research: Event-Based Information Acquisition, Learning, and Control in High-Dimensional Cyber-Physical Systems","awardID":"1329936","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[553646],"PO":["564728"]},"205216":{"abstract":"The human vision system understands and interprets complex scenes for a wide range of visual tasks in real-time while consuming less than 20 Watts of power. This Expeditions-in-Computing project explores holistic design of machine vision systems that have the potential to approach and eventually exceed the capabilities of human vision systems. This will enable the next generation of machine vision systems to not only record images but also understand visual content. Such smart machine vision systems will have a multi-faceted impact on society, including visual aids for visually impaired persons, driver assistance for reducing automotive accidents, and augmented reality for enhanced shopping, travel, and safety. The transformative nature of the research will inspire and train a new generation of students in inter-disciplinary work that spans neuroscience, computing and engineering discipline.<br\/><br\/>While several machine vision systems today can each successfully perform one or a few human tasks ? such as detecting human faces in point-and-shoot cameras ? they are still limited in their ability to perform a wide range of visual tasks, to operate in complex, cluttered environments, and to provide reasoning for their decisions. In contrast, the mammalian visual cortex excels in a broad variety of goal-oriented cognitive tasks, and is at least three orders of magnitude more energy efficient than customized state-of-the-art machine vision systems. The proposed research envisions a holistic design of a machine vision system that will approach the cognitive abilities of the human cortex, by developing a comprehensive solution consisting of vision algorithms, hardware design, human-machine interfaces, and information storage. The project aims to understand the fundamental mechanisms used in the visual cortex to enable the design of new vision algorithms and hardware fabrics that can improve power, speed, flexibility, and recognition accuracies relative to existing machine vision systems. Towards this goal, the project proposes an ambitious inter-disciplinary research agenda that will (i) understand goal-directed visual attention mechanisms in the brain to design task-driven vision algorithms; (ii) develop vision theory and algorithms that scale in performance with increasing complexity of a scene; (iii) integrate complementary approaches in biological and machine vision techniques; (iv) develop a new-genre of computing architectures inspired by advances in both the understanding of the visual cortex and the emergence of electronic devices; and (v) design human-computer interfaces that will effectively assist end-users while preserving privacy and maximizing utility. These advances will allow us to replace current-day cameras with cognitive visual systems that more intelligently analyze and understand complex scenes, and dynamically interact with users.<br\/><br\/>Machine vision systems that understand and interact with their environment in ways similar to humans will enable new transformative applications. The project will develop experimental platforms to: (1) assist visually impaired people; (2) enhance driver attention; and (3) augment reality to provide enhanced experience for retail shopping or a vacation visit, and enhanced safety for critical public infrastructure. This project will result in education and research artifacts that will be disseminated widely through a web portal and via online lecture delivery. The resulting artifacts and prototypes will enhance successful ongoing outreach programs to under-represented minorities and the general public, such as museum exhibits, science fairs, and a summer camp aimed at K-12 students. It will also spur similar new outreach efforts at other partner locations. The project will help identify and develop course material and projects directed at instilling interest in computing fields for students in four-year colleges. Partnerships with two Hispanic serving institutes, industry, national labs and international projects are also planned.","title":"Collaborative Research: Visual Cortex on Silicon","awardID":"1317470","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[549505],"PO":["565227"]},"206789":{"abstract":"This project develops the theory and technology for a new frontier in cyber-physical systems: cyber-physical manipulation. The goal of cyber-physical manipulation is to enable groups of hundreds or thousands of individual robotic agents to collaboratively explore an environment, manipulate objects in that environment, and transport those objects to desired locations. The project embraces realistic assumptions about the communication, computation, and sensing capabilities of simple individual robots, leading to algorithmic solutions that intrinsically leverage population size in favor of complex agents. Cyber-physical solutions for locating, grasping, and characterizing objects require tools based on distributed computational geometry, while the tasks of planning a path, initiating motion, and controlling the trajectory require tools from decentralized control and consensus. The project lays the theoretical and algorithmic foundations of cyber-physical manipulation, and proves the feasibility of the concept experimentally in hardware tests with up to 100 individual robots. The project uses the problem of manipulation as a stage on which to explore the deeper cyber-physical issue of information asymmetry; the difference in the state of the world as perceived by different agents in the system due to differences in their history of observations, and limitations in their communication capabilities.<br\/><br\/>The object retrieval problem studied in this project is an elemental building block for enabling more complex cyber-physical manipulation tasks. It provides crucial algorithmic components for numerous applications of broad societal benefit, including automated construction (in which hundreds or thousands of robots fabricate large, complex structures), autonomous emergency response (in which large teams of robots find and retrieve incapacitated human survivors after a disaster), and automated environmental cleanup (in which robots secure a dangerous environment by removing debris or hazardous substances). Furthermore, distributed algorithms for multi-agent systems are of broad scientific relevance beyond the realm of cyberphysical systems. The natural world is, in its algorithmic essence, decentralized at many levels. Hence, any advancement in the understanding of how groups of individual agents collaborate to accomplish a coherent task will have broad scientific ramifications. The project has a robust educational and outreach program. One aspect is a hands-on curriculum for robotics outreach activities, called the 'Cyber-Physical Manipulation Lab.' Using a custom-designed robot platform, this educational module introduces the theory and practice of cyber-physical systems to young students to attract them to STEM subject areas at an early age. Results of the project are also incorporated into several graduate and undergraduate level courses at Rice University and Boston University.","title":"CPS: Breakthrough: Collaborative Research: Cyber-Physical Manipulation (CPM): Locating, Manipulating, and Retrieving Large Objects with Large Populations of Robots","awardID":"1330036","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[553678],"PO":["565136"]},"205458":{"abstract":"Most traditional approaches to computer security assume that information from the system can only be sent through intended output channels, such as network connection, monitor, portable disk drive, etc. Side-channel and covert-channel attacks circumvent these protections by extracting information that is leaked or deliberately sent from the system through unintended signals, such as electromagnetic emanations, power consumption, timing of computational activity, etc. Methods for reducing such information leakage are usually tied to specific hardware and\/or specific algorithms, and are very labor intensive. This allows specific fragments of code, such as cryptographic functions, to be relatively safe, but is not feasible for analysis and protection in large codes, such as entire operating systems or web browsers, that also tend to process sensitive information. This project is investigating the relationship between software activity and the resulting side-channel leakage, with the goal of automating software analyses that can discover which data might be leaked and in which parts of the code. These analyses can reveal both covert-channel (intentional) and side-channel (unintentional) leakage vulnerabilities in software, helping programmers focus their efforts on reducing or eliminating these vulnerabilities. In addition to these research components that will help increase national security, the project also includes specific outreach activities, such as building an interactive demonstrator to help educate the public about cyber-security concepts, and visits to local schools to help improve K-12 education and participation of women and minorities in science and engineering.","title":"TWC: Small: Quantitative Analysis and Reporting of Electromagnetic Covert and Side Channel Vulnerabilities","awardID":"1318934","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["550974",550165],"PO":["565327"]},"205227":{"abstract":"The human vision system understands and interprets complex scenes for a wide range of visual tasks in real-time while consuming less than 20 Watts of power. This Expeditions-in-Computing project explores holistic design of machine vision systems that have the potential to approach and eventually exceed the capabilities of human vision systems. This will enable the next generation of machine vision systems to not only record images but also understand visual content. Such smart machine vision systems will have a multi-faceted impact on society, including visual aids for visually impaired persons, driver assistance for reducing automotive accidents, and augmented reality for enhanced shopping, travel, and safety. The transformative nature of the research will inspire and train a new generation of students in inter-disciplinary work that spans neuroscience, computing and engineering discipline.<br\/><br\/>While several machine vision systems today can each successfully perform one or a few human tasks - such as detecting human faces in point-and-shoot cameras - they are still limited in their ability to perform a wide range of visual tasks, to operate in complex, cluttered environments, and to provide reasoning for their decisions. In contrast, the mammalian visual cortex excels in a broad variety of goal-oriented cognitive tasks, and is at least three orders of magnitude more energy efficient than customized state-of-the-art machine vision systems. The proposed research envisions a holistic design of a machine vision system that will approach the cognitive abilities of the human cortex, by developing a comprehensive solution consisting of vision algorithms, hardware design, human-machine interfaces, and information storage. The project aims to understand the fundamental mechanisms used in the visual cortex to enable the design of new vision algorithms and hardware fabrics that can improve power, speed, flexibility, and recognition accuracies relative to existing machine vision systems. Towards this goal, the project proposes an ambitious inter-disciplinary research agenda that will (i) understand goal-directed visual attention mechanisms in the brain to design task-driven vision algorithms; (ii) develop vision theory and algorithms that scale in performance with increasing complexity of a scene; (iii) integrate complementary approaches in biological and machine vision techniques; (iv) develop a new-genre of computing architectures inspired by advances in both the understanding of the visual cortex and the emergence of electronic devices; and (v) design human-computer interfaces that will effectively assist end-users while preserving privacy and maximizing utility. These advances will allow us to replace current-day cameras with cognitive visual systems that more intelligently analyze and understand complex scenes, and dynamically interact with users.<br\/><br\/>Machine vision systems that understand and interact with their environment in ways similar to humans will enable new transformative applications. The project will develop experimental platforms to: (1) assist visually impaired people; (2) enhance driver attention; and (3) augment reality to provide enhanced experience for retail shopping or a vacation visit, and enhanced safety for critical public infrastructure. This project will result in education and research artifacts that will be disseminated widely through a web portal and via online lecture delivery. The resulting artifacts and prototypes will enhance successful ongoing outreach programs to under-represented minorities and the general public, such as museum exhibits, science fairs, and a summer camp aimed at K-12 students. It will also spur similar new outreach efforts at other partner locations. The project will help identify and develop course material and projects directed at instilling interest in computing fields for students in four-year colleges. Partnerships with two Hispanic serving institutes, industry, national labs and international projects are also planned.","title":"Collaborative Research: Visual Cortex on Silicon","awardID":"1317560","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["550859","562561",549540,549541,549542],"PO":["565227"]},"208615":{"abstract":"Future cyber-infrastructures are increasingly expected to revolve around the integration of big data, computation, and high performance networking. The High Performance Computing with Data and Networking Acceleration (HPCDNA) project focuses on these issues in the context of campus science and computational requirements. Many researchers have application specific data and a variety of desired compute environments, including purpose built small lab compute resources, medium scale campus High Performance Computing (HPC), cloud computing, and national scale distributed or centralized resources. The inability to flexibly and seamlessly get data to the most appropriate compute resource is often the limiting factor determining where the computation is run and what computation is performed. The HPCDNA project is developing technologies to greatly improve the ability to utilize common data sets across this diverse set of computational resources.<br\/><br\/>The HPCDNA architecture and technologies include a Network Embedded Storage (NES) system based on a distributed high performance parallel file system deployed in the core of the Mid-Atlantic Crossroads regional network. This system is enhanced for high performance via tight integration with campus HPC, campus networks, and wide area networks. An NES client interface is being developed, which coordinates storage with dynamic network provisioning, and enables a variety of high performance access methods by workflow processes. <br\/><br\/>It is expected that the HPCDNA system will facilitate expanded use of HPC and clouds by researchers, which will allow the adoption of more ambitious goals with the knowledge that their computing environments can scale up along with their problem space.","title":"CC-NIE Integration: High Performance Computing with Data and Networking Acceleration (HPCDNA)","awardID":"1340984","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8080","name":"Campus Cyberinfrastrc (CC-NIE)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}}],"PIcoPI":[559175,559176,559177,559178,"285553"],"PO":["564246"]},"205249":{"abstract":"Outsourcing computation to the cloud has a difficult set of privacy challenges, a primary one being that the client cannot really trust cloud or application software. Encrypted computation achieves privacy by having the user specify encrypted inputs to a program in the cloud and returning encrypted results.<br\/><br\/>The design and implementation of a secure processor architecture, called Ascend, that guarantees privacy of data computed upon by untrusted programs and run on an untrusted operating system (OS) is underway. Our security goal is to only trust the Ascend processor chip and show that it is secure against software attacks and power analysis attacks on its pins even though application and system software can be malicious. Our performance goal is to show that execution time and energy overheads of encrypted computation are reasonable. The key idea in Ascend to guarantee privacy is obfuscated program execution: from the perspective of the Ascend chip's input\/output and power pins, an untrusted server cannot learn anything about private user data regardless of the program run.<br\/><br\/>Through innovations in architectural mechanisms, security protocols, and applied cryptography, we hope to show that it is viable to only trust hardware and not trust any software in some security-conscious applications, thereby substantially minimizing the trusted computing base for these applications. The development of simulator infrastructure and hardware prototypes will allow the fruits of the research to be widely disseminated. This project will introduce high-school students to research in applied cryptography and security through an innovative high-school outreach program.","title":"TWC: Small: Ascend: Architecture for Secure Computation on Encrypted Data","awardID":"1317763","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"1668","name":"FED CYBER SERV: SCHLAR FOR SER"}}],"PIcoPI":["561979"],"PO":["565327"]},"209748":{"abstract":"Proteins are the 'workhorse' molecules in cells. Their interactions with each other, nucleic acids, ligands, and other molecules underlie many important cellular processes. Therefore, elucidating protein interactions, preferentially at the atomic level, is important to understanding these processes and treating them in diseased cells. Protein docking achieves the purpose computationally by finding the protein conformation of the lowest free energy values. Solving such a free energy minimization problem is challenging for two reasons. First, the search space is extremely high-dimensional because proteins are not rigid bodies but rather flexible when interacting. Secondly, the free energy function is very costly to evaluate and rugged to optimize. <br\/><br\/>Intellectual Merit<br\/>The proposed research directly addresses these challenges to protein docking at the refinement stage. First, the dimension of the search space will be substantially lowered. Although proteins consist of hundreds to thousands of atoms, not all collective motions of those atoms are physically meaningful. The proposed methods will decompose the space of collective atomic motions into that of rigid-body motions and that of a few relevant flexibility motions by applying novel normal mode analysis (NMA) tools. Second, the search efficiency for the energy minimum will be substantially improved. Energy landscape in the reduced search space will be characterized and state-of-the-art search methods will be applied for energy minimization in the space. The proposed research will also produce insights on the reduced conformational space of protein interactions and the landscape of free energy functions in the reduced space. <br\/><br\/>Broader Impacts<br\/>The ability to predict how proteins interact with efficiency and accuracy is of tremendous value to understanding the structural and functional organization of life, developing diagnosis and therapeutics tools to cure diseases, and discovering approaches to improve bioenergy yields. The proposed research is interdisciplinary and thus expected to be useful to biologists who need protein docking tools to aid their study as well as computer scientists who need to apply or develop dimension reduction and optimization methods. Project will provide training opportunities to students in developing interdisciplinary skills.","title":"CCF: EAGER: Dimension Reduction and Optimization Methods for Flexible Refinement of Protein Docking","awardID":"1347865","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7931","name":"COMPUTATIONAL BIOLOGY"}}],"PIcoPI":[562282],"PO":["565223"]},"209649":{"abstract":"The National Science Foundation (NSF) is pleased to announce the selection of Mung Chiang , the Arthur LeGrand Doty Professor of Electrical Engineering at Princeton University, to receive its 2013 Alan T. Waterman Award. Dr. Chiang is also an associated faculty of Computer Science and an affiliated faculty of the Department of Applied and Computational Mathematics at Princeton.<br\/><br\/>The Waterman Award is the National Science Foundation's (NSF) highest honor. The annual award recognizes outstanding researchers under the age of 35 in any field of science or engineering that NSF supports. In addition to a medal, this year's awardee will receive a $1 million grant over a five-year period for further advanced study in his field.<br\/><br\/>Professor Chiang, is the founder of the Princeton EDGE Lab, which bridges over the theory-practice divide in networking through collaboration across many disciplinary boundaries as well as the academia-industry boundary. His team constantly re-examines the mathematical crystallization of engineering artifacts in networking. His research investigates an evolving set of projects spanning the modeling, analysis, and design of networks, both technological and human ones. Prof. Chiang also received the 2012 IEEE Kiyo Tomiyasu Award -for demonstrating the practicality of a new theoretical foundation for the analysis and design of communication networks', a U.S. Presidential Early Career Award for Scientists and Engineers in 2008, an Office of Naval Research Young Investigator Award in 2007, and a National Science Foundation CAREER Award in 2005. He was named as an MIT Technology Review TR35 Young Innovator in 2007, and was elected an IEEE Fellow in 2012.","title":"Waterman Award","awardID":"1347234","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[561963],"PO":["565303"]},"199023":{"abstract":"This project focusses on equation solving in Algebra I for seventh and eighth grade students. This research extends research on an on-going project on developing an on-line, game-like learning environment called APLUS (Artificial Peer Learning environment Using SimStudent) in which students learn by teaching a synthetic peer called SimStudent. Learning by teaching is an exciting and innovative approach to learning and instruction that is often reported to be effective in classroom trials. However, little is known about the underlying cognitive and social theory on how and when students learn by teaching. Although some studies have shown a potential for scale learning by teaching through implementation in technology, very little is known about the transformative theory to successfully implement learning by teaching. To address this issue, the researchers build on their current work to further develop the theory of learning by teaching and to understand how best to achieve the theory development through advanced technology support. The researchers also investigate the similarities and differences between learning by teaching and learning by being tutored to better engineer effective advanced learning technology. In particular, the researchers propose to improve the effectiveness of APLUS by providing adaptive scaffolding for students to teach SimStudent correctly and appropriately. The researchers also propose to collect detailed process data that show fine-grained interactions between the student and SimStudent in addition to outcome data, which are test scores. By combining the process and outcome data, the researchers will explore the cognitive and social theory of learning by teaching. The researchers hypothesize that providing help on how to solve problems (cognitive help) and how to tutor (metacognitive help) will facilitate tutor learning. They also conjecture that the interaction between cognitive and metacognitive help will yield a rich learning environment that, in combination with the unique characteristics of learning by teaching, will be more effective than learning by being tutored. The following research questions will be addressed:<br\/><br\/>Q1: Does cognitive help facilitate tutor learning? If so, how and why?<br\/><br\/>Q2: Does metacognitive help facilitate tutor learning? If so, how and why?<br\/><br\/>Q3: Is learning by teaching with the meta-tutor assistance better than learning by being tutored?<br\/><br\/><br\/>Learning by teaching has been widely recognized to be effective for academically challenging populations, including African American students and underprivileged students. Therefore, the proposed intervention, if proven to be effective, would contribute to the development of effective STEM learning support system for all students regardless of their race\/ethnicity, gender, socioeconomic status, or geographical locale in contemporary US classrooms. Since the entire proposed technology would run as a web-based application, the software products will be distributed widely and rapidly. The study data will be shared through the opendata repository, DataShop, under the direct supervision of the Pittsburgh Science of Learning Center. Thus, the research effort will contribute to the general learning research community by providing that community opportunities to conduct secondary data analyses.","title":"Learning by Teaching a Synthetic Peer: Investigating the effect of tutor scaffolding for tutor learning","awardID":"1252440","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7625","name":"REESE"}}],"PIcoPI":[533935,533936,533937],"PO":["564412"]},"205700":{"abstract":"This project develops science and technology for ensuring performance stability of large-scale software systems, such as resource management mechanisms used in data centers. The term \"stability\" is used here in a control-theoretic sense that applies to dynamical systems and roughly means freedom from divergence a range of desired system states. Performance stability refers to stability of performance parameters, such as latency, response time, service throughput, utilization, cache hit ratio, or timeout rate. The project develops the foundations and tools necessary to ensure software stability, and to diagnose and undo root causes of unstable behavior when it occurs in deployed systems. A significant contribution lies in exploring rules and guidelines that, if obeyed, allow reasoning about software stability in a compositional manner, such that stability of composite systems can be inferred from stability of components. Compositional stability analysis of software performance is facilitated by advances in control theory such as Passivity Theory and the Theory of Positive and Dissipative Systems. These advances offer a wealth of results on stability and compositionality for a restricted category of non-linear systems that fits software models. <br\/><br\/>Performance stability challenges have been largely overlooked in software design. They are not typically manifest in small systems, but grow with the size and complexity of systems. The trend towards more software consolidation and outsourcing of computing services entails more complexity, more layering, and more interactions among various resource management mechanisms, making it harder to anticipate side-effects, and more likely there will be stability problems. The project improves the current understanding of the design, execution, and management of large systems that exploit feedback mechanisms to achieve performance and robustness objectives. Educational activities include incorporation of project elements into several courses taught by the PI, and involvement of undergraduate students in the research. Outreach activities include an on-campus \"Feedback Computing Day\", a tutorial on feedback computing to be offered in conjunction with a major research conference, and efforts by the PI to recruit students from under-represented groups. Dissemination activities include documentation of results of the research in a book by the PI, and efforts to transition technology through collaborators in industry.","title":"CSR: Small: On Modeling Software Dynamics for Feedback Computing","awardID":"1320209","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["553633"],"PO":["564778"]},"210199":{"abstract":"Two extremes of modern computing are supercomputers in the Petaflops performance regime taking up thousands of square feet and embedded computing found in cell phones, automobiles, and TV remote controls. Yet these apparently disparate classes of computing devices have many properties and requirements in common and, in fact, are converging. Power, reliability, multicore, efficiency, and programmability are among the many demands that these two historically separate forms share. The multicore challenge demands a new strategy for organizing and conducting concurrent tasks, which is referred to as a \"model of computation\" or alternatively an \"execution model\". Typically embedded computers have been programmed individually by cores to guarantee real-time operation. But as their performance requirements grow, embedded processors will have to depend on multiple cores to achieve needed response time. Supercomputers are relying on multicore components with exponentially growing number of cores per socket to deliver increased performance with technology advances. This project is producing a new version of the ParalleX execution model to support embedded real-time multicore operation while imbuing future supercomputers with the semantics of real-time for introspection, enabling dynamic adaptive resource management and task scheduling. This further advances future supercomputers, as a current trend is to replace heavyweight cores such as the IBM Power architecture or the Intel x86 architecture with lightweight cores similar to embedded processors like the IBM PowerPC architecture or the Intel Xeon Phi architecture. Other supercomputer projects are exploring the use of the ARM embedded cores for high performance systems. The availability of the ParalleX real-time execution model will unify both embedded control computers and high performance computers for mutual support and benefit. Key results of this project will be a new runtime system that can serve both embedded and high performance computing systems and a programming interface to facilitate scalable application development of both.<br\/><br\/>The project's broader significance is that it will dramatically strengthen US competitiveness in both realms of computing-critical domains and enhance the nation?s economic development while addressing key challenges to the advancement of both. The field of supercomputing is facing a major challenge in how to continue to exploit technology advancement and the ParalleX execution model augmented with real-time introspection is providing the guiding principles to support co-design of architecture, programming methods, and system software and tools. Embedded control computers need to be able to use parallel processing with a single-system image for ease of programming and adaptive resource utilization. ParalleX will provide this capability. Finally, through the work of this project, future embedded processors will become the building blocks of the next generation of high performance computing to achieve exascale performance by decade's end.","title":"EAGER:Real-time Semantics for the ParalleX Execution Model to Enable Single-Image Multicore Embedded Computing","awardID":"1352969","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}}],"PIcoPI":[563330,563331],"PO":["565272"]},"205733":{"abstract":"One of the major advances in information technology infrastructures in the past decade is the use of server virtualization technology. By decoupling the server software from the underlying physical hardware, virtualization helped open up new business models and bring about more efficient computing infrastructures. With virtualization, (virtual) servers are freely able to be started and stopped on demand, and, through live VM migration, even change physical servers at run time without affecting the operating system or applications running on those servers. This dynamic repositioning of servers is used to consolidate servers to save energy, balance load, perform planned maintenance, and optimize user performance (among other benefits). The network, unfortunately, is still tied to the physical resources.<br\/><br\/>This research project introduces liquid networking, which provides the ability to morph a network dynamically, much like migration provided dynamic morphing in the server space. Supporting this raises many challenging research questions that this research project will address. First, understanding how to provide primitives that efficiently transform the network without affecting the correct operation of the network is an important research challenge. Through implementation of multiple applications, a deep understanding of the limitations and capabilities of liquid networking will be explored. With it, new algorithms and tools will need to be developed. Second, understanding the impact future network technology has on liquid networking, namely software-defined networking, and the impact liquid networking will have on future networking technology is an equally important challenge that will be addressed.<br\/><br\/>Broader Impacts: This project will open up an entirely new set of possibilities in the management of a computing infrastructure. With a liquid network, networks will have greater flexibility, lower IT costs, and better security. Additional important broader impacts for society resulting from this project are expected to include enhancing the curriculum of advanced graduate systems courses and enabling undergraduate students, underrepresented minorities and women to participate in the project through programs such as the Discovery Learning Apprentice (DLA) program run by the college of engineering at the University of Colorado, and the Colorado Diversity Initiative.","title":"NeTS: Small: Liquid Networking","awardID":"1320389","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["556809"],"PO":["565090"]},"205502":{"abstract":"Fully homomorphic encryption (FHE) allows an untrusted party to efficiently compute any compact function directly on ciphertexts. When made available over an untrusted cloud server, data is submitted and returned in encrypted form, and the execution remains secure against malicious users. Early FHE proposals had rather disappointing efficiencies. Recently new FHE schemes based on the difficulty of the learning with errors (LWE) problem emerged with orders of magnitude improvement over earlier constructions. This project addresses a variety of problems in engineering, computer science and mathematics all centered around the goal of bringing LWE-based homomorphic encryption techniques closer to practice which could impact the way society utilizes computing services.<br\/><br\/>The project team explores three research components. The first research component investigates algorithmic optimizations to speed up LWE-based schemes, and to develop optimized software implementations on CPUs and graphics processing units. Specifically, the investigators apply optimization techniques including changing the representation of the operands, batching, and precomputation. The team also aims to build a LWE-FHE based homomorphic instruction set. In another research component the project team develops application specific custom hardware to overcome inefficiencies of software platforms. Finally, we investigate the customization of parameters to match the needs of select lightweight cryptographic primitives.","title":"TWC: Small: Towards Practical Fully Homomorphic Encryption","awardID":"1319130","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["564461",550273],"PO":["565264"]},"205623":{"abstract":"Society has long relied on increasing computing power to drive<br\/>technological development. Continuing this trend in the multi-core era<br\/>will require a large scale migration to parallel software. As an<br\/>acknowledgment of the new importance of parallelism in software<br\/>development, the 2011 C and C++ standards extended C and C++ with<br\/>language support for low-level atomic operations to allow developers<br\/>to write portable efficient concurrent data structures.<br\/>Unfortunately, implementing concurrent data structures is extremely<br\/>difficult to do correctly. Despite the difficulties, we expect that<br\/>the potential performance benefits will lure many developers, both<br\/>experts and others, to attempt to develop customized concurrent data<br\/>structures. Without tool support, this will inevitably lead to<br\/>potentially costly failures in deployed software.<br\/><br\/>This project will explore techniques for efficiently model checking<br\/>concurrent data structures under the C\/C++ memory model and support<br\/>for developers to effectively use a model checker for testing and<br\/>debugging code. These techniques will be implemented in the form of a<br\/>concurrent data structure checking tool, CDSChecker, that will be<br\/>developed by the this project. The project will develop efficient<br\/>model-checking techniques for the C\/C++ memory model, explore how to<br\/>specify the correct behavior of concurrent data structures, explore<br\/>how to support testing and debugging of concurrent code, and explore<br\/>how to effectively communicate information about concurrency bugs to<br\/>developers.","title":"SHF: Small: CDSChecker: Model-Checking Concurrent Data Structures under the C11\/C++11 Memory Model","awardID":"1319786","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[550574],"PO":["565264"]},"205514":{"abstract":"In phishing, an attacker tries to steal sensitive information, e.g., bank\/credit card account numbers, login information, etc., from Internet users. The US society and economy are increasingly dependent on the Internet and the web, which is plagued by phishing. One popular phishing method is to create a site that mimics a good site and then attract users to it via email, which is by far the most popular medium to entice unsuspecting users to the phishing site. Because of this modus operandi and the damages caused by phishing, it is important to design efficient and effective classifiers for emails and web sites. <br\/><br\/>In this project, new techniques, inspired from natural language processing methods, are being designed for phishing email and web site detection. They are then implemented and validated rigorously on realistic data sets. They are also applied to automatic detection of opinion spam. <br\/><br\/>Proposed research is expected to: (i) be useful in pushing the envelope of natural language processing techniques, and (ii) yield new applications of these techniques in cyber security. In the past, the PI has been very successful in involving women and minorities including underrepresented minorities in his research and this effort will be continued in this project. University of Houston has been recognized as a Hispanic-serving institution and the PI will continue his past successful efforts to involve underrepresented minorities including African Americans and Hispanics in this research. This research will be moved into the classroom and broadly disseminated through publications and software on the web.","title":"TWC: Small: Unsupervised and Statistical Natural Language Processing Techniques for Automatic Phishing and Opinion Spam Detection","awardID":"1319212","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[550310],"PO":["564223"]},"205877":{"abstract":"Robotic networks can have a tremendous impact in many different areas such as disaster relief, emergency response, and national security. The recent disasters such as Hurricane Sandy of 2012 or Japan's earthquake of 2011 remind us of the crucial role that unmanned autonomous networks can play as part of our society. The goal of this project is to introduce a new multi-disciplinary design paradigm for the successful operation of mobile robotic networks through the co-optimization of sensing, communications and navigation. In the robotics\/control community, most existing work does not deal with realistic communication issues (such as shadowing and multipath fading) and ideal links\/disk models are assumed for predicting connectivity. On the other hand, the communication and networking communities are not typically concerned with path planning and navigation. In a robotic network, path planning not only affects sensing quality but also impacts connectivity maintenance. This multi-disciplinary nature makes designing robust decision-making strategies for a successful task accomplishment in robotic networks considerably challenging and an open problem. Furthermore, a separate optimization of the given sensing, communications and navigation resources may not suffice for a successful operation under resource constraints.<br\/><br\/>In this research effort, the focus is on the impact of limited energy (both motion and communications), time, and bandwidth resources and on laying the foundation of the corresponding optimum sensing, communication and navigation co-design policies, which includes trajectory, sensing, connectivity, motion speed\/power, and communication transmission rate\/power optimization. In this approach, realistic probabilistic connectivity metrics are properly co-optimized with sensing and navigation goals such that each robot chooses a trajectory that allows it to maximize its information gathering while maintaining the needed connectivity. This framework answers fundamental questions such as when to invest in motion and when to invest in communications. The project also addresses task feasibility and the fundamental limits of information generation, gathering and exchange, which can provide key insights for resource planning before deployment. <br\/><br\/>Overall, this new co-optimization foundation enables the successful operation of robotic networks under limited resources and can thus have a tremendous impact on our society. This project also has a significant educational impact on minority and under-represented students.","title":"NeTS: Small: Co-Optimization of Sensing, Communications and Navigation of a Robotic Network under Resource Constraints","awardID":"1321171","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[551173],"PO":["565303"]},"205646":{"abstract":"The project aims to improve the quality of service and lifetime of real-time<br\/>embedded systems, particularly those implemented on multi-core platforms. In<br\/>contrast with many other quality metrics, such as performance and power<br\/>consumption, reliability is difficult to accurately estimate because it is<br\/>influenced by design decisions, environmental conditions, and process variation<br\/>during integrated circuit fabrication.<br\/><br\/>This project consists of three main technical tasks. (1) Develop a reliability<br\/>modeling and analysis framework that can efficiently and accurately determine<br\/>the impact of design and runtime management decisions on reliability. (2)<br\/>Develop a reliability-driven resource management framework, which includes<br\/>runtime algorithms for assignment and scheduling of real-time tasks to maximize<br\/>system lifetime while keeping soft error rates low, and a lightweight technique<br\/>to adaptively adjust the activation frequency of the algorithms (i.e.,<br\/>overhead). (3) Develop wear state monitoring techniques and data collection<br\/>infrastructure to enable the runtime refinement and validation of system-level<br\/>reliability models that require long-term in-field system deployment.<br\/><br\/><br\/>The techniques developed in this project will support the production of more<br\/>reliable and\/or less expensive electronic devices, enabling integrated<br\/>circuits, which are susceptible to wear due to lifetime fault processes to be<br\/>used in special-purpose computers with strict reliability and performance<br\/>requirements. In particular, this project aims to ease the use of multicore<br\/>processors in high-reliability computing applications with deadlines, such as<br\/>automotive, multimedia, and health care applications. These applications have<br\/>historically seen slow adoption of multicore processors, despite their price,<br\/>performance, and power consumption benefits. We believe this is partially due<br\/>to gaps in knowledge of how to control and optimize reliability on such<br\/>systems, some of which this project will fill. The involvement of both industry<br\/>researchers and university students at the undergraduate and graduate level<br\/>will result in a broad dissemination of the research results.","title":"CSR: Small: Collaborative Research: Reliability Driven Resource Management of Multi-Core Real-Time Embedded Systems","awardID":"1319904","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[550624],"PO":["565255"]},"205547":{"abstract":"This project investigates operating system mechanisms to manage hardware accelerator resources in a safe, fair, and protected manner while maintaining high performance. Programmable vector processors including general-purpose graphical processing units (GP-GPUs) and other accelerators for encryption, compression, media transcoding, pattern matching, parsing, etc. are increasingly ubiquitous in computer systems. For the sake of safety and fairness, such accelerators must be managed by the operating system, but for the sake of performance, they must be accessible directly from user-level applications, without OS intervention. The conflict between these goals is exacerbated by the opacity of proprietary library\/driver\/hardware interfaces. This project seeks a balanced solution to these conflicting goals through: (1) an operating system resource management architecture that allows direct user-level access in the common case, but intercedes in the existing accelerator access path when necessary to delay and re-order requests; (2) a tool chain that uncovers hidden interface semantics required for resource management, together with a characterization of the information needed from vendors in the future; and (3) an integrated management and scheduling strategy across the full set of computational resources in a given system.<br\/><br\/>By focusing on safe, fair, and efficient access to computational accelerators, the project aims to increase performance and power efficiency over a broad range of applications critical to today's digital economy and society. Broad dissemination is promoted through implementation in the Linux kernel, and open-source software release. Technology transfer is pursued through regular communication and collaboration with GPU industry vendors. Project research is integrated with education through curricular development and graduate student instruction.","title":"CSR: Small: First-Class Operating System Management of Computational Accelerators","awardID":"1319417","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["564815",550397],"PO":["564778"]},"206768":{"abstract":"To ensure operational safety of complex cyber-physical systems such as automobiles, aircraft, and medical devices, new models, analyses, platforms, and development techniques are needed that can predict, possible interactions between features, detect them in the features' concrete implementations, and either eliminate or mitigate such interactions through precise modeling and enforcement of mixed-criticality cyber-physical system semantics. This project is taking a novel approach to reasoning about and managing feature interactions in cyber-physical systems, which encompasses interactions within software, interactions through the physical dynamics of the system, and interactions via shared computational resources. The proposed approach consists of three tightly coupled research thrusts: (1) a novel way of modeling features as automata equipped with both physical dynamics of the feature environment, and an assigned criticality level in each state of an automaton, (2) new automata-theoretic and control-theoretic analysis techniques, enabled by the modeling approach, and (3) new algorithms for adaptive sharing of computational resources between individual features that are guaranteed to satisfy the assumptions made during analysis, realized within a novel mixed-criticality cyber-physical platform architecture. The modeling approach will introduce a new model for mixed-criticality cyber-physical components and will support modern development standards, such as AUTOSAR in the automotive industry, for assigning criticality levels to features. Component interfaces in this model will capture control modes and the associated physical dynamics, operating modes and the associated resource requirements and criticality level, as well as relationships between control modes and operating modes. Analysis of features expressed in the proposed model will include detection of interactions and exploration of their effect on safety properties of the composite system. The broader impacts of the proposed work are twofold. One impact lies in the pervasive use of cyber-physical systems in our society. If the developed results are adopted in industry, it may help to promote improved safety of such systems. Results of the proposed research will be used in courses offered at both University of Pennsylvania and Washington University at the graduate and undergraduate levels. The project will also provide students with opportunities to get involved in cutting edge research within their fields of study","title":"CPS: Synergy: Collaborative Research: Safety-Feature Modeling and Adaptive Resource Management for Mixed-Criticality Cyber-Physical Systems","awardID":"1329861","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["556687","560533"],"PO":["565136"]},"209914":{"abstract":"Numerical software is increasingly playing a critical role in society, and thus numerical errors in software can have disastrous consequences. However, it is very difficult to test numerical software, and numerical errors are hard to detect because they may not necessarily result in system crashes. There is a strong need for effective and practical techniques or tools to detect and prevent such errors and improve robustness of numerical software.<br\/><br\/>This project explores novel and practical techniques for testing and analyzing numerical software to detect numerical errors in order to improve its robustness. In particular, this project carries out a set of preliminary research tasks to demonstrate the feasibility of the techniques, including developing an initial public repository of numeric constraints and exploring techniques to guide, optimize, and use parallel path exploration in symbolic execution. The research in this project enhances the infrastructure for teaching and research by providing open source tools and data sets for use by students and practitioners, and for enhancement by other researchers.","title":"EAGER: Improving Robustness of Numerical Software","awardID":"1349666","effectiveDate":"2013-10-01","expirationDate":"2015-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[562727],"PO":["565264"]},"205206":{"abstract":"Next-generation WLAN protocols will rely heavily on spectrum aggregation to achieve Gbps throughput. But the aggregated wideband spectrum may be severely underutilized and even starved when it overlaps with legacy narrowband channels. As WLAN protocols continue their expansion and diversification, such heterogeneous spectrum sharing becomes increasingly prevalent, raising coexistence as a fundamental problem and practical problem. The objective of this research is to gain insights into coexistence of Gbps and legacy WLANs through measurement studies, develop optimization-driven protocols to enable efficient spectrum sharing between them, and validate the protocols in a medium-scale software-radio testbed. The proposed solutions improve the MAC layer's awareness of heterogeneous spectrum sharing, and enforce intelligent control over the PHY layer through fine-grained spectrum access and opportunistic spectrum aggregation. They have the potential to realize Gbps wireless networking even in a crowd of low-rate legacy networks\/devices.<br\/><br\/>By addressing the key issues of heterogeneous spectrum sharing, the proposed research helps accelerate the deployment of Gbps WLANs which will, in turn, improve the quality of experience for billions of WiFi end-users. It will also train graduate students with a balanced mix of theory and hands-on experiences, and synthesize their knowledge in both computer science and communications engineering. Undergraduate students will also participate in this project, with the complementary support from the undergraduate research programs in the PI's institutions. The PIs will interact closely with industry for possible transitioning of the research results.","title":"NeTS: Small: Collaborative Research: Efficient Spectrum Access for Gbps WLANs in a Crowd of Legacy Networks","awardID":"1317411","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["553551"],"PO":["557315"]},"206779":{"abstract":"Until now, the \"cyber\" component of automobiles has consisted of control algorithms and associated software for vehicular subsystems designed to achieve one or more performance, efficiency, reliability, comfort, or safety goals, primarily based on short-term intrinsic vehicle sensor data. However, there exist many extrinsic factors that can affect the degree to which these goals can be achieved. These factors can be determined from: longer-term traces of in-built sensor data that can be abstracted as triplines, socialized versions of these that are shared amongst vehicle users, and online databases. These three sources of information collectively constitute the automotive infoverse.<br\/><br\/>This project harnesses this automotive infoverse to achieve these goals through high-confidence vehicle tuning and driver feedback decisions. Specifically, the project develops software called Headlight that permits the rapid development of apps that use the infoverse to achieve one or more goals. Advisory apps can provide feedback to the driver in order to ensure better fuel efficiency, while auto-tuning goals can set car parameters to promote safety. Allowing vehicles and such apps to share vehicle data with others and to use extrinsic information results in novel information processing, assurance, and privacy challenges. The project develops methods, algorithms and models to address these challenges.<br\/><br\/>Broader Impact - This project can have significant societal impact by reducing carbon emissions and improving vehicular safety, can spur innovation in tuning methods and encourage researchers to experiment with this class of cyber-physical systems. The active participation of General Motors will strongly facilitate technology transfer. There is significant outreach including high school student participation, undergraduate research activities, internships, and creation of an open framework for plug and play application developers to use.","title":"CPS: Synergy: Collaborative Research: Harnessing the Automotive Infoverse","awardID":"1329939","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[553648],"PO":["565274"]},"205569":{"abstract":"Network protocol stacks typically follow a multi-layer hierarchical architecture. What determines the required number of layers, or the number of protocols at each layer? The space of applications, services and user expectations (at the top layer) and the space of elementary functions (at the bottom layer) are constantly evolving -- how does this dynamic environment affect the organization of layered protocol stacks? What determines the evolvability of a protocol stack in the presence of changes? How does evolvability relate to other important system-wide properties such as robustness (the ability to deal with unexpected change), optimality and modularity? These are some of the high-level questions that this research project focuses on. <br\/><br\/>Intellectual Merit: This research seeks to reexamine the fundamentals of protocols design and investigate the role of and dependencies between several central concepts: layering, modularity, complexity, robustness, optimality. The central theme in this research, however, is evolution -- networking architectures are not designed to work in a static environment. Applications, services, user expectations, communication and computing technologies, as well as the underlying economics, are all in a constant state of flux. <br\/><br\/>Rather than rely on a single modeling framework, this research starts with two preliminary models, referred to as Stratum and Lexis. The two models share some features but are also significantly different and complementary. They both capture the time-varying character of a layered design process aiming to support a dynamic set of applications from an underlying set of (also dynamic) elementary functions. Stratum is more constrained than Lexis as it considers, first, a specific ordering for the available building blocks, and second, an endogenous model for the ``death rate'' of existing applications. Lexis, on the other hand, is more general and more abstract, and captures how a time-varying set of regular expressions can be constructed hierarchically from a time-varying alphabet, re-using simpler regular expressions as much as possible.<br\/>The Stratum and Lexis models are initial steps towards developing a base understanding of what factors influence the evolvability and sustainability of protocols. With this base in place, further domain-specific insight can be developed and yield targeted guidelines for the design of future network protocols.<br\/><br\/>Broader Impact: There are currently four large NSF-funded Future Internet Architecture (FIA) projects that pursue a ``clean-slate'' design approach for a future Internet that is more robust, secure, evolvable, etc. A goal of this research is to both inform and learn from the efforts of the four FIA projects.<br\/><br\/>The broader impact of this project also includes the release of two extensible simulators (corresponding to Stratum and Lexis) that will allow students and instructors to experiment with how network architectures evolve in dynamic environments and under optimization objectives and constraints. No such tools are available today.<br\/><br\/>Additionally, this project has a significant inter-disciplinary component in both its ?inputs and outputs.? Specifically, much of the prior work behind this research (inputs) has originated in economics, physics and evolutionary biology. Conversely, the project's results (outputs) are likely to be relevant to other disciplines such as software engineering, smart manufacturing and the science of organizations.","title":"NeTS: SMALL: Collaborative Research: Protocol Stacks Design and Evolution: The Role of Layering and Modularity","awardID":"1319549","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[550447],"PO":["565090"]},"208429":{"abstract":"The emergence of large-scale Internet applications and services has driven a surge in research on cloud platforms, virtualization, data center architectures, and green computing. However, realistic performance evaluation of new research prototypes continues to be a major challenge. Home-grown performance evaluation tools that are often used by researchers are no longer able to capture the complexity of today's real systems and applications. To address this drawback, the project seeks to develop BenchLab, an open, flexible community infrastructure comprising applications, workloads and tools to enable realistic performance evaluation and benchmarking by systems researchers. BenchLab is an open framework where source code and workload datasets are freely available for modification and use by researchers for their specific experiments. The framework consists of a suite of server-side benchmark applications and workloads that represent cloud, mobile web, and green computing environments. BenchLab employs a modular, extensible architecture that is designed to support a range of server applications and workloads, with the ability to add support for newer applications and workloads and retire outdated ones. BenchLab is designed to be easy to use for experimental systems research \"at scale\" in commercial clouds, such as Amazon EC2, or virtualized clusters in laboratory settings. <br\/> BenchLab will provide open tools and workloads for the research community to enable researchers to run larger and more realistic performance evaluation experiments that better emulate today's real-word systems. BenchLab will be incorporated into hands-on lab assignments to teach students the science and art of experimental performance evaluation.","title":"S12-SSE: BenchLab: Open Community Tools and Infrastructure for Performance Research in Cloud, Mobile and Green Computing","awardID":"1339839","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":[558563,558564],"PO":["565247"]},"210992":{"abstract":"Introduction\/Motivation: Synthetic Biology moves beyond conventional genetic manipulation to construct novel biological components which do not originate in nature. There still exists though a big gap of knowledge between genomic sequence and function. To enhance understanding of gene expression, researchers have constructed and evaluated libraries of gene variants, which traditionally have limited size due to synthesis costs, and random or biased composition. Valuable insights have been gained, but precise control of expression in redesigned synthetic genes remains elusive.<br\/>The proposed algorithmic research involves combinatorial design of synthetic gene variants to aid the construction of large scale, purposed libraries. The aim is to assay the most important sequence features which determine gene expression, while minimizing experimental cost and maximizing the exploration of the coding landscape. Proposed design, synthesis and wet-lab evaluation of reporter gene variants with modified characteristics will help determine their quantitative effect on expression in a model organism and validate our algorithmic designs.<br\/><br\/>Intellectual merit: Upon successful completion, this project will make major advances in the computational and life sciences, through new algorithmic results in combinatorial design of diverse gene libraries with minimized cost, and fundamental discoveries regarding gene expression. PIs expect their design methodologies to fuel an array of new discoveries by enabling high throughput cost effective experiments to study the effects of sequence features of genes and pathways, and help gain important insights by comparing experimental observations with long standing computational and theoretical models.<br\/><br\/>Broader Impact: The algorithms and software developed with this award will be used to design the next generation of large-scale synthetic construct experiments, which will enable optimized redesign of genetic elements to be transferred from one organism to another, adapting to an altogether different environment. The primary impact will ultimately rest with the science done using these techniques, such as drug and chemical synthesizing microorganisms with improved yields, rapidly produced vaccines, and CO2 transforming micro-algae. The educational impact includes active promotion of computational and synthetic biology in lectures towards graduate and undergraduate students, and dissemination of research findings and data through web accessible repositories.","title":"EAGER: Algorithms for Synthetic Gene Library Design","awardID":"1418874","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7931","name":"COMPUTATIONAL BIOLOGY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7946","name":"BIO COMPUTING"}}],"PIcoPI":[565222],"PO":[565223]},"202830":{"abstract":"Model-Driven Development (MDD) is an approach to software development that is gaining traction world-wide. The Repository for Model-Driven Development (ReMoDD) is a resource that has been developed to facilitate and accelerate research and education in MDD through the sharing of high quality modeling experiences. ReMoDD provides facilities for curating, querying, and operating on models. The first version was developed under a prior NSF grant and currently supports a broad and growing community of Software Engineering researchers, practitioners, educators, and students. New requirements emerging from the community of developers and users are the basis for this new grant. The project will significantly improve ReMoDD as follows: (1) To help attract more artifacts from industry, we will provide facilities that can be used to sanitize models so that valuable proprietary information is obfuscated; (2) to help attract artifacts that demonstrate the application of MDD methods on industrial software development problems, we will provide facilities for industry\/academia collaborations on industry-relevant challenge problems; (3) to extend the scope of relevant artifacts that can be accessed via ReMoDD, we will work with developers of related repositories (e.g., the European Open Models Initiative) so that searches in ReMoDD will yield artifacts stored in collaborating repositories; and (4) we will extend ReMoDD with social networking features that support, for example, crowd sourcing challenging modeling problems. The enhancement of ReMoDD will be a collaborative effort involving teams from Colorado State University (CSU) and Michigan State University (MSU). ReMoDD has an Advisory Board of leading MDD researchers and industry representatives that are committed to ensuring that ReMoDD continues to be a useful and sustainable community resource. <br\/><br\/>By providing ReMoDD as MDD community infrastructure, groups performing MDD research will advance the overarching objective of Model Driven software Development (MDD), which is to reduce the cost and effort of developing complex software systems through the use of software models. The problems tackled by MDD researchers are challenging and good solutions typically evolve through a community process driven by feedback from the use of solutions in research and industrial settings. The project will strengthen engagement with the international research community, who will contribute new ideas, share tools, and share in the project effort. To support the international collaboration, this award is being co-funded by NSF?s Office of International and Integrative Activities.","title":"Collaborative Research: CI-ADDO-EN: Research Repository for Model-Driven Software Development (REMODD)","awardID":"1305381","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":[543603,"557996"],"PO":["564388"]},"210211":{"abstract":"This project studies the design of robust bio-inspired Wireless Sensor Networks (B-WSN) by leveraging optimal results from nature?s computation. Functional robustness of living organisms is often attributed to the optimized structures of their gene regulatory networks (GRNs), which oversee the proper behavior of cells through interactions among different genes. GRNs can adapt to dynamic changes (i.e., perturbations) in the environment, and are resilient to the removal\/malfunction of nodes in the network. This project will identify the features intrinsic to GRN based robustness and fault-tolerance and apply them to bio-inspired wireless sensor networks. In particular, teh project will devise suitable mapping between GRNs and WSNs to form the basis of our B-WSN testbed to assess network level robustness of biological systems. The B-WSN will be designed to act as an in silico testbed, where each node can be monitored and GRN-based routing topologies can be modi&#64257;ed so that it is possible to demonstrate how speci&#64257;c topological aspects contribute to the robustness of complex systems.","title":"CSR: EAGER: Exploring Biological Network Robustness using Bio-Inspired Wireless Sensor Networks: A Novel Paradigm for Systems Research","awardID":"1353111","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[563362],"PO":["565255"]},"205833":{"abstract":"Distributed in-network data processing aims to reduce energy consumed for communication and establish a self-contained data storage, retrieval, aggregation, and query sensor system. Previous research focuses on two-dimensional (2D) wireless sensor networks where a 2D planar setting is assumed. Compared with sensor networks deployed on 2D plane, it is significantly more challenging to support in-network data processing in three-dimensional (3D) wireless sensor networks. This project aims to explore distributed in-network data storage and retrieval in a 3D wireless sensor network, especially one that is deployed in an irregular region with potential coverage holes.<br\/><br\/>The proposed research will apply geometric and topological tools to investigate and develop different schemes for constructing geographic hash table-based and double-ruling based information storage and retrieval in general 3D sensor networks. The designed algorithms ensure the success and accuracy of data retrieval, well-balanced load across the network, limited information stored at individual nodes, and distributed operations. A testbed will be established for experimental exploration and evaluation.<br\/><br\/>This project helps to extend distributed in-network data processing from 2D sensor networks to 3D, in support of a range of future applications in diverse disciplines that demand sensors to be deployed in three dimensional space. It also enriches the engineering curriculum to integrate the theory of computational geometry and topology with practical systems. The PIs will continue the effort in improving female presence in computer science.","title":"NeTS: Small: Distributed In-network Data Storage and Retrieval in 3D Wireless Sensor Networks","awardID":"1320931","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[551058,551059],"PO":["565303"]},"202214":{"abstract":"The goal of this project is to develop a new framework where teams of mobile robots self-engineer the structure of their communication network in order to improve on the performance of distributed algorithms used for team coordination. The key idea that enables this work is the representation of the network structure in terms of metrics that depend on the full eigenvalue spectrum of the network's adjacency and Laplacian matrices, but can be approximated in a very efficient and decentralized way. These metrics can then be related to the performance of popular, distributed, coordination algorithms, such as consensus, gossiping, and viral information dissemination. The intellectual merit of this research lies in the development of a hybrid network of mobile robots that is controlled jointly in the space of network configurations and robot positions. The study of the integrated system requires the synthesis of new theoretical results drawing from control theory, spectral graph theory, wireless networking, and optimization. This hybrid network combines the following interrelated objectives: Spectral analysis and distributed control of robot networks; Integrated network and mobility control; Richer models of the communication space; Platform deployment and validation.<br\/><br\/>Successful completion of this research will provide these necessary components in facilitating the design of mobile autonomous systems and fostering their adoption. Wide availability of such systems can have a significant societal impact on, e.g., search, rescue and recovery operations, environmental monitoring for homeland security, or surveillance and reconnaissance missions. The broader impact of this project lies on disseminating the research output in the industry and academia.","title":"NeTS: Medium: Collaborative Research: Optimal Communication for Faster Sensor Network Coordination","awardID":"1302284","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[541930],"PO":["565303"]},"206702":{"abstract":"A hybrid system is a dynamical model that describes the coupled evolution of both continuous-valued variables and discrete patterns. A prime example of such a system is a power electronic circuit, where the semiconductor transistors behave as ideal switches whose switching actions effectively change the circuit topology (i.e., the discrete pattern) that in turn defines the dynamics of currents and voltages (i.e., the continuous variables) and hence the switching actions. There have been two disparate paths to analyzing and designing hybrid systems. One path is to focus on the discrete patterns and achieve scalable, high-level analysis and synthesis. The other path is to pay attention to the dynamics of continuous variables and guarantee low-level properties such as stability and transient performance. The research objective of this proposal is to bridge these approaches by enabling a synergy between the discrete pattern based and continuous variable based approaches. The theory and algorithms developed in course of this work will be applied to digital control of power electronic circuits in order to overcome the scalability and stability issues suffered by existing approaches to power electronics design.<br\/><br\/>The PIs envision that a successful completion of the project will establish a new paradigm in the analysis and design of hybrid systems, and thus contribute to the needs of modern society, such as microgrids and embedded generation, where power electronic circuits are integral parts. The research will be integrated into educational programs through student mentoring and development of courses and laboratory equipment. The PIs will make a special effort to recruit women and minority students. These broader-impact programs will help innovate science and engineering education and prepare for next-generation CPS scientists and engineers.","title":"CPS: Synergy: Collaborative Research: Digital Control of Hybrid Systems via Simulation and Bisimulation","awardID":"1329422","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[553438,"553440",553440],"PO":["562984"]},"205734":{"abstract":"Network configuration and management today is a complex and error-prone task, done by expert administrators, who implement policies as a brittle composition of independent control rules on heterogeneous devices. Networks become stifled, as changes to configuration have hard-to-predict consequences in the resulting policies. At the same time, there is pressure in the opposite direction for more dynamic networks, as increasingly distributed applications can benefit from network flexibility, and actually have information about the semantics of their traffic that can inform network configuration. <br\/><br\/>The goal of this project is to enable end-user applications to take active part in the configuration, provisioning, and management of the network, and, in turn, have more visibility into the network state to better reconfigure themselves. The proposed approach, Participatory Software Defined Networking, aims to be a unifying and extensible framework to expose network control mechanisms and state to end-user applications. It leverages the emerging paradigm of Software Defined Networking, with its logically centralized and programmable control plane, and, in an analogy to Operating Systems, provides the \"user-level system calls to the network\". Applications request current and future service properties, gain visibility into network properties, and provide hints about future demands to the network. The research will combine programming languages techniques to define the semantics of policy and query language and compilation, with systems design and experiments on a real programmable network testbed, guided by real applications.<br\/><br\/>Intellectual Merit: The contributions of this project are to expose the control plane of the network to end-user applications through a unifying and extensible framework, to solve the challenges to make this safe and efficient, and ultimately to allow for radical joint optimization of applications and the network. More specifically, this work will: (1) define the semantics for the delegation of privileges necessary for the safe exposure of the control plane to end-user applications. (2) define a high level hierarchical representation of policies, with flexible semantics for policy composition from different users, across several network resources. (3) produce a sound compilation strategy from the high level combined policies to efficient sets of distributed rules on switches and (4) propose and evaluate the joint optimization of applications and the network given the flexibilities and requirements of the former, and the constraints and load of the latter.<br\/><br\/>Broader Impacts: The results of the proposed research will be broadly applicable to regular network users, with direct, tangible benefits in efficiency, security, sharing, and ease of use of the networking infrastructure. Participatory networking will enable home users (or their applications, on the users' behalf), to effectively configure the network according to intuitive policies. Network queries can provide the foundation for a ubiquitous \"weather service\" for networks, which can have positive effects on user expectations. Heavy users on campus networks, such as physicists, will be able to safely share the network without the need for physically separate networks. Enterprise users will be able to install firewall rules deeper in the network without requiring human intervention. Co-optimization of applications and datacenter networks will enable significantly more efficient large-scale data processing, helping advance science and business at large. The PI will integrate undergraduate students in the research, and will create a course on Advanced Networking focused on SDNs and in datacenters. He will continue to speak about networking and the Internet to the 9th-grade girls at the NSF-sponsored Artemis program.","title":"NeTS: Small: Participatory Software Defined Networking","awardID":"1320397","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[550830],"PO":["565090"]},"204777":{"abstract":"The domain name system (DNS) protocol plays a significant role in operation of the Internet by enabling the bi-directional association of domain names with IP addresses. It is also increasingly abused by malware, particularly botnets, by use of: (1) automated domain generation algorithms for rendezvous with a command-and-control (C&C) server, (2) DNS fast flux as a way to hide the location of malicious servers, and (3) DNS as a carrier channel for C&C communications. This project explores the development of a scalable, hierarchical machine-learning stack, called HIMALAYAS, which specializes in algorithms for automatically mining DNS data for malware activity. In particular, we are interested in isolating both ordered and unordered sets of malware domain groups whose access patterns are temporally and logically correlated. <br\/><br\/>HIMALAYAS performs a task of increasing complexity at each level - starting from scalable clustering and feature selection at lower levels, to more advanced malware domain subsequence identification algorithms at higher levels. It has multiple benefits, including speed, accuracy, interpretability, and ability to use domain knowledge, which makes it very well suited for malware analysis and related tasks. The analysis by HIMALAYAS should accelerate the identification and takedown of malware domains on the Internet and improve services such as Google SafeSearch. <br\/><br\/>The machine-learning stack developed as part of the HIMALAYAS project has broader application to many important data mining problems, e.g., in financial data analysis, and mining user patterns from web access logs. The project provides opportunities for students to participate in the development and transition of the technology.","title":"TWC: Medium: Collaborative: HIMALAYAS: Hierarchical Machine Learning Stack for Fine-Grained Analysis of Malware Domain Groups","awardID":"1314956","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[548388,548389],"PO":["565239"]},"205515":{"abstract":"Application-level, aka ``flash-DDoS'' attacks are the most challenging form of distributed denial of service (DDoS). They flood the victim with legitimate-like service requests generated from numerous bots. There is no defense today that is even remotely effective against flash-DDoS attacks, thus such attacks are today a serious and unmitigated threat to any server.<br\/><br\/>Our project works on developing defenses against flash-DDoS attacks that can pinpoint traffic sent by automated bots and differentiate it from human-generated traffic. Bot IPs are then blacklisted and their traffic filtered protecting the server under attack without any damage to legitimate users. Our project develops novel technologies called ASTUTE (pASsive TUring TEsts) to distinguish bots from human users, by modeling three aspects of human user behavior: (1) dynamics of human-server interaction, (2) human preference for server content, and (3) human processing of visual and textual cues. IP addresses of detected bots will be blacklisted and their traffic will be dropped during server overload. ASTUTE technologies model human behavior without conscious human participation, thus performing Turing tests (human vs machine differentiation) transparently to humans. <br\/><br\/>We will implement all our code as extensions of popular open-source server platforms, such as Apache (for Web) and bind (for DNS). At the end of this work we will deliver working prototypes of these extensions, thus our research will directly transition into practice for any interested party at no cost to them. All our code will be released as open-source under the GNU GPL v3 license.","title":"TWC: Option: Small: FRADE: Model Human Behavior for Flash cRowd Attack DEfense","awardID":"1319215","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[550312,550313],"PO":["564223"]},"206736":{"abstract":"This project investigates a new type of cyber-physical system (CPS), comprising magnetic nanoparticles in a fluidic environment such as human tissue whose motion is controlled by a computer via a magnetic field. The research aims to develop computational and experimental tools to perform the dynamic modeling, closed loop control and experimental validation of such a system of nanoparticles under guidance and observation using a magnetic resonance imaging (MRI) environment. The envisioned CPS infrastructure is composed of a new computational platform to perform 3D simulation, visualization and post-processing analysis of the aggregation and disaggregation process of magnetic nanoparticles within a fluidic environment like the small arteries and arterioles or fluid-filled cavities of the human body. It also includes the development of robust control algorithms for the guidance of a swarm of magnetic nanoparticles in a MRI environment. Experimental validation is to be performed in clinical MRI scanners and in customized laboratory test-beds that generate controllable magnetic fields able to move magnetic nanoparticles in fluidic environments. <br\/><br\/>Potential applications of this basic research include nano-robotic drug delivery systems, composed of a system of magnetic nanoparticles guided by MRI scanners for targeted drug delivery in the human body. The project integrates education through participation of graduate and undergraduate students in the research, and involvement of the PI and graduate students in several outreach activities for students in high and middle schools.","title":"CPS: Breakthrough: A Cyber-Physical Framework for Magnetic Resonance Imaging (MRI) Guided Magnetic NanoParticles","awardID":"1329649","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["561575"],"PO":["564778"]},"205405":{"abstract":"It is generally recognized that protecting online privacy is important, with modern society manifesting this concern in many ways. Preliminary research indicates that third parties, with modest crawling and computational resources, and employing simple data mining heuristics, can potentially combine online services and publicly available information to create detailed profiles of the users living in any targeted geographical area.<br\/><br\/>This research investigates measures that can significantly improve privacy protection of users, while not degrading their overall Internet experience. The focus is on less-trustworthy third parties (e.g., data brokers, advertisers, spammers, malware distributors, and pedophiles), who can scrape, aggregate and infer information from many different online and offline sources. This research has two interrelated research thrusts. First, it explores to what extent third parties can collect, aggregate, and statistically process information from OSNs and other online and offline sources to create profiles. This thrust is developing rigorous statistical methodologies and probabilistic models for estimating the degree of potential privacy leakage. Second, this research investigates a variety of privacy policies that governments can establish, and a wide range of measures OSNs can take, to reduce the privacy risk. For promising combinations of policies and measures, this research quantifies the trade-off between privacy protection and usability.","title":"TWC SBE: Small: Protecting the Online Privacy of Users of Social Networks","awardID":"1318659","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[550020],"PO":["562974"]},"205526":{"abstract":"Years of effort to develop algorithms capable of learning from reward signals have resulted in a plethora of techniques that can leverage numerical signals that vary in value based on performance. Recent efforts to use these techniques to learn from humans providing rewards have been slower to progress, in part, because humans give feedback discretely rather than numerically. This project contributes new learning algorithms designed specifically to leverage the information contained in the choices humans make to provide such discrete feedbacks. The algorithms are inspired by the human-canine partnership, and the incredible things that humans are able to teach dogs using only discrete feedback and carefully constructed sequences of tasks. The Bayesian learning framework being developed in this project will leverage the pragmatic implicatures contained in the feedbacks and tasks sequences to learn more quickly from human feedback. <br\/><br\/>The ultimate goal of this work is to provide a more natural paradigm for humans to tell computers what they would like for them to do. To that end, project efforts will result in a teaching module for Brown University?s Learning Exchange (LE). The LE involves undergraduates working with underserved minority middle school students to engage them in STEM. They are a perfect audience to demonstrate the broader impacts of this work. LE participants learn to instruct computers using a combination of programming with the Scratch environment and the feedback paradigm, which shows how powerful the algorithms are.","title":"RI: Small: Collaborative Research: Speeding Up Learning through Modeling the Pragmatics of Training","awardID":"1319305","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["553568"],"PO":["565035"]},"206626":{"abstract":"This work will advance human-robot partnerships by establishing a new concept called complementary situational awareness (CSA), which is the simultaneous perception and use of the environment and operational constraints for task execution. The proposed CSA is transformative because it ushers in a new era of human-robot partnerships where robots act as our partners, not only in manipulation, but in perception and control. This research will establish the foundations for CSA to enable multifaceted human-robot partnerships. Three main research objectives guide this effort: 1) Real-time Sensing during Task Execution: design low-level control algorithms providing wire-actuated or flexible continuum robots with sensory awareness by supporting force sensing, exploration, and modulated force interaction in flexible unstructured environments; 2) Situational Awareness Modeling: prescribe information fusion and simultaneous localization and mapping (SLAM) algorithms suitable for surgical planning and in-vivo surgical plan adaptation; 3) Telemanipulation based on CSA: Design, construct, and integrate robotic testbeds with telemanipulation algorithms that use SLAM and exploration data for online adaptation of assistive telemanipulation virtual fixtures. This research also includes investigation of previously unaddressed questions on how sensory exploration and palpation data can be used to enable online-adaptation of assistive virtual fixtures based on force and stiffness data while also taking into account preoperative data and intraoperative correction of registration parameters.<br\/><br\/>The proposed work will restore the situational awareness readily available in open surgery to minimally invasive surgery. This will benefit patients by enabling core technologies for effective and safe natural orifice surgery or single port access surgery. The societal impact of the proposed work on these two surgical paradigms is reduced pain for patients, shorter hospital stay, improved cosmesis and patients' self image, and lower costs. We also believe that CSA will impact manufacturing where its future will require people and robots working together in a shared space on collaborative tasks. Also, the same concepts of CSA apply to telemanipulation in constrained and unstructured environments and the proposed research has direct relevance to robot-human partnerships for space exploration. To ensure this broader impact will be achieved, an advisory board has been assembled with experts from medicine, manufacturing and aerospace. Finally, the PIs will facilitate collaboration in the medical robotics research community by making our software and hardware designs available on-line and using commercial-grade hardware available at multiple institutions.","title":"NRI: Large: Collaborative Research: Complementary Situational Awareness for Human-Robot Partnerships","awardID":"1327597","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":[553216],"PO":["564069"]},"205658":{"abstract":"The proliferation of personal mobile computing devices along with a plethora of data-intensive mobile applications has resulted in a tremendous increase in demand for ubiquitous and high-data-rate wireless communications over the last few years. Additional deployment and maintenance of a large number of stand-alone cellular Base Stations (BSs) to meet the growing capacity demand are highly inefficient due to excessive capital and operating expenditures. Presently, multiple Radio Access Networks (RANs), each composed of geographically proximal BSs, are statically configured and deployed; such an approach, however, does not allow for any margin to handling the fluctuations in capacity demands due to the ever transforming mobile applications landscape and unexpected events such as emergencies. Cloud-RAN (C-RAN), composed of Remote Radio Units (RRUs) distributed over a wide geographic region controlled by remote Virtual Base Stations (VBSs) housed in centralized BS pools, is a new paradigm for broadband wireless access to address the fluctuation in capacity demand efficiently.<br\/><br\/>This research focuses on designing a dynamic reconfigurable cellular communication system that relies on elastic VBSs, which can be dynamically resized to meet the fluctuations in per-user capacity demands. This elasticity enables improvements in user Quality of Service (QoS) and efficiency in energy and computing resource utilization in C-RANs. However, Virtual Machine (VM) provisioning, i.e., determining the ?size? of VMs that hold VBSs, as well as appropriate allocation of VMs to physical servers are non-trivial challenges. The tasks of this project consist in the design and development of (i) a demand-aware dynamic VM provisioning algorithm that relies on an offline profiling of the computational complexity and memory footprint of the communication functionalities implemented in software; (ii) a QoS-aware VM allocation algorithm that exploits VBS co-location models; (iii) a C-RAN testbed on virtualized enterprise-class servers for validation of the profiling and allocation solutions through emulation campaigns.<br\/><br\/>This work will generate computer-literate undergraduate and graduate researchers with a comprehensive knowledge of energy-efficient design and management of computing resources. The PI will create new teaching modules on elastic resource allocation, provide opportunities for exchange programs, leverage existing minority student outreach networks at Rutgers University, and incorporate student exchange programs.","title":"NeTS: Small: Demand-Aware Dynamic Virtual Base Station Provisioning and Allocation in Cloud Radio Access Networks (C-RANs)","awardID":"1319945","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[550654],"PO":["565303"]},"205669":{"abstract":"This project encompasses design, implementation, and experimental evaluation of an operating system (OS) targeted specifically for compute nodes in \"cloud\" data centers. Cloud computing offers a chance to rethink OS design, as the goal is not a desktop system but rather an efficient building block for large clusters that support networked applications. The proposed OS acts as a \"dumb\" node in a cluster, taking commands from an external cluster manager and handing out resources to applications as appropriate. This, plus the use of relatively few devices and no graphical user interface, means it need only support a small fraction of traditional OS features. Instead the focus is on high performance with many cores, performance isolation, remote control, and tiers of service. <br\/><br\/>The operating system mechanisms explored in this project have potential to improve data center efficiency, both by improving single-node efficiency, and by making it easier to leverage underutilized nodes for batch processing and large-scale data analysis without hindering latency-sensitive applications. For greater impact, the project will release the source code of the developed OS as free, open-source software. An earlier version of the operating system that focused on enabling many-core parallelism has already been released. The new OS has potential uses for education as well for exploring higher-level cluster OS ideas. In addition, the principal investigator will leverage Berkeley's SUPERB program to bring in underrepresented undergraduate students for an 8-week summer research experience.","title":"CSR: Small: A Node OS for High-Performance Cloud Computing","awardID":"1320005","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[550677],"PO":["564778"]},"206769":{"abstract":"This cross-disciplinary project brings together a team of engineering and computer science researchers to create, validate, and demonstrate the value of new techniques for ensuring that systems composed of combinations of hardware, software, and humans are designed to operate in a truly synergistic and safe fashion. One notable and increasingly common feature of these \"Cyber-Physical-Human\" (CPH) systems is that the responsibility for safe operation and performance is typically shared by increasingly sophisticated automation in the form of hardware and software, and humans who direct and oversee the behavior of automation yet may need to intervene to take over manual or shared system control when unexpected environmental situations or hardware or software failures occur. The ultimate goal is to achieve levels of safety and performance in system operation that exceed the levels attainable by either skilled human operators or completely autonomous systems acting alone. To do so, the research team will draw upon their expertise in the design of robust, fault-tolerant control systems, in the design of complexity-reduction architectures for software verification, and in human factors techniques for cognitive modeling to assure high levels of human situation awareness through effective interface design. By doing so, the safety, cost and performance benefits of increasingly sophisticated automation can be achieved without the frequently observed safety risks caused by automation creating greater distance between human operators and system operation. The techniques will be iteratively created and empirically evaluated using experimentation in human-in-the-loop simulations, including a medium-fidelity aircraft and flight simulator and a simulation of assistive automation in a medical context.<br\/><br\/>More broadly, this research is expected to impact and inform the engineering of future CPH systems generally, for all industries and systems characterized by an increasing use of hardware and software automation directed and overseen by humans who provide an additional layer of safety in expected situations, Examples include highway and automotive automation, aerospace and air traffic control automation, semi-automated process control systems, and the many forms of automated systems and devices increasingly being used in medical contexts, such as the ICU and operating room. This research is also expected to inform government and industry efforts to provide safety certification criteria for the technologies used in CPH systems, and to educate a next generation of students trained in the cross-disciplinary skills and abilities needed to engineer the CPH systems of the future. The investigators will organize industry, academic, and government workshops to disseminate results and mentor students who are members of underrepresented groups through the course of this research project.","title":"CPS: Synergy: Collaborative Research: Engineering Safety-Critical Cyber-Physical-Human Systems","awardID":"1329870","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[553620],"PO":["562984"]},"205207":{"abstract":"The human vision system understands and interprets complex scenes for a wide range of visual tasks in real-time while consuming less than 20 Watts of power. This Expeditions-in-Computing project explores holistic design of machine vision systems that have the potential to approach and eventually exceed the capabilities of human vision systems. This will enable the next generation of machine vision systems to not only record images but also understand visual content. Such smart machine vision systems will have a multi-faceted impact on society, including visual aids for visually impaired persons, driver assistance for reducing automotive accidents, and augmented reality for enhanced shopping, travel, and safety. The transformative nature of the research will inspire and train a new generation of students in inter-disciplinary work that spans neuroscience, computing and engineering discipline.<br\/><br\/>While several machine vision systems today can each successfully perform one or a few human tasks ? such as detecting human faces in point-and-shoot cameras ? they are still limited in their ability to perform a wide range of visual tasks, to operate in complex, cluttered environments, and to provide reasoning for their decisions. In contrast, the mammalian visual cortex excels in a broad variety of goal-oriented cognitive tasks, and is at least three orders of magnitude more energy efficient than customized state-of-the-art machine vision systems. The proposed research envisions a holistic design of a machine vision system that will approach the cognitive abilities of the human cortex, by developing a comprehensive solution consisting of vision algorithms, hardware design, human-machine interfaces, and information storage. The project aims to understand the fundamental mechanisms used in the visual cortex to enable the design of new vision algorithms and hardware fabrics that can improve power, speed, flexibility, and recognition accuracies relative to existing machine vision systems. Towards this goal, the project proposes an ambitious inter-disciplinary research agenda that will (i) understand goal-directed visual attention mechanisms in the brain to design task-driven vision algorithms; (ii) develop vision theory and algorithms that scale in performance with increasing complexity of a scene; (iii) integrate complementary approaches in biological and machine vision techniques; (iv) develop a new-genre of computing architectures inspired by advances in both the understanding of the visual cortex and the emergence of electronic devices; and (v) design human-computer interfaces that will effectively assist end-users while preserving privacy and maximizing utility. These advances will allow us to replace current-day cameras with cognitive visual systems that more intelligently analyze and understand complex scenes, and dynamically interact with users.<br\/><br\/>Machine vision systems that understand and interact with their environment in ways similar to humans will enable new transformative applications. The project will develop experimental platforms to: (1) assist visually impaired people; (2) enhance driver attention; and (3) augment reality to provide enhanced experience for retail shopping or a vacation visit, and enhanced safety for critical public infrastructure. This project will result in education and research artifacts that will be disseminated widely through a web portal and via online lecture delivery. The resulting artifacts and prototypes will enhance successful ongoing outreach programs to under-represented minorities and the general public, such as museum exhibits, science fairs, and a summer camp aimed at K-12 students. It will also spur similar new outreach efforts at other partner locations. The project will help identify and develop course material and projects directed at instilling interest in computing fields for students in four-year colleges. Partnerships with two Hispanic serving institutes, industry, national labs and international projects are also planned.","title":"Collaborative Research: Visual Cortex on Silicon","awardID":"1317414","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[549481],"PO":["565227"]},"205339":{"abstract":"Software development is a complex and manual process, in part because typical software programs contain more than hundreds of thousands lines of computer code. If software programmers fail to perform critical checks in that code, such as making sure a user is authorized to update an account, serious security compromises ensue. Indeed, vulnerable software is one of the leading causes of cyber security problems. Checking for security problems is very expensive because it requires examining computer code for security mistakes, and such a process requires significant manual effort. This research project aims at developing an interactive help system to warn software programmers about potential security mistakes, similar to the way modern word processors warn writers of spelling and grammar errors. This is likely lead to new functions for software development tools that will significantly reduce security vulnerabilities in software.<br\/><br\/>The research is based on the concept of interactive static analysis, a novel mixed-initiative paradigm for interacting with programmers to aid in the detection and prevention of security vulnerabilities. Static analysis is seamlessly integrated into the development environment in such a way that programmers are not required to learn additional programming language and analysis concepts beyond the use of the development environment. Static analysis is performed in the context of development, allowing programmers to utilize and influence such analysis during their program construction. The goals of this research are to bring programmers into the security loop, improving their ability to detect, understand, and prevent vulnerabilities; and utilize the programmer's contextual knowledge to drive customized static analysis, detecting software vulnerabilities that are difficult to detect using current static analysis techniques.","title":"TWC: Small: Collaborative: Discovering Software Vulnerabilities through Interactive Static Analysis","awardID":"1318323","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["549910"],"PO":["564388"]},"204701":{"abstract":"The domain name system (DNS) protocol plays a significant role in operation of the Internet by enabling the bi-directional association of domain names with IP addresses. It is also increasingly abused by malware, particularly botnets, by use of: (1) automated domain generation algorithms for rendezvous with a command-and-control (C&C) server, (2) DNS fast flux as a way to hide the location of malicious servers, and (3) DNS as a carrier channel for C&C communications.<br\/>This project explores the development of a scalable, hierarchical machine-learning stack, called HIMALAYAS, which specializes in algorithms for automatically mining DNS data for malware activity. In particular, we are interested in isolating both ordered and unordered sets of malware domain groups whose access patterns are temporally and logically correlated. <br\/><br\/>HIMALAYAS performs a task of increasing complexity at each level ? starting from scalable clustering and feature selection at lower levels, to more advanced malware domain subsequence identification algorithms at higher levels. It has multiple benefits, including speed, accuracy, interpretability, and ability to use domain knowledge, which makes it very well suited for malware analysis and related tasks. The analysis by HIMALAYAS should accelerate the identification and takedown of malware domains on the Internet and improve services such as Google SafeSearch. <br\/><br\/>The machine-learning stack developed as part of the HIMALAYAS project has broader application to many important data mining problems, e.g., in financial data analysis, and mining user patterns from web access logs. The project provides opportunities for students to participate in the development and transition of the technology.","title":"TWC: Medium: Collaborative: HIMALAYAS: Hierarchical Machine Learning Stack for Fine-Grained Analysis of Malware Domain Groups","awardID":"1314560","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["557452"],"PO":["565239"]},"204712":{"abstract":"Wireless connectivity has become the primary way most users access cyberspace. The wide use of the internet on wireless and mobile devices is further encouraged with new services that simultaneously engage and connect a large number of users. As a result, the society at large is quickly getting comfortable with the idea of conducting everyday lives on mobile devices most of which require communicating sensitive and confidential information over the wireless medium. Consequently, secure access to cyberspace necessitates wireless security. Wireless, being an open medium, is more prone to malicious cyber acts as compared to wired connectivity. On the other hand, this medium also presents unique opportunities to provide security guarantees through the interaction of nodes and advanced physical layer techniques. In particular, information theoretic security emerges with design insights that provide guaranteed security against computationally unlimited adversaries. In order to do so, information theory assumes a network of altruistic nodes and looks for fundamental performance limits which usually come with complex interaction and coordination requirements. The premise of this project is that this idealistic set-up can be successfully transformed into a practical one by amalgamating information theory with the theory of incentives in order to provide secure wireless cyber access.<br\/><br\/>Specific research topics being addressed include the development of: (1) mechanisms to incentivize non-altruistic cognitive nodes to participate in information theoretic security protocols; (2) incentive mechanisms for scenarios where all nodes have equal access to spectrum and need confidentiality, even from each other; (3) techniques for providing security to groups of cooperative nodes and the associated trust issues; (4) incentive mechanisms for combating active attacks; (5) strategies for combating colluding adversaries; and (6) mechanisms to ensure that nodes have the incentive to adopt a given security protocol.<br\/><br\/>Broader impacts of this work include: (1) providing secure access to cyberspace via the wireless medium; (2) new design insights for practical security protocols; and (3) amalgamating information theory and game theory via incentive mechanisms. Educational broader impacts include: (1) dissemination of research results in the form of tutorials and short courses; (2) enhancing graduate-student research experiences via a three-university research exchange program; (3) incorporating the research results into graduate and undergraduate communications courses; and (4) recruitment of and mentorship for women in engineering and science.","title":"TWC SBE: Medium: Collaborative: Incentive Compatible Wireless Security","awardID":"1314620","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["560218"],"PO":["565239"]},"204734":{"abstract":"Wireless connectivity has become the primary way most users access cyberspace. The wide use of the internet on wireless and mobile devices is further encouraged with new services that simultaneously engage and connect a large number of users. As a result, the society at large is quickly getting comfortable with the idea of conducting everyday lives on mobile devices most of which require communicating sensitive and confidential information over the wireless medium. Consequently, secure access to cyberspace necessitates wireless security. Wireless, being an open medium, is more prone to malicious cyber acts as compared to wired connectivity. On the other hand, this medium also presents unique opportunities to provide security guarantees through the interaction of nodes and advanced physical layer techniques. In particular, information theoretic security emerges with design insights that provide guaranteed security against computationally unlimited adversaries. In order to do so, information theory assumes a network of altruistic nodes and looks for fundamental performance limits which usually come with complex interaction and coordination requirements. The premise of this project is that this idealistic set-up can be successfully transformed into a practical one by amalgamating information theory with the theory of incentives in order to provide secure wireless cyber access.<br\/><br\/>Specific research topics being addressed include the development of: (1) mechanisms to incentivize non-altruistic cognitive nodes to participate in information theoretic security protocols; (2) incentive mechanisms for scenarios where all nodes have equal access to spectrum and need confidentiality, even from each other; (3) techniques for providing security to groups of cooperative nodes and the associated trust issues; (4) incentive mechanisms for combating active attacks; (5) strategies for combating colluding adversaries; and (6) mechanisms to ensure that nodes have the incentive to adopt a given security protocol.<br\/><br\/>Broader impacts of this work include: (1) providing secure access to cyberspace via the wireless medium; (2) new design insights for practical security protocols; and (3) amalgamating information theory and game theory via incentive mechanisms. Educational broader impacts include: (1) dissemination of research results in the form of tutorials and short courses; (2) enhancing graduate-student research experiences via a three-university research exchange program; (3) incorporating the research results into graduate and undergraduate communications courses; and (4) recruitment of and mentorship for women in engineering and science.","title":"TWC SBE: Medium: Collaborative: Incentive Compatible Wireless Security","awardID":"1314733","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[548269],"PO":["565239"]},"205724":{"abstract":"This project is pursuing a novel strategy for video segmentation based on the decomposition of a video into multiple overlapping segments of pixels, and the subsequent composition of these segments into hypotheses about the existence of objects within the video. Given an input video, this approach produces a set of spatio-temporal pixel regions as its output, where the set of output regions has a high degree of overlap with the objects that are present in the video. The project further develops methods for semantic segmentation, occlusion analysis, and activity recognition which can exploit a segment-based video representation. The basis for the approach is a statistical framework known as composite likelihood, which implicitly models the joint distribution of a random vector through distributions of low-dimensional statistics on overlapping subsets of variables. This statistical model is ideally-suited to describing video objects as a collection of multiple overlapping segments. Using this framework, methods are being developed to track overlapping segments within a video and generate object hypotheses. Additional efforts are aimed at improving the computational efficiency of the approach in order to address applications in on-line video analysis.<br\/><br\/>The resulting algorithms yield improved performance in video object segmentation and tracking, and provide new approaches to content-based video categorization and retrieval, for unstructured video collections such as those found on YouTube. The project is producing a novel publicly-available dataset containing fine-grained ground truth video object segmentations, in order to facilitate research activities in video analysis. The project is integrated with education and outreaches high school students to research in STEM.","title":"RI: Small: A Compositional Approach to Video Segmentation","awardID":"1320348","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[550806,550807],"PO":["564316"]},"205845":{"abstract":"The project will develop rigorous and fast (practical) graph-theoretic genome-wide algorithms associated with genome sequence data and graphs within an integrated set of research and educational activities designed to intertwine synergistically with statistical modeling; apply these to the solution of real-world problems and long-standing computer science and mathematics questions that impact molecular biology; and make these techniques accessible to students, researchers, and practitioners in the corresponding fields. The project focuses on algorithms for haplotype reconstruction from genome sequence data of various organisms and genomes having different polyploidy number, i.e., number of haplotypes. The mammalian genomes, human included, are diploid genomes. However, the polyploidy number varies across the life spectrum from 1 (bacteria) to more than 100 (adder's-tongue fern). The HapCompass graph-theoretic framework associates genome sequencing read mappings with the genome-wide SNP data in the human genome.The HapCompass algorithm uses local optimization algorithms on the spanning tree cycle basis of HapCompass graphs for objective functions that model various measures of error correction in haplotype reconstruction. Earlier work provided a combinatorial framework for error-correction models for diploid haplotype assembly, a framework embraced by the large literature on the topic in the following decade. The fundamental case of diploid genomes and the HapCompass graph theory, data structures and algorithms set the stage for generalizations to polyploidy and integrative genome-wide haplotype reconstruction in samples of individuals that share haplotypic regions identical by descent. In addition, curriculum development is plan that covers the topics from both a computing and the user perspective. All materials and software, source code, and documentation will be available. Software will rely on the open-source model.<br\/><br\/>This project intertwines computer science with statistical models and an impact in genomics and molecular biology. Faster and more accurate algorithms for diploid haplotype assembly based on multi-criteria optimization using multiple models of error correction on the spanning-tree cycle bases of compass graphs will be developed. In addition, robust generalizations of the graph theory and algorithms for polyploid genomes that permit a common algorithmic strategy are planned. The team also is developing an optimal linear time algorithm for shared IBD tract identification in the case of phased genotype data, and efficient and exact algorithms for IBD haplotype tract identification for shared IBD tracts in unphased genotype data that are linear in the number of haplotypes and subquadratic in the number of genotypes to enhance efficiency. The final product of the work will be an algorithmic framework for genome-wide haplotype reconstruction created by combining the new algorithms and Clark Consistency Graph data structures and algorithms.","title":"III: Small: Genome-Wide Algorithms for Haplotype Reconstruction and Beyond: A Combined Haplotype Assembly and Identical-by-Descent Tracts Approach","awardID":"1321000","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[551092],"PO":["565136"]},"205735":{"abstract":"This research takes advantage of the synergy between 3D integration and the Vertical Slit Field Effect Transistor (VeSFET)-based Integrated Circuits (ICs) paradigm. Because further scaling of flat circuits is becoming less profitable, building circuits from vertically stacked multiple active layers seems to be a viable option of delivering continuously improved performance. VeSFET with its unique properties appears to be a uniquely suited transistor to serve as a basis for 3D ICs. It is expected that in terms of heat removal, noise control, power distribution, and testability, VeSFET-based realization of 3D integration will be superior to the traditional 3D CMOS technology. To support this claim, appropriate physical design exploration and thermal management tools will be developed. <br\/><br\/>If successful, the methodologies and techniques developed during the course of this research may have a large impact on the IC manufacturing and designing practices. It is possible that VeSFET-based 3D ICs will delay the necessity of using sophisticated cooling techniques and dark silicon by two to three technology nodes as compared to conventional technologies. It is also likely that this research will result in convincing mainstream chip manufacturers that it is economically viable to produce 3D integrated circuits on the basis of VeSFET. Women and minority students will be encouraged to participate in the research program.","title":"SHF: Small: Assessing VeSFET Technology for 3-D Integration","awardID":"1320401","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":[550832],"PO":["562984"]},"205856":{"abstract":"As critical applications are converging onto the Internet, effective response to large-scale network dynamics like failures and demand spikes is gaining more importance. Major portion of the time for handling such network dynamics is determining how to respond, mostly performed manually in the current practice. Experienced human administrators are typically the ones who can quickly find a close-to-optimum response. However, as the networks are getting larger and more diverse, managing and attaining effective responses for an online operational network necessitates meta-tools to swiftly learn and characterize the network. <br\/><br\/>This project will develop tools for automated management of a running network by framing heuristic optimization, empirical learning, experimental design, and network management with a simulation interface. The project will develop an online management and experimentation system for large-scale networks in an environment that enables trainee administrators to explore what-if scenarios, without having to risk the network operation. The project will also develop algorithms for empirical characterization of network dynamics, and tools for quick and close-to-optimal configuration of numerous network parameters in response to failures or customer traffic trends.<br\/><br\/>The project will integrate behavioral scientific concepts into the practice of operational network management. The automated management using online optimization may establish a foundation for managing multi-owner systems, e.g., power grid, transportation, and water infrastructure networks. The project's heuristic optimization and experiment design methods as well as the approach to operator training are applicable to training in safety and mission critical industries where mistakes of ill-trained administrators are intolerable, e.g., airline pilot and nuclear reactor administrator training.","title":"NeTS: Small: Online Management, Experimentation, and GAme (OMEGA) of Large-Scale Networks","awardID":"1321069","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[551119,"551169"],"PO":["564993"]},"202226":{"abstract":"After decades of reliable improvement, processor speeds have<br\/>flattened; for the foreseeable future, computers will add processing<br\/>power by adding more processors, rather than faster ones. This is a<br\/>tremendous challenge for software designers. It's far too easy for<br\/>software using multiple processors to burn up a growing fraction of<br\/>available processing power on coordination overheads like locking,<br\/>rather than actual work. That is, it's far too easy for software to<br\/>not scale: to get slower as processors are added. And an important<br\/>reason for this is simply that scalability is poorly understood. Some<br\/>programs don't scale because they're badly written, but others don't<br\/>scale because their goals are fundamentally impossible to accomplish<br\/>in a scalable way. Programmers lack effective tools for high-level<br\/>reasoning about software scalability limitations, and thus waste<br\/>effort on both impossible and uninteresting tasks.<br\/><br\/>We will produce the first well-grounded and formal reasoning procedure<br\/>for scalability that is flexible enough to apply to an entire<br\/>operating system. Our scalability rule links commutativity and<br\/>scalability. We characterize software interfaces as more or less<br\/>inherently scalable depending on the contexts in which those<br\/>interfaces commute: the more commutative an interface (that is, the<br\/>more often the order of its function calls doesn't matter), the more<br\/>scalable an implementation can be. We prove that a scalable<br\/>implementation exists for any commutative context. This idea can<br\/>already guide software designers in developing easily-scalable<br\/>interfaces, but we will also provide a set of automated tools for<br\/>measuring interface commutativity and for finding implementation<br\/>scalability bottlenecks, and evaluate our ideas in a highly-scalable<br\/>operating system. The resulting tools and ideas could make scalable<br\/>software far easier to design and program, and thus help software<br\/>designers provide the software performance on which so much of our<br\/>economy depends.","title":"CSR: Medium: Collaborative Research: The Commutativity Rule for Scalable System Software","awardID":"1302359","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[541961],"PO":["565255"]},"205867":{"abstract":"This work develops a novel receiver methodology to integrate signal detection and forward<br\/>error correction in multiple-input-multiple-output (MIMO) communications and various diversity<br\/>transmissions. Moving beyond traditional approaches relying on belief-propagation, this<br\/>investigation into the rather classic open problem of integrated signal detection and decoding<br\/>involves novel joint optimization formulations that incorporate binary field parity constraints<br\/>imposed by the low-density parity check within maximum likelihood detection frameworks for<br\/>unified optimization. This novel framework is general and encompasses a number of practical<br\/>transmission models, including distributed antennas, opportunistic cooperative networking,<br\/>and signal retransmission as well as their integrations. This project has broad impacts on<br\/>engineering, education, and society. Its success can lead to new research directions, new<br\/>tools, and results to help advance other science and engineering fields.<br\/><br\/>Focusing on multicarrier MIMO signal reception, the investigators will develop and optimize<br\/>integrated receivers for important wireless network diversities including distributed<br\/>transmissions, cooperative MIMO, and hybrid-ARQ retransmission systems. The new design<br\/>methodology emphasizes integration of multiple constraints from incompatible fields. By<br\/>reformulating and relaxing joint detection and decoding problems into convex optimization, the<br\/>investigators will design high performance receivers that are efficient and are robust to various<br\/>forms of uncertainties in channel state information. Such a novel approach to receiver design<br\/>integration represents a fundamental and practical design paradigm that can fully utilize<br\/>various a priori signaling and code constraints for joint detection and decoding against channel<br\/>distortions and other non-idealities to achieve high performance, efficiency, and reliability. The<br\/>research findings can contribute practically to improvement of future wireless services and<br\/>broaden their applications in many practical fields where quality, efficiency, and distributivity<br\/>concerns are paramount.","title":"CIF: Small: Optimized Receiver Design Integration for Diversity and Cooperative Transmissions Beyond Belief Propagation","awardID":"1321143","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7936","name":"SIGNAL PROCESSING"}}],"PIcoPI":[551148],"PO":["564898"]},"205879":{"abstract":"This project seeks to improve the performance of a wide verity of memory-constrained object-oriented applications by automatically recycling objects. Large-scale, object-oriented software commonly suffers from systemic performance problems, due to inefficiencies inherent in an object-oriented language as well as commonly-adopted design and implementation principles. These problems are becoming increasingly critical as object-oriented languages are used in systems that typically have small memory space and computation power, such as mobile devices. In such systems, memory inefficiencies inherent in an object-oriented language can lead to severe performance degradation and reduced scalability. Evidence suggests that excessive object creation is a major source of inefficiencies in memory-constrained object-oriented applications. Object recycling reduces this object creation overhead. Recycling is achieved by designing and implementing runtime system support that can cache objects upon their creation, detect unreachable objects from the cache, and reuse both instances and data content of dead objects.<br\/><br\/>Modern life relies increasingly on memory-constrained systems such as smartphones, tablets, and data-analytical tools. This project provides an immediate performance benefit for such memory-constrained systems, thereby leading to improved quality, usability, and user satisfaction. In addition, the research represents a first step in a new direction for the research community to explore, and may provoke further interests in automating, other important (currently manually-enforced) optimizations. The impact of the research is extended by a strategy of open-source licensing and distribution of the resulting software through the OpenJDK and Android communities. The educational component of this project includes creation of new course materials, recruitment of undergraduate students and students from under-represented groups, and education of local programmers on how to develop highly-efficient memory-constrained applications.","title":"CSR: Small: Runtime System Support for Automated Object Recycling","awardID":"1321179","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[551177],"PO":["564778"]},"206638":{"abstract":"Motivated by the complementary abilities of humans and humanoids, the objective of this proposal is to develop the science and technology necessary for realizing human-robot cooperative object manipulation and transportation. The key concepts that this research seeks to promote are adaptability to human activity under minimal communication, and robustness to variability and uncertainty in the environment, achieved through a layered representation and deliberate processing of the available information. Moreover, this project aims to make maximum use of a minimal set of sensors to plan and control the actions of the robot, while ensuring safe and efficient cooperative transportation. The embodiment of this research is a humanoid co-worker that bears most of the load, when helping a person to carry an object, without requiring excessive communication, or prior training on the part of the human.<br\/><br\/>By introducing concrete methods for human-robot physical collaboration in semi-structured environments, this project enables a unique synergy between robots and humans that has the potential to increase productivity, and reduce accidents and injuries. In doing so, it also promotes the advancement of new practical applications of robots in construction, manufacturing, logistics, and home services. By developing open-source, portable algorithms for humanoid robots and mobile manipulators, this effort results in cost and time savings for researchers, developers, educators, and end-users in robotics. Finally, through an aggressive educational and community outreach plan, and by actively engaging K-12 students in an exciting RoboTech Fellows program, this project seeks to increase diversity and attract underrepresented groups to STEM.","title":"NRI: Large: Collaborative Research: Human-robot Coordinated Manipulation and Transportation of Large Objects","awardID":"1328018","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":[553248],"PO":["564316"]},"205428":{"abstract":"Retrospection is the ability of a data store to run ad-hoc programs over consistent past states of a data store as if they were the current state. Retrospection makes it easier to analyze past states providing a valuable tool for auditors, historians, economists, social scientists and others with a need to investigate historical data. Retrospection is also valuable to those who want to analyze past states to predict the future, an increasingly in-demand feature in modern data management applications.<br\/><br\/>Most light-weight data stores today do not support retrospection. The key reason is that existing retrospection techniques, for performance, require invasive hard-to-adopt modifications to data store internals. Without support for retrospection, it may be hard for application developers to reconstruct the consistent states corresponding to past events of interest.<br\/><br\/>This project will develop an easy-to-adopt modular method and a set of associated techniques for supporting retrospection in light-weight transactional data stores using an<br\/>embedded persistent consistent past-state system. The technical challenges are:<br\/>1) How to provide consistent past states without harming data store performance? The past state system needs to be tightly integrated for efficiency but extensive modifications to the internal data store components are infeasible, requiring new modular techniques that operate at a low-level in the data store software stack.<br\/>2) How to run programs efficiently over past state that spans large time intervals? past state needs to be created incrementally to avoid disrupting the data store but running a program over incremental state can be slow, requiring new clustering and caching techniques optimized for incremental data.<br\/>3) Can one avoid slowing down programs that do not use retrospection? To evaluate any additional overhead, the project will develop an experimental prototype in an industrial strength data store, and conduct studies to answer this question experimentally and analytically.","title":"CSR: Small: Efficient Techniques for Modular Past State Systems","awardID":"1318798","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[550086],"PO":["565255"]},"199884":{"abstract":"The Schloss Dagstuhl - Leibniz Center for Informatics is one of the leading computer science research centers worldwide. Dagstuhl hosts more than 3000 internationally renowned researchers each year in Germany, in seminars on the important topics and the recent developments in computer science and its application to science, technology, and society. Many of these seminars are organized with the participation of researchers from the United States. <br\/><br\/>This award provides support for the participation of US-based junior faculty researchers in the Dagstuhl seminars and activities. It offers them the opportunity to meet the leading scientists in the world in a collegial setting during the weeklong seminars and gain valuable experience with the larger scientific community. It is a competitive process of selection, providing support for an estimated 80 scholarships annually for three years, open to all Dagstuhl seminars.","title":"Schloss Dagstuhl Support Grant for Junior Researchers","awardID":"1257011","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[535880],"PO":["565239"]},"209619":{"abstract":"This NSF-FDA Scholar-In-Residence award supports translational research in modeling to inform future medical device design and approval processes. It is supported by the NSF Cyber-Physical Systems program in the Division of Computer and Network Systems in the Directorate for Computer and Information Science and Engineering.<br\/><br\/>Sudden cardiac death is the leading cause of fatalities in the industrialized world. One in five people in the United States is affected by some sort of heart disease and one third of all deaths are due to cardiac diseases with an economic impact of about $200 billion a year. Most of these deaths result from arrhythmias, particularly fibrillation, which is rapid, disorganized electrical activity. The classification of arrhythmias as either reentrant or focal is of clinical significance, yet is difficult to assess. The FDA is responsible for regulating the systems and algorithms that aim to make this important differentiation. Such differentiation is a complex task involving the analysis of complex spatio-temporal patterns of electrical activity. The objectives of this project are to identify the key features of fibrillation that models should represent, to compare how well (or poorly) existing models correspond to measured values of these features, and to develop models that better represent fibrillation. The project develops and extends cell and tissue models and explores the analysis of clinical, experimental and simulation data from the perspective of regulatory science at the FDA, including verification, validation, and uncertainty quantification (VVUQ). The project seeks to 1) validate and create new models that reproduce not only single-cell dynamics, but also experimental and clinically relevant physiological dynamics in tissue and 2) initiate a new developmental framework that the FDA can use not only to test cardiac electrophysiology devices but also to characterize and verify massive submissions of therapeutic compounds obtained by computer-aided drug design methods. The research is conducted in collaboration with the Center for Devices and Radiological Health at FDA, and is aimed at developing tools that can characterize and evaluate real-world performance of devices. This will help the FDA to better regulate and verify the safety and effectiveness of devices that are developed to treat and terminate cardiac arrhythmias. All results from this project will be made freely available to the research community and to the general public.","title":"Development, verification, and validation of computer models of cardiac fibrillation","awardID":"1347015","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[561887,561888],"PO":[561889]},"210147":{"abstract":"Moving Target defense (MTD) is a new Cybersecurity paradigm for deterring and disturbing attacks proactively in order to counter the ?asymmetry? phenomena in cyber warfare. A number of moving target techniques have been recently proposed to inverse this asymmetry by randomizing systems? attributes (e.g., configuration) and exhibiting non-determinism to attackers. However, due to potential inter-dependency between various MTD mechanisms, an ad hoc combination of MTD techniques can cause profoundly detrimental effect on security, performance and the operational integrity of the system.<br\/><br\/>This project is investigating novel and transformative approaches to formulate a prescriptive framework to instantiate new MTD strategies that are correct-by-construction, from an arbitrary list of MTD mechanisms. The proposed framework enables integrating MTD mechanisms vertically, or horizontally, while balancing the benefit and cost of the synthesized integrated MTD strategy. As a case study, two main classes of MTD mechanisms, namely, Host Configuration Mutation and Network Configuration Mutation, are integrated to create a cohesive and more powerful composite MTD mechanism.<br\/><br\/>To this end, the results of this research enable new theoretical foundations and transformative approaches in the science of moving target defense by contributing to the understanding of automated reasoning for moving target defense synthesis and evaluation. As this far-forward looking EAGER proposal exhibits high-risk, it also entails high-value that is to be always many steps ahead of attackers. Through the development of a framework for reasoning about MTD, MTD course modules will be developed. The software artifacts permit for further experimentation and progress in this area.","title":"EAGER: Toward Automated Integration of Moving Target Defense Techniques","awardID":"1352238","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[563217],"PO":["565327"]},"205802":{"abstract":"Flash memory manufactures are aggressively scaling up NAND flash density in order to increase capacity and reduce the cost per gigabyte using either MLC (multi-level cell) or TLC (triple level cell) technologies. However, other metrics like reliability, endurance, and performance are all declining. As a result, developing a high-performance and highly reliable embedded flash storage system on top of increasingly larger but inferior NAND flash memory devices has become both indispensable and challenging. Utilizing a holistic approach from hardware re-architecting to software redesign, this project designs, implements, and evaluates a new flash storage system for emerging and future data-intensive mobile applications such as wireless healthcare and live sport broadcast. In particular, this project will replace the existing single-device hardware organization with a multiple-device array architecture. Next, this project will develop a new flash file system that can access multiple flash memory devices in parallel. Also, a wide spectrum of new techniques including garbage collection method, wear levelling mechanism, ECC protection, and data recovery scheme will be developed. Finally, a hardware prototype that can empirically evaluate the new flash device array architecture and all software modules will be built. The new flash file system including source code and documents, all new techniques, and the hardware prototype, the outcomes of this project, will be released to the public. This project will also promote teaching, learning, and training by exposing students to technological and scientific underpinnings in the field of mobile storage systems.","title":"CSR: Small: A Device-Array Based Flash Storage System for Emerging Data-Intensive and Mission-Critical Mobile Applications: from Architecture Redesign to New File System","awardID":"1320738","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["562727"],"PO":["565255"]},"210279":{"abstract":"The tremendous growth of information in the data-intensive world and a new wave of big data are creating a promising future for global ultra-large-scale data sharing, where widely-scattered massive data will be pooled and shared globally. A distributed data intensive information system is a critical component for realizing this future. The system will allow users to efficiently and effectively search similar data. However, the unprecedented amount of data, along with the large-scale environment and autonomous nature of participants pose high efficiency and effectiveness challenges to the development of such a system. This research will provide collaborative research opportunities for faculty, graduate and undergraduate students, as well as K-12 students in South Carolina.<br\/><br\/>A growing need persists for developing an efficient and effective information searching system, and this challenge represents one of the more formidable hurdles facing data-intensive computing. This proposal is aimed at addressing this need through the development of a distributed information system supporting efficient and effective data searching. This system achieves both high efficiency and effectiveness. Efficiency means the speed and overhead of sorting and searching date, while effectiveness means the ability to find all matching data in the system with fewer false positives and false negatives. This system translates data items to IDs, maps the data items to nodes in a distributed system and enables the similarity searching in a distributed manner. First, previous data translation methods relying on a multi-dimensional space to hash a data item to one index achieve high efficiency but suffer from low effectiveness due to the curse of dimensionality in data dimension reduction. Previous exact mapping methods that hash each keyword of a data item for data search are highly effective but inefficient. By eliminating the need of a multi-dimensional space, this system is both highly efficient and effective. Second, unlike some previous systems relying on a centralized or hierarchical structure for data searching, this system builds a distributed hash table (DHT) structure, which provides highly efficient data searching in a distributed manner. Unlike most traditional DHT-based data sharing which provides only exact matching services, this system offers similarity searching.","title":"EAGER: An Efficient and Effective Distributed Information System","awardID":"1354123","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8083","name":"Big Data Science &Engineering"}}],"PIcoPI":[563519],"PO":["565136"]},"205714":{"abstract":"In cognitive radio networks, to avoid interference with licensed users, unlicensed users must vacate the spectrum accessed by the primary users. Since it takes some time for the unlicensed users to detect and switch to other available spectrum, the ongoing data transmission may have to be interrupted, leading to poor data access performance. Although there is a lot of research on cognitive radio networks, not much work has been done on data access. This project focuses on three intertwined issues to support resilient and efficient data access: (i) Various topology control protocols which carefully assign communication channels considering network robustness and channel interference to achieve better data accessibility, are designed and evaluated; (ii) Delay-constrained caching techniques are introduced to deal with primary user appearance, where data is cached\/replicated at appropriate nodes to statistically limit the data access delay; (iii) Spectrum-aware data replication schemes are designed to improve data access performance in intermittently connected cognitive radio networks, by considering both node mobility pattern and primary user appearance. This project will make significant theoretical and technological advances in understanding and supporting resilient and efficient data access in cognitive radio networks. The success of this project is likely to have a broader impact on making cognitive radio networks more affordable and amenable to commercial, civilian, and military applications. The results of the project will be disseminated widely through high quality publications and presentations. The proposed research will also be integrated with the education curricula at the Pennsylvania State University.","title":"NeTS: Small: Resilient and Efficient Data Access in Cognitive Radio Networks","awardID":"1320278","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[550785],"PO":["557315"]},"205857":{"abstract":"In this Cyberlearning: Transforming Education EXP project, the PIs focus on designing classrooms as collaborative workspaces and learning how such learning environments can foster learning well. They are addressing these issues in high school mathematics classrooms. Learners view videos and read textbooks as homework to begin to learn new content and to deepen their understanding of material already covered. The classroom is \"flipped\"; rather than the teacher lecturing, the teacher plays the role of mentor and facilitator as learners work in the classroom at making sense of what they've read or heard, applying what they are learning, and deepening their understanding and capabilities. The hard work of learning is thus done along their peers as collaborators and the teacher available as a mentor. Based on cognitive and socio-cognitive theories of learning, the PIs have designed an ensemble of strategies and technological tools for promoting learning in such an environment. The tools include video for story telling in support of reflection, electronic pen-and-ink, and intelligent-tutoring type systems, but the innovation is in the integration of these tools into an ensemble. Research addresses how such an ensemble of technologies can foster deeply absorbing and effective learning experiences and important dynamics associated with learning when collaborative workspaces are in place in formal classrooms.<br\/><br\/>Many educators and educational theorists are experimenting with the idea of \"flipped classrooms,\" where learners read or view video lectures outside of class and spend classroom time working on problems together or working on projects, in effect, using classroom time for making sense together of what is being learned, applying what is being learned, deepening understanding, and mastering capabilities. While such an approach holds promise for promoting engagement and learning, little systematic research has been done about how, exactly, to design such learning environments to best promote deep and engaged learning. The PIs in this project address that issue, focusing specifically on students learning high school mathematics.","title":"EXP: Collaborative Research: A cyber-ensemble of inversion, immersion, collaborative workspaces, query and media-making in mathematics classrooms","awardID":"1321071","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":[551122,551123],"PO":["562669"]},"204768":{"abstract":"OpenSSH reveals excerpts from encrypted login sessions. TLS (HTTPS) reveals encrypted PayPal account cookies. DTLS is no better. EAXprime allows instantaneous forgeries. RFID security has been broken again and again. All of these failures of confidentiality and integrity are failures of authenticated ciphers: algorithms that promise to encrypt and authenticate messages using a shared secret key.<br\/><br\/>It is easy to blame many of these security problems on a lack of education: much stronger authenticated ciphers have been in the literature for many years. However, in many cases these stronger authenticated ciphers fail to meet the performance requirements of the applications. Performance is exactly the motivation for RC4 in WEP; EAXprime in the \"Smart Grid\"; HB in RFID; and \"IPsec\" continuing to support unauthenticated encryption.<br\/><br\/>This project is building a new generation of authenticated ciphers that improve efficiency without compromising security and that improve security without compromising efficiency. This work spans seven main topics: more efficient ciphers; more efficient MACs; more efficient forgery rejection; improved protection against side channels; improved protection against misuse and bad luck; improved quantitative security; and improved security proofs. The ultimate objective is to obtain the best possible security subject to a variety of performance constraints specified by cryptographic users.<br\/><br\/>The high-security high-performance authenticated ciphers produced in this project will be directly and straightforwardly usable in cryptographic applications, avoiding the disasters in current applications and finally bringing secure secret-key cryptography from theory to practice.","title":"TWC: Option: Medium: Collaborative: Authenticated Ciphers","awardID":"1314919","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[548359],"PO":["565239"]},"205626":{"abstract":"Data centers have become both significant consumers of electricity and substantial sources of greenhouse gas emissions, and so a focus on energy-efficient computing has emerged. Until now, the most common approach for improving sustainability of data centers is a ?local? one, e.g., installing rooftop PV panels. This project takes a different, more ?global? approach: it allows data centers to contribute towards improving the sustainability of the electricity grid as a whole, in order to meet data centers' social responsibility as major energy consumers. Interestingly, engaging in such global sustainability efforts will, in turn, provide data centers with new opportunities to gain financial benefits.<br\/><br\/>This project will coordinate data centers with the smart grid through programs such as demand response, which allow the utilities to signal consumers to reduce or increase consumption as needed in order to stabilize the grid and tackle the unpredictability of the renewable energy resources. New resource management algorithms for data centers will be developed to facilitate their participation in demand response and other electricity market programs; and the responsiveness that data centers can provide the smart grid through such participation will be quantified and optimized.<br\/><br\/>This proposal is truly interdisciplinary as it requires a deep understanding not only about data centers and cloud computing but also about electricity markets and the smart grid. In particular, the results will help data centers in terms of both their choice of which electricity market programs to participate in and how to participate in such programs. Additionally, this project will help utility companies in the design of electricity market programs that encourage maximum data center responsiveness to better operate the grid and to reduce the price of electricity.","title":"CSR: Small:Collaborative Research: Data Center Demand Response: Coordinating the Cloud and the Smart Grid","awardID":"1319798","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[550580],"PO":["565255"]},"205868":{"abstract":"In this Cyberlearning: Transforming Education EXP project, a collaborative team of assessment specialists, learning scientists, K12 educators, educational technologisst, and informal science educators are exploring the design and feasibility of a tool called the Learning Lens, a mobile multi-media tool for gathering data in the midst of learning activities that can shed light on learners' capabilities and understanding and the interactions between learners and educators. The system's design is informed by ideas of evidence-based assessment; it is designed to allow a user to collect the kinds of data that can be used to support arguments about what learners understand and are capable of, including formal products of learners, their presentations or explanations, discussions among peers, and interactions with people and objects in the learning environment.<br\/><br\/>Such a tool could play important roles in the the education of education practitioners. Pre-service and in-service teachers might gather data sporadically in their classrooms to use in discussions with others about their practice. Or, those observing educators in practice might gather data to be used later in reflecting on educational practices. <br\/><br\/>As well, such a tool holds promise for enhancing assessment. While paper-and-pencil testing can be used to assess understanding and some disciplinary skills, it is quite a bit more challenging to objectively assess complex social, communication, reasoning, and meta-cognitive skills. The Learning Lens is being developed to promote evidence-based analysis of such skills. With the tool, researchers or teacher observers or teachers themselves would collect data showing what learners understand or can do. Such data capture holds promise for allowing educators and researchers to iteratively and collaboratively document learner development, develop assessment rubrics, track students' real-time growth in situ, and identify outcomes of pedagogical moves and tactics.","title":"EXP: Learning Lens: An Evidence-Centered Tool for 21st Century Assessment","awardID":"1321145","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7645","name":"DISCOVERY RESEARCH K-12"}}],"PIcoPI":[551150,551151,551152],"PO":["562669"]},"206628":{"abstract":"Motivated by the complementary abilities of humans and humanoids, the objective of this proposal is to develop the science and technology necessary for realizing human-robot cooperative object manipulation and transportation. The key concepts that this research seeks to promote are adaptability to human activity under minimal communication, and robustness to variability and uncertainty in the environment, achieved through a layered representation and deliberate processing of the available information. Moreover, this project aims to make maximum use of a minimal set of sensors to plan and control the actions of the robot, while ensuring safe and efficient cooperative transportation. The embodiment of this research is a humanoid co-worker that bears most of the load, when helping a person to carry an object, without requiring excessive communication, or prior training on the part of the human.<br\/><br\/>By introducing concrete methods for human-robot physical collaboration in semi-structured environments, this project enables a unique synergy between robots and humans that has the potential to increase productivity, and reduce accidents and injuries. In doing so, it also promotes the advancement of new practical applications of robots in construction, manufacturing, logistics, and home services. By developing open-source, portable algorithms for humanoid robots and mobile manipulators, this effort results in cost and time savings for researchers, developers, educators, and end-users in robotics. Finally, through an aggressive educational and community outreach plan, and by actively engaging K-12 students in an exciting RoboTech Fellows program, this project seeks to increase diversity and attract underrepresented groups to STEM.","title":"NRI: Large: Collaborative Research: Human-robot Coordinated Manipulation and Transportation of Large Objects","awardID":"1327614","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":[553221],"PO":["564316"]},"202822":{"abstract":"This award provides funding for a new institutional Computing Research Infrastructure (CRI) project focused on residential energy research at the University of Virginia. Recent studies have demonstrated great potential for applications of embedded sensing and control in the home environment. However, research in this area is limited by the inability to experiment beyond small scale field tests and pilot studies. The BetaHome Network is a new residential sensing testbed that includes an array of homes with extensive and semi-permanent instrumentation of the electrical, water, and HVAC systems. The testbed captures several dimensions of variability in homes that are not captured by one-off field tests and small pilot studies. Additionally, and perhaps most importantly, the BetaHome Network system tracks and records the locations of occupants within the home, in relation to the energy, water, and HVAC events that are also being recorded. This unique sensing testbed provides a complete, real-time picture of both occupancy and energy usage in the home with unprecedented detail about the internal happenings of the home. The testbed enables several new types of studies that were heretofore impractical, including cross-sectional analytics and controlled intervention studies. The project enables research on novel techniques for (i) occupancy and energy monitoring in homes (ii) personalized energy feedback (iii) intelligent thermostat control (iv) low-cost energy audits, and (v) intelligent fixture-driven water heating.<br\/><br\/>The research infrastructure created by this project enables research on new home monitoring and energy efficiency technologies, focusing on practical and low-cost solutions that can be readily translated to market. For example, preliminary studies demonstrated a 28% reduction per household in the energy required for heating and cooling, at the cost of only $25 in additional sensors per home. This project opens a new realm for residential ``living laboratories'' that enhance the infrastructure for research and education in the area of energy-efficient technologies, helping to propel the nation towards its goal of a 70% improvement in the total energy efficiency of existing buildings across the country by 2030. New courses are being developed as a result of this infrastructure and both graduate and undergraduate researchers are involved in new research. The project is producing a new data set of unprecedented detail that can be used as benchmarks for the energy monitoring community to enable research and inspire future generations of researchers to study science and engineering by illustrating its applied nature and potential for social benefit.","title":"II-NEW: The BetaHome Network: A Multi-Home Testbed for Smart Building Technology","awardID":"1305362","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[543576],"PO":["564778"]},"210247":{"abstract":"The project supports 5 scholarships to enable attendance by students and junior faculty of the diversity workshop organized by the PI along with the upcoming SoSP conference. The workshop will be held on Nov 3 in Farmington, PA. The goal of the workshop is to strengthen the pipeline of systems students, providing them with advice and networking opportunities that they might not otherwise receive.","title":"Travel Support for The 6th Workshop on Diversity in Systems Research (Diversity '13)","awardID":"1353771","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[563444],"PO":["565255"]},"204725":{"abstract":"Both sound software verification techniques and heuristic software<br\/>flaw-finding tools benefit from the presence of software annotations<br\/>that describe the behavior of software components. Function summaries<br\/>(in the form of logical annotations) allow modular checking of software<br\/>and more precise reasoning. However, such annotations are difficult to<br\/>write and not commonly produced by software developers, despite their<br\/>benefits to static analysis.<br\/><br\/>The Crowdsourcing Annotations project will address this deficiency by<br\/>encouraging software-community-based crowd-sourced generation of<br\/>annotations. This effort will be supported by tools that generate, use,<br\/>and translate the annotations; the results of annotation efforts will be<br\/>shared through openly available repositories. We will also use pilot<br\/>projects to demonstrate and encourage the use of annotations and static<br\/>analysis. The project will leverage and interact with the Software Assurance Marketplace (SWAMP)<br\/>project's collection of static analysis tools and example software. Some<br\/>of the technical challenges are developing uniform styles and languages<br\/>for annotations, reliably validating crowd-sourced submissions, merging<br\/>annotations and the corresponding source code, version control, and<br\/>integration with typical software development environments. The social<br\/>challenges are also important: designing and implementing a<br\/>crowd-sourcing infrastructure in a way that enhances and motivates<br\/>community and individual technical and social benefits.","title":"TTP: Medium: Crowd Sourcing Annotations","awardID":"1314674","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[548249],"PO":[548250]},"202206":{"abstract":"The most significant performance and energy bottlenecks in a computer are<br\/>often caused by the storage system, because the gap between storage device<br\/>and CPU speeds is greater than in any other part of the machine. Big data<br\/>and new storage media only make things worse, because today's systems are<br\/>still optimized for legacy workloads and hard disks. The team at Stony<br\/>Brook University, Harvard University, and Harvey Mudd College has shown that<br\/>large systems are poorly optimized, resulting in waste that increases<br\/>computing costs, slows scientific progress, and jeopardizes the nation's<br\/>energy independence.<br\/><br\/>First, the team is examining modern workloads running on a variety of<br\/>platforms, including individual computers, large compute farms, and a<br\/>next-generation infrastructure, such as Stony Brook's Reality Deck, a<br\/>massive gigapixel visualization facility. These workloads produce combined<br\/>performance and energy traces that are being released to the community.<br\/><br\/>Second, the team is applying techniques such as statistical feature<br\/>extraction, Hidden Markov Modeling, data-mining, and conditional likelihood<br\/>maximization to analyze these data sets and traces. The Reality Deck is<br\/>used to visualize the resulting multi-dimensional performance\/energy data<br\/>sets. The team's analyses reveal fundamental phenomena and principles that<br\/>inform future designs.<br\/><br\/>Third, the findings from the first two efforts are being combined to develop<br\/>new storage architectures that best balance performance and energy under<br\/>different workloads when used with modern devices, such as solid-state<br\/>drives (SSDs), phase-change memories, etc. The designs leverage the team's<br\/>work on storage-optimized algorithms, multi-tier storage, and new optimized<br\/>data structures.","title":"CSR: Medium: Collaborative Research: Workload-Aware Storage Architectures for Optimal Performance and Energy Efficiency","awardID":"1302246","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[541908,"543574"],"PO":["565255"]},"205847":{"abstract":"Configuration errors (i.e., misconfiguration) are a major cause of system failures according to several studies. For example, misconfiguration has caused serious crashes and center-wide outages in a number of data centers and commercial cloud infrastructures affecting millions of customers. In addition to system down time, misconfiguration also wastes engineers' or administrators' time in troubleshooting and corrections, leading to significant maintenance and support costs.<br\/><br\/>Although recent work on detecting misconfiguration has improved the situation to some degree, the fundamental root cause needs to be better addressed. Based on the insights gained from the PIs' recent empirical study on 546 real world configuration errors in commercial and open source systems, the intellectual merit of this project is to take a more fundamental approach to addressing misconfiguration problems from the root cause in a proactive, anticipatory way. This work has three objectives: (1) to improve configuration design to make them less error-prone; (2) to harden software systems to better tolerate and gracefully react to users' configuration errors; and (3) to detect hard-to-check configuration issues such as compatibility and cross-component parameter inconsistency.<br\/><br\/>The broader impacts include significantly reducing the amount of system downtime in data centers, decreasing vendors' customer support cost for troubleshooting configuration issues, and planned educational, outreach, and broadening participation activities.","title":"CSR: Small: Proactive Methods in Handling Configuration Errors in Data Centers and Cloud Infrastructures","awardID":"1321006","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[551097],"PO":["565255"]},"205858":{"abstract":"Online social networks (OSNs) such as Facebook and LinkedIn are valuable infrastructures for communication and interactions between a large volume of Internet users. For years, researchers have been trying to answer fundamental questions about the formation of these complex networks, their ongoing evolution, formation of internal structures, and change at different time scales. Since answering these questions requires real dynamics datasets at scale, most prior studies have been significantly constrained by a lack of data. The Principal Investigators have been granted access by an OSN provider to a uniquely detailed and complete trace of dynamics over 2+ years of a social network. The goal is to mine and analyze the traces of network dynamics to validate existing models and guide new models for fine grain network dynamics. Objectives include analysis of the preferential attachment model at different stages of network growth, developing new models of network dynamics at fine granularity in both time and graph topology, and explorations of applications driven by novel metrics of graph dynamics.<br\/><br\/>The work has the potential to dramatically change our understanding of dynamics in online social networks. By taking an empirical, data-driven approach to network modeling, they can shed light on how traditional models of network dynamics deviate from ground truth. In addition, they are developing empirical models that are more effective at accurately predicting network events at small scales. Both PIs Zhao and Zheng are heavily invested in educational and outreach programs for female and minority students: female students and postdocs often outnumber male counterparts in their lab. The PIs will disseminate their results to their collaborators atRenren and LinkedIn, and also share results with researchers at Twitter, Zynga, Facebook and Google through existing technical contacts and informal visits\/talks. <br\/><br\/>For further information, please see the project webpage at: http:\/\/sandlab.cs.ucsb.edu\/dynamics","title":"III: Small: Analysis and Models of Social Network Structure, Growth and Dynamics","awardID":"1321083","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["560388",551126],"PO":["563727"]},"206716":{"abstract":"This highly interdisciplinary research addresses two fundamental challenges in image sensing and image understanding: 1) versatile camera systems in a small form factor, and 2) 3-dimensional scene and object recognition from 2-dimensional photos. These fundamental challenges are tackled together by developing a cyber-physical imaging system, called smart flexible camera sheet, which integrates an array of many micro-cameras (millimeters in size each) onto a thin substrate. The substrate has flexible geometric shape and the orientation of each camera is individually adjusted and controlled in real time via intelligent algorithms. The overall imaging system is ultra-thin and space-efficient, and can be easily mounted onto or embedded into any planar or curved surface. Hence it opens up a plethora of new civilian and military applications where surveillance and visual monitoring are required, thus bearing great commercialization potential. Example applications are: smart vehicles, smart transportation, highway safety, smart civil infrastructure, manufacturing lines, battlefield surveillance and reconnaissance, sensor networks, mobile robotics, medical facilities, and patient care. <br\/><br\/>Broader Impact: This project generates new educational opportunities for students at all levels, leading to curricular development in electrical engineering, applied physics, materials science and engineering, and computer science. An important component of the project is a strong dissemination and outreach program to reach other universities, K-12 students, teachers, parents and the general public.","title":"CPS: Synergy: Smart Flexible Camera Sheet: Ultra-Thin Semantic-Guided Cooperative Micro-Camera Array","awardID":"1329481","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[553478,"490501"],"PO":["565274"]},"205529":{"abstract":"Our physical world presents an incredibly rich set of observation modalities. Recent advances in wireless sensor networks (WSNs) enable the continuous monitoring of various physical phenomena at unprecedented high spatial densities and long time durations, hence opening exciting new opportunities for numerous scientific endeavors. Since sensor nodes are unattended and batterypowered, network monitoring\/tomography from indirect measurements at the sink(s) and energy conservation are critical in the deployment of large-scale environmental WSNs. Therefore, a viable framework for energy-efficient network monitoring and data collection is fundamentally important to significantly improve WSN management\/operations and reduce its deployment costs.<br\/><br\/>This project investigates the energy-efficient network monitoring\/tomography and data collections in large-scale outdoor WSNs, based on the recent breakthrough of compressed sensing (CS) through an integrated theoretical and empirical approach. The project studies WSN topology tomography for dynamic routing under wireless link dynamics due to channel fading and interference. The objectives of this project are to develop a novel and rigorous framework of topology tomography for real-world WSNs operated in highly noisy communication environments. Dynamic routing topology recovery algorithms are devised for both complete indirect measurements and incomplete indirect measurements received at the sink(s). The accuracy of the tomography approach is studied both analytically and empirically. The developed WSN topology tomography framework can be essential not only for WSN's routing improvement, topology control, hot spot elimination, and anomaly detection in practice, but also for emerging CS-based data collection. This approach extends the current CS technology to form a unified framework for network tomography and data collection in large-scale WSNs, upon which energy-efficient WSN topology tomography and data gathering protocol suite is developed. The developed framework and protocol suite will be validated and evaluated in a real-world environmental WSN testbed in a hilly watershed.<br\/><br\/>The project intends to create a new paradigm of optimal design, development, and management\/operations for large-scale WSNs to significantly extend their lifetime. This would lead to a substantial reduction of the prohibitive cost of large-scale WSN deployments for scientific, civic, national security, and military purposes in the near future. The project creates an interdisciplinary educational practice for both undergraduate and graduate students through hands-on experience with a real-world WSN testbed. The outreach includes summer camps and scientific projects for school students using the WSN testbed.","title":"NeTS: Small: Collaborative Research: Compressed Network Tomography and Data Collection in Large-Scale Wireless Sensor Networking","awardID":"1319331","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["460719"],"PO":["565303"]},"206629":{"abstract":"This work will advance human-robot partnerships by establishing a new concept called complementary situational awareness (CSA), which is the simultaneous perception and use of the environment and operational constraints for task execution. The proposed CSA is transformative because it ushers in a new era of human-robot partnerships where robots act as our partners, not only in manipulation, but in perception and control. This research will establish the foundations for CSA to enable multifaceted human-robot partnerships. Three main research objectives guide this effort: 1) Real-time Sensing during Task Execution: design low-level control algorithms providing wire-actuated or flexible continuum robots with sensory awareness by supporting force sensing, exploration, and modulated force interaction in flexible unstructured environments; 2) Situational Awareness Modeling: prescribe information fusion and simultaneous localization and mapping (SLAM) algorithms suitable for surgical planning and in-vivo surgical plan adaptation; 3) Telemanipulation based on CSA: Design, construct, and integrate robotic testbeds with telemanipulation algorithms that use SLAM and exploration data for online adaptation of assistive telemanipulation virtual fixtures. This research also includes investigation of previously unaddressed questions on how sensory exploration and palpation data can be used to enable online-adaptation of assistive virtual fixtures based on force and stiffness data while also taking into account preoperative data and intraoperative correction of registration parameters.<br\/><br\/>The proposed work will restore the situational awareness readily available in open surgery to minimally invasive surgery. This will benefit patients by enabling core technologies for effective and safe natural orifice surgery or single port access surgery. The societal impact of the proposed work on these two surgical paradigms is reduced pain for patients, shorter hospital stay, improved cosmesis and patients' self image, and lower costs. We also believe that CSA will impact manufacturing where its future will require people and robots working together in a shared space on collaborative tasks. Also, the same concepts of CSA apply to telemanipulation in constrained and unstructured environments and the proposed research has direct relevance to robot-human partnerships for space exploration. To ensure this broader impact will be achieved, an advisory board has been assembled with experts from medicine, manufacturing and aerospace. Finally, the PIs will facilitate collaboration in the medical robotics research community by making our software and hardware designs available on-line and using commercial-grade hardware available at multiple institutions.","title":"NRI: Large: Collaborative Research: Complementary Situational Awareness for Human-Robot Partnerships","awardID":"1327657","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":[553223],"PO":["564069"]},"200733":{"abstract":"The Project aims to create a sustainable collaborative ecosystem built around several large scientific data sets for the broader science community. Based upon the expertise developed for the Sloan Digital Sky Survey (SDSS) SkyServer and the associated projects the Project will formalize the main system components and reengineer them to be much more reusable. <br\/><br\/>The Project will take full ownership of the Sloan Digital Sky Survey archive and will provide a robust environment for its continued operations, using an economy of scale enabled by common, shared building blocks derived from the existing SDSS SkyServer framework, based upon a large, scalable database system.<br\/><br\/>Using these building blocks, the team will build and operate open data archives from large observations and numerical simulations, including computational fluid dynamics, ocean circulation and astrophysics, reaching PB scales. The Project will further extend the tools to life sciences, like large-scale, next-generation genome sequencing experiments, as well as high-throughput neuroscience imaging data. The resulting distributed, parallel database framework will be linked to small, user-created data sets that can be used also collaboratively, in conjunction with each other and the large data collections. <br\/><br\/>The Project will work with selected communities to help deploying and serving data using our building blocks, demonstrating portability, generality and economies of scale; will help and encourage other institutions and communities to use the tools, while seeking collaborations that result in disruptive changes, and will build tools that accelerate the timescale to deploy new services and applications and rapidly test new ideas.<br\/><br\/>The Project will enable individual users to bring their \"small data\" and analyze it collaboratively in the context of the large data. <br\/>Our particular goals are:<br\/><br\/> (i) Take full ownership of the SDSS Archive (database and flat files) and ensure a scalable and robust environment for its continued operation;<br\/><br\/> (ii) Build upon our decade-long effort on SDSS and its ad-hoc spinoffs, through reengineering its components into portable and general building blocks;<br\/><br\/> (iii) Systematically address curation issues arising from using a service-oriented architecture (SOA), and the resulting service life-cycle;<br\/><br\/> (iv) Work with projects from additional scientific domains to help deploying and serving data using our building blocks, demonstrating portability, generality and economies of scale;<br\/><br\/> (v) Develop scalable extensions to our database cluster in order to deal with large numerical simulations scaling up to petabytes, and turn them into open numerical laboratories;<br\/><br\/> (vi) Use our CasJobs Collaborative Environment to address the problem of small but complex data in the \"Long Tail\" of science.","title":"CIF21 DIBBs: Long Term Access to Large Scientific Data Sets: The SkyServer and Beyond","awardID":"1261715","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}}],"PIcoPI":[538208,"551737",538210,538211,538212],"PO":["565292"]},"202801":{"abstract":"The past few years have seen a tremendous growth of massive computing resources and storage capacities in large data centers enabling new Internet applications and services. At the same time, there has been a rapid growth and widespread adoption of smart phones, tablets, and e-readers, through which users access these applications and services on the move. The confluence of these complementary trends has given rise to the emerging notions of mobile services and cloud computing. However, current mobile services and cloud computing offerings pose many difficult challenges to realize their full potential. These challenges include lack of user control over computing resources, poor performance and lack of context due to the separation between user devices and cloud resources, and limited privacy provided by centralized clouds. These challenges raise important questions such as: Can we build large-scale, ?community-based?, customizable cloud computing infrastructures by leveraging computing and storage resources contributed by a large number of small players? Can we develop personalized and collaborative Internet cloud services and mobile apps that enable user control, while tapping into existing cloud computing infrastructures? What applications can be run effectively on each type of cloud, and how could such clouds be coupled to yield a much more powerful platform? How can we fully realize the potential of mobile and cloud computing while minimizing its carbon footprint?<br\/><br\/>The PIs at the University of Minnesota (UMN) are conducting a wide range of research on addressing these challenges, by building an integrated cloud system that is diverse and dispersed across a wide area of locations; it not only utilizes the commercial large-scale cloud infrastructures, but also leverages smaller-scale, local community resources at the edge. A significant barrier to continued progress in these research efforts is lack of a flexible and controllable computing, storage and networking infrastructure for experimentation. This project seeks to overcome this obstacle by building the Minnesota Integrated cloud Systems Testbed (MiST) research infrastructure for advancing research on cloud computing infrastructures and applications. This research facility is organized in three interconnected logical tiers: i) core cloud systems consisting of two data centers; ii) several distributed edge server clouds consisting of a few server machines; and iii) swarms of stationary and mobile users, comprising a wide array of different user devices. <br\/><br\/>In terms of education, this research infrastructure provides an ideal \"hands-on\" learning environment to teach both graduate and undergraduate students important data analysis, system building and experimental skills that are critical for today's IT workforce. The PIs incorporate research conducted on the MiST research infrastructure in their classroom teaching, both for class projects in the core courses on networking, security, storage, and distributed systems, as well as in undergraduate senior and directed research courses. The PIs have a strong track-record of supporting undergraduate students, especially women and under-represented students. The PIs plan to disseminate the research advances via close interaction with their industrial collaborators, and through publications, presentations and public release of research data, software tools and prototype systems to the larger research community.","title":"II-NEW: One Cloud Does Not Fit All: Minnesota Integrated Cloud Systems Research Testbed (MiST)","awardID":"1305237","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[543507,543508,543509,543510],"PO":["565272"]},"202834":{"abstract":"Literature reviews, whether systematic or ad hoc, are an integral part of the research process. By enabling the execution of systematic literature reviews, this infrastructure helps ensure that researchers identify a complete and unbiased set of candidate papers when performing such a review. In addition, this project lowers the barrier for performing SLRs allowing a larger portion of the SE community to conduct SLRs. This work is especially helpful for PhD students who much perform a literature review as part of their thesis work. Because SLRs are often publishable as stand-alone articles, this infrastructure will also help increase students? publication rate.<br\/><br\/>This project conducts planning activities in preparation for the creation of an infrastructure to support the SLR process. The community targeted by this project comprises SE researchers who already conduct SLRs, as well as SE researchers who will be more likely to conduct SLRs if the barriers to adoption are removed. The primary objectives of this are to: evolve an understanding of community needs and the proposed infrastructure; and create a detailed plan for the development and deployment of the infrastructure","title":"CI-P: Advanced Systematic Literature Review Infrastructure for Software Engineering","awardID":"1305395","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[543613,"551799",543615],"PO":["565272"]},"210215":{"abstract":"The advent of sophisticated photo editing software has made it increasingly easier to manipulate digital images. Often visual inspection cannot definitively distinguish the resulting forgeries from authentic photographs. In response, forensic techniques have emerged to detect geometric or statistical inconsistencies that result from specific forms of photo manipulation. The PI aspires to develop new forensic methods based on geometric content analysis, which focus on finding inconsistencies in the geometric relationships among objects depicted in a photograph. The geometric relationships in a 2D image correspond to the projection of the relations that exist in the 3D scene; if a scene is known to contain a given relationship but the projected relation does not hold in the photograph, then one may conclude that the photograph is not a true projective image of the scene. With this in mind, the PI's goal in this exploratory project is to build a set of testable constraints that must be satisfied in real images, so that an unsatisfied constraint constitutes definitive, objective evidence of image manipulation. Fundamental challenges of this work include: developing tools for analysis from incomplete lighting information, building testable models of skin reflectance, accounting for structured uncertainty in feature comparison, and establishing method guidelines for forensic image analysis.<br\/><br\/>Broader Impacts: This project will create tools for objectively detecting image manipulation, which will help reporters, law enforcement, scientists, and others differentiate between legitimate photographs and forged images. The products of this research will be communicated via academic publications and online source code. Collaborations with industrial partners will allow the research to have practical impact as well.","title":"EAGER: Image and Video Forensics: Detecting Image Manipulation by Content Analysis","awardID":"1353155","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[563370],"PO":["565227"]},"210336":{"abstract":"Graph analytics form a canonical Big Data problem that is of significant value to the long tail of science, from social sciences to genomics. While graph algorithms for big-memory machines abound, they are inaccessible to the wider community. Developing appropriate abstractions for graph applications on distributed cyber-infrastructure like Clouds and commodity clusters has been challenging. This work explores a subgraph-centric approach which offers the potential for an order-of-magnitude performance benefit. This work investigates graph algorithms, focused on de novo plant genome sequencing, that use a scalable subgraph-centric graph programming model for Clouds. It offers a novel research direction that can profoundly impact next-generation genome sequencing in addition to other domains where graph abstractions can be employed. It catalyzes research into distributed graph analytics through a critical mass of subgraph-centric algorithms, mitigating the lost opportunity cost in delayed adoption of the technology and domain specific computing abstractions. In the process, it will fundamentally advance scalable graph processing to rapidly accelerate and democratize cyber-infrastructure for Big Data for next generation sequencing.","title":"Accelerating Graph Analytics on Clouds for Genome Assembly","awardID":"1355377","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[563658,563659,563660],"PO":[563661]},"205804":{"abstract":"This project aims to develop a framework for performance characterization, representation, optimization and debugging for the emerging domain of soft real time computing. Key elements include a new metric, called \"variance\", that characterizes the timing properties of such workloads, and a \"variant characterization graph\" (VCG) that represents the relationships among the variance contributing functions in a software system. The VCG is subjected to a combination of static analysis, dynamic profiling and statistical analysis. The results of these analyses are applied to the problems of debugging performance bottlenecks, and dynamic performance optimization making use of predictive methods and contextual information obtained at run time. <br\/><br\/>Interactive, response-time sensitive applications such as video games, computer vision, and multi-media encoder\/decoders are an important, growing class of emerging applications on mobile devices such as the smart-phones. A proliferation of powerful new devices is driving up the scale and pervasiveness of applications. The diversity of new devices and the number of kinds of resources present in them, accompanied by a market-driven demand for shorter application development cycles, are making performance tuning more challenging and more essential. Success of this project would provide a practical conceptual backbone for converting the optimization of such soft real time systems from an art to a science. Transition of the results of this research to practice is furthered through open source distribution of software tools implementing and applying the VCG-based analyses, and an on-line graduate course titled \"Optimizations for Interactive Embedded Software\".","title":"CSR: Small: Profiling and Optimizing Embedded Software for Soft Real-Time Behavior and Responsiveness","awardID":"1320752","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[550988],"PO":["564778"]},"205606":{"abstract":"The project aims to improve the quality of service and lifetime of real-time<br\/>embedded systems, particularly those implemented on multi-core platforms. In<br\/>contrast with many other quality metrics, such as performance and power<br\/>consumption, reliability is difficult to accurately estimate because it is<br\/>influenced by design decisions, environmental conditions, and process variation<br\/>during integrated circuit fabrication.<br\/><br\/>This project consists of three main technical tasks. (1) Develop a reliability<br\/>modeling and analysis framework that can efficiently and accurately determine<br\/>the impact of design and runtime management decisions on reliability. (2)<br\/>Develop a reliability-driven resource management framework, which includes<br\/>runtime algorithms for assignment and scheduling of real-time tasks to maximize<br\/>system lifetime while keeping soft error rates low, and a lightweight technique<br\/>to adaptively adjust the activation frequency of the algorithms (i.e.,<br\/>overhead). (3) Develop wear state monitoring techniques and data collection<br\/>infrastructure to enable the runtime refinement and validation of system-level<br\/>reliability models that require long-term in-field system deployment.<br\/><br\/>The techniques developed in this project will support the production of more<br\/>reliable and\/or less expensive electronic devices, enabling integrated<br\/>circuits, which are susceptible to wear due to lifetime fault processes to be<br\/>used in special-purpose computers with strict reliability and performance<br\/>requirements. In particular, this project aims to ease the use of multicore<br\/>processors in high-reliability computing applications with deadlines, such as<br\/>automotive, multimedia, and health care applications. These applications have<br\/>historically seen slow adoption of multicore processors, despite their price,<br\/>performance, and power consumption benefits. We believe this is partially due<br\/>to gaps in knowledge of how to control and optimize reliability on such<br\/>systems, some of which this project will fill. The involvement of both industry<br\/>researchers and university students at the undergraduate and graduate level<br\/>will result in a broad dissemination of the research results.","title":"CSR: Small: Collaborative Research: Reliability Driven Resource Management of Multi-Core Real-Time Embedded Systems","awardID":"1319718","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[550536],"PO":["565255"]},"209908":{"abstract":"Society increasingly depends on numerical software, which uses finite precision arithmetic to approximate the reals and necessarily introduces approximation and error. Anti-lock breaks and medical devices such as haptic control systems for remote surgery are two such examples. Numerical errors in these systems can be disastrous. Toyota suspects such errors contributed to its recent, costly unintended acceleration problem, and the Ariane 5 rocket exploded due to an overflow in its inertial reference system. This project explores practical techniques to test and analyze numerical software, which will advance the state-of-the-art in engineering robust numerical software to help avoid costly, dangerous errors.<br\/><br\/>In particular, the project focuses on the two most fundamental sources of numerical errors: uncaught exceptions and numerical stability and accuracy. The proposed core framework is centered around symbolic execution, and domain insights will be used to develop principles and heuristics to make it practical. This project will complete several preliminary research tasks to validate and demonstrate the promise of the proposed general approach. It will explore new problem modeling strategies for numerical accuracy and stability, examining realistic numerical constraints to build insights into constraint solving strategies and algorithms, and improving the promising Ariadne symbolic analysis infrastructure.","title":"EAGER: Toward Numerically Robust Software","awardID":"1349528","effectiveDate":"2013-10-01","expirationDate":"2015-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":[562712,562713,562714],"PO":["565264"]},"199216":{"abstract":"When presented with a novel image, humans typically have little problem providing a consistent interpretation of the scene in terms of contours, surfaces, junctions, and the relations between them. This process of perceptual organization is closely coupled with recognition of familiar shapes and materials. Perceptual organization can aid recognition by reducing the complexity of a cluttered scene to a small number of candidate surfaces while recognition can help resolve ambiguities in grouping based on local image cues. This project is developing a computational framework that fuses top-down information provided by recognition with bottom-up perceptual organization in order to automatically produce a coherent scene interpretation. This research includes (1) identifying local image features that provide cues to grouping and figure-ground, (2) developing libraries of composable detectors that capture the appearance of objects, parts and their spatial relations, and (3) designing models and efficient inference routines that explicitly reason about occlusion and the binding of image regions and contours into object shapes.<br\/><br\/>Integrated models of grouping and recognition have direct significance to expand the computer vision capabilities of robotics and assistive technologies that must operate in complex, cluttered environments. The framework being developed also has applications in automating biological image analysis where top-down shape information are useful in resolving noisy local measurements. The computational tools developed by the project along with dissemination and educational efforts are aimed at forming an interdisciplinary bridge between biological imaging and cutting-edge computer vision research.","title":"CAREER: Combinatorial Inference and Learning for Fusing Recognition and Perceptual Grouping","awardID":"1253538","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["538669"],"PO":["564316"]},"200734":{"abstract":"The Pittsburgh Supercomputing Center (PSC) will carry out an accelerated, development pilot project to create, deploy and test software building blocks and hardware implementing functionalities specifically designed to support data-analytic capabilities for data intensive scientific research. Building on the successful Data Supercell (DSC) technology which replaced a conventional tape-based archive with a disk-based system to economically provide the much lower latency and higher bandwidth data success necessary for data-intensive activities, PSC will implement and bring to production quality additional functionalities important to such work. These include improved local performance, additional abilities for remote data access and storage, enhanced data integrity, data tagging and improved manageability. PSC will work with partners in diverse fields of science, initially chosen from biology, astronomy and computer science, who will provide scientific and technology drivers and system validation. The project will leverage current NSF\/CI investments in data analytics systems at PSC. Those investments include DSC, Blacklight (an SGI UV1000 with 2\u00d716TB of hardware-enabled cache-coherent shared memory), and Sherlock (a YarcData ?Urika? graph-analytic appliance which also supports a globally accessible shared memory), both very capable for data analytic applications. Their tight coupling to the pilot storage system will allow synergistic development of analytical capabilities with development of increasingly sophisticated mechanisms for data handling. Working with the new, multi-petabyte data store, they will constitute a system specifically optimized for data intensive work as contrasted with conventional HPC systems. Blacklight will be upgraded with more powerful technology, specifically architected to satisfy the more demanding needs of data analytics in years 3,4. When successful, PSC will engage the NSF to consider larger-scale deployment aiming at exascale capacity.","title":"CIF21 DIBBS: The Data Exacell","awardID":"1261721","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[538214,538215,538216,538217,"565291"],"PO":["565292"]},"202813":{"abstract":"The creation, management, and access of data is key to the advancement of the state-of-the-art in computer science. Currently many research and educational activities in social network, web mining, multimedia retrieval, and high performance computing, just to name a few, need to involve big data. However, existing infrastructure of the Computer Science Department at Texas State University falls far behind its increasing research and educational needs.<br\/><br\/>This project builds a shared high-performance data center, providing the fundamental facilities to collect, process, and manage large volumes of data. The new data center supplies the necessary computational power and storage to support the exploration and development of new research and technologies within and beyond the department in the fields of computer vision, wireless network, information retrieval, data mining, human computer interaction, software engineering, high performance computing, and security. The data center also supports quality undergraduate and graduate student research experience, enables the integration of research and education, encourages inter-departmental and cross-university collaborations, and promotes the Ph.D. program development in the Computer Science Department. The developed infrastructure will significantly enhance the current research and educational capabilities of the department, university, and community.","title":"II-NEW: Shared High Performance Data Center","awardID":"1305302","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["547822",543548,543549,543550,543551],"PO":["563727"]},"210315":{"abstract":"Funtional Magnetic Resonance Imaging (fMRI) offers a rich source of data for understanding brain structure and function. There is an urgent need for computational approaches to eliciting brain structure-function relationships from such data. While current approaches that rely on network representations of fMRI data offer useful insights into brain connectivity, they have significant limitations in terms of discovering and validating complex functional mechanisms that underly brain function: the very notion of a node in the functional network is difficult to define, inter- and intra- subject variability leads to network representations that vary a great deal within and among subjects; and static representations of correlations between activities of different brain regions offer only a partial picture of brain activity which is inherently dynamic. <br\/><br\/>This exploratory research project aims to introduce dynamic network analysis techniques to discover functional brain regions and study their evolution over time and across subjects. It leverages the research team's experience in the analysis of continuous and highly variable spatio-temporal climate data to address several of the outstanding challenges in analyzing brain networks built from fMRI data. A key goal of this exploratory study is to explore the feasibility of analyzing network representations of fMRI data to answer questions such as the following: Do nodes changes dynamically with time during an fMRI scan? What community detection techniques work best for dynamic networks? What patterns arise in dynamic brain networks? What is the statistical validity of the observed patterns?<br\/><br\/>Broader Impact: If successful, the project could establish the feasibility of research directions that could eventually lead to computational tools that enable better characterization of normal and abnormal brain function; better understanding of the variation of brain function within and across individuals over time, including patterns that characterize the brain activities of different populations e.g., adolescents, those suffering from specific brain disorders, etc. The project offers enhanced opportunities for interdisciplinary collaborations between neuroscientists and computer scientists, and research-based advanced training of graduate and postdoctoral students at the University of Minnesota. Free dissemination of open source implementations of the algorithms resulting from the project to the larger research community contribute to its broader impact.","title":"EAGER: Building and analyzing dynamic brain functional networks","awardID":"1355072","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[563607,563608,563609],"PO":["565136"]},"211008":{"abstract":"Facilitating workload consolidation and improving server utilization are critical for reducing cost and improving energy-efficiency of modern datacenters. One major challenge for improving utilization is to do so without affecting the quality of service (QoS). On modern servers, various co-located jobs may share critical resources including 1) micro-architectural resources such as last level cache, memory bandwidth, and functional units, etc., and 2) energy resources including grid power and distributed batteries that provide an additional power source especially during high load period. Multiple co-located jobs may contend for shared these resources, causing interference, threatening application QoS or even triggering the circuit breaker and resulting in costly downtime and severe QoS violations.<br\/>This project addresses these challenges by designing a cross-layer system that effectively manages workload consolidation, quality of service (QoS) and various energy sources to optimize for energy efficient computing. Our system spans several layers, including profiler, static compiler, online lightweight monitoring and prediction, runtime execution management, hardware power state control and energy sources control. The compilation technique identifies and inserts markers in contentious code regions in low-priority applications, as well as critical regions in high-priority applications that require QoS protection. The lightweight runtime utilizes the compiler hints, monitors the QoS, power consumption, etc., and adaptively adjusts the pressure applications generate to the shared resources such as shared cache and memory bandwidth, manages battery (dis) charges and hardware power states to guarantee QoS and achieve efficient power shaving.","title":"CSR: Small: Cross-layer HW\/SW solutions towards Energy-Efficient Datacenters","awardID":"1419243","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[565254],"PO":[565255]},"205706":{"abstract":"The objective of this project is to investigate version consistency, a new concurrent programming consistency model, as a means of enhancing the performance and scalability of concurrent systems. Under version consistency, which can be seen as a relaxation of release consistency, processes are guaranteed to see the same memory contents (only) if they are accessing the same version of the memory. Such versions are created, retrieved and\/or merged through calls analogous with version control systems for source code.<br\/><br\/>An important class of applications that benefits substantially from version consistency is deterministic concurrency runtimes, where the goal is to ensure that a program produces the same output given the same input, independent of any non-deterministic timing effects. In prior work, the PI achieved up to 50% performance gain for the deterministic runtime DThreads, using version consistency. In this project, one of the goals is to achieve ``pthreads parity\" for a deterministic runtime, where enforcing determinism incurs only negligible performance impact. When and if this is achieved, ``determinism by default'' becomes a feasible option for mainstream computer systems.<br\/><br\/>As computer processors continue to evolve from a centralized single ``core'' architecture to highly distributed and parallel ``multi-core systems'', writing correct programs that make efficient use of this extremely powerful hardware is becoming increasingly difficult. This results in a number of detrimental effects ranging from poor resource utilization, to seriously flawed programs where loss of data, or even loss of life may result. This project investigates (a) a means of reducing the complexity of programming highly parallel systems to combat these problems, and (b) a means of guaranteeing that even an incorrect parallel program produces the same result every time. This latter part will help programmers write correct programs, and to fix software flaws that may otherwise be intermittent and difficult to identify.","title":"CSR: Small: Multi-Version Concurrency Control (MVCC) for Main Memory and its Implications for Deterministic Concurrency","awardID":"1320235","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[550764],"PO":["565319"]},"205728":{"abstract":"Society relies on an ever broadening array of computer systems for productivity, communication, entertainment, safety, and health. Systems capable of processing at faster rates and with greater efficiency are necessary to sustain the pace of innovation. A key part of achieving this goal is the development of tools and techniques that make it easier to build sophisticated software with a desired set of requirements. One aspect of these tools, the focus of this work, is data dependence profiling. A data dependence profiler (DDP) conveys to a programmer, compiler, or other program analysis tool the likelihood of a data dependence between two arbitrary memory operations while the program is running. DDPs are critical since compilers and programmers often do not know or cannot determine all such relationships simply by analyzing the source code; hence, DDPs provide important information for further optimization and tuning.<br\/><br\/>This project focuses on the design of a fast practical DDP that works effectively for a wide range of applications and for a wide range of program analysis needs. The first goal is speed: that the DDP impose only a small slowdown, the target being a factor of two. A second goal is to maintain accuracy: bounding the uncertainty and imprecision inherent in profiling, and providing information about the accuracy with the profiler feedback. The third goal is integration of the DDP into a feedback-directed optimization framework, to explore and understand its capabilities.<br\/><br\/>If the goals of the project are met, DDPs are expected to become more widely integrated into program development tools in support of existing technology and enabling new technologies that ultimately will benefit society. Open source distribution of the tools developed by the project strengthens and extends the available open-source software infrastructure relied upon by both academia and industry. The project integrates education with research through involvement of graduate, undergraduate, and high school students.","title":"CSR: Small: A Practical Data Dependence Profiler for Program Characterization and Optimization","awardID":"1320356","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[550815],"PO":["565255"]},"210679":{"abstract":"Network protocol stacks typically follow a multi-layer hierarchical architecture. What determines the required number of layers, or the number of protocols at each layer? The space of applications, services and user expectations (at the top layer) and the space of elementary functions (at the bottom layer) are constantly evolving -- how does this dynamic environment affect the organization of layered protocol stacks? What determines the evolvability of a protocol stack in the presence of changes? How does evolvability relate to other important system-wide properties such as robustness (the ability to deal with unexpected change), optimality and modularity? These are some of the high-level questions that this research project focuses on. <br\/><br\/>Intellectual Merit: This research seeks to reexamine the fundamentals of protocols design and investigate the role of and dependencies between several central concepts: layering, modularity, complexity, robustness, optimality. The central theme in this research, however, is evolution -- networking architectures are not designed to work in a static environment. Applications, services, user expectations, communication and computing technologies, as well as the underlying economics, are all in a constant state of flux. <br\/><br\/>Rather than rely on a single modeling framework, this research starts with two preliminary models, referred to as Stratum and Lexis. The two models share some features but are also significantly different and complementary. They both capture the time-varying character of a layered design process aiming to support a dynamic set of applications from an underlying set of (also dynamic) elementary functions. Stratum is more constrained than Lexis as it considers, first, a specific ordering for the available building blocks, and second, an endogenous model for the ``death rate'' of existing applications. Lexis, on the other hand, is more general and more abstract, and captures how a time-varying set of regular expressions can be constructed hierarchically from a time-varying alphabet, re-using simpler regular expressions as much as possible.<br\/>The Stratum and Lexis models are initial steps towards developing a base understanding of what factors influence the evolvability and sustainability of protocols. With this base in place, further domain-specific insight can be developed and yield targeted guidelines for the design of future network protocols.<br\/><br\/>Broader Impact: There are currently four large NSF-funded Future Internet Architecture (FIA) projects that pursue a ``clean-slate'' design approach for a future Internet that is more robust, secure, evolvable, etc. A goal of this research is to both inform and learn from the efforts of the four FIA projects.<br\/><br\/>The broader impact of this project also includes the release of two extensible simulators (corresponding to Stratum and Lexis) that will allow students and instructors to experiment with how network architectures evolve in dynamic environments and under optimization objectives and constraints. No such tools are available today.<br\/><br\/>Additionally, this project has a significant inter-disciplinary component in both its ?inputs and outputs.? Specifically, much of the prior work behind this research (inputs) has originated in economics, physics and evolutionary biology. Conversely, the project's results (outputs) are likely to be relevant to other disciplines such as software engineering, smart manufacturing and the science of organizations.","title":"NETS: SMALL: Collaborative Research: Protocol Stacks Design and Evolution: The Role of Layering and Modularity","awardID":"1361771","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[564485],"PO":["565090"]},"202825":{"abstract":"The University of South Alabama plans to expand their laboratory infrastructure for cybersecurity to facilitate research, education and training in hardware design, prototyping, reverse engineering, forensic de-obfuscation, side-channel characterization, and program analysis.<br\/><br\/>This CRI award in cybersecurity is important to the workforce development for the region and extends programs at the new Center for Forensics Information Technology Security (CFITS) at the University of South Alabama.","title":"II-NEW: RUI: Expanding Cyber Assurance Research and Education","awardID":"1305369","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[543586,543587],"PO":["565239"]},"205806":{"abstract":"Wireless Underground Sensor Networks (WUSNs), i.e., networks of wireless sensor nodes that operate below the ground surface, are the enabling technology of many emerging applications, such as intelligent agriculture, underground pipelines and power grid monitoring, oil reservoir monitoring, concealed border patrol, earthquake and landslide forecasting, and underground mine disaster prevention and rescue, amongst others. Despite their potential advantages, the realization of WUSNs is very challenging. The peculiarities of the underground environments prevent the direct use of most, if not all, existing wireless communication and networking solutions, mainly due to the very high path loss, small communication range, and high dynamics of electromagnetic (EM) waves in the underground environment. The objective of this project is to address the unique challenges for the realization of WUSNs in challenging underground environments. The proposed research is built on top of novel Magnetic Induction (MI)-based communication mechanisms as well as system architectures in underground soil medium, oil reservoirs, and mines and tunnels. This particular project has contributions along four major thrusts. First, a cross-layer communication framework based on the MI channel characteristics is proposed to achieve high-throughput, energy-efficient, and reliable underground communications. Second, a new Received Magnetic Filed Strength (RMFS)-based localization paradigm is proposed to exploit the unique multi-path and fading-free propagation properties of MI-based signals, which guarantees the accuracy, simplicity, and convenience of the localization strategy. Third, an optimal MI-based network deployment strategy is proposed for different WUSNs applications with the objective to minimize the coil density while maintaining the required bandwidth constraint and reliability requirements. Finally, a physical MI-based WUSN testbed is developed, which consists of our own designed MI-based sensor devices and an engineered underground environment, to validate our proposed solutions. <br\/><br\/>The proposed research is expected to pave the way for the realization and implementation of emerging WUSNs applications, which bring significant advances in the industrial productivity and homeland security, e.g., concealed border patrol. This project will bring together researchers in the areas of information theory, radio design, and networking, and enable the establishment of new research connections and interpretations. The project will support two graduate students. The solutions of the project will also result in patents for the proposed techniques and novel system architectures. The research results will be disseminated in important scientific conferences, journals and premier magazines of the field. The developed simulation tool and physical testbed will serve as the evaluation platform for the research community.","title":"NeTS: Small: The MOLES: Enabling Wireless Sensor Networks in Underground","awardID":"1320758","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["562752"],"PO":["565303"]},"205608":{"abstract":"This proposal is motivated by the observation that the battery drain of an app in a mobile device is user-centric, i.e., it depends on several factors that are associated with specific usage patterns. These factors include but are not limited to the mode in which the app is used, the network coverage that the user enjoys and whether or not certain features of the app are turned on\/off. In this project, the objectives are to (i) develop a fundamental understanding of the factors that influence the energy consumption of smartphone apps and, (ii) based on the understanding obtained, design and implement a user-centric battery management system that is called BLT. <br\/><br\/>The PIs plan to first undertake an extensive measurement study that will provide a comprehensive understanding of how and to what extent user-centric factors affect the energy consumption on a smartphone. Subsequently, they aim to tackle several challenges towards identifying the energy hungry apps on a user's smartphone; some of these challenges include the presence of several coexisting active apps at any given time. Finally, they will design and implement a set of solutions that allow a user to trade-off performance or content quality for energy savings. This project hinges on a strong experimental and prototyping effort, and the PIs will leverage the smartphone testbeds at UC Riverside and UC Davis towards undertaking the same.<br\/><br\/>The project will have an immediate broader impact in empowering users with an ability to control their battery usage. It will also allow users and developers in understanding why activities and apps result in high battery drain. The project will also undertake efforts towards inspiring K-12 students in our respective regions, and helping teachers develop projects for science olympiads. The project will include the modification of wireless networking courses taught at UCD and UCR, and new educational efforts on establishing courses that include design and implementation on mobile devices.","title":"NeTS: Small: Collaborative Research: Towards a User Centric Battery Management System for Smartphones","awardID":"1319721","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[550540],"PO":["565303"]},"198756":{"abstract":"The size and complexity of these \"Big Data\" graphs have always posed significant challenges, limiting the scope of their analysis and thus also limiting the implications that one can draw from them. Mining data from large real-world graphs typically poses two challenges: one of computational resources and another of incomplete information. A comprehensive analysis of these graphs has usually required access to large distributed computing platforms and sophisticated software. This project aims to address a portion of these challenges by investigating a new method, based in statistics and spectral graph theory, to infer essential properties of the full graph through extracting a representative sample of small subgraphs from the full graph. The goal is to reduce the computational burden on researchers interested in large graphs and thus broaden participation in \"Big Data\" activities. As is now well-understood, the analysis of large graphs has many applications in a variety of fields including business, economics, public policy development, law enforcement, public health, sociology and, of course, computer science. This breadth of applicability and the proposed curriculum development activities have the potential to draw and retain a greater diversity of students into computer science and engineering and increasing the participation by under-represented groups.<br\/><br\/>Many of the principal properties of a graph can be inferred from the graph spectrum (eigenvalues of its adjacency or the normalized Laplacian matrix). In particular, a rich set of interlacing results in spectral graph theory allows one to bound the eigenvalues of the full graph using the eigenvalues of its subgraphs. This project will develop new algorithms for generating subgraph samples, and then use basic estimation theory from statistics and the interlacing results from spectral graph theory to discern properties of a large graph. The new method based on subgraph sampling (as opposed to node or edge sampling) uses results from spectral graph theory and statistics to estimate the spectrum (eigenvalues) of the graph based on the spectrum of the sampled subgraphs. The goal is to allow a meaningful analysis of extremely large graphs without the use of anything beyond a typical desktop computer. The data collected and the algorithms developed as part of this project will be made available to the larger research community through a data repository hosted by Drexel University. The project will also make contributions to open-source software.","title":"BIGDATA: Small: DA: Mining large graphs through subgraph sampling","awardID":"1250786","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8083","name":"Big Data Science &Engineering"}}],"PIcoPI":[533237,533238],"PO":["565136"]},"200736":{"abstract":"This project will develop geospatial data analysis building blocks as core part of the HUBzero Scientific Collaboration platform to enable researchers and educators to create and share geospatial data sets and modeling tools. The project will build upon geospatial capabilities that have been developed by IT experts and validated by the science community and bring such capabilities to the masses, hence any domain scientist can develop and deploy geospatial applications with graphical user interfaces on the web. The deliverables include (1) tools and web service interfaces of \"data space\" for managing and sharing data, including geospatial data, and (2) Extended RAPPTURE Toolkit APIs to support geospatial mapping, image processing, visualization, and access to shared data in the data space. The building blocks software developed in this project will be open source as part of the HUBzero open source releases.","title":"CIF21 DIBBs: Integrating Geospatial Capabilities into HUBzero","awardID":"1261727","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}}],"PIcoPI":[538222,538223,538224,538225],"PO":["565292"]},"203728":{"abstract":"This collaborative study aims to advance the understanding of visual object recognition by combining electrophysiology, computational, modeling and psychophysics to probe the implications of newly discovered properties of neurons in visual cortical area V4, an important intermediate stage in the shape processing pathway of the brain.<br\/><br\/>V4 neurons respond selectively to a variety of shape attributes, but recent studies demonstrate that they are also selective for the contrast polarity of stimuli and can be broadly classified into four categories based on their preference for the luminance contrast of shapes relative to a uniform background. Specifically, Equiluminance cells respond best to stimuli defined purely by a chromatic contrast with no luminance contrast while Bright, Dark and Contrast cells respond best to positive contrasts, negative contrasts or either, respectively. Because these categories are based on simple stimuli, it remains unknown how these cells respond to more naturalistic stimuli, where boundaries are seldom defined by a fixed luminance contrast, and whether the different cell classes have different functional roles for encoding objects. Characterizing V4 neurons with a parameterized set of naturalistic stimuli that are developed with rigorous psychophysical testing will provide novel insights into underlying circuitry and function and open new understanding about V4 and the ventral stream.<br\/><br\/>Computational models of visual form processing in the brain have also been limited: they have not taken account of realistic physiological cell types known to exist from the retina to the visual cortex, they have been largely aimed at processing achromatic signals, and have relied heavily on feedfoward processing. This study will generate models that overcome these limitations and are invaluable for gaining insights into the circuits and mechanisms underlying form processing. These models will be available in an open, online framework designed to set a standard for ease of use and transparency, to spur further collaboration between theoreticians and experimentalists, and to facilitate education.<br\/><br\/>Finally, there has been a longstanding debate in vision science, motivated from the psychophysical literature, that questions whether and how chromatic signals contribute to form processing. The traditional view has been that boundary detection and segmentation are solely based on luminance contrast. Color then paints a surface within the confines of the identified boundary. Recent psychophysical and theoretical studies are at odds with this view and argue that color is important for segmentation and form processing in natural scenes, for example, fruit amidst leaves, where detection based on luminance contrast is very difficult. The experiments in this study will inject much needed physiology data into this debate and the models developed here will shed light on the functional organization of cortical pathways at multiple stages, revealing how different aspects of our natural visual input contribute to form perception.<br\/><br\/>This award is being co-funded by NSF's Office of the Director, International Science and Engineering. A companion project is being funded by the German Ministry of Education and Research (BMBF).","title":"US-German Collaboration: Circuit models of form processing in primate V4","awardID":"1309725","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":[545721,545722],"PO":["564318"]},"204707":{"abstract":"OpenSSH reveals excerpts from encrypted login sessions. TLS (HTTPS) reveals encrypted PayPal account cookies. DTLS is no better. EAXprime allows instantaneous forgeries. RFID security has been broken again and again. All of these failures of confidentiality and integrity are failures of authenticated ciphers: algorithms that promise to encrypt and authenticate messages using a shared secret key.<br\/><br\/>It is easy to blame many of these security problems on a lack of education: much stronger authenticated ciphers have been in the literature for many years. However, in many cases these stronger authenticated ciphers fail to meet the performance requirements of the applications. Performance is exactly the motivation for RC4 in WEP; EAXprime in the \"Smart Grid\"; HB in RFID; and \"IPsec\" continuing to support unauthenticated encryption.<br\/><br\/>This project is building a new generation of authenticated ciphers that improve efficiency without compromising security and that improve security without compromising efficiency. This work spans seven main topics: more efficient ciphers; more efficient MACs; more efficient forgery rejection; improved protection against side channels; improved protection against misuse and bad luck; improved quantitative security; and improved security proofs. The ultimate objective is to obtain the best possible security subject to a variety of performance constraints specified by cryptographic users.<br\/><br\/>The high-security high-performance authenticated ciphers produced in this project will be directly and straightforwardly usable in cryptographic applications, avoiding the disasters in current applications and finally bringing secure secret-key cryptography from theory to practice.","title":"TWC: Option: Medium: Collaborative: Authenticated Ciphers","awardID":"1314592","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[548202],"PO":["565239"]},"210813":{"abstract":"One of the main challenges to designing robots that can operate around humans is to create systems that can guarantee safety and effectiveness, while being robust to the nuisances of unstructured environments, from hardware faults to software issues, erroneous calibration, and less predictable anomalies, such as tampering and sabotage. However, the fact that the streams of observations and commands possess coherence properties suggests that many of these disturbances could be detected and automatically mitigated with general methods that imply very low design efforts. Currently, robotic systems are developed as a set of components realizing a directed \"computation graph\". This project focuses on theoretical methods, applicable designs, and reference implementation of a faults\/anomalies detection mechanism for low-level robotic sensorimotor signals. The system, without any prior information about the robot configuration, should learn a model of the robot and the environment by passive observations of the signals exposed in the computation graph, and, based on this model, instantiate faults\/anomalies detection components in an augmented computation graph.<br\/><br\/>The project engages undergraduate and graduate students in advanced robotics design and development. It is expected the research results will have a significant impact on future robotic systems and machine learning.","title":"NRI-Small: Improved safety and reliability of robotic systems by faults\/anomalies detection from uninterpreted signals of computation graphs","awardID":"1405259","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":[564811],"PO":["565239"]},"199219":{"abstract":"This proposal outlines a research and educational plan to advance decision-making techniques for robots that cooperate with human operators. Because humans far exceed the abilities of state-of-the-art robots in vision, creativity, and adaptability, interest is rapidly growing in a human-centered approach to robotics: combining the strengths of humans with the superior precision and repeatability of robots. And yet, our available motion planning tools, while powerful at computing motions for complex autonomous tasks, are poorly suited for human-centered applications that demand responsive and natural motions. This proposal hypothesizes that a new cooperative motion planning paradigm will support major advances in intuitiveness and task performance of human-operated robots such as intelligent vehicles, tele-surgery systems, search and-rescue robots, and household robots. This hypothesis is echoed in an educational plan that aims to train engineers with cross-disciplinary strengths that bridge both the technical and social dimensions of robotics. Initial human subjects studies on novice operators with the PI's cooperative motion planning algorithms suggest that the technique leads to dramatic reductions in task completion time and collision rate in cluttered environments. The proposed work will conduct further investigations along this line of research to 1) identify characteristics of cooperative planners - such as optimality, responsiveness, and completeness - that yield effective human-operator systems, both in terms of objective performance metrics and subjective preferences, 2) to design planners that optimize cooperativity metrics under computational resource and communication constraints, and 3) to enhance the capabilities of such planners to assist operators in complex manipulation tasks.<br\/><br\/>The planners developed in this research and the rich datasets acquired via user studies will serve as resources to help human-robot interaction (HRI) researchers design safe and socially acceptable robot behaviors. Moreover, advances in cooperative motion planning may have long-term social and economic impact by enabling new applications of robotics in driver assist systems, space exploration, medicine, household robotics, manufacturing, and construction. Research is integrated with education in a range of activities that include CS curriculum development, development of a new graduate course on optimization and machine learning, and in new software libraries for robotics education. New modules on motion planning, behavior recognition, and HRI will be incorporated in AI and robotics courses. An REU is requested for each summer of the grant and will be recruited from a minority-serving institution in cooperation with the Alliance for the Advancement of African-American Researchers in Computing (A4RC). One or more IU undergraduates will be involved in research and mentored according to the Undergraduate Research Opportunities in Computing (UROC) program, with preference given to minority and women students.","title":"CAREER: Cooperative Motion Planning for Human-Operated Robots","awardID":"1253553","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0302","name":"Division of ASTRONOMICAL SCIENCES","abbr":"AST"},"pgm":{"id":"1045","name":"CAREER: FACULTY EARLY CAR DEV"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["560558"],"PO":["564069"]},"202827":{"abstract":"As the scale and complexity of computing and data infrastructures supporting science and engineering grow, power costs are becoming important concerns in terms of costs, reliability and overall sustainability. As a result, it is becoming increasingly important to understand power\/performance behaviors and tradeoffs from an application perspective for emerging system configuration, i.e., those with multiple cores, deep memory hierarchies and accelerators. This project builds an instrumented experimental platform that supports such an understanding, and enables research and training activities in this area. Specifically, the proposed experimental platform is composed of nodes with a deep memory architecture that contains four different levels: DRAM, PCIe-based non-volatile memory, solid-state drive and spinning hard disk, in addition to accelerators. Power metering is deployed as part of the infrastructure.<br\/><br\/>The experimental platform enables the experimental exploration of the power\/performance behaviors of large scale computing systems and datacenters as well as compute and data intensive application they support, and uniquely supports research toward understanding the management and optimization of these systems and applications. It also enables research in multiple areas, including: application-aware cross-layer management, power-performance tradeoffs for data-intensive scientific workflows and thermal implications of deep memory hierarchies in virtualized Cloud environments.<br\/><br\/>Data and compute intensive applications are becoming increasingly critical to a wide range of domains, and the ability to develop large-scale and sustainable platforms and software infrastructure to support these applications will have significant impact in driving research and innovations in these domains. The developed experimental platform enables key research activities to support this. It provides important insights that will impact the realization and sustainability of very large-scale infrastructures necessary for current and emerging data and compute intensive applications. The infrastructure also provides an important infrastructure for education and training in different areas related to power management, energy efficiency, data management, memory management, and virtualization.","title":"II-NEW: An Experimental Platform for Investigating Energy-Performance Tradeoffs for Systems with Deep Memory Hierarchies","awardID":"1305375","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["558205","550654","558206"],"PO":["565272"]},"205709":{"abstract":"In this Cyberlearning: Transforming Education EXP project, the investigators are aiming to learn how to promote geo-spatial thinking skills and ability to use data gathered geo-spatially to solve complex problems. The technology being refined leverages on-line maps to situate scenarios in GeoGames so that learners have access to real GIS, remote sensing, socioeconomic, agricultural and other data and models as they engage with others to solve real-world problems in the GeoGame. The focus is on helping learners gain and use a spatial perspective in their thinking and problem solving. Geogames present real-world challenges that require large-scale data collected across geographical areas in game-like ways to draw in the learners; the learners solve problems using the data found through navigating the maps and in conjunction with each other. Research is carried out in the context of a particular GeoGame called Green Revolution. In that simulation, students take on the roles of rural farmers in a developing country and interact with each other to deal with water and weather issues. Learners navigate geo-spatial representations (world maps) to access real data that allow them to make predictions together and develop strategies together for making it through coming storms, pest infestations, and other real-world hazzards. Already learned in that project is that solving problems together in such a simulated real-world context promotes better understanding of the difficulties involved in the lives of farmers in developing countries and some of strategies that might lead to success. Research in this new project focus on trade-offs between complexity of the factors that might be considered in solving complex real-world problems and learning outcomes. The GeoGame technology and its use integrate the strengths of geo-spatial technologies, gaming, and social networking with availability of real-world data to promote learning about real-world facts and also complex, interlinked human, environmental, and technological systems in an experiential, collaborative, and engaging way. The focus is at the college level but ultimately could be appropriate for high-schoolers, middle-schoolers, and the general population.<br\/><br\/>Policy people tell us that a geo-spatial perspective is essential in addressing many of society's pressing issues (e.g., economics, agriculture, climate change, transportation, relief, urban planning, emergency services). This approach of GeoGames may provide an engaging and broadly-applicable way to educate future policy makers in taking a global perspective on both the global and local problems they address. The approach may also provide a way to help the public appreciate the connectedness of the world, the broad implications of local policy decisions, and the issues that must be considered in policy making.","title":"EXP: GeoGames - online map games for teaching and learning through a real-world spatial perspective","awardID":"1320259","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"7511","name":"TUES-Type 2 Project"}}],"PIcoPI":[550771,550772,550773],"PO":["562669"]},"200705":{"abstract":"The information age has made it trivial for anyone to create and then share vast amounts of digital data. This includes unstructured collections made of data such as images, video, and audio to collections of born digital content made up of data such as documents and spreadsheets. While the creation and sharing of content has been made easy, its inverse, the ability to search and use the contents of digital data, has been made exponentially more difficult. In the physical analogue librarians have used the process of curation to standardize the format by which information is stored and diligently index holdings with metadata to allow both current and future generations to find information. Digitally this does not happen as that curation overhead is an unwelcomed bottleneck to the creation of more data. Though popular services such as modern search engines give the illusion that this is being done, this is largely over the portion of digital data that is text based and\/or containing text metadata. Unstructured collections and contents trapped behind difficult to read file formats, however, make up a significant part of our collective digital data assets and are largely not accessible. <br\/>Science today not only uses but relies on software and digital content. It is well known that science is not only responsible for a significant amount of our digital data holdings but that also much of this is un-curated data, what the scientific community currently refer to as \"long-tail\" data. As such contemporary science, which relies on digital data and software, software which evolves and disappears quickly as underlying technology changes, is entering a realm where scientific results are no-longer easily reproducible and as such in essence no longer a science as science hinges on the fact that a documented procedure will result in the same result each time.","title":"CIF21 DIBBs: Brown Dog","awardID":"1261582","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}}],"PIcoPI":["554538","554467","561766","471959","554468"],"PO":["565292"]},"202818":{"abstract":"Increasing functionality and complexity of integrated circuits, particularly those used in high performance computational devices such as computers but also in portable and mobile devices, necessitate high frequency communication links. The information generated and processed at the relentlessly increasing pace in these devices flows over the high frequency communication links between computation, storage and display units. The design and analysis of these high frequency communication links, much like the computation, storage and display units themselves, necessitate design and measurement equipment that is capable of supporting their multi-GHz range of operation. This project is for the acquisition of such a measurement testbed for high frequency interconnects to be located at Drexel University in Philadelphia, PA. Opportunistically, the measurement testbed is used for testing of many types of circuits and systems including those involving microelectronics, optics, sensors, radio-frequency applications, nano-electronics and molecular-electronics. Measurements of the circuit and system devices enabled with this infrastructure enable the development of computing devices that are increasingly portable, fast and significantly less power demanding than the current electronic products. The measurement testbed is used to develop lecture modules on high frequency measurement, bridging a gap with the US microelectronics industry demand with practical hands-on training with integrated circuit measurement and testing in undergraduate education. <br\/><br\/>The measurement testbed is used by a large number of faculty members at the host institution (and users in the Delaware Valley region) in a number of computing and non-computing projects. The primary computing projects that are enhanced by this measurement testbed are novel approaches in developing high performance integrated circuit interconnects: 1. On-chip wireless interconnects, 2. Resonant clock interconnects, 3. On-chip wireless interconnects. The measurement testbed is useful as a whole or in pieces to the many other computing and non-computing research areas thanks to enabling on-wafer testing and multi-port measurement. These additional projects range from reduced dimensional photonics for THz sensing to nanowires for energy storage and IC-based artificial photosynthesis.","title":"II-NEW: Testbed for High Performance Interconnects","awardID":"1305350","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[543562,543563,543564,543565,"562909"],"PO":["565272"]},"202819":{"abstract":"Model-Driven Development (MDD) is an approach to software development that is gaining traction world-wide. The Repository for Model-Driven Development (ReMoDD) is a resource that has been developed to facilitate and accelerate research and education in MDD through the sharing of high quality modeling experiences. ReMoDD provides facilities for curating, querying, and operating on models. The first version was developed under a prior NSF grant and currently supports a broad and growing community of Software Engineering researchers, practitioners, educators, and students. New requirements emerging from the community of developers and users are the basis for this new grant. The project will significantly improve ReMoDD as follows: (1) To help attract more artifacts from industry, we will provide facilities that can be used to sanitize models so that valuable proprietary information is obfuscated; (2) to help attract artifacts that demonstrate the application of MDD methods on industrial software development problems, we will provide facilities for industry\/academia collaborations on industry-relevant challenge problems; (3) to extend the scope of relevant artifacts that can be accessed via ReMoDD, we will work with developers of related repositories (e.g., the European Open Models Initiative) so that searches in ReMoDD will yield artifacts stored in collaborating repositories; and (4) we will extend ReMoDD with social networking features that support, for example, crowd sourcing challenging modeling problems. The enhancement of ReMoDD will be a collaborative effort involving teams from Colorado State University (CSU) and Michigan State University (MSU). ReMoDD has an Advisory Board of leading MDD researchers and industry representatives that are committed to ensuring that ReMoDD continues to be a useful and sustainable community resource. <br\/><br\/>By providing ReMoDD as MDD community infrastructure, groups performing MDD research will advance the overarching objective of Model Driven software Development (MDD), which is to reduce the cost and effort of developing complex software systems through the use of software models. The problems tackled by MDD researchers are challenging and good solutions typically evolve through a community process driven by feedback from the use of solutions in research and industrial settings. The project will strengthen engagement with the international research community, who will contribute new ideas, share tools, and share in the project effort. To support the international collaboration, this award is being co-funded by NSF?s Office of International and Integrative Activities.","title":"Collaborative Research: CI-ADDO-EN: Research Repository for Model-Driven Software Development (REMODD)","awardID":"1305358","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":[543568],"PO":["564388"]},"208090":{"abstract":"Proposal #: 13-38192<br\/>PI(s): Kuester, Falko; DeFanti, Thomas A.; Rosing, Tajana S.; Schulze, Jurgen P.<br\/>Institution: University of California - San Diego<br\/>Title: MRI\/Dev.: Advanced Visualization Instrumentation for the Collaborative Exploration of Big Data<br\/>Project Proposed:<br\/>This project, developing a Scalable Omni-Presence Environment (ScOPE), a next generation visualization system for collaborative exploration of large volumes of data, provides an environment for analyzing, processing, and visualizing Big Data resulting from many different areas of science and engineering. The instrument serves as an integrative, virtual metaphor for a combined microscope and telescope, enabling users to explore data from the nano to macro to mega scale. ScOPE provides researchers the ability to study simulated and acquired data at a level of precision previously unmatched. It is expected to become the platform for training a new generation of users to be fluent in data analytics in collaborative environments. Initially, three universities will have direct access to the ScOPE instrument and all its features: U. California-San Diego (UCSD), Jackson State U. (JSU), and U of Texas Medical Branch (UTMB). Nonetheless, following the tradition of the project team (effectively done with earlier generations of visualization technologies (e.g., OptIPortal tile display walls now installed at more than 100 institutions worldwide), the critical components of the infrastructure will be broken such that they may be replicated for use at remote locations by other research or educational institutions. The developers anticipate that private-sector collaborators, such as Qualcomm and Intel, will help popularize use of specific components for the nation?s big-data analytics infrastructure. Notwithstanding, the broadest impact of the instrument should be evident in the discoveries and advances made by engineers and scientist that use ScOPE to enhance collaboration and analysis in the disciplines that have been singled out as ?Domain Drivers? for the project. These include projects led by researchers in ocean sciences (and ocean observatories); cyber-archaeology and cultural heritage diagnostics; real-time brain imaging; digital cinema and very-high quality digital media; integrative computational biology; underwater microscopy; molecular dynamics; structural biology and computational chemistry; and large-scale numerical simulation. In turn, these domain specialists will work alongside computer scientists who will address grand challenges in system architecture, data transport, security, representation, arching, processing multi-modal analytics, and human-computer interaction. ScOPE?s long-distance collaboration will be supported by telepresence at bandwidths ranging up to 40 Gigabits per second. Thus, the project creates a highly interactive collaboration space equipped with a natural human-computer interface and advanced 3D modeling and rendering at a sufficient scale to tackle complex experiments and analyze large amount of visual and numerical data pertaining to phenomena of wide dimensions and extreme time scales. Domain drivers have been identified to ensure that the resulting environment and tools are applicable to a broad array of scientific disciplines. These include earth system sciences, civil and structural engineering, mechanical and aerospace engineering, biomedical and electrical (and ocean observatories engineering, social sciences, and anthropology. This project takes a great leap forward into a new generation of collaborative environment that until recently was unthinkable. The display capabilities will no longer be passive; envisioned is a continuous spatial workspace imaging, including eye, skin response, and even mobile electroencephalography sensing, allowing ScOPE to respond to and infer user intent. The environment will be designed specifically to handle ?big data,? using a failure-tolerant and cloud-centric approach while also downsizing the supercomputer flash memory architecture. ?Big Data.? The instrument will enable scientific discoveries as well as research on how best to process, analyze, and visualize Scope will serve as a prototype for other similar instruments. The research enabled by ScOPE will have impacts in many areas of science.<br\/>Broader Impacts: <br\/>As previously mentioned, the ScOPE instrument provides researchers the ability to study simulated and acquired data at a level of precision previously unmatched. ScOPE is expected to become the platform for training a new generation of users to be fluent in data analytics in collaborative environments. The developers anticipate that private-sector collaborators, such as Qualcomm and Intel, will help popularize the use of specific components for the nation?s big-data analytics infrastructure. Notwithstanding, the broadest impact of the instrument should be evident in the discoveries and advances made by engineers and scientist that use ScOP","title":"MRI: Development of Advanced Visualization Instrumentation for the Collaborative Exploration of Big Data","awardID":"1338192","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[557605,"560640",557607,557608],"PO":[557609]},"209191":{"abstract":"Typically, an electronic component goes through process of design, fabrication, assembly, distribution, usage in the system, and finally end of life. Obsolete integrated circuits (ICs) are commonly targeted by counterfeiters through recycling, remarking, and cloning. If counterfeit components end up in critical applications such as defense, aerospace, automotive, or medical systems, the results could be catastrophic. This research will raise awareness of counterfeiting, piracy, and electronic components recycling and remarking issues which will have positive socioeconomic effects on electronic components innovation and growth, rights' holders and consumers.<br\/><br\/>Detecting these counterfeit ICs is an extremely difficult task because of the large number of counterfeit types, part types, and defects and anomalies associated with the counterfeit parts. In this project, we develop innovative 2D\/3D optical imaging for detecting exterior physical defects, novel 3D X-ray imaging technologies for interior physical defects detection and to eliminate the need for decapping of ICs, and a Tera-Hertz imaging technology for exterior and interior physical defects detection.","title":"EAGER: Novel Imaging Approaches for the Detection of Counterfeit ICs","awardID":"1344271","effectiveDate":"2013-10-01","expirationDate":"2015-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[560769,560770,560771],"PO":["565264"]},"209192":{"abstract":"This INSPIRE award is partially funded by the Geobiology & Low Temperature Geochemistry Program in the Division of Earth Sciences in the Directorate for Geoscience; the Human Centered Computing Program in the Division of Information & Intelligent Systems in the Directorate for Computer & Information Science & Engineering; and the Virtual Organizations as Socio-technical Systems Program in the Division of Advanced Cyber-Infrastructure in the Directorate for Computer & Information Science & Engineering.<br\/><br\/>This project will develop new scientific work practices and cyberinfrastructure tools to advance the fields of hydrology and limnology (lake ecology). The project will develop a socio-technical model of \"organic team science\" in which scientists are motivated to collaborate across diverse scientific communities and to share and normalize data to solve scientific problems through an open framework. potentially creating new cross-disciplinary collaborations around the modelling problems. The project will advance hydrology by making already-collected geospatial data more usable for analysis and simulations. It will advance limnology by developing an integrated hydrodynamic model of lakes as connected to the broader hydrologic network to quantify water, material, nutrient and energy fluxes, which is potentially transformative for limnology. The project will be carried out with collaborators including the NSF Susquehanna\/Shale Hills Critical Zone Observatory and the GLEON projects.<br\/><br\/>The project will provide benefits by developing cyberinfrastructure to provide access for limnology to climate and geospatial data and models as well as novel practices for supporting organic team science. The later is potentially a significant and transformative contribution to the infrastructure for science. The hydro-dynamic model could be useful for those managing lakes. The proposal includes plans for outreach to the scientific community to share these findings.","title":"INSPIRE Track 1: The Age of Water and Carbon in Hydroecological Systems: A New Paradigm for Science Innovation and Collaboration through Organic Team Science","awardID":"1344272","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7642","name":"VIRTUAL ORGANIZATIONS"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"8078","name":"INSPIRE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0603","name":"Division of EARTH SCIENCES","abbr":"EAR"},"pgm":{"id":"7570","name":"SURFACE EARTH PROCESS SECTION"}}],"PIcoPI":["563687",560774,"561826"],"PO":["565342"]},"209182":{"abstract":"This INSPIRE award is partially funded by the Robust Intelligence Program in the Division of Information and Intelligent Systems in the Directorate for Computer and Information Science and Engineering and the Perception, Action, and Cognition Program in the Division of Behavioral and Cognitive Sciences in the Directorate for Social, Behavioral, and Economic Sciences.<br\/><br\/>This project studies a hallmark of human intelligence, namely the ability to think ahead. Anticipating the consequences of one's own actions and those of others is of crucial importance in areas as diverse as business negotiations, military strategy, and teaching. In each of these domains, the quality of one's decisions depends on the quality of one's mental simulations of event sequences, which might be limited by cognitive capacity limitations, one's grasp of the complexities of the decision space, or both. The project's goal is to identify the factors that affect people's performance in thinking ahead, and investigate to what extent this performance can be improved through training. The project ties into the study of heuristics (general rules used by decision-makers) in psychology and behavioral economics.<br\/><br\/>Thinking ahead is difficult to measure and model in real-world problems. Therefore, the investigator has developed a two-person strategic decision-making task as a controllable experimental environment. Participants take turns to put tokens on a 4x11 board and try to get four of their own tokens in a row. The rules are unfamiliar to subjects, yet easy to learn. The size of the state space for this task is of the order of 10^20, much smaller than that of chess (~10^47), yet of appreciable complexity and much too large for humans to easily grasp. The investigators have \"weakly solved\" this task using an improved version of alpha-beta pruning. It can most likely also be solved strongly, which means that one can determine in any given position whether any given decision is an error. Human data will be collected in three task modes: one in which the subject is given a position and has to win in a set number of moves; human versus computer; and human versus human. The investigators will track subjects' eye movements, which could reveal aspects of planning and perhaps even serve to visualize the process of mental simulation. <br\/><br\/>An important component of the project will be computational modeling of the data. Humans cannot think ahead to the end of the task, so we hypothesize that they use simple features of positions (heuristics) to value certain moves over others. Examples of features could be the presence of a three-in-a-row, or of an adjacent, open-ended two-in-a-row. Preliminary human data suggest \"strategic blind spots\" created by the application of the incorrect heuristics. The investigators aim to predict the probability that a subject will in a given position make a particular move, based on features of the position that would be created by that move, as well as the subject's limited depth of reasoning. The resulting model will allow to quantitatively address the question of whether learning mostly serves to increase one's depth of reasoning or to refine one's palette of heuristics. The behavioral and eye movement data will lay the foundation for studies of the neural substrates of reasoning in complex decision-making contexts.<br\/><br\/>The project is positioned at the intersection of computer science, cognitive psychology, management and decision science, and education, and has the potential to contribute to each of these fields. In the long run, the project might be able to contribute to understanding and perhaps avoiding failures to think \"out of the box\" in real-life problem-solving. Moreover, strategic tasks like the one used in this project could serve as a mini-environment for testing hypotheses about teaching methods.","title":"INSPIRE Track 1: Human reasoning and learning in a complex but tractable decision-making paradigm","awardID":"1344256","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"7252","name":"PERCEPTION, ACTION & COGNITION"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"8078","name":"INSPIRE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[560732],"PO":["564318"]},"209590":{"abstract":"perfSONAR (http:\/\/www.perfsonar.net) is a set of community-developed protocols and a widely-adopted infrastructure for multi-domain network performance monitoring, facilitating the ability to collect and share measurement data relevant to solve end-to-end network performance problems and to enable network-aware applications. The first perfSONAR workshop was successfully held 8-9 July 2010 in Arlington, VA. This project will organize and hold the Second perfSONAR workshop to be held February 20-21 2014 at at the NSF in Arlington VA, open to members of the perfSONAR community. The goal of the second workshop is to build upon the first workshop outcomes and capitalize on the inherent flexible multi-domain nature of the perfSONAR protocols and infrastructure. The intended focus is to cross-fertilize ideas from a variety of stakeholders that include: researchers, applications developers, network operators, network managers, and others with an interest in network research and performance measurement\/monitoring.<br\/><br\/>The workshop goals include:<br\/> 1. Identification of unimplemented techniques and network research focus areas with existing ideas that can help solve problems of R&E networks, as well as open research questions focused on solving real world end-to-end performance problems;<br\/> 2. Identification of required perfSONAR infrastructure components for network operators, end users, network researchers, and virtual organizations, and any missing components;<br\/> 3. Operational requirements, federation policies and best practices for ongoing and on-demand measurements end-to-end, cross-domain, and transoceanic links; and<br\/> 4. Creating a larger perfSONAR community seeded by the workshop participants, including strategies for engaging new network researchers, new domain science researchers, new science communities, and new networks.<br\/><br\/>perfSONAR is a tool supporting multiple high-priority programs in multiple U.S. agencies. It is a key tool for network diagnostics for in the High Performance Computing community. As such enhancements to the perfSONAR framework have direct impacts on projects across a wide range of disciplines. The output of the workshop will be a report suitable for archival within the ACM Digital Library. The report will summarize the discussions and recommendations of participants in accordance with the aforementioned workshop goals, and could serve to inform and guide future community actions.","title":"Collaborative Research: Workshop on perfSONAR based Multi-domain Network Performance Measurement and Monitoring","awardID":"1346852","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[561820],"PO":["564993"]},"208061":{"abstract":"This is an award to acquire a compute cluster at LSU. The computer is a heterogeneous HPC cluster named SuperMIC containing both Intel Xeon Phi and NVIDIA Kepler K20X GPU (graphics processing unit) accelerators. The intent is to conduct research on programming such clusters while advancing projects that are dependent on HPC. The efforts range from modeling conditions which threaten coastal environments and test mitigation techniques; to simulating the motions of tumors\/organs in cancer patients due to respiratory actions to aid radiotherapy planning and management. The burden of learning highly complex hybrid programming models presents an enormous software development crisis and demands a better solution. SuperMIC will serve as the development platform to extend current programming frameworks, such as Cactus, by incorporating GPU and Xeon Phi methods. Such frameworks allow users to move seamlessly from serial to multi-core to distributed parallel platforms without changing their applications, and yet achieve high performance. The SuperMIC project will include training and education at all levels, from a Beowulf boot camp for high school students to more than 20 annual LSU workshops and computational sciences distance learning courses for students at LONI (Louisiana Optical Network Initiative) and LA-SiGMA (Louisiana Alliance for Simulation-Guided Materials Applications) member institutions. These include Southern University, Xavier University, and Grambling State University - all historically black colleges and universities (HBCU) which have large underrepresented minority enrollments. The SuperMIC cluster will be used in the LSU and LA-SiGMA REU and RET programs. It will impact the national HPC community through resources committed to the NSF XSEDE program and the Southeastern Universities Research Association SURAgrid. The SuperMIC will commit 40% of the usage of the machine to the XSEDE XRAC allocation committee.","title":"MRI: Acquisition of SuperMIC -- A Heterogeneous Computing Environment to Enable Transformation of Computational Research and Education in the State of Louisiana","awardID":"1338051","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7726","name":"DATANET"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"7231","name":"CYBERINFRASTRUCTURE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}},{"dir":{"id":"14","name":"Office of OFFICE OF POLAR PROGRAMS                ","abbr":"OPP"},"div":{"id":"1403","name":"Division of ANTARCTIC SCIENCES DIVISION","abbr":"ANT"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["559222",557461,"199555",557463,"558252"],"PO":["565292"]},"208072":{"abstract":"Proposal #: 13-38099<br\/>PI(s): Vardi, Moshe; Allen, Genevera; Bradshaw, Stephen; Karaki, Lydia; Veeraraghavan, Ashok<br\/>Institution: Rice University<br\/>Title: MRI\/Acq.: Big-Data Private Cloud Research Cyberinfrastructure (BDPC) <br\/>Project Proposed:<br\/>This project, acquiring a novel cyber-infrastructure instrument for big data cloud computing designed as a loosely coupled computations system with large memory requirements, enables a significant range of application domains as well as research into infrastructures for cloud computing. The domain sciences addressed range from development of big-data enabling software technologies spanning fundamental computer science work, to the analysis of electronic medical records, twitter streams, and hurricane evacuation strategies. Additional benefits are expected in understanding disease and therapeutic treatments, and in the development and application of mathematical models in the areas of machine learning, optimization, compressed sensing, image processing, and statistical analysis and data mining. The instrument will also help bridge the gap between numerical models and observations in astrophysics.<br\/>Broader Impacts: <br\/>The broader impacts on society, and especially in education and training (including for members of underrepresented groups) are all compelling. The instrument will directly impact the educational experience for all students taking classes in computing and computational problem solving. The targeted research communities are diverse and broad, including the underrepresented groups, with strong empirical and experimental components. The proposed instrument is highly suitable for training and education.","title":"MRI: Acquisition of Big-Data Private-Cloud Research Cyberinfrastructure (BDPC)","awardID":"1338099","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["565263",557516,557517,557518,"559636"],"PO":["557609"]},"209183":{"abstract":"This INSPIRE award is partially funded by the Cyber-Human Systems Program in the Directorate for Computer and Information Science and Engineering, the Robust Intelligence Program in the Directorate for Computer and Information Science and Engineering, and the Social Psychology Program in the Directorate for Social, Behavioral and Economic Sciences. The goal of this project is to gather new insights into the ways people organize and understand their worlds within and across different cultures by means of innovative methodologies and tools from the fields of psychology and computational linguistics. The findings from this project will provide a better understanding of people on the individual psychological level as well as the cultures themselves, while developing and demonstrating new research techniques that can be used in future by many disciplines to exploit the vast troves of scientifically valuable textual data currently available online. Specifically, the project targets the following three main research objectives: 1) Construct a very large multicultural database of writings from English-speaking cultures, covering several styles and genres, including: social media (e.g., blogs, tweets); news articles; literary works; student writings. 2) Build computational linguistic models that can automatically identify differences in concept usage for different cultures, and apply these models on a large scale. 3) Validate the findings of these computational models through psychological qualitative and quantitative methods in laboratory studies. <br\/><br\/>The ways people use words can provide insights into the ways they see and understand their worlds. Everyday language can also tell us about people's social, emotional, and psychological states and even the ways they think about themselves and others. Particularly interesting is that many of the social and psychological insights we find with the language of individuals can be extrapolated to groups, communities, and entire cultures. This project seeks to analyze the written language of people across several cultures in a way that will allow us to better understand the ways groups of people understand their worlds. In short, it will use advances in computational linguistics and social psychology to track the underlying values, beliefs, and concerns of very large groups of people by analyzing the ways they use words. Unlike previous studies, which have been limited to relatively small self-report surveys targeting a handful of concepts across cultures, this project will help us understand the differences in perception for thousands of concepts, by several cultures representing hundreds of thousands of people.<br\/><br\/>This project promises to shed new light on cultural differences by analyzing the ways people understand their worlds through their everyday language use. The approach will inform applications in communication, threat control, tracking of cultural values, and others. The project will also provide educational opportunities, in the form of training for students in both computer science and psychology, who will be directly exposed to interdisciplinary research, cultural diversity, and international experiences. Finally, the large multicultural dataset that will be created as part of this project, along with the tools to process it, will be made publicly available, thus enabling future research, as well as educational projects concerned with the analysis and understanding of cultural diversity and worldview.","title":"INSPIRE Track 1: Language-Based Computational Methods for Analyzing Worldviews","awardID":"1344257","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"8078","name":"INSPIRE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["564432",560735],"PO":["564456"]},"208062":{"abstract":"This award enables Villanova to purchase and further develop an interactive virtual reality system known as a System for Immersive Video Research, Immersive Learning, and Visualization Support for Research (CAVE) at Villanova University. The Falvey Memorial Library at Villanova will house the facility. CAVE technology's ability to provide immersive experiences of rendered environments is well-known. This project proposes development of a CAVE system with mobile immersive spherical video technology to capture photorealistic representations of real world environments without involved modeling. This development project has two facets. The first lies in the integration of mobile immersive spherical video camera equipment with a CAVE to display real-world environments, thereby reducing environmental modeling time. This approach will permit greater usage of CAVE technology for disseminating immersive views of significant locations or phenomena without concern for the displayed material appearing too unrealistic. The second facet is the project's visualization support for research across many domains. CAVE placement near the greater Philadelphia area will permit increased public access to the learning possibilities of the equipment, as well as support the collection and dissemination of immersive videos of culturally significant locations such as the Vatican Museum's facilities that are often not able to be visited by large crowds. Understanding how to systematically use CAVE technology in libraries has the potential to transform these institutions into social and collaborative environments, called public Collaboratories. Classrooms for CAVE use will be established.","title":"MRI: Development of a CAVE System for Immersive Video Research, Immersive Learning, and Visualization Support for Research at Villanova","awardID":"1338052","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7619","name":"EQUIPMENT ACQUISITIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"14","name":"Office of OFFICE OF POLAR PROGRAMS                ","abbr":"OPP"},"div":{"id":"1403","name":"Division of ANTARCTIC SCIENCES DIVISION","abbr":"ANT"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[557466,557467,557468],"PO":["565272"]},"208084":{"abstract":"Proposal #: 1338155<br\/>PI(s): Ricci, Robert; Corbato, Steven C; Eide, Eric N; Facelli, Julio C; Van Der Merwe, Jacobus<br\/>Institution: University of Utah <br\/>Title: MRI\/Dev: Apt, a Testbed Instrument with Adaptable Profiles for Network and Computational Science<br\/>Project Proposed:<br\/>This project, developing a novel adaptable instrument (Apt), aims at attaining a novel control framework to manage a cluster of compute nodes, storage servers, and a flexible interconnect fabric. Adaptability constitutes the key feature enabling the creation of diverse instruments for computer science research. The work is geared towards representing a new generation of testbed instruments that engage a broader community of users by empowering them to customize it to their needs. The instrument is expected to leverage and drive the trends in cloud computing, thus making the development of adaptable instrument environments easier, cheaper, and less risky. At the same time, it offers properties not available on commercial clouds, including the proposed levels of resource fidelity and transparency required of a scientific instrument. The project also develops the control and management system for creating and using profiles, and for supporting concurrent experiments and allocating resources among them in a dynamic manner. The fundamental building blocks of Apt identified include: <br\/>- Resource provisioning, scheduling, and conditioning; <br\/>- Operational state tracking; experiment management, archive, and replay; and <br\/>- User management. <br\/>This work contributes to make these elements reusable in a way that enables the proposed to be shared by profiles supporting a wide range of research domains. The domains currently targeted include, but are not limited to, sustainable energy control systems, biomolecular science, privacy and security, and data-intensive computation.<br\/>Broader Impacts: <br\/>The instrument is expected to be a national resource for computer science and other computing-based fields, Internet-accessible and to contribute to the nation?s cyberinfrastructure. The broad and diverse targeted research communities include strong empirical and experimental components. The proposed instrument is highly suitable for training and education.","title":"MRI: Development of Apt, A Testbed Instrument with Adaptable Profiles for Network and Computational Science","awardID":"1338155","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[557574,557575,"559299","559300","560436"],"PO":["557609"]},"208030":{"abstract":"Proposal #: 13-37884<br\/>PI(s): Cook, Jonathan E.<br\/> Cao, Huiping; Cook, Jeanine M.; Pontelli, Enrico; Song, Mingzhou<br\/>Institution: New Mexico State University <br\/>Title: MRI\/Acq.: Instrument for Research in Irregularly Parallel Big Data Computation<br\/>Project Proposed:<br\/>This project, acquiring a computational instrument configured to support data-driven graph computations (DDGC) that might enable-to-scale and improve parallel computation that is generally irregular and hard to scale and improve. (Very regular computations--for example, fluid dynamics--already have a long history of development and are highly optimized to run on modern high performance (HPC) instruments.) <br\/>The instrument, with 320 cores and a node and system architecture, is designed specifically with potentially transformative DDGC research in mind. The local node memory hierarchy includes both fast solid state secondary storage and traditional mechanical disk storage. Research projects explore ways to exploit the new layer of fast solid state storage, not just as a standalone data container, but within the memory hierarchy of the local node. The system has in its configuration both GPU and FPGA computing support. Some of the research projects exploit non-traditional, yet potentially powerful computation mechanisms. In particular, the instrument supports the following projects:<br\/>- Genome Assembly and Annotation Computations,<br\/>- Data Mining over Large Graphs,<br\/>- Reasoning with Big Knowledge,<br\/>- Hardware Acceleration for Scalable Graph-Based Computations, and<br\/>- Data Driven Monitoring and Analysis of Scientific Computations.<br\/>Each of these projects will make use of the general architecture of the instrument. GPU and FPGA capabilities will be used to further explore and enhance the possibilities to improve performance of data-driven graph computations. The instrument architecture is intended to enable cross-fertilization between the research projects that will, in turn, contribute to the development of new approaches that can perform DDG computations efficiently.<br\/>Broader Impacts: <br\/>Due to the growth of data analytics in so many areas of society, the techniques developed utilizing the instrument should be valuable across society (from economic capacity to homeland security needs). <br\/>Techniques that can improve the DDG computations within many of the big data computations (from improved algorithms to newly demonstrated hardware approaches) are immediately useful. Moreover, the instrumentation enriches the research and educational activities at a minority-serving institution within an EPSCoR jurisdiction. The project offers opportunities for students and professors to participate in novel computer research.","title":"MRI: Acquisition of an Instrument for Research in Irregularly Parallel Big Data Computation","awardID":"1337884","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["561141",557313,557314,557315,557316],"PO":["557609"]},"209251":{"abstract":"The majority of morbidity and mortality during adolescence is preventable and related to behaviors such as substance use and vehicle-related injuries. Most adolescents visit a healthcare provider once a year, providing an ideal opportunity to integrate behavioral health screening into clinical care. Although the majority of adolescent health problems are amenable to behavioral intervention, few health information technology interventions have been integrated into adolescent care. With complementary theoretical advances (social-cognitive theories of behavior change) and technology advances (intelligent narrative-centered learning environments, user modeling, and machine learning), the field is now well positioned to design health behavior change systems that can realize significant impacts on behavior change for adolescent preventive health. <br\/><br\/>Computationally-enabled models of behavior change hold significant promise for adolescent healthcare. The objective of the proposed research is to design, implement, and investigate INSPIRE, a self-adaptive personalized behavior change system for adolescent preventive health. INSPIRE will utilize a social-cognitive theory of behavior change built around a tight feedback loop in which a narrative-centered behavior change environment will produce improved behaviors in patients, and the resulting patient outcome data will be used by a reinforcement learning optimization system to learn refined computational behavior change models. With a focus on risky behaviors and an emphasis on substance use, adolescents will interact with INSPIRE to develop an experiential understanding of the dynamics and consequences of their substance use decisions. A unique feature of INSPIRE afforded by recent advances in machine learning will be its ability to optimize health behavior change at both the individual and population levels. At the individual level, INSPIRE will utilize a patient behavior model to personalize its behavior change narratives for individual adolescents. It will customize interactions based on an adolescent's goals and affective models. At the population level, INSPIRE will utilize reinforcement learning to adapt its narrative generation system to systematically increase its ability to improve two types of outcomes: behavior change and self-efficacy. The project will culminate with an experiment conducted with a fully implemented version of INSPIRE at outpatient clinics within the UC San Francisco Department of Pediatrics, Benioff Children's Hospital. <br\/><br\/>It is anticipated that INSPIRE interventions will yield two types of outcomes: 1) improved health behavior through significant reductions in adolescent risky behavior, relative to standard of care; and 2) increased self-efficacy with respect to adolescents' ability to make good decisions about their health behaviors, relative to standard of care. Designed for natural integration into clinic workflow, interoperability with EHR and patient portal systems, and security and privacy requirements, INSPIRE will report patient behavior change summaries to healthcare providers. Through multi-platform deployments supporting laptop, desktop, tablet, and mobile computing devices, INSPIRE will serve as an empowering tool for adolescents, making them full participants in their own wellbeing. It will also enable researchers to run behavior analytics to investigate which properties of alternate interventions contribute most effectively to behavior change outcomes. Going forward, it is anticipated that INSPIRE will provide a testbed for a broad range of behavior change research and serve as the foundation for next-generation personalized preventive healthcare through computationally-enabled behavior change.","title":"SCH: INT: Collaborative Research: A Self-Adaptive Personalized Behavior Change System for Adolescent Preventive Healthcare","awardID":"1344670","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[560972],"PO":["565136"]},"208074":{"abstract":"Proposal #: 13-38105<br\/>PI(s): Zhu, Ye; Kaufman, Miron; Wang, Haodong; Xiong, Fuqin; Yu, Chansu<br\/>Institution: Cleveland State University <br\/>Title: MRI\/Acq.: A 4G\/LTE Wireless Communication Test Set<br\/>Project Proposed:<br\/>This project, acquiring an E6621A PXT 4G\/LTE wireless communication test set, aims to enable studies on:<br\/>- Security and privacy of 4G communications,<br\/>- Fast indoor positioning in large-scale, chaotic venues,<br\/>- Efficient modulation and coding for 4G mobile communications,<br\/>- Characterization of noise in wireless channels with statistical physics approaches, and<br\/>- Security of medical communication systems.<br\/>The proposed system would also enable research on complex topics that require multidisciplinary approaches, including<br\/>- Hybrid approaches to detect security attacks and privacy leakage in 4G networks,<br\/>- Cross layer design for 4G networks, and<br\/>- Modulation support for indoor positioning systems.<br\/>Since the versatile and highly integrated system supports conducting both physical layer research through features such as RF parametric measurement and MIMO operation, and network and upper layer conducts research through features such as protocol logging and analysis and message editor, this instrumentation should facilitate these projects. Moreover, the research supported by the acquisition would impact a wide range of scientific and engineering fields such as digital communications, networking, distributed computing, mobile computing, network security and privacy, information systems, and physics.<br\/>Broader Impacts:<br\/>This acquisition would enable the development of new labs, projects, and lectures in seven courses and would provide students with hands-on experiences. The instrument would also provide valuable research experiences to undergraduates (through senior design projects, summer undergraduate research, and independent study research projects) and graduate Masters and Ph.D. students in electrical engineering, computer engineering, computer and information science, and physics. The university has also been actively involving minority, women, and disadvantaged background students in research. Thus, the instrument will contribute in the well-established outreach programs such as NSF-funded CSUTeach program (0934842) which is designed to improve the quality of high school science and math teachers, and the Fenn Academy, a consortium between the Fenn College of Engineering and a group of high schools and local corporations (established to attract students to engineering fields through high-quality pre-engineering programs). The instrument would also lend support to some local companies.","title":"MRI: Acquisition of a 4G\/LTE Wireless Communications Test Set","awardID":"1338105","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[557526,557527,557528,"469752",557530],"PO":["557609"]},"205391":{"abstract":"The project examines novel services built on top of public cloud<br\/>infrastructure to enable cost-effective high-performance computing.<br\/>The PIs will explore the on-demand, elastic, and configurable features of<br\/>cloud computing to complement the traditional supercomputer\/cluster<br\/>platforms. More specifically, this research aims to assess the efficacy<br\/>of building dynamic cloud-based clusters leveraging the configurability<br\/>and tiered pricing model of cloud instances. The scientific value of this<br\/>proposal lies in the novel use of untapped features of cloud computing<br\/>for HPC and the strategic adoption of small, cloud-based clusters for<br\/>the purpose of developing\/tuning applications for large supercomputers.<br\/><br\/>Through this research, the PIs expect to answer key research questions<br\/>regarding: (1) automatic workload-specific cloud cluster configuration,<br\/>(2) cost-aware and contention-aware data and task co-scheduling,<br\/>and (3) adaptive, integrated cloud instance provisioning and job<br\/>scheduling, plus workload aggregation for cloud instance rental cost<br\/>reduction. If successful, this research will result in tools that<br\/>adaptively aggregate, configure, and re-configure cloud resources for<br\/>different HPC needs, with the purpose of offering low-cost R&D<br\/>environments for scalable parallel applications.","title":"CSR: Small: Collaborative Research: Enabling Cost-Effective Cloud HPC","awardID":"1318572","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["553485"],"PO":["565255"]},"209263":{"abstract":"The majority of morbidity and mortality during adolescence is preventable and related to behaviors such as substance use and vehicle-related injuries. Most adolescents visit a healthcare provider once a year, providing an ideal opportunity to integrate behavioral health screening into clinical care. Although the majority of adolescent health problems are amenable to behavioral intervention, few health information technology interventions have been integrated into adolescent care. With complementary theoretical advances (social-cognitive theories of behavior change) and technology advances (intelligent narrative-centered learning environments, user modeling, and machine learning), the field is now well positioned to design health behavior change systems that can realize significant impacts on behavior change for adolescent preventive health. <br\/><br\/>Computationally-enabled models of behavior change hold significant promise for adolescent healthcare. The objective of the proposed research is to design, implement, and investigate INSPIRE, a self-adaptive personalized behavior change system for adolescent preventive health. INSPIRE will utilize a social-cognitive theory of behavior change built around a tight feedback loop in which a narrative-centered behavior change environment will produce improved behaviors in patients, and the resulting patient outcome data will be used by a reinforcement learning optimization system to learn refined computational behavior change models. With a focus on risky behaviors and an emphasis on substance use, adolescents will interact with INSPIRE to develop an experiential understanding of the dynamics and consequences of their substance use decisions. A unique feature of INSPIRE afforded by recent advances in machine learning will be its ability to optimize health behavior change at both the individual and population levels. At the individual level, INSPIRE will utilize a patient behavior model to personalize its behavior change narratives for individual adolescents. It will customize interactions based on an adolescent's goals and affective models. At the population level, INSPIRE will utilize reinforcement learning to adapt its narrative generation system to systematically increase its ability to improve two types of outcomes: behavior change and self-efficacy. The project will culminate with an experiment conducted with a fully implemented version of INSPIRE at outpatient clinics within the UC San Francisco Department of Pediatrics, Benioff Children's Hospital. <br\/><br\/>It is anticipated that INSPIRE interventions will yield two types of outcomes: 1) improved health behavior through significant reductions in adolescent risky behavior, relative to standard of care; and 2) increased self-efficacy with respect to adolescents' ability to make good decisions about their health behaviors, relative to standard of care. Designed for natural integration into clinic workflow, interoperability with EHR and patient portal systems, and security and privacy requirements, INSPIRE will report patient behavior change summaries to healthcare providers. Through multi-platform deployments supporting laptop, desktop, tablet, and mobile computing devices, INSPIRE will serve as an empowering tool for adolescents, making them full participants in their own wellbeing. It will also enable researchers to run behavior analytics to investigate which properties of alternate interventions contribute most effectively to behavior change outcomes. Going forward, it is anticipated that INSPIRE will provide a testbed for a broad range of behavior change research and serve as the foundation for next-generation personalized preventive healthcare through computationally-enabled behavior change.","title":"SCH: INT: Collaborative Research: A Self-Adaptive Personalized Behavior Change System for Adolescent Preventive Healthcare","awardID":"1344803","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[561013],"PO":["565136"]},"209153":{"abstract":"Current healthcare diagnostics and assessment systems are limited by health data, which is sporadic, periodic, and incomplete. Wireless devices and health sensor technologies are increasing in use for continuous monitoring and assessment of key physiologic, psychological, and environmental variables and reduce the current gaps in health data. Uptake of such data by current health systems has been slow because of the reliance upon the physician\/healthcare team to interpret and manage incoming data. Nevertheless, the large streams of data generated by these devices in conjunction with traditional clinical data (Electronic Medical Records) have the potential provide real and important insights into patient health and behavior. To address this gap, this proposal will develop SenseHealth -- a novel software platform that will automatically process and incorporate volumes of real-time data from sensors tailored to the individual in the context of personal electronic medical records and available environmental data. Such data will be integrated into the clinical care workflow to enable system usability, feasibility, and ultimately utility. A core component of the cyberinfrastructure is a collection of quantitative, predictive models that are sensitive to concerns across age, diseases, and health and variety of patient situations (ranging from low priority with no consequence on patient management to high priority requiring emergency evaluation), and sensor failures. The models will be integrated with a distributed real-time stream data processing system and a complex event stream processing engine to process sensor data in a scalable and fault-tolerant manner. Research at Rady Children's Hospital of San Diego, an affiliate of UCSD will be leveraged to develop these models. In each of the following studies, clinically relevant events (i.e. events that require clinical intervention) will be identified and disease specific models will be developed that will predict clinical relevance or the need for intervention. Incoming data and resulting clinical management activity from studies using various types of health sensors will be evaluated in two different patient populations: (1) MyGlucoHealth application for evaluating the use of a Bluetooth-enabled glucometer (for blood sugar measurements) in 40 youths with Type 1 diabetes, and (2) Asthma Tracking application for evaluating the ability of a metered dose inhaler (MDI) tracking device to track asthma medication use in 50 mild-to-moderate asthma subjects over a period of 6 months. The models will then be evaluated using multiple sensor streams in youth with diabetes (The Diabetes Management Integrated Technology Research Initiative (DMITRI) study) and in a prospective study in youth with asthma to determine their validity, efficacy, and utility in identifying patient scenarios of concern.<br\/><br\/>The SenseHealth system architecture will consist of four major components (1) Health and environmental sensors linked with (2) smartphone applications that communicate with (3) a back-end Data Center comprised of data storage and clusters doing and real-time analytics and data visualization, which will then provide a comprehensive health picture to users\/clients via (4) tailored, programmed user\/client applications. For these continuous sensing applications, managing sensors and smartphone in an energy-efficient manner is critical. SenseHealth will include a novel context-aware power management framework that uses both the application-level context (e.g., sensor data) and the dynamic environmental or system-level context (e.g., battery level, next phone charging opportunity prediction, or bandwidth availability) to adaptively control the state of hardware components and deliver a consistent performance (e.g. data accuracy, latency). In particular, data sampling protocols will be energy-aware and will be designed to sample data accurately but only as necessary to provide relevant clinical information. SenseHealth will use Storm, an open source distributed real-time computation system to process the data in a scalable and fault-tolerant manner. The aforementioned predictive models will be implemented in ESPER, an open-source complex event processing (CEP) engine. The models will use ESPER's rich Event Processing Language (EPL) to express filtering, aggregation, and joins, possibly over sliding windows of multiple event streams and pattern semantics to express complex temporal causality among events and trigger custom actions when event conditions occur among event streams. Finally, SenseHealth will fuse sensor and clinical data in a visual format that will increase interpretability and comprehension independent of literacy levels and will provide feedback and ultimately intervention support that is timely and relevant to the user (patient and clinician) based on comprehensive knowledge of data. Open source software visualization tools developed at Calit2 that leverage advances i","title":"SCH: EXP: SenseHealth: A Platform to Enable Personalized Healthcare through Context-aware Sensing and Predictive Modeling Using Sensor Streams and Electronic Medical Record Data","awardID":"1344153","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[560639,560640,560641,560642,560643],"PO":["565136"]},"209164":{"abstract":"This INSPIRE award is partially funded by the Engineering and Systems Design and the Manufacturing programs in the Civil, Mechanical and Manufacturing Innovation Division of the NSF Engineering Directorate and by the Information Integration and Informatics Program in the Division of Information and Intelligent Systems in the NSF Computer and Information Science and Engineering Directorate.<br\/><br\/>The objective of this research project is to establish a universal formal computational model for the information that flows from design into additive manufacturing. This model plays a role similar to that of the Church-Turing model that underlies general computation. It describes part geometry and materials while connecting to the physics that underlies a part. The computational model is necessary to embody complex information and enable new behaviors in ways that existing tools and technologies cannot accommodate.<br\/><br\/>In the new world of additive manufacturing, the central embodiment of an artifact, the thing that we buy and sell and improve, will be the information used to additively manufacture an object, not the object itself. This project is developing a language in which to express that information, a language sufficiently rich and rigorous to unleash design capabilities and control manufacturing processes. Development of such a language \/ model is a critical step to bringing the Maker culture into the economic mainstream.","title":"INSPIRE Track 1: The Informatics of Making","awardID":"1344205","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"8078","name":"INSPIRE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1385","name":"SPECIAL STUDIES AND ANALYSES"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1464","name":"ENGINEERING DESIGN AND INNOVAT"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"7951","name":"ENG INTERDISC RES (IDR)"}}],"PIcoPI":[560676,560677],"PO":["564651"]},"209197":{"abstract":"This INSPIRE award is partially funded by the Software and Hardware Foundations Program in the Division of Computing and Communication Foundations in the Directorate for Computer and Information Science and Engineering, the Developmental Systems Program in the Division of Integrative Organismal Systems in the Directorate for Biological Sciences, and the Biological and Computing Shared Principles working group. <br\/><br\/>Every cell contains an extremely complex control system for functions essential for survival and reproduction of the organism. Identification of the design principles embodied in this poorly understood core regulatory circuitry of the cell is the focus of this project. In many ways, this cellular control system resembles the electronic systems that humans design, although it uses biochemical and genetic reactions instead of transistors as its underlying technology. Over many decades, electrical engineers have learned design principles that enable the design of robust, reliable systems. This project investigates whether cellular control circuitry makes use of these same principles, and whether there are new principles that can be learned from cells. This is addressed by analysis of the essential logic controlling the bacterium Caulobacter crescentus. Caulobacter control circuitry resembles asynchronous digital circuits, a type of digital design that does not use a global clock signal to coordinate the system. The design of reliable asynchronous circuits is a difficult engineering challenge, and many interesting methods for designing and analyzing these circuits have been developed. <br\/><br\/>This project maps out the essential control circuitry, which regulates the processes that are vital to cell viability, using a combination of laboratory and computational methods. The research integrates results from several types of high-throughput data, including ribosome profiling, RNA-seq data at various points in the cell cycle, and ChIP-seq, and combines that with computational DNA binding motif search. A hybrid continuous and discrete mathematical model will be developed for the essential cell regulatory system, and a homologous asynchronous digital circuit will be constructed and analyzed using model checking software. The circuit structure and model checking results are used to map existing asynchronous circuit design concepts to the biological domain, and to identify new circuit design methods that may have been selected by evolution that lead to the extreme robustness displayed by living cells.","title":"INSPIRE track 1: Asynchronous circuit design principles in the essential regulatory network of Caulobacter Crescentus","awardID":"1344284","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"8078","name":"INSPIRE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7931","name":"COMPUTATIONAL BIOLOGY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"7275","name":"CROSS-EF ACTIVITIES"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"1118","name":"PLANT FUNGAL & MICROB DEV MECH"}}],"PIcoPI":[560798,560799,560800],"PO":["565264"]},"203390":{"abstract":"The cerebral cortex is comprised of two competing types of brain cells: inhibitory neurons tend to suppress brain activity while excitatory neurons do the opposite. This project will illuminate principles governing the balance of inhibition versus excitation. Focusing on the role of inhibition, the project will test the hypothesis that a particular intermediate level of inhibition is optimal for sensory information processing, because it places the cortex network in a special operating regime called criticality. <br\/><br\/>When inhibition is too high, cortical neurons are suppressed and act largely independently. When inhibition is too low neurons are hyperactive and act largely in unison. Neither extreme is conducive to effective information processing. However, gradually decreasing inhibition from a high level can result in an abrupt onset of correlated, intense activity among the neurons. The tipping point of this onset is called criticality. Importantly, computer models and cortex slice investigations predict that at criticality certain types of information processing are optimized. However, the potentially pivotal role of criticality in processing real sensory input in an intact sensory system remains untested. Such tests will be undertaken here in an in vitro whole-brain preparation that allows the researchers to precisely manipulate levels of global inhibition, record cortical activity with microelectrode arrays for many hours, and stimulate the retina with naturalistic images. Employing novel, statistically rigorous, multifaceted, quantitative tests of criticality, the proposed research will determine the roles of inhibition and criticality in intact cortex during visual processing. Specifically, the experiments are designed to determine whether information transfer from visual stimulus to cortical response is maximized at an intermediate level of inhibition which manifests as criticality.<br\/><br\/>This project represents the first experimental test of the hypothesized functional benefits of criticality in real sensory processing. It builds on a strong conceptual foundation combining statistical physics and computational neuroscience, and may open a new paradigm for investigating cortical visual processing in large neural networks. This new paradigm is particularly relevant in light of emerging new technologies that enable the recording of activity from thousands of neurons. From the medical perspective this contribution is significant because it is expected to illuminate the etiology of numerous brain disorders with abnormal inhibition. Finally, the project brings the excitement of research into Missouri and Arkansas high schools with teacher training and classroom presentations. Newly fostered interest in STEM research will be assessed by longitudinal measures.","title":"CRCNS: Collaborative Research: The role of inhibition and correlated dynamics in cortical visual processing","awardID":"1308159","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[544949],"PO":["564318"]},"202191":{"abstract":"The capability to preserve, model, and predict information cascades over online social networks has many theoretical and practical implications, e.g., for marketing, recommendation filtering, and studying of societal behavior. Massive empirical data sets on users' online social activities are being collected, but they are often too big to analyze. The goal of this project is to design graph generative models and summarization techniques that can preserve pertinent information about online social interactions that lead to interesting events, e.g., viral diffusion of information or drastic change of user behavior. Towards this end, the project will develop generative models that can capture the dynamic evolution of user activity graphs (UAGs), which represent a sequence of inter-user communications\/actions. At the microscopic level, the project will investigate user influence in the recruitment process. In addition, the project will design graph summarization techniques that can achieve good tradeoffs between data compression ratio, computational complexities, and accuracy in answering fundamental queries, such as identifying 'influential' sources of information cascades.<br\/><br\/>Broader Impact: If successful, this project will provide efficient methods for storing\/archiving massive graph data to support longitudinal study on the dynamics of online social interactions, which has potential impact on multiple disciplines (e.g., economics, history, political sciences, and social science). This project will help train future researchers and practitioners in online social networking and network science through classroom curriculum development and online teaching. The PIs will continue ongoing diversity recruitment and outreach to K-12 students. Transfer of technology into commercial practice is made feasible through partnership with industry.","title":"NeTS: Medium: Collaborative Research: Towards Building Time Capsule for Online Social Activities","awardID":"1302197","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["349186"],"PO":["565090"]},"205491":{"abstract":"The Internet has transformed from a small non-profit network into a gigantic infrastructure that creates revenues measured in billions of dollars. Unfortunately, this has created an unprecedented pressure on the end user's privacy by trackers and information aggregators, because a user's profile is used to determine which personalized content (e.g., ads, search results, recommendations, etc.) will be served to the given user. The common goal of the trackers is to gather a more perfect user profile in an attempt to increase revenues from content personalization. Such user profiling can often be misused. For example, signs of price and search discrimination have been recently reported. Others argue that content personalization, which creates the so-called 'filter bubble' effect, has an even more profound impact on the society and in particular on the future of democracy.<br\/><br\/>The PI proposes endpoint user profile control as a comprehensive approach to the above personalization-induced problems. In the PI's approach, the user has the ability and means, which this project will develop, to explicitly define and implicitly control its profile at all possible trackers at once. The PI will develop and implement endpoint user profile controller as a thin sub-layer that 'sits' between the end-user and endpoint client applications. The controller imprints the desired user profiles by leaving controlled online footprints in the public domain, e.g., by actively visiting web pages from a set of selected topics, sending search queries semantically linked with the user-defined profile etc. This allows users to submit their preferences to all possible trackers they encounter, granting the user a single point of control over their profiles. <br\/><br\/>Intellectual Merit: The proposed research will address fundamental questions that are key to developing and deploying effective endpoint user profile control. The main challenges are how to effectively control numerous ad trackers at once and how to achieve this in a scalable and effective manner. The PI's focus will be on the control of (i) ad trackers, (ii) web site trackers, (iii) search engine trackers, (iv) social-network trackers, and (v) information aggregators. The PI will develop statistical methods to accurately evaluate the properties of these trackers in order to effectively control them. The proposed techniques range from statistical rule mining to developing comprehensive scoring, noise-reduction, and orthogonal probing algorithms that are necessary for effective control.<br\/><br\/>Broader Impact: By empowering the user to explicitly and comprehensively control his user profile on the Internet, the system will not only help users regain their online privacy, but also enhance human liberties and promote free and open society. This will be possible to achieve without scrutinizing the online advertising industry, which is effectively funding today's Internet. The proposed system is capable of achieving this goal in a realistic and feasible way, without the adoption of a complex infrastructure. The PI plans to design and disseminate endpoint user profile controller as easy-to-use browser extensions, plug-ins, and mobile applications, which will enable effective endpoint user profile control.","title":"NeTS: Small: Endpoint User Profile Control","awardID":"1319086","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[550250],"PO":["565090"]},"205194":{"abstract":"The human vision system understands and interprets complex scenes for a wide range of visual tasks in real-time while consuming less than 20 Watts of power. This Expeditions-in-Computing project explores holistic design of machine vision systems that have the potential to approach and eventually exceed the capabilities of human vision systems. This will enable the next generation of machine vision systems to not only record images but also understand visual content. Such smart machine vision systems will have a multi-faceted impact on society, including visual aids for visually impaired persons, driver assistance for reducing automotive accidents, and augmented reality for enhanced shopping, travel, and safety. The transformative nature of the research will inspire and train a new generation of students in inter-disciplinary work that spans neuroscience, computing and engineering discipline.<br\/><br\/>While several machine vision systems today can each successfully perform one or a few human tasks ? such as detecting human faces in point-and-shoot cameras ? they are still limited in their ability to perform a wide range of visual tasks, to operate in complex, cluttered environments, and to provide reasoning for their decisions. In contrast, the mammalian visual cortex excels in a broad variety of goal-oriented cognitive tasks, and is at least three orders of magnitude more energy efficient than customized state-of-the-art machine vision systems. The proposed research envisions a holistic design of a machine vision system that will approach the cognitive abilities of the human cortex, by developing a comprehensive solution consisting of vision algorithms, hardware design, human-machine interfaces, and information storage. The project aims to understand the fundamental mechanisms used in the visual cortex to enable the design of new vision algorithms and hardware fabrics that can improve power, speed, flexibility, and recognition accuracies relative to existing machine vision systems. Towards this goal, the project proposes an ambitious inter-disciplinary research agenda that will (i) understand goal-directed visual attention mechanisms in the brain to design task-driven vision algorithms; (ii) develop vision theory and algorithms that scale in performance with increasing complexity of a scene; (iii) integrate complementary approaches in biological and machine vision techniques; (iv) develop a new-genre of computing architectures inspired by advances in both the understanding of the visual cortex and the emergence of electronic devices; and (v) design human-computer interfaces that will effectively assist end-users while preserving privacy and maximizing utility. These advances will allow us to replace current-day cameras with cognitive visual systems that more intelligently analyze and understand complex scenes, and dynamically interact with users.<br\/><br\/>Machine vision systems that understand and interact with their environment in ways similar to humans will enable new transformative applications. The project will develop experimental platforms to: (1) assist visually impaired people; (2) enhance driver attention; and (3) augment reality to provide enhanced experience for retail shopping or a vacation visit, and enhanced safety for critical public infrastructure. This project will result in education and research artifacts that will be disseminated widely through a web portal and via online lecture delivery. The resulting artifacts and prototypes will enhance successful ongoing outreach programs to under-represented minorities and the general public, such as museum exhibits, science fairs, and a summer camp aimed at K-12 students. It will also spur similar new outreach efforts at other partner locations. The project will help identify and develop course material and projects directed at instilling interest in computing fields for students in four-year colleges. Partnerships with two Hispanic serving institutes, industry, national labs and international projects are also planned.","title":"Collaborative Research: Visual Cortex on Silicon","awardID":"1317348","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[549447],"PO":["565227"]},"208021":{"abstract":"Proposal #: 13-37854<br\/>PI(s): Fei, Yunsi; Kaeli, David R.; Leeser, Miriam E.<br\/>Institution: Northeastern University <br\/>Title: MRI\/Dev.: A Testbed for Side Channel Analysis and Security Evaluation (TeSCASE)<br\/>Project Proposed:<br\/>This project, developing a common free testbed, called TeSCASE, for side-channel analysis and security evaluation of cryptosystems, targets research and development in hardware security. The instrument under development, consisting of two platforms for hardware and software, fulfills the following objectives:<br\/>- Holistic testbed: For side-channel leakage acquisition, TeSCASE provides both hardware measurement setup on real systems and a set of tools and methodologies for evaluating system specifications at different levels. (Most existing tools target hardware and not the design.)<br\/>- Comprehensive attack library: The development includes various attacks (power analysis, timing-based, electro-magnetic emanation, and fault analysis) to evaluate the vulnerability\/resilience of a target system. <br\/>- General compatibility: TeSCASE includes measuring interfaces for different devices and consequently can be adapted in diverse application domains.<br\/>- Open source: Facilitating research proliferation, the instrument results will be made open to the public.<br\/>Analyzing side-channel information and exploiting it in side-channel attacks is expected to contribute in the understanding of the design, implementation, and new countermeasures. The work facilitates research on developing provable (side-channel analysis) SCA-resilient cryptographic systems that could lead to discoveries and inventions in multiple aspects of hardware security, fundamental side-channel analysis modeling, effective countermeasures, leakage-resilient cryptography, and fields products in security evaluation. This work develops an open holistic testbed for analyzing a system?s side-channel leakage and hardware security. While the testbed hardware platform services various side-channel leakage acquisitions, the software platform controls the hardware interface, simulates designs at different levels, estimates side-channel leakage, analyzes the leaked information, and evaluates hardware security with multiple metrics. The side channel analysis library provides a suite of known side-channel attacks and countermeasures.<br\/>Broader Impacts:<br\/>This development project could lead to the formulation of test metrics and evaluation standards. TeSCASE can be incorporated into the design process opening opportunities for exploring security countermeasures early in the design process. In addition to the contribution in research, the instrument might aid the semiconductor business and the government. On the educational side, a new graduate level course and an undergraduate-level lab should raise awareness of the need for security in the design and implementation of computing systems, consequently enabling the training of students with adequate hardware security knowledge and skills. TrustHub and cybersecurity competitions will help to disseminate the results. TeSCASE will be evaluated with selected applications on realistic devices and systems. Furthermore, the project seeks women and minority groups.","title":"MRI: Development of a Testbed for Side Channel Analysis and Security Evaluation (TeSCASE)","awardID":"1337854","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":[557272,557273,557274],"PO":["557609"]},"209132":{"abstract":"This project addresses a major inefficiency in healthcare today: an under-informed, homogeneous approach to patient care that doesn't consider community disease prevalence and its effect on an individual's disease risk in an actionable manner. The approach is to combine real-time diagnostic information from select community members via an easy to use, gargle-based immunoassay detection test with more abundant contemporaneous community symptom reports via an online informatics platform. The hypothesis is that the likelihood of a virological diagnosis of influenza (flu) can be accurately predicted for the individual using real-time flu self-diagnostics and symptom information from their community, and can influence a user to take appropriate measures to prevent disease spread. This approach enables testing of several concepts regarding (1) the specificity and sensitivity of a rapid flu diagnostic test for Influenza A and B detection compared to a laboratory polymerase chain reaction test, (2) generation of valid user-contributed diagnostic information at scale (3), potential of real-time contextual data to be used to calculate influenza risk, (4) use and acceptance of this information by individuals. The team brings together experience in building and studying novel crowdsourced data sources for disease surveillance and expertise in software, graphic design, epidemiology, medicine, and engineering, to develop user-friendly systems that the community will employ at scale.<br\/><br\/>The proposed system has substantial potential for beneficial societal impact through acertaining and changing the way people approach healthcare. Empowering individuals to generate and act on health information impresses on them the importance of surveillance and educates them to become more involved and accountable for their health. In order to maximize the impact and sustainability of the system, this system also functions as an educational tool. Clear open communication of anonymized and privacy-protected data to the general public in an easy to interpret manner will assist individuals, policy-makers and other researchers in using contextual disease risk information. Undergraduate and graduate students from a variety of backgrounds will have opportunity to participate in the research. Collaborators at the American Public Health Association and their associated groups concerned with the health of minority populations such as The Association of Minority Health Professions Schools and The Latina Health Project will assist in engaging a diverse group of participants nationwide.","title":"SCH: EXP: Smart integration of community crowdsourced data for real-time individualized disease risk assessment","awardID":"1343968","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[560577],"PO":["564778"]},"208076":{"abstract":"Proposal #: 13-38118 Collaborative Proposal #: 13-37866<br\/>PI(s): Makedon, Fillia S PI(s): Betke, Margrit<br\/>Athitsos, Vassilis; Gatchel, Robert J; Huang, Heng; Romero-Ortega, Mario I<br\/>Institution: University of Texas-Arlington INstitution: Boston Univeristy <br\/>Title: MRI\/Dev :Collab Dev. of iRehab, an Intelligent Closed-loop Instrument for Adaptive Rehabilitation<br\/>Project Proposed:<br\/>This project, developing of an instrument referred to as iRehab, aims to enable personalized rehabilitation therapy for individuals suffering from brain injury, motor disabilities, cognitive impairments, and\/or psychosocial symptoms. The instrument, a modular rehabilitation device, in its simplest form consists of a computer, a camera, and adaptive software for assessment and training of cognitive functions. In its final, most complex form, the instrument will integrate data from a 4-degree-of-freedom robotic-arm with gimbals and torque sensing, a Kinect sensor, multiple cameras, an eye-tracking device, a touch screen, a microphone, and an fNIRS brain imaging sensor. <br\/>The instrument will be developed in two phases. In the first phase, the investigators develop a Barrett robot arm. In the second phase, the instrument will extend to a Kinect sensor, multiple cameras, an eye-tracking device, and related low-cost components, along with the assessment software for assessing motor function and cognitive, emotional, and personality functioning. <br\/>iRehab consists integrates multidisciplinary methodologies and sensors to assess and assist the cognitive and physical rehabilitation of persons affected by various impairments. This work highly interdisciplinary work follows a cyber-physical approach. It provides new research opportunities across the fields of human-centered computing, computer vision, assistive technology, robotics, machine learning, and neuroimaging. This work advances research in human brain activity mapping, personalized medicine, and big data.<br\/>Broader Impacts: <br\/>The proposed instrument exhibits potential for large broader impact as it directly contributes to future healthcare and human wellbeing improving accessibility to affordable rehabilitation for a broad range of patients. The instrument is likely to accelerate the recovery of a large spectrum of injuries and diseases including those causing motor, neurological, and cognitive disorders. An education plan includes course development, internships, workshops and tutorials, and an on-line resource center. In addition to many educational impacts, impact will be felt on the fundamental research in the areas addressed.","title":"MRI Collaborative: Development of iRehab, an Intelligent Closed-Loop Instrument for Adaptive Rehabilitation","awardID":"1338118","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[557538,557539,"560636",557541,"229551"],"PO":["557609"]},"208330":{"abstract":"Purdue University, in partnership with Project Lead the Way (PLTW), proposes a project entitled \"Leading the Way to CS10K: Assessing a Just-in-Time Professional Development Approach for Teacher Knowledge Growth in Computer Science.\" The project will (i) develop and implement a high-quality professional development approach that incorporates face-to-face training coupled with continuous online just-in-time support at a large-scale; and (ii) assess the effectiveness of that professional development at improving teachers' Knowledge, Skills, and Attitudes (KSAs) for teaching computer science. PLTW is a non-profit organization that has successfully implemented innovative and rigorous STEM curriculum in over 4,700 schools and trained 10,500 STEM teachers across the United States. PLTW is introducing a new Computer Science and Software Engineering (CSE) course, which aligns with the CS Principles framework. The CSE course aims to develop students' computational thinking and introduce computational tools that foster creativity. The large network of schools implementing this new course provides the opportunity to implement and study professional development for a large number of teachers, including teachers with little CS background. This large-scale project will establish an evidence-based professional development program to improve teachers' knowledge to teach computer science, and it will deliver empirically validated best practices for providing computer science professional development to teachers, especially those with limited computer science background.","title":"CS 10K: Leading the Way to CS10K: Assessing a Just-in-Time Professional Development Approach for Teacher Knowledge Growth in Computer Science","awardID":"1339245","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}}],"PIcoPI":[558285,558286,558287,558288],"PO":["561855"]},"207010":{"abstract":"This project is funded as part of the United States-Israel Collaboration in Computer Science (USICCS) program. Through this program, NSF and the United States - Israel Binational Science Foundation (BSF) jointly support collaborations among US-based researchers and Israel-based researchers.<br\/><br\/>This project will examine and extend computational techniques that allow computers to out-perform humans on certain classes of difficult problems, some of which have practical applications across many areas of science and engineering. The techniques to be studied, which are modeled on biological processes of evolution, have already been shown to produce human-competitive performance in areas ranging from pure mathematics to quantum system design, and from game-playing systems to software engineering and debugging. In this project the co-PIs will collaborate to characterize the application areas in which these human-competitive successes have been achieved, along with the specific techniques that were used in each case. The project will use these characterizations to guide improvements to the techniques and applications to new problems.<br\/><br\/>The initial data for the study will be taken from the winners of the of the Human Competitive Results Competition that has been held annually since 2004 at the Genetic and Evolutionary Computation Conference. Areas of anticipated application work include software engineering, for example for automatic program synthesis and repair, where early successes and the scale of the potential applications indicate substantial promise. The long-term potential of work in this area is for computers to automatically generate useful software, for many applications of scientific or social significance, that would be prohibitively difficult or expensive for human programmers to produce. The project will be conducted with undergraduates and graduate students and will also thereby help to train future innovators in computer science.","title":"BSF:2012144:Human-Competitive Evolutionary Computation","awardID":"1331283","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":[554244],"PO":["565157"]},"209210":{"abstract":"The Gigabit Community Fund project catalyzes the development of applications (apps) that leverage ultra-high speed broadband networks in service to education and workforce development needs. The project integrates institutional partnerships, an incentivizing fund to support app development, and a repository of open source tools, code, and documentation to develop learning laboratories for the next generation Internet. <br\/><br\/>Extending the work of the US Ignite Application Challenge project, the Gigabit Community Fund continues the progression from ideation to build to pilot. The project adopts Mozilla's model of Hive Learning Networks in which collaborative teams in each of the partner cities, Chattanooga and Kansas City, link developers with local anchor institutions to create user-centric apps. The Gigabit Community Fund advances understanding in three critical domains: 1) the development process of the gigabit apps themselves, including specifics of code and strategy; 2) designing compelling STEM applications that increase learning and engagement; and 3) optimizing features of a national ecosystem for gigabit innovation.<br\/><br\/>The Gigabit Community Fund project demonstrates the potential for and capacity of ultra-high speed broadband networks to make significant contributions to public sector needs. The pilot apps generated through the project seeds demand for and investment in technology infrastructure while serving an immediate national imperative to increase access and engagement in STEM learning, particularly by traditionally underserved and underrepresented communities. Through the creation of dynamic learning laboratories, the Gigabit Community Fund project informs the national conversations on infrastructure, app development, and STEM.","title":"The Gigabit Community Fund: Moving Gigabit Apps From Prototype to Pilot","awardID":"1344309","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["560884",560847,560848],"PO":["564993"]},"209199":{"abstract":"This INSPIRE award is partially funded by the following programs (a) the Symbiosis, Defense & Self-Recognition Program (Division of Integrative Organismal Systems, Biology Directorate) (b) the Emerging Frontiers Office ( Biology Directorate) (c) the Information Integration and Informatics and Special Projects programs of the Division of Information and Intelligent Systems (Directorate for Computer & Information Science & Engineering) (d) The Africa\/Middle East\/South Asia cluster (Kenya, Ghana) and Americas (Latin America, SDC) Cluster of the Office of International Science and Engineering. <br\/>It is well-known that breastfeeding protects infants from illness, especially in the poorest regions of the world. The full nature of this protective effect, however, is less well understood. A major barrier to understanding is the fact that almost nothing is known about the factors that influence the considerable variation in milk composition around the globe, or about the effects of this variation on infant health. This INSPIRE project represents the first comprehensive investigation of the global differences in human milk composition along with the various microbial, evolutionary, environmental, and sociocultural factors that might influence both milk composition and infant health. An international, interdisciplinary collaboration of physiologists, nutritional scientists, anthropologists, microbiologists, and mathematicians will collect biological data from breastfeeding women and their infants, in concert with extensive anthropologic and ecological data, in both developed (US, Spain, Sweden) and developing countries (Central African Republic, Gambia, Ghana, Peru, and Kenya). To test the possibility of a correlation between milk oligosaccharide composition, milk microbiota, and the gastrointestinal microbiome of infants, milk samples and infant fecal samples will be analyzed using state-of-the-art biochemical and genomic techniques. This study will allow important cross-cultural comparisons of milk composition and infant feeding practices; it also will utilize sophisticated computational methods to integrate the extensive, diverse body of combined biological and anthropological data to elucidate the relationships among sociocultural factors, evolutionary history, environmental exposures, microbial constituents and milk composition. The researchers predict that what is considered \"normal\" milk composition in one population may not support optimal health in another. This information is crucial to the humanitarian quest to understand how infant nutrition and overall health can be improved around the world. In addition, this project will provide extensive research training opportunities for undergraduate, graduate and postdoctoral scientists.","title":"INSPIRE Track 1: What is Normal Milk? Sociocultural, Evolutionary, Environmental, and Microbial Aspects of Human Milk Composition","awardID":"1344288","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"8078","name":"INSPIRE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"7275","name":"CROSS-EF ACTIVITIES"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"7656","name":"SYMBIOSIS DEF & SELF RECOG"}}],"PIcoPI":[560805,560806,560807,560808,560809],"PO":["564675"]},"202270":{"abstract":"The operational complexity of networks and the resulting operational expense (OPEX) count among the top challenges faced by network operators. This complexity arises, in part, because of the scale and continued growth of modern networks, the inherent complexity and intricate dependencies of the protocols that these networks run, and the increased expectations of network users due to the increasing importance that network connectivity and networked services play in society. This complexity has been heightened by recent developments that make networks much more dynamic, adding a whole new dimension to the complexities of network management and operations (M&O). The resulting state of affairs acts to impede the pace of innovation and change in networks. The research on network M&O has not kept pace with the research transforming the networks themselves.<br\/><br\/>This project addresses these issues by designing and building a Knowledge-Centric Software-Defined Network Management and Operations architecture (KnowOps). KnowOps will represent a significant step in moving M&O towards fully autonomic operation. The project will generalize database-like abstractions to create a network operations fabric (NOF) as a systematic and principled foundation for comprehensive network management and operations. The PIs will combine this foundation with information centric data mining methods to create a structured information base which captures, in a systematic manner, the status of the network and expose it to other network management functions. The end result will be a knowledge base capable of systematically capturing operational procedures and policies as specified by domain experts. <br\/><br\/>Network OPEX is a major challenge for continued penetration of digital technologies into application areas in the home and small business. The project will involve collaboration with a large, national network operator but also with a small, mostly rural carrier. Improved network management tools are particularly important for smaller regional operators serving cyber-disadvantaged communities, who often do not have the technical breadth and depth of larger operators, but who, nonetheless, face the same operational challenges.","title":"NeTS: Medium: KnowOps-Making Network Management and Operations Software Defined","awardID":"1302688","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[542075,542076,"559299","560436"],"PO":["564993"]},"205240":{"abstract":"The computing revolution began over two thousand years ago with the advent of mechanical devices for calculating the motions of celestial bodies. Sophisticated clockwork automata were developed centuries later to control the machinery that drove the industrial revolution, culminating in Babbage's remarkable design for a programmable mechanical computer. With the electronic revolution of the last century, the speed and complexity of computers increased dramatically. Using embedded computers we now program the behavior of a vast array of electro-mechanical devices, from cell phones and satellites to industrial manufacturing robots and self-driving cars. The history of computing has taught researchers two things: first, that the principles of computing can be embodied in a wide variety of physical substrates from gears to transistors, and second, that the mastery of a new physical substrate for computing has the potential to transform technology. Another revolution is just beginning, one whose inspiration is the incredible chemistry and molecular machinery of life, one whose physical computing substrate consists of synthetic biomolecules and designed chemical reactions. Like the previous revolutions, this \"molecular programming revolution\" will have the principles of computer science at its core. By systematically programming the behaviors of a wide array of complex information-based molecular systems, from decision-making circuitry and molecular-scale manufacturing to biomedical diagnosis and smart therapeutics, it has the potential to radically transform material, chemical, biological, and medical industries. With molecular programming, chemistry will become a major new information technology of the 21st century.<br\/><br\/>This Expeditions-in-Computing project aims to establish solid foundations for molecular programming. Building on advances in DNA nanotechnology, DNA computing, and synthetic biology, the project will develop methods for programmable self-assembly of DNA strands to create sophisticated 2D and 3D structures, dynamic biochemical circuitry based on programmable interactions between DNA, RNA, and proteins, and integrated behaviors within spatially organized molecular systems and living cells. These architectures will provide systematic building blocks for creating programmable molecular systems able to sense molecular input, compute decisions about those inputs, and act on their environment. To manage system complexity and to provide modularity, the project will establish abstraction hierarchies with associated high-level languages for programming structure and behavior, compilers that turn high-level code into lists of synthesizable DNA sequences, and analysis software that can predict the performance of the sequences. This will allow molecular programmers to specify, design, and verify the correctness of their systems before they are ever synthesized in the laboratory. In addition to these software tools, the project will study the theory of molecular algorithms in order to understand the potential and limitations of information-based molecular systems, what makes them efficient at the tasks they can perform, and how they can be effectively designed and analyzed. Putting the products of this fundamental research to the test, the project will pursue real-world applications such as molecular instruments for probing biological systems and programmable fabrication of nanoscale devices.<br\/><br\/>This project will expand the network of scientists and engineers working in molecular programming by building a diverse community of students, teachers, researchers, scientists, and engineers. This community will be fostered through the creation of publicly accessible software tools, courses, textbooks, workshops, tutorials, undergraduate research competitions, and popular science videos to teach the principles and methods of molecular programming and to engage young researchers and the public in this exciting new field. Industrial partnerships with relevant biotechnology and other high-tech companies will ensure fast transfer of knowledge generated into real-world products. Perhaps most importantly, as molecular programming becomes a widespread technology, it has the potential to transform industry with new complex nanostructured materials, to transform chemistry with integrated and autonomous control of reactions, to transform biology with advanced molecular instruments, and to transform health care with more sophisticated diagnostics and therapeutics.","title":"Collaborative Research: Molecular Programming Architectures, Abstractions, Algorithms, and Applications","awardID":"1317694","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[549583,549584,549585,"558957",549587],"PO":["565223"]},"205394":{"abstract":"Opportunistic spectrum access (OSA) is at the core of the cognitive radio technologies with the focus on improving spectrum utilization efficiency and reliability. Despite the benefits, existing OSA protocols suffer from their deterministic nature and cannot prevent an ill-intended jammer from disrupting legitimate communications. A cognitive jammer can always effectively jam the idle channels by exploiting public-available channel statistics and causes serious spectrum underutilization. This project addresses the challenge of establishing robust anti-jamming communication in cognitive radio networks (CRNs) through a multiple-line of defense approach. The research considers a variety of network environments and integrates defense technologies from different dimensions, including adaptive uncoordinated frequency hopping (AUFH), power control, and signal processing. The defense approach enables both reactive and proactive protections, from evading jammers to competing against jammers, and to expelling jamming signals, and thus ensures robust user communications in CRNs. <br\/><br\/>The research in this project has a potential to significantly advance the state-of-the-art and develop innovative and sophisticated defense strategies using the proposed multiple lines of defense approach. The proposed solutions will contribute towards eventually building robust and dependable CRNs that are critical to the future communication systems. The project will also contribute directly to the curriculum development, teaching, student supervising and future security engineer training. Major results of this project will be disseminated through presentations, publications, as well as online materials in the forms of tutorials and software packages.","title":"NeTS: Small: Collaborative Research: Enabling Robust Communication in Cognitive Radio Networks with Multiple Lines of Defense","awardID":"1318594","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["553866"],"PO":["557315"]},"208320":{"abstract":"SRI will investigate the potential of a computer science curriculum, Build IT that successfully encourages African American and Latina girls' interests and pursuits in computer science, to encourage these girls? educators to pursue computer science learning and careers. Preliminary data suggest that Build IT may increase IT education and career pursuits among the educators, who are primarily women of color in their 20s and 30s. SRI will conduct a mixed-methods study in both the Girls Inc. network of affiliates throughout the United States and the California School-Age Consortium (CalSAC) network of afterschool programs in California to understand (1) under what conditions do Build IT educators pursue computer science learning and careers, (2) what types of computer science learning and careers do Build IT educators indicate interest in and pursue, and (3) to what extent is there a relationship between educators' computing interests and pursuits, their implementation of Build IT, and youth outcomes for Build IT. To address these research questions, the team will conduct a study of Build IT and other STEM educators in the Girls Inc. and CalSAC networks gathering data on their STEM backgrounds, implementation practices, and their IT career plans. The team will examine the impact of the Build IT educators' IT interests and career plans on youth outcomes. <br\/><br\/>This research is important for practitioners, researchers, and policymakers interested in encouraging underrepresented populations to pursue STEM learning and careers in general and computer science learning and careers, specifically. While there is some evidence that teaching STEM programs may encourage afterschool educators to pursue further STEM experiences, there is a gap in the research on the role that teaching such an afterschool computer science curriculum can play to activate or reactive young women from African American and Latina backgrounds in pursuing computer science and the effect that these educators? pursuits can have on girls' computer science learning and career interests. This research will inform practice and research on programmatic designs and implementation environments that encourage underrepresented populations of both learners and educators to pursue computer science. Through Girls Inc. and CalSAC, the Build IT curriculum and research findings and practices can reach hundreds of thousands of middle school girls and thousands of afterschool educators who are predominantly female and from African American and Latina backgrounds.","title":"BP: Broadening Participation by Building the Capacity of Afterschool Computer Science Educators: Reaching African American and Latina Women with the Build IT Curriculum","awardID":"1339181","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}}],"PIcoPI":[558256,558257],"PO":["560704"]},"205196":{"abstract":"Technical Summary: <br\/><br\/>The main technical goal of this research is to solve the problem of index coding from an interference alignment perspective. The index coding problem lies at the intersection of several challenging problems in network information theory such as broadcast channels, source coding and network coding. This project explores the index coding problem and its generalizations as they relate to the problem of optimal interference management in wireless and wired communication networks, when only a coarse knowledge of network topology is available to the transmitters. <br\/><br\/>Broader Significance:<br\/><br\/>Understanding the capacity limits of wireless and wired networks under practical assumptions is critical for industry, academia, government agencies and society in general, to have realistic expectations from communication networks of the future. Interference between concurrent information flows is a key bottleneck in both wired and wireless networks. The unified perspective of interference management taken in this research allows existing insights to be translated from wireless networks to wired networks and vice versa, as well as the discovery of new insights that cut across applications. The research brings together areas like wireless communications, network coding, classical information theory, graph-theory, as well as optimization and algorithms, providing cutting-edge training to the participating student researchers in these critical technical areas.","title":"CIF: Small: Topological Interference Management","awardID":"1317351","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["550258"],"PO":["564924"]},"208342":{"abstract":"Drexel University, together with partners at Mozilla Foundation University of Nevada at Omaha, will investigate the impact of beginning web development experiences on learners' mastery and perceptions of computational skills and concepts. Using introductory web editors openHTML and Thimble in both formal and informal settings, they will engage beginners who have little or no experience with creative computation in constructing their first web pages and learning HTML and CSS. They will conduct observational studies paired with testing to understand learners' experiences with web development and identify activity patterns that signal recurring errors, recoveries, misconceptions and competencies and will use these findings to identify markers of error and competency in beginner's code.<br\/><br\/>Widespread computational competency is a vital component of a competitive workforce and vibrant economy. By lowering the barriers to comfort and competence with computing, this project aims to 1) engage individuals who may not otherwise appear on the computer science education radar in creative computational activities 2) improve the tools available to web development educators and learners and 3) extend scientific knowledge about the development of early computational thinking skills.","title":"CER: openHTML, a Scaffolded Web Development Tool to Support Elementary Computational Literacy","awardID":"1339344","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}}],"PIcoPI":[558319,558320,558321,558322],"PO":["560704"]},"208067":{"abstract":"Proposal #: 13-38078<br\/>PI(s): Chen, Yong; Gropp, William D.; Smith, Philip W.; Sun, Xian-He; Zhuang, Yu<br\/>Institution: Texas Tech University <br\/>Title: MRI Collab\/Dev.: Data Intensive Scalable Computing Instrument for High Performance Computing<br\/>Project Proposed:<br\/>This project, developing DICSI, an all-around computing instrument that compensates the limitations of existing computing-centric HPC instruments toward data-intensive applications, supports five large research projects in HPC system design, computational chemistry, biotechnology, and atmospheric science. Based on research introducing the application-aware and decoupled-execution paradigm concept, the project addresses the big gap between research prototypes and the engineering solution. Impact on future applications, algorithms, and instruments design is expected since the instrument could open up new research areas in supporting data-intensive sciences and possibly reshape HPC instruments adopted in National Computing Facilities and some institutions. In addition to the conventional HPC compute nodes, DISCI has a set of specially designed data nodes. The data nodes offer in-situ data processing to reduce data movement and data-access delay and dynamic provisioning as 'fat' compute nodes when necessary, while the functionality of compute nodes remains the same as in conventional instrumentation. These data nodes work with compute nodes in concert and together they provide an optimum system performance for data-intensive HPC. Based on a hardware-software co-development principle, the instrument consists of two components: the DISCI system architecture and the DISCI runtime software. The system architecture builds an HPC instrument with a data-centric view. The runtime software extends the MPI (Message Passing Interface) and MPI-IO library to support data nodes and their associated in-situ processing. The instrument will enable and foster research activities in the areas of chemical dynamics simulation, simulations of turbulent flows, atmospheric data assimilation and weather forecasting, computational biology, and computer systems that PIs and senior personnel conduct. <br\/>Broader Impacts: <br\/>This development project will enable academic departments, cross-disciplinary units, organizations, and multi-organization collaborations to integrate their development, education, and outreach efforts. <br\/>To attract underrepresented students into the DISCI development, the institution will coordinate with institutional projects at respective organizations. The experience gained will be integrated into undergraduate and graduate courses and summer orientation trainings to get students involved in the development. The education plan concentrates on supporting data-intensive HPC and training a broadly inclusive and globally competitive science workforce. The project is expected to provide the pathway to future national HPC instruments to support data-intensive sciences. Furthermore, it could have a direct impact on building exascale HPC instruments.","title":"MRI Collaborative: Development of a Data-Intensive Scalable Computing Instrument for High Performance Computing","awardID":"1338078","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"5761","name":"INDUSTRY\/UNIV COOP RES CENTERS"}}],"PIcoPI":[557487,557488,557489,"503234","474923"],"PO":["557609"]},"206990":{"abstract":"This project is funded as part of the United States-Israel Collaboration in Computer Science (USICCS) program. Through this program, NSF and the United States - Israel Binational Science Foundation (BSF) jointly support collaborations among US-based researchers and Israel-based researchers.<br\/><br\/>The goal of this project is to use ideas and techniques developed in the field of Computational Learning Theory to produce algorithms that can aid users or firms in solving certain economic decision-making problems. Computational Learning Theory studies how one can automatically learn good prediction rules from data, as well as questions such as how much data is intrinsically needed in order to learn rules of a given complexity. In economic decision-making, one often has some amount of data (or recent experience) and must extrapolate from this a course of action for the future. This project aims to bring these two areas together in order to produce improved economic decision-making tools.<br\/><br\/>This project focuses specifically on three challenging problems for which ideas from Computational Learning Theory appear to be especially promising. The first concerns the decision of how many of each of a given suite of products to produce when customers are arriving over time and have disjunctive needs, and the production costs for each product obey economies of scale. The goal in this setting is from a small amount of initial observation to be able to commit to a near-optimal plan for how much of each product to produce, to satisfy future customers at the least possible total cost. The second concerns the problems of market segmentation when the potential customers have known attributes but the relation of these attributes to their preferences is not known up front. Finally, the last concerns the problem of inferring a model for bidders in an auction when only the outcome information of the auction is observable. These problems all involve challenging inference tasks for which tools from Computational Learning Theory appear to be well suited.","title":"BSF: 2012251: Algorithmic Game Theory meets Computational Learning Theory","awardID":"1331175","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":[554195],"PO":["565157"]},"205670":{"abstract":"MapReduce has been widely leveraged as a new programming model to tap the power of parallel data processing for Big Data. More and more systems are being deployed to serve data-intensive analytics applications written in MapReduce. Many jobs can show up at the same time on a system with conflicting resource requirements. This project investigates cross-layer cooperation techniques to achieve system efficiency, cross-phase techniques to enhance job fairness and system throughput, and cross-job task co-scheduling techniques to exploit the temporal relationship among jobs for better throughput and services to analytic queries composed of multiple MapReduce jobs.<br\/><br\/>This project has profound impacts in several aspects. These include (1) strengthening computer science courses at Auburn University, and enhancing instruction effectiveness with student research projects on MapReduce; (2) recruiting and cultivating students of diverse backgrounds, particularly under-represented minority and female student groups for careers in computing; (3) disseminating research results as publications, presentations, conference tutorials and demonstrations, releasing open-source software codes, and eventually pushing them for integration into the official Hadoop code base; and (4) collaborating with industry, strengthening research partnerships, and cultivating opportunities for technology transfer to industry.","title":"CSR: Small: XooMR: Cross-Layer and Cross-Phase Cooperation for Fair and Efficient MapReduce","awardID":"1320016","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["559143"],"PO":["565255"]},"205692":{"abstract":"As the number of computer nodes increases, so does the size of the interconnect network. Historically, floating point was the most costly component of a system, but this is no longer the case. Systems today, and those anticipated in the future, are increasingly bound by their communication infrastructure and the power dissipation associated with data movement across the rapidly growing number of nodes. How to address the increasing cost of data movement on ever-growing systems is becoming critical.<br\/><br\/>This project will develop a framework named COTA, a COoperative framework for Topology Awareness. COTA will be an integrated framework that coordinates across the hardware, job scheduler, runtime, and application to jointly attack the increasing concern of data movement for communication- and power-efficiency on large-scale systems. Most importantly, the framework will support topology awareness not only at job startup, but also during job execution. The newly developed mapping algorithms, topology-aware methods and tools, and topology-aware models will provide a critical foundation for the realization of topology awareness on current and future systems. This research will have a direct impact on system productivity as well as a broad range of application domains that use parallel systems for simulations. The project will also enhance the curriculum at Illinois Institute of technology, broaden the participation by underrepresented groups, and outreach to the surrounding communities.","title":"SHF: CSR: Small: A Cooperative Framework for Topology Awareness on Large-Scale Systems","awardID":"1320125","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[550730,"174082"],"PO":["565255"]},"206792":{"abstract":"This project investigates new reinforcement learning algorithms to enable long-term real-time autonomous learning by cyber-physical systems (CPS). The complexity of CPS makes hand-programming safe and efficient controllers for them difficult. For CPS to meet their potential, they need methods that enable them to learn and adapt to novel situations that they were not programmed for. Reinforcement learning (RL) is a paradigm for learning sequential decision making processes with potential for solving this problem. However, existing RL algorithms do not meet all of the requirements of learning in CPS. Efficacy of the new algorithms for CPS is evaluated in the context of smart buildings and autonomous vehicles.<br\/><br\/>Cyber-physical systems (CPS) have the potential to revolutionize society by enabling smart buildings, transportation, medical technology, and electric grids. Success of this project could lead to a new generation of CPS that are capable of adapting to their situation and improving their performance autonomously over time. In addition to the traditional methods of dissemination, this project will develop and release open-source code implementing the new reinforcement learning algorithms. Education and outreach activities associated with the project include a Freshman Research Initiative course, participation in a UT Austin annual open house that draws in many underrepresented minorities to interest the public in computer science and science in general, and the department's annual summer school for high school girls called First Bytes.","title":"CPS: Breakthrough: Reinforcement Learning Algorithms for Cyber-Physical Systems","awardID":"1330072","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[553684],"PO":["564778"]},"205461":{"abstract":"Opportunistic spectrum access (OSA) is at the core of the cognitive radio technologies with the focus on improving spectrum utilization efficiency and reliability. Despite the benefits, existing OSA protocols suffer from their deterministic nature and cannot prevent an ill-intended jammer from disrupting legitimate communications. A cognitive jammer can always effectively jam the idle channels by exploiting public-available channel statistics and causes serious spectrum underutilization. This project addresses the challenge of establishing robust anti-jamming communication in cognitive radio networks (CRNs) through a multiple-line of defense approach. The research considers a variety of network environments and integrates defense technologies from different dimensions, including adaptive uncoordinated frequency hopping (AUFH), power control, and signal processing. The defense approach enables both reactive and proactive protections, from evading jammers to competing against jammers, and to expelling jamming signals, and thus ensures robust user communications in CRNs. <br\/><br\/>The research in this project has a potential to significantly advance the state-of-the-art and develop innovative and sophisticated defense strategies using the proposed multiple lines of defense approach. The proposed solutions will contribute towards eventually building robust and dependable CRNs that are critical to the future communication systems. The project will also contribute directly to the curriculum development, teaching, student supervising and future security engineer training. Major results of this project will be disseminated through presentations, publications, as well as online materials in the forms of tutorials and software packages.","title":"NeTS: Small: Collaborative Research: Enabling Robust Communication in Cognitive Radio Networks with Multiple Lines of Defense","awardID":"1318948","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["565164"],"PO":["557315"]},"206693":{"abstract":"This project is a modular, computationally-distributed multi-robot cyberphysical system (CPS) for assisting young developmentally-delayed children in learning to walk. The multi-robot CPS is designed to function in the same way as an adult assisting a child in learning to walk (addressing the research target area of a science of CPS by introducing developmental rehabilitation robotics). It addresses the research target area of new CPS technology by introducing a multi-robot system: 1) a multi-cable scaffold robot that continuously modulates the stabilization of medio-lateral and anterior-posterior sway, and 2) a soft, wearable, exosuit robot with embedded sensing and actuation, which assists with stance push off and swing flexion. The objective is to build a prototype multi-robot CPS and perform tests with human subjects to evaluate the CPS functionality, safety, and interoperability (addressing the research target area of engineering CPS). Longitudinal tests of typically developing and developmentally delayed children learning to walk with or without assistance of the multi-robot CPS are conducted in a motion capture laboratory. Body center of mass behavior as well as gait parameters of walking are measured as the two robots work together to assist the child in maintaining balance and propelling the body forward with each step.<br\/><br\/>This exosuit\/scaffolding multi-robot technology will advance knowledge within engineering with bio-inspired soft components, including miniature pneumatic artificial muscle actuators with embedded sensors that enable the control of the muscles in real time. The bio-inspired architecture and material components of the exosuit will make possible a new generation of ?smart fabric? that acts in concert with the body for efficient energy use. The exosuit is part of a larger modular design that makes it possible to couple it to additional assistive robots via a modular communications network. Together, the exosuit, scaffold robot, and wireless communications network for modular CPS, will advance knowledge for the engineering of other CPS that require high levels of interoperability and safety, such as medical CPS. <br\/><br\/>The multi-robot CPS is designed for children who are developmentally delayed as a result of early brain injury. The long term consequences of early brain injury, e.g., in children born prematurely, constitute a major health problem and a significant emotional and financial burden for families and society. The use of a multi-robot cyberphysical system as part of a rehabilitation program may be able to harness the potential of the nervous system for plasticity, the ability to re-organize its structure, function, and connections. The focus is on young children with a history of early brain injury due to prematurity. However, this new cyberphysical system will have a much broader impact in restoring function throughout the life span. Neuroplasticity is not just an immediate response to injury, but occurs throughout the developmental period, providing an opportunity to promote repair and re-education, and restore function. A key to this broad application is the developmentally-motivated, modular structure and interoperability of the exosuit.","title":"CPS: Synergy: Multi-Robot Cyberphysical System for Assisting Young Developmentally-Delayed Children in Learning to Walk","awardID":"1329363","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":["558467",553416,553417],"PO":["565136"]},"205252":{"abstract":"The proposed work seeks to leverage cloud computing to enable robots to efficiently learn from remote human domain experts - \"Cloud Learning from Demonstration.\" Building on RobotsFor.Me, a remote robotics research lab, this research will unite Learning from Demonstration (LfD) and Cloud Robotics to enable anyone with Internet access to teach a robot household tasks. The value of this work stems from three aspects. First is the remote system that can learn task models from a series of remote demonstrations from a single user, focusing on learning high-level tasks as opposed to low-level motor skills. The second is the extension of learning from demonstration to multiple teachers. This represents an important relaxation of a limiting assumption to focus on evaluating teacher strengths and effectively handling distinct task solutions. Finally, transparency mechanisms to allow a remote user to develop a correct mental model about the robot?s learning process.<br\/><br\/>The long term goal of this research is to one day make personal robots accessible to everyday people. The interactive learning framework based on RobotsFor.Me provides unique opportunities for education and outreach. Thomaz and Chernova will outreach to K-12 teachers and students by creating an education portal surrounding RobotsFor.Me containing hands-on workshop curricula. This material will be integrated with the WPI Frontiers program for middle school students, and the GT ePDN professional education network for teachers. A key impact on students at GT and WPI will be direct involvement in this research agenda, and integration with AI, robotics and HRI courses. Chernova is the Diversity Coordinator in the Robotics Engineering Program, and faculty advisor for Women In Robotics Engineering and Women in Technology student groups which will enable braod exposure. Thomaz mentors the RoboWomen graduate women?s group. Software components will also be made available as open source and the PIs have a collaboration plan in place with researchers at Willow Garage, and through student internships will transfer technology to their labs.","title":"NRI: Small: Collaborative Research: Learning from Demonstration for Cloud Robotics","awardID":"1317775","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":[549619],"PO":["564069"]},"205494":{"abstract":"High-end embedded systems are turning to multicore architectures to meet the performance, and performance\/Watt, demands required for their applications. Moreover, as the demand for more compute-intensive capabilities for embedded systems increases, these multicore architectures will evolve into many-core systems for improved performance or performance\/area\/Watt. These systems are often organized as cluster-based Non-Uniform Memory Access (NUMA) architectures that provide the programmer with a shared-memory abstraction. That is, simple cores are grouped into clusters sharing local interconnection and memory and these clusters are then replicated and interconnected using a scalable network-on-chip medium. This project investigates one of the principal challenges presented by these emerging NUMA architectures for embedded systems: providing efficient, energy-effective, and convenient mechanisms for synchronization and communication. In particular, it proposes new solutions based on hardware support for speculative synchronization, and software support to make such speculation transparent. Important metrics for measuring the effectiveness of the solutions include throughput, ease of use, system energy consumption, and architectural simplicity.<br\/><br\/>Embedded systems are becoming ubiquitous over a broad range of applications, including smart phones, automotive systems, security, and other ambient intelligence systems. Increasing computational demands have led to more sophisticated products and therefore increased challenges in meeting tight design constraints, particularly throughput\/Watt. Improvements to the way these systems communicate and synchronize data can have a substantial impact in terms of improved functionality, utility, and durability. The project is an international collaboration that combines PI expertise in Network-on-Chip architectures, embedded system design, and memory synchronization. Broader impacts of the proposal include new course development, outreach to graduate and undergraduate women and under-represented minorities, and student exchanges between international institutions.","title":"CSR: Small: Collaborative Research: Transparent and Energy-Efficient Speculation on NUMA Architectures for Embedded Multiprocessor Systems","awardID":"1319095","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":[550256],"PO":["565319"]},"205164":{"abstract":"Smart phones and tablets enable consumers to enjoy rich audio and video content on the go, but the proliferation of such increasingly sophisticated mobile devices has created a capacity crisis for mobile operators. It is estimated that supporting rich media content for a rapidly increasing fraction of mobile users requires a 1000-fold increase in cellular network capacity, which current cellular bands simply cannot support. The research pursued under this grant explores an alternative, and potentially transformational, approach to cellular data, using unlicensed spectrum in the 60 GHz band, where the available bandwidth is orders of magnitude higher than those used in existing systems, at the level of multiple Gigabits per second throughput on the downlink to the mobile devices. <br\/><br\/>Base stations for the envisioned network will be deployed opportunistically (e.g., on lampposts and rooftops). Due to the small carrier wavelength, many antenna arrays with a very large number (e.g., 1000) of elements can be built into base stations which are no larger than a typical WiFi access point. Such antenna arrays can be used to direct pencil beams at mobile users, with peak data rates of multiples of Gigabits per second (order of magnitude higher than the highest WiFi data rates available today). However, the small carrier wavelength also implies that the radio waves are easily blocked by obstacles such as buildings, walls, and humans, including the body of the person carrying the mobile device. In order to handle such rapid changes in the propagation environment, novel techniques are developed for multiple base stations to coordinate, such that they can adapt their beams to maintain connectivity with a given mobile device, and can ensure that the data destined for the mobile follows it around. A novel asymmetric network architecture is employed, with low-bandwidth 60 GHz beaconing and multi-Gbps data on the downlink, and LTE feedback and lower-speed data on the uplink. The base stations employ compressive signal processing for rapid channel estimation and beam adaptation, based on the feedback from the mobiles. Distributed base station coordination mechanisms are developed for seamlessly switching base stations or paths. The architecture minimizes complexity and power consumption in the mobile device: the device's 60 GHz radio only needs to receive, and the device is oblivious of handoffs.<br\/><br\/>The mobile broadband capacity crisis is the greatest challenge facing cellular providers today, hence the success of this project can impact a multi-billion dollar industry. In order to maximize the potential for impact, the results and models will be widely disseminated to both industry and academia. The investigators plan significant efforts for recruitment and mentoring of female undergraduate and graduate students, organized around the concept of a caring community.","title":"NeTS: Small: Mobile mmWaves: Addressing the Cellular Capacity Crisis with 60 GHz Picocells","awardID":"1317153","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[549356,"551126"],"PO":["565303"]},"205186":{"abstract":"The computing revolution began over two thousand years ago with the advent of mechanical devices for calculating the motions of celestial bodies. Sophisticated clockwork automata were developed centuries later to control the machinery that drove the industrial revolution, culminating in Babbage's remarkable design for a programmable mechanical computer. With the electronic revolution of the last century, the speed and complexity of computers increased dramatically. Using embedded computers we now program the behavior of a vast array of electro-mechanical devices, from cell phones and satellites to industrial manufacturing robots and self-driving cars. The history of computing has taught researchers two things: first, that the principles of computing can be embodied in a wide variety of physical substrates from gears to transistors, and second, that the mastery of a new physical substrate for computing has the potential to transform technology. Another revolution is just beginning, one whose inspiration is the incredible chemistry and molecular machinery of life, one whose physical computing substrate consists of synthetic biomolecules and designed chemical reactions. Like the previous revolutions, this \"molecular programming revolution\" will have the principles of computer science at its core. By systematically programming the behaviors of a wide array of complex information-based molecular systems, from decision-making circuitry and molecular-scale manufacturing to biomedical diagnosis and smart therapeutics, it has the potential to radically transform material, chemical, biological, and medical industries. With molecular programming, chemistry will become a major new information technology of the 21st century.<br\/><br\/>This Expeditions-in-Computing project aims to establish solid foundations for molecular programming. Building on advances in DNA nanotechnology, DNA computing, and synthetic biology, the project will develop methods for programmable self-assembly of DNA strands to create sophisticated 2D and 3D structures, dynamic biochemical circuitry based on programmable interactions between DNA, RNA, and proteins, and integrated behaviors within spatially organized molecular systems and living cells. These architectures will provide systematic building blocks for creating programmable molecular systems able to sense molecular input, compute decisions about those inputs, and act on their environment. To manage system complexity and to provide modularity, the project will establish abstraction hierarchies with associated high-level languages for programming structure and behavior, compilers that turn high-level code into lists of synthesizable DNA sequences, and analysis software that can predict the performance of the sequences. This will allow molecular programmers to specify, design, and verify the correctness of their systems before they are ever synthesized in the laboratory. In addition to these software tools, the project will study the theory of molecular algorithms in order to understand the potential and limitations of information-based molecular systems, what makes them efficient at the tasks they can perform, and how they can be effectively designed and analyzed. Putting the products of this fundamental research to the test, the project will pursue real-world applications such as molecular instruments for probing biological systems and programmable fabrication of nanoscale devices.<br\/><br\/>This project will expand the network of scientists and engineers working in molecular programming by building a diverse community of students, teachers, researchers, scientists, and engineers. This community will be fostered through the creation of publicly accessible software tools, courses, textbooks, workshops, tutorials, undergraduate research competitions, and popular science videos to teach the principles and methods of molecular programming and to engage young researchers and the public in this exciting new field. Industrial partnerships with relevant biotechnology and other high-tech companies will ensure fast transfer of knowledge generated into real-world products. Perhaps most importantly, as molecular programming becomes a widespread technology, it has the potential to transform industry with new complex nanostructured materials, to transform chemistry with integrated and autonomous control of reactions, to transform biology with advanced molecular instruments, and to transform health care with more sophisticated diagnostics and therapeutics.","title":"Collaborative Research: Molecular Programming Architectures, Abstractions, Algorithms, and Applications","awardID":"1317291","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[549421,"561030"],"PO":["565223"]},"208332":{"abstract":"The Research and Evaluation Group at CEMSE (Center for Elementary Mathematics and Science Education) at the University of Chicago will support the CS 10K effort by contributing to a necessary knowledgebase for CS 10K success through the following project goals: (1) Informing CS 10K leaders and other CS educators about the supports and barriers to wide scale high school CS education implementation and providing strategies for addressing them; (2) Providing tools for measuring CS program implementation and the supports and barriers that affect implementation; and (3) Creating products from research findings and recommendations about implementing and growing CS education. This project builds on CEMSE's previous NSF work rigorously studying implementation of educational innovations (new practices and programs) and the factors that affect innovation implementation and sustainability. <br\/><br\/>The research team will accomplish the project goals by examining implementation of the Exploring Computer Science (ECS) program and identifying the supports for, and barriers to implementation in several large school districts. Specifically, the project will rigorously study ECS implementation in Chicago, Los Angeles, and Washington, DC with a focus on the factors that currently affect ECS use, with particular attention to how and why these factors vary in the different contexts. The study will focus three research questions: (1) What is the status of ECS implementation in each site?; ( 2) What supports and barriers contribute to or inhibit the implementation and endurance of ECS?; and (3) To what extent do these supports and barriers differ by location and over time? The team will employ a mixed-methods research design using data collected through teacher and student questionnaires; ECS developer, school district personnel, school leader, and teacher interviews; and student focus groups. <br\/><br\/>Researchers will work collaboratively with CS 10K project leaders, CS education advisors, and school and district practitioners to produce findings and share timely and useful information with involved stakeholders through publication, presentations, on-line reports, webinars, and in-person discussions. The study will highlight the challenges to systemic efforts to increase accessibility, quality and quantity of high school CS education and offer recommendations to meet those challenges, ultimately helping the K-12 CS community bring needed programs into schools, and support lasting, systemic change.","title":"Examining the Factors that Affect the Implementation and Sustainability of Exploring Computer Science (ECS) in School Districts","awardID":"1339256","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}}],"PIcoPI":[558292,558293],"PO":["561855"]},"209575":{"abstract":"Proliferation of mobile smartphones has opened up possibilities of leveraging the people and devices in a crowd, (i.e., crowd-sourcing) to gather data from and monitor large crowds. However, current solutions either put unpredictable stress on the wireless or cellular infrastructure to a cloud and on energy-constrained smartphones or do not accurately capture crowd behavior. In response, our CrowdWatch project will investigate monitoring crowds from the ?inside-out? via a scalable, distributed and energy-efficient in-network crowd-sourcing framework. Local energy-efficient coordination and processing will enable the off-loading of some of the processing to the devices by establising a hierarchy of participants? multi-radio devices (i.e., Wi-Fi and Bluetooth). Through probabilistic monitoring of a crowd, CrowdWatch will reduce the demand on the bandwidth to the cloud and enhance traditional crowd-sourcing by enabling information to be delivered back to and among people within the crowd.<br\/><br\/><br\/><br\/>The main challenges of this project are (1) deployment and validation of the hierarchical crowd-sourcing system architecture, (2) design and validation of adaptive sampling algorithms to enable distributed sensing and control using Bluetooth and Wi-Fi sensing, (3) role selection algorithms based on resource availability (i.e., energy, bandwidth). Validation of CrowdWatch will entail experimentation and measurements of performance metrics such as resource usage, crowd density and user mobility, effectiveness of information distribution and monitoring of interaction frequency among users during two crowed events on our campus, the Engineering Open House and a University Basketball Game.","title":"EAGER: Enabling In-Network Crowd-Sensing","awardID":"1346782","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[561784,561785],"PO":["565255"]},"209498":{"abstract":"This award supports graduate and postdoctoral student participation from US universities, national labs, and non-profit research organizations to attend the 22nd International Meshing Roundtable (IMR) Conference be held in October 2013 in Orlando, FL. IMR created in 1992 is a unique conference for researchers in the field of mesh generation to exchange ideas and is also an excellent educational opportunity for students who are working on the meshing research and related applications. Potential topics for discussion in the conference include: mesh generation and modification, meshing for high-performance and distributed computing, CAD and computational geometry issues, and applications of meshing in computer graphics, finite-element analysis, computational fluid dynamics, biomedical engineering, processing of laser\/CT\/MRI scans, etc.<br\/>Students have the opportunity to attend a short course in meshing where the lecturers are internationally known experts in mesh generation. The instructors address practical problems for the design and implementation of both unstructured and structured grid generation. The course is ideal for graduate students that just enter the field and for advance graduate and postdoctoral students that want to expand their current skills and knowledge.<br\/>The workshop provides a forum to foster discussions mesh generation and will enable the identification of areas of common interest and potential collaboration among attendees from academia, National Laboratories, and industry. Priority will be given to students\/postdocs presenting a paper or poster at the conference. The PI plans to diversify the accepted attendees' pool and attract underrepresented groups.","title":"Introducing Next Generation of STEM Students to Mesh Modeling for Simulation and Visualization","awardID":"1346401","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7929","name":"COMPUTATIONAL GEOMETRY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7942","name":"HIGH-PERFORMANCE COMPUTING"}}],"PIcoPI":[561580],"PO":["565272"]},"207078":{"abstract":"Issues relating to climate change and food security require an understanding of the interaction between the natural world and human society over long time scales. Understanding climate change, its impacts on the natural world and society, and the tradeoffs inherent in societal responses demands an unprecedented degree of cooperation across academic fields. New data sources on expected future climate, soil characteristics, economic activity, historical weather, population, and land cover, provide a potential basis for this cooperation. New methods are needed for sharing within and across communities not only data but the software used to generate, synthesize, and analyze it. Progress on these research challenges is hindered by the extreme difficulties that researchers, collaborators and the community experience when they collaborate around data. Multiplicity of data formats, inadequate computational tools, difficulty in sharing data and programs, lack of incentives for pro-social behavior, and large data volumes are among the technology barriers. The FACE-IT project employs an integrated approach to cyberinfrastructure to advance the characterization of vulnerabilities, impacts, mitigation, and adaptation to climate change in human and environmental systems. Leveraging existing research cyberinfrastructure the project will create a full-featured FACE-IT Platform prototype with new capabilities for ingesting, organizing, managing, analyzing and using large quantities of diverse data. The project team will collaborate with two distinct interdisciplinary communities to create specific FACE-IT Instances that will both advance their research and enable at-scale evaluation of the utility of the FACE-IT approach.<br\/><br\/>Many important and challenging problems facing humankind occur at the intersection of the social, physical, biological, and computational sciences. The proposed methods and approaches have general applicability for advancing the use of research information across diverse communities.","title":"Collaborative Research: CyberSEES:Type 2: Framework to Advance Climate, Economics, and Impact Investigations with Information Technology (FACE-IT)","awardID":"1331782","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"7231","name":"CYBERINFRASTRUCTURE"}}],"PIcoPI":["562935"],"PO":["564022"]},"209168":{"abstract":"ABSTRACT<br\/>This INSPIRE award is partially funded by the Biophotonics (7236)and Biomedical Engineering (5345) programs in the CBET Division in the Directorate for Engineering; the Robust Intelligence (7495) program in the Division of Information and Intelligent Systems in the Directorate for Computer and Information Science and Engineering; and the the Organization (7712) program in the Division of Integrative Organismal Systems in the Directorate for Biology and the Instrumentation and Instrument Development (1108) program in the Division of Biological Infrastructure, also in the Directorate for Biology. Emerging Frontiers (7275) money was provided for the Organization and Instrumentation and Instrument Development programs by the Directorate for Biology.<br\/><br\/><br\/>The ability to optically image real-time physiological processes in living systems is of central importance for understanding how biological systems compute and function. In order to enable the imaging of deep, arbitrary-scale tissues, the PI proposes to address one of the fundamental limitations in live tissue imaging: the scattering of light by live tissues. Much work has been devoted to adaptive optics using conventional off-the-shelf spatial light modulators, interferometers, cameras, and other hardware. Here the PI proposes to create new technologies for adaptive optics based instead upon nanotechnology, which can help correct optical imaging for the scattering properties of living tissues. The project goal is nothing less than that of making real-time physiological processes visible throughout live tissues and organs, important for understanding how biological computations occur. The impact will be large for any field where understanding complex 3-D systems is key - for the study of live organs such as heart and brain, for the immune system, for the study of metabolism, for the study of development and aging, and for cancer biology. <br\/>They will distribute all tools as freely as possible, and pursue distribution mechanisms to maximize the availability of tools, at cost whenever possible. The proposed innovations will also benefit the field of optogenetic control of complex systems. These innovations will also greatly help with teaching of biology and medicine at all levels of education, since the ability to visualize things is powerful in education; we will incorporate these tools into teaching both at MIT and elsewhere, engaging scientists-in-training, as well as the public. Through both direct impact of tool usage, as well as via teaching, they anticipate that these proposed technologies will result in a more scientifically literate workforce. they also anticipate commercial impact, in the creation of new methods of diagnostics and medicine. The ability to hunt down better disease mechanisms, or mechanisms of disease treatment, may accelerate the development of new drugs and therapies. Some of the technologies here proposed could also lead to new companies, or new products, thus contributing to economic development, as well as helping with dissemination of the tools.","title":"INSPIRE Track 1: Nanotechnology for Adaptive Optics","awardID":"1344219","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"8078","name":"INSPIRE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"5345","name":"BIOMEDICAL ENGINEERING"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"7236","name":"BIOPHOTONICS, IMAGING &SENSING"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"7275","name":"CROSS-EF ACTIVITIES"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"1108","name":"INSTRUMENTAT & INSTRUMENT DEVP"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"7712","name":"ORGANIZATION"}}],"PIcoPI":[560687],"PO":["564986"]},"210290":{"abstract":"This grant supports organization of the workshop that brings together thought leaders from industry and academia to discuss use-case scenarios for use of robots in small and medium sized enterprises. The objective of the workshop is (1) to present and discuss industry use-cases for robotics in manufacturing and in particular examples where a move from fixed automation to flexible automation is an economic enabler and (2) to have broad discussions across academia and industry to internalize a common set of challenges and opportunities. The workshop participants gain new insights into what advances needed to deploy robotics in small and medium manufacturers. The workshop report provides a roadmap of challenges and research opportunities to guide the robotics community. The workshop stimulates future research towards development of robots for manufacturing applications. These activities directly impact the U.S. manufacturing.","title":"NRI: NSF: Challenges and Opportunities in Utilizing Robotics in Small and Medium Manufacturing Enterprises","awardID":"1354459","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["565099"],"PO":["564316"]},"202250":{"abstract":"The number of cameras in our lives and the scale of camera systems are continuously increasing as technological advances and falling prices in camera systems create new opportunities and applications. In addition to personal uses, cameras are widely employed in military, public and commercial applications for surveillance and statistics gathering. There are an estimated 30 million surveillance cameras in the U.S. capturing 4 billion hours of footage a week. Besides the traditional use of cameras for surveillance purposes, projects such as Google Glass are driving the development of miniature and low-cost cameras with local processing and communication capabilities. For future camera systems, local intelligence and autonomous collaboration among components will provide the capability to solve more complex tasks, which requires a unifying perspective to simultaneously address the challenges of hardware\/software co-design, real-time operation, high accuracy and self-coordination and self-adaptation in run-time.<br\/><br\/>This project provides a holistic and novel approach for the design, deployment and self-coordination of a set of collaborative embedded smart cameras, with the goal of monitoring large areas with the highest accuracy and smallest latency. One objective is designing synthesis approaches and computing infrastructure for the embedded smart cameras that allow hardware restructuring and systematic swapping of tasks between hardware and software on-the-fly. Another objective is to develop self-configuration approaches to autonomously adapt system behavior and optimally deal with run-time environmental changes, including node failures.<br\/><br\/>This research is expected to enable development of new real-time, fully automated, collaborative and highly accurate camera systems by providing a systematic approach for the design and deployment of such systems, and testing new methods at laboratory and campus scales. Potential applications include smart surveillance systems, multi-camera-based driver assistance systems, assistance in nursing homes, quality control on production lines based on 3D reconstruction, and remote surgery. The project also integrates research with the undergraduate and graduate programs of two institutions and contributes towards increasing the involvement of under-represented groups through the University of Arkansas Engineering Career Awareness Program, Arkansas Louis Stokes Alliance for Minority Participation and George Washington Carver Project, and the WiSE program at Syracuse University. Students from under-represented groups are to be recruited and involved in the design, implementation, and deployment of collaborative multi-camera networks.","title":"CSR: Medium: Collaborative Research: Self-Coordination in Cooperative Smart Camera Networks Incorporating System-On-Chip Reconfiguration","awardID":"1302559","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[542021],"PO":["564778"]},"202272":{"abstract":"The capability to preserve, model, and predict information cascades over online social networks has many theoretical and practical implications, e.g., for marketing, recommendation filtering, and studying of societal behavior. Massive empirical data sets on users' online social activities are being collected, but they are often too big to analyze. The goal of this project is to design graph generative models and summarization techniques that can preserve pertinent information about online social interactions that lead to interesting events, e.g., viral diffusion of information or drastic change of user behavior. Towards this end, the project will develop generative models that can capture the dynamic evolution of user activity graphs (UAGs), which represent a sequence of inter-user communications\/actions. At the microscopic level, the project will investigate user influence in the recruitment process. In addition, the project will design graph summarization techniques that can achieve good tradeoffs between data compression ratio, computational complexities, and accuracy in answering fundamental queries, such as identifying 'influential' sources of information cascades.<br\/><br\/>Broader Impact: If successful, this project will provide efficient methods for storing\/archiving massive graph data to support longitudinal study on the dynamics of online social interactions, which has potential impact on multiple disciplines (e.g., economics, history, political sciences, and social science). This project will help train future researchers and practitioners in online social networking and network science through classroom curriculum development and online teaching. The PIs will continue ongoing diversity recruitment and outreach to K-12 students. Transfer of technology into commercial practice is made feasible through partnership with industry.","title":"NeTS: Medium: Collaborative Research: Towards Building Time Capsule for Online Social Activities","awardID":"1302691","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["551132",542083],"PO":["565090"]},"205792":{"abstract":"Live migration of virtual machines (VMs) is a key feature of server virtualization that underlies numerous operations in cloud computing platforms such as routine maintenance, load balancing, scaling to handle peak demands, and saving energy. Even though work in both industry and academia has made impressive advances in live migration technology, several important challenges remain to be addressed. This research investigates new VM migration mechanisms having better performance, robustness, and security. In particular, this work explores (1) simultaneous live migration of multiple VMs using distributed de-duplication and scatter-gather transfer of memory contents, (2) fault-tolerant VM migration to recover VMs after a failure during live migration, and (3) secure live VM migration techniques that reduce the performance impact of encryption and increase robustness against attacks.<br\/><br\/>This research benefits modern data centers by advancing the state-of-the-art in live VM migration technology. Broader impacts include technology transfer, outreach to local high schools, and involving undergraduates, women and minority students in research. Integration of research with education includes development of course modules, course projects, and an advanced topics graduate course.","title":"CSR: Small: Towards High-Performance, Robust, and Secure Live Migration of Virtual Machines","awardID":"1320689","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[550962,"557776"],"PO":["564778"]},"205440":{"abstract":"Software development is a complex and manual process, in part because typical software programs contain more than hundreds of thousands lines of computer code. If software programmers fail to perform critical checks in that code, such as making sure a user is authorized to update an account, serious security compromises ensue. Indeed, vulnerable software is one of the leading causes of cyber security problems. Checking for security problems is very expensive because it requires examining computer code for security mistakes, and such a process requires significant manual effort. This research project aims at developing an interactive help system to warn software programmers about potential security mistakes, similar to the way modern word processors warn writers of spelling and grammar errors. This is likely lead to new functions for software development tools that will significantly reduce security vulnerabilities in software.<br\/><br\/>The research is based on the concept of interactive static analysis, a novel mixed-initiative paradigm for interacting with programmers to aid in the detection and prevention of security vulnerabilities. Static analysis is seamlessly integrated into the development environment in such a way that programmers are not required to learn additional programming language and analysis concepts beyond the use of the development environment. Static analysis is performed in the context of development, allowing programmers to utilize and influence such analysis during their program construction. The goals of this research are to bring programmers into the security loop, improving their ability to detect, understand, and prevent vulnerabilities; and utilize the programmer's contextual knowledge to drive customized static analysis, detecting software vulnerabilities that are difficult to detect using current static analysis techniques.","title":"TWC: Small: Collaborative: Discovering Software Vulnerabilities through Interactive Static Analysis","awardID":"1318854","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[550117,550118],"PO":["564388"]},"206892":{"abstract":"This project is funded as part of the United States-Israel Collaboration in Computer Science (USICCS) program. Through this program, NSF and the United States - Israel Binational Science Foundation (BSF) jointly support collaborations among US-based researchers and Israel-based researchers. This project aims to design a framework for the integration of advanced foundational methods from computational geometry with effective sampling-based methods from motion planning. This will allow the practical use of these techniques in important applications and the development of useful educational experiences. Motion planning, in its basic form, corresponds to the problem of finding a collision-free path for a robot in a workspace cluttered with static obstacles. It is important for many application domains, such as manufacturing and warehouse management, product assembly, surgical planning, architectural design, graphical animation, computer games, and computational biology. The collaboration of the US and Israeli researchers will impact the application areas through the development of novel efficient tools based on sound theory for motion planning of complex systems. Furthermore, the availability of these tools can have an impact in educational efforts in the areas of algorithms, computational geometry and robotics.<br\/><br\/>Towards achieving these objectives, the investigators will implement and evaluate composite methods for motion planning, that lie at the intersection of computational geometry and sampling-based planning. In particular, the investigators will utilize foundational methods to compute compact motion planning representations that provide optimality guarantees, based in part on recent advances in summary of big data in other fields. The collaboration can also lead to advances in the area of multi-robot motion planning, by taking advantage of recent progress in combinatorial solvers and transferring these results in the continuous motion planning domain. Overall, the integrated framework will allow advances in geometry-based algorithms to be readily available to the motion planning community, especially in sampling entire low-dimensional manifolds of the configuration space instead of individual configurations, collision detection and space decomposition.","title":"BSF:2012166:A Framework for Composite Techniques in Motion Planning","awardID":"1330789","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":[553948],"PO":["565264"]},"205682":{"abstract":"From key-value stores to distributed file systems to distributed <br\/>databases, networked storage underpins modern Internet services. <br\/>Networked storage allows programmers to separate logic and data, enables <br\/>high throughput scale out, and takes advantage of increasingly fast <br\/>datacenter networks. However, in the big data era, networked storage <br\/>faces a new challenge: The amount of data accessed per user request is <br\/>growing rapidly; outpacing processor speeds and DRAM capacity. <br\/>Increasingly, user-perceived response times are dominated by the slowest <br\/>storage accesses, i.e., the 99th percentile tails. Networked storage is <br\/>notorious for fat tailed response times.<br\/><br\/>We are developing networked storage systems that are 1) always fast and 2) <br\/>cost efficient. A key approach is to understand and selectively use <br\/>replication for predictability (or cloning). In this approach, clients <br\/>issue redundant storage accesses against independent hardware resources. <br\/>The first to respond provides the result. Replication for predictability <br\/>reduces client-perceived variability, leading to always fast response <br\/>times. Our implementations are especially cost effective at scale. To <br\/>lower costs, we study the root causes of slow response times, saving <br\/>resources by focusing on common causes. We also trade quality---e.g., <br\/>slightly degraded search engine results--- for lower hardware costs when <br\/>appropriate. For broader impact, the PI will work to transfer the <br\/>technology to national and local companies.","title":"CSR: SHF: SMALL: Efficient, Low-Latency Networked Storage","awardID":"1320071","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["563444"],"PO":["565255"]},"206782":{"abstract":"To ensure operational safety of complex cyber-physical systems such as automobiles, aircraft, and medical devices, new models, analyses, platforms, and development techniques are needed that can predict, possible interactions between features, detect them in the features' concrete implementations, and either eliminate or mitigate such interactions through precise modeling and enforcement of mixed-criticality cyber-physical system semantics. This project is taking a novel approach to reasoning about and managing feature interactions in cyber-physical systems, which encompasses interactions within software, interactions through the physical dynamics of the system, and interactions via shared computational resources. The proposed approach consists of three tightly coupled research thrusts: (1) a novel way of modeling features as automata equipped with both physical dynamics of the feature environment, and an assigned criticality level in each state of an automaton, (2) new automata-theoretic and control-theoretic analysis techniques, enabled by the modeling approach, and (3) new algorithms for adaptive sharing of computational resources between individual features that are guaranteed to satisfy the assumptions made during analysis, realized within a novel mixed-criticality cyber-physical platform architecture. The modeling approach will introduce a new model for mixed-criticality cyber-physical components and will support modern development standards, such as AUTOSAR in the automotive industry, for assigning criticality levels to features. Component interfaces in this model will capture control modes and the associated physical dynamics, operating modes and the associated resource requirements and criticality level, as well as relationships between control modes and operating modes. Analysis of features expressed in the proposed model will include detection of interactions and exploration of their effect on safety properties of the composite system. The broader impacts of the proposed work are twofold. One impact lies in the pervasive use of cyber-physical systems in our society. If the developed results are adopted in industry, it may help to promote improved safety of such systems. Results of the proposed research will be used in courses offered at both University of Pennsylvania and Washington University at the graduate and undergraduate levels. The project will also provide students with opportunities to get involved in cutting edge research within their fields of study","title":"CPS: Synergy: Collaborative Research: Safety-Feature Modeling and Adaptive Resource Management for Mixed-Criticality Cyber-Physical Systems","awardID":"1329984","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[553656,553657,553658],"PO":["565136"]},"205572":{"abstract":"The project develops new methodologies for testing complex Cyber-Physical Systems that perform safety-critical tasks in a wide variety of application domains such as automotive, airspace, medical devices and power generation. The primary challenge in these applications lies in the complexity of the physical system, modeled as systems of non-linear Ordinary Differential Equations (ODE) with a large number of state variables, and the interaction of this physical subsystem with a software-based controller. In many industrial applications, these models are not even available in a closed-form representation and only system simulations can be performed. In this project, ideas from optimization and optimal control theory are employed in order to drive the process of state-space exploration for system verification. The theory of robustness metrics for temporal logic specifications is combined with non-smooth optimization theory which results in gradient descent search methods for multi-modal CPS. At a higher level, concrete and symbolic execution techniques are combined to enhance the performance of the search methods. The verification methods can be readily integrated into existing industrial strength simulation environments. The target applications for such verification tools are from the domains of medical and automotive applications.<br\/><br\/>Verification of complex Cyber-Physical Systems (CPS) is a challenging problem. Continuous and multiple recalls of medical and automotive products due to software errors across virtually all manufacturers establish the urgency and importance of the problem. This project integrates usable verification tools inside existing and widely adopted model-based development platforms. The application focus on the verification of medical and automotive software aims to avoid harmful losses due to errors in these safety-critical systems. The concrete benefit to society is twofold: first, improved system safety and dependability; and, second, reduced development times for new products. The educational aspects of this project revolve around courses that train students on model-based design and verification methods for safety-critical CPS. The educational mission of the project also stresses a \"safety first\" approach to designing CPS wherein specification and verification are taught as integral steps in the design rather than post-design steps. Besides research publications, avenues of dissemination include sharing of software, models, and course materials via cps-vo.org and other publicly accessible websites.","title":"CSR: Small: Collaborative Research: Gray Box Testing of Complex Cyber-Physical Systems Using Optimization and Optimal Control Techniques","awardID":"1319560","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["562871"],"PO":["564778"]},"205693":{"abstract":"Our physical world presents an incredibly rich set of observation modalities. Recent advances in wireless sensor networks (WSNs) enable the continuous monitoring of various physical phenomena at unprecedented high spatial densities and long time durations, hence opening exciting new opportunities for numerous scientific endeavors. Since sensor nodes are unattended and batterypowered, network monitoring\/tomography from indirect measurements at the sink(s) and energy conservation are critical in the deployment of large-scale environmental WSNs. Therefore, a viable framework for energy-efficient network monitoring and data collection is fundamentally important to significantly improve WSN management\/operations and reduce its deployment costs.<br\/><br\/>This project investigates the energy-efficient network monitoring\/tomography and data collections in large-scale outdoor WSNs, based on the recent breakthrough of compressed sensing (CS) through an integrated theoretical and empirical approach. The project studies WSN topology tomography for dynamic routing under wireless link dynamics due to channel fading and interference. The objectives of this project are to develop a novel and rigorous framework of topology tomography for real-world WSNs operated in highly noisy communication environments. Dynamic routing topology recovery algorithms are devised for both complete indirect measurements and incomplete indirect measurements received at the sink(s). The accuracy of the tomography approach is studied both analytically and empirically. The developed WSN topology tomography framework can be essential not only for WSN's routing improvement, topology control, hot spot elimination, and anomaly detection in practice, but also for emerging CS-based data collection. This approach extends the current CS technology to form a unified framework for network tomography and data collection in large-scale WSNs, upon which energy-efficient WSN topology tomography and data gathering protocol suite is developed. The developed framework and protocol suite will be validated and evaluated in a real-world environmental WSN testbed in a hilly watershed.<br\/><br\/>The project intends to create a new paradigm of optimal design, development, and management\/operations for large-scale WSNs to significantly extend their lifetime. This would lead to a substantial reduction of the prohibitive cost of large-scale WSN deployments for scientific, civic, national security, and military purposes in the near future. The project creates an interdisciplinary educational practice for both undergraduate and graduate students through hands-on experience with a real-world WSN testbed. The outreach includes summer camps and scientific projects for school students using the WSN testbed.","title":"NeTS: Small: Collaborative Research: Compressed Network Tomography and Data Collection in Large-Scale Wireless Sensor Networking","awardID":"1320132","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[550733],"PO":["565303"]},"206793":{"abstract":"This cross-disciplinary project brings together a team of engineering and computer science researchers to create, validate, and demonstrate the value of new techniques for ensuring that systems composed of combinations of hardware, software, and humans are designed to operate in a truly synergistic and safe fashion. One notable and increasingly common feature of these \"Cyber-Physical-Human\" (CPH) systems is that the responsibility for safe operation and performance is typically shared by increasingly sophisticated automation in the form of hardware and software, and humans who direct and oversee the behavior of automation yet may need to intervene to take over manual or shared system control when unexpected environmental situations or hardware or software failures occur. The ultimate goal is to achieve levels of safety and performance in system operation that exceed the levels attainable by either skilled human operators or completely autonomous systems acting alone. To do so, the research team will draw upon their expertise in the design of robust, fault-tolerant control systems, in the design of complexity-reduction architectures for software verification, and in human factors techniques for cognitive modeling to assure high levels of human situation awareness through effective interface design. By doing so, the safety, cost and performance benefits of increasingly sophisticated automation can be achieved without the frequently observed safety risks caused by automation creating greater distance between human operators and system operation. The techniques will be iteratively created and empirically evaluated using experimentation in human-in-the-loop simulations, including a medium-fidelity aircraft and flight simulator and a simulation of assistive automation in a medical context.<br\/><br\/>More broadly, this research is expected to impact and inform the engineering of future CPH systems generally, for all industries and systems characterized by an increasing use of hardware and software automation directed and overseen by humans who provide an additional layer of safety in expected situations, Examples include highway and automotive automation, aerospace and air traffic control automation, semi-automated process control systems, and the many forms of automated systems and devices increasingly being used in medical contexts, such as the ICU and operating room. This research is also expected to inform government and industry efforts to provide safety certification criteria for the technologies used in CPH systems, and to educate a next generation of students trained in the cross-disciplinary skills and abilities needed to engineer the CPH systems of the future. The investigators will organize industry, academic, and government workshops to disseminate results and mentor students who are members of underrepresented groups through the course of this research project.","title":"CPS: Synergy: Collaborative Research: Engineering Safety-Critical Cyber-Physical-Human Systems","awardID":"1330077","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[553686,553687,553688,553689],"PO":["562984"]},"205462":{"abstract":"The digital provenance of a digital object gives a history of its life cycle including its creation, update, and access. It thus provides meta-level information about the sequence of events that lead up to the current version of the object, as well as its chain of custody. Such provenance information can be used for a variety of purposes, such as identifying the origins of a document, assessing the quality or reliability of data, and detecting undesirable actions such as forgery or unauthorized alteration of data. However, all of these practical uses of provenance information presuppose that the provenance system is secure, i.e. that provenance data is collected, processed, and stored in a manner that ensures its confidentiality and integrity. Without such guarantees, users can get an incorrect impression of document authenticity, potentially with significant real-world consequences.<br\/><br\/>This project investigates the design of secure provenance collection systems where the collected meta-data can be relied upon even in light of realistic insider attack models. Security, however, is not sufficient; a practical system must also be efficient even when large amounts of fine-grained provenance data needs to be stored and processed. The project is aimed at addressing both issues through the following three objectives. (1) Techniques for continuously updatable software tamperproofing to ensure the integrity of the system itself. (2) Techniques for robust, continuous marking, collusion-free, text fingerprinting to mitigate document leakage. (3) Techniques for anonymous storage on untrusted storage servers to allow for efficient storage and access of fine-grained provenance data.","title":"TWC TTP: Small: Mitigating Insider Attacks in Provenance Systems","awardID":"1318955","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[550173,550174,550175],"PO":["565327"]},"208982":{"abstract":"Existing spectrum-sharing paradigms have set clear boundaries between primary and secondary networks. There is very limited node-level cooperation between primary and secondary networks. This project develops a new and bold paradigm that explores policy-based network cooperation as a new dimension for spectrum sharing between primary and secondary networks. The benefits of this paradigm are numerous, as it allows integrating resources from two networks. To move this new paradigm from concept to reality, this project aims to (1) develop fundamental understanding of policy-based cooperation through mathematical models and optimization, (2) explore new achievable rate regions through the use of advanced physical layer technologies, and (3) develop distributed optimization algorithms that can offer performance approaching the theoretical limits. For prototype, the project implements the policy-based cooperation on a 48-node testbed.<br\/><br\/>The project investigates a new paradigm and technologies that enable more flexible and efficient sharing of the radio spectrum. New mathematical models developed in this research will help gain fundamental understanding of the benefits of the new paradigm. The use of advanced physical layer technologies will further push the performance envelopes of achievable rate regions. New textbooks will be developed and used in classrooms at Virginia Tech and other universities. Special efforts to broadening participation by female and underrepresented students are planned through an on-going NSF REU site for cognitive radio communications and Virginia Tech's participation in Pacesetters, a program organized by the National Center for Women and Information Technology.","title":"A New Dimension in Radio Spectrum Sharing through Network Cooperation","awardID":"1343222","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7976","name":"EARS"}}],"PIcoPI":[560139,560140,"564848","564847"],"PO":["557315"]},"205231":{"abstract":"The computing revolution began over two thousand years ago with the advent of mechanical devices for calculating the motions of celestial bodies. Sophisticated clockwork automata were developed centuries later to control the machinery that drove the industrial revolution, culminating in Babbage's remarkable design for a programmable mechanical computer. With the electronic revolution of the last century, the speed and complexity of computers increased dramatically. Using embedded computers we now program the behavior of a vast array of electro-mechanical devices, from cell phones and satellites to industrial manufacturing robots and self-driving cars. The history of computing has taught researchers two things: first, that the principles of computing can be embodied in a wide variety of physical substrates from gears to transistors, and second, that the mastery of a new physical substrate for computing has the potential to transform technology. Another revolution is just beginning, one whose inspiration is the incredible chemistry and molecular machinery of life, one whose physical computing substrate consists of synthetic biomolecules and designed chemical reactions. Like the previous revolutions, this \"molecular programming revolution\" will have the principles of computer science at its core. By systematically programming the behaviors of a wide array of complex information-based molecular systems, from decision-making circuitry and molecular-scale manufacturing to biomedical diagnosis and smart therapeutics, it has the potential to radically transform material, chemical, biological, and medical industries. With molecular programming, chemistry will become a major new information technology of the 21st century.<br\/><br\/>This Expeditions-in-Computing project aims to establish solid foundations for molecular programming. Building on advances in DNA nanotechnology, DNA computing, and synthetic biology, the project will develop methods for programmable self-assembly of DNA strands to create sophisticated 2D and 3D structures, dynamic biochemical circuitry based on programmable interactions between DNA, RNA, and proteins, and integrated behaviors within spatially organized molecular systems and living cells. These architectures will provide systematic building blocks for creating programmable molecular systems able to sense molecular input, compute decisions about those inputs, and act on their environment. To manage system complexity and to provide modularity, the project will establish abstraction hierarchies with associated high-level languages for programming structure and behavior, compilers that turn high-level code into lists of synthesizable DNA sequences, and analysis software that can predict the performance of the sequences. This will allow molecular programmers to specify, design, and verify the correctness of their systems before they are ever synthesized in the laboratory. In addition to these software tools, the project will study the theory of molecular algorithms in order to understand the potential and limitations of information-based molecular systems, what makes them efficient at the tasks they can perform, and how they can be effectively designed and analyzed. Putting the products of this fundamental research to the test, the project will pursue real-world applications such as molecular instruments for probing biological systems and programmable fabrication of nanoscale devices.<br\/><br\/>This project will expand the network of scientists and engineers working in molecular programming by building a diverse community of students, teachers, researchers, scientists, and engineers. This community will be fostered through the creation of publicly accessible software tools, courses, textbooks, workshops, tutorials, undergraduate research competitions, and popular science videos to teach the principles and methods of molecular programming and to engage young researchers and the public in this exciting new field. Industrial partnerships with relevant biotechnology and other high-tech companies will ensure fast transfer of knowledge generated into real-world products. Perhaps most importantly, as molecular programming becomes a widespread technology, it has the potential to transform industry with new complex nanostructured materials, to transform chemistry with integrated and autonomous control of reactions, to transform biology with advanced molecular instruments, and to transform health care with more sophisticated diagnostics and therapeutics.","title":"Collaborative Research: Molecular Programming Architectures, Abstractions, Algorithms, and Applications","awardID":"1317640","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[549550],"PO":["565223"]},"206694":{"abstract":"This project is funded as part of the United States-Israel Collaboration in Computer Science (USICCS) program. Through this program, NSF and the United States - Israel Binational Science Foundation (BSF) jointly support collaborations among US-based researchers and Israel-based researchers. Computing systems are embedded in a wide variety of commercial applications, driving the economy and transforming our society and culture. The next generation computing systems are becoming severely limited by energy dissipation constraints, due to the need for portability and ever increasing complexity. These computer systems range in applications from battery operated personal devices to large scale data servers servicing the internet. The primary objectives of this project are to provide circuit and architectural design technologies to fundamentally enhance this condition of energy constraints by exploiting new magnetic technologies in the design of these computing systems. Specifically, memristors will be exploited to develop advanced computing systems that will use fundamentally less power while offering novel heretofore unseen applications due to the inherent advantages of this burgeoning and exciting technology.<br\/><br\/>The ability of memristors to maintain state without energy will be exploited as a replacement for on-chip memory; for example, DRAM and high speed cache, to greatly lower the energy requirements of portable computing. Furthermore, due to the ability to easily integrate memristors with CMOS, hybrid circuits and architectures will be developed to provide novel computing structures that operate differently and advantageously as compared to modern computing systems. The combination of these novel circuit structures, computing architectures, and advanced magnetic technologies will contribute to better understanding and exploitation of on-chip locality of information while reinvigorating the slowing development of computing technologies. Furthermore, improved portability will be attained while saving energy and enhancing the environment.","title":"BSF:2012139:Computing Structures Beyond Moore and von Neumann","awardID":"1329374","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":[553419],"PO":["565264"]},"205484":{"abstract":"This research project helps secure the privacy of web browser users. It specifically targets the browser addon framework, which allows third-party developers to extend the browser's functionality. These addons are written in JavaScript and have extraordinary privileges and access to sensitive user information. Therefore, vetting third-party addons to prevent malicious or accidental security violations is critical. However, the current vetting process for browser addons is manual and ad-hoc, making this process both tedious and error-prone. The goal of this research project is to enhance and automate addon vetting by using static analysis for JavaScript to enforce formal security policies.<br\/><br\/>The approach taken by this project is three-fold: (1) design formal security policies to provide provable guarantees; (2) create a provably-sound static security analysis for JavaScript-based browser addons; and (3) develop new tools for explaining security problems in addon code so that third-party developers can revise insecure add ons to eliminate vulnerabilities. This work benefits society as a whole by giving people assurance that their sensitive information is being treated securely. The work also benefits academia and industry by providing the first-ever provably-sound JavaScript static analysis for browser addons. The techniques that are developed will advance understanding of how to usefully analyze dynamic languages such as JavaScript, and the analysis framework itself will enhance research infrastructure by providing a platform for researchers to develop static analyses for JavaScript.","title":"SHF: Small: Static Analysis for Safe Browser Addons","awardID":"1319060","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[550234],"PO":["564388"]},"208641":{"abstract":"As demands on campus networks - many driven by science and engineering disciplines - intensify, traditional network management approaches are increasingly obsolete. Researchers often require network paths with higher throughput, increased security, and\/or perimeter firewall bypass. Network operators traditionally have accommodated a few research users by provisioning dedicated resources. Previous approaches for addressing requests for special connectivity to regional and national facilities have not scaled well.<br\/><br\/>At the University of Utah, a research team is upgrading part of the campus network with technology originally developed for a national network research testbed (NSF GENI). This \"sliceable network\" model allows multiple virtual networks to be established in parallel over the same equipment. Each resulting science slice may have different characteristics and may connect to distinct resources either on or off campus. This allocation scheme may incorporate computational and storage resources in addition to network paths. With hardware supporting emerging Software Defined Networking standards, these slices can be controlled to very fine granularity. This technology inherently supports dynamic slice creation to enable on-demand network resource allocation for researchers.<br\/><br\/>This work provides an abstraction to insulate multiple high-intensity users cleanly in a campus network. The ensuing intellectual merit follows from applying a research focused network management approach more broadly to part of a large production environment. For broader impact, a connection to the University?s undergraduate honors residence allows this innovative cohort to interact directly with the sliced network and also pursue guided experimentation. The core software base and project-specific enhancements are available under open-source licensing.","title":"CC-NIE Integration: Science Slices Converting Network Research Innovation into Enhanced Capability for Computational Science and Engineering at the University of Utah","awardID":"1341034","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[559298,559299,559300,"560436",559302],"PO":["564246"]},"209873":{"abstract":"Data-driven innovation requires a foundation of infrastructure to support the sharing, access, use, re-use, analysis, and stewardship of digital data. Data infrastructure includes cyber-infrastructure tools for data discovery and analysis (and their underlying technical structures and components -- persistent digital identifiers, shared metadata frameworks, etc.), and social infrastructure in the form of community policy and organizational practice (harmonization of standards, approaches for data access and preservation, etc.). To address the growing global need for data infrastructure, the Research Data Alliance (RDA) was planned and launched in FY13 as an international community-driven organization. RDA's mission is to build the social, organizational, and technical infrastructure needed to reduce barriers to data sharing and exchange, and to accelerate data-driven innovation world-wide. In the wake of precipitous growth, RDA is now working to develop a stable support model for at least a five-year period. The RDA 2 project provides support for U.S. participation and leadership within the RDA, as well as strategic expansion of the U.S. community within RDA (RDA\/U.S.). RDA 2 integrates a) strategic efforts and pilots to expand, diversify, and strengthen the RDA\/U.S. community, and b) support for U.S. contributions to RDA operations and leadership, including U.S. participation in, and hosting of, RDA Plenaries. RDA\/U.S. will be led by a Steering Committee consisting of Fran Berman, RPI (Chair), Beth Plale, IU, (Vice Chair, Technical Programs), Larry Lannom, CNRI, (Vice Chair, Outreach and Development) and Mark Parsons, RPI (Managing Director).<br\/><br\/>The RDA 2 project builds RDA through increasing U.S. engagement and leadership. RDA 2 builds RDA\/U.S. through pilots in three strategic areas: Community Engagement and Outreach, Student and Early Career Engagement, and Adoption and Impact Amplification. The pilots are designed to expand and diversify RDA\/U.S. data community, increase the impact of RDA deliverables in the U.S., and enhance the benefit of RDA for U.S. institutions, communities, businesses, and individuals. A strong RDA\/U.S. can be a vehicle for accelerating U.S. innovation, and positioning the U.S. community for greater competitiveness and leadership. RDA\/U.S. can contribute to the data infrastructure needed to make new U.S. policy approaches and initiatives work, and serve as a means of capitalizing","title":"RCN: Building the Research Data Alliance Community through US and International Engagement (RDA 2)","awardID":"1349002","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"7231","name":"CYBERINFRASTRUCTURE"}}],"PIcoPI":["565242","562790",562620,562621],"PO":["565292"]},"209642":{"abstract":"The recently introduced Single Root I\/O Virtualization (SR-IOV)<br\/>technique for InfiniBand and High Speed Ethernet provides native I\/O<br\/>virtualization capabilities and enables us to provision the internal<br\/>PCI bus interface between multiple Virtual Machines (VMs). However,<br\/>achieving near native throughput for HPC applications that use both<br\/>point-to-point and collective operations on virtualized multi-core<br\/>systems with SR-IOV presents a new set of challenges for the designers<br\/>of high performance middleware, such as MPI. In order to solve this<br\/>problem, this project aims to address the following set of challenges:<br\/>1) How to redesign MPI communication library to achieve efficient<br\/>locality-aware communication and facilitate fair resource sharing on<br\/>modern virtualized high performance clusters, with SR-IOV? 2) Can<br\/>communication libraries be designed to deliver the best communication<br\/>performance across different VM subscription policies and network<br\/>communication modes? 3) What are the the challenges involved in<br\/>designing support for advanced features such as, live migration,<br\/>Quality of Service, and I\/O storage virtualization? and 4) What kind<br\/>of benefits, in terms of performance and scalability, can be achieved<br\/>by the proposed approach for HPC applications? A synergistic and<br\/>comprehensive research plan is proposed to address the above<br\/>challenges for HPC Virtualization on clusters with SR-IOV and study<br\/>its impact for a set of HPC applications.","title":"CSR: Eager: HPC Virtualization with SR-IOV","awardID":"1347189","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[561947],"PO":["565255"]},"209202":{"abstract":"This INSPIRE award is partially funded by the Cyber-Physical Systems Program in the Division of Computer and Network Systems in the Directorate for Computer and Information Science and Engineering, the Information and Intelligent Systems Program in the Division of Information and Intelligent Systems in the Directorate for Computer and Information Science and Engineering, the Computer Systems Research Program in the Division of Computer and Network Systems in the Directorate for Computer and Information Science and Engineering, and the Software and Hardware Foundations Program in the Division of Computing and Communications Foundations in the Directorate for Computer and Information Science and Engineering.<br\/><br\/>Sound plays a vital role in the ocean ecosystem as many organisms rely on acoustics for navigation, communication, detecting predators, and finding food. Therefore, the 3D underwater soundscape, i.e., the combination of sounds present in the immersive underwater environment, is of extreme importance to understand and protect underwater ecosystems. This project is creating a transformative distributed ocean observing system for studying the underwater soundscape at revolutionary spatial (~100 meters) and temporal (~100 seconds) resolutions that is also able to simultaneously resolve small-scale ocean current flow. These breakthroughs are achieved using a distributed collective of small hydrophone-equipped subsurface floats, which utilize group management techniques and sensor fusion to understand the ocean soundscape in a Lagrangian manner. The ability to record soundscapes provides a novel sensing technology to understand the effects of sound on marine ecosystems and the role that sound plays for species development. Experiments off the coast of San Diego, CA, and a research campaign in the Cayman Islands provide concrete scientific studies that are tightly interwoven with the engineering research.<br\/><br\/>Oceans are drivers of global climate, are home to some of the most important and diverse ecosystems, and represent a substantial contribution to the world's economy as a major source of food and employment. The technological and scientific advances in this project provide crucial tools to understand natural ocean resources, by studying soundscapes at spatio-temporal scales that were heretofore extremely burdensome and expensive to obtain.","title":"INSPIRE Track I: Distributed Sensing Collective to Capture 3D Soundscapes","awardID":"1344291","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"8078","name":"INSPIRE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[560816,560817,560818,560819,560820],"PO":["561889"]},"209587":{"abstract":"This project will provide long-term support for external evaluation activities and services for the Computing and Information Sciences and Engineering Research Experiences for Undergraduates (CISE REU) community. This project will address the ongoing need among principal investigators who are fulfilling CISE REU Site program evaluation efforts by providing an evaluation toolkit that facilitates evaluation reporting while strengthening research about undergraduate research program outcomes. The primary purpose of the evaluation toolkit is to provide targeted instructional resources and tools for quality program evaluation that balance the desire for standardized assessment along with the responsibility to account for individual program contexts. Toolkit contents include instructional materials about evaluation practice, a standardized applicant management tool, and a validated modulated outcomes measure. Services associated with the toolkit are providing a Common Application for site recruiting, a Shared Applicant Pool for principal investigators to share applicants across sites, delivery of an online student survey known as the A la Carte Student Survey, and corresponding responses to REU Site principle investigators. Project expansion will continue these tools and services as well as expand to include a Faculty Career Impact Survey, Student REU Alumni Survey, and a study of site organizational characteristics. The benefits of the toolkit are in providing cost effective, sustainable evaluation tools, a community forum for program evaluation, and aggregate measurement of key program outcomes indicators for the national program. The evaluation toolkit project balances the need for individual site context evaluation with the need for broader, generalizable program impact evaluation. <br\/><br\/>Intellectual Merit<br\/>The intellectual merit of this project resides in the contributions to understanding the impact of undergraduate computing research programs for both students and faculty participants. The comprehensive program evaluation will inform collective efforts to recruit undergraduate students to doctoral programs. The program evaluation will generate knowledge about features of REU Site structure for enhancing student learning outcomes and motivating individuals to pursue advanced degrees and careers in research. The knowledge generated by this study will also provide insights about how faculty engage in REU Sites and the impact on their careers.<br\/><br\/>Broader Impacts<br\/>The broader impact of the project will be evidenced by the instruments and online tools developed by this project that will benefit any researcher involved in supporting research experiences for undergraduates. This will enable formative improvements for numerous REU programs, enrich REU experiences for undergraduate students, and augment faculty capacity for leading successful REU programs, thereby enhancing the graduate school pipeline and faculty career development. In addition, the outcomes of the proposed project will contribute to evaluation capacity building research for multi-site program assessment.","title":"CISE REU Evaluation Toolkit Expansion Project","awardID":"1346847","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[561814],"PO":["564181"]},"209169":{"abstract":"This INSPIRE award is partially funded by the NeTS program in the Division of Computer and Network Systems in the Directorate for Computer and Information Science and Engineering, the Directorate for Computer and Information Science and Engineering, and the Directorate for Engineering.<br\/><br\/>This project will design and build \"The Optical Turing Machine\" (OTM) a digital device that computes using a optical data modulation format compatible with long-distance, high-speed transmission to support terabit-per-second. It integrates computation and communication by computing with the same symbols used for transmission, which enables native optical processing of network data while avoiding costly optical-electronic-optical conversion or modulation format conversion (e.g., serial to parallel). Specific to the NSF INSPIRE program, OTM explores in-network high-speed processing that necessitates concurrent cross-disciplinary development across networking, computation, and optical devices. It involves new perspectives on modulation to support computation, the transformation of algorithms into serial architectures and system design based on the needs of networking within the constraints of optical capabilities that cannot be developed from any single vantage point or focus.<br\/><br\/>OTM motivates research in serial computation, algorithms in higher-order logic, homomorphic transforms, new methods for big data analysis, and new active optical devices. OTM benefits society by enabling faster communication and computation at potentially lower power and complexity, supporting enhanced in-network capabilities for privacy, error correction, and packet services at rates far in excess of those capable by current electronic processing. If successful, it also provides an opportunity to reexamine the fundamental assumptions of several decades of attempts at optical computing. Cross-publication across both CS and EE will enhance this effect.","title":"INSPIRE Track 1: An Optical Turing Machine for Native Computing Using High-Capacity Transmission Modulation Format Symbols","awardID":"1344221","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"8078","name":"INSPIRE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0709","name":"Division of BIOENGINEERING & ENVIRON SYSTE","abbr":"BES"},"pgm":{"id":"1385","name":"SPECIAL STUDIES AND ANALYSES"}}],"PIcoPI":[560689,560690],"PO":["564993"]},"210291":{"abstract":"This workshop at the Institute for Computational and Experimental Research in Mathematics (ICERM) at Brown University brings together researchers from several disciplines, who are interested in a encompassing mathematical foundation for cyber security. The results of the workshop will be made widely available through archival publications and online at ICERM.","title":"Workshop Proposal: Mathematical Challenges in Cybersecurity","awardID":"1354474","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[563550],"PO":["565239"]},"210181":{"abstract":"Cognitive radio is a promising technology that can significantly alleviate spectrum scarcity and improve the spectral efficiency. This project conducts a comprehensive study on developing a social and context aware spectrum management framework that targets maximizing the spectral efficiency for cognitive radio networks with heterogeneous devices and applications. This research is motivated by the idea that the efficient management of spectrum requires the consideration of the entire network ecosystem where the users and their applications interact with each other. In the proposed framework, a novel fairness criterion is developed for the network scenarios under consideration. With the developed fairness criterion as a constraint, a social and context aware spectrum allocation scheme is developed, which contributes to the maximization of the spectral efficiency. In addition, a fair opportunistic spectrum sharing mechanism is proposed to further improve the spectral efficiency. Lastly, various aspects of social bonding in a group of users are exploited to reduce the delay occurred in the spectrum sharing process.<br\/><br\/>The expected results of this project include novel algorithms, designs, and technologies to enable the future deployment of commercial cognitive radio networks and new emerging applications. The findings of this project will be disseminated through journal and conference publications. The developed hardware and software tools will be made available to the research community at large as well. The project integrates research and education with the intent of training undergraduate students. It also outreaches to high school students in the local area.","title":"EAGER: A Social and Context Aware Spectrum Management Framework for Heterogeneous Cognitive Radio Networks","awardID":"1352726","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[563291],"PO":["557315"]},"205771":{"abstract":"The premise of this research project is: i) the rigid hierarchical structure of scalable coders represents a critical flaw that poses an existential threat to their practical deployment, despite compelling demand for such technology with the proliferation of heterogeneous networks and diverse device capabilities; ii) eliminating this shortcoming requires reconsideration of the problem at its most fundamental level, from information theoretic principles involving common information. The root cause is that real data sources are virtually never successively refinable -- the information required to achieve coarse quality reconstruction is not a proper subset of the information required for higher quality reconstruction. Hence, optimality necessitates splitting the information into what is common to different layers, and what is \"private\" to each layer. Research is pursued along several lines: derivation of a theoretical foundation for a common information framework for layered coding, analysis of asymptotic and finite delay performance gains, translation of theoretical insights into a practical framework of layered audio coding, extensions to sources with memory, and to scalability involving sampling resolution, multi-channel audio, and multi-view video.<br\/><br\/>The research focus is on eliminating the underlying cause for suboptimality of scalable multimedia coders. Ramifications of this limitation are exemplified by the industry's business decision to avoid existing scalable coders and default to the wasteful (in storage and network resources) alternative of redundant, independent encoding at various quality levels. Thus, beside fundamental contributions to information theory, successful elimination of this shortcoming would significantly impact the efficacy of multimedia storage and networking, and thereby the broader sector of related high-tech industries including multimedia content delivery, wireless communications, and the critical effort to satisfy the rapidly growing demand for network resources.","title":"CIF: Small: The Common Information Framework and Optimal Coding for Layered Storage and Transmission of Audio Signals","awardID":"1320599","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":[550914],"PO":["564924"]},"206761":{"abstract":"Reliable operation of cyber-physical systems (CPS) of societal importance such as Smart Electric Grids is critical for the seamless functioning of a vibrant economy. Sustained power outages can lead to major disruptions over large areas costing millions of dollars. Efficient computational techniques and tools that curtail such systematic failures by performing fault diagnosis and prognostics are therefore necessary. The Smart Electric Grid is a CPS: it consists of networks of physical components (including generation, transmission, and distribution facilities) interfaced with cyber components (such as intelligent sensors, communication networks, and control software). This grant provides funding to develop new methods to build models for the smart grid representing the failure dependencies in the physical and cyber components. The models will be used to build an integrated system-wide solution for diagnosing faults and predicting future failure propagations that can account for existing protection mechanisms. The original contribution of this work will be in the integrated modeling of failures on multiple levels in a large distributed cyber-physical system and the development of novel, hierarchical, robust, online algorithms for diagnostics and prognostics. <br\/><br\/>If successful, the model-based fault diagnostics and prognostics techniques will improve the effectiveness of isolating failures in large systems by identifying impending failure propagations and determining the time to critical failures that will increase system reliability and reduce the losses accrued due to failures. This work will bridge the gap between fault management approaches used in computer science and power engineering that are needed as the grid becomes smarter, more complex, and more data intensive. Outcomes of this project will include modeling and run-time software prototypes, research publications, and experimental results in collaborations with industry partners that will be made available to the scientific community.","title":"CPS: Synergy: Collaborative Research: Diagnostics and Prognostics Using Temporal Causal Models for Cyber Physical Systems- A Case of Smart Electric Grid","awardID":"1329800","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[553598],"PO":["564949"]},"206651":{"abstract":"Motivated by the complementary abilities of humans and humanoids, the objective of this proposal is to develop the science and technology necessary for realizing human-robot cooperative object manipulation and transportation. The key concepts that this research seeks to promote are adaptability to human activity under minimal communication, and robustness to variability and uncertainty in the environment, achieved through a layered representation and deliberate processing of the available information. Moreover, this project aims to make maximum use of a minimal set of sensors to plan and control the actions of the robot, while ensuring safe and efficient cooperative transportation. The embodiment of this research is a humanoid co-worker that bears most of the load, when helping a person to carry an object, without requiring excessive communication, or prior training on the part of the human.<br\/><br\/>By introducing concrete methods for human-robot physical collaboration in semi-structured environments, this project enables a unique synergy between robots and humans that has the potential to increase productivity, and reduce accidents and injuries. In doing so, it also promotes the advancement of new practical applications of robots in construction, manufacturing, logistics, and home services. By developing open-source, portable algorithms for humanoid robots and mobile manipulators, this effort results in cost and time savings for researchers, developers, educators, and end-users in robotics. Finally, through an aggressive educational and community outreach plan, and by actively engaging K-12 students in an exciting RoboTech Fellows program, this project seeks to increase diversity and attract underrepresented groups to STEM.","title":"NRI: Large: Collaborative Research: Human-robot Coordinated Manipulation and Transportation of Large Objects","awardID":"1328722","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":[553283,"553429"],"PO":["564316"]},"206772":{"abstract":"The electric power grid is a complex cyber-physical system, whose reliable and secure operation is of paramount importance to national security and economic vitality. There is a growing and evolving threat of cyber-based attacks, both in numbers and sophistication, on the nation's critical infrastructure. Therefore, cyber security \"encompassing attack prevention, detection, mitigation, and resilience\" is critical in today's power grid and the emerging smart grid. The goal of this project is to develop a unified system-theoretic framework and analytical tools for cyber-physical security of power systems, capturing the dynamics of the physical system as well as that of the cyber system. Research tasks include: 1) Development of a methodology for impact analysis that includes systematic identification of worst-case stealthy attacks on the power system's wide-area control and evaluating the resulting consequences in terms of stability violations and performance loss. 2) Development of robust cyber-physical countermeasures, employing a combination of methods from system theory, cyber security, and model-based\/data-driven tools, in the form of domain-specific anomaly detection\/tolerance algorithms and attack-resilient control algorithms. 3) Evaluating the effectiveness of the proposed impact modeling and mitigation algorithms through a combination of simulation and testbed-based evaluations, using realistic system topologies and attack scenarios. The project makes significant contributions to enhance the security and resiliency of the power grid and lays a scientific foundation for cyber-physical security of critical infrastructure. Also, the project develops novel curriculum modules, mentors graduate and undergraduate students including under-represented minorities, leverages industrial collaborations, and exposes high school students to cyber security concepts.","title":"CPS: Synergy: Collaborative Research: A Unified System Theoretic Framework for Cyber Attack-Resilient Power Grid","awardID":"1329885","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[553629],"PO":["565239"]},"205441":{"abstract":"Third-party hardware Intellectual Property (IP), written as code in a Hardware Description Language (HDL), is extensively used in modern integrated circuits. Contemporary electronics typically include 75% of third party hardware IP and only 25% in-house design to provide customization or a profit-making edge. Such extensive use of third-party hardware IP in both commercial and military applications raises security and trustworthiness concerns, especially in today's globalized market. Malicious modifications to a module's HDL code may introduce vulnerabilities, jeopardizing the security of the larger system within which it is integrated. So how does one protect electronics from the threat of potentially tampered with third-party hardware IP? To this end, this project is developing a framework for facilitating acquisition of provably trustworthy microprocessor cores. Drawing concepts from software proof-carrying code (PCC), security-related properties are codified in a temporal logic to outline the boundaries of trusted operation. In the case of microprocessor cores, these security properties ensure that the microprocessor instruction set architecture (ISA) does not introduce malicious architectural state changes, thereby preventing attackers from using a programming interface to exploit maliciously introduced hardware modifications. A formal proof of these security properties is then crafted by the vendor and presented to the consumer, who can automatically check correctness and validate compliance to the security properties. An ecosystem for developing provably trustworthy microprocessor cores, including a foundations framework, libraries, software tools, and demonstrations, as well as an educational module on Trusted Integrated Circuits and Systems are being developed as part of this project.","title":"TWC: Small: Collaborative: Toward Trusted Third-Party Microprocessor Cores: A Proof Carrying Code Approach","awardID":"1318860","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[550120],"PO":["564223"]},"205562":{"abstract":"High-end embedded systems are turning to multicore architectures to meet the performance, and performance\/Watt, demands required for their applications. Moreover, as the demand for more compute-intensive capabilities for embedded systems increases, these multicore architectures will evolve into many-core systems for improved performance or performance\/area\/Watt. These systems are often organized as cluster-based Non-Uniform Memory Access (NUMA) architectures that provide the programmer with a shared-memory abstraction. That is, simple cores are grouped into clusters sharing local interconnection and memory and these clusters are then replicated and interconnected using a scalable network-on-chip medium. This project investigates one of the principal challenges presented by these emerging NUMA architectures for embedded systems: providing efficient, energy-effective, and convenient mechanisms for synchronization and communication. In particular, it proposes new solutions based on hardware support for speculative synchronization, and software support to make such speculation transparent. Important metrics for measuring the effectiveness of the solutions include throughput, ease of use, system energy consumption, and architectural simplicity.<br\/><br\/>Embedded systems are becoming ubiquitous over a broad range of applications, including smart phones, automotive systems, security, and other ambient intelligence systems. Increasing computational demands have led to more sophisticated products and therefore increased challenges in meeting tight design constraints, particularly throughput\/Watt. Improvements to the way these systems communicate and synchronize data can have a substantial impact in terms of improved functionality, utility, and durability. The project is an international collaboration that combines PI expertise in Network-on-Chip architectures, embedded system design, and memory synchronization. Broader impacts of the proposal include new course development, outreach to graduate and undergraduate women and under-represented minorities, and student exchanges between international institutions.","title":"CSR: Small: Collaborative Research: Transparent and Energy-Efficient Speculation on NUMA Architectures for Embedded Multiprocessor Systems","awardID":"1319495","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[550431],"PO":["565319"]},"205210":{"abstract":"The human vision system understands and interprets complex scenes for a wide range of visual tasks in real-time while consuming less than 20 Watts of power. This Expeditions-in-Computing project explores holistic design of machine vision systems that have the potential to approach and eventually exceed the capabilities of human vision systems. This will enable the next generation of machine vision systems to not only record images but also understand visual content. Such smart machine vision systems will have a multi-faceted impact on society, including visual aids for visually impaired persons, driver assistance for reducing automotive accidents, and augmented reality for enhanced shopping, travel, and safety. The transformative nature of the research will inspire and train a new generation of students in inter-disciplinary work that spans neuroscience, computing and engineering discipline.<br\/><br\/>While several machine vision systems today can each successfully perform one or a few human tasks ? such as detecting human faces in point-and-shoot cameras ? they are still limited in their ability to perform a wide range of visual tasks, to operate in complex, cluttered environments, and to provide reasoning for their decisions. In contrast, the mammalian visual cortex excels in a broad variety of goal-oriented cognitive tasks, and is at least three orders of magnitude more energy efficient than customized state-of-the-art machine vision systems. The proposed research envisions a holistic design of a machine vision system that will approach the cognitive abilities of the human cortex, by developing a comprehensive solution consisting of vision algorithms, hardware design, human-machine interfaces, and information storage. The project aims to understand the fundamental mechanisms used in the visual cortex to enable the design of new vision algorithms and hardware fabrics that can improve power, speed, flexibility, and recognition accuracies relative to existing machine vision systems. Towards this goal, the project proposes an ambitious inter-disciplinary research agenda that will (i) understand goal-directed visual attention mechanisms in the brain to design task-driven vision algorithms; (ii) develop vision theory and algorithms that scale in performance with increasing complexity of a scene; (iii) integrate complementary approaches in biological and machine vision techniques; (iv) develop a new-genre of computing architectures inspired by advances in both the understanding of the visual cortex and the emergence of electronic devices; and (v) design human-computer interfaces that will effectively assist end-users while preserving privacy and maximizing utility. These advances will allow us to replace current-day cameras with cognitive visual systems that more intelligently analyze and understand complex scenes, and dynamically interact with users.<br\/><br\/>Machine vision systems that understand and interact with their environment in ways similar to humans will enable new transformative applications. The project will develop experimental platforms to: (1) assist visually impaired people; (2) enhance driver attention; and (3) augment reality to provide enhanced experience for retail shopping or a vacation visit, and enhanced safety for critical public infrastructure. This project will result in education and research artifacts that will be disseminated widely through a web portal and via online lecture delivery. The resulting artifacts and prototypes will enhance successful ongoing outreach programs to under-represented minorities and the general public, such as museum exhibits, science fairs, and a summer camp aimed at K-12 students. It will also spur similar new outreach efforts at other partner locations. The project will help identify and develop course material and projects directed at instilling interest in computing fields for students in four-year colleges. Partnerships with two Hispanic serving institutes, industry, national labs and international projects are also planned.","title":"Collaborative Research: Visual Cortex on Silicon","awardID":"1317433","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[549488],"PO":["565227"]},"206794":{"abstract":"This project focuses on the problem of information acquisition, state estimation and control in the context of cyber physical systems. In our underlying model, a (set of) decision maker(s), by controlling a sequence of actions with uncertain outcomes, dynamically refines the belief about stochastically time-varying parameters of interest. These parameters are then used to control the physical system efficiently and robustly. Here the cyber system collects, processes, and acquires information about the underlying physical system of interest, which is used for its control. The proposed work will develop a new theoretical framework for stochastic learning, decision-making, and control in stochastically-varying cyber physical systems. <br\/><br\/>In order to obtain analytical insights into the structure of efficient design, we first consider the case where the actions of the cyber system only affect the estimate of the underlying physical system. This class of problems arises in the context of (distributed) sensing\/tracking of a physical system in isolation from cyber system control of the physical system's state. Joint state estimation and control for cyber-physical systems will then be considered. Here the most natural first step is to obtain sufficient conditions and\/or special classes of systems where a separated approach to the information acquisition and efficient control is (near) optimal. To demonstrate its utility in practice, our theoretical framework will be applied in the specific context of energy efficient control of data centers and robust control of the smart grid under limited sensing.<br\/><br\/>The intellectual merit of this work will be to develop a theoretical framework for the design of cyber-physical systems including information acquisition, state estimation, and control. In addition, separation theorems for the optimality of separate state estimation and control will be explored.<br\/><br\/>In terms of broader impacts, significant performance improvement of control systems closed over communication networks will impact a wide range of applications for societal benefit, including smart buildings, intelligent transportation systems, energy-efficient data centers, and the future smart-grid. The PIs plan to disseminate the research results widely through conferences and journals, as well as by organizing specialized workshops and conference sessions related to cyber physical systems. The proposed project will train Ph.D. students as well as enrich the curriculum taught by the PIs in communications, stochastic control, and networks. The PIs have a strong track record in diversity and outreach activities, which for this project will include exposure and involvement of high school and undergraduate students, including under-represented minorities and women.","title":"CPS: Synergy: Collaborative Research: Event-Based Information Acquisition, Learning, and Control in High-Dimensional Cyber-Physical Systems","awardID":"1330081","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[553691],"PO":["564728"]},"204132":{"abstract":"Human speech and animal communication require both the extraction of meaning from sound and the processing of one's own voice to guide the production of these vocalizations. These processes require non-trivial computations that have challenged linguists and engineers but that are performed effortlessly by our brains. To understand what are the neural computations performed to decode the behavioral meaning and vocal gestures of communication signals, this study will examine how the auditory cortex of a songbird processes the complete vocal repertoire of its own species. <br\/><br\/>The Theunissen Lab acquired a unique database of all the vocalizations emitted by adult and juvenile, and both male and female zebra finches. This database contains the complete repertoire with multiple exemplars of each vocalization type for many individuals. Because the behavioral context of each communication sound was carefully recorded, these sounds are classified in meaning categories. This database will thus enable the detailed investigation of how the auditory system extract meaning from vocalizations, while controlling for variability of production within vocalization type as well as between individuals.<br\/><br\/>The approach of this project consists in obtaining neural responses to these communication sounds using advanced neurophysiological recording techniques, and then investigating the neural computations by finding the statistics models that best predict these responses. Multi-electrode arrays will be used to record the simultaneous neural activity of large sets of single neurons in the primary and secondary auditory areas. The response of these neurons will then be fitted using statistical models that incorporate increasing levels of abstraction: from elementary sound features, to vocal gestures and semantic labels. The representation in terms of vocal gestures will be obtained from a reduced physical model of the avian vocal organ. This analysis will not only point out the brain regions that are involved in semantic processing but also the nature of the hierarchical computations that lead to these higher-level representations. The research will also investigate the link between perception and production by directly assessing the role of a motor-based representation of sounds in high-level auditory areas. <br\/><br\/>By combining ethological, neurophysiological and computational studies of acoustic communication in a songbird, the project will establish an appropriate animal model system to elucidate how the auditory cortex extracts and categorizes sound features in order to link sound to meaning. Given the similarities in the anatomy and physiology of the auditory system across vertebrates and the common signal processing problems shared in all vocal communications, this study can also contribute significantly to the neurophysiological understanding of neural mechanisms underlying speech perception. <br\/><br\/>This award is being co-funded by NSF's Office of the Director, International Science and Engineering. A companion project is being funded by the French National Research Agency (ANR).","title":"US-French Collaboration: Auditory computations for interpreting and producing communication signals.","awardID":"1311446","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":[546744],"PO":["564318"]},"208983":{"abstract":"Stanford University proposes to develop and evaluate a proof-of-concept online middle school course (with a teacher version as well) that adapts concepts from the Exploring Computer Science (ECS) curriculum, specifically algorithmic thinking and introductory programming. The project will: <br\/>(1) Design and deploy an online six-week \"Foundations for Advancing Computational Thinking\" (FACT) curriculum on Stanford University's instance of the open edX online platform. Aimed at 12 to 15 year-old learners, the curriculum borrows from the ECS Programming and Problem Solving units. It will be driven by short video lessons with in-video and stand-alone quizzes for formative and summative assessments, and programming activities.<br\/>(2) Pilot FACT in a Bay Area public middle school class.<br\/>(3) Empirically examine the efficacy of: (a) the curriculum for the development of computational competencies, preparation for future learning of computing, and changes in student perceptions of CS via assessments designed for these purposes, and (b) student attitudes towards and experiences with online learning, including online course features such as in-video quizzes and discussion forums.<br\/>(4) Create and pilot an appropriately enhanced version of the curriculum for teachers to effectively prepare them to facilitate FACT\/ECS use in their classrooms.","title":"EAGER: Foundations for Advancing Computational Thinking (FACT): Learning and Assessment through an Online Middle School Curriculum","awardID":"1343227","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7645","name":"DISCOVERY RESEARCH K-12"}}],"PIcoPI":["351237",560145],"PO":["560704"]},"205496":{"abstract":"Third-party hardware Intellectual Property (IP), written as code in a Hardware Description Language (HDL), is extensively used in modern integrated circuits. Contemporary electronics typically include 75% of third party hardware IP and only 25% in-house design to provide customization or a profit-making edge. Such extensive use of third-party hardware IP in both commercial and military applications raises security and trustworthiness concerns, especially in today's globalized market. Malicious modifications to a module's HDL code may introduce vulnerabilities, jeopardizing the security of the larger system within which it is integrated. So how does one protect electronics from the threat of potentially tampered with third-party hardware IP? To this end, this project is developing a framework for facilitating acquisition of provably trustworthy microprocessor cores. Drawing concepts from software proof-carrying code (PCC), security-related properties are codified in a temporal logic to outline the boundaries of trusted operation. In the case of microprocessor cores, these security properties ensure that the microprocessor instruction set architecture (ISA) does not introduce malicious architectural state changes, thereby preventing attackers from using a programming interface to exploit maliciously introduced hardware modifications. A formal proof of these security properties is then crafted by the vendor and presented to the consumer, who can automatically check correctness and validate compliance to the security properties. An ecosystem for developing provably trustworthy microprocessor cores, including a foundations framework, libraries, software tools, and demonstrations, as well as an educational module on Trusted Integrated Circuits and Systems are being developed as part of this project.","title":"TWC: Small: Collaborative: Toward Trusted Third-Party Microprocessor Cores: A Proof Carrying Code Approach","awardID":"1319105","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[550260],"PO":["564223"]},"206112":{"abstract":"From Wikipedia to Linux to scientific and business work-groups all over the world, both online and off-line groups are becoming a pervasive part of modern life. It is becoming increasingly important, therefore, to understand how to improve the performance of these groups. The work proposed here will use a new measure of generalized group effectiveness -- called \"collective intelligence\" -- to help do this. <br\/><br\/>Building on previous work by the investigators, the project will first develop an online test for collective intelligence. Then it will compare the results of online and face-to-face groups taking this new test with previous results for groups taking an offline version of the test. This will help clarify the degree to which online and off-line groups differ in their general effectiveness on a wide range of different tasks. Next the project will use this test to systematically measure the collective intelligence of online groups that range in size from 2 to 20 people. This will lay the foundation for exploring whether larger online groups can take advantage of the increased resources that more people bring, without suffering as much from the process losses that usually accompany increased group size in face-to-face groups. Finally, the project will systematically measure the collective intelligence of online groups with varying proportions of women. In doing so, the project will also test one particularly promising explanation for a gender effect on group performance: that groups with more women are less interpersonally competitive, and that this lower intra-group competitiveness leads to higher collective intelligence. <br\/><br\/>While there have been decades of research on factors that affect the performance of groups, almost all these studies have each focused on a single task. Thus, strictly speaking, the lessons to be learned from this previous work are limited to the specific tasks studied. The work proposed here uses the perspective of collective intelligence to investigate, not just the ability of a group to perform a single task, but the group?s general ability to perform a wide range of tasks. Since many real-world groups must cope with a wide range of problems, just such a perspective may be needed to systematically predict their performance. In addition, the approach developed here can provide a significant economy of effort in evaluating potential ways of improving online group effectiveness. Instead of testing interventions on many different specific tasks, researchers will be able to test the interventions once with this general measure, and then have some basis for predicting the effects of the intervention on many other tasks. By making an online test of collective intelligence available to other researchers, the project will help advance scientific practice in this area. More generally, by providing a firmer scientific foundation for measuring and improving the performance of groups, the project may help our society address many of its most important problems more effectively. For instance, with the right kinds of collaboration tools, online groups may be able to be much more effective than face-to-face groups, taking advantage of the simultaneous efforts of far more people without the coordination losses that usually occur in larger groups. And understanding the dynamics of gender diversity may help us to improve the collaboration of the groups in which both men and women work, by giving everyone?s best ideas a better chance to be heard. And perhaps, someday, this will help create groups that are more collectively intelligent than any groups have ever been before.","title":"VOSS: Collaborative Research: Is Larger Smarter? Investigating the Effect of Group Size on Collective Intelligence","awardID":"1322241","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"8031","name":"Science of Organizations"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[551787],"PO":["565272"]},"206475":{"abstract":"IEEE 802.11 is an evolving standard used throughout the Internet. Recent advances in wireless communication have been incorporated into IEEE 802.11-based standards. IEEE 802.11n and 802.11ac, for example, offer new mechanisms that enable a multifold increase in transmission speeds relative to 802.11a\/b\/g. Newly available features make configuring a network, and the devices which use it, a critical challenge. The performance of even the most sophisticated networks suffer debilitating degradation if the network is improperly configured. This project is focused on the following questions: 1) What gains can be achieved by closed-loop 802.11n\/ac rate adaptation solutions? 2) How can IEEE 802.11 features better be utilized in a rate adaptation solution? 3) How responsive and adaptive should a real-time channel monitoring solution be? and 4) How can the cost of expensive Channel State Information be minimized? By designing new network configuration mechanisms and observing the performance of these mechanisms in a wide variety of real-world deployment scenarios, wireless network performance and robustness are being improved.<br\/><br\/>As the scale of wireless network deployments grows, the need for effective network configuration mechanisms is critical. The work in this project is developing highly flexible protocol enhancements that are adding significant new performance and robustness capabilities to wireless networks running the newest IEEE 802.11 standards. Through scientific publications, conference presentations, and industrial collaborations, the outcomes of this project will be made available to wireless equipment vendors, thereby achieving tangible improvements in Internet performance.","title":"GOALI: Maximizing Available Bandwidth in Next Generation WLANs","awardID":"1324729","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[552796,"560332",552798],"PO":["557315"]},"209863":{"abstract":"Cities are the crucibles of civilization, and accelerating global urbanization raises challenges and opportunities related to density and scale in areas including transportation; food production and distribution; human health and wellbeing; education; social policy and services; and management of water and energy. Seeking to understand the human, social, and economic to help develop effective education or public policy scientists, and thus city officials, have traditionally been limited to qualitative studies or to using sparse, often stale data sources. The open data movement is making an increasingly rich set of urban data available, but the cyber infrastructure technologies and tools used to make this data available were designed primarily to support the analysis of individual data sets rather than exploring relationships among many data sets. Consequently, urban scientists from sociology, economics, behavioral sciences, education, engineering, operations research, and other disciplines lack the tools and infrastructure to fully harness urban data for their research. The questions these researchers ask are therefore constrained by the data they have in hand. Two new cyber infrastructure capabilities have potential to unleash these data sources, both exploiting the fact that most of the published urban data sets share the attributes of location and time. The first is to allow a scientist to assemble data from multiple, independent, data sources for a specific geographical location point (latitude\/longitude), city unit (street segment, census tract, block), or area (polygon). The second is to select a window of time and to normalize the selected data sources using a common sampling interval, merging them into a composite structure for computational and statistical analysis. Taken together, these capabilities will allow a scientist to study urban areas, over specific time periods, with varied, relevant data represented as a time series of vectors. We propose to develop, in partnership with urban scientists and City officials initially from Chicago and eventually from New York City, a proof-of-concept with these capabilities.<br\/><br\/>The prototype will draw data from open data portals, allowing a researcher to specify a location, a window of time, a sampling period, and a list of data sets. The system will provide a matrix with one row per time sample and columns representing each data set. By merging and transforming urban data into matrices we will enable urban scientists to apply the tools of mathematics and computation to understand urban challenges ranging from youth violence and crime to graduate rates to employment and economic decline and revitalization.","title":"EAGER: Prototyping an Urban Data Cyberinfrastructure for Computational Social Sciences","awardID":"1348865","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[562593],"PO":["565292"]},"205199":{"abstract":"The human vision system understands and interprets complex scenes for a wide range of visual tasks in real-time while consuming less than 20 Watts of power. This Expeditions-in-Computing project explores holistic design of machine vision systems that have the potential to approach and eventually exceed the capabilities of human vision systems. This will enable the next generation of machine vision systems to not only record images but also understand visual content. Such smart machine vision systems will have a multi-faceted impact on society, including visual aids for visually impaired persons, driver assistance for reducing automotive accidents, and augmented reality for enhanced shopping, travel, and safety. The transformative nature of the research will inspire and train a new generation of students in inter-disciplinary work that spans neuroscience, computing and engineering discipline.<br\/><br\/>While several machine vision systems today can each successfully perform one or a few human tasks ? such as detecting human faces in point-and-shoot cameras ? they are still limited in their ability to perform a wide range of visual tasks, to operate in complex, cluttered environments, and to provide reasoning for their decisions. In contrast, the mammalian visual cortex excels in a broad variety of goal-oriented cognitive tasks, and is at least three orders of magnitude more energy efficient than customized state-of-the-art machine vision systems. The proposed research envisions a holistic design of a machine vision system that will approach the cognitive abilities of the human cortex, by developing a comprehensive solution consisting of vision algorithms, hardware design, human-machine interfaces, and information storage. The project aims to understand the fundamental mechanisms used in the visual cortex to enable the design of new vision algorithms and hardware fabrics that can improve power, speed, flexibility, and recognition accuracies relative to existing machine vision systems. Towards this goal, the project proposes an ambitious inter-disciplinary research agenda that will (i) understand goal-directed visual attention mechanisms in the brain to design task-driven vision algorithms; (ii) develop vision theory and algorithms that scale in performance with increasing complexity of a scene; (iii) integrate complementary approaches in biological and machine vision techniques; (iv) develop a new-genre of computing architectures inspired by advances in both the understanding of the visual cortex and the emergence of electronic devices; and (v) design human-computer interfaces that will effectively assist end-users while preserving privacy and maximizing utility. These advances will allow us to replace current-day cameras with cognitive visual systems that more intelligently analyze and understand complex scenes, and dynamically interact with users.<br\/><br\/>Machine vision systems that understand and interact with their environment in ways similar to humans will enable new transformative applications. The project will develop experimental platforms to: (1) assist visually impaired people; (2) enhance driver attention; and (3) augment reality to provide enhanced experience for retail shopping or a vacation visit, and enhanced safety for critical public infrastructure. This project will result in education and research artifacts that will be disseminated widely through a web portal and via online lecture delivery. The resulting artifacts and prototypes will enhance successful ongoing outreach programs to under-represented minorities and the general public, such as museum exhibits, science fairs, and a summer camp aimed at K-12 students. It will also spur similar new outreach efforts at other partner locations. The project will help identify and develop course material and projects directed at instilling interest in computing fields for students in four-year colleges. Partnerships with two Hispanic serving institutes, industry, national labs and international projects are also planned.","title":"Collaborative Research: Visual Cortex on Silicon","awardID":"1317373","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[549458,"560649"],"PO":["565227"]},"209313":{"abstract":"Research Experiences for Undergraduates (REUs) are critically important in maintaining a healthy pipeline of domestic graduate students in computer science and related fields. These early research experiences are often formative for their participants, giving them both an understanding of the research enterprise and the confidence required to consider a research career. In addition, REUs provide valuable skills and long-term mentoring relationships that are likely to contribute to personal satisfaction and success in graduate school. The current demand for REU opportunities exceeds the supply. The goal of this proposal is to increase the supply of REU opportunities by offering encouragement, resources, and support to research-active faculty members. This award will fund four short workshops on undergraduate research at major research conferences over the next two years. The conferences will be chosen to represent a broad cross section of areas covered by the CISE Directorate.","title":"Workshops to Engage Junior Faculty in Undergraduate Research","awardID":"1345291","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":[561152,"209556",561154],"PO":["564588"]},"208345":{"abstract":"Illinois State University (ISU) proposes a project -- Teacher Education in Computer Science (TECS) -- which will create an innovative structure for preparing in-service and future high school teachers to teach Computer Science (CS). Although the Illinois State Board of Education (ISBE) has established standards for a CS Endorsement, currently there are no CS Teacher Education programs in the state. This project will create a state-approved program of study at ISU so that upon its completion, teaches will be well-positioned to pass the certification exam for the CS Endorsement. The TECS curriculum will mesh with existing ISU Mathematics and Technology teacher education major requirements, so that student teachers and in-service teachers in those fields can efficiently obtain the CS endorsement, making TECS graduates highly employable. The TECS program will recruit in-service math and technology teachers from school districts in 50-mile radius of ISU, as well as ISU students from Mathematics Teacher Education (MTE) and Technology & Engineering Education (T&EE). The TECS curriculum will be created by an interdisciplinary team of ISU faculty, out of existing courses from CS, Mathematics, and Technology, with advice from the NSF-funded \"Taste of Computing\" team in Chicago. UCLA's Gail Chapman will provide a design for a new CS teaching methods course to be added to existing courses, to be piloted in cooperation with the Taste of Computing institutions. Faculty and student learning communities will be formed to foster an academic, social, and cultural environment to successfully implement the TECS program. The project will utilize advanced CS majors for peer-tutoring and mentoring TECS students. Scholarships will be provided as needed for pre-service and in-service teachers in TECS. Especially for in-service teachers, TECS will offer evening, summer, or online classes. Continual multi-faceted evaluation of learning outcomes and program operation will include competency-based tests and attitude measures for TECS participants, and feedback forms for participating faculty, peer-tutors and mentors, professionals, and student teaching supervisors. The project will host statewide annual summits for relevant educators, industry representatives, and state officials to raise awareness and promote quality CS education in Illinois schools. The ISU administration, MTE and T&EE Directors, and district administrators of surrounding school districts (like Bloomington, Dunlap, and Peoria) and Chicago Public Schools are highly supportive of the TECS program.","title":"Illinois State University (ISU) Initiates Teacher Education in Computer Science (TECS)","awardID":"1339356","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[558330,558331],"PO":["561855"]},"207047":{"abstract":"The International Symposium on Bioinformatics Research and Applications (ISBRA) is in its 9th year. This year's meeting will be held at the University of North Carolina at Charlotte, an emerging research university that has invested substantially in the development of research and educational programs in Bioinformatics since 2004. The International Symposium on Bioinformatics Research and Applications (ISBRA) will contribute to the rapid dissemination of latest research results and to foster the formation of collaborations between researchers with the multidisciplinary expertise required to analyze the enormous datasets accumulated in modern biological research. The conference content will encompass diverse topics from comparative and functional genomics, to systems biology, to population biology and genetics. ISBRA will provide important formative experiences to graduate students and post-doctoral scholars, helping them to become future leaders in the field. In 2013, when other popular bioinformatics conferences are being held outside the US, ISBRA will provide a valuable opportunity for resource-limited U.S.-based students and PIs to present research and interact with colleagues.","title":"Travel Support: 9th International Symposium on Bioinformatics Research and Applications","awardID":"1331534","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[554355,554356],"PO":["565136"]},"208026":{"abstract":"Proposal #: 13-38118 Collaborative Proposal #: 13-37866 <br\/>PI(s): Makedon, Fillia S collaboration with PI(s): Betke, Margrit <br\/>Athitsos, Vassilis; Gatchel, Robert J; Huang, Heng; Romero-Ortega, Mario I <br\/>Institution: University of Texas-Arlington collaboration with Institution: Boston Univeristy <br\/>Title: MRI\/Dev :Collab Dev. of iRehab, an Intelligent Closed-loop Instrument for Adaptive Rehabilitation <br\/>Project Proposed: <br\/>This project, developing of an instrument referred to as iRehab, aims to enable personalized rehabilitation therapy for individuals suffering from brain injury, motor disabilities, cognitive impairments, and\/or psychosocial symptoms. The instrument, a modular rehabilitation device, in its simplest form consists of a computer, a camera, and adaptive software for assessment and training of cognitive functions. In its final, most complex form, the instrument will integrate data from a 4-degree-of-freedom robotic-arm with gimbals and torque sensing, a Kinect sensor, multiple cameras, an eye-tracking device, a touch screen, a microphone, and an fNIRS brain imaging sensor. <br\/>The instrument will be developed in two phases. In the first phase, the investigators develop a Barrett robot arm. In the second phase, the instrument will extend to a Kinect sensor, multiple cameras, an eye-tracking device, and related low-cost components, along with the assessment software for assessing motor function and cognitive, emotional, and personality functioning. <br\/>iRehab consists integrates multidisciplinary methodologies and sensors to assess and assist the cognitive and physical rehabilitation of persons affected by various impairments. This work highly interdisciplinary work follows a cyber-physical approach. It provides new research opportunities across the fields of human-centered computing, computer vision, assistive technology, robotics, machine learning, and neuroimaging. This work advances research in human brain activity mapping, personalized medicine, and big data. <br\/>Broader Impacts: <br\/>The proposed instrument exhibits potential for large broader impact as it directly contributes to future healthcare and human wellbeing improving accessibility to affordable rehabilitation for a broad range of patients. The instrument is likely to accelerate the recovery of a large spectrum of injuries and diseases including those causing motor, neurological, and cognitive disorders. An education plan includes course development, internships, workshops and tutorials, and an on-line resource center. In addition to many educational impacts, impact will be felt on the fundamental research in the areas addressed.","title":"MRI Collaborative: Development of iRehab, an Intelligent Closed-Loop Instrument for Adaptive Rehabilitation","awardID":"1337866","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[557296],"PO":["557609"]},"209258":{"abstract":"Many health conditions are caused by unhealthy lifestyles and can be improved by behavior change. Traditional behavior-change methods (e.g., weight-loss clinics; personal trainers) have bottlenecks in providing expert personalized day-to-day support to large populations for long periods. There is a pressing need to extend the reach and intensity of existing successful health behavior change approaches in areas such as diet and fitness. Smartphone platforms provide an excellent opportunity for projecting maximally effective interventions for behavior change into everyday life at great economies of scale. Smartphones also provide an excellent opportunity for collecting rich, fine-grained data necessary for understanding and predicting behavior-change dynamics in people going about their everyday lives. The challenge posed by these opportunities for detailed measurement and intervention is that current theory is not equally fine-grained and predictive. <br\/><br\/>This interdisciplinary project investigates theory and methods to support fine-grained behavior-change modeling and intervention integrated via smartphone into the daily lives of individuals and groups. Fittle+ develops a new and transformative form of smartphone-delivered Ecological Momentary Intervention (EMI) for improving diet and physical activity. This approach will provide social support and autonomously planned and personalized coaching that builds on methods from mobile sensing, cognitive tutoring, and evidence-based social design. The foundation for this new approach will require new predictive computational theories of health behavior change. Current coarse-grained conceptual theories of individual health behavior change will be refined into fine-grained predictive computational models. These computational models will be capable of tracking moment-by-moment human context, activity, and social patterns based on mobile sensing and interaction data. Using these monitoring capabilities, Fittle+'s computational models will support assessment of, and predictions about, individual users and groups based on underlying motivational, cognitive, and social mechanisms. These predictive models will also be used to plan and optimize coaching actions including detailed diagnostics, individualized goals, and contextually and personally adapted interventions. <br\/><br\/>The collaborative team of researchers works with weight-loss interventionists at one of nation's largest health organization's facility in Hawaii. The team includes expertise in mobile sensing, artificial intelligence, computational cognition, social psychology, human computer interaction, computer tutoring, and measurement theory.","title":"SCH: INT: Collaborative Research: FITTLE+: Theory and Models for Smartphone Ecological Momentary Intervention","awardID":"1344768","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[560994,560995],"PO":["565136"]},"208059":{"abstract":"Proposal #: 13-38042<br\/>PI(s): Papanikolopoulos, Nikolaos<br\/> Banerjee, Arindam; Bernstein, Gail; Hadjiyanni, Tassoulla; Lim, Kelvin, K.<br\/>Institution: University of Minnesota-Twin Cities<br\/>Title: MRI\/Dev.: Instrument that Monitors Behaviors Associated with OCD and Schizophrenia <br\/>Project Proposed:<br\/>This project, developing a new instrument to facilitate data collection associated with clinical assessment of complex mental health disorders such as obsessive-compulsive behaviors (known as OCD), aims to enable long-term research advances in computer vision, activity recognition and tridimensional reconstruction algorithms to automate the identification of behaviors typical of OCD subjects. The immersion of selected subjects in a virtual reality room (CAVE) is used to trigger specific behaviors to be captured and analyzed. The sophisticated sensor system under development will serve to collect these data and provide intelligent data processing capabilities that would enable future exploration and testing of new diagnostic and therapeutic protocols, leading to the establishment of the basis for, and utility in, seeking early at-risk markers in children and adolescents. This instrument initiative is based on the premise that expertise can accurately identify useful diagnostic markers and on the belief that technologies can now be developed to collect massive behavioral data in ways not previously done and discover behavioral patterns.<br\/>The instrument is expected to<br\/>- Provide extensive data collection associated with subjects diagnosed with the respective disorders (data useful not only to clinicians but also to computer vision and machine learning researchers among others),<br\/>- Capture interactions, behaviors, and physiological reactions to real and\/or synthetic multimodal stimuli (optical, acoustical, etc.),<br\/>- Allow computer and information scientists to develop computational tools and algorithms to generate quantitative, adequate, and cost-effective norms for screening a broad population, <br\/>- Enhance Cognitive Behavior Therapy (CBT) procedures and diagnostic protocols by integration of technologies that can excite or inhibit triggers for schizophrenic or OCD episodes,<br\/>- Assess particular Augmented and Virtual Environments (AE\/VEs) and social media devices (smart phones and tablets) and their impacts on the cognitive presence of normal versus afflicted subjects, and<br\/>- Evaluate whether an enhanced cognitive presence via an AE\/VE can increase or suppress (habituate) the intensity of behavioral symptoms detectable by sensors. <br\/>Broader Impacts: Among these we have:<br\/>- Creation of large and complex datasets that will enable computer scientists to apply the newest computational tools on them,<br\/>Development of a potentially transformative technology-driven instrument for detecting early risk markers of OCD,<br\/>- Exploration of a platform well-suited to new directions for a better characterization of mental disorders,<br\/>- Systematic database development of quantified, multimodal data and a sounder and more precise basis for earlier detection,<br\/>- Reduction of overall costs and a parallelizing reduction in the long-term costs due to previously delayed or incorrect diagnoses,<br\/>- Reduction of anxiety, disruption, stress, and sometimes real tragedy on patients and their families, <br\/>- Earlier detection and reduced need for drug-based, later stage interventions enabled by the ease of testing, and associated societal benefits, and<br\/>- Student education and training in the use of the instrument.","title":"MRI: Development of an Instrument that Monitors Behaviors Associated with Obsessive-Compulsive Behaviors and Schizophrenia","awardID":"1338042","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"5761","name":"INDUSTRY\/UNIV COOP RES CENTERS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":[557449,557450,557451,557452,557453],"PO":["557609"]},"205870":{"abstract":"Optimizing compilers are asked to automatically achieve good performance over an increasingly larger and heterogeneous set of architectures. Complex high-level program transformations are required to address this problem, to map the proper grain of independent computation and the proper data locality to a complex hierarchy of memory, computing and interconnection resources. The polyhedral compilation framework is one of the most powerful and flexible loop transformation system, with numerous compelling results achieved in recent years in terms of automatic program optimization (CPUs, GPUs and FPGAs). But a difficult challenge remains the deployment of those research results to larger-scale programs. Indeed, this framework uses complex mathematical algorithms that are the reason for the better program performance achieved, but which are often too time consuming for production use.<br\/><br\/>The goal of this project is to significantly improve the scalability and effectiveness of polyhedral optimizations, through the design of exact optimization methods and their associated approximation heuristics for increased scalability. We will develop novel program transformation algorithms operating under hardware resources constraints, for a variety of devices currently available on heterogeneous computing systems: for multi-core CPUs using short-vector SIMD units; for FPGAs with the help of high-level synthesis tool-chain; and for GPUs. The proposed work has the potential to significantly enhance the effectiveness of optimizing compilers thereby reducing the manual performance tuning required, with significant cost savings. The developed tools will be made publicly and freely available to the research community.","title":"SHF:Small:Scalable Scheduling for Program Transformations in Heterogeneous Computing","awardID":"1321147","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":[551156,"558485"],"PO":["564588"]},"206740":{"abstract":"Reliable operation of cyber-physical systems (CPS) of societal importance such as Smart Electric Grids is critical for the seamless functioning of a vibrant economy. Sustained power outages can lead to major disruptions over large areas costing millions of dollars. Efficient computational techniques and tools that curtail such systematic failures by performing fault diagnosis and prognostics are therefore necessary. The Smart Electric Grid is a CPS: it consists of networks of physical components (including generation, transmission, and distribution facilities) interfaced with cyber components (such as intelligent sensors, communication networks, and control software). This grant provides funding to develop new methods to build models for the smart grid representing the failure dependencies in the physical and cyber components. The models will be used to build an integrated system-wide solution for diagnosing faults and predicting future failure propagations that can account for existing protection mechanisms. The original contribution of this work will be in the integrated modeling of failures on multiple levels in a large distributed cyber-physical system and the development of novel, hierarchical, robust, online algorithms for diagnostics and prognostics. <br\/><br\/>If successful, the model-based fault diagnostics and prognostics techniques will improve the effectiveness of isolating failures in large systems by identifying impending failure propagations and determining the time to critical failures that will increase system reliability and reduce the losses accrued due to failures. This work will bridge the gap between fault management approaches used in computer science and power engineering that are needed as the grid becomes smarter, more complex, and more data intensive. Outcomes of this project will include modeling and run-time software prototypes, research publications, and experimental results in collaborations with industry partners that will be made available to the scientific community.","title":"CPS: Synergy: Collaborative Research: Diagnostics and Prognostics Using Temporal Causal Models for Cyber Physical Systems- A Case of Smart Electric Grid","awardID":"1329666","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[553534,553535],"PO":["564949"]},"205651":{"abstract":"This project will develop a large-area dense-array tactile display device suitable for displaying a full-page of braille characters and tactile diagrams. This device will co-locate tactile input and output and will make interaction with text and graphic content on mobile devices as direct and meaningful for visually impaired users as touchscreen interaction is for sighted users. Current braille display technology can only render a single line of content at a time. This project will address this problem by developing new display technology based on microfluidic actuators and microfluidic logic circuits. This technology holds tremendous promise for creating refreshable tactile features on a flat screen, and for new multipurpose displays because the microfluidic substrate can be designed as a transparent overlay to a visual display. There are just a few technological barriers remaining until microfluidics is practical for creating programmable haptic features. One of these barriers is the \"piping problem\", packing a dense array of bubble actuators without an independent channel dedicated to each actuator. A second problem involves matching the microfluidic actuators to the properties and sensitivity of the fingertip skin through an appropriately engineered surface. The research team has piloted solutions to both of these problems and will construct analytical models that will enable these solutions to be scaled, both up and down, for rendering a variety of features from individually perceivable braille dots to perceptually continuous lines, curves and tactile forms. The design of the display technology will be guided and informed by a series of user evaluations that will advance the science of surface haptics while at the same time comparing this microfluidic approach to alternative assistive technologies currently under development in academia and industry. The collaborative team is uniquely qualified to develop microfluidics technology specifically for a braille display. Mark Burns will further develop microfluidic logic circuits and shift registers to individually address braille pin actuators. Brent Gillespie will optimize the mechanics of the actuators and braille dots and adapt them to the mechanics of the skin and actively guided touch. Sile O'Modhrain will develop the science of surface haptics to guide the match between microfluidic technology and application in human-computer interaction through braille. <br\/><br\/>Broader Impacts: The project will develop a full-page electronic braille device that will increase braille literacy among blind persons worldwide. At the same time, the project will solve the most pressing problems blocking the application of microfluidics in shape display and surface haptics on touchscreens. The availability of a large-area tactile display would open up the possibility for a wide range of scientific exploration and would also have a huge commercial impact because it would have a profound impact on what is fundamentally possible with touchscreen devices. The project will recruit and engage blind persons, under-represented minorities, women, and undergraduate researchers.","title":"HCC: Small: The Development and Evaluation of a Full-Page Refreshable Braille Display","awardID":"1319922","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[550635,550636,550637],"PO":["565362"]},"206751":{"abstract":"This project will result in fundamental physical and algorithmic building blocks of a novel cyber-physical for a two-way communication platform between handlers and working dogs designed to enable accurate training and control in open environments (eg, disaster response, emergency medical intervention).<br\/><br\/>Miniaturized sensor packages will be developed to enable non- or minimally-invasive monitoring of dogs' positions and physiology. Activity recognition algorithms will be developed to blend data from multiple sensors. The algorithms will dynamically determine position and behavior from time series of inertial and physiological measurements. Using contextual information about task performance, the algorithms will provide duty-cycling information to reduce sensor power consumption while increasing sensing specificity. The resulting technologies will be a platform for implementation of communication.<br\/><br\/>Strong interactions among computer science, electrical engineering, and veterinary science support this project. Work at the interface between electrical engineering and computer science will enable increased power efficiency and specificity of sensing in the detectors; work at the interface of electrical engineering and veterinary behavior will enable novel physiological sensing packages to be developed which measure behavioral signals in real time; Project outcomes will enable significant advances in how humans interact with both cyber and physical agents, including getting clearer pictures of behavior through real time physiological monitoring.<br\/><br\/>Students are part of the project and multidisciplinary training will help to provide development of the Cyber-Physical Systems pipeline. Project outreach efforts will include working with middle school children, especially women and under-represented minorities, presentations in public museums that will promote public engagement and appreciation of the contribution of cyber-physical systems to daily lives. The goal of each outreach activity is to encourage both interest and excitement for STEM topics, demonstrating how computer science and engineering can lead to effective and engaging cyber-physical systems.","title":"CPS: Synergy: Integrated Sensing and Control Algorithms for Computer-Assisted Training","awardID":"1329738","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[553567,553568,553569],"PO":["565136"]},"205420":{"abstract":"The future Cognitive Radio Networks (CRNs) will consist of heterogeneous devices such as smartphones, tablets and laptops moving dynamically. Accurate and robust spectrum sensing and identification of unauthorized spectrum usage are essential components of spectral efficiency in future radio systems. This project aims to utilize consensus-based cooperation featuring self-organizable and scalable network structure to capture the swarming behaviors of spectrum users and providing cooperative spectrum sensing in a fully distributed manner. By using a combination of control theory and machine learning techniques, the project designs secure weighted average consensus for cooperative spectrum sensing that can not only capture the swarming behaviors in CRNs with heterogeneous devices, but also is robust to practical channel conditions. Robust localization approaches are developed grounded on dynamic signal strength mapping, which have the capability to localize multiple malicious users. Additionally, the new techniques are validated using an actual testbed with on-campus deployment and system demonstration to industrial collaborators. The integration of control theory with dynamic spectrum access will enable a new revolution in the way for enhancing spectrum efficiency in CRNs. The project serves as a pioneer in exploiting multi-disciplinary knowledge (e.g., control systems and machine learning techniques) to achieve a more efficient spectrum usage in future radio systems, aiming to alleviate the increasing crowdness of the spectrum occupancy and support the co-existence of heterogeneous devices. This project also carries out a broad range of education and outreach activities to encourage students to pursue careers in the fields of science and engineering. Research results will be disseminated to academia and industry through presentations and publications in meetings, conferences and journals.","title":"NeTS: Small: Collaborative Research: Distributed Robust Spectrum Sensing and Sharing in Cognitive Radio Networks","awardID":"1318748","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["513898",550063],"PO":["557315"]},"206762":{"abstract":"Reliable operation of cyber-physical systems (CPS) of societal importance such as Smart Electric Grids is critical for the seamless functioning of a vibrant economy. Sustained power outages can lead to major disruptions over large areas costing millions of dollars. Efficient computational techniques and tools that curtail such systematic failures by performing fault diagnosis and prognostics are therefore necessary. The Smart Electric Grid is a CPS: it consists of networks of physical components (including generation, transmission, and distribution facilities) interfaced with cyber components (such as intelligent sensors, communication networks, and control software). This grant provides funding to develop new methods to build models for the smart grid representing the failure dependencies in the physical and cyber components. The models will be used to build an integrated system-wide solution for diagnosing faults and predicting future failure propagations that can account for existing protection mechanisms. The original contribution of this work will be in the integrated modeling of failures on multiple levels in a large distributed cyber-physical system and the development of novel, hierarchical, robust, online algorithms for diagnostics and prognostics.<br\/><br\/>If successful, the model-based fault diagnostics and prognostics techniques will improve the effectiveness of isolating failures in large systems by identifying impending failure propagations and determining the time to critical failures that will increase system reliability and reduce the losses accrued due to failures. This work will bridge the gap between fault management approaches used in computer science and power engineering that are needed as the grid becomes smarter, more complex, and more data intensive. Outcomes of this project will include modeling and run-time software prototypes, research publications, and experimental results in collaborations with industry partners that will be made available to the scientific community.","title":"CPS: Synergy: Collaborative Research: Diagnostics and Prognostics Using Temporal Causal Models for Cyber Physical Systems- A Case of Smart Electric Grid","awardID":"1329803","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[553600,553601],"PO":["564949"]},"205200":{"abstract":"The human vision system understands and interprets complex scenes for a wide range of visual tasks in real-time while consuming less than 20 Watts of power. This Expeditions-in-Computing project explores holistic design of machine vision systems that have the potential to approach and eventually exceed the capabilities of human vision systems. This will enable the next generation of machine vision systems to not only record images but also understand visual content. Such smart machine vision systems will have a multi-faceted impact on society, including visual aids for visually impaired persons, driver assistance for reducing automotive accidents, and augmented reality for enhanced shopping, travel, and safety. The transformative nature of the research will inspire and train a new generation of students in inter-disciplinary work that spans neuroscience, computing and engineering discipline.<br\/><br\/>While several machine vision systems today can each successfully perform one or a few human tasks ? such as detecting human faces in point-and-shoot cameras ? they are still limited in their ability to perform a wide range of visual tasks, to operate in complex, cluttered environments, and to provide reasoning for their decisions. In contrast, the mammalian visual cortex excels in a broad variety of goal-oriented cognitive tasks, and is at least three orders of magnitude more energy efficient than customized state-of-the-art machine vision systems. The proposed research envisions a holistic design of a machine vision system that will approach the cognitive abilities of the human cortex, by developing a comprehensive solution consisting of vision algorithms, hardware design, human-machine interfaces, and information storage. The project aims to understand the fundamental mechanisms used in the visual cortex to enable the design of new vision algorithms and hardware fabrics that can improve power, speed, flexibility, and recognition accuracies relative to existing machine vision systems. Towards this goal, the project proposes an ambitious inter-disciplinary research agenda that will (i) understand goal-directed visual attention mechanisms in the brain to design task-driven vision algorithms; (ii) develop vision theory and algorithms that scale in performance with increasing complexity of a scene; (iii) integrate complementary approaches in biological and machine vision techniques; (iv) develop a new-genre of computing architectures inspired by advances in both the understanding of the visual cortex and the emergence of electronic devices; and (v) design human-computer interfaces that will effectively assist end-users while preserving privacy and maximizing utility. These advances will allow us to replace current-day cameras with cognitive visual systems that more intelligently analyze and understand complex scenes, and dynamically interact with users.<br\/><br\/>Machine vision systems that understand and interact with their environment in ways similar to humans will enable new transformative applications. The project will develop experimental platforms to: (1) assist visually impaired people; (2) enhance driver attention; and (3) augment reality to provide enhanced experience for retail shopping or a vacation visit, and enhanced safety for critical public infrastructure. This project will result in education and research artifacts that will be disseminated widely through a web portal and via online lecture delivery. The resulting artifacts and prototypes will enhance successful ongoing outreach programs to under-represented minorities and the general public, such as museum exhibits, science fairs, and a summer camp aimed at K-12 students. It will also spur similar new outreach efforts at other partner locations. The project will help identify and develop course material and projects directed at instilling interest in computing fields for students in four-year colleges. Partnerships with two Hispanic serving institutes, industry, national labs and international projects are also planned.","title":"Collaborative Research: Visual Cortex on Silicon","awardID":"1317376","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[549461],"PO":["565227"]},"206652":{"abstract":"Motivated by the complementary abilities of humans and humanoids, the objective of this proposal is to develop the science and technology necessary for realizing human-robot cooperative object manipulation and transportation. The key concepts that this research seeks to promote are adaptability to human activity under minimal communication, and robustness to variability and uncertainty in the environment, achieved through a layered representation and deliberate processing of the available information. Moreover, this project aims to make maximum use of a minimal set of sensors to plan and control the actions of the robot, while ensuring safe and efficient cooperative transportation. The embodiment of this research is a humanoid co-worker that bears most of the load, when helping a person to carry an object, without requiring excessive communication, or prior training on the part of the human.<br\/><br\/>By introducing concrete methods for human-robot physical collaboration in semi-structured environments, this project enables a unique synergy between robots and humans that has the potential to increase productivity, and reduce accidents and injuries. In doing so, it also promotes the advancement of new practical applications of robots in construction, manufacturing, logistics, and home services. By developing open-source, portable algorithms for humanoid robots and mobile manipulators, this effort results in cost and time savings for researchers, developers, educators, and end-users in robotics. Finally, through an aggressive educational and community outreach plan, and by actively engaging K-12 students in an exciting RoboTech Fellows program, this project seeks to increase diversity and attract underrepresented groups to STEM.","title":"NRI: Large: Collaborative Research: Human-robot Coordinated Manipulation and Transportation of Large Objects","awardID":"1328805","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":[553286,553287],"PO":["564316"]},"206773":{"abstract":"This project will develop architecture and supporting enabling technologies to avert imminent loss of life or property in fast changing environments. The selected application is resuscitation in an intensive care unit (ICU) because it is life critical, time critical, human-centric and includes complex devices and software. For example, heart attack can be obscured in a trauma patient hemorrhaging from a broken leg in the presence of a collapsed lung. The challenge lies in solving the overarching difficulties of safe execution while maintaining complex and dynamic workflows. The availability and skill levels of medical staff, patient conditions, and medical device configurations all change rapidly. The core contribution is design and verification of reduced complexity situation awareness architecture for Emergency Cyber Physical Human systems (ECPH), supported by enabling technologies such as workflow adaptation protocols, managing data uncertainty and safe device plug and play. The ECPH workflow adaptation protocols are not only a function of the tasks and environment at hand, but must also be aware of the capabilities and training of the medical staff. In addition, risk mitigation driven safety interlock protocols will keep the actions of medical staff and CPS in synchrony with dynamically selected workflows. This is a cooperative effort of UIUC engineering and the ICU department of Carle Foundation Hospital.<br\/><br\/>An ECPH team operates to accomplish a mission under rapidly changing circumstances. The stressful, rushed, and often unfriendly environment of an ECPH system means that errors, uncertainty, and failures will arise. This research will offer safety and resilience in the face of such disruptions. Effective and immediate intervention enabled by an optimized ECPH system will dramatically reduce preventable errors. The societal impact of effective collaboration under high stress will be enormous in terms of human lives and health care costs. According to CDC in 2010, the estimated direct & indirect costs of heart attacks and strokes alone in the U.S. were $503.2 billion; a significant percent of such patients during emergency care suffer complications and harm which are preventable. This project will develop educational material for training the next generation of researchers and engineers. The technology to be developed will also be adapted to other similar ECPH environments such as fighting a raging building fire.","title":"CPS: Synergy: Integrated Emergency Cyber Physical Human Systems","awardID":"1329886","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["553686",553632,553633],"PO":["562984"]},"205332":{"abstract":"Next-generation WLAN protocols will rely heavily on spectrum aggregation to achieve Gbps throughput. But the aggregated wideband spectrum may be severely underutilized and even starved when it overlaps with legacy narrowband channels. As WLAN protocols continue their expansion and diversification, such heterogeneous spectrum sharing becomes increasingly prevalent, raising coexistence as a fundamental problem and practical problem. The objective of this research is to gain insights into coexistence of Gbps and legacy WLANs through measurement studies, develop optimization-driven protocols to enable efficient spectrum sharing between them, and validate the protocols in a medium-scale software-radio testbed. The proposed solutions improve the MAC layer's awareness of heterogeneous spectrum sharing, and enforce intelligent control over the PHY layer through fine-grained spectrum access and opportunistic spectrum aggregation. They have the potential to realize Gbps wireless networking even in a crowd of low-rate legacy networks\/devices.<br\/><br\/>By addressing the key issues of heterogeneous spectrum sharing, the proposed research helps accelerate the deployment of Gbps WLANs which will, in turn, improve the quality of experience for billions of WiFi end-users. It will also train graduate students with a balanced mix of theory and hands-on experiences, and synthesize their knowledge in both computer science and communications engineering. Undergraduate students will also participate in this project, with the complementary support from the undergraduate research programs in the PIs' institutions. The PIs will interact closely with industry for possible transitioning of the research results.","title":"NeTS: Small: Collaborative Research: Efficient Spectrum Access for Gbps WLANs in a Crowd of Legacy Networks","awardID":"1318292","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560209"],"PO":["557315"]},"206784":{"abstract":"Cyber-physical systems are found in nearly every area of daily life: transportation, energy, medical systems, and food production. Life and safety frequently depend upon their correct operation. This project develops a novel systematic framework and methods for understanding, designing, and controlling complex coupled cyber and physical systems based on large-scale computation. This is achieved by explicitly developing the connection between the abstraction, modeling and verification frameworks of physics-based models and those of discrete-transition systems. The approach is fundamentally new, based on the unification of two recent developments: (1) new probabilistic tools for simulating and analyzing high-fidelity physics-based models; and (2) statistical model checking methods. In addition to analytical research, the project produces methods and computational tools that can be used on a wide range of cyber-physical systems, particularly those that are safety and performance critical.<br\/>There have been dramatic recent advances in probabilistic computational techniques for purely physics-based models, treating them computationally as Markov chains, and enabling efficient computation even for high-dimensional systems. Simultaneously with these purely physics-based model approaches, state-of-the-art methods for the verification of purely discrete-state systems have been developed based on stochastic computational tools also using Markov chains as the basis. This project connects these two independent branches to yield a radically new approach for complex, high-dimensional cyber-physical systems, based on the unifying concept of Markov models as an interface between the cyber and physical domains. <br\/>An integral part of the project is a unified educational program aimed at addressing key bottlenecks in the recruitment and development of female and minority students into engineering and computer science. The educational program is developed around a new robotic vehicle with complex fluid-structure dynamics, that is used in: (i) a week-long residential summer camp for female high-school students on \"Mechanics & Dynamics\"; (ii)undergraduate research experiences for female and minority students to facilitate the transition to graduate education; and (iii) an experimental graduate course on verification of embedded systems.","title":"CPS: Breakthrough: Statistical Model Checking of High-Dimensional Cyber-Controlled Systems","awardID":"1329991","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[553663,553664,"562182"],"PO":["561889"]},"205695":{"abstract":"This proposal is motivated by the observation that the battery drain of an app in a mobile device is user-centric, i.e., it depends on several factors that are associated with specific usage patterns. These factors include but are not limited to the mode in which the app is used, the network coverage that the user enjoys and whether or not certain features of the app are turned on\/off. In this project, the objectives are to (i) develop a fundamental understanding of the factors that influence the energy consumption of smartphone apps and, (ii) based on the understanding obtained, design and implement a user-centric battery management system that is called BLT. <br\/><br\/>The PIs plan to first undertake an extensive measurement study that will provide a comprehensive understanding of how and to what extent user-centric factors affect the energy consumption on a smartphone. Subsequently, they aim to tackle several challenges towards identifying the energy hungry apps on a user's smartphone; some of these challenges include the presence of several coexisting active apps at any given time. Finally, they will design and implement a set of solutions that allow a user to trade-off performance or content quality for energy savings. This project hinges on a strong experimental and prototyping effort, and the PIs will leverage the smartphone testbeds at UC Riverside and UC Davis towards undertaking the same.<br\/><br\/>The project will have an immediate broader impact in empowering users with an ability to control their battery usage. It will also allow users and developers in understanding why activities and apps result in high battery drain. The project will also undertake efforts towards inspiring K-12 students in our respective regions, and helping teachers develop projects for science olympiads. The project will include the modification of wireless networking courses taught at UCD and UCR, and new educational efforts on establishing courses that include design and implementation on mobile devices.","title":"NeTS: Small: Collaborative Research: Towards a User Centric Battery Management System for Smartphones","awardID":"1320148","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[550738],"PO":["565303"]},"203396":{"abstract":"The cerebral cortex is comprised of two competing types of brain cells: inhibitory neurons tend to suppress brain activity while excitatory neurons do the opposite. This project will illuminate principles governing the balance of inhibition versus excitation. Focusing on the role of inhibition, the project will test the hypothesis that a particular intermediate level of inhibition is optimal for sensory information processing, because it places the cortex network in a special operating regime called criticality. <br\/><br\/>When inhibition is too high, cortical neurons are suppressed and act largely independently. When inhibition is too low neurons are hyperactive and act largely in unison. Neither extreme is conducive to effective information processing. However, gradually decreasing inhibition from a high level can result in an abrupt onset of correlated, intense activity among the neurons. The tipping point of this onset is called criticality. Importantly, computer models and cortex slice investigations predict that at criticality certain types of information processing are optimized. However, the potentially pivotal role of criticality in processing real sensory input in an intact sensory system remains untested. Such tests will be undertaken here in an in vitro whole-brain preparation that allows the researchers to precisely manipulate levels of global inhibition, record cortical activity with microelectrode arrays for many hours, and stimulate the retina with naturalistic images. Employing novel, statistically rigorous, multifaceted, quantitative tests of criticality, the proposed research will determine the roles of inhibition and criticality in intact cortex during visual processing. Specifically, the experiments are designed to determine whether information transfer from visual stimulus to cortical response is maximized at an intermediate level of inhibition which manifests as criticality.<br\/><br\/>This project represents the first experimental test of the hypothesized functional benefits of criticality in real sensory processing. It builds on a strong conceptual foundation combining statistical physics and computational neuroscience, and may open a new paradigm for investigating cortical visual processing in large neural networks. This new paradigm is particularly relevant in light of emerging new technologies that enable the recording of activity from thousands of neurons. From the medical perspective this contribution is significant because it is expected to illuminate the etiology of numerous brain disorders with abnormal inhibition. Finally, the project brings the excitement of research into Missouri and Arkansas high schools with teacher training and classroom presentations. Newly fostered interest in STEM research will be assessed by longitudinal measures.","title":"CRCNS: Collaborative Research: The role of inhibition and correlated dynamics in cortical visual processing","awardID":"1308174","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[544963],"PO":["564318"]},"206795":{"abstract":"This project develops the theory and technology for a new frontier in cyber-physical systems: cyber-physical manipulation. The goal of cyber-physical manipulation is to enable groups of hundreds or thousands of individual robotic agents to collaboratively explore an environment, manipulate objects in that environment, and transport those objects to desired locations. The project embraces realistic assumptions about the communication, computation, and sensing capabilities of simple individual robots, leading to algorithmic solutions that intrinsically leverage population size in favor of complex agents. Cyber-physical solutions for locating, grasping, and characterizing objects require tools based on distributed computational geometry, while the tasks of planning a path, initiating motion, and controlling the trajectory require tools from decentralized control and consensus. The project lays the theoretical and algorithmic foundations of cyber-physical manipulation, and proves the feasibility of the concept experimentally in hardware tests with up to 100 individual robots. The project uses the problem of manipulation as a stage on which to explore the deeper cyber-physical issue of information asymmetry; the difference in the state of the world as perceived by different agents in the system due to differences in their history of observations, and limitations in their communication capabilities.<br\/><br\/>The object retrieval problem studied in this project is an elemental building block for enabling more complex cyber-physical manipulation tasks. It provides crucial algorithmic components for numerous applications of broad societal benefit, including automated construction (in which hundreds or thousands of robots fabricate large, complex structures), autonomous emergency response (in which large teams of robots find and retrieve incapacitated human survivors after a disaster), and automated environmental cleanup (in which robots secure a dangerous environment by removing debris or hazardous substances). Furthermore, distributed algorithms for multi-agent systems are of broad scientific relevance beyond the realm of cyberphysical systems. The natural world is, in its algorithmic essence, decentralized at many levels. Hence, any advancement in the understanding of how groups of individual agents collaborate to accomplish a coherent task will have broad scientific ramifications. The project has a robust educational and outreach program. One aspect is a hands-on curriculum for robotics outreach activities, called the 'Cyber-Physical Manipulation Lab.' Using a custom-designed robot platform, this educational module introduces the theory and practice of cyber-physical systems to young students to attract them to STEM subject areas at an early age. Results of the project are also incorporated into several graduate and undergraduate level courses at Rice University and Boston University.","title":"CPS: Breakthrough: Collaborative Research: Cyber-Physical Manipulation (CPM): Locating, Manipulating, and Retrieving Large Objects with Large Populations of Robots","awardID":"1330085","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[553693],"PO":["565136"]},"205585":{"abstract":"Ubiquity of multicore processors has created a demand to support parallel processing in all programming languages. However, the dynamic nature of scripting languages makes supporting correct parallel programming in these languages especially difficult. Recent research has enabled safe parallel programming through speculative program parallelization. This project extends these techniques to support parallel programming in the Ruby language. The work focuses on three areas: the interpreter, the core language libraries, and the garbage collector. Through experimentation on Ruby, the research helps to understand the general synergy and limitations when a dynamic language meets dynamic parallelization.<br\/><br\/>The resulting parallel Ruby implementation is a general-purpose parallel language that can be used by non-programming experts. Because of its ease of use, it is expected to be very useful for rapid prototyping of parallel programming applications and teaching parallel programming across all scientific disciplines. Transfer of this technology is facilitated by open-source distribution of the code on the Web. Outreach activities associated with the project include work with pre-college students, recruitment of students from under-represented groups, and collaboration with industry. Education is integrated with the research through involvement of students in the language implementation, and by experimentation with the use of the parallel Ruby language in several courses.","title":"CSR: Small: Safe Parallelization in a Dynamic Language","awardID":"1319617","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[550486],"PO":["564778"]},"202197":{"abstract":"The goal of this project is to develop a new framework where teams of mobile robots self-engineer the structure of their communication network in order to improve on the performance of distributed algorithms used for team coordination. The key idea that enables this work is the representation of the network structure in terms of metrics that depend on the full eigenvalue spectrum of the network's adjacency and Laplacian matrices, but can be approximated in a very efficient and decentralized way. These metrics can then be related to the performance of popular, distributed, coordination algorithms, such as consensus, gossiping, and viral information dissemination. The intellectual merit of this research lies in the development of a hybrid network of mobile robots that is controlled jointly in the space of network configurations and robot positions. The study of the integrated system requires the synthesis of new theoretical results drawing from control theory, spectral graph theory, wireless networking, and optimization. This hybrid network combines the following interrelated objectives: Spectral analysis and distributed control of robot networks; Integrated network and mobility control; Richer models of the communication space; Platform deployment and validation.<br\/><br\/>Successful completion of this research will provide these necessary components in facilitating the design of mobile autonomous systems and fostering their adoption. Wide availability of such systems can have a significant societal impact on, e.g., search, rescue and recovery operations, environmental monitoring for homeland security, or surveillance and reconnaissance missions. The broader impact of this project lies on disseminating the research output in the industry and academia.","title":"NeTS: Medium: Collaborative Research: Optimal Communication for Faster Sensor Network Coordination","awardID":"1302222","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[541882,541883],"PO":["565303"]},"205486":{"abstract":"Modern software systems inherit their architecture, software development methodology, and security model from time-sharing operating systems developed four decades ago. Desktop, server, cloud, and even industrial control systems rely on a large stack of commercial off-the-shelf software that runs on top of a monolithic operating system kernel. Each application runs with the full set of privileges of some user, has access to the entire file space of that user, and can access the complete interface of a complex operating system kernel, and a number of privileged systems components. The security model exposed by existing software systems is fundamentally too weak; it fails to provide adequate isolation between computations.<br\/><br\/>XCap is a secure environment for least-authority execution of applications and system services. Unmodified, untrusted, off-the-shelf applications, running on untrusted operating systems, are isolated by a virtual machine monitor. XCap builds on two principles: strong isolation and secure collaboration. XCap's default -- a share nothing environment -- is augmented by a capability access control model: a clean and general abstraction, enabling fine-grained delegation of rights in a flexible and manageable way. In XCap, capabilities serve as a general foundation for constructing least privilege services out of existing components of the traditional operating system stack. XCap maximizes the principle of least authority: it redesigns common operating system services in such a way that the authority of individual applications and services is minimized. Each component possesses the smallest subset of rights required to accomplish its task.","title":"TWC: Small: XCap: Practical Capabilities and Least Authority for Virtualized Environments","awardID":"1319076","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[550238,550239],"PO":["564223"]},"206113":{"abstract":"From Wikipedia to Linux to scientific and business work-groups all over the world, both online and off-line groups are becoming a pervasive part of modern life. It is becoming increasingly important, therefore, to understand how to improve the performance of these groups. The work proposed here will use a new measure of generalized group effectiveness -- called \"collective intelligence\" -- to help do this. <br\/><br\/>Building on previous work by the investigators, the project will first develop an online test for collective intelligence. Then it will compare the results of online and face-to-face groups taking this new test with previous results for groups taking an offline version of the test. This will help clarify the degree to which online and off-line groups differ in their general effectiveness on a wide range of different tasks. Next the project will use this test to systematically measure the collective intelligence of online groups that range in size from 2 to 20 people. This will lay the foundation for exploring whether larger online groups can take advantage of the increased resources that more people bring, without suffering as much from the process losses that usually accompany increased group size in face-to-face groups. Finally, the project will systematically measure the collective intelligence of online groups with varying proportions of women. In doing so, the project will also test one particularly promising explanation for a gender effect on group performance: that groups with more women are less interpersonally competitive, and that this lower intra-group competitiveness leads to higher collective intelligence. <br\/><br\/>While there have been decades of research on factors that affect the performance of groups, almost all these studies have each focused on a single task. Thus, strictly speaking, the lessons to be learned from this previous work are limited to the specific tasks studied. The work proposed here uses the perspective of collective intelligence to investigate, not just the ability of a group to perform a single task, but the group's general ability to perform a wide range of tasks. Since many real-world groups must cope with a wide range of problems, just such a perspective may be needed to systematically predict their performance. In addition, the approach developed here can provide a significant economy of effort in evaluating potential ways of improving online group effectiveness. Instead of testing interventions on many different specific tasks, researchers will be able to test the interventions once with this general measure, and then have some basis for predicting the effects of the intervention on many other tasks. By making an online test of collective intelligence available to other researchers, the project will help advance scientific practice in this area. More generally, by providing a firmer scientific foundation for measuring and improving the performance of groups, the project may help our society address many of its most important problems more effectively. For instance, with the right kinds of collaboration tools, online groups may be able to be much more effective than face-to-face groups, taking advantage of the simultaneous efforts of far more people without the coordination losses that usually occur in larger groups. And understanding the dynamics of gender diversity may help to improve the collaboration of the groups in which both men and women work, by giving everyone's best ideas a better chance to be heard. And perhaps, someday, this will help create groups that are more collectively intelligent than any groups have ever been before.","title":"VOSS: Collaborative Research: Is Larger Smarter? Investigating the Effect of Group Size on Collective Intelligence","awardID":"1322254","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"7642","name":"VIRTUAL ORGANIZATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[551789],"PO":["565272"]},"205266":{"abstract":"The proposed work seeks to leverage cloud computing to enable robots to efficiently learn from remote human domain experts - \"Cloud Learning from Demonstration.\" Building on RobotsFor.Me, a remote robotics research lab, this research will unite Learning from Demonstration (LfD) and Cloud Robotics to enable anyone with Internet access to teach a robot household tasks. The value of this work stems from three aspects. First is the remote system that can learn task models from a series of remote demonstrations from a single user, focusing on learning high-level tasks as opposed to low-level motor skills. The second is the extension of learning from demonstration to multiple teachers. This represents an important relaxation of a limiting assumption to focus on evaluating teacher strengths and effectively handling distinct task solutions. Finally, transparency mechanisms to allow a remote user to develop a correct mental model about the robot?s learning process.<br\/><br\/>The long term goal of this research is to one day make personal robots accessible to everyday people. The interactive learning framework based on RobotsFor.Me provides unique opportunities for education and outreach. Thomaz and Chernova will outreach to K-12 teachers and students by creating an education portal surrounding RobotsFor.Me containing hands-on workshop curricula. This material will be integrated with the WPI Frontiers program for middle school students, and the GT ePDN professional education network for teachers. A key impact on students at GT and WPI will be direct involvement in this research agenda, and integration with AI, robotics and HRI courses. Chernova is the Diversity Coordinator in the Robotics Engineering Program, and faculty advisor for Women In Robotics Engineering and Women in Technology student groups which will enable braod exposure. Thomaz mentors the RoboWomen graduate women?s group. Software components will also be made available as open source and the PIs have a collaboration plan in place with researchers at Willow Garage, and through student internships will transfer technology to their labs.","title":"NRI: Small: Collaborative Research: Learning from Demonstration for Cloud Robotics","awardID":"1317926","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":["550868"],"PO":["564069"]},"205398":{"abstract":"The FCC seeks to connect 19 million unserved Americans to broadband by 2020. These rural areas have yet to be fully connected to the Internet due to wireline infrastructure costs which exceed potential revenue opportunities. Even in heavily-populated environments with sufficient wireline infrastructure, capacity issues remain in congested stadiums, disaster recovery zones, and public transportation. Each aforementioned access challenge seemingly is well-suited for wireless mesh networks, but have yet to be fully solved. However, recently, there has been a sizable growth in radios operating in diverse frequency bands (e.g., TV white spaces) with emerging multi-antenna schemes. In this project, multi-user beamforming and diverse frequency bands are leveraged to significantly build upon the flexibility originally sought by mesh networks. In doing so, frequency-agile beamforming mesh (FabMesh) networks seek to truly scale in complexity and cost according to the user population and traffic demand. The work includes three key innovations: (i) client-side, beamforming-aware, and frequency-agile protocols to improve performance and reliability of clients, using contextual information and advanced physical layer techniques, (ii) analysis of spatial reuse and capacity for media access control in mesh networks which leverage multi-user beamforming, and (iii) scalable network deployments which leverage multi-user beamforming along the backhaul and adaptation across multiple frequency bands according to network demand. The project includes a number of hands-on courses for university students at all levels, \"just in time\" pedagogical approaches to thousands of online students, outreach to under-represented students and communities, and key industrial collaborations to accelerate the commercial adoption of FabMesh networks.","title":"NeTS: Small: Collaborative Research: Theory, Algorithms, and Experiments for Frequency-Agile Beamforming Mesh (FabMesh)","awardID":"1318607","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["561963"],"PO":["557315"]},"209578":{"abstract":"Prior work has shown that the unobtrusive, continuous monitoring of individuals with in-home sensors provides useful embedded health assessment, i.e., the continuous assessment of health changes based on each person's individual activity patterns and baseline health conditions, and can improve health outcomes. Especially for older adults, identifying and assessing problems early provides a window of opportunity for interventions to alleviate problems before they become catastrophic and require hospital or nursing home care.<br\/><br\/>This project augments monitoring of individuals with a new interactive exercise coaching interface that will connect a remote physical therapist to senior clients in the home. GENI-enabled networking will be incorporated to support real-time interaction via high-definition video. The proposed project will meet the following objectives:<br\/>* Develop an integrated, interactive interface for displaying in-home gait history and coaching remote users on proper exercise form.<br\/>* Extend the integrated system to support GENI-slice overlay network channels.<br\/>* Deploy the integrated monitoring and coaching system in senior independent living homes<br\/><br\/>The project will impact technology, healthcare, policy, quality of life for seniors, and peace of mind for their families. The technology impacts include significant contributions to GENI-enabled networking and interactive interfaces for seniors. Results will further embedded health assessment and offer new ways to detect health problems before they become catastrophic. The project results will be disseminated both through traditional academic publications and by outreach to the general public via the US Ignite conferences and the university?s Engineering Week Open House in which hundreds of K-12 students tour the college. Additionally, the project will recruit undergraduate students, especially women and under-represented groups.","title":"US-Ignite: EAGER: GENI-Enabled In-Home, Personalized Health Monitoring and Coaching","awardID":"1346789","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["562286",561792,561793,561794],"PO":["564993"]},"209589":{"abstract":"perfSONAR (http:\/\/www.perfsonar.net) is a set of community-developed protocols and a widely-adopted infrastructure for multi-domain network performance monitoring, facilitating the ability to collect and share measurement data relevant to solve end-to-end network performance problems and to enable network-aware applications. The first perfSONAR workshop was successfully held 8-9 July 2010 in Arlington, VA. This project will organize and hold the Second perfSONAR workshop to be held February 20-21 2014 at at the NSF in Arlington VA, open to members of the perfSONAR community. The goal of the second workshop is to build upon the first workshop outcomes and capitalize on the inherent flexible multi-domain nature of the perfSONAR protocols and infrastructure. The intended focus is to cross-fertilize ideas from a variety of stakeholders that include: researchers, applications developers, network operators, network managers, and others with an interest in network research and performance measurement\/monitoring.<br\/><br\/>The workshop goals include:<br\/> 1. Identification of unimplemented techniques and network research focus areas with existing ideas that can help solve problems of R&E networks, as well as open research questions focused on solving real world end-to-end performance problems;<br\/> 2. Identification of required perfSONAR infrastructure components for network operators, end users, network researchers, and virtual organizations, and any missing components;<br\/> 3. Operational requirements, federation policies and best practices for ongoing and on-demand measurements end-to-end, cross-domain, and transoceanic links; and<br\/> 4. Creating a larger perfSONAR community seeded by the workshop participants, including strategies for engaging new network researchers, new domain science researchers, new science communities, and new networks.<br\/><br\/>perfSONAR is a tool supporting multiple high-priority programs in multiple U.S. agencies. It is a key tool for network diagnostics for in the High Performance Computing community. As such enhancements to the perfSONAR framework have direct impacts on projects across a wide range of disciplines. The output of the workshop will be a report suitable for archival within the ACM Digital Library. The report will summarize the discussions and recommendations of participants in accordance with the aforementioned workshop goals, and could serve to inform and guide future community actions.","title":"Collaborative Research: Workshop on perfSONAR based Multi-domain Network Performance Measurement and Monitoring","awardID":"1346851","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["562286"],"PO":["564993"]},"205871":{"abstract":"Mobility models are an indispensable tool in the design, testing, and evaluation of wireless networks and their protocols. It is now widely recognized that mobility models should account for both geographical features of the region being studied as well as the social relations and interactions among users. This project aims to develop a unified yet flexible mobility modeling framework that combines both social and geography factors that influence how users move, and to develop formal statistical learning methods to calibrate mobility models using real mobility data. Additionally, an important deliverable of the project is to develop software tools that implement our models and can be used by researchers and practitioners to evaluate mobile systems and protocols.<br\/><br\/>This project is expected to have significant impact on the way network researchers and practitioners design, test, and evaluate mobile networks and their protocols. The project also has an important educational component: students working on this research are expected to develop a crosscutting research and academic and background. Research results from this project will be disseminated through project Web site, and technical papers published in conferences and journals. The mobility generation software tool will also be freely available through the project's Web site.","title":"NeTS: Small: Socially- and Geographically-Aware Modeling Framework for User Mobility in Wireless Networks","awardID":"1321151","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[551159,"551769"],"PO":["557315"]},"206730":{"abstract":"The objective of this research is to prove that cyber-physical systems are safe before they are deployed. The approaches the research investigates are extensions of approaches used to test communications protocols. The problems with cyber-physical systems are that 1) they are much more complicated than communications protocols, 2) time is a more critical component of these systems, and 3) in a competitive environment there are likely to be many implementations that must interoperate.<br\/><br\/>The complexity of communications protocols is reduced by using a layered architecture. Each layer provides a well defined service to the next layer. This research is developing multi-dimensional architectures that reflect the different ways that the cyber-physical system interacts with the physical world. The techniques are evaluated on a driver-assisted merge protocol. An architecture for the merge protocol has four dimensions organized as stacks for communications, external sensors, vehicle monitoring and control, and timing. This architecture will also be useful during standardization.<br\/><br\/>Timing increases verification complexity by increasing the number of potential execution paths. The research conducted in this project explores how to reduce the number of paths by synchronizing clocks and using simultaneous operations. This approach is reasonable because of the timing accuracy now available with GPS. A two step verification process is used that creates an unambiguous model of the cyber-physical system, first proving that the model is safe, then checking that each implementation conforms to the model. This reduces the number and cost of tests for a three-party merge protocol. Specifically, assuming there are N implementation versions for different manufacturers and models, this approach reduces the number of necessary interaction tests, which would be cubic in N, to a single model verification and N conformance tests.","title":"CPS: Breakthrough: Safe Protocols in Cyber-Physical Systems (CPS)","awardID":"1329593","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[553512],"PO":["561889"]},"205762":{"abstract":"The objectives of this project include the design of networked mobile robotic sensor nodes, which are<br\/>inspired by insects within the family gerridae, that can monitor water quality in lakes and rivers, and jump<br\/>repeatedly to enhance communication capability to overcome the effect of water on radio signal propagation.<br\/>This work will also develop energy efficient algorithms that carefully select sensor nodes to jump to gain the<br\/>benefit of longer distance communication while managing the energy required to jump. The robotic sensor<br\/>can harvest solar energy in a outdoor environment to maintain long term performance. New methods for<br\/>sensor localization as the sensor floats within a lake or river will be developed as well as efficient algorithms to collect sensor data and deliver it to the cyber infrastructure that could be used for hydrology modeling and prediction.<br\/><br\/>The results of this research effort should significantly enhance the capability of networked mobile sensor<br\/>systems for water quality monitoring in response to water pollution or other environmental conditions. These<br\/>concerns can be from oil spills, issues of bacterial levels, or even detection of levels of radiation from nuclear power plant disasters. This research should provide a cost-effective approach for water quality monitoring that can protect health and emergency management such as advising people to vacate areas of environmental damage. Furthermore, new sensor technology should be developed that provides enhanced opportunities for business and job opportunities to industries and society and provides students with a platform to learn and understand all levels of sensor development and operation.","title":"NeTS: Small: Networked Robotic Gerridae for Sensing and Communications in Aquatic Environments","awardID":"1320561","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["512771",550894,550895],"PO":["565303"]},"204673":{"abstract":"The advent of mobile health (mHealth) technology brings great opportunity to improve quality of life, improve individual and public health, and reduce healthcare costs. Although mHealth devices and applications are proliferating, many challenges remain to provide the necessary usability, manageability, interoperability, availability, security, and privacy. The goal of this project is to engineer the tools for, and lay the scientific foundation of, secure wearable mHealth. In the process, the investigators are developing a general framework for body-area pervasive computing, centered around health-monitoring and health-management applications.<br\/><br\/>The vision is that computational jewelry, in a form like a bracelet or pendant, will provide the properties essential for successful body-area mHealth networks. These devices coordinate the activity of the body-area network and provide a discreet means for communicating with their wearer. Such devices complement the capabilities of a smartphone, bridging the gap between the type of pervasive computing possible with a mobile phone and that enabled by wearable computing.<br\/><br\/>The interdisciplinary team of investigators is designing and developing 'Amulet', an electronic bracelet and a software framework that enables developers to create (and users to easily use) safe, secure, and efficient mHealth applications that fit seamlessly into everyday life. The research is determining the degree to which computational jewelry offers advantages in availability, reliability, security, privacy, and usability, and developing techniques that provide these properties in spite of the severely-constrained power resources of wearable jewelry.","title":"CSR: Large: Collaborative research: Computational Jewelry for Mobile Health","awardID":"1314342","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[548119,548120],"PO":["565255"]},"206741":{"abstract":"The objective of this proposal is to develop a distributed algorithmic framework, supported by a highly fault-tolerant software system, for executing critical transmission-level operations of the North American power grid using gigantic volumes of Synchrophasor data. As the number of Phasor Measurement Units (PMU) increases to more than thousands in the next 4-5 years, it is rather intuitive that the current state-of-the-art centralized communication and information processing architecture of Wide-Area Measurement System (WAMS) will no longer be sustainable under such data-explosion, and a completely distributed cyber-physical architecture will need to be developed. The North American Synchrophasor Initiative (NASPI) is currently addressing this architectural aspect by developing new communication and computing protocols through NASPI-net and Phasor Gateway. However, very little attention has been paid so far to perhaps the most critical consequence of this envisioned distributed architecture \"namely\", distributed algorithms, and their relevant middleware. Our primary task, therefore, will be to develop parallel computational methods for solving real-time wide-area monitoring and control problems with analytical investigation of their stability, convergence and robustness properties, followed by their implementation and testing against extraneous malicious attacks using our WAMS-RTDS testbed at NC State. In particular, we will address three critical research problems \"namely\" distributed wide-area oscillation monitoring, transient stability assessment, and voltage stability monitoring.<br\/><br\/>The intellectual merit of this research will be in establishing an extremely timely application area of the PMU technology through its integration with distributed computing and optimal control. It will illustrate how ideas from advanced ideas from numerical methods and distributed optimization can be combined into power system monitoring and control applications, and how they can be implemented via fault-tolerant computing to maintain grid stability in face of catastrophic cyber and physical disturbances.<br\/><br\/>The broader impact of this project will be in providing a much-needed application of CPS engineering to advance emerging research on PMU-integrated next-generation smart grids. Research results will be broadcast through journal publications, jointly organized graduate courses between NC State and University of Illinois Urbana Champagne, conference tutorials and workshops. Undergraduate research for minority engineering students will be promoted via the FREEDM Systems Center, summer internships via Information Trust Institute (UIUC) and RENCI, and middle\/high-school student mentoring through the NCSU Science House program.","title":"CPS: Synergy: Collaborative Research: Distributed Asynchronous Algorithms and Software Systems for Wide-Area Monitoring of Power Systems","awardID":"1329681","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[553537,553538],"PO":["564728"]},"205421":{"abstract":"The future Cognitive Radio Networks (CRNs) will consist of heterogeneous devices such as smartphones, tablets and laptops moving dynamically. Accurate and robust spectrum sensing and identification of unauthorized spectrum usage are essential components of spectral efficiency in future radio systems. This project aims to utilize consensus-based cooperation featuring self-organizable and scalable network structure to capture the swarming behaviors of spectrum users and providing cooperative spectrum sensing in a fully distributed manner. By using a combination of control theory and machine learning techniques, the project designs secure weighted average consensus for cooperative spectrum sensing that can not only capture the swarming behaviors in CRNs with heterogeneous devices, but also is robust to practical channel conditions. Robust localization approaches are developed grounded on dynamic signal strength mapping, which have the capability to localize multiple malicious users. Additionally, the new techniques are validated using an actual testbed with on-campus deployment and system demonstration to industrial collaborators. The integration of control theory with dynamic spectrum access will enable a new revolution in the way for enhancing spectrum efficiency in CRNs. The project serves as a pioneer in exploiting multi-disciplinary knowledge (e.g., control systems and machine learning techniques) to achieve a more efficient spectrum usage in future radio systems, aiming to alleviate the increasing crowdness of the spectrum occupancy and support the co-existence of heterogeneous devices. This project also carries out a broad range of education and outreach activities to encourage students to pursue careers in the fields of science and engineering. Research results will be disseminated to academia and industry through presentations and publications in meetings, conferences and journals.","title":"NeTS: Small: Collaborative Research: Distributed Robust Spectrum Sensing and Sharing in Cognitive Radio Networks","awardID":"1318751","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["564316"],"PO":["557315"]},"206763":{"abstract":"This project develops algorithms for revising a given model for a cyber-physical system while ensuring that the revised model is correct-by-construction and is realizable in the constraints imposed by the cyber-physical system. It specializes these algorithms in the context of fault-tolerance (with the theory of separation of concerns) and in the context of timed models (with the role of fairness). The project identifies constraints imposed by the inability to revise some or all physical components and ensure that they are satisfied during revision. It specializes model revision algorithms in two contexts: fault-tolerance and role of fairness during revision. Regarding fault-tolerance, it develops the theory of separation of concerns for cyber-physical systems. This work bridges the gap between fault-tolerance components, control theory and model revision. Regarding fairness, it develops efficient algorithms for revision by using abstraction to model continuous behaviors with discrete behaviors that utilize fairness. <br\/><br\/>One broad impact of this project is to advance the fundamental science and technology of cyber-physical systems by developing systematic methods that ensure system correctness during maintenance where the system is revised due to changing requirements and\/or environment. The algorithms from this project will provide techniques for providing assurance in automotive and aeronautical systems. In the context where fault-tolerance properties are added, the proposed activities also have the potential to identify missing specifications early and thereby reduce the cost of designing corresponding systems. The proposed activities facilitate in educating graduate students about different tasks involved in providing assurance via component based models and via model revision.","title":"CPS: Breakthrough: Scalable Component-Based Model Revision of Cyber-Physical Systems with Separation of Concerns","awardID":"1329807","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[553603],"PO":["561889"]},"205553":{"abstract":"Interference between neighboring wireless networks is a serious problem in high-density deployments. As one well-known example, WiFi networks in dense deployment areas can experience severe performance degradation. Current approaches efficiently share available bandwidth between networks, but do not address the underlying interference problem. One potential approach is multiple-input multiple-output (MIMO) interference cancellation. While the theory of MIMO interference cancellation is well understood, it has not been deployed due to practical limitations. This project is designing, evaluating, and implementing practical solutions to MIMO interference cancellation. Ideas being studied include Consistent Access Point Orientation to reduce the complexity of gathering channel state information, Proportional Fairness with Interference, which enables better MIMO link scheduling, multi-level scheduling to reduce computational overheads, tit-for-tat policies that encourage access point cooperation, and Guided CSMA\/CA to guide nodes toward a scheduled execution. Approaches are being implemented and evaluated within the ns-3 network simulator using accurate physical layer models, and are also being tested on a software-defined radio platform. <br\/><br\/>This project aims to significantly boost performance of wireless networks, such as WiFi networks and femtocells, that operate in dense deployment areas. The approach taken enables each network to use the full available bandwidth of the wireless channel regardless of surrounding interference. The project is expected to produce algorithms and protocols to enable MIMO interference cancellation techniques to be adopted in practical network settings. The project will also contribute to the research infrastructure by implementing support for MIMO interference cancellation the ns-3 network simulator and making the enhancements available to the research community.","title":"NeTS: Small: Practical Strategies for using MIMO to Mitigate Interference in High-Density Uncoordinated Wireless Networks","awardID":"1319455","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["562577","560261"],"PO":["557315"]},"205795":{"abstract":"With the explosion of new mobile apps, protocols and services, there is a compelling need for new tools to evaluate and test mobile networks. This project aims to establish a systematic framework to produce benchmarks (called MobiBench) in the form of evaluation scenarios and test-suites for mobile networking protocols and services for user and vehicular mobility. Two threads of research are pursued. First, a multi-dimensional metric space is introduced for characterization of user (human) mobility, to be applied to mobility measurements and models. The metrics span: i. individual, ii. pair-wise and iii. collective mobility dimensions, and facilitate comprehensive analysis and evaluation of mobility models and networking protocols. Novel, trace-driven models are developed to accurately capture user mobility metrics and mobile network performance. The COBRA model is designed to capture collective communal behavior in mobile social networks. Second, new extensive vehicular traces are collected and analyzed, including vehicular imagery data from thousands of webcams around the world. Vehicular density distributions and models are developed to aid in establishing realistic vehicular mobility models and benchmarks. Estimation of vehicular density uses adapted background subtraction algorithms for image processing. This work will result in the establishment of a library of benchmarks, traces, models and test-suites for pedestrian and vehicular mobility, to be used for the realistic evaluation of future mobile protocols, networks and services. Results of this research will impact mobile networking research and aid in traffic control and transportation congestion mitigation.","title":"NeTS: Small: MobiBench: Benchmarking Mobility Models for Simulation and Design of Future Networks","awardID":"1320694","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[550970],"PO":["557315"]},"205564":{"abstract":"This project addresses the problem of design space exploration for high-performance embedded computing platforms. Such systems are increasingly heterogeneous, and include powerful multi-core microprocessors (CPUs), many-core Graphics Processing Units (GPUs), and Digital Signal Processors (DSPs). Despite the availability of these powerful platforms, many barriers exist for application developers and platform designers to reap the full benefits of these devices. Some of these challenges include finding effective mappings of applications to a wide range of heterogeneous compute platforms and defining\/exploring the most appropriate memory interfaces. <br\/><br\/>The goal of the project is development of a Heterogeneous Design Environment (HDE), that will allow one to define algorithms at a high level, and automate the search of the design space to select hardware and software implementations to meet desired objectives. Towards this co-design goal, the research includes investigation of methods of expressing algorithms at a conceptual, functional level; exploration of static methods of analyzing parallelism of applications; and extending simulation frameworks to support and accurately model power and performance on CPUs, GPUs, and DSPs at different levels of abstraction. The target application domain for proof of this concept is computer vision, one of the fastest growing market sectors within embedded high-performance computing, in which applications tend to be data-driven, compute-hungry and power-constrained.<br\/><br\/>The Heterogeneous Design Environment is expected to simplify development of power-efficient embedded computing applications across a set of heterogeneous devices. By providing a rich set of design exploration tools in the context of industry-standard programming frameworks, such as Multi2Sim and OpenCL, the project aims to accelerate the pace at which new computer vision applications are developed. Integrated education and outreach activities include new development of new courseware, delivery of tutorials, involvement of undergraduates, participation in a summer program for middle-school students, and use of the HDE in undergraduate and graduate courses.","title":"CSR: Small: Power Efficient Emerging Heterogeneous Platforms","awardID":"1319501","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["557272",550436],"PO":["565255"]},"205333":{"abstract":"Consider a network where each node is either good or bad. The good nodes all run an algorithm that attempts to achieve a specific goal. The hidden set of bad nodes are controlled by an adversary who uses them to thwart this goal.<br\/><br\/>Informally, cost-competitive analysis considers the resource cost of each good node as a function of the total resource cost of the adversary. The goal is to design algorithms that achieve their objectives, while minimizing this cost. Critically, when bad nodes suffer higher costs than good nodes, it is expected that they will eventually cease their attack, as their resources become depleted.<br\/><br\/>Goals of this project are to design cost-competitive algorithms for: communication in wireless networks; tolerating distributed denial-of-service attacks; secure routing in peer-to-peer networks; and enabling nodes to come to agreement.<br\/><br\/>Cost-competitive analysis offers a novel approach for making progress on challenging attacks that cannot be adequately addressed in models that ignore the costs of the attacker. By adopting a more realistic attack model, this approach more accurately quantifies the limits of efficient attack resistance. It is thus expected that a cost-competitive approach will yield more compelling solutions to security challenges in many domains. In particular, this project may have high impact in security challenges involving open environments such as: wireless sensor networks, overlays, reputation systems; and aspects of contemporary problems in industry such as: public cloud computing, reliable versions of MapReduce, and robust distributed lock managers like Google's Chubby lock service.","title":"TWC: Small: Collaborative: Cost-Competitve Analysis - A New Tool for Designing Secure Systems","awardID":"1318294","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[549839],"PO":["565327"]},"206785":{"abstract":"Cyber-physical systems employed in transportation, security and manufacturing applications rely on a wide variety of sensors for prediction and control. In many of these systems, acquisition of information requires the deployment and activation of physical sensors, which can result in increased expense or delay. A fundamental aspect of these systems is that they must seek information intelligently in order to support their mission, and must determine the optimal tradeoffs as to the cost of physical measurements versus the improvement in information.<br\/><br\/>A recent explosion in sensor and UAV technology has led to new capabilities for controlling the nature and mobility of sensing actions by changing excitation levels, position, orientation, sensitivity, and similar parameters. This has in turn created substantial challenges to develop cyber-physical systems that can effectively exploit the degrees of freedom in selecting where and how to sense the environment. These challenges include high-dimensionality of observations and the associated \"curse of dimensionality\", non-trivial relationships between the observations and the latent variables, poor understanding of models relating the nature of potential sensing actions and the corresponding value of the collected information, and lack of sufficient training data from which to learn these models.<br\/><br\/>Intellectual Merit: The proposed research includes: (1) data-driven stochastic control theory for intelligent sensing in cyber-physical systems that incorporates costs\/delays\/risks and accounts for scenarios where models for sensing, decision-making, and prediction are unavailable or poorly understood. (2) Validation of control methods on a UAV sensor network in the real world domain of archaeological surveying.<br\/><br\/>Broader Impacts: The proposed effort includes: (a) Outreach: planned efforts for encouraging participation of women and under-represented groups; (b) Societal impact: research will lead to novel concepts in environmental monitoring, traffic surveillance, and security applications. (c) Multi- disciplinary activities: Impacting existing knowledge in cyber-physical systems, sensor management, and statistical learning. Research findings will be disseminated through conferences presentations, departmental seminars, journal papers, workshops and special sessions at IEEE CDC and RSS; (d) Curriculum development through new graduate level courses and course projects.","title":"CPS: Synergy: Data Driven Intelligent Controlled Sensing for Cyber Physical Systems","awardID":"1330008","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[553667,553668,"553678"],"PO":["564728"]},"206675":{"abstract":"This project is funded as part of the United States-Israel Collaboration in Computer Science (USICCS) program. Through this program, NSF and the United States - Israel Binational Science Foundation (BSF) jointly support collaborations among US-based researchers and Israel-based researchers. The project targets scalable verification of concurrent software via compositional techniques. Compositional techniques break-up the full program into smaller components that are checked separately. Typically, a component cannot be verified in isolation from its environment, consisting of the other components. The component is therefore verified under a relatively small assumption on its environment. Progress has been made in the past on automating assumption generation in the context of a simple reasoning rule, where assumptions and properties are related in an acyclic manner. However, there are cases where circular dependency within a system is a real phenomenon that requires more complex, circular rules, which typically use inductive arguments. Although effective in scaling up verification, the applicability of these rules has been limited by the manual effort involved in defining the assumptions.<br\/><br\/>The project addresses the automation of the assumption discovery process in the context of existing circular rules and of new rules, developed as needed. Abstraction and learning techniques are used to iteratively build assumptions and refine them based on counterexamples obtained from checking components separately. The algorithms developed incorporate 3-valued reasoning to allow for more precise yet concise assumptions. The techniques aim at increasing the assurance of general-purpose concurrent and distributed software, by scaling up existing verification techniques through novel automated circular compositional reasoning. Two specific application areas are investigated, namely UML-based software and security protocols; both these areas can highly benefit from compositional reasoning.","title":"BSF:2012259:Circular compositional reasoning by learning and abstraction-refinement","awardID":"1329278","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":[553368],"PO":["565264"]},"205586":{"abstract":"Years of effort to develop algorithms capable of learning from reward signals have resulted in a plethora of techniques that can leverage numerical signals that vary in value based on performance. Recent efforts to use these techniques to learn from humans providing rewards have been slower to progress, in part, because humans give feedback discretely rather than numerically. This project contributes new learning algorithms designed specifically to leverage the information contained in the choices humans make to provide such discrete feedbacks. The algorithms are inspired by the human-canine partnership, and the incredible things that humans are able to teach dogs using only discrete feedback and carefully constructed sequences of tasks. The Bayesian learning framework being developed in this project will leverage the pragmatic implicatures contained in the feedbacks and tasks sequences to learn more quickly from human feedback. <br\/><br\/>The ultimate goal of this work is to provide a more natural paradigm for humans to tell computers what they would like for them to do. To that end, project efforts will result in a teaching module for Brown University?s Learning Exchange (LE). The LE involves undergraduates working with underserved minority middle school students to engage them in STEM. They are a perfect audience to demonstrate the broader impacts of this work. LE participants learn to instruct computers using a combination of programming with the Scratch environment and the feedback paradigm, which shows how powerful the algorithms are.","title":"RI: Small: Collaborative Research: Speeding Up Learning through Modeling the Pragmatics of Training","awardID":"1319618","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[550488],"PO":["565035"]},"205355":{"abstract":"Hypervisors are the building blocks of cloud computing. They host the virtualized operating systems and applications which provide highly-scalable, pervasive services on a continuous basis. These thin-layer, bare-metal operating systems create a prime target for attack. A compromised hypervisor grants access to hosted virtual machines and data stores. Its computing resources can be used for malicious purposes, including mounting additional attacks. To avoid detection, rooted hypervisors must not only avoid tripping internal alarms, but also convince external monitors that they are operating normally. To conceal illicit activities, they may underreport performance metrics. Although rootkits can hide unauthorized activity by understating system load, they cannot tamper with external measures of power usage. This research develops a new method for identifying compromised hypervisors which integrates energy usage statistics. This method correlates independent measures of server energy usage with hypervisor reports of system state to create models of power consumption. The detection process focuses on hypervisors which appear to use more power than expected, given reported performance metrics. Three out-of-band tests for detecting compromise are undergoing testing and refinement. The results of this research will indicate the effectiveness of energy correlation-approaches at identifying rooted hypervisors. If successful, this project will provide a platform-neutral method for cloud management monitors to identify compromised hypervisors. It reduces adoption risks for organizations and individual users of cloud services. In addition, it will provide opportunities for graduate and undergraduate students to developed advanced skills in cloud and data center security.","title":"TWC: Small: Securing Cloud Infrastructure: Unobtrusive Techniques for Detecting Hypervisor Compromise","awardID":"1318399","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[549892],"PO":["564223"]},"208402":{"abstract":"Computer simulation plays a central role in helping us understand, predict, and engineer the physical and chemical properties of technological materials systems such as semiconductor devices, photovoltaic systems, chemical reactions and catalytic behavior. Despite significant progress in performing realistic simulations in full microscopic detail, some problems are currently out of reach: two examples are the modeling of electronic devices with multiple functional parts based on new materials such as novel low power computer switches that would revolutionize the Information Technology industry, and the photovoltaic activity of complex interfaces between polymers and inorganic nanostructures that would enhance US energy self-reliance. The research program of this collaborative software institute aims to create an open and effective scientific software package that can make efficient use of cutting-edge high performance computers (HPC) to solve challenging problems involving the physics and chemistry of materials. By having such software available, this software initiative will have multiple broad impacts. First, the community of materials scientists will be able to study next-generation problems in materials physics and chemistry, and computer science advances that enable the software will be demonstrated and made accessible for both communities which will help cross-fertilize further such collaborative efforts. Second, the capability of simulating and engineering more complex materials systems and technological devices could play a role in helping the US continue is competitive edge in science, technology, and education. Third, through training of young scientists, direct outreach to the broader scientific community through workshops and conferences, and educational programs ranging from secondary to graduate levels, the power, importance, and capabilities of computational modeling, materials science, and computer science methodologies that enable the science will be communicated to a broad audience. Finally, by enabling the refinement of existing materials systems as well as discovery of new materials systems, the resulting scientific advances can help broadly impact society via technological improvements: in terms of the two examples provided above, (a) the successful design of new electronic device paradigms helps significantly advance the digital revolution by permitting the introduction of smaller, more efficient, and more capable electronic circuits and information processing systems, and (b) successful creation of inexpensive, easy-to-fabricate, and durable photovoltaic materials and devices can lead to cleaner forms of energy production while reducing reliance on fossil fuels.<br\/><br\/>The technical goal is to greatly enhance the open software tool OPENATOM to advance discovery in nanoscience and technology. OPENATOM will be delivered as a open, robust and validated software package capable of utilizing HPC architectures efficiently to describe the electronic structure of complex materials systems from first principles. In terms of describing electronic ground-states, OPENATOM will be enhanced by features such as improved configurational sampling methods, hybrid density functionals, and incorporation of fast super-soft pseudopotential techniques. In addition, the team will incorporate the many-body GW-BSE approach for electronic excitations that permits accurate computation of electronic energy levels, optical absorption and emission, and luminescence. Ultimately, such an extensible software framework will permit accurate electronic structure computations to employ effectively future HPC platforms with 10,000,000 cores.","title":"SI2-SSI: Collaborative Research: Scalable, Extensible, and Open Framework for Ground and Excited State Properties of Complex Systems","awardID":"1339715","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0307","name":"Division of MATERIALS RESEARCH","abbr":"DMR"},"pgm":{"id":"1712","name":"DMR SHORT TERM SUPPORT"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"8084","name":"CDS&E"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0707","name":"Division of INDUSTRIAL INNOVATION & PARTNE","abbr":"IIP"},"pgm":{"id":"7231","name":"CYBERINFRASTRUCTURE"}}],"PIcoPI":[558488],"PO":["565247"]},"205388":{"abstract":"The project examines novel services built on top of public cloud<br\/>infrastructure to enable cost-effective high-performance computing.<br\/>The PIs will explore the on-demand, elastic, and configurable features of<br\/>cloud computing to complement the traditional supercomputer\/cluster<br\/>platforms. More specifically, this research aims to assess the efficacy<br\/>of building dynamic cloud-based clusters leveraging the configurability<br\/>and tiered pricing model of cloud instances. The scientific value of this<br\/>proposal lies in the novel use of untapped features of cloud computing<br\/>for HPC and the strategic adoption of small, cloud-based clusters for<br\/>the purpose of developing\/tuning applications for large supercomputers.<br\/><br\/>Through this research, the PIs expect to answer key research questions<br\/>regarding: (1) automatic workload-specific cloud cluster configuration,<br\/>(2) cost-aware and contention-aware data and task co-scheduling,<br\/>and (3) adaptive, integrated cloud instance provisioning and job<br\/>scheduling, plus workload aggregation for cloud instance rental cost<br\/>reduction. If successful, this research will result in tools that<br\/>adaptively aggregate, configure, and re-configure cloud resources for<br\/>different HPC needs, with the purpose of offering low-cost R&D<br\/>environments for scalable parallel applications.","title":"CSR: Small: Collaborative Research: Enabling Cost-Effective Cloud HPC","awardID":"1318564","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["553865","549981",549981],"PO":["565255"]},"204750":{"abstract":"The domain name system (DNS) protocol plays a significant role in operation of the Internet by enabling the bi-directional association of domain names with IP addresses. It is also increasingly abused by malware, particularly botnets, by use of: (1) automated domain generation algorithms for rendezvous with a command-and-control (C&C) server, (2) DNS fast flux as a way to hide the location of malicious servers, and (3) DNS as a carrier channel for C&C communications.<br\/>This project explores the development of a scalable, hierarchical machine-learning stack, called HIMALAYAS, which specializes in algorithms for automatically mining DNS data for malware activity. In particular, we are interested in isolating both ordered and unordered sets of malware domain groups whose access patterns are temporally and logically correlated. <br\/><br\/>HIMALAYAS performs a task of increasing complexity at each level ? starting from scalable clustering and feature selection at lower levels, to more advanced malware domain subsequence identification algorithms at higher levels. It has multiple benefits, including speed, accuracy, interpretability, and ability to use domain knowledge, which makes it very well suited for malware analysis and related tasks. The analysis by HIMALAYAS should accelerate the identification and takedown of malware domains on the Internet and improve services such as Google SafeSearch. <br\/><br\/>The machine-learning stack developed as part of the HIMALAYAS project has broader application to many important data mining problems, e.g., in financial data analysis, and mining user patterns from web access logs. The project provides opportunities for students to participate in the development and transition of the technology.","title":"TWC: Medium: Collaborative: HIMALAYAS: Hierarchical Machine Learning Stack for Fine-Grained Analysis of Malware Domain Groups","awardID":"1314823","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[548314],"PO":["565239"]},"204761":{"abstract":"OpenSSH reveals excerpts from encrypted login sessions. TLS (HTTPS) reveals encrypted PayPal account cookies. DTLS is no better. EAXprime allows instantaneous forgeries. RFID security has been broken again and again. All of these failures of confidentiality and integrity are failures of authenticated ciphers: algorithms that promise to encrypt and authenticate messages using a shared secret key.<br\/><br\/>It is easy to blame many of these security problems on a lack of education: much stronger authenticated ciphers have been in the literature for many years. However, in many cases these stronger authenticated ciphers fail to meet the performance requirements of the applications. Performance is exactly the motivation for RC4 in WEP; EAXprime in the \"Smart Grid\"; HB in RFID; and \"IPsec\" continuing to support unauthenticated encryption.<br\/><br\/>This project is building a new generation of authenticated ciphers that improve efficiency without compromising security and that improve security without compromising efficiency. This work spans seven main topics: more efficient ciphers; more efficient MACs; more efficient forgery rejection; improved protection against side channels; improved protection against misuse and bad luck; improved quantitative security; and improved security proofs. The ultimate objective is to obtain the best possible security subject to a variety of performance constraints specified by cryptographic users.<br\/><br\/>The high-security high-performance authenticated ciphers produced in this project will be directly and straightforwardly usable in cryptographic applications, avoiding the disasters in current applications and finally bringing secure secret-key cryptography from theory to practice.","title":"TWC: Option: Medium: Collaborative: Authenticated Ciphers","awardID":"1314885","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[548342],"PO":["565239"]},"202220":{"abstract":"Functional Reactive Programming, or FRP, is a declarative programming paradigm based on two fundamental abstractions: a continuous (functional) modeling of time-varying behaviors, and a discrete (reactive) calculus of user and process interaction. FRP provides a novel and effective approach to solving problems in which there is a combination of both continuous and discrete entities such as found in computer animation, robotics, control systems, GUIs, and interactive multimedia. FRP?s broader impact is seen in its adoption by several other research projects, and its use in several applications different from those at Yale. The proposed work will strengthen these existing projects, and further broaden the applicability of FRP. The proposed improvements in implementation will make FRP more suitable for compute-intensive applications, such as interactive 3D graphics and real-time audio processing. It will also benefit the modeling and simulation community, which often uses declarative approaches to specifying and solving problems.<br\/><br\/>Previous research at Yale helped to establish the foundations of FRP, and demonstrated its utility in several application domains. Despite this preliminary success, more work is needed to make \"FRP for real.\" That is, to develop a system that facilitates writing natural and concise descriptions of reactive behaviors, responds well enough to satisfy most common real-time constraints, reifies real-world objects as first-class signal functions, runs efficiently through program optimization and parallel execution on multicore architectures, and has been validated in a real-world application domain, specifically audio signal processing. The proposed research will advance the overall FRP methodology in three areas: Language Design (type system extensions to capture resource constraints, a redesign of the mediation between the discrete and continuous, and a better syntax to capture the essence of FRP); Language Implementation (program optimizations, multicore execution, asynchronous sub-processes); and Validation and Testing (with a focus on real-time audio signal processing).","title":"SHF: Medium: Collaborative Research: FRP for Real","awardID":"1302327","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":[541946],"PO":["564588"]},"205740":{"abstract":"In current operating systems, writes to pages that are not in core memory require the process to block until the page can be fetched from the backing store. This project investigates buffering the write to a temporary page in core memory, so as to unblock the process to continue computation, and applying the write asynchronously. Research tasks include study and experimentation with implementation techniques for deferring out-of-core page writes, analysis of how scheduling and other aspects of the operating system may need to be modified in order to realize the full benefits of write deferral, and empirical studies to assess the performance impact of write deferral on a variety of applications.<br\/><br\/>By incorporating non-blocking writes within the operating system, applications can transparently benefit from a performance improvement, without any modification to the application. The potential performance benefits apply to a broad spectrum of computer systems and applications. The project promotes transition of the technology to practice through open source distribution of Linux operating system code implementing the innovations. Educational activities include involvement of undergraduate students and incorporation of project research into courses taught by the PI. Outreach includes recruitment of under-represented minority students for participation in the project.","title":"CSR: Small: Non-blocking Writes","awardID":"1320426","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[550842],"PO":["564778"]},"205861":{"abstract":"A key tool for understanding and engineering Internet backbone is the analysis of packet traces. However, given the increasing backbone speed towards 100Gbps, it is prohibitive to monitor individual flows at all times. This project develops optimal online learning and adaptation strategies for accurate traffic sampling, inference, and detection under hard resource constraints (e.g., limited CPU or memory at routers) and dynamic network\/traffic conditions. Based on theories and techniques in multi-arm bandits, group testing, and compressed sensing, optimal or near-optimal solutions will be developed by exploiting the unique structures of the specific measurement application under study. Challenges addressed include learning from observations with heavy-tailed distributions and long-range dependencies, coping with sparse and\/or imperfect observations, and distributed learning strategies that involve multiple monitors and decision points.<br\/><br\/>If successful, this research will provide fundamental design principles for a flexible traffic measurement infrastructure under the software-defined networking (SDN) paradigm. Reconfigurable measurements based on a learning process can be realized in commodity router\/switches using SDN APIs such as OpenFlow, leading to potential development of new services. As this project examines problems at the intersection of networking and stochastic learning\/optimization, it provides interdisciplinary training to graduate and undergraduate students in a team environment.","title":"NeTS: Small: Beating the Odds in Traffic Measurements\/Detection with Optimal Online Learning and Adaptive Policies","awardID":"1321115","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[551132,551133],"PO":["564993"]},"205872":{"abstract":"This project aims to explore the fundamental architectural considerations involved in designing\/operating wireless networks for fast Machine to Machine (M2M) communication. Current ideas in the M2M space are fundamentally being driven by ``slow M2M'' applications like electricity-monitoring in the Smart Grid with their intellectual foundations coming from the now maturing field of wireless sensor networks. This project advances the field by addressing the high-performance case of industrial automation with tight real-time operating requirements and the demand for very high reliability. To do this, the project will be leveraging new mathematical and conceptual tools developed to understand decentralized control systems as well as modern approaches to doing multiterminal wireless networking that better exploit the full potential of the wireless medium. The techniques used in this project will span networking, control theory, information theory, wireless modeling, signal processing, and circuit implementation.<br\/><br\/>Broadly speaking, the kind of \"Fast M2M\" technology that this project is developing has the potential to help invigorate the agile manufacturing sector of the economy. Easily reconfigurable wireless interconnection in the industrial setting could help high-skill manufacturing where the United States has a potential advantage over low-wage countries. In the course of developing this technology, the project will train students and postdocs in a way that encourages cross-fertilization of ideas between wireless communication, networking, circuit implementation, control theory, and information theory. These ideas will also be incorporated into courses, including new M.Eng. courses aimed at educating technical leaders for industry. This is the kind of non-siloed education that is essential for innovation in the future. The project will also broaden participation in the technical workforce by mentoring female graduate students.","title":"NeTS: Small: Wireless Design for Fast M2M Control","awardID":"1321155","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560234","560235"],"PO":["565303"]},"206731":{"abstract":"The aim of this project is to lay down the foundations of a novel approach to real-time control of networked cyber-physical systems (CPS) that leverages their cooperative nature. Most networked controllers are not implementable over embedded digital computer systems because they rely on continuous time or synchronous executions that are costly to enforce. These assumptions are unrealistic when faced with the cyber-physical world, where the interaction between computational and physical components is multiplex, information acquisition is subject to error and delay, and agent schedules are asynchronous. Even without implementation obstacles, the periodic availability of information leads to a wasteful use of resources. Tuning controller execution to the task at hand offers the potential for great savings in communication, sensing, and actuation. The goal of this project is to bring this opportunity to fruition by combining event- and self-triggered control ideas into a unified approach that inherits the best of both models. The key conceptual novelty is for agents to make promises to one another about their future states and warn each other if they later decide to break them. The information provided by promises allows agents to autonomously determine when fresh information is needed, resulting in an efficient network performance.<br\/><br\/>Networked cyber-physical systems are transforming the way society interacts with the physical world. Advances in this field are extending the range of human capabilities in an increasing number of areas with high societal and economic impact, such as smart energy, intelligent transportation, advanced manufacturing, health technology, and the environment. This project contributes to the science and technology of cyber-physical systems by developing a novel principled approach for networked systems to operate efficiently and cope with the sources of uncertainty present in real-word applications. The potential benefits are real-time operation in a wide range of application domains of cooperative cyber-physical systems with a superior level of efficiency and robustness than currently possible. The project promises to contribute to the training of a new generation of engineering students at UC San Diego with the skills necessary to deal with this type of multi-faceted systems and applications. The plan includes undergraduate student involvement in research, graduate supervision and curriculum development, outreach to high-school students, retention of minorities in STEM disciplines, and broad dissemination activities.","title":"CPS: Breakthrough: Robust Team-Triggered Coordination for Real-Time Control of Networked Cyber-Physical Systems","awardID":"1329619","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[553514],"PO":["564778"]},"206742":{"abstract":"Objective: How much a person should be allowed to interact with a controlled machine? If that machine is safety critical, and if the computer that oversees its operation is essential to its operation and safety, the answer may be that the person should not be allowed to interfere with its operation at all or very little. Moreover, whether the person is a novice or an expert matters. <br\/><br\/>Intellectual Merit: This research algorithmically resolves the tension between the need for safety and the need for performance, something a person may be much more adept at improving than a machine. Using a combination of techniques from numerical methods, systems theory, machine learning, human-machine interfaces, optimal control, and formal verification, this research will develop a computable notion of trust that allows the embedded system to assess the safety of the instruction a person is providing. The interface for interacting with a machine matters as well; designing motions for safety-critical systems using a keyboard may be unintuitive and lead to unsafe commands because of its limitations, while other interfaces may be more intuitive but threaten the stability of a system because the person does not understand the needs of the system. Hence, the person needs to develop trust with the machine over a period of time, and the last part of the research will include evaluating a person's performance by verifying the safety of the instructions the person provides. As the person becomes better at safe operation, she will be given more authority to control the machine while never putting the system in danger.<br\/><br\/>Broader Impacts: The activities will include outreach, development of public-domain software, experimental coursework including two massive online courses, and technology transfer to rehabilitation. Outreach will include exhibits at the Museum of Science and Industry and working with an inner-city high school. The algorithms to be developed will have immediate impact on projects with the Rehabilitation Institute of Chicago, including assistive devices, stroke assessment, and neuromuscular hand control. Providing a foundation for a science of trust has the potential to transform rehabilitation research.","title":"CPS: Synergy: Collaborative Research: Mutually Stabilized Correction in Physical Demonstration","awardID":"1329683","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[553540],"PO":["564728"]},"205532":{"abstract":"Multicore systems-on-a-chip have permeated every segment of the<br\/>digital market, from servers and supercomputers, to desktops and smart<br\/>phone\/mobile devices. Innovative applications continue to emerge that<br\/>integrate user interactivity via mobile devices with the power of<br\/>high-end computation and large-scale storage. These applications tend<br\/>to demonstrate dynamic and diverse execution behaviors, requiring<br\/>close tracking in order to manage resource consumption. Inherent<br\/>application behavior variations and resource requirements, coupled<br\/>with complex interactions due to contention for shared resources,<br\/>present new challenges for efficient, dependable, and sustainable<br\/>advances in computing and information technologies.<br\/><br\/>This project will develop foundational system mechanisms to manage<br\/>individual cores, memory, and power\/energy consumption on<br\/>multicore-based systems, and explore resource allocation policies that<br\/>use these mechanisms. A new online multicore power model will allow<br\/>power and energy tracking at a fine-grain level, combining available<br\/>hardware-based power measurements with event-based modeling and<br\/>attribution of power for shared resources. Accuracy will be improved<br\/>via coarse-grain measurement-triggered online model recalibration. A<br\/>new operating system mechanism, power containers, will be developed to<br\/>allow application-defined boundaries for resource tracking, breaking<br\/>from the traditional thread and process boundary resource tracking in<br\/>state-of-the-art operating systems. Further optimizations will be<br\/>explored to lower the overhead of resource tracking, allowing online<br\/>power accounting to scale to large core and resource counts. Finally,<br\/>new techniques will be developed to enable use of the power containers<br\/>to control and isolate power usage in an application-defined manner.<br\/><br\/>This project will enhance the power protection, energy efficiency, and<br\/>dependability of multicore-based computer systems. The techniques<br\/>developed can be broadly applied to emerging dynamic applications in<br\/>data centers, desktops, and mobile devices. In particular, power<br\/>containers will identify and mitigate (either malicious or<br\/>unintentional) power anomalies (execution that results in unusually<br\/>high power consumption), in both high-end servers and multi-core and<br\/>multi-accelerator smart phones. The success of this project will<br\/>contribute to the long-term sustainability of the world's fast<br\/>evolving digital economy and society.","title":"CSR: Small: Managing Multicore Energy for Emerging Applications and Devices","awardID":"1319353","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["556692","550397"],"PO":["565319"]},"206984":{"abstract":"This project is funded as part of the United States-Israel Collaboration in Computer Science (USICCS) program. Through this program, NSF and the United States - Israel Binational Science Foundation (BSF) jointly support collaborations among US-based researchers and Israel-based researchers. Until recently, processors became faster every year, because basic circuit elements like transistors and wires became both smaller and faster. Around 2005, things changed. Every year, circuits elements continue to become smaller, but they no longer become faster, because they overheat. In response, processor manufacturers now put multiple processors on each chip. Instead of doing one task faster, these multicore architectures do many tasks in parallel. This revolution in computer architecture presents enormous challenges to software designers, who must now structure software to exploit increasing parallelism, not speed.<br\/><br\/>Recently, Intel and IBM announced new multicore architectures with direct hardware support for transactions, a programming abstraction that promises to make parallel software much easier to design. The move to hardware transactions can bring about a fundamental positive change in the way we program multicore machines, and now is the time to understand the implications of such a shift. The proposed research will center around rethinking and redesigning basic synchronization structures such as locks, memory management, and a range of concurrent data structures such as heaps, hash tables, and skip lists, and on how progress guarantees for these data structures interact with issues such as memory management.","title":"BSF:2012171:Progress Guarantees for Hardware Transactional Memory","awardID":"1331141","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":[554181],"PO":["565264"]},"206753":{"abstract":"The objective of this proposal is to develop a distributed algorithmic framework, supported by a highly fault-tolerant software system, for executing critical transmission-level operations of the North American power grid using gigantic volumes of Synchrophasor data. As the number of Phasor Measurement Units (PMU) increases to more than thousands in the next 4-5 years, it is rather intuitive that the current state-of-the-art centralized communication and information processing architecture of Wide-Area Measurement System (WAMS) will no longer be sustainable under such data-explosion, and a completely distributed cyber-physical architecture will need to be developed. The North American Synchrophasor Initiative (NASPI) is currently addressing this architectural aspect by developing new communication and computing protocols through NASPI-net and Phasor Gateway. However, very little attention has been paid so far to perhaps the most critical consequence of this envisioned distributed architecture \"namely\", distributed algorithms, and their relevant middleware. Our primary task, therefore, will be to develop parallel computational methods for solving real-time wide-area monitoring and control problems with analytical investigation of their stability, convergence and robustness properties, followed by their implementation and testing against extraneous malicious attacks using our WAMS-RTDS testbed at NC State. In particular, we will address three critical research problems \"namely\" distributed wide-area oscillation monitoring, transient stability assessment, and voltage stability monitoring.<br\/><br\/>The intellectual merit of this research will be in establishing an extremely timely application area of the PMU technology through its integration with distributed computing and optimal control. It will illustrate how ideas from advanced ideas from numerical methods and distributed optimization can be combined into power system monitoring and control applications, and how they can be implemented via fault-tolerant computing to maintain grid stability in face of catastrophic cyber and physical disturbances.<br\/><br\/>The broader impact of this project will be in providing a much-needed application of CPS engineering to advance emerging research on PMU-integrated next-generation smart grids. Research results will be broadcast through journal publications, jointly organized graduate courses between NC State and University of Illinois Urbana Champagne, conference tutorials and workshops. Undergraduate research for minority engineering students will be promoted via the FREEDM Systems Center, summer internships via Information Trust Institute (UIUC) and RENCI, and middle\/high-school student mentoring through the NCSU Science House program.","title":"CPS: Synergy: Collaborative Research: Distributed Asynchronous Algorithms and Software Systems for Wide-Area Mentoring of Power Systems","awardID":"1329745","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[553574],"PO":["564728"]},"208700":{"abstract":"The Albert Einstein Distinguished Educator Fellowship Program provides a unique professional development opportunity for K-12 educators to inform national STEM policy and improve communication between the STEM education community and national leaders. Albert Einstein Fellows spend eleven months working at the National Science Foundation, bringing extensive knowledge and classroom experience to STEM education programs. In addition, fellows are provided with an extensive program of professional development training during their cohort year. The Albert Einstein Fellows program is run by the non-profit Triangle Coalition for Science and Technology Education on behalf of the Department of Energy Office of Science. Other federal participants in the fellowship program include NASA, NOAA, and the U.S. Congress. In 2013-14, NSF will host seventeen Albert Einstein Fellows.<br\/><br\/>The Albert Einstein Fellows program is designed to provide substantial STEM work experience beyond the confines of the classroom, as well as extensive training in the individual fields of science, technology, and engineering, STEM education policy, and STEM program outcomes. During the eleven-month fellowship, the Triangle Coalition provides programming that supports professional development in three broad goal areas: 1) development of leadership skills; 2) development as a STEM educator; and, 3) addressing grand challenges in STEM education. The Triangle Coalition engages a third-party evaluator to measure the efficacy of the professional development programming and the overall impact of the program. The evaluators will collect and analyze data that addresses the cumulative impact of the Albert Einstein Fellows program upon the participants and STEM programs with which they engage. The analysis will provide insight into fellows' diversity of experiences post-fellowship that can inform program analyses and research into STEM issues such as resource allocation, teacher preparedness, student interest, and minority participation in STEM.<br\/><br\/>The Albert Einstein Distinguished Educator Fellows Program advances knowledge of STEM disciplines and the critical role educators play in advancing STEM learning and career development. The program increases STEM knowledge and pedagogical skills, provides an opportunity for building leadership capabilities as STEM experts, and assists educators with understanding the policy process. The fellowship equips educators to be STEM capacity-builders and problem-solvers for social, economic, and political challenges created or exacerbated by lack of STEM comprehension. The program also encourages broader diversity in STEM by recruiting in demographic sectors (race, ethnicity, location, etc.) that are historically underrepresented.","title":"2013-14 Albert Einstein Distinguished Educator Fellowship Program","awardID":"1341388","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0600","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"1053","name":"GLOB LEARN & OBSER TO BEN ENVI"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0704","name":"Division of EMERGING FRONTIERS IN RES & IN","abbr":"EFRI"},"pgm":{"id":"7633","name":"EFRI RESEARCH PROJECTS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"1359","name":"RES EXP FOR TEACHERS(RET)-SITE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0706","name":"Division of DESIGN & MANUFACTURING INNOV","abbr":"DMI"},"pgm":{"id":"1788","name":"NANOMANUFACTURING"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"1793","name":"MSP-OTHER AWARDS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"1795","name":"ROBERT NOYCE SCHOLARSHIP PGM"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1106","name":"Division of HUMAN RESOURCE DEVELOPMENT","abbr":"HRD"},"pgm":{"id":"1593","name":"PRES AWDS FOR EXCELL IN SCI"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7259","name":"INFORMAL SCIENCE EDUCATION"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7625","name":"REESE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7645","name":"DISCOVERY RESEARCH K-12"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"9199","name":"UNDISTRIBUTED PANEL\/IPA FUNDS"}},{"dir":{"id":"14","name":"Office of OFFICE OF POLAR PROGRAMS                ","abbr":"OPP"},"div":{"id":"1403","name":"Division of ANTARCTIC SCIENCES DIVISION","abbr":"ANT"},"pgm":{"id":"5294","name":"Antarctic Education"}}],"PIcoPI":[559453,559454],"PO":["562491"]},"205554":{"abstract":"The project develops new methodologies for testing complex Cyber-Physical Systems that perform safety-critical tasks in a wide variety of application domains such as automotive, airspace, medical devices and power generation. The primary challenge in these applications lies in the complexity of the physical system, modeled as systems of non-linear Ordinary Differential Equations (ODE) with a large number of state variables, and the interaction of this physical subsystem with a software-based controller. In many industrial applications, these models are not even available in a closed-form representation and only system simulations can be performed. In this project, ideas from optimization and optimal control theory are employed in order to drive the process of state-space exploration for system verification. The theory of robustness metrics for temporal logic specifications is combined with non-smooth optimization theory which results in gradient descent search methods for multi-modal CPS. At a higher level, concrete and symbolic execution techniques are combined to enhance the performance of the search methods. The verification methods can be readily integrated into existing industrial strength simulation environments. The target applications for such verification tools are from the domains of medical and automotive applications.<br\/><br\/>Verification of complex CPS is a challenging problem. Continuous and multiple recalls of medical and automotive products due to software errors across virtually all manufacturers establish the urgency and importance of the problem. This project results in usable verification tools integrated inside existing and widely adopted model-based development platforms. The application focus on the verification of medical and automotive software ultimately helps avoid harmful losses due to errors in these safety-critical systems. The concrete benefit to society is twofold: first, improved system safety and dependability; and, second, reduced development times for new products. The educational aspects of this project revolve around courses that train students on model-based design and verification methods for safety-critical CPS. The educational mission of the project also stresses a \"safety first\" approach to designing CPS wherein specification and verification are taught as integral steps in the design rather than post-design steps. Besides research publications, avenues of dissemination include sharing of software, models, and course materials via cps-vo.org and other publicly accessible websites.","title":"CSR: Small: Collaborative Research: Gray Box Testing of Complex Cyber-Physical Systems Using Optimization and Optimal Control Techniques","awardID":"1319457","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550702"],"PO":["564778"]},"206775":{"abstract":"Objective: How much a person should be allowed to interact with a controlled machine? If that machine is safety critical, and if the computer that oversees its operation is essential to its operation and safety, the answer may be that the person should not be allowed to interfere with its operation at all or very little. Moreover, whether the person is a novice or an expert matters. <br\/><br\/>Intellectual Merit: This research algorithmically resolves the tension between the need for safety and the need for performance, something a person may be much more adept at improving than a machine. Using a combination of techniques from numerical methods, systems theory, machine learning, human-machine interfaces, optimal control, and formal verification, this research will develop a computable notion of trust that allows the embedded system to assess the safety of the instruction a person is providing. The interface for interacting with a machine matters as well; designing motions for safety-critical systems using a keyboard may be unintuitive and lead to unsafe commands because of its limitations, while other interfaces may be more intuitive but threaten the stability of a system because the person does not understand the needs of the system. Hence, the person needs to develop trust with the machine over a period of time, and the last part of the research will include evaluating a person's performance by verifying the safety of the instructions the person provides. As the person becomes better at safe operation, she will be given more authority to control the machine while never putting the system in danger.<br\/><br\/>Broader Impacts: The activities will include outreach, development of public-domain software, experimental coursework including two massive online courses, and technology transfer to rehabilitation. Outreach will include exhibits at the Museum of Science and Industry and working with an inner-city high school. The algorithms to be developed will have immediate impact on projects with the Rehabilitation Institute of Chicago, including assistive devices, stroke assessment, and neuromuscular hand control. Providing a foundation for a science of trust has the potential to transform rehabilitation research.","title":"CPS: Synergy: Collaborative Research: Mutually Stabilized Correction in Physical Demonstration","awardID":"1329891","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[553637,"555644"],"PO":["564728"]},"205565":{"abstract":"Graphs and graph algorithms are fundamental to computer science. Although historically they have not played a major role in traditional scientific computing, their importance is rapidly increasing with the emergence of informatics and data-centric applications. Although many graph analysis tasks are performed sequentially today, problem sizes continue to grow, necessitating the increasing use of parallel computing. Parallel graph algorithms are already being written, but with great effort and limited code reuse. A major issue in current ways of implementing parallel graph algorithms is the lack of performance portability: not only is it often required to reimplement algorithms on different platforms for the best performance, it is frequently also necessary to completely redesign them.<br\/><br\/>To avoid this rewriting and thus increase scientists' productivity, this project will study domain-specific programming languages allowing graph algorithms to be expressed portably, while using compilation techniques that allow the high-level expressions to achieve performance competitive with hand-written, low-level code for these algorithms. Domain-specific languages have already shown benefit in multiple application areas. This project will extend their benefits further in the graph domain, including to more platforms and data representations than in the past. In particular, the project goals include finding abstractions common to the expressions of graph applications on different platforms, as well as between different applications. To demonstrate the effectiveness of these abstractions, the project includes the creation of prototype implementations of graph algorithms for a variety of high-performance computing platforms and the evaluation of the high-level versions of algorithms against comparable low-level versions.","title":"CSR: Small: High-Level Programming Languages and Environments for Scalable Graph Processing","awardID":"1319520","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["562709",550439],"PO":["565255"]},"206786":{"abstract":"This project establishes a new framework for the formal verification of cyber-physical systems. The framework combines the power of logical decision engines and scalable numerical methods to perform safety verification of general nonlinear hybrid systems. The key difficulty with formal verification of hybrid systems is that all scalable modern verification techniques rely heavily on the use of powerful decision procedures. For hybrid systems, one needs to reason about logic formulas over the real numbers with nonlinear functions, which has been regarded as an intractable problem. The project proposes new directions for tackling the core decision problems, with the combined power of logical and numerical algorithms. The research directly leads to the development of practical tools that will push the frontier of verification of realistic cyber-physical systems to a brand new level.<br\/><br\/>This project aims at fundamental research of problems that stand at the core of the design, analysis, and implementation of reliable cyber-physical systems. It combines techniques from logic, numerical analysis, and automated reasoning, and will produce a unifying methodology that is powerful to address main challenges in this field. The techniques developed in this project will significantly enhance the complexity and reliability of the next generations of cyber-physical systems.<br\/><br\/> Cyber-physical systems are ubiquitous in safety-critical applications as diverse as aerospace, automotive, civil infrastructure, energy, manufacturing, and healthcare. Malfunctioning cyber-physical systems can have catastrophic economic and societal consequences. This project will have a broad range of impact in these areas. <br\/>This research aims to significantly enhance the management of complexity and reliability of the next generations of cyber-physical systems, and will broadly impact all the application areas.","title":"CPS: Breakthrough: Rigorous Integration of Decision Procedures and Numerical Algorithms for the Formal Verification of Cyber-Physical Systems","awardID":"1330014","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[553671],"PO":["561889"]},"202199":{"abstract":"Functional Reactive Programming, or FRP, is a declarative programming paradigm based on two fundamental abstractions: a continuous (functional) modeling of time-varying behaviors, and a discrete (reactive) calculus of user and process interaction. FRP provides a novel and effective approach to solving problems in which there is a combination of both continuous and discrete entities such as found in computer animation, robotics, control systems, GUIs, and interactive multimedia. FRP's broader impact is seen in its adoption by several other research projects, and its use in several applications different from those at Yale. The proposed work will strengthen these existing projects, and further broaden the applicability of FRP. The proposed improvements in implementation will make FRP more suitable for compute-intensive applications, such as interactive 3D graphics and real-time audio processing. It will also benefit the modeling and simulation community, which often uses declarative approaches to specifying and solving problems.<br\/><br\/>Previous research at Yale helped to establish the foundations of FRP, and demonstrated its utility in several application domains. Despite this preliminary success, more work is needed to make \"FRP for real.\" That is, to develop a system that facilitates writing natural and concise descriptions of reactive behaviors, responds well enough to satisfy most common real-time constraints, reifies real-world objects as first-class signal functions, runs efficiently through program optimization and parallel execution on multicore architectures, and has been validated in a real-world application domain, specifically audio signal processing. The proposed research will advance the overall FRP methodology in three areas: Language Design (type system extensions to capture resource constraints, a redesign of the mediation between the discrete and continuous, and a better syntax to capture the essence of FRP); Language Implementation (program optimizations, multicore execution, asynchronous sub-processes); and Validation and Testing (with a focus on real-time audio signal processing).","title":"SHF: Medium: Collaborative Research: FRP for Real","awardID":"1302230","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":[541889],"PO":["564588"]},"205235":{"abstract":"The computing revolution began over two thousand years ago with the advent of mechanical devices for calculating the motions of celestial bodies. Sophisticated clockwork automata were developed centuries later to control the machinery that drove the industrial revolution, culminating in Babbage's remarkable design for a programmable mechanical computer. With the electronic revolution of the last century, the speed and complexity of computers increased dramatically. Using embedded computers we now program the behavior of a vast array of electro-mechanical devices, from cell phones and satellites to industrial manufacturing robots and self-driving cars. The history of computing has taught researchers two things: first, that the principles of computing can be embodied in a wide variety of physical substrates from gears to transistors, and second, that the mastery of a new physical substrate for computing has the potential to transform technology. Another revolution is just beginning, one whose inspiration is the incredible chemistry and molecular machinery of life, one whose physical computing substrate consists of synthetic biomolecules and designed chemical reactions. Like the previous revolutions, this \"molecular programming revolution\" will have the principles of computer science at its core. By systematically programming the behaviors of a wide array of complex information-based molecular systems, from decision-making circuitry and molecular-scale manufacturing to biomedical diagnosis and smart therapeutics, it has the potential to radically transform material, chemical, biological, and medical industries. With molecular programming, chemistry will become a major new information technology of the 21st century.<br\/><br\/>This Expeditions-in-Computing project aims to establish solid foundations for molecular programming. Building on advances in DNA nanotechnology, DNA computing, and synthetic biology, the project will develop methods for programmable self-assembly of DNA strands to create sophisticated 2D and 3D structures, dynamic biochemical circuitry based on programmable interactions between DNA, RNA, and proteins, and integrated behaviors within spatially organized molecular systems and living cells. These architectures will provide systematic building blocks for creating programmable molecular systems able to sense molecular input, compute decisions about those inputs, and act on their environment. To manage system complexity and to provide modularity, the project will establish abstraction hierarchies with associated high-level languages for programming structure and behavior, compilers that turn high-level code into lists of synthesizable DNA sequences, and analysis software that can predict the performance of the sequences. This will allow molecular programmers to specify, design, and verify the correctness of their systems before they are ever synthesized in the laboratory. In addition to these software tools, the project will study the theory of molecular algorithms in order to understand the potential and limitations of information-based molecular systems, what makes them efficient at the tasks they can perform, and how they can be effectively designed and analyzed. Putting the products of this fundamental research to the test, the project will pursue real-world applications such as molecular instruments for probing biological systems and programmable fabrication of nanoscale devices.<br\/><br\/>This project will expand the network of scientists and engineers working in molecular programming by building a diverse community of students, teachers, researchers, scientists, and engineers. This community will be fostered through the creation of publicly accessible software tools, courses, textbooks, workshops, tutorials, undergraduate research competitions, and popular science videos to teach the principles and methods of molecular programming and to engage young researchers and the public in this exciting new field. Industrial partnerships with relevant biotechnology and other high-tech companies will ensure fast transfer of knowledge generated into real-world products. Perhaps most importantly, as molecular programming becomes a widespread technology, it has the potential to transform industry with new complex nanostructured materials, to transform chemistry with integrated and autonomous control of reactions, to transform biology with advanced molecular instruments, and to transform health care with more sophisticated diagnostics and therapeutics.","title":"Collaborative Research: Molecular Programming Architectures, Abstractions, Algorithms, and Applications","awardID":"1317653","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[549567,549568],"PO":["565223"]},"206687":{"abstract":"The objective of this project is to research tools to manage uncertainty in the design and certification process of safety-critical aviation systems. The research focuses on three innovative ideas to support this objective. First, probabilistic techniques will be introduced to specify system-level requirements and bound the performance of dynamical components. These will reduce the design costs associated with complex aviation systems consisting of tightly integrated components produced by many independent engineering organizations. Second, a framework will be created for developing software components that use probabilistic execution to model and manage the risk of software failure. These techniques will make software more robust, lower the cost of validating code changes, and allow software quality to be integrated smoothly into overall system-level analysis. Third, techniques from Extreme Value Theory will be applied to develop adaptive verification and validation procedures. This will enable early introduction of new and advanced aviation systems. These systems will initially have restricted capabilities, but these restrictions will be gradually relaxed as justified by continual logging of data from in-service products. <br\/><br\/>The three main research aims will lead to a significant reduction in the costs and time required for fielding new aviation systems. This will enable, for example, the safe and rapid implementation of next generation air traffic control systems that have the potential of tripling airspace capacity with no reduction in safety. The proposed methods are also applicable to other complex systems including smart power grids and automated highways. Integrated into the research is an education plan for developing a highly skilled workforce capable of designing safety critical systems. This plan centers around two main activities: (a) creation of undergraduate labs focusing on safety-critical systems, and (b) integration of safety-critical concepts into a national robotic snowplow competition. These activities will provide inspirational, real-world applications to motivate student learning.","title":"CPS: Synergy: Collaborative Research: Managing Uncertainty in the Design of Safety-Critical Aviation Systems","awardID":"1329341","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[553399,553400],"PO":["564949"]},"205488":{"abstract":"Algorithmic semi-algebraic geometry lies at the heart of many problems in several different areas of computer science and mathematics, including discrete and computational geometry, robot motion planning, geometric modeling, computer-aided design, geometric theorem proving, mathematical investigations of real algebraic varieties, molecular chemistry, constraint databases, etc. <br\/><br\/>Recent breakthroughs in discrete and computational geometry have spurred new research in real algebraic geometry, and there is a new synergy between these two fields. The award funds research that contributes to both areas -- increasing our understanding of real algebraic geometry, and how it impacts discrete and computational geometry. The main new ideas involved include more intricate perturbation schemes of polynomials using infinitesimals, and novel application of the well developed tool from differential topology -- namely, Morse theory, including stratified Morse theory, used in the context of semi-algebraic geometry. The results will potentially have far reaching impact in the study of arrangements in computational geometry, computer graphics, robotics, and even in areas of pure mathematics such as harmonic analysis. In addition, the research aims at developing newer and more efficient algorithms for several extremely important problems in algorithmic semi-algebraic geometry. These include algorithms for computing \"roadmaps\", a crucial ingredient in deciding questions of connectivity of semi-algebraic sets. These improvements will potentially impact the way the vitally important problem of robot motion planning is dealt with currently. <br\/><br\/>All these research objectives are integrated in a broad program of training graduate students and curriculum development. In particular, graduate students are involved in both aspects -- namely, proving theoretical results, as well as practical implementations of algorithms.","title":"AF: Small: Algorithmic and Quantitative Semi-Algebraic Geometry and Applications","awardID":"1319080","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7929","name":"COMPUTATIONAL GEOMETRY"}}],"PIcoPI":[550244],"PO":["565157"]},"205257":{"abstract":"This project envisions the future of scientific exploration as a collaborative endeavor between human scientists and autonomous robotic systems. The key challenge to materializing this vision lies in combining the expert knowledge of the scientist with the optimization capabilities of the autonomous system. The scientist brings specialized knowledge and experience to the table, while the autonomous system is capable of processing and evaluating large quantities of data. This research leverages these complementary strengths to develop a collaborative system capable of guiding scientific exploration and data collection by integrating input from scientists into an autonomous learning and planning framework. This is achieved by combining probabilistic planning with inverse reinforcement learning to integrate human input and prior knowledge into a unified optimization framework in the context of scientific exploration. The project team is validating the approach in the challenging domain of autonomous underwater ocean monitoring. This domain is particularly well suited for the testing of human-robot collaboration due to the limited communication available underwater and the necessary supervised autonomy capabilities. By integrating feedback from the human user into an algorithmic planning framework, the goal is to improve the efficiency of scientific data collection and gather data about phenomena that were previously outside the reach of scientific investigation. The use of autonomous vehicles for scientific data collection is becoming increasingly prominent; however, the research community lacks a foundational understanding of the interactions between scientists and autonomous vehicles. This work focuses on principled methods for integrating human input into algorithmic optimization techniques moving towards the goal of supervised autonomy for robots.<br\/><br\/>This project has the potential to change the way scientific data are collected through the development of a foundational framework for human-robot scientific collaboration. Such a framework is expected to have broad implications throughout the fields of human-robot interaction and artificial intelligence. The proposed research is being integrated into the robotics and computer science curriculum at both the graduate and undergraduate levels. It is also being utilized for K-12 robotics outreach programs in Los Angeles. The algorithms created in this research are transitioned to field tests and operations via ongoing collaborations with the Monterey Bay Aquarium Research Institute (MBARI) and the Southern California Coastal Ocean Observing System (SCCOOS).","title":"NRI: Small: Collaborative Planning for Human-robot Science Teams","awardID":"1317815","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":["560335"],"PO":["564069"]},"205378":{"abstract":"Field-programmable gate arrays (FPGAs) represent an important computing infrastructure which must be protected from attackers. They are used in a wide variety of applications, including networking routers, satellites, military equipment, and automobiles, among others. The storage of FPGA programming information in memory external to the device creates a natural security weakness which, to date, has primarily been addressed via bitstream encryption. Recent work has shown that bitstream encryption is not impervious to attack and, with sufficient effort, the logical function of some or all of an FPGA design can be determined from a bitstream. This work systematically investigates advanced attacks on FPGA designs and, more importantly, develops sound countermeasures against FPGA design manipulations by determined attackers. To eliminate weaknesses, FPGA security is addressed from a new angle: the use of hardware obfuscation to make the true functionality of an FPGA design nearly indecipherable even if the entire logic-level design can be determined by bitstream reverse engineering. These questions are addressed by first developing a series of search-based computer-aided design tools which can identify security primitives (e.g. crypto primitives) in FPGA design logic-level netlists. As a result of this work, a series of automated tools which allow FPGA circuit designers to obscure the functionality of their subcircuits will be developed. These tools will make malicious design modification significantly more difficult or impossible.","title":"TWC: Small: New Directions in Field Programmable Gate Arrays (FPGA) Security","awardID":"1318497","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[549951,549952],"PO":["565327"]},"208425":{"abstract":"As the era of computer architectures dominated by serial processors comes to a close, the convergence of several unprecedented changes in processor design has produced a broad consensus that much of the essential software infrastructure of computational science and engineering is utterly obsolete. Math libraries have historically been in the vanguard of software that must be quickly adapted to such design revolutions because they are the common, low-level software workhorses that do all the most basic mathematical calculations for many different types of applications. The Sustained Innovation for Linear Algebra Software (SILAS) project updates two of the most widely used numerical libraries in the history of Computational Science and Engineering---LAPACK and ScaLAPACK, (abbreviated Sca\/LAPACK)---enhancing and hardening them for this ongoing revolution in processor architecture and system design. SILAS creates a layered package of software components, capable of running at every level of the platform deployment pyramid, from the desktop to the largest supercomputers in the world. It achieves three complementary objectives: 1) Wherever possible, SILAS delivers seamless access to the most up-to-date algorithms, numerical implementations, and performance, by way of Sca\/LAPACK programming interfaces that are familiar to many computational scientists; 2) Wherever necessary, SILAS makes advanced algorithms, numerical implementations and performance capabilities available through new interface extensions; and 3) SILAS provides a well engineered conduit through which new discoveries at the frontiers of research in these areas can be channeled as quickly as possible to all the application communities that depend on high performance linear algebra. The improvements and innovations included in SILAS derive from a variety of sources. They represent the results (including designs and well tested prototypes) of the PIs' own algorithmic and software research agenda, which has targeted multicore, hybrid and extreme scale system architectures. They are an outcome of extensive and on-going interactions with users, vendors, and the management of large NSF and DOE supercomputing facilities. They flow from cross-disciplinary engagement with other areas of computer science and engineering, anticipating the demands and opportunities of new architectures and programming models. And finally, they come from the enthusiastic participation of the research community in developing and offering enhanced versions of existing Sca\/LAPACK codes.<br\/><br\/>The primary impact of SILAS is a direct function of the importance of the Sca\/LAPACK libraries to many branches of computational science. The Sca\/LAPACK libraries are the community standard for dense linear algebra and have been adopted and\/or supported by a large community of users, computing centers, and HPC vendors. Learning to use them is a basic part of the education of a computational scientist or engineer in many fields and at many academic institutions. Application domains where Sca\/LAPACK have historically been heavily used include (among a host of other examples) airplane wing design, radar cross-section studies, flow around ships and other off-shore constructions, diffusion of solid bodies in a liquid, noise reduction, and diffusion of light through small particles. Moreover, the list of application partners working with SILAS to enhance and transform these libraries for next generation platforms expands this traditional list to include quantum chemistry, adaptive mesh refinement schemes, computational materials science, geophysical flows, stochastic simulation and database research for \"big data\". No other numerical library can claim this breadth of integration with the community. Thus, there is every reason to believe that enhancing these libraries with state of the art methods and algorithms and adapting them for new and emerging platforms (reaching up to extreme scale), will have a correspondingly large impact on the research and education community, government laboratories, and private industry.","title":"SI2-SSI: Collaborative Research: Sustained Innovation for Linear Algebra Software (SILAS)","awardID":"1339822","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0111","name":"Office of CYBERINFRASTRUCTURE","abbr":"OCI"},"pgm":{"id":"8004","name":"Software Institutes"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"8069","name":"CDS&E-MSS"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0309","name":"Division of CHEMISTRY","abbr":"CHE"},"pgm":{"id":"1253","name":"OFFICE OF MULTIDISCIPLINARY AC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":[558550],"PO":["565247"]},"209756":{"abstract":"Mobile (wireless) communication has become an essential information exchange platform for today's enterprise and government organizations. They need to secure mobile devices as they secure wired devices. Today, it is common for these organizations to have multiple external mobile and wireless connections to the outside world to provide high bandwidth and tolerate connection failures. One way to protect the network perimeter is to use border gateways that impose a uniform static policy on network traffic (wired and wireless) entering through its borders and by installing effective security schemes and policies on mobile devices itself. While being simple, such a static policy has many disadvantages and may not provide necessary protection to mobile and wired perimeter. They are (a) unable to react to changes in its external environment, (b) they have physical limitations and differences in trust relationships, and (c) completeness among a non- communicating set of policies is problematic. Therefore, in order to provide perimeter protection policies that react to dynamic changes (quite frequent in mobile perimeter) and respect organizational objectives such as preferential treatment, yet enforce overall security objectives of organizations, requires that individual policies enforced at each border gateway be (a) dynamic and flexible, and (b) be a part of a global policy such that taken together enforce common security objectives in mobile infrastructure. In this proposal we achieve this by a logic-based security framework. Our solution has the potential to improve the security while reducing the management costs.","title":"EAGER: A Logic-Based Security Framework for Wired and Mobile Perimeter","awardID":"1347958","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[562301],"PO":[562302]},"207589":{"abstract":"Proposal #: 13-35263<br\/>PI(s): Hu, Fei<br\/> Qahouq, Jaber Abu; Brown, David A.; Gray, Jeffrey G.; Tsoupikova, Daria<br\/>Institution: University of Alabama ? Tuscaloosa<br\/>Title: MRI\/Dev.: Robot-aided, Cognitive Virtual Rehabilitation for Automatic Physical Training of <br\/> Individuals with Disabilities (iRAPID) <br\/>Project Proposed:<br\/>This project, developing iRAPID, a robot-aided cognitive virtual rehabilitation instrument for automatic physical training of individuals with disabilities, integrates several hardware components (the KineAssist robot, programmable treadmill, biomarkers (sensors) and Xbox kinect sensors) to build an augmented virtual reality animation of the patient. A series of newly developed software tools will support virtual rehab research computations of body balancing and neuro-pattern changes during rehab.<br\/>The instrument will be designed to be suitable for three different cost\/performance levels, with successive levels making use of more comprehensive sensors. Combining the sensors (e.g., functional NearInfraRed and EEG brain imaging) with physical rehab mechanisms (e.e., treadmill) make possible interesting research areas related to the effectiveness of physical rehabilitation training. Hence, iRAPID will be a cognitive, research-oriented rehab instrument with automatic, accurate rehab training progress computation. To enable the stated goals, the system should be capable of recording a wealth of sensor measurements. Advancing the next-generation rehab system, the work<br\/>- Adopts a hierarchical (3 layers), incremental (3 modes) development strategy,<br\/>- Supports computational rehabilitation research, and<br\/>- Adopts evolution-oriented software design.<br\/>Broader Impacts: <br\/>The instrumentation enables research an education of an exciting new field, Cognitive ElectroBiomedical Systems (CEBS), enables the training in CEEBS of two PhD students, and outreach to minorities. CEBS is a trans-disciplinary (TrD) field has distinguished features compared to multi-disciplinary (MuD) and inter-disciplinary (InD). The authors compare these fields to a cake where different ingredients are not easily distinguishable (TrD) giving a new format product, and a plate of salad that still has clear existence of different ingredients ((InD). The PhD training program will have a training structure included TrD\/MuD\/InD curriculum and service learning. The Director of Multicultural Engineering Program (MEP) will assist in involving underrepresented students with summer CAMP and K-12 activities. This development is likely to highly contribute within an EPSCoR jurisdiction.","title":"MRI: Development of Instrument on Robot-aided, Cognitive Virtual Rehabilitation for Automatic Physical Training of Individuals with Disabilities (iRAPID)","awardID":"1335263","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[555863,"513708",555865,555866,555867],"PO":["557609"]},"209437":{"abstract":"Many health conditions are caused by unhealthy lifestyles and can be improved by behavior change. Traditional behavior-change methods (e.g., weight-loss clinics; personal trainers) have bottlenecks in providing expert personalized day-to-day support to large populations for long periods. There is a pressing need to extend the reach and intensity of existing successful health behavior change approaches in areas such as diet and fitness. Smartphone platforms provide an excellent opportunity for projecting maximally effective interventions for behavior change into everyday life at great economies of scale. Smartphones also provide an excellent opportunity for collecting rich, fine-grained data necessary for understanding and predicting behavior-change dynamics in people going about their everyday lives. The challenge posed by these opportunities for detailed measurement and intervention is that current theory is not equally fine-grained and predictive. <br\/><br\/>This interdisciplinary project investigates theory and methods to support fine-grained behavior-change modeling and intervention integrated via smartphone into the daily lives of individuals and groups. Fittle+ develops a new and transformative form of smartphone-delivered Ecological Momentary Intervention (EMI) for improving diet and physical activity. This approach will provide social support and autonomously planned and personalized coaching that builds on methods from mobile sensing, cognitive tutoring, and evidence-based social design. The foundation for this new approach will require new predictive computational theories of health behavior change. Current coarse-grained conceptual theories of individual health behavior change will be refined into fine-grained predictive computational models. These computational models will be capable of tracking moment-by-moment human context, activity, and social patterns based on mobile sensing and interaction data. Using these monitoring capabilities, Fittle+'s computational models will support assessment of, and predictions about, individual users and groups based on underlying motivational, cognitive, and social mechanisms. These predictive models will also be used to plan and optimize coaching actions including detailed diagnostics, individualized goals, and contextually and personally adapted interventions. <br\/><br\/>The collaborative team of researchers works with weight-loss interventionists at one of nation's largest health organization's facility in Hawaii. The team includes expertise in mobile sensing, artificial intelligence, computational cognition, social psychology, human computer interaction, computer tutoring, and measurement theory.","title":"SCH: INT: Collaborative Research: FITTLE+: Theory and Models for Smartphone Ecological Momentary Intervention","awardID":"1346066","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8018","name":"Smart Health & Wellbeing"}}],"PIcoPI":[561428,561429],"PO":["565136"]},"209558":{"abstract":"GENI, the Global Environment for Network Innovations, is a suite of research infrastructure rapidly taking shape in prototype form across the United States. GENI aims to transform experimental research in networking and distributed systems, as well as emerging research into very large social-technical systems, by providing a suite of infrastructure for \"at scale\" experiments in future internets. Nationwide experiments began in Summer 2010. In the intervening three years, GENI has shown rapid growth in adoption by experimental researchers and is now expanding to over 50 GENI-enabled campuses.<br\/><br\/>This project will implement four coordinated thrusts that consolidate important GENI gains and advance the maturity of GENI as it progresses through its \"at scale\" deployment phase. This work positions GENI to be maintainable, expandable, and broadly usable for research and energizes the GENI community to sustain the powerful growth momentum that is carrying GENI forward.<br\/><br\/>* Build and deploy experimenter tools that make GENI easier to use for a growing community. <br\/>* Create processes and institutions to carry GENI into the future. <br\/>* Stretch and test GENI's experimental capabilities. <br\/>* Introduce GENI to industry, research leaders, and students through direct engagements that make GENI relevant in their work by partnering with product developers and service providers and by bringing GENI-based curriculum into college and university classrooms.<br\/><br\/>GENI allows academic and industrial researchers to perform a new class of experiments that tackle critically important issues in global communications networks, issues such as our ability to understand or predict the behavior of complex, large-scale networks, issues associated with the barriers to innovation in the current Internet, and issues related to the resilience and trust needed of our critical infrastructures. GENI is emerging as the prototype of a system for deploying and managing custom combinations of computation and communication. As such it is potentially a model for the next generation of commercial network infrastructure.","title":"GENI D&P Solicitation 4","awardID":"1346688","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[561745],"PO":["564993"]},"208348":{"abstract":"Harvey Mudd College will convene expert computer science (CS) educators to collaboratively document refine, and publish pedagogical content knowledge resources related to ninety topics in computer science. The central goal of the project is to document, validate, and promote CS pedagogical content knowledge, the combined knowledge of both the CS learner and CS content that enables an expert teacher to teach well. Resources developed will enable novice teachers to perform the actions of a more advanced CS teacher, such as incorporating new teaching practices, anticipating students? difficulties, and building upon students' strengths. In addition to this practical contribution, this research will identify open research questions in CS education.","title":"CER: Import PCK: What 10K Novice Teachers Can Learn from Teachers with 10K Hours of Experience","awardID":"1339404","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}}],"PIcoPI":[558338,558339,558340],"PO":["560704"]},"209019":{"abstract":"This project develops a holistic approach to sociotechnical system security that combines innovations in both criminology and engineering\/computer science. We design unified sociotechnical security models that capture how sociotechnical intrusions against social as well as technical aspects of the system (i.e., modeled as hidden sequences of system security states) result in observed hard data such as security sensor alerts and soft data produced by human\/social sensors such as reports about slow machines. <br\/><br\/>To model the social aspect of the sociotechnical security models, (1) we collect extensive social survey data from one specific subpopulation (employees) nested within one sociotechnical system (the university campus); (2) we identify various social and social-psychological factors reducing susceptibility to victimization by computer-focused crime drawing on several criminological and sociological theories; (3) we supplement social survey data with organizational-level data to explore influences of characteristics of organizational units on individual-level employee victimization by computer-focused crimes as well as rates of such cybercrime threats in organizational units. We analyze the collected data by applying unique integrated sociotechnical analytical approaches that encapsulate the adversarial actions and subsequent rewards\/costs using stochastic Markov decisions processes and probabilistic data production models. <br\/><br\/>Our research provides guidelines for other researchers looking to incorporate social science methods and models into engineering systems, with the criminological\/sociological aspect of the study of use to many other researchers. This work will transform how researchers approach the problem of sociotechnical security, in that our holistic view cognizant of both social and technical factors will become widespread.","title":"EAGER: Cybercrime Susceptibility in the Sociotechnical System: Exploration of Integrated Micro- and Macro-Level Sociotechnical Models of Cybersecurity","awardID":"1343430","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[560249,560250,560251,560252],"PO":["565327"]},"210240":{"abstract":"This project funds an October 8, 2013 joint workshop between the Open Networking Foundation (ONF), GENI, and US Ignite communities. The goal of the workshop is to jointly explore the interaction of emerging uses of Software Defined Networking (SDN) in the US Ignite and GENI communities and SDN standardization roadmaps and feature sets. As a result, SDN is likely to become a more powerful tool for GENI network research experimentation, US Ignite pre-commercial applications, and commercial uses. <br\/><br\/>Communication between the communities will facilitate development of SDN standards and applications. Additionally, this project supports the involvement of 20 students in the workshop. US Ignite will seek two types of student participants: 1) students who are familiar with OpenFlow and working in Computer Science systems and networking and GENI or US Ignite projects; and 2) students who have been participating in US Ignite, Mozilla-Ignite, and GENI projects and can share information on application patterns of SDN use. Output of the workshop will be shared with the larger community via a workshop report posted to the US Ignite web site as well as other web pages, wikis and communication mechanisms.","title":"ONF US Ignite Workshop","awardID":"1353550","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[563429],"PO":["564993"]},"202221":{"abstract":"The most significant performance and energy bottlenecks in a computer are<br\/>often caused by the storage system, because the gap between storage device<br\/>and CPU speeds is greater than in any other part of the machine. Big data<br\/>and new storage media only make things worse, because today's systems are<br\/>still optimized for legacy workloads and hard disks. The team at Stony<br\/>Brook University, Harvard University, and Harvey Mudd College has shown that<br\/>large systems are poorly optimized, resulting in waste that increases<br\/>computing costs, slows scientific progress, and jeopardizes the nation's<br\/>energy independence.<br\/><br\/>First, the team is examining modern workloads running on a variety of<br\/>platforms, including individual computers, large compute farms, and a<br\/>next-generation infrastructure, such as Stony Brook's Reality Deck, a<br\/>massive gigapixel visualization facility. These workloads produce combined<br\/>performance and energy traces that are being released to the community.<br\/><br\/>Second, the team is applying techniques such as statistical feature<br\/>extraction, Hidden Markov Modeling, data-mining, and conditional likelihood<br\/>maximization to analyze these data sets and traces. The Reality Deck is<br\/>used to visualize the resulting multi-dimensional performance\/energy data<br\/>sets. The team's analyses reveal fundamental phenomena and principles that<br\/>inform future designs.<br\/><br\/>Third, the findings from the first two efforts are being combined to develop<br\/>new storage architectures that best balance performance and energy under<br\/>different workloads when used with modern devices, such as solid-state<br\/>drives (SSDs), phase-change memories, etc. The designs leverage the team's<br\/>work on storage-optimized algorithms, multi-tier storage, and new optimized<br\/>data structures.","title":"CSR: Medium: Collaborative Research: Workload-Aware Storage Architectures for Optimal Performance and Energy Efficiency","awardID":"1302334","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[541948],"PO":["565255"]},"205862":{"abstract":"Stereoscopic 3D provides an immersive viewing experience and has evoked a tremendous amount of interest. However, stereoscopic content must be properly produced to avoid \"3D fatigue,\" such as blurring vision, eyestrain, and headache. The difficulty in producing stereoscopic content has become a bottleneck that limits its impact. <br\/><br\/>This research develops computational stereoscopic cinematography technologies to assist stereoscopic content production by integrating computer graphics, computer vision, stereoscopic cinematography, and stereo perception. This project explores fundamental and unique problems in computational stereoscopic cinematography: how to edit disparity to deliver a pleasant viewing experience; how disparity interacts with other aspects of stereoscopic content like monocular depth cues and motion; how to optimize disparity during stereoscopic content manipulation and authoring, including warping, collage authoring, and video stabilization; how to coordinate the process of the left and right view with no or unreliable stereo correspondences; and how to extend monocular content manipulation and authoring technologies to stereoscopic content in a principled way. In short, this project solves key problems in computational stereoscopic cinematography and establishes general principles for developing stereoscopic content processing and authoring technologies. <br\/><br\/>This computational stereoscopic cinematography research facilitates high-quality stereoscopic content production, which is critical in sustaining and boosting the impact of stereoscopic 3D in a variety of applications, including virtual reality, human computer interaction, scientific visualization, educational training, and medical rehabilitation. The research results, including the technical writings, the stereoscopic image\/video library, and the code infrastructure, are disseminated through paper publications and online sharing.","title":"CGV: Small: Towards Computational Stereoscopic Cinematography","awardID":"1321119","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[551135],"PO":["564316"]},"205873":{"abstract":"In this Cyberlearning: Transforming Education EXP project, the PIs focus on designing classrooms as collaborative workspaces and learning how such learning environments can foster learning well. They are addressing these issues in high school mathematics classrooms. Learners view videos and read textbooks as homework to begin to learn new content and to deepen their understanding of material already covered. The classroom is \"flipped\"; rather than the teacher lecturing, the teacher plays the role of mentor and facilitator as learners work in the classroom at making sense of what they've read or heard, applying what they are learning, and deepening their understanding and capabilities. The hard work of learning is thus done along their peers as collaborators and the teacher available as a mentor. Based on cognitive and socio-cognitive theories of learning, the PIs have designed an ensemble of strategies and technological tools for promoting learning in such an environment. The tools include video for story telling in support of reflection, electronic pen-and-ink, and intelligent-tutoring type systems, but the innovation is in the integration of these tools into an ensemble. Research addresses how such an ensemble of technologies can foster deeply absorbing and effective learning experiences and important dynamics associated with learning when collaborative workspaces are in place in formal classrooms.<br\/><br\/>Many educators and educational theorists are experimenting with the idea of \"flipped classrooms,\" where learners read or view video lectures outside of class and spend classroom time working on problems together or working on projects, in effect, using classroom time for making sense together of what is being learned, applying what is being learned, deepening understanding, and mastering capabilities. While such an approach holds promise for promoting engagement and learning, little systematic research has been done about how, exactly, to design such learning environments to best promote deep and engaged learning. The PIs in this project address that issue, focusing specifically on students learning high school mathematics.","title":"EXP: Collaborative Research: A cyber-ensemble of inversion, immersion, collaborative workspaces, query and media-making in mathematics classrooms","awardID":"1321162","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1109","name":"Division of RESEARCH ON LEARNING","abbr":"DRL"},"pgm":{"id":"7645","name":"DISCOVERY RESEARCH K-12"}}],"PIcoPI":["91250"],"PO":["562669"]},"204663":{"abstract":"The advent of mobile health (mHealth) technology brings great opportunity to improve quality of life, improve individual and public health, and reduce healthcare costs. Although mHealth devices and applications are proliferating, many challenges remain to provide the necessary usability, manageability, interoperability, availability, security, and privacy. The goal of this project is to engineer the tools for, and lay the scientific foundation of, secure wearable mHealth. In the process, the investigators are developing a general framework for body-area pervasive computing, centered around health-monitoring and health-management applications.<br\/><br\/>The vision is that computational jewelry, in a form like a bracelet or pendant, will provide the properties essential for successful body-area mHealth networks. These devices coordinate the activity of the body-area network and provide a discreet means for communicating with their wearer. Such devices complement the capabilities of a smartphone, bridging the gap between the type of pervasive computing possible with a mobile phone and that enabled by wearable computing.<br\/><br\/>The interdisciplinary team of investigators is designing and developing 'Amulet', an electronic bracelet and a software framework that enables developers to create (and users to easily use) safe, secure, and efficient mHealth applications that fit seamlessly into everyday life. The research is determining the degree to which computational jewelry offers advantages in availability, reliability, security, privacy, and usability, and developing techniques that provide these properties in spite of the severely-constrained power resources of wearable jewelry.","title":"CSR: Large: Collaborative research: Computational Jewelry for Mobile Health","awardID":"1314281","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["553543",548097,548098],"PO":["565255"]},"206732":{"abstract":"The goal of the project is the development of the theory, hardware and computational infrastructure that will enable automatically transforming user-defined, high-level tasks such as inspection of hazardous environments and object retrieval, into provably-correct control for modular robots. Modular robots are composed of simple individual modules; while a single module has limited capabilities, connecting multiple modules in different configurations allows the system to perform complex actions such as climbing, manipulating objects, traveling in unstructured environments and self-reconfiguring (breaking into multiple independent robots and reassembling into larger structures). The project includes (i) defining and populating a large library of perception and actuation building blocks both manually through educational activities and automatically through novel algorithms, (ii) creating automated tools to assign values to probabilistic metrics associated with the performance of library components, (iii) developing a grammar and automated tools for control synthesis that sequence different components of the library to accomplish higher level tasks, if possible, or provide feedback to the user if the task cannot be accomplished and (iv) designing and building a novel modular robot platform capable of rapid and robust self-reconfiguration.<br\/><br\/>This research will have several outcomes. First, it will lay the foundations for making modular robots easily controlled by anyone. This will enrich the robotic industry with new types of robots with unique capabilities. Second, the research will create novel algorithms that tightly combine perception, control and hardware capabilities. Finally, this project will create an open-source infrastructure that will allow the public to contribute basic controllers to the library thus promoting general research and social interest in robotics and engineering.","title":"CPS: Synergy: Collaborative Research: High-Level Perception and Control for Autonomous Reconfigurable Modular Robots","awardID":"1329620","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":[553516],"PO":["564949"]},"202255":{"abstract":"The number of cameras in our lives and the scale of camera systems are continuously increasing as technological advances and falling prices in camera systems create new opportunities and applications. In addition to personal uses, cameras are widely employed in military, public and commercial applications for surveillance and statistics gathering. There are an estimated 30 million surveillance cameras in the U.S. capturing 4 billion hours of footage a week. Besides the traditional use of cameras for surveillance purposes, projects such as Google Glass are driving the development of miniature and low-cost cameras with local processing and communication capabilities. For future camera systems, local intelligence and autonomous collaboration among components will provide the capability to solve more complex tasks, which requires a unifying perspective to simultaneously address the challenges of hardware\/software co-design, real-time operation, high accuracy and self-coordination and self-adaptation in run-time.<br\/><br\/>This project provides a holistic and novel approach for the design, deployment and self-coordination of a set of collaborative embedded smart cameras, with the goal of monitoring large areas with the highest accuracy and smallest latency. One objective is designing synthesis approaches and computing infrastructure for the embedded smart cameras that allow hardware restructuring and systematic swapping of tasks between hardware and software on-the-fly. Another objective is to develop self-configuration approaches to autonomously adapt system behavior and optimally deal with run-time environmental changes, including node failures.<br\/><br\/>This research is expected to enable development of new real-time, fully automated, collaborative and highly accurate camera systems by providing a systematic approach for the design and deployment of such systems, and testing new methods at laboratory and campus scales. Potential applications include smart surveillance systems, multi-camera-based driver assistance systems, assistance in nursing homes, quality control on production lines based on 3D reconstruction, and remote surgery. The project also integrates research with the undergraduate and graduate programs of two institutions and contributes towards increasing the involvement of under-represented groups through the University of Arkansas Engineering Career Awareness Program, Arkansas Louis Stokes Alliance for Minority Participation and George Washington Carver Project, and the WiSE program at Syracuse University. Students from under-represented groups are to be recruited and involved in the design, implementation, and deployment of collaborative multi-camera networks.","title":"CSR: Medium: Collaborative Research: Self-Coordination in Cooperative Smart Camera Networks Incorporating System-On-Chip Reconfiguration","awardID":"1302596","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["561660"],"PO":["564778"]},"206765":{"abstract":"This project focuses on the problem of information acquisition, state estimation and control in the context of cyber physical systems. In our underlying model, a (set of) decision maker(s), by controlling a sequence of actions with uncertain outcomes, dynamically refines the belief about stochastically time-varying parameters of interest. These parameters are then used to control the physical system efficiently and robustly. Here the cyber system collects, processes, and acquires information about the underlying physical system of interest, which is used for its control. The proposed work will develop a new theoretical framework for stochastic learning, decision-making, and control in stochastically-varying cyber physical systems. <br\/><br\/>In order to obtain analytical insights into the structure of efficient design, we first consider the case where the actions of the cyber system only affect the estimate of the underlying physical system. This class of problems arises in the context of (distributed) sensing\/tracking of a physical system in isolation from cyber system control of the physical system's state. Joint state estimation and control for cyber-physical systems will then be considered. Here the most natural first step is to obtain sufficient conditions and\/or special classes of systems where a separated approach to the information acquisition and efficient control is (near) optimal. To demonstrate its utility in practice, our theoretical framework will be applied in the specific context of energy efficient control of data centers and robust control of the smart grid under limited sensing.<br\/><br\/>The intellectual merit of this work will be to develop a theoretical framework for the design of cyber-physical systems including information acquisition, state estimation, and control. In addition, separation theorems for the optimality of separate state estimation and control will be explored.<br\/><br\/>In terms of broader impacts, significant performance improvement of control systems closed over communication networks will impact a wide range of applications for societal benefit, including smart buildings, intelligent transportation systems, energy-efficient data centers, and the future smart-grid. The PIs plan to disseminate the research results widely through conferences and journals, as well as by organizing specialized workshops and conference sessions related to cyber physical systems. The proposed project will train Ph.D. students as well as enrich the curriculum taught by the PIs in communications, stochastic control, and networks. The PIs have a strong track record in diversity and outreach activities, which for this project will include exposure and involvement of high school and undergraduate students, including under-represented minorities and women.","title":"CPS: Synergy: Collaborative Research: Event-Based Information Acquisition, Learning, and Control in High-Dimensional Cyber-Physical Systems","awardID":"1329819","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[553607],"PO":["564728"]},"205445":{"abstract":"Consider a network where each node is either good or bad. The good nodes all run an algorithm that attempts to achieve a specific goal. The hidden set of bad nodes are controlled by an adversary who uses them to thwart this goal.<br\/><br\/>Informally, cost-competitive analysis considers the resource cost of each good node as a function of the total resource cost of the adversary. The goal is to design algorithms that achieve their objectives, while minimizing this cost. Critically, when bad nodes suffer higher costs than good nodes, it is expected that they will eventually cease their attack, as their resources become depleted.<br\/><br\/>Goals of this project are to design cost-competitive algorithms for: communication in wireless networks; tolerating distributed denial-of-service attacks; secure routing in peer-to-peer networks; and enabling nodes to come to agreement.<br\/><br\/>Cost-competitive analysis offers a novel approach for making progress on challenging attacks that cannot be adequately addressed in models that ignore the costs of the attacker. By adopting a more realistic attack model, this approach more accurately quantifies the limits of efficient attack resistance. It is thus expected that a cost-competitive approach will yield more compelling solutions to security challenges in many domains. In particular, this project may have high impact in security challenges involving open environments such as: wireless sensor networks, overlays, reputation systems; and aspects of contemporary problems in industry such as: public cloud computing, reliable versions of MapReduce, and robust distributed lock managers like Google's Chubby lock service.","title":"TWC: Small: Collaborative: Cost-Competitve Analysis - A New Tool for Designing Secure Systems","awardID":"1318880","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["551090"],"PO":["565327"]},"206798":{"abstract":"The objective of this project is to improve the performance of autonomous systems <br\/>in dynamic environments, such as disaster recovery, by integrating perception, planning<br\/>paradigms, learning, and databases. For the next generation of autonomous systems to be<br\/>truly effective in terms of tangible performance improvements (e.g., long-term operations,<br\/>complex and rapidly changing environments), a new level of intelligence must be attained.<br\/>This project improves the state of robotic systems by enhancing their ability to coordinate<br\/>activities (such as searching a disaster zone), recognize objects or people, account for<br\/>uncertainty, and \"most important\" learn, so the system's performance is continuously <br\/>improving. To do this, the project takes an interdisciplinary approach to developing <br\/>techniques in core areas and at the interface of perception, planning, learning, and databases <br\/>to achieve robustness. <br\/><br\/>This project seeks to significantly improve the performance of cyber-physical systems <br\/>for time-critical applications such as disaster monitoring, search and rescue, autonomous <br\/>navigation, and security and surveillance. It enables the development of techniques and <br\/>tools to augment all decision making processes and applications which are characterized<br\/>by continuously changing operating conditions, missions and environments. The project<br\/>contributes to education and a diverse engineering workforce by training students at the<br\/>University of California, Riverside, one of the most diverse research institutions in US <br\/>and an accredited Hispanic Serving Institution. Instruction and research opportunities<br\/>cross traditional disciplinary boundaries, and the project serves as the basis for <br\/>undergraduate capstone design projects and a new graduate course. The software and <br\/>testbeds from this project will be shared with the cyber-physical system research community,<br\/>industry, and end users. The project plans to present focused workshops\/tutorials at major <br\/>IEEE and ACM conferences. The results will be broadly disseminated through the <br\/>project website.<br\/><br\/>For further information see the project website at: <br\/>http:\/\/vislab.ucr.edu\/RESEARCH\/DSLC\/DSLC.php","title":"CPS: Synergy: Distributed Sensing, Learning and Control in Dynamic Environments","awardID":"1330110","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[553702,553703,553704,553705],"PO":["563727"]},"203289":{"abstract":"Spatial navigation and episodic memory are important for daily activity and survival in rodents and primates. Episodic memory consists of collections of past experiences that occurred at a particular time and space, expressed in the form of sequences of temporal or spatial events. Spatial (topographical or topological) representation of the environment is pivotal for navigation. The hippocampus plays a significant role in both spatial representations and episodic memory. However, it remains unclear how the spikes of hippocampal neurons might be used by downstream structures in order to reconstruct the spatial environment without the a priori information of the place receptive fields. Little is known how the hippocampal neuronal representation might be affected by experimental manipulation. Furthermore, cortico-hippocampal interplay and communications are critical for memory consolidation, but many questions about their temporal coordination during sleep remains unresolved. This project proposes a collaborative proposal for studying the neural representation of population codes in rodent hippocampal-cortical circuits. The investigators and collaborators at MGH, MIT and Boston University will integrate innovative computational and experimental approaches to explore the neural codes during various spatial navigation and spatial\/temporal memory tasks as well as during post-behavior sleep---as sleep is critical to hippocampal-dependent memory consolidation. Notably, due to the lack of measured behavior, it remains a great challenge to analyze or interpret sleep-associated hippocampal or cortical spike data. <br\/><br\/>The important questions central to this project are: how do hippocampal (or hippocampal-cortical) neuronal representations vary with respect to species (rat vs. mouse), animal (healthy vs. diseased), experience (novel vs. familiar), environment (one vs. two-dimensional), behavioral state (awake vs. sleep), and task (active vs. passive navigation; spatial working memory vs. temporal sequence memory). The investigators will simultaneously record ensemble spike activity from two or multiple areas of the rodent brain (hippocampus, primary visual cortex, prefrontal cortex, and retrosplenial cortex) under different experimental conditions, and will decipher the population codes using a coherent statistical framework. In light of Bayesian inference (variational Bayes or nonparametric Bayes), innovative unsupervised or semi-supervised learning approaches are developed for mining and visualizing sparse (in terms of both sample size and low firing rate) neuronal ensemble spike data. <br\/><br\/>The outcome of this investigation will improve the understanding of neural mechanisms of hippocampal (or hippocampal-cortical) population coding and its implications in learning, sleep and memory. The derived findings will shed light on the links between the variability of neural responses and the animal behavior (or other external factors), and will provide further insight into memory dysfunction (such as in Alzheimer's disease). Furthermore, this project has broader impacts in developing efficient algorithms to decipher neuronal population spike activity during behavior or sleep, as well as in discovering invariant topological representation of population codes in other cortical areas. In addition to the scientific significance, this proposal bears an educational component for training researchers on advanced quantitative skills in ensemble spike data analysis as well as for disseminating scientific resources (by sharing data and software) to a broad neuroscience community.","title":"CRCNS: Computational Approaches to Uncover Neural Representation of Population Codes in Rodent Hippocampal-Cortical Circuits","awardID":"1307645","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7334","name":"MATHEMATICAL BIOLOGY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0804","name":"Division of EMERGING FRONTIERS","abbr":"EF"},"pgm":{"id":"7275","name":"CROSS-EF ACTIVITIES"}}],"PIcoPI":[544702,"512209"],"PO":["564318"]},"205478":{"abstract":"Recent trends in computing have prompted users and organizations to store an increasingly large amount of sensitive data at third party locations in the cloud outside of their direct control. In order to protect this data, it needs to be encrypted. However, traditional encryption systems lack the expressiveness needed for most applications involving big and complex data. The continued adoption and deployment of cloud computing hinges crucially on the ability to provide cryptographic measures that protect the privacy of our data, and new encryption schemes have the potential to affect how successful this computing paradigm will be. <br\/><br\/>Functional encryption is an emerging paradigm for public-key encryption that enables more fine-grained access control to encrypted data. Functional encryption provides the ability to specify a decryption policy in the ciphertext so that only individuals who satisfy the policy can decrypt, or the ability to associate keywords to a secret key so that it can only decrypt documents containing the keyword. This project investigates methods to obtain more efficient pairings-based functional encryption, and methods to realize new functionalities and more expressive functional encryption schemes.","title":"SaTC: Small: New Challenges in Functional Encryption","awardID":"1319021","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[550219],"PO":["565264"]},"206699":{"abstract":"The objective of this project is to research tools to manage uncertainty in the design and certification process of safety-critical aviation systems. The research focuses on three innovative ideas to support this objective. First, probabilistic techniques will be introduced to specify system-level requirements and bound the performance of dynamical components. These will reduce the design costs associated with complex aviation systems consisting of tightly integrated components produced by many independent engineering organizations. Second, a framework will be created for developing software components that use probabilistic execution to model and manage the risk of software failure. These techniques will make software more robust, lower the cost of validating code changes, and allow software quality to be integrated smoothly into overall system-level analysis. Third, techniques from Extreme Value Theory will be applied to develop adaptive verification and validation procedures. This will enable early introduction of new and advanced aviation systems. These systems will initially have restricted capabilities, but these restrictions will be gradually relaxed as justified by continual logging of data from in-service products.<br\/><br\/>The three main research aims will lead to a significant reduction in the costs and time required for fielding new aviation systems. This will enable, for example, the safe and rapid implementation of next generation air traffic control systems that have the potential of tripling airspace capacity with no reduction in safety. The proposed methods are also applicable to other complex systems including smart power grids and automated highways. Integrated into the research is an education plan for developing a highly skilled workforce capable of designing safety critical systems. This plan centers around two main activities: (a) creation of undergraduate labs focusing on safety-critical systems, and (b) integration of safety-critical concepts into a national robotic snowplow competition. These activities will provide inspirational, real-world applications to motivate student learning.","title":"CPS: Synergy: Collaborative Research: Managing Uncertainty in the Design of Safety-Critical Aviation Systems","awardID":"1329390","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[553429,553430],"PO":["564949"]},"209889":{"abstract":"In this Cyberlearning: Transforming Education EAGER project, the PI proposes a research program and set of events for educators, policy makers, students, designers, researchers, and makers to present, discuss, investigate, and learn about digital fabrication in education. Digital fabrication and \"making\" is a new chapter in the process of bringing powerful ideas and expressive media to schoolchildren. Yet the making that happens in classrooms is usually disconnected from what is known about promoting learning from such making. The PI is organizing a series of activities aimed at better understanding what is needed so that teachers will be better able to use making activities to promote learning and what research and development needs to be done to meet those needs. Activities include (1) a conference as a venue for stakeholders (including educators, students, researchers, and others) to present, discuss, and learn about digital fabrication, the culture around it, and what is known about learning from making; (2) a summer institute that would help teachers deepen their fabrication skills and learn more about learning and assessment; (3) a research summit to share findings, receive feedback, and develop collaborations; and (4) a fellow program to support teachers in activity planning and curriculum development. Throughout, the PI and team will be taking notes and convening discussions with an eye toward formulating a research agenda around promoting learning in classrooms in the context of design and fabrication activities.","title":"EAGER: Infusing Learning Sciences Research into Digital Fabrication and Making in Education","awardID":"1349163","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8020","name":"Cyberlearning: Transforming Ed"}}],"PIcoPI":[562668],"PO":[562669]},"208338":{"abstract":"The Education Development Center, Inc. (EDC) proposes the Massachusetts Exploring Computer Science Partnership (MECSP) in response to NSF's call for projects that will help develop the knowledge base and partnerships needed to catalyze the CS 10K Project. EDC and its partners -- Advanced Math and Science Academy (AMSA) charter school, University of Massachusetts (UMass), Boston?s Broadening Advanced Technological Education Connections (BATEC) program, and the Massachusetts Technology Leadership Council (MassTLC) -- propose to design and implement MECSP. The overarching goal of the partnership is to broaden computer science (CS) education across MA through the expansion of the Exploring Computer Science (ECS) course in high schools. MECSP will build an effective multi-sector collaboration for the ECS course and professional d evelopment (PD) model, building a cadre of Teacher Leaders who prepare other teachers to engage greater numbers and a greater diversity of students in CS education and the workforce. In order to achieve the project outcomes, the project will implement the ECS course statewide in MA, and build a statewide infrastructure with the capacity to sustain that implementation. The infrastructure will include three regional ECS PD Hubs, an online professional learning community, the leveraging of existing statewide CS initiatives through co-sponsored activities, and the engagement of industry representatives of the technology business community directly with teachers and students to help them to understand the value of CS and CS careers to the MA and national economy. EDC, its partners and advisers bring extensive expertise in capacity building, teacher professional development, broadening participation in STEM, and successful public-private sector collaborations; the PIs have a long and successful history of working at the intersection of STEM education and workforce development. <br\/><br\/>MECSP's focus on reaching students from underrepresented populations ensures that it has great potential to address significant equity issues within CS and to expand access to college preparatory CS courses for a diverse population of MA students. MECSP will also have an impact beyond Massachusetts, serving as a model for education-business partnerships that can help meet pressing STEM workforce development needs. Finally, connecting with key national organizations and leaders will ensure that lessons learned within Massachusetts are shared with a national community of stakeholders engaged in efforts to diversify CS and other STEM fields.","title":"Massachusetts Exploring Computer Science Partnership (MECSP)","awardID":"1339300","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7382","name":"Computing Ed for 21st Century"}}],"PIcoPI":[558308,558309,558310],"PO":["561855"]},"210351":{"abstract":"Through billions of years 'computation' using 'survival of the fittest' algorithm, biological systems have naturally become robust and self-adaptive to environmental changes, such as perturbations and adverse situations. Inspired by this phenomenon, this ambitious EAGER project, called BISON, will aim to design robust wireless sensor networks (WSNs), by leveraging optimal results from nature's computation. Functional robustness of living organisms is often attributed to the optimized topological structures of gene regulatory networks (GRNs) that oversee proper behavior of biological cells by means of signal transmissions between the genes. GRNs are adaptive to dynamic changes (e.g., noises and perturbations) and also resilient to the removal or malfunction of nodes. Recognizing that WSNs conceptually operate under similar conditions, the BISON project will exploit intrinsic features of GRNs to improve efficiency and robustness of WSNs.<br\/><br\/>This exploratory project will: (i) establish innovative mapping between GRNs and WSNs by modeling them as graphs, and (ii) apply bio-inspired robust templates in GRNs to design resilient and transmission-efficient WSN topologies. Approaching from biological principles will lead to a novel paradigm shift in robust design of wireless sensor networks with applications in environmental and health monitoring, intrusion detection and target tracking, and vulnerability analysis of cyber-physical systems. The proposed fundamental approach will produce new research in comparing GRN topologies from different organisms under the unifying goal of understanding their information transport robustness.<br\/><br\/>The BISON project aims to transcend the mapping between biological networks and robust WSNs to other networks such as wireless cellular networks, vehicular and social networks. Research findings will be integrated into existing computer science courses, such as advances in sensor networks and fundamentals of wireless networks, at the Missouri University of Science and Technology, thus training diverse students in an interdisciplinary topic. Efforts will also be made to recruit women and minority students, and engage undergraduates to bio-inspired applications. Research outcomes will be disseminated through a dedicated website, publications and presentations in high quality conferences and journals, and through the Complex Networks Dynamics (CoNeD) workshop co-founded by the PI.","title":"EAGER: BISON: Bio-Inspired Solutions for RobustWireless Sensor Networking","awardID":"1355505","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["564777"],"PO":["565303"]},"210274":{"abstract":"The Network and Distributed System Security (NDSS) Symposium is held each February in San Diego, CA. It is a three day conference that brings together innovative and forward thinking members of the Internet community who design, develop, exploit, and deploy the technologies that define network and distributed system security.<br\/><br\/>This grant provides funding to assist US-based graduate and undergraduate students to attend this event. Participation in symposia like the NDSS are a critical part of these students' educational experiences by providing them the opportunity to interact with senior researchers and to be exposed to leading-edge work in the field. The support provided by this grant enable the participation of students who would otherwise be unable to attend the NDSS.","title":"Student Travel Grants for the 2014 Network and Distributed System Security Symposium","awardID":"1354080","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[563508],"PO":["565327"]},"204730":{"abstract":"Wireless connectivity has become the primary way most users access cyberspace. The wide use of the internet on wireless and mobile devices is further encouraged with new services that simultaneously engage and connect a large number of users. As a result, the society at large is quickly getting comfortable with the idea of conducting everyday lives on mobile devices most of which require communicating sensitive and confidential information over the wireless medium. Consequently, secure access to cyberspace necessitates wireless security. Wireless, being an open medium, is more prone to malicious cyber acts as compared to wired connectivity. On the other hand, this medium also presents unique opportunities to provide security guarantees through the interaction of nodes and advanced physical layer techniques. In particular, information theoretic security emerges with design insights that provide guaranteed security against computationally unlimited adversaries. In order to do so, information theory assumes a network of altruistic nodes and looks for fundamental performance limits which usually come with complex interaction and coordination requirements. The premise of this project is that this idealistic set-up can be successfully transformed into a practical one by amalgamating information theory with the theory of incentives in order to provide secure wireless cyber access.<br\/><br\/>Specific research topics being addressed include the development of: (1) mechanisms to incentivize non-altruistic cognitive nodes to participate in information theoretic security protocols; (2) incentive mechanisms for scenarios where all nodes have equal access to spectrum and need confidentiality, even from each other; (3) techniques for providing security to groups of cooperative nodes and the associated trust issues; (4) incentive mechanisms for combating active attacks; (5) strategies for combating colluding adversaries; and (6) mechanisms to ensure that nodes have the incentive to adopt a given security protocol.<br\/><br\/>Broader impacts of this work include: (1) providing secure access to cyberspace via the wireless medium; (2) new design insights for practical security protocols; and (3) amalgamating information theory and game theory via incentive mechanisms. Educational broader impacts include: (1) dissemination of research results in the form of tutorials and short courses; (2) enhancing graduate-student research experiences via a three-university research exchange program; (3) incorporating the research results into graduate and undergraduate communications courses; and (4) recruitment of and mentorship for women in engineering and science.","title":"TWC SBE: Medium: Collaborative: Incentive Compatible Wireless Security","awardID":"1314719","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":["550356"],"PO":["565239"]},"210186":{"abstract":"The overarching goal of the Holistically Application-Aware Multi-dimensional Cognitive Radio (HAMCR) research is to create a set of transformative and holistic technologies that enable substantial growth in the capacity of wireless networks, with support for diverse applications, but without increasing the available spectrum. The project is based on the observation that in today's wireless networks the spectral allocation of resources is either independent of the applications' Quality of Service (QoS) requirements and of the user's perceived QoS, or at best relies on a set of pre-defined fixed priorities. HAMCR maximizes spectrum utilization by trading off the spectral resource allocations of connections for the application-level QoS, while still maintaining acceptable levels of QoS for the individual users of the underlying applications, thus satisfying an increased number of users in times of shortage of spectral resources. Such an application-aware cognitive radio significantly advances spectrum utilization by intelligently supporting the expected traffic growth and by dynamically satisfying the changing demands in traffic. To achieve the above goal, the objectives of the proposed research are to: 1) Develop the fundamental design of middleware to optimize the allocation of the available physical resources by characterizing the applications' parameters and by trading off application-level QoS for spectral resources, while minimizing the degradation to the user-perceived QoS, thus maximizing the spectrum utilization; and 2) Design and implementation of a simulated wireless testbed to assess the feasibility of the application-based resources allocation by evaluating the complexity and the gain of the proposed approach for a number of realistic communication scenarios. The results of this project are expected to forge a new direction in the cognitive radio field, i.e., application-aware cognitive radio.","title":"EAGER: Collaborative Research: Holistically Application-Aware Multi-dimensional Cognitive Radio (HAMCR)","awardID":"1352880","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["438934"],"PO":["557315"]},"205841":{"abstract":"Understanding where and how the more than 40,000 actively routed Autonomous Systems (ASes) in today's Internet interconnect is essential for meaningfully investigating a wide range of critical Internet-related problems such as the vulnerability of the Internet to physical damage. However, much of the published work on Internet topology has focused primarily on discovering the existence of such interconnections (e.g., logical connectivity such as AS-to-AS links or physical connectivity such as router-to-router links). Considerably less attention has been paid to the where and in how many different locations these interconnections have been established. For example, the often-studied AS-level view of the Internet is too coarse as mapping entire ASes to single geographic locations eliminates essential details (e.g. AS-level path diversity). At the same time, the popular router-level view of the Internet is not only too detailed, but also inherently difficult to capture.<br\/><br\/>Intellectual Merit: The main goal of this project is to design, develop and rigorously evaluate techniques to accurately map the geographic location of all the PoPs (Point-of-Presence) of a given target AS and determine the inter-AS connections that are established at each PoP (point of presence) of this AS. A significant fraction of the Internet's physical infrastructure (e.g. routers, switches) is hosted at a relatively small number of physical building complexes, called colocation (or colo) facilities or data centers that can be accurately geo-located. Thus, a core element of this project is the design of new targeted active measurement campaigns specifically developed to map a given colo facility by identifying not only all the PoPs of all the ASes present in that colo facility, but also the corresponding inter-AS connectivity that is visible to active probing at that location. <br\/><br\/>Broader Impact: The inferred PoP-level maps are leveraged to develop a new and improved simulation environment, called cBGP+, that is built on the existing simulator (cBGP) but supports real-world AS path diversity. This new simulator will enable many Internet stakeholders (e.g. ISPs, DHS) to meaningfully assess, evaluate, and predict the inter-AS reachability of the Internet in the presence of certain events or changes (e.g., political unrests or the results of natural or man-made disasters).","title":"NeTS: Small: Towards an Accurate, Geo-Aware, PoP-Level Perspective of the Internet's Inter-AS Connectivity","awardID":"1320977","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[551078,551079,551080],"PO":["565090"]},"205852":{"abstract":"Facilitating workload consolidation and improving server utilization are critical for reducing cost and improving energy-efficiency of modern datacenters. One major challenge for improving utilization is to do so without affecting the quality of service (QoS). On modern servers, various co-located jobs may share critical resources including 1) micro-architectural resources such as last level cache, memory bandwidth, and functional units, etc., and 2) energy resources including grid power and distributed batteries that provide an additional power source especially during high load period. Multiple co-located jobs may contend for shared these resources, causing interference, threatening application QoS or even triggering the circuit breaker and resulting in costly downtime and severe QoS violations.<br\/>This project addresses these challenges by designing a cross-layer system that effectively manages workload consolidation, quality of service (QoS) and various energy sources to optimize for energy efficient computing. Our system spans several layers, including profiler, static compiler, online lightweight monitoring and prediction, runtime execution management, hardware power state control and energy sources control. The compilation technique identifies and inserts markers in contentious code regions in low-priority applications, as well as critical regions in high-priority applications that require QoS protection. The lightweight runtime utilizes the compiler hints, monitors the QoS, power consumption, etc., and adaptively adjusts the pressure applications generate to the shared resources such as shared cache and memory bandwidth, manages battery (dis) charges and hardware power states to guarantee QoS and achieve efficient power shaving.","title":"CSR: Small: Cross-layer HW\/SW solutions towards Energy-Efficient Datacenters","awardID":"1321047","effectiveDate":"2013-10-01","expirationDate":"2014-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["560640","565254"],"PO":["565255"]},"206710":{"abstract":"The electric power grid is a national critical infrastructure that is increasing vulnerable to malicious physical and cyber attacks. As a result, detailed data describing grid topology and components is considered highly sensitive information that can be shared only under strict non-disclosure agreements. There is also increasing need to foster cooperation among the growing number of participants in microgrid-enabled electric marketplace. However, to maintain their economic competitiveness, the market participants are not inclined to share sensitive information about their grid with other participants. Motivated by this need for increased cyber-physical security and economic confidentiality, the project is developing techniques to obfuscate sensitive design information in power system models without jeopardizing the quality of the solutions obtained from such models. Specifically, solution approaches have been developed to hide sensitive structural information in Direct Current (DC) Optimal Power Flow models. These approaches are currently being extended to Alternating Current (AC) Optimal Power Flow models. The project is also developing secure multi-party methods where the market participants collectively optimize the grid operation while only sharing encrypted private sensitive information. Finally, the project is incorporating secure market operations in jointly solving the Optimal Power Dispatch problem without revealing sensitive private information from each participant to other participants. The techniques developed in this project have the potential to broadly impact areas beyond power systems. The general principles developed in the project can be used to mask sensitive information in many problems that can be formulated as a linear or non-linear programming optimization.","title":"CPS: Synergy: Preserving Confidentiality of Sensitive Information in Power System Models","awardID":"1329452","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[553458,553459],"PO":["565239"]},"205500":{"abstract":"Increasingly, all large-scale computing activities, including critical enterprise, financial, and public services, are being transitioned to cloud computing. Cloud computing is based on the technology of virtual machines, which enforces separation between the clients of a cloud service provider. Trust in cloud computing services depends on the security of the virtual machine implementation, of which virtual devices are building blocks. This project designs software tools that can automatically detect flaws in virtual device implementations, within a virtual machine platform. The inaccessible state of physical devices is represented as symbolic values in symbolic execution over the virtual device code, allowing for comparison of virtual and physical device states after subjecting each to a set of test events, without requiring measurements that interfere with the physical device state.<br\/><br\/>By detecting hidden flaws and vulnerabilities in virtual devices, this project reduces the risk of potential attacks that threaten the security of virtual machines and cloud services. The release of software tools as open source allows other researchers and practitioners to build on the results. In addition, the project integrates the research with educational and outreach activities, including a new course on troubleshooting in virtualized environment, recruitment of student participants from underrepresented groups, and participation in community organizations related to information technology and security.","title":"CSR: Small: Detecting Flaws in Virtual Devices by Conformance Checking","awardID":"1319115","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["555591"],"PO":["564778"]},"205742":{"abstract":"The FCC seeks to connect 19 million unserved Americans to broadband by 2020. These rural areas have yet to be fully connected to the Internet due to wireline infrastructure costs which exceed potential revenue opportunities. Even in heavily-populated environments with sufficient wireline infrastructure, capacity issues remain in congested stadiums, disaster recovery zones, and public transportation. Each aforementioned access challenge seemingly is well-suited for wireless mesh networks, but have yet to be fully solved. However, recently, there has been a sizable growth in radios operating in diverse frequency bands (e.g., TV white spaces) with emerging multi-antenna schemes. In this project, multi-user beamforming and diverse frequency bands are leveraged to significantly build upon the flexibility originally sought by mesh networks. In doing so, frequency-agile beamforming mesh (FabMesh) networks seek to truly scale in complexity and cost according to the user population and traffic demand. The work includes three key innovations: (i) client-side, beamforming-aware, and frequency-agile protocols to improve performance and reliability of clients, using contextual information and advanced physical layer techniques, (ii) analysis of spatial reuse and capacity for media access control in mesh networks which leverage multi-user beamforming, and (iii) scalable network deployments which leverage multi-user beamforming along the backhaul and adaptation across multiple frequency bands according to network demand. The project includes a number of hands-on courses for university students at all levels, \"just in time\" pedagogical approaches to thousands of online students, outreach to under-represented students and communities, and key industrial collaborations to accelerate the commercial adoption of FabMesh networks.","title":"NeTS: Small: Collaborative Research: Theory, Algorithms, and Experiments for Frequency-Agile Beamforming Mesh (FabMesh)","awardID":"1320442","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[550846],"PO":["557315"]},"206721":{"abstract":"A hybrid system is a dynamical model that describes the coupled evolution of both continuous-valued variables and discrete patterns. A prime example of such a system is a power electronic circuit, where the semiconductor transistors behave as ideal switches whose switching actions effectively change the circuit topology (i.e., the discrete pattern) that in turn defines the dynamics of currents and voltages (i.e., the continuous variables) and hence the switching actions. There have been two disparate paths to analyzing and designing hybrid systems. One path is to focus on the discrete patterns and achieve scalable, high-level analysis and synthesis. The other path is to pay attention to the dynamics of continuous variables and guarantee low-level properties such as stability and transient performance. The research objective of this proposal is to bridge these approaches by enabling a synergy between the discrete pattern based and continuous variable based approaches. The theory and algorithms developed in course of this work will be applied to digital control of power electronic circuits in order to overcome the scalability and stability issues suffered by existing approaches to power electronics design.<br\/><br\/>The PIs envision that a successful completion of the project will establish a new paradigm in the analysis and design of hybrid systems, and thus contribute to the needs of modern society, such as microgrids and embedded generation, where power electronic circuits are integral parts. The research will be integrated into educational programs through student mentoring and development of courses and laboratory equipment. The PIs will make a special effort to recruit women and minority students. These broader-impact programs will help innovate science and engineering education and prepare for next-generation scientists and engineers.","title":"CPS: Synergy: Collaborative Research: Digital Control of Hybrid Systems via Simulation and Bisimulation","awardID":"1329539","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[553493],"PO":["562984"]},"205632":{"abstract":"Data centers have become both significant consumers of electricity and substantial sources of greenhouse gas emissions, and so a focus on energy-efficient computing has emerged. Until now, the most common approach for improving sustainability of data centers is a ?local? one, e.g., installing rooftop PV panels. This project takes a different, more ?global? approach: it allows data centers to contribute towards improving the sustainability of the electricity grid as a whole, in order to meet data centers' social responsibility as major energy consumers. Interestingly, engaging in such global sustainability efforts will, in turn, provide data centers with new opportunities to gain financial benefits.<br\/><br\/>This project will coordinate data centers with the smart grid through programs such as demand response, which allow the utilities to signal consumers to reduce or increase consumption as needed in order to stabilize the grid and tackle the unpredictability of the renewable energy resources. New resource management algorithms for data centers will be developed to facilitate their participation in demand response and other electricity market programs; and the responsiveness that data centers can provide the smart grid through such participation will be quantified and optimized.<br\/><br\/>This proposal is truly interdisciplinary as it requires a deep understanding not only about data centers and cloud computing but also about electricity markets and the smart grid. In particular, the results will help data centers in terms of both their choice of which electricity market programs to participate in and how to participate in such programs. Additionally, this project will help utility companies in the design of electricity market programs that encourage maximum data center responsiveness to better operate the grid and to reduce the price of electricity.","title":"CSR: Small:Collaborative Research: Data Center Demand Response: Coordinating the Cloud and the Smart Grid","awardID":"1319820","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["564049",550593],"PO":["565255"]},"205753":{"abstract":"This project is focused on the development of new data analysis tools for analyzing personal data archives, namely, the streams of digital data that are routinely recorded reflecting different aspects of individuals' daily lives. Examples of such data include keystrokes, email histories, text messages, social media interactions, microblogs, as well as records of physical activity, diet, and sleep. As sensors become more accurate and cheaper and as data storage becomes effectively zero cost, there is increasing demand for data analysis tools that allow individuals to analyze and gain insight into their own personal data. This research project is developing new statistical machine learning algorithms for analyzing these types of data. The project has a particular focus on the development of models and algorithms to handle personal archives in the form of event time-series data, consisting of logs of time-stamped events involving interactions with other individuals as well as textual and other metadata. Testbed data sets being used to support this research include publicly-available archives of email histories, software development discussions, Twitter microblogs, Wikipedia editing interactions, and physical proximity data. In terms of broader societal impact, the data analysis tools being developed by this project have the potential to significantly transform how individuals analyze their personal data to better understand and monitor their physical and mental health.","title":"III: Small: Statistical Learning Algorithms for Micro-Event Time Series Data","awardID":"1320527","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[550872],"PO":["565136"]},"205874":{"abstract":"Data centers worldwide use approximately 30 billion watts of electricity<br\/>with data centers in the United States using approximately 8 to 10<br\/>billion watts. Power consumption of datacenter systems is expected to<br\/>continue to grow both absolutely and as a percentage of national<br\/>consumption. The goal of the proposed research is to develop massively<br\/>parallel processor arrays that work in conjunction with traditional<br\/>enterprise-class processors to compute datacenter workloads with vastly<br\/>greater efficiency. The proposed research may lead to new applications<br\/>and capabilities that were previously constrained by power dissipation<br\/>or processing throughput.<br\/><br\/>Project participants will propose, model, develop, and characterize<br\/>novel fine-grain many-core architectures, VLSI chip designs, and<br\/>application algorithms for a processor array serving as a co-processor<br\/>or functional unit. The proposed programmable fine-grained many-core<br\/>processor array contains no algorithm-specific hardware and is of a core<br\/>granularity that is very lightly explored in prior work. The array will<br\/>operate inside or near, and in co-ordination with a host<br\/>enterprise-class processor and compute key computational kernels often<br\/>with similar or higher performance than the host processor, but with<br\/>orders of magnitude higher energy efficiency. During kernel computation,<br\/>the host processor could attend to other tasks or enter a low power<br\/>state. The targeted workloads include sorting, regular expression based<br\/>pattern matching, encryption, data compression, video encoding and<br\/>decoding, and other enterprise workloads of high impact that are<br\/>discovered during the course of the research.","title":"SHF:Small:Fine-Grain Many-Core Processor Arrays for Efficient Enterprise Computing","awardID":"1321163","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":[551167],"PO":["366560"]},"206744":{"abstract":"The goal of the project is the development of the theory, hardware and computational infrastructure that will enable automatically transforming user-defined, high-level tasks such as inspection of hazardous environments and object retrieval, into provably-correct control for modular robots. Modular robots are composed of simple individual modules; while a single module has limited capabilities, connecting multiple modules in different configurations allows the system to perform complex actions such as climbing, manipulating objects, traveling in unstructured environments and self-reconfiguring (breaking into multiple independent robots and reassembling into larger structures). The project includes (i) defining and populating a large library of perception and actuation building blocks both manually through educational activities and automatically through novel algorithms, (ii) creating automated tools to assign values to probabilistic metrics associated with the performance of library components, (iii) developing a grammar and automated tools for control synthesis that sequence different components of the library to accomplish higher level tasks, if possible, or provide feedback to the user if the task cannot be accomplished and (iv) designing and building a novel modular robot platform capable of rapid and robust self-reconfiguration.<br\/><br\/>This research will have several outcomes. First, it will lay the foundations for making modular robots easily controlled by anyone. This will enrich the robotic industry with new types of robots with unique capabilities. Second, the research will create novel algorithms that tightly combine perception, control and hardware capabilities. Finally, this project will create an open-source infrastructure that will allow the public to contribute basic controllers to the library thus promoting general research and social interest in robotics and engineering.","title":"CPS: Synergy: Collaborative Research: High-Level Perception and Control for Autonomous Reconfigurable Modular Robots","awardID":"1329692","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["553705",553547],"PO":["564949"]},"202146":{"abstract":"After decades of reliable improvement, processor speeds have<br\/>flattened; for the foreseeable future, computers will add processing<br\/>power by adding more processors, rather than faster ones. This is a<br\/>tremendous challenge for software designers. It's far too easy for<br\/>software using multiple processors to burn up a growing fraction of<br\/>available processing power on coordination overheads like locking,<br\/>rather than actual work. That is, it's far too easy for software to<br\/>not scale: to get slower as processors are added. And an important<br\/>reason for this is simply that scalability is poorly understood. Some<br\/>programs don't scale because they're badly written, but others don't<br\/>scale because their goals are fundamentally impossible to accomplish<br\/>in a scalable way. Programmers lack effective tools for high-level<br\/>reasoning about software scalability limitations, and thus waste<br\/>effort on both impossible and uninteresting tasks.<br\/><br\/>We will produce the first well-grounded and formal reasoning procedure<br\/>for scalability that is flexible enough to apply to an entire<br\/>operating system. Our scalability rule links commutativity and<br\/>scalability. We characterize software interfaces as more or less<br\/>inherently scalable depending on the contexts in which those<br\/>interfaces commute: the more commutative an interface (that is, the<br\/>more often the order of its function calls doesn't matter), the more<br\/>scalable an implementation can be. We prove that a scalable<br\/>implementation exists for any commutative context. This idea can<br\/>already guide software designers in developing easily-scalable<br\/>interfaces, but we will also provide a set of automated tools for<br\/>measuring interface commutativity and for finding implementation<br\/>scalability bottlenecks, and evaluate our ideas in a highly-scalable<br\/>operating system. The resulting tools and ideas could make scalable<br\/>software far easier to design and program, and thus help software<br\/>designers provide the software performance on which so much of our<br\/>economy depends.","title":"CSR: Medium: Collaborative Research: The Commutativity Rule for Scalable Systems Software","awardID":"1301934","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["562011",541752,"562012"],"PO":["565319"]},"206755":{"abstract":"In telerobotic applications, human operators interact with robots through a computer network. This project is developing tools to prevent security threats in telerobotics, by monitoring and detecting malicious activities and correcting for them. To develop tools to prevent and mitigate security threats against telerobotic systems, this project adapts cybersecurity methods and extends them to cyber-physical systems. Knowledge about physical constraints and interactions between the cyber and physical components of the system are leveraged for security. A monitoring system is developed which collects operator commands and robot feedback information to perform real-time verification of the operator. Timely and reliable detection of any discrepancy between real and spoofed operator movements enables quick detection of adversarial activities. The results are evaluated on the UW-developed RAVEN surgical robot.<br\/><br\/>This project brings together research in robotics, computer and network security, control theory and machine learning, in order to gain better understanding of complex teleoperated robotic systems and to engineer telerobotic systems that provide strict safety, security and privacy guarantees. The results are relevant and applicable to a wide range of applications, including telerobotic surgery, search and rescue missions, military operations, underwater infrastructure and repair, cleanup and repair in hazardous environments, mining, as well as manipulation\/inspections of objects in low earth orbit. The project algorithms, software and hardware are being made available to the non-profit cyber-physical research community. Graduate and undergraduate students are being trained in cyber-physical systems security topics, and K-12, community college students and under-represented minority students are being engaged.","title":"CPS: Breakthrough: Secure Telerobotics","awardID":"1329751","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[553580,"559051"],"PO":["561889"]},"206645":{"abstract":"Motivated by the complementary abilities of humans and humanoids, the objective of this proposal is to develop the science and technology necessary for realizing human-robot cooperative object manipulation and transportation. The key concepts that this research seeks to promote are adaptability to human activity under minimal communication, and robustness to variability and uncertainty in the environment, achieved through a layered representation and deliberate processing of the available information. Moreover, this project aims to make maximum use of a minimal set of sensors to plan and control the actions of the robot, while ensuring safe and efficient cooperative transportation. The embodiment of this research is a humanoid co-worker that bears most of the load, when helping a person to carry an object, without requiring excessive communication, or prior training on the part of the human.<br\/><br\/>By introducing concrete methods for human-robot physical collaboration in semi-structured environments, this project enables a unique synergy between robots and humans that has the potential to increase productivity, and reduce accidents and injuries. In doing so, it also promotes the advancement of new practical applications of robots in construction, manufacturing, logistics, and home services. By developing open-source, portable algorithms for humanoid robots and mobile manipulators, this effort results in cost and time savings for researchers, developers, educators, and end-users in robotics. Finally, through an aggressive educational and community outreach plan, and by actively engaging K-12 students in an exciting RoboTech Fellows program, this project seeks to increase diversity and attract underrepresented groups to STEM.","title":"NRI: Large: Collaborative Research: Human-robot Coordinated Manipulation and Transportation of Large Objects","awardID":"1328268","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8013","name":"National Robotics Initiative"}}],"PIcoPI":["403839"],"PO":["564316"]},"206777":{"abstract":"The electric power grid is a complex cyber-physical system, whose reliable and secure operation is of paramount importance to national security and economic vitality. There is a growing and evolving threat of cyber-based attacks, both in numbers and sophistication, on the nation's critical infrastructure. Therefore, cyber security \"encompassing attack prevention, detection, mitigation, and resilience\" is critical in today's power grid and the emerging smart grid. The goal of this project is to develop a unified system-theoretic framework and analytical tools for cyber-physical security of power systems, capturing the dynamics of the physical system as well as that of the cyber system. Research tasks include: 1) Development of a methodology for impact analysis that includes systematic identification of worst-case stealthy attacks on the power system's wide-area control and evaluating the resulting consequences in terms of stability violations and performance loss. 2) Development of robust cyber-physical countermeasures, employing a combination of methods from system theory, cyber security, and model-based\/data-driven tools, in the form of domain-specific anomaly detection\/tolerance algorithms and attack-resilient control algorithms. 3) Evaluating the effectiveness of the proposed impact modeling and mitigation algorithms through a combination of simulation and testbed-based evaluations, using realistic system topologies and attack scenarios. The project makes significant contributions to enhance the security and resiliency of the power grid and lays a scientific foundation for cyber-physical security of critical infrastructure. Also, the project develops novel curriculum modules, mentors graduate and undergraduate students including under-represented minorities, leverages industrial collaborations, and exposes high school students to cyber security concepts.","title":"CPS: Synergy: Collaborative Research: A Unified System Theoretic Framework for Cyber Attack-Resilient Power Grid","awardID":"1329915","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7918","name":"CYBER-PHYSICAL SYSTEMS (CPS)"}}],"PIcoPI":[553642,553643,"561186"],"PO":["565239"]},"205578":{"abstract":"Hyperspectral imaging systems play an important role in scientific research, especially in planetary and terrestrial geology, environmental monitoring, military and security surveillance, and mineralogy. With current advances in imaging systems technology, large datasets at higher resolutions are being produced and research on automated analysis of these datasets is becoming critical. The goal of this project is to formulate mathematical models for hyperspectral datasets that capture the types of structure commonly identified by practitioners as informative and leveraged semantically in existing ad-hoc methods. The focus is on models based on wavelet representations for spectral signatures in order to provide features that represent the desired multiscale structural information. The features will leverage the wavelet's multiscale time-frequency analysis properties, and will be tested on several labeling, classification, and retrieval problems from a broad range of application areas that are expected to attract underrepresented groups in engineering. This proposal is centered on the application of the proposed models to hyperspectral signal processing and machine learning. The overall goal is to formulate and study new geometric signal models for high-dimensional data and new performance metrics for parameter estimation to be leveraged by new computationally feasible estimation algorithms that (i) are amenable to compressive signal processing due to the use of geometric structure to capture relevant signal information and (ii) overcome the performance shortcomings observed in existing approaches. The formulation of a semantic model for spectral signatures is expected to increase the acceptance of universal representations in applications where processes driven by ad-hoc rules are commonplace. The project broadens participation of underrepresented groups by considering applications areas that have the potential to appeal to diverse communities and constituencies in order to attract interest from a diverse class of populations underrepresented in engineering. Student researchers will be exposed to collaborators from a diverse set of scientific backgrounds and cultures. Opportunities for undergraduate research and high-school teacher research experience will be offered in this project with a particular emphasis on venues serving groups underrepresented in engineering.","title":"III: Small: Wavelet-Based Representations for Hyperspectral Data Processing and Interpretation","awardID":"1319585","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[550470,550471],"PO":["565136"]},"209934":{"abstract":"This project seeks to simplify the proof of fully homomorphic encryption (FHE) and reduce the computational complexity of the FHE algorithm, motivated by new approaches in lattice theory. If FHE were computationally practical, it would change security practices in cloud computing and storage that would have significant economic and social benefits.","title":"EAGER: Homomorphic Encryption, Ideal Membership, and Fourier Transforms","awardID":"1349908","effectiveDate":"2013-10-01","expirationDate":"2015-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"8060","name":"Secure &Trustworthy Cyberspace"}}],"PIcoPI":[562776,562777],"PO":["565239"]},"206799":{"abstract":"Until now, the cyber component of automobiles has consisted of control algorithms and associated software for vehicular subsystems designed to achieve one or more performance, efficiency, reliability, comfort, or safety goals, primarily based on short-term intrinsic vehicle sensor data. However, there exist many extrinsic factors that can affect the degree to which these goals can be achieved. These factors can be determined from: longer-term traces of in-built sensor data that can be abstracted as triplines, socialized versions of these that are shared amongst vehicle users, and online databases. These three sources of information collectively constitute the automotive infoverse.<br\/><br\/>This project harnesses this automotive infoverse to achieve these goals through high-confidence vehicle tuning and driver feedback decisions. Specifically, the project develops software called Headlight that permits the rapid development of apps that use the infoverse to achieve one or more goals. Advisory apps can provide feedback to the driver in order to ensure better fuel efficiency, while auto-tuning goals can set car parameters to promote safety. Allowing vehicles and such apps to share vehicle data with others and to use extrinsic information results in novel information processing, assurance, and privacy challenges. The project develops methods, algorithms and models to address these challenges.<br\/><br\/>Broader Impact - This project can have significant societal impact by reducing carbon emissions and improving vehicular safety, can spur innovation in tuning methods and encourage researchers to experiment with this class of cyber-physical systems. The active participation of General Motors will strongly facilitate technology transfer. The program has outreach through internships, course material, high school and undergraduate involvement, and through creating an open infrastructure usable by diverse developers.","title":"CPS: Synergy: Collaborative Research: Harnessing the Automotive Infoverse","awardID":"1330118","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[553707,553708],"PO":["565274"]},"199132":{"abstract":"This proposal connects foundational research for multi-robot formations with the development of empowering experiences for women undergraduates in the classroom and beyond. The theoretical nature of the research is complemented by a firm grounding in hardware and computer vision fundamentals, integrated throughout a comprehensive education plan. The PI will develop an understanding of geometric formations of multi-robot systems, such as swarms in both 2- and 3-dimensions. Sensor and communication costs will be integral to modeling and algorithmic considerations, as minimizing power consumption is increasingly important for the design of lightweight and agile robot platforms. The PI will establish mathematical foundations and develop algorithms in three fundamental directions: (1) understanding a formation's structural properties, (2) producing optimal control architectures, and (3) predicting a formation?s internal motions. Developing a unifying theory from both theoretical and applied perspectives will produce a wealth of new directions, such as actuating a formation as if it were a single traditional robot.<br\/><br\/>The research contributions have the potential to significantly impact cutting-edge technology for the control and coordination of multi-robot systems. The PI is junior faculty at Mount Holyoke College, a liberal arts college for women, where a recent growth in enrollments has led to an average of 15 computer science majors a year (surpassing the peak of 2002). She will engage this vibrant community of budding computer scientists through her proposed education plan. Two courses will be developed, designed to simultaneously educate undergraduates through core computer science principles and expose them to exciting research problems challenging the field. Students will have additional opportunities for experiences outside the classroom through highly visible robotics and computer vision projects on campus, producing role models for generations to come. By working closely with the student-run CS Club, the PI will establish a supportive environment that fosters growing interest in technology from traditionally under-represented groups. She will also actively involve students in research by supervising two undergraduates each summer through a compelling research experience.","title":"CAREER: A Rigidity Theory for Multi-Robot Formations","awardID":"1253146","effectiveDate":"2013-10-01","expirationDate":"2018-09-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0302","name":"Division of ASTRONOMICAL SCIENCES","abbr":"AST"},"pgm":{"id":"1045","name":"CAREER: FACULTY EARLY CAR DEV"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[534178],"PO":["564069"]},"207019":{"abstract":"This project is funded as part of the United States-Israel Collaboration in Computer Science (USICCS) program. Through this program, NSF and the United States - Israel Binational Science Foundation (BSF) jointly support collaborations among US-based researchers and Israel-based researchers. The objective of this research project is to collaboratively design efficient algorithms to compute distance structures for analyzing 3D solid models. These structures are essential building blocks for algorithms in numerous application areas, including shape analysis, segmentation, proximity queries, meshing for finite element analysis, pattern recognition, and motion planning, with wide-ranging societal and economic benefits ranging from security to drug design. <br\/><br\/>The proposed approach builds on the collaborating PIs preliminary results that introduced an algorithmic approach that combines lower-envelope methods and massively parallel Graphics Processing Unit (GPU) computations. New algorithms will be developed to compute distance structures directly from the curved surfaces defining CAD models, including the defacto industry standard of Non-Uniform Rational B-Spline (NURBS) surfaces. This problem was previously considered intractable because of the resulting high order surfaces if solved analytically. The proposed GPU-based approach will address issues of speed and robustness by analyzing the curved surfaces directly, instead of using piecewise-linear approximations of the input. The research will encompass both theoretical error analysis of worst-case error and measurement of the approximation error in practice so as to optimally address the speed versus accuracy tradeoff.","title":"BSF:2012362:Parallel GPU Algorithms for Proximity Analysis of Freeforms","awardID":"1331352","effectiveDate":"2013-10-01","expirationDate":"2017-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":[554265],"PO":["565264"]},"205831":{"abstract":"Recent years have witnessed rapid adoption of wireless sensor-actuator networks (WSANs) in process industries. Real-world deployments of industrial standards such as WirelessHART have demonstrated the feasibility to achieve reliable wireless communication in industrial environments. However, existing wireless technologies still face significant challenges in supporting process control applications that impose stringent real-time requirements on network communication. Moreover, optimizing control performance over wireless networks is challenging due to the coupling between control performance and communication delays, as well as inter-dependencies among multiple layers of the network protocol stack. To meet these critical challenges faced by process industries, this project is developing a control-aware network design approach for WSANs. This holistic approach integrates wireless networking, real-time scheduling and non-linear optimization in a unified framework with three novel technologies: (1) an efficient local search approach that leverages real-time scheduling analysis to optimize control performance over wireless networks; (2) an agile multilayer optimization approach that adapts transmission scheduling, routing and sampling rate selection in a hierarchical fashion in response to network changes; (3) a hierarchical network architecture that enables large-scale real-time wireless control networks. The project implements and evaluates the network architecture and protocols using realistic industrial process control applications on physical wireless testbeds through collaboration with Emerson, an industrial leader of the WirelessHART standard.<br\/><br\/>Successful completion of this research will enable a broad range of process control applications with high societal and industrial impacts such as oil refining, petrochemicals and water treatment. Collaboration with industrial partners will lead to real-world deployments and technology transfer to process industries through industrial standards. This research will produce an open-source implementation of the real-time wireless protocol stack, which will further broaden the impacts on research, education and industry.","title":"NeTS: Small: Real-Time Wireless Sensor-Actuator Networks","awardID":"1320921","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560533","560534"],"PO":["565303"]},"202201":{"abstract":"The most significant performance and energy bottlenecks in a computer are<br\/>often caused by the storage system, because the gap between storage device<br\/>and CPU speeds is greater than in any other part of the machine. Big data<br\/>and new storage media only make things worse, because today's systems are<br\/>still optimized for legacy workloads and hard disks. The team at Stony<br\/>Brook University, Harvard University, and Harvey Mudd College has shown that<br\/>large systems are poorly optimized, resulting in waste that increases<br\/>computing costs, slows scientific progress, and jeopardizes the nation's<br\/>energy independence.<br\/><br\/>First, the team is examining modern workloads running on a variety of<br\/>platforms, including individual computers, large compute farms, and a<br\/>next-generation infrastructure, such as Stony Brook's Reality Deck, a<br\/>massive gigapixel visualization facility. These workloads produce combined<br\/>performance and energy traces that are being released to the community.<br\/><br\/>Second, the team is applying techniques such as statistical feature<br\/>extraction, Hidden Markov Modeling, data-mining, and conditional likelihood<br\/>maximization to analyze these data sets and traces. The Reality Deck is<br\/>used to visualize the resulting multi-dimensional performance\/energy data<br\/>sets. The team's analyses reveal fundamental phenomena and principles that<br\/>inform future designs.<br\/><br\/>Third, the findings from the first two efforts are being combined to develop<br\/>new storage architectures that best balance performance and energy under<br\/>different workloads when used with modern devices, such as solid-state<br\/>drives (SSDs), phase-change memories, etc. The designs leverage the team's<br\/>work on storage-optimized algorithms, multi-tier storage, and new optimized<br\/>data structures.","title":"CSR: Medium: Collaborative Research: Workload-Aware Storage Architectures for Optimal Performance and Energy Efficiency","awardID":"1302232","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["543573"],"PO":["565255"]},"210187":{"abstract":"The overarching goal of the Holistically Application-Aware Multi-dimensional Cognitive Radio (HAMCR) research is to create a set of transformative and holistic technologies that enable substantial growth in the capacity of wireless networks, with support for diverse applications, but without increasing the available spectrum. The project is based on the observation that in today's wireless networks the spectral allocation of resources is either independent of the applications' Quality of Service (QoS) requirements and of the user's perceived QoS, or at best relies on a set of pre-defined fixed priorities. HAMCR maximizes spectrum utilization by trading off the spectral resource allocations of connections for the application-level QoS, while still maintaining acceptable levels of QoS for the individual users of the underlying applications, thus satisfying an increased number of users in times of shortage of spectral resources. Such an application-aware cognitive radio significantly advances spectrum utilization by intelligently supporting the expected traffic growth and by dynamically satisfying the changing demands in traffic. To achieve the above goal, the objectives of the proposed research are to: 1) Develop the fundamental design of middleware to optimize the allocation of the available physical resources by characterizing the applications' parameters and by trading off application-level QoS for spectral resources, while minimizing the degradation to the user-perceived QoS, thus maximizing the spectrum utilization; and 2) Design and implementation of a simulated wireless testbed to assess the feasibility of the application-based resources allocation by evaluating the complexity and the gain of the proposed approach for a number of realistic communication scenarios. The results of this project are expected to forge a new direction in the cognitive radio field, i.e., application-aware cognitive radio.","title":"EAGER: Collaborative Research: Holistically Application-Aware Multi-dimensional Cognitive Radio (HAMCR)","awardID":"1352883","effectiveDate":"2013-10-01","expirationDate":"2014-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[563303,563304],"PO":["557315"]},"205622":{"abstract":"The project aims to improve the quality of service and lifetime of real-time<br\/>embedded systems, particularly those implemented on multi-core platforms. In<br\/>contrast with many other quality metrics, such as performance and power<br\/>consumption, reliability is difficult to accurately estimate because it is<br\/>influenced by design decisions, environmental conditions, and process variation<br\/>during integrated circuit fabrication.<br\/><br\/>This project consists of three main technical tasks. (1) Develop a reliability<br\/>modeling and analysis framework that can efficiently and accurately determine<br\/>the impact of design and runtime management decisions on reliability. (2)<br\/>Develop a reliability-driven resource management framework, which includes<br\/>runtime algorithms for assignment and scheduling of real-time tasks to maximize<br\/>system lifetime while keeping soft error rates low, and a lightweight technique<br\/>to adaptively adjust the activation frequency of the algorithms (i.e.,<br\/>overhead). (3) Develop wear state monitoring techniques and data collection<br\/>infrastructure to enable the runtime refinement and validation of system-level<br\/>reliability models that require long-term in-field system deployment.<br\/><br\/>The techniques developed in this project will support the production of more<br\/>reliable and\/or less expensive electronic devices, enabling integrated<br\/>circuits, which are susceptible to wear due to lifetime fault processes to be<br\/>used in special-purpose computers with strict reliability and performance<br\/>requirements. In particular, this project aims to ease the use of multicore<br\/>processors in high-reliability computing applications with deadlines, such as<br\/>automotive, multimedia, and health care applications. These applications have<br\/>historically seen slow adoption of multicore processors, despite their price,<br\/>performance, and power consumption benefits. We believe this is partially due<br\/>to gaps in knowledge of how to control and optimize reliability on such<br\/>systems, some of which this project will fill. The involvement of both industry<br\/>researchers and university students at the undergraduate and graduate level<br\/>will result in a broad dissemination of the research results.","title":"CSR: Small: Collaborative Research: Reliability Driven Resource Management of Multi-Core Real-Time Embedded Systems","awardID":"1319784","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[550572],"PO":["565255"]},"205875":{"abstract":"As the largest man-made complex network, the Internet grows with no central authority. Thousands of small and medium size Autonomous Systems connect individuals, businesses, universities, and agencies while focusing on optimizing their own communication efficiency and economic objectives. Each network is built by operators with different technical expertise and range a from small local organization network to a large transcontinental backbone. This integrated research and education plan aims to develop an Internet Topology Mapping System that will provide an underlay for improved communications in various application domains. The project attempts to provide significant improvements at multiple levels of Internet topology measurements and transforms the resulting measurement data into useful information for modeling and extracting knowledge from the Internet topology. This project: (i) builds upon novel ideas in approaching the challenges in large-scale topology data handling to capture Internet characteristics and dynamics, (ii) provides valuable longitudinal Internet topology measurements and a customizable graph indexing tool for large scale graph databases, (iii) integrates complex network theories to understand and suggest ways to improve the Internet backbone, and (iv) closely integrates K-12, college, and graduate education into its research activities.<br\/><br\/>Intellectual Merit: The motivation of the project is to develop a comprehensive system that will capture the Internet topology at fine granularity and periodically provide snapshots of the Internet backbone. The mapping system will then be utilized to investigate topological characteristics of the Internet and provide an underlay for applications to optimize their communications. Compared to the existing Internet topology measurement platforms, the system will (i) build Internet topology graphs with higher accuracy as the system integrates several mechanisms to efficiently handle large-scale measurement data; (ii) work at higher level of granularity by providing backbone topology maps at link layer; (iii) periodically release annotated network topologies in addition to the raw measurement data so that the community can utilize them in their experiments and optimize network communications; (iv) help in understanding Internet topology dynamics and providing network enhancements; and (v) provide a graph indexing tool to process and analyze large-scale networks.<br\/><br\/>Broader Impacts: Understanding the topological characteristics of the Internet is an important issue for various communities including the government, academia and industry. Network research community depends on such Internet mapping systems to understand characteristics of the Internet so that better protocols and services are developed. Moreover, new network paradigms such as cloud farms and content distribution networks require knowledge of the underlying networks. The mapping system will help these communities to conduct topography analysis and study large-scale characteristics of the Internet. The project integrates research to all levels of education including science projects, seminars, and summer camps for K-12 students and curriculum development and mentorship of college and graduate students. The services developed within the project will be available to researchers and practitioners. Similarly, the developed tools, data, and course material will be available to public via open-source distribution.","title":"Nets: Small: Mapping Internet Backbone as an Underlay for Improved Communications","awardID":"1321164","effectiveDate":"2013-10-01","expirationDate":"2016-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[551169],"PO":["565090"]}}