{"129404":{"abstract":"Cognitive radio networks enable the sharing of the wireless spectrum with licensed users, but impose challenges due to the fluctuating nature of the spectrum as well as the diverse quality-of-service (QoS) requirements. To address these challenges, a spectrum-aware COGnitive radio NETwork (COGNET) based on orthogonal frequency division multiplexing (OFDM) is proposed.<br\/><br\/>In COGNET, five major research directions are investigated: (1) First, a frequency agile, wideband analog\/RF front-end technology is developed, which is robust to non-linearity (RF\/analog IC design). (2) To detect the presence of licensed users, a fast detection scheme is developed by exploiting the spatial diversity inherent to multi-user networks (spectrum sensing), (3) To select the best channel, novel decision methods are proposed that consider channel information, licensed user activities, and application requirements (spectrum decision). (4) A dual-mode spectrum sharing framework is proposed, which enables access to existing networks as well as coordination between cognitive radio users (spectrum sharing). (5) A spectrum mobility management framework is proposed to achieve efficient operations as cognitive users switch between the channels when a licensed user is detected (spectrum mobility). Based on these research topics, a testbed is developed to demonstrate the protocols developed on cognitive radio transceivers.<br\/><br\/>Although COGNET was originally proposed for both infrastructure and ad hoc networks, due to the budget cut, research topics on ad hoc networks (\"cooperative spectrum sensing for COGNET ad-hoc access\" and \"spectrum-adaptive route recovery for COGNET ad hoc access\") will not be investigated.","title":"NeTS-WN: COGNET: Cognitive Radio Networks based on OFDM","awardID":"0721580","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["562752","364722","562754"],"PO":["557315"]},"129525":{"abstract":"Modern wireless computing devices raise privacy concerns by leaking information that can be used to track and profile users. These privacy concerns are inherent to the low-level design of network and link-layer protocols and are, therefore, not addressed by the traditional approach of encrypting messages to ensure that their contents remain confidential. This project studies the question of how to protect user privacy in the context of a future Internet with rich connectivity to these wireless computing devices. The research focuses on designs that accomplish this without sacrificing the requirements for manageability and accountability.<br\/><br\/>The research approach is to study existing systems such as 802.11 to characterize privacy threats and design improved network and link protocols that provide stronger privacy guarantees. Part of the project is to rethink names and addresses in their various forms to limit the disclosure of identity information only to trusted parties This includes names that conceal identity without compromising network functions, such as routing, that rely on them; name discovery and resolution protocols that do not reveal information across system layers.; techniques to detect implicit names exposed by end-points. Finally, the project also explores methods to expose the privacy status to users.<br\/><br\/>Broader Impact: The combination of improving privacy and educating end-users about their privacy risks significantly and justifiably reduces the fears of Internet users. This makes the Internet a more widely accessible resource by allowing users to perform tasks, such as online-shopping, that they may not have been comfortable with before.","title":"Collaborative Research NeTS-FIND: Protecting User Privacy in a Network with Ubiquitous Computing Devices","awardID":"0722004","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["543394","559051"],"PO":["565090"]},"129536":{"abstract":"This project focuses on the investigation, development, and integration of multi-modal and mobilitybased<br\/>sensor networking technologies. In particular, future sensor networking technologies will include<br\/>(i) multi-modal sensing that mixes complex data types such as audio, images or video and (ii) mobilitybased<br\/>sensing, where parts of the sensor network may be dynamic. The objectives of this proposal<br\/>include the study of the following topics:<br\/>Logical Association and Organization Framework: It has been observed that network connectivity via ad<br\/>hoc routing algorithms does not reflect the physical placement of sensors within the environment. The<br\/>inclusion of multi-modal sensing and mobility into sensor networking systems requires logical<br\/>organization ability. This project will focus on develping a multi-layer organization and routing<br\/>mechanism that supports logical associations, allowing for efficient organization of sensor networks in<br\/>application meaningful ways.<br\/>Mobility-based Localization, Organization, and Calibration: Besides actuation capability, mobility opens<br\/>up new ways of effectively coordinating and organizing the sensor network. This subtask explores the<br\/>design and implementation of algorithms that exploit user, coordinated and autonomous mobility for<br\/>robust, mobility-assisted calibration, logical association, and localization.<br\/>This project will be performed in the context of a flexible and extensible sensor networking framework<br\/>called Cascades. Cascades is a Python-based framework combining highly optimized applicationspecific<br\/>code segments, such as video processing or video compression, into a script-based architecture<br\/>that is readily deployable into a sensor network.","title":"NeTS-NOSS: Towards Dynamically Reconfigurable Multimodal Sensing Systems","awardID":"0722063","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["518376","357733"],"PO":["557315"]},"127479":{"abstract":"Proposal 0713483<br\/>\"RI: Learning Structure to Structure Mappings\"<br\/>PI: Thorsten Joachims<br\/>Cornell University<br\/><br\/>ABSTRACT<br\/><br\/>This goal of this proposal is to extend ongoing work on learning with <br\/>structured output spaces in the support-vector-machine (SVM) <br\/>framework. Such structured output spaces arise in problems where the <br\/>prediction is not a univariate response (e.g., yes\/no), but a <br\/>structured object (e.g., a sequence, tree, or alignment). While <br\/>recent work has uncovered how to discriminatively learn prediction <br\/>rules for simple structures with limited interdependencies, research <br\/>is needed to extend these methods to the complex structures needed <br\/>for many applications (e.g., machine translation). This project aims <br\/>to extend the structural SVM framework to such complex structures. <br\/>Specifically, it focuses on the required gains in computational <br\/>efficiency, broader classes of loss functions, and the use of <br\/>unlabeled data to improve statistical efficiency. As done in the <br\/>past, the project plans to make available software implementations of <br\/>the methods developed in the project. These will be made sufficiently <br\/>robust and efficient so as to be suitable for real-world applications <br\/>outside the machine learning research community as well as for <br\/>classroom teaching. The project will apply its results to two <br\/>high-impact areas like protein structure prediction or machine <br\/>translation.","title":"RI: Learning Structure to Structure Mappings","awardID":"0713483","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["531625"],"PO":["491702"]},"129426":{"abstract":"The BehaviorScope project seeks to develop a framework for understanding patterns and behaviors from sensor data and metadata in distributed multimodal sensor nodes. Patterns and behaviors (especially of humans) will be parsed by a hierarchy of probabilistic grammars and other mechanisms into a compact and more descriptive semantic form. These higher-level interpretations of the data will provide the necessary network cognition needed to provide services in many everyday life applications such as assisted living, workplace safety, security, entertainment and more. The project will use a lightweight camera sensor network as its primary platform and will focus on two types of spatio-temporal data processing. At the local sensor's field of view, this research will investigate the design of filters for robustly detecting humans as well as their gestures and postures. At a more macroscopic level, collections of sensors will coordinate to detect longer term patterns of behavior. The expected outcome is a new data interpretation framework that can understand the spatial and temporal aspects of data and respond to them with meaningful services. To collect real data and to demonstrate the developed concepts in practical applications, this work will use assisted living as the driver application. In this context, the developed sensor network will supervise the behaviors of elders living alone at home to generate daily activity summaries, post warnings and alarms when they engage in dangerous activities, and provide a variety of services that increase the autonomy and independence of these individuals.","title":"NeTS-NOSS: Collaborative Research: The BehaviorScope Project: Sensory Grammars for Sensor Networks","awardID":"0721632","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["399674"],"PO":["564777"]},"128106":{"abstract":"The project proposes \"manifest security\" as a new architectural principle for secure extensible systems. Its research objectives are to develop the theoretical foundations for manifestly secure software and to demonstrate its feasibility in practice.<br\/><br\/>Manifest security applies to extensible software platforms, where it addresses two fundamental problems: (1) how to specify policies about what resources an extension may use and how it can handle sensitive data, and (2) how to enforce such policies. The project is developing a novel high-level logical specification language, encompassing both authorization properties for access control and information flow properties to restrict the use of sensitive data. Adherence to the specification is enforced by a combination of static and dynamic methods, and trustworthiness of the code is established by the explicit representation and verification of formal proofs. Such proofs make the security properties manifest.<br\/><br\/>Because extensible systems are in widespread use (for example, in web browsers, office software, media players, games, virtual communities, and operating systems) the concept of manifest security has significant potential for broad impact. Rigorous verification methods based on logic and type theory are increasingly important to the software industry; the project advances the use of these methods to ensure security. Results from the research are released via publications and a software platform for secure browser extension, making advances accessible to researchers and practitioners. Results are being integrated into graduate and undergraduate teaching materials as well as courses at summer schools.","title":"CT-T: Collaborative Research: Manifest Security","awardID":"0715936","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["563479","556654","550615"],"PO":["529429"]},"129448":{"abstract":"This project's driving vision is to provide under-resourced urban communities with cost-effective wireless mesh networks, mobile access, and transformational applications including health sensing. This vision will be realized and test-driven via a deployed experimental wireless mesh network in an under-resourced Houston community with experimental mobile devices distributed to community residents. Residents of the community will be engaged with ethnographically-driven qualitative inquiry and analysis to better understand their needs, usage, and user-perceived performance of the wireless infrastructure. This project presents an unprecedented opportunity to holistically study all components of a wireless system, from the end user to the mesh backhaul.<br\/><br\/>With a multi-disciplinary approach spanning wireless networking, mobile computing, and ethnographic techniques, this project will make fundamental contributions in (i) theory and development of predictable and resilient mesh network services, (ii) design and deployment of usable and energy-efficient mobile access, and (iii) ethnographic evaluation of user impact in under-resourced urban communities.<br\/><br\/>This project will produce new technologies for optimizing wireless mobile computing and understanding the technological needs of under-resourced urban communities. The experimental deployment in an under-resourced and primarily Hispanic Houston community will provide low-cost access to IT for its residents. Its success will demonstrate the possibility to achieve affordable, economically-sustainable, wireless broadband access for all. The project will offer opportunities for minority students in the universities and the served neighborhoods. Our extensive collaboration with community leaders, equipment manufacturers, and health-care providers will help transfer technologies and lessons for future IT deployments.","title":"NeTS-WN: Collaborative Research: Mesh Networks for Under-Served Urban Communities: Engaging Users and Integrating Mobile Access and Health Sensing","awardID":"0721688","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["365970"],"PO":["557315"]},"128238":{"abstract":"Malicious activity on the Internet is a significant threat to both individuals and institutions. Over the past few years, network honeypots have emerged as an important tool for measuring and understanding the details of cyber attacks. The objective of the proposed research is to stimulate the development of next generation Internet security systems and forensic tools based on automated, indepth analysis of malicious activity and malicious software (malware) observed in network honeypots. The research program to achieve these capabilities will address four critical challenges: (1) efficient malware collection, (2) identification of evasion and obfuscation techniques embedded in the malware, (3) full understanding of malware intent and logic, and (4) the full exercise of malware functionality during runtime execution. The technical approach to address these challenges, which is referred to as Informed Malware Execution (IME), is comprehensive in its use of techniques drawn from a variety of disciplines including network security, forensic analysis, static and dynamic program analysis, and binary instrumentation. The broader impacts of this project are that it will enable a deep understanding of malware logic and execution, and lead to more effective, generalized (non-instance-specific) network security. The expected results of this work include research papers describing new malware analysis methods, prototype software for malware collection and analysis, and datasets collected from network honeypots. The project also includes education and outreach activities that will develop course materials on practical aspects of network security, and provide training for graduate students involved in all aspects of the research.","title":"Collaborative Research: CT-T: Logic and Data Flow Extraction for Live and Informed Malware Execution","awardID":"0716570","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["543138"],"PO":["529429"]},"129217":{"abstract":"The InterGridSolve project is developing an environment that will enable scientists to easily harness Grid resources provided by Computational Services Providers (CSPs) ranging from federally funded TeraGrid to commercially available services such as those provided by Amazon Elastic Compute Cloud (EC2). In order to support the Scientific Computing Environments (SCEs) that many scientists use in their work (e.g., Matlab, Octave), and to incorporate flexible computing models, the research is enhancing GridSolve, a pre-existing brokered RPC environment. GridSolve is based on the GridRPC API proposed by the Open Grid Forum (OGF) and uses function handles and sessions to make remote procedure calls on Grid resources. GridSolve includes resource scheduling, execution monitoring and fault tolerance. General purpose data movement mechanisms (i.e., data handles) are being designed and added to GridSolve in order to enable workflow applications. The data handle mechanisms are to be proposed as extensions to the GridRPC API. Tools to enable workflow applications on Grid resources using data handles in GridSolve are being explored, and several classes of workflow applications (such as simple DAGs) are being implemented. <br\/><br\/>Broader Impact: This project will enable computational scientists across multiple domains to use their accustomed SCEs to access Grid resources made available by various service providers, and to run computationally intensive, workflow jobs on these resources.","title":"Collaborative Research: CSR---AES: InterGridSolve: A Virtualized, General Purpose, and Interoperable Grid Computing Environment for Computational Science","awardID":"0720822","effectiveDate":"2007-09-01","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["495745"],"PO":["493916"]},"128249":{"abstract":"Malicious activity on the Internet is a significant threat to both individuals and institutions. Over the past few years, network honeypots have emerged as an important tool for measuring and understanding the details of cyber attacks. The objective of the proposed research is to stimulate the development of next generation Internet security systems and forensic tools based on automated, indepth analysis of malicious activity and malicious software (malware) observed in network honeypots. The research program to achieve these capabilities will address four critical challenges: (1) efficient malware collection, (2) identification of evasion and obfuscation techniques embedded in the malware, (3) full understanding of malware intent and logic, and (4) the full exercise of malware functionality during runtime execution. The technical approach to address these challenges, which is referred to as Informed Malware Execution (IME), is comprehensive in its use of techniques drawn from a variety of disciplines including network security, forensic analysis, static and dynamic program analysis, and binary instrumentation. The broader impacts of this project are that it will enable a deep understanding of malware logic and execution, and lead to more effective, generalized (non-instance-specific) network security. The expected results of this work include research papers describing new malware analysis methods, prototype software for malware collection and analysis, and datasets collected from network honeypots. The project also includes education and outreach activities that will develop course materials on practical aspects of network security, and provide training for graduate students involved in all aspects of the research.","title":"Collaborative Research: CT-T: Logic and Data Flow Extraction for Live and Informed Malware Execution","awardID":"0716612","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["402605"],"PO":["497499"]},"129107":{"abstract":"As modern embedded systems gain more functionality and complexity, there is a need for a novel discipline for their design, development and deployment. In recent years, the idea of the model-based design paradigm is to develop design models and subject them to early analysis, testing, and validation prior to their implementation. Simulation-based testing ensures that a finite number of user-defined system trajectories meet the desired specification. Even though computationally inexpensive simulation is ubiquitous in system design, it suffers from incompleteness, as it is impossible or impractical to test all system trajectories. On the other hand, verification methods enjoy completeness by showing that all system trajectories satisfy the desired property. For embedded hybrid systems with an infinite number of possible behaviors, exhaustive verification seems to be very hard, and simulation-based testing seems to provide no confidence in our system design. In addition to the gap between testing and verification for embedded systems, there is even a more fundamental, and largely unaddressed, challenge. Uncertainty in the environment, errors in physical devices make overall system robustness one of most critical yet least understood challenges in embedded systems. There is a clear intellectual opportunity for laying the scientific foundations and developing methods and algorithms for analyzing and testing the robustness and safety of embedded hybrid systems. This project brings together leading experts in embedded control, hybrid systems, and software monitoring and testing to develop the foundations of a modern framework for testing the robustness of embedded hybrid systems. The central idea that this proposal is centered around is the notion of a robust test, where the robustness of nominal test can be computed and used to infer that a tube of trajectories around the nominal test will yield the same qualitative behavior. By computing the robustness margins of tests, this project explores how to infer how robust each test is, guide subsequent tests, estimate the robustness for the system, as well provide well-defined coverage metrics using finite number of tests. In addition, this project emphasizes cross-cutting, multi-departmental education of graduate students and emphasizes testing and robustness for embedded hybrid systems in relevant electrical engineering and computer science courses. The educational agenda is to expose computer science students to notions of robustness, and control students to software testing algorithms.","title":"CSR--EHS: Robust Testing by Testing Robustness of Embedded Systems","awardID":"0720518","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["553656","526896"],"PO":["561889"]},"128139":{"abstract":"Proposal Number: 0716389<br\/>PI: Rafail Ostrovsky<br\/>Institution: University of California, Los Angeles <br\/>Lead<br\/><br\/>Proposal Number: 0716199<br\/>PI: Brent Waters<br\/>Institution: SRI International<br\/>Sub<br\/><br\/>Proposal Number: 0715739<br\/>PI: Dan Boneh<br\/>Institution: Stanford University<br\/>Sub<br\/><br\/>Proposal Number 0716230<br\/>PI: Dawn Song<br\/>Institution: Carnegie Mellon University<br\/>Sub<br\/><br\/><br\/><br\/>Title: Collaborative Research CT-T: Cryptographic Techniques for Searching and Processing Encrypted Data<br\/><br\/><br\/><br\/><br\/><br\/>In this proposal we consider the question of what constitutes identities in cryptography. Typical examples of identities include your name and your social-security number, or your fingerprint\/iris-scan, or your address, or your (non-revoked) Public-Key coming from some trusted public-key infrastructure. In many situations, however, where you are defines your identity. For example, we know the role of a bank-teller behind a bullet-proof bank window not because he or she shows us her<br\/>credentials but by merely knowing her location. In this proposal, we ask the following question: is it possible to have the \"\"geographical position\"\" of a party take part in defining the set of credentials<br\/>she has? What are the new possibilities in terms of what we can achieve in this setting?<br\/><br\/>First, we propose to consider the central task in this setting, i.e.,<br\/>securely verifying the position of a device. Despite much work in this area, we have preliminary results that show that in the \"\"vanilla\"\" (i.e., standard) model, the above task (i.e., of secure<br\/>positioning) is impossible to achieve.<br\/><br\/>We propose to study the proof of position in the bounded storage model (i.e. where we assume some bound on the total memory of the adversary).<br\/>In this setting, we wish to achieve two tasks: secure positioning, and position-based key exchange. While the question of secure positioning has been asked in the past, no satisfactory answers exist. <br\/><br\/>The second question (of position-based key exchange) has not been asked in the past. We also ask a broader question: whether position-based Secure Multi-Party Computation can be achieved in this setting.","title":"Collaborative Research: CT-T: Cryptographic Techniques for Searching and Processing Encrypted Data","awardID":"0716199","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["521455"],"PO":["529429"]},"134970":{"abstract":"The Free\/Open Source Software (F\/OSS) research community is growing across and within multiple disciplines. This community faces a new and unusual situation. The traditional difficulties of gathering enough empirical data have been replaced by issues of dealing with enormous amounts of freely available public data from many disparate sources (online discussion forums, source code directories, bug reports, OSS Web portals, etc.). Consequently, these data are being discovered, gathered, analyzed, and used to support multidisciplinary research. Many projects are building alternative research infrastructures to support these activities, but these are often autonomous and not coordinated, resulting in overlaps or gaps. At present, no means exist for assembling these data under common access points and frameworks for comparative, longitudinal, and collaborative research across disciplines. Thus, the F\/OSS research community in the United States is, in a sense, working against their own interests. <br\/><br\/>The time is right for a research workshop to identify a national strategy for coordination. Goals of this event include minimizing the development of infrastructure as a venue for conflict (e.g., across disciplines, over data formats, making free riders pay, or rules that limit unconditional access), coping with limited resources, and partnering with international F\/OSS research infrastructure efforts. <br\/><br\/>The vision is for the multi-discipline F\/OSS research community to establish a scholarly commons that provides for communicating, sharing, and building on the ideas, artifacts, tools, and facilities of community participants in an open, globally accessible, and public way. Such infrastructure provides a medium for sharing resources of common interest (e.g., F\/OSS data sets, domain models, tools for processing data in F\/OSS repositories, research pre-prints and publications), common-pool resources (F\/OSS portals like SourceForge), and public goods (scientific knowledge, Internet access and connectivity). <br\/><br\/>Such a F\/OSS scholarly commons may not just emerge spontaneously, though it could emerge in an ad hoc manner whose design and operation does not provide for a reasonably equitable distribution of access, costs, or benefits for community participants. Thus, the ultimate goal of establishing national information infrastructures for multidisciplinary empirical research into F\/OSS development is to do so in a manner that will subsequently enable the formation, integration, and transition to international research infrastructures for empirical studies of F\/OSS.","title":"A Workshop to Establish National and International Research Infrastructures for Multidisciplinary Empirical Science of Free\/Open Source Software","awardID":"0749353","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["535599"],"PO":["388678"]},"133650":{"abstract":"This project will pioneer a technical, social, and aesthetic grammar for fully immersive interactive installations. This project will identify breakthroughs in the grammar of interactivity analogous to the development of cross-cutting in cinema, which transformed cinema from a diversion to a powerful communication medium; or the introduction of hyperlinking to digital texts on the Internet, which transformed reading from a passive linear activity to an interactive nonlinear one. The intellectual advances will include: <br\/>? New systems and technologies for full-body interaction with projected interactive installations that go beyond simple physical cause and effect, including real-time computer vision analysis of viewers? body language, culture and mood; and analysis of large crowds? movements. <br\/>? High-level principles of this medium for effective communication. Communication will be explored in the educational (science themes) and the cultural (art and humanity themes). <br\/>? Human-Computer Interface analysis of immersive interactive media, including a comparison with passive media and studies with psychologists for independent analysis (pending human subjects review). <br\/><br\/>The broader impact is the development of a new medium which is as powerful as cinema, and yet where the viewers remain aware of themselves and the people around them as active participants in a mutually created narrative story. This medium may become the dominant means for education and communication in public institutions as the internet subsumes traditional \"kiosk\" and \"wall text\" installations.","title":"SGER - The Grammar of Immersive Interactive Narrative","awardID":"0742297","effectiveDate":"2007-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":[355388,"387187"],"PO":["424970"]},"134761":{"abstract":"This proposal for a workshop entitled \"EPSCoR Cyberinfrastructure Assessment Workshop\" was submitted July 19, 2007. To address the problem of the \"Cyberinfrastructure (CI) Gap\" between EPSCoR and non-EPSCoR jurisdictions, KY NSF EPSCoR proposes hosting a workshop that will expand on the groundwork developed at previous meetings and will ultimately result in a collaborative plan\/proposal for proactively addressing CI in the EPSCoR jurisdictions. EPSCoR workshop participants will have CI expertise and performed an assessment within their respective jurisdictions to be able to present the current status of CI across the community. The first day of the workshop will consist of presentations by experts in CI from the EPSCoR jurisdictions about the capabilities and needs of the CI in their jurisdictions. Also included will be presentations by experts outside of the EPSCoR community who have set up interstate CI structures, such as networks and grids. The presentations by the outside experts will be focused on practical CI applications. The second day of the workshop will summarize the plans and extract common elements. This will lead to a coordinated plan for EPSCoR jurisdictions to share resources, e.g. a grid of computational resources with the appropriate software and expertise to make it function as a powerful scientific engine, and to provide easy access to other resources such as the NSF Teragrid.<br\/><br\/>Intellectual Merit<br\/>NSF recognizes that developing CI is inherently necessary for the nation to balance its research portfolio and to enhance the intellectual merit of future research. Cyberinfrastructure represents a changing platform for enabling the future of academic research. As this technology evolves, the EPSCoR jurisdictions run the risk of being left behind technically advanced states with robust network connections and sizable investments in high-end computing. In addition, EPSCoR jurisdictions represent diverse populations and a broad range of CI needs and conditions. The plan will position EPSCoR jurisdictions to develop the capabilities needed for future science and educational competitiveness. The results of this workshop can be carried on to the EPSCoR Annual Meeting in Hawaii where additional planning by EPSCoR jurisdiction project directors can formalize planning efforts and will ultimately result in a collaborative plan\/proposal for proactively addressing CI in the EPSCoR jurisdictions.<br\/><br\/>Broader Impacts<br\/>The broader impacts of the workshop include developing an EPSCoR-wide collaborative effort to actively address and shape the jurisdictions' response to the changing nature of academic research. This plan will necessarily include educational and training components, as there is a critical shortage of trained people in the EPSCoR jurisdictions to operate and maintain modern CI. The assessment will include CI needs for tribal and community colleges.","title":"EPSCoR Cyberinfrastructure Assessment Workshop","awardID":"0748366","effectiveDate":"2007-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0112","name":"Office of EPSCoR","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["461236"],"PO":[358098]},"134882":{"abstract":"The 2007 ACM SIGCOMM Conference on Communications Architectures, Protocols and Applications will be held in Kyoto, Japan, from the 27th to the 31st of August of 2007. This conference is the premier technical meeting that examines the state-of-the-art in computer networks and communications. This award will assist approximately 16 United States-based (including Puerto Rico) graduate students as well as approximately 2 U.S.-based under-represented minority (including women) faculty members or faculty members of U.S. institutions that are primarily serving under represented minorities (including women) in attending this meeting. Participation in conferences such as SIGCOMM is an extremely important part of the graduate school experience, as well as an important part of the teaching and research in data networking. It provides the opportunity to interact with more senior researchers and to be exposed to leading edge research in the field. The award enables the participation of students and minority or minority serving faculty members who would otherwise be unable to attend ACM SIGCOMM 2007. For the portion for student support, the travel grant chairs are committed to encouraging the participation of women and under-represented minorities.<br\/><br\/>Intellectual Merit: This project proposes to provide travel support for graduate students, minority, or minority serving faculty members to attend SIGCOMM 2007. This will expose them to new ideas and allow for interaction with other researchers.<br\/><br\/>Broader Impact: This project integrates research and education of students through exposure to the premier technical meeting in computer networks and communications. Students and minority faculty members will have the opportunity to observe high-quality presentation and interact with senior researchers in the field. The proposed student participation will have positive impact on students' interest and the quality of their research, on faculty member's teaching and the quality of their research. Woman and other minority students are encouraged to participate.","title":"Student and Minority Faculty Travel Support for Association for Computing Machinery Special Interest Group on Data Communication 2007 Conference","awardID":"0748970","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[358352],"PO":["565090"]},"133672":{"abstract":"This is a workshop on \"Creativity and Rationale in Design\". Creativity and rationale connote the complementary natures of design: creating new worlds through strokes of innovation versus analyzing the underlying tradeoffs in current artifacts and systems to guide the development of new ones. The workshop premise is that these poles should not be opposed world-views.<br\/><br\/>The workshop is intended as an occasion to identify and synthesize new frameworks and directions, and new research agendas. The workshop goal is to bring together a range of perspectives and approaches, to articulate and develop new research ideas and hypotheses, and to reconsider and reconstruct prior work and results toward new research directions.<br\/><br\/>The workshop will involve thought leaders from four design research communities within the CISE space - each corresponding to a conference series, which nonetheless have had too little constructive interaction: (1) the Designing Interactive Systems Conference, (2) the Creativity and Cognition Conference, (3) the Designing for User Experience Conference, and (4) the Design Science Research in Information Systems and Technology Conference.","title":"CreativeIT Workshop: Creativity and Rationale in Design","awardID":"0742392","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":["549541"],"PO":["424970"]},"131131":{"abstract":"The diverse functions performed by a living cell during her life cycle are controlled and regulated through complicated gene- and protein- interaction networks. Any pattern of irregular behavior of genes in the network can lead to cell malfunctioning, cell death, or the emergence of diseases like cancer. It is therefore of crucial importance to recognize erroneous gene interaction patterns and compare them to those in healthy cells. For this type of study, one of the most frequently used bioengineering systems is the well known DNA microarray device. DNA microarrays consist of grids of spots containing unique genetic identifiers for each of the tested genes, capable of generating snapshots of gene activity in terms of selective DNA sequence annealing. Microarrays have also found many other applications in the field of molecular biology, most notably for the purpose of detecting hostile microbial agents in food, water, and in the air. One of the main drawbacks of current microarray designs is that they are, for the purpose of whole genome studies, severely underutilized; similarly, for biosensing applications, existing microarray systems cannot be used for simultaneous identification of a large number of microorganisms and their strains due to technological limitations.<br\/><br\/>The investigators study novel array architectures, termed compressed sensing DNA microarrays. The research involves finding DNA probes that serve as group identifiers for classes of microorganisms; designing sparse sensing matrices for DNA group identifiers; developing compressed sensing reconstruction algorithms capable of handling saturation effects arising due to high agent concentration levels; characterizing the fundamental trade-offs between distortion and sensor dimension for non-linear arrays; and, analyzing the complexity of integrating compressed sensing microarrays into existing biosensor networks.","title":"Collaborative Research: Design and Analysis of Compressed Sensing DNA Microarrays","awardID":"0729049","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["554197"],"PO":["564898"]},"132121":{"abstract":"Effective processes, techniques, and tools for Verification and Validation (V&V) of medical devices will play a significant role in enabling FDA to carry out its mandate of approving only safe and effective medical devices. However, much work is needed to develop V&V techniques and certification processes that can cope with and encourage the same revolutionary changes in medical devices that are occurring informational, financial, and scientific service domains. In contrast to the monolithic nature of past systems, modern computing and information systems tend to be highly componentized and emphasize customization through flexible integration of components via ?plug-and-play? (PnP) and service-oriented architectures. In the medical device domain, systems are still largely monolithic due to the substantial verification challenges, absence of standards for interfaces and architectures, and lack of clear processes and techniques for approving componentized safety-critical medical devices. Without substantial progress in these areas, innovations in medical devices and health care will be severely inhibited and the risk of introducing unsafe devices into the market will increase as manufacturers continue to push newer technologies into medical devices.<br\/><br\/>This project has developed a suite of new capabilities, integrated in a tool framework called Bogor\/Kiasan for pervasive specification, analysis, and testing of component-based embedded systems that are expected to be very relevant for V&V of PnP medical device systems. These capabilities include: interface specification and verification frameworks for Java that allow complex pre\/post-conditions and invariants to be specified and automatically checked using model-checking and lightweight theorem-proving technologies; automated unit test case generation from specifications that enable the source code checking technologies to be more directly integrated with existing testing-centric quality assurance mechanisms; scalable static analysis techniques for calculating program dependences and information flow that can be used to reasoning about system coupling, to automatically derive traceability information, and to detect and visualize security flaws that are manifested as improper information flows. The focus of this NSF-FDA research project is the application of these tools to a PnP framework prototype that is being designed by FDA engineers. The goal is to extend existing V&V processes and techniques to better support development of safe and effective medical device systems that utilize current and emerging component, networking, and plug-and-play technologies, and also to verify that the associated implementation conforms to specifications, to generate test suites to achieve coverage requirements associated with device approval, and to improve the evidence produced to document results of certification activities.","title":"Development of an Open Test-bed for Application of Formal Methods to Plug and Play Medical Devices","awardID":"0734204","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["563763","559268","563764",351048],"PO":["561889"]},"131153":{"abstract":"Correlated data arises for many reasons in wireless communications: it may arise naturally due to the correlation in the observed data, as in sensor networks, or it may be created artificially by the communication protocol in order to improve the rates, as in user cooperation and feedback. In the first case, correlation is external to the system, whereas in the second case, correlation is created internally as part of the communication protocol in an effort to optimize the overall performance of the system. Efficient handling of correlation is critical for the optimal design and operation of current and future wireless ad-hoc and sensor networks. Yet, what is known and settled in this field is extremely limited.<br\/><br\/>The goal of this project is to develop a fundamental understanding and a comprehensive theory for optimum distributed coding, transmission, creation and exploitation of correlation in multi-user wireless networks. In order to achieve this goal, the investigator will distill the main theoretical challenges, initially isolate and tackle them in smaller sub-problems, and then finally integrate them to develop a unified theory. To that end, the project consists of three major thrusts: (i) development of a fundamental understanding for the optimum distributed coding and transmission of correlated data, when the source of correlation is external, and without allowing for the creation of internal correlation via relaying, cooperation or feedback; (ii) development of a fundamental understanding for the creation and then utilization of correlation internally as part of the communication protocol in order to improve the rates, e.g., through relaying, cooperation and feedback, when there is no correlation in the external data; (iii) development of a fundamental understanding for the interactions and the optimum interplay between the external correlation in the data and the internal correlation created as part of the communication protocol through relaying, cooperation and feedback.","title":"Correlation, Cooperation and Feedback (CCF) in Multi-user Wireless Communications","awardID":"0729127","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["548269"],"PO":["564924"]},"131043":{"abstract":"In living cells, signaling pathways composed of protein-protein interactions communicate information about extracellular conditions from the cell wall to the nucleus, leading to changes in the expression of genes and their protein products that enable the cell to adapt and survive in diverse environments. Biologists have uncovered portions of certain signaling pathways, but the current understanding of full signaling network structures is far from complete. Due to intrinsic difficulties associated with in vivo measurement, this research considers the problem of inferring the structure of a cellular signaling network using data generated by existing high-throughput experiments that indicate which proteins are utilized in each signaling pathway. Cell signaling networks underlie the growth, development and survival of living cells, and therefore the results of this project may advance the state of knowledge in the critical areas of human disease, biosensor development, and biofuel manufacturing.<br\/><br\/>This project investigates a new technique for the reconstruction of cell signaling networks that is based on data generated by existing high-throughput experiments that indicate which proteins are utilized in each signaling pathway, but do not directly reveal the structure\/order of the pathways. The cell signaling networks and the experimental data are mathematically modeled by a shuffled Markov process, which accounts for the fact that the data do not reveal the pathway structure\/order. The shuffled Markov model reduces the network reconstruction problem to the task of inferring the Markov transition matrix. Computationally efficient inference algorithms, based on expectation-maximization and importance sampling techniques, are developed for this task. Computational experiments using real and synthetic biological data, as well as mathematical analysis techniques, demonstrate the capabilities of the model and algorithms.","title":"Genomic Network Tomography","awardID":"0728767","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["518179",347899],"PO":["564898"]},"125840":{"abstract":"One promise of computing technology is to deliver information, anytime anywhere. Yet, even in the most computerized settings such as offices, this vision has yet to be fully realized. Instead, many workplaces suffer from an unfortunate irony: the very systems designed to solve workplace problems have created new difficulties. People are expert at seamlessly managing social and information flows, however, the technological substrate intended to support such collaboration is often brittle and slow to adapt. Interactions with this technological infrastructure become foregrounded, forcing users to attend to the technology itself rather than to the work at hand. This disconnect becomes all the more apparent in the face of highly dynamic, fluid forms of collaboration in which technological inertia slows the pace of interchange. Reconfiguring our technical infrastructure is rarely as easy or as natural as moving chairs together in a meeting room.<br\/><br\/>This proposed research aims to create, deploy, and evaluate a system of technical infrastructure that will help rather than hinder fluid collaboration. It will attempt to couple the digital infrastructure ? the services, applications, protocols, and devices in a space ? to the physical infrastructure of that space. This will make the digital infrastructure responsive to actions taken in the physical realm; likewise, it will make the physical infrastructure a medium for conveying affordances and feedback of the digital capabilities in a space to its users. This coupling will enable the fluid movement of information and collaborative artifacts from the physical domain to the digital, and vice versa. The results will be not only a set of digital services designed to enhance collaboration, but a deep integration of those services into the physical environment, along with a set of design guidelines, principles, and evaluation methodology for how to successfully blend the physical and the digital to better support fluid collaboration.<br\/><br\/>Broader Impact: This research has tremendous practical import to potentially improve the productivity of knowledge workers by decreasing the frustration and inefficiencies associated with on-the-fly use of collaborative technologies. The strong partnership with Steelcase and a commitment to public release of prototypes should facilitate rapid transfer of key findings to industry. The prototype design and evaluation activities will serve to engage students at all levels in Georgia Tech's new Human-Centered Computing program.","title":"HCC: Physical and Digital Design for Fluid Collaboration","awardID":"0705569","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["506686","472141","550811"],"PO":["564456"]},"133595":{"abstract":"Spelman College proposes the ARTSI (Advancing Robotics Technology for Societal Impact) Alliance in collaboration with Florida A&M University, the University of the District of Columbia, Hampton University, Morgan State University, Norfolk State University, Winston-Salem State University, the University of Arkansas-Pine Bluff, Carnegie Mellon University, Georgia Institute of Technology, Brown University, Duke University, the University of Alabama, the University of Washington, and the University of Pittsburgh. Seven of these partners are HBCUs and seven are Carnegie Research I institutions. Their collaboration joins the strengths of HBCUs in conducting outreach and education in a nurturing learning environment with those of the R1's for conducting world class research. The ARTSI Alliance will motivate students to pursue computer science careers by emphasizing the creativity and socially beneficial aspects robotics technology with hands-on projects, curriculum, and media. ARTSI activities will span the academic pipeline from K-12 through the faculty ranks. At the K-12 level, students will be recruited with community outreach using robotics and art, robotics road shows, and a robotics educational film online repository. At the undergraduate level, HBCU students will be exposed to new robotics curriculum, and they will be encouraged to pursue advanced training in graduate school through summer research experiences, collaborative, interdisciplinary robotics projects in the arts and health, instruction in technical film documentation, student virtual film festivals, annual robotics conferences, and instruction in entrepreneurship for computer science. At the faculty level, it will increase the number of HBCU faculty who educate students in robotics and involve students in robotics research by providing faculty mentoring, summer research experiences for underrepresented faculty at R1 robotics labs, robotics summer workshops, and development and dissemination of robotics educational material through a web-based portal. The Alliance will have industry partners, including Seagate, iRobot, Microsoft Research, and Juxtopia, as well as educational partners, including Florida-Georgia Louis Stokes Alliance for Minority Participation and Computer Science Teachers Association.","title":"Collaborative Research: BPC-A : ARTSI: Advancing Robotics for Societal Impact","awardID":"0742086","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7584","name":"ITR-BROADENING PARTICIPATION"}}],"PIcoPI":["554912","464056"],"PO":["561855"]},"131175":{"abstract":"This research studies network information theory based on the viewpoint of entropic vectors and convex optimization. There is currently great interest in the problem of information transmission over wired and wireless networks. Information theory is well poised to have an impact on the manner in which future networks are designed and maintained, both because wired networks are ripe for the application of network coding and also because wireless networks cannot be satisfactorily dealt with using conventional networking tools. The challenge is that most network information theory problems are notoriously difficult and so the mathematical barriers that must be overcome are often quite high.<br\/><br\/>The approach adopted in this research is through the definition of the space of normalized entropic vectors, which differs slightly from that in the literature in that entropy is normalized by the logarithm of the alphabet size. This definition is more natural for determining the capacity region of networks and renders the closure of the resulting space convex (and compact), even under constraints imposed by channels internal to the network. For acyclic memoryless networks, the capacity region for an arbitrary set of sources and destinations can be found by maximizing a linear function over the set of channel-constrained normalized entropic vectors and some linear constraints. While not necessarily making the problem simpler, this approach certainly circumvents the ``infinite-letter characterization'', as well as the nonconvexity of earlier formulations, and exposes the core of the problem as that of determining the space of normalized entropy vectors. Much of the research therefore focuses on constructing computable inner and outer bounds to this space using tools from group theory, lattice theory, non-Shannon inequalities, and others.","title":"Entropy Vectors, Convex Optimization and Network Information Theory","awardID":"0729203","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["451966"],"PO":["564924"]},"132154":{"abstract":"The Ethics Fellows Pilot Program at the University of New Mexico will be offered in three or four sections of the Engineering curriculum. The one year program will provide data on the expansion to other institutions, including CNM and SIPI, and may also provide insight into issues that are cross-cultural, since UNM is an MSI. The co-teaching experience of the Fellows will be provided with a teaching mentor and a colleague in another department, Philosophy. A seminar will help prepare Fellows and regular meetings will provide follow-up. Faculty mentors are interdisciplinary; evaluation is a critical component.","title":"Ethics Fellows in Engineering","awardID":"0734784","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7915","name":"Ethics & Values of SET"}}],"PIcoPI":["541388",351149,351150],"PO":["565136"]},"133012":{"abstract":"Colorado School of Mines (CSM) proposes a Demonstration Project designed to attract and retain females in computer science from middle school through undergraduate studies. Specifically, the project aims to (1) develop effective strategies for stimulating female interest in computer science from middle school through undergraduate studies, (2) increase the number of female undergraduate students who declare majors in computer science, (3) increase the retention of female undergraduate majors in computer science, (4) redesign the undergraduate computer science curriculum in a manner that is <br\/>appealing to both male and female students. Each intervention has been specifically designed to build on results from prior research. At the middle and high school levels, interventions ? including a summer technology camp and an academic technology club ? are planned to stimulate female interests in and understanding of mathematics, science and technology. Interventions will also take place at summer workshops for teachers, where middle school and high school teachers will learn both the statistics on female attrition and research based methods to encourage female participation in computer science, mathematics and science. Efforts will further be made to improve academic advising at the middle school, high school and undergraduate levels with respect to technical fields. At the undergraduate level, the computer science curriculum at CSM will be redesigned to build on the efforts of the Humanitarian Engineering program at CSM, which is known to attract female participation.","title":"BPC-DP: Broadening Female Participation in Computing: Middle School through Undergraduate Study","awardID":"0739233","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7584","name":"ITR-BROADENING PARTICIPATION"}}],"PIcoPI":[353756,"420994","412046","381567"],"PO":["561855"]},"134343":{"abstract":"The traditional vision of human-robot interaction is that the machines will be fully cooperative partners. Correspondingly, issues of robot disagreement have never been explored. Using a variable-based approach, the effects of robot autonomy, robot form, and robot politeness strategies on human behaviors and attitudes will be empirically tested. Behavior measures will include performance, physiological responses, and memory. Attitudinal measures will include affective responses as well as various assessments of the robot. Results will enable the discovery of which aspects of human-human interaction apply directly to human-robot interaction, and which aspects are different with respect to performance, memory, and attitudes. <br\/><br\/>This exploratory research project will seek to empirically identify features of robots that influence humans' responses to robots' expressions of disagreement. Results are expected to identify strategies to facilitate the resolution of conflicts between humans and robots. While there are models of human-human disagreement, it is unknown which of these models will be applicable to human-robot interaction. This is an important exploratory area to pursue given that in many contexts, such as space exploration and colonization, rehabilitation, and complex manufacturing, the robot must express disagreement with the human, a highly-charged situation. This research will provide initial answers to the following critical questions: 1) which strategies of disagreement will be most effective and most palatable to human interaction partners? and 2) which characteristics of robots will most effectively enable the situation to be one of joint understand rather than pure conflict? It is expected that findings will enable researchers to create and study robots that are better able to coordinate with humans and assist humans in reaching their goals as well as reveal the ways in which robots can induce social responses to technology.","title":"SGER: Disagreeing Robots","awardID":"0746109","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["513294"],"PO":["565227"]},"131087":{"abstract":"This research involves the theory, design, and efficient implementation of locally adaptive time-domain pre-\/post-processing operators for efficient signal representation and robust communications. The time-domain interpretation leads to a powerful signal decomposition and signal reconstruction approach with an unprecedented level of adapting capability. This framework retains all flexible features of block-based approaches and adds on top a high level of adaptivity: data samples are processed with small pre-\/post-processing block operators and each can be adapted on-the-fly if necessary. Furthermore, small local operators lend themselves nicely to parallel computing, and fast, VLSI-friendly, possibly multiplierless, implementations. Finally, the fact that time-domain pre-filtering is the closest link to the sensor and post-filtering to the display\/renderer allows the highest level of integration flexibility as well as the most economical implementation with minimum software or hardware upgrade. This research is particularly geared toward low-complexity signal coding and communication algorithms or systems in resource-constrained, speed-critical, and real-time applications for wireless hand-held devices. <br\/><br\/>In particular, the investigators study local adaptivity via adaptive Wiener filtering technique, providing the critical bridge between ad-hoc, but effective, pre-\/post-filtering approaches and fundamental information-theoretic signal decomposition strategies. Target applications of such time-domain local operators under investigation include: (i) under-sampled pre-filtering and over-sampled post-filtering for low bit-rate coding and fast local compressed sensing;(ii) transform-based multiple description coding; (iii) error-resilient pre-\/post-filters in error concealment for packet-switched erasure channels; (iv) optimal transform for distributed source coding in a dense sensor networks; and (v) design and application of adaptive two-dimensional (2-D) non-separable local decomposition for visual data representation and processing.","title":"Adaptive Pre- and Post-Filtering for Block-Based Communication Systems","awardID":"0728893","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["486320"],"PO":["564898"]},"133034":{"abstract":"As it expands, the Internet faces many challenges, including security, management and control, and change in the Internet is of increasing relevance. This project will map out a radical departure from present-day Internet architecture, based upon full switching and switch-bank-style routing, such as has been used in traditional telephony. This approach could change the Internet engineering space, and provide solutions to challenges, but it has long been understood to be infeasible in the competitive market of service providers. In parallel with development of the technology solution, the project will explore the adoption and impact issues, using business and socioeconomic techniques. The PIs come from computer networking and business disciplines. The project will initially explore how the switched internet architecture supports interfacing with diverse wireless networks and what economics and incentives could cause such an architecture to be adopted.<br\/><br\/>Among the broader impacts of the project will be the project's interdisciplinary findings, because of the societal and economic impact of Internet architecture. Other broader impacts include enriching undergraduate and graduate research experience by offering subtopics as projects; encouraging women in computing through female research assistantships; curriculum enhancement through incorporating subtopics into our curricula; and outreach with these multidisciplinary topics in Project Lead the Way and Kids on Campus, at RIT.","title":"SGER: A Switched Internet Architecture","awardID":"0739362","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["382244","382245"],"PO":["565090"]},"131098":{"abstract":"Today's world is characterized by a deluge of information, which needs to be extracted in an efficient manner from a variety of data sources. There is a great need for finding ways to process the data quickly, without compromising on their accuracy. The need becomes even more pressing in natural language applications related to national security (e.g., text classification, language identification), where the data may be noisy or very diverse. This research focuses on investigating new ways of performing denoising, dimensionality reduction and structure extraction from data efficiently; the ultimate goal is to significantly improve upon the state-of-the-art in the aforementioned applications.<br\/><br\/>The main agenda driving this research is the use of Integrated Sensing and Processing Decision Trees (ISPDTs), which are inherently suitable for processing high-dimensional data. The main characteristic of ISPDTs is that they perform joint dimensionality reduction and clustering (or classification), with the ultimate goal of optimizing a desired objective function. Preliminary experiments with ISPDTs have shown that they are very efficient in revealing structure and interesting statistical connections between text documents, with performance that surpasses the state-of-the-art. The strength of ISPDTs lies in the fact that they are adaptable, and can be trained to match the data characteristics in a variety of ways.","title":"Novel Approaches to Unsupervised Classification via Integrated Sensing and Processing Decision Trees","awardID":"0728931","effectiveDate":"2007-09-01","expirationDate":"2013-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["438318",348019,"445173"],"PO":["564898"]},"135344":{"abstract":"This research concerns recognition of words in handwritten responses of children in reading comprehension tests. The approach to word recognition will be based on conditional random fields (CRFs), which are discriminative methods that do not make any assumptions about the underlying data and hence are known to be superior to Hidden Markov Modes (HMMs) for sequence labeling problems.<br\/>The student response is first segmented into word images using an existing neural network based algorithm. Each word image is then over- segmented into a number of small segments such that the combination of segments forms character images. Segments are labeled as characters with probability evaluated from the CRF model. The total probability of a word image representing an entry from the lexicon is computed using a dynamic programming algorithm which evaluates the optimal combination of segments. A lexicon derived from the reading passage, testing prompt, answer rubric and student responses is used to limit the number of paths to explore.<br\/><br\/>The state and transition parameters of the CRF model are estimated from handwriting samples. State parameters correspond to features such as: position (normalized by length), place (in start, middle or end), height, width, distances to prototype, deviations of height, etc. Transition parameters correspond to features such as: label of character pair (th, er, qu, etc), vertical overlap (of pixels of candidate character images), height difference, width difference, aspect ratio difference, bigram width, etc.<br\/><br\/>The research test-bed will consist of scored handwritten responses to reading comprehension prompts from Grades 8 and 5 of an inner city school in Buffalo, New York. There are 300 Grade 8 responses and 200 Grade 5 responses, with about 100-150 words in each response. <br\/>Training data for parameter estimation will initially consist of 150 student responses and 1,000 half-page writings of adults. These will be supplemented with additional school data as research progresses.<br\/><br\/>Goal-oriented integration of complex document image analysis, natural language processing and machine learning will drive improved handwriting recognition methods. Children?s handwriting recognition has never before been studied in document analysis. Handwriting recognition technology for complex documents is as yet largely unavailable. Success will allow statewide testing to be done later in the school year with results provided sooner thereby having an impact on improved education.","title":"Recognition of Handwritten Words in School Essays Using Conditional Random Fields","awardID":"0750876","effectiveDate":"2007-09-15","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[359532],"PO":["564316"]},"127512":{"abstract":"Prior research on data integration led<br\/>to XML mediators, which provide to applications a<br\/>virtual integrated XML view<br\/>that allows a single point of access to the data of<br\/>multiple distributed and heterogeneous information sources.<br\/>Consequent industrial products address <br\/>Enterprise Information Integration<br\/>and follow the Global-As-View paradigm,<br\/>where the owner specifies the integrated<br\/>view as an XQuery function of the source views.<br\/><br\/>The emergence of Service-Oriented Architectures<br\/>and large scale Internet-based data integration, which<br\/>is often needed in the science domains,<br\/>renders Global-As-View-based information insufficient to benefit from<br\/>the emerging opportunities and inefficient in large scale environments.<br\/>Service-Oriented Architectures provide live data access<br\/>at data sets by offering a set of web service calls to them,<br\/>as opposed to (the studied in prior works) <br\/>full query access to the data sets.<br\/>Large scale data integration highlights the deployment, development<br\/>and maintenance bottleneck that the Global-As-View paradigm<br\/>creates by requiring the integrated view owner to have knowledge<br\/>of the schema, data formats and semantics of all sources.<br\/><br\/>The proposed mediator provides a scalable solution<br\/>by employing a new Global-Local-As-View paradigm in an XML setting:<br\/>Each source owner can become responsible for fitting her source<br\/>data and web services to the integrated view.<br\/><br\/>Fundamental algorithmic and system innovations <br\/>are needed for the implementation of the paradigm.<br\/>First, queries over the integrated view must be rewritten to use the <br\/>source services and data. Existing algorithms for rewriting<br\/>relational queries over relational views <br\/>are not sufficient, as they do not address services and<br\/>the rich structure of XML queries. Second, the source owner needs<br\/>an appropriate language and visual tools to export interfaces in<br\/>a way that can range from full access to the<br\/>underlying database to a few parameterized queries and anywhere<br\/>inbetween. Finally, the client needs corresponding systems<br\/>to comprehend which XQueries can be asked on the integrated view.<br\/><br\/>The resolution of the above fundamental contributions will enable<br\/>the development of the rewriting module of the UCSD-XMED XQuery<br\/>mediator, which can become a valuable information sharing <br\/>and publishing component, especially for science portals where <br\/>scientists will connect their databases <br\/>of experimental data to XML-based portals for integrated access<br\/>to scientific information. The UCSD-XMED query processor will be<br\/>used by graduate and undergraduate students in database and<br\/>middleware technologies.<br\/><br\/>Updates about the project, including its people, software <br\/>distributions and publications are available at <br\/>http:\/\/db.ucsd.edu\/NSF07xmlMed\/","title":"III:Next Generation XML Mediators","awardID":"0713672","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["525612"],"PO":["543481"]},"125213":{"abstract":"CCF-CPA: Communication and Synchronization Mechanisms for Emerging <br\/>Multi-Core Processors<br\/>Sandhya Dwarkadas and Michael L. Scott<br\/>March 2007<br\/><br\/><br\/>As a result of increasing chip density and power limitations, explicit hardware parallelism will soon dominate the computing spectrum, with multicore chips replacing uniprocessors throughout the desktop and<br\/>laptop markets. If these chips are to be used effectively, new programming models must ease the task of writing multithreaded code. These models must in turn be supported by architectural mechanisms that<br\/>minimize the cost of data communication and synchronization.<br\/><br\/>The sponsored research addresses the challenge of mainstream parallelism using a combined hardware-software approach. The key idea is to identify common time-critical operations, across a variety of applications and programming models, that might be accelerated or simplified by new architectural mechanisms, and then to design those mechanisms in as general a fashion as possible. By leaving policy to<br\/>software whenever possible, this strategy aims to maximize opportunities for adaptive and application-specific protocols that increase scalability. Candidate hardware mechanisms include alert-on-update, which leverages cache coherence for fast event-based communication; programmable data isolation, which allows a processor to hide local writes for speculation and transactions; and adaptive cooperative caching, which re-engineers the on-chip coherence protocol to accommodate different patterns of data sharing and to communicate values efficiently between cores. These mechanisms will be studied mainly at the hardware level, but system software will also be developed to support new programming models (transactions, speculation) and to enable detailed evaluation of performance and programmability.<br\/><br\/>Through better parallel programming models and efficient implementations, the sponsored research aims to continue the computing revolution over the course of the coming decade. By enabling the effective use of larger numbers of simpler cores, it also addresses the critical need to reduce energy consumption in mainstream processors. Driving applications will be drawn from multiple sources, including collaborative efforts with University colleagues in Biology, Astrophysics, and Chemistry; department colleagues in Artificial Intelligence and Internet services; and local and remote colleagues in data mining. Programming models and tasks will include transactional computing, speculative execution, and performance and correctness debugging.","title":"Communication and Synchronization Mechanisms for Emerging Multi-Core Processors","awardID":"0702505","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["564815","556692"],"PO":["559883"]},"126544":{"abstract":"CRI: IAD: Acquisition of High-Performance Multi-FPGA Platform<br\/><br\/>Xinmiao Zhang<br\/><br\/>Error-correcting coding and cryptography play important roles in the reliability and security of digital communication and storage systems, and digital signal processing can extract useful signals from noisy backgrounds. Our research in the area of VLSI architecture design for these systems serves as a bridge connecting theoretical advancements to their efficient hardware implementations. Currently, our research capability is seriously limited by slow software simulations and the lack of platforms for prototyping and emulation of our designs. In this project, we proposed to acquire a CHIPit Iridium Edition V4 Field Programmable Gate Array (FPGA) platform. This platform offers great flexibility and handles design capacities of up to 4 million Application Specific Integrated Circuits (ASIC) gates. The great flexibility and large capacity of this platform facilitates simulating communication systems in a reasonable time and prototyping complicated systems in real hardware. <br\/><br\/>The reconfigurable FPGA platform combines the simplicity of software design with high-speed and large-capacity performance. This feature allows us to overcome the limitations on simulating and evaluating the increasingly complicated communication and cryptography systems, as well as verify our designs in real time implementations. Specifically, the Iridium FPGA platform will aid our research in the following ways. First it will significantly increase our simulation capability for error-correcting codes. Secondly, it will allow us to prototype large scale systems, such as soft-decision Reed-Solomon decoders, parallel long BCH encoders, cryptographic applications and electrocardiogram (ECG) signal extraction. Thirdly, it will help us to find the hardware implementation bottlenecks in the design, which are otherwise invisible from simulations. Strong educational components are also integrated in this plan. The research results enabled by the proposed acquisition will contribute to the development of a new course. In addition, this project will provide students with hands-on experience on hardware implementation, as well as increase the participation of underrepresented groups in engineering.","title":"CRI: IAD Acquisition of High-Performance Multi-Field Programmable Gate Array Platform","awardID":"0708685","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[335750,"390981"],"PO":["550859"]},"134178":{"abstract":"The proposed workshop provides a forum to discuss Biological Communications Technology, an emerging interdisciplinary field that integrates molecular biology and communications technology into a new computing and communication paradigm. The proposed workshop will bring together leading researchers from Biology, Nanotechnology, Communications Technology, Network Engineering, Information Theory areas to discuss key technologies, the current state of the art, and future directions of this important emerging field. The specific<br\/>areas of interest of the proposed workshop are (1) design and development of networking components for biological communication systems, (2) architecture and system design methodologies for biological communication systems, (3) information and coding theory of biological communication, (4) applications of biological communications technology, (5) mathematical modeling and simulation for biological communications systems, and (6)understanding of biological communication.<br\/>The workshop is being proposed as part of the Emerging Models and Technologies for Computation (EMT) Program of NSF; and through exploring the above mentioned areas, the proposed workshop is expected to suggest what directions the CISE\/CCF community and EMT program are to seek in order to create a new integrated science from Biology, Nanotechnology, Engineering and Information Science.","title":"WORKSHOP: Workshop on Biological Communication Technology","awardID":"0745366","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["392840"],"PO":["564898"]},"125224":{"abstract":"Proposal ID: 0702567 <br\/>PI name: Dan Jiao, Venkataramanan Balakrishnan, and Chenk-Kok Koh<br\/>Inst: Purdue University<br\/><br\/>Title:A hierarchical matrix framework for electromagnetics-based analysis and design of next generation ICs<br\/><br\/>ABSTRACT<br\/>As IC design scales into the deep submicron and nanometer regimes, electromagnetics-based analysis has become essential. While so-called computational electromagentics (CEM) has found many successful engineering applications, the performance of existing CEM techniques is still inadequate when tackling realistic IC design problems. The analysis and design of next-generation ICs using the most accurate EM-based models results in numerical problems of very large scale, requiring up to billions of parameters to describe them accurately. However, even the state-of-art techniques do not scale well when applied to matrices of large sizes encountered with the analysis and design of next-generation ICs. In this proposal, the PIs will address the problem of full-wave analysis and design for next-generation integrated circuits, considering numerical problems arising from both partial differential equation (PDE) based models and integral equation (IE) based models. The proposed solution techniques hinge on the observation that the matrices underlying the numerical problems or their inverses are ``sparse-banded,'' wherein the matrices parametrizing the models or their inverses have (either exactly or approximately) a sparse, block-banded structure. There exists a general mathematical framework one that includes sparse-banded matrices as a special case called the ``Hierarchical Matrix'' framework, which enables a highly compact representation and efficient numerical computation. The hierarchical matrix framework will form the basis of the techniques proposed for the solution of the underlying numerical problems. The techniques combine an appreciation of the physics underlying the problems with elegant results from matrix theory and sound computational principles. This combined with the increased availability of distributed computing resources offers another rich new avenue of research. <br\/><br\/>The philosophy underlying the proposed approach is that by combining advances in theory (i.e., understanding) with progress in optimization and numerical linear algebra (i.e., numerical computation), one can realize enormous advances in the state of the art in research. The PIs have considerable experience with incorporating this philosophy in their own educational efforts. The graduate students who participate in the proposed effort will be trained with a broad range of skills, in areas such as electromagnetics, numerical linear algebra, and parallel computing fundamentals. Undergraduate research projects will provide an integrated research experience to students from the sophomore through the senior years. The PIs have a history of collaboration, commitment to teaching, and fostering diversity in the workplace, and are thus well-positioned to involve a diverse population of students in the research and teaching activities envisioned in this proposal.","title":"A Hierarchical Matrix Framework for Electromagnetics-Based Analysis and Design of Next Generation ICs","awardID":"0702567","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["475380","475378",332293],"PO":["562984"]},"126676":{"abstract":"The Emulab network testbed based at the University of Utah is a premiere facility for network and distributed systems research, used by thousands of researchers and students at hundreds of institutions around the world. It has come to be a central resource in the network research community. In addition to the services provided by the facility itself, the Emulab team is universally praised for their responsiveness in answering questions and addressing problems.<br\/><br\/>Emulab is not only a highly successful facility, it is software: an \"operating system\" to control network and distributed system experimentation. That software, largely unchanged, is running more than 20 other testbed sites, including the DETER security-oriented testbed.<br\/><br\/>A large amount of skilled development and operations time is required to deal with changing requirements and to support the facility's users and other Emulab facilities. This project supports a significant portion of those personnel costs.<br\/><br\/>The intellectual merit of this proposal lies in finding ways to continuously evolve the Emulab software base, while keeping it running 24\/7. Doing so is additionally challenging because separate work will be federating Emulab with other testbeds. The broader impact of this proposal will be to enable thousands of researchers, students, and hundreds of research projects to run network-oriented experiments that would otherwise be impossible.","title":"CRI: CRD: Keeping Emulab Tuned and Humming","awardID":"0709427","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["344532","550238","472196"],"PO":["564778"]},"127413":{"abstract":"Recent advances in smart Electro-active Polymers (EAP) have created a unique opportunity to design true biologically-inspired robots. However, the ionic EAP actuator has been observed by many researchers that the wiring power line, to the respective electrode surface, is challenging, especially in multi-segment design applications and micro-scale actuation. In order to adequately design robust robotic systems that can be adaptable to a variety of unstructured and tortuous environmental conditions, it is necessary to have breakthroughs in the intelligent power supply and the control unit. In this proposal, we introduce an innovative approach to use a wireless link between EAP based target locomotion units and a remote control\/power unit. The remote unit can provide necessary intelligence to the target locomotion units by modulating both frequency and amplitude of the microwave to selectively actuate a different segment of the EAP actuator by using a specially coded patch antenna pattern on the electrode surface of the actuator. The proposed microwave control systems have a wide spectrum of future engineering applications where proper intelligence capabilities need to be provided to the local locomotion unit. The success of the proposal can lead to the development of Integrative Biomimetics cluster that will provide necessary foundation for education and outreach programs.","title":"Collaborative Research: Intelligent Microwave Power Transmission and Control System for Artificial Muscle-Driven Biomimetic Robotic Systems","awardID":"0713075","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["441459"],"PO":["429182"]},"125235":{"abstract":"CCF-0702622 <br\/>Program Analysis for Reliable Numerical Software<br\/>Zhendong Su<br\/><br\/>Many software systems involve numerical computation, and numerical errors in these systems can be disastrous. Well-known examples include the loss of the Mars Climate Orbiter (due to a misuse of measurement units) and the explosion of the Ariane 5 rocket (due to an overflow). Studies show that such errors often occur, even in well-tested code, because it is difficult to test numerical software and few static tools exist to help detect such kinds of errors.<br\/><br\/>This project aims at developing practical program analysis techniques and tools to help avoid common classes of numerical errors. It focuses on three main aspects of the problem: (1) automatic dimensional analysis and unit checking, (2) static detection of uncaught exceptions such as overflows and underflows, and (3) static estimation of error propagation and numerical stability. The general approach is to cast these problems as constraint-based program analyses by modeling the formal semantics of the IEEE floating-point standards and designing approximate abstract semantics with appropriate constraint formalisms. For wide dissemination of the research results, analysis tools developed in the project will be distributed to the public domain for use in teaching, research, and experimental evaluation.","title":"Program Analysis for Reliable Numerical Software","awardID":"0702622","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["562712"],"PO":["564388"]},"135036":{"abstract":"This award provides support for a second summit and follow-up activities between American and Chinese researchers from leading universities in both countries. The first summit was held in China in 2006. This second meeting is being arranged as a result of a recommendation from the American delegation from the initial meeting of the delegations. The summit is to take place in the summer of 2008 and to be organized by a joint U. S.\/China Steering Committee. <br\/><br\/>The intellectual merit of this project lies in the opportunities it provides American researchers to develop new methods for improving education and research at their own institutions and in the nation. During the meeting and subsequent smaller meetings across the United States, researchers from both countries plan to identify research and education projects of common interest for further collaboration. American participants should gain further insights into the educational structures and research programs in China and thus develop research and education practices needed for today?s global economy.<br\/><br\/>The broader impacts of this project involve the potential for American students and faculty to adapt an increasingly global higher education and economy and to open up lines of communication that may enable new international collaborations at all levels of the education and scientific research enterprises.","title":"Second US-China Computer Science Leadership Summit","awardID":"0749641","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["264120"],"PO":["564181"]},"127424":{"abstract":"This project will examine whether federal agency rulemaking can be improved with two innovations: a) multi-level deliberation (MLD), in which people discuss rulemakings in small groups that then select members to represent the group in a higher-level group and b) the combination of language technologies into an artificial discussion facilitation agent (DiFA). The project poses computer science challenges of combining several Natural Language Processing technologies (primarily Interactive QA, Dialogue Analysis, and Summarization) into a viable facilitation agent and in applying these technologies in an eclectic, multi-user discussion environment. We expect advances to be made within each component technology. For example, we hope to increase the utility of Dialogue Act tagging across applications and domains by using a set of general discussion tags for tracking and summarizing threads of discussion by combining dialogue structure and content analysis. We will also investigate how general our Question Answer approaches are. The social science herein breaks new ground in the nascent fields of e-rulemaking and democratic deliberation research. The project will advance research on measuring the quality of deliberation and the effects of deliberation and DiFA on individuals and communities. Research will involve four rulemaking experiments. The first three are subsets of the final one. The final 3X2 experiment crosses MLD, non-MLD deliberation, and non-deliberation with the presence or absence of DiFA. The success of the various conditions of these experiments will be measured using a multi-trait, multi-method approach that will include survey and focus group measures of agency official and participant perceptions and evaluations, a content analysis measure of the cognitive sophistication of rulemaking comments, both human-coded and automated content analyses of the quality of deliberation, measures of the impact of the deliberations on participants (knowledge, trust, citizenship), DiFA usage patterns, and continued participation in our user community.<br\/><br\/>The federal agency rulemaking comment process represents an important potential avenues by which the American public can affect how it is governed. Such comments can make agency officials aware of likely adverse effects of the proposed rules. Unfortunately, the current rulemaking comment process faces a number of social and organizational problems including poorly informed and distrustful participants, lack of dialog among participants that could sharpen their reasoning, and problems of scale such as the large number of comments generated. Researchers believe that most rulemaking comments are low in quality or redundant?a product of form letters used by public interest groups. Rulemaking is not a plebiscite, but an effort to identify reasons to accept or modify proposed rules. This project will seek to address the problems of existing rulemaking by immersing rulemaking participants in small discussion groups that will be assisted by discussion facilitation software. The software will use cutting-edge technologies to help answer questions, summarize discussion, and provide feedback and suggestions on their discussion. Discussion itself will be organized into a hierarchy of representative groups to help the best ideas spread among participants and rise to the top. The value of the technology and of the deliberation methods will be thoroughly tested using experimental methods and data collected via surveys, focus groups, and by the software. The project will advance research in several areas. In computer science, it will seek to apply natural language technologies in a more general setting than before. The technology created could have broad application. It will also combine several technologies into a discussion facilitator that may be more widely used. The project will also advance research on democratic deliberation by improving and testing measures of deliberative quality and by adding to knowledge of how deliberation affects citizens.","title":"Collaborative Research: Deliberative E-Rulemaking Decision Facilitation Project (DEER)","awardID":"0713143","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["557867"],"PO":["564456"]},"129855":{"abstract":"Proposal #: CNS 07-23248<br\/>PI(s): Lepreau, Jay<br\/> Corbato, Steven C.<br\/>Institution: University of Utah<br\/> Salt Lake City, UT 84112-8930<br\/>Title: MRI\/Dev.: Evolutionary Development of an Advanced Distributed Testbed<br\/>Project Proposed:<br\/>This project, developing an advanced distributed testbed, aims to take the best software components from several existing infrastructure projects, add missing pieces, integrate them into a coherent whole, deploy on selected hardware and network connections, and quickly build an early, but fully functional version of an advanced experimental facility, called NewLab. The work evolves in three phases that<br\/>. Provide early but broad and powerful function, where the best components of Emulab and PlanetLab are integrated into a coherent whole;<br\/>. Focus on interfaces and software modularity, evolving cleaner interfaces and more separable modules;<br\/>. Refine, and improve selected components, tuning for better performance.<br\/><br\/>Broader Impacts: The testbed provides researchers and students with a rich experimental network facility, an integrated and powerful experimental management to control it, and engineering and architectural lessons on components and interfaces for testbed and experiment management.","title":"MRI: Evolutionary Development of an Advanced Distributed Testbed","awardID":"0723248","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["559300",344532,"550238","559299"],"PO":["557609"]},"127435":{"abstract":"This is an interdisciplinary inter-institutional collaborative research (0713087: Catherine Plaisant, University of Maryland College Park; 0712770: Jean Scholtz, Battelle Memorial Institute; 0713198: George Grinstein, University of Massachusetts Lowell) focuses on visual analytics (VA), i.e., the science of analytical reasoning facilitated by interactive visual interfaces. This project addresses an important aspect of visual analytics methods and tools, namely developing an evaluation infrastructure, as there is currently no general consensus on how to evaluate VA systems. It is especially difficult to assess their effectiveness as they combine multiple components (analytical reasoning, visual representations of data, computer human interactions, data representations and algorithms, tools for communicating the results of such analyses) integrated in complex systems. Further, it is difficult to assess the effectiveness without realistic data and tasks; hence, it is quite costly for each individual researcher to evaluate the effectiveness of their specific VA approach. <br\/><br\/>The goal of this project is to design and conduct initial tests of an evaluation infrastructure that will provide datasets with ground truth, supply guidance for experiments, test methodologies and metrics, and encourage collaboration and sharing of qualitative and quantitative results amongst researchers. Because visual analytics tasks vary widely, from maintaining awareness to assessing a situation, monitoring changes, solving crimes or dealing with emergencies, and are applicable to a variety of domains with different needs (e.g., business or intelligence analysis, medical research, emergency management), this project aims to bridge those diverse communities. The project Web site (http:\/\/www.cs.umd.edu\/hcil\/semvast\/) will include a sharable set of methods, tools and metrics for evaluation, and other results from this project. <br\/><br\/>Community wide, systematic evaluations of visual analytic systems will produce better understanding of the issues in the core research fields involved in visual analytics as well as the issues that cross between those research fields. The evaluation methodologies developed will benefit research activities as well as product development. This will lead to more effective systems and impact all visual analytics application domains. Classes in visual analysis are now being taught at the university level as well as in government agencies. Benchmarks and automated evaluation tools will be developed with professors and students and used in class projects and assignments.","title":"III-CXT: Collaborative Research: Scientific Evaluation Methods for Visual Analytics Science and Technology","awardID":"0713198","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["429576"],"PO":["563751"]},"129514":{"abstract":"This project investigates using controlled degradation of local area network performance to control the types of applications that can run effectively on the network. Network administrators can use the techniques developed by the project to prevent undesirable applications (peer file sharing, network games, etc.) from being run on the network merely by adjusting network performance. For example, some network games can be made intolerable by varying jitter or live audio can be disrupted by high loss rates, without impacting applications like web browsing, remote file access, or email. This technique works even if you cannot log into computers connected to the network and it is much harder for users to evade. The project will build practical tools that allow network administrators to control their networks in this manner and provide insight into how to use those tools for common cases. A major challenge for this approach is to find fundamental required network conditions that control important applications such that no attempt by programmers or users to work with the applications in the face of those degraded conditions is likely to be fruitful. The project will also investigate analytic issues of network performance, in particular the use of derivatives and integrals of common network performance metrics like bandwidth and delay. <br\/><br\/>Broader Impact: This analysis will both assist in building control mechanisms for the project and generally increase the research community's understanding of network behaviors. The software and analytic tools developed by this project will be released to the research community.","title":"NBD: Controlling Applications by Managing Network Characteristics","awardID":"0721963","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[343177,"485932"],"PO":["565090"]},"127215":{"abstract":"The long-term goal of this project is to enable robot manipulation<br\/>in the unstructured and uncertain environments of the home and the workplace.<br\/>To operate robustly and effectively when there is uncertainty, a robot<br\/>must be able to reason explicitly about how uncertain it is, and<br\/>potentially choose actions that will yield sensory information that<br\/>will reduce the uncertainty. This project addresses the problem of<br\/>reasoning about uncertainty by using a probability distribution over<br\/>possible underlying states of the world to represent its current<br\/>``belief'', and by choosing actions in virtue of the effects they will<br\/>have on the robot's belief about the state of the world. Robot<br\/>manipulation problems will be formulated as partially observable<br\/>Markov decision processes (POMDPs) to generate effective strategies<br\/>for manipulation under uncertainty.","title":"RI: Robot Manipulation Under Uncertainty","awardID":"0712012","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["486246","486247"],"PO":["543539"]},"127457":{"abstract":"Current methods for machine translation (MT) rely on large amounts of text data. However, large data is not available for many languages or for specialized vocabularies even in major languages. This project elicits bilingual data from a fairly naive human bilingual informant.<br\/>Bilingual speakers are available for a language even when large data and trained linguists are not. A Corpus Navigator uses knowledge from language typology to choose the pieces of data that are most valuable for automatic learning of MT rules. The Corpus Navigator employs active learning in the sense that its state is updated by eliciting data from a human translator.<br\/><br\/>Two hypotheses are being tested: an MT system can get by with less data if it is the right data, and that the right data can be acquired through an active learning process guided by linguistic knowledge.<br\/>Current government-run MT evaluations provide a testbed for these hypotheses. The outputs of MT systems trained on different data sets are compared in order to determine whether the hypotheses are correct. An initial prototype Corpus Navigator is being produced as a proof-of-concept. <br\/><br\/>This project will make it easier to build MT systems in situations where large text resources are not available. Languages that will be tested may include Inupiaq, Bengali, Thai, Urdu, Uzbek, and Tigrinia.<br\/>The output of Corpus Navigation is a parallel, word-aligned corpus annotated with a semantic feature structure. This data will be available to other researchers.","title":"Active Selection of Data for Machine Translation","awardID":"0713292","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["496511",338010],"PO":["565215"]},"125158":{"abstract":"The emergence of multicores as the standard machine design has created one of the most important challenges to the software industry in the history of computing. To take advantage of the additional computational power of each new generation of machines, programs must be able to profit from the most important characteristic of multicores: the presence of multiple processors. In other words, programs must be able to execute in parallel. Furthermore, for efficient execution, this parallelism must take a form that is consistent with the internal organization of the multicore machine where the program is to execute. If these programs were to be manually designed, the need to take into account machine characteristics would increase the cost of program development significantly. Also, since newer multicore designs are likely to include novel architectural features, the process of porting programs from one generation to the next will also involve significant costs. In other words, if nothing is done, the significant increases in the cost of software will be necessary for widespread acceptance of multicores. <br\/>Our objective in this project is to develop techniques for automating the process of generating efficient parallel programs. To this end, we will extend Pivot, a prototype C++ compiler, under development at Texas A&M, with techniques capable of automatically detecting the parallelism implicit in most conventional C++ programs and mapping it onto a wide range of multicore systems. That is, we will extend Pivot with automatic parallelization techniques. We will build on static and hybrid (static and dynamic) analysis techniques developed at Illinois and Texas A&M for numerical computations and extend them to handle the irregular data structures that are often used in C++ programs.","title":"Collaborative Research: Next Generation Compilers for Emerging Multicore Systems","awardID":"0702260","effectiveDate":"2007-09-15","expirationDate":"2012-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["533380","550505"],"PO":["565272"]},"127348":{"abstract":"This is an interdisciplinary inter-institutional collaborative research (0713087: Catherine Plaisant, University of Maryland College Park; 0712770: Jean Scholtz, Battelle Memorial Institute; 0713198: George Grinstein, University of Massachusetts Lowell) focuses on visual analytics (VA), i.e., the science of analytical reasoning facilitated by interactive visual interfaces. This project addresses an important aspect of visual analytics methods and tools, namely developing an evaluation infrastructure, as there is currently no general consensus on how to evaluate VA systems. It is especially difficult to assess their effectiveness as they combine multiple components (analytical reasoning, visual representations of data, computer human interactions, data representations and algorithms, tools for communicating the results of such analyses) integrated in complex systems. Further, it is difficult to assess the effectiveness without realistic data and tasks; hence, it is quite costly for each individual researcher to evaluate the effectiveness of their specific VA approach. <br\/><br\/>The goal of this project is to design and conduct initial tests of an evaluation infrastructure that will provide datasets with ground truth, supply guidance for experiments, test methodologies and metrics, and encourage collaboration and sharing of qualitative and quantitative results amongst researchers. Because visual analytics tasks vary widely, from maintaining awareness to assessing a situation, monitoring changes, solving crimes or dealing with emergencies, and are applicable to a variety of domains with different needs (e.g., business or intelligence analysis, medical research, emergency management), this project aims to bridge those diverse communities. The project Web site (http:\/\/www.cs.umd.edu\/hcil\/semvast\/) will include a sharable set of methods, tools and metrics for evaluation, and other results from this project. <br\/><br\/>Community wide, systematic evaluations of visual analytic systems will produce better understanding of the issues in the core research fields involved in visual analytics as well as the issues that cross between those research fields. The evaluation methodologies developed will benefit research activities as well as product development. This will lead to more effective systems and impact all visual analytics application domains. Classes in visual analysis are now being taught at the university level as well as in government agencies. Benchmarks and automated evaluation tools will be developed with professors and students and used in class projects and assignments.","title":"III-CXT: Collaborative Research: Scientific Evaluation Methods for Visual Analytics Science and Technology","awardID":"0712770","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[337754],"PO":["563751"]},"127469":{"abstract":"In many problems arising in biology, social sciences and various other <br\/>fields, it is often necessary to analyze populations of entities <br\/>(e.g., molecules or individuals) interconnected by a network. This proposal <br\/>intends to develop new statistical formalisms and computational methodologies<br\/>for modeling and inference the semantic underpinnings of<br\/>network entities, and investigate how these aspects influence <br\/>the network topology and its temporal evolution during biological and <br\/>sociological processes. It will also study a number of yet unexplored <br\/>topics such as discriminative learning of network structures,<br\/>recovering temporally evolving network sequences, and related theoretical <br\/>issues. <br\/><br\/>The proposed research is envisaged to help address big-picture problems <br\/>such as: 1) Hidden Identity\/Function Induction, e.g., what role(s)<br\/>do individuals play when they interact with different peers under different<br\/>conditions? 2) Structural\/Organizational Forecast, e.g., whether and how <br\/>changes of molecular functions lead to alterations of biological pathways? <br\/>3) System Robustness, e.g., how a network adjusts to <br\/>perturbations caused by exogenous intrusions? <br\/><br\/>This research straddles statistical learning, social\/biological sciences<br\/>and data mining. The intellectual merit of the proposed work lies in both <br\/>the algorithmic and theoretical novelties of the methodological developments, <br\/>and the analysis of specific social and biological networks and various other <br\/>applications enabled by the proposed methods. The main novelties include: <br\/>(1) new Bayesian formalisms for latent space modeling of node <br\/>functions and network linkages, which capture the functional\/behavioral <br\/>context of network entities; (2) novel temporal extensions of exponential <br\/>random graph model for network evolution, and inference\/learning algorithms; <br\/>(3) algorithms for reverse-engineering temporally rewiring networks from <br\/>longitudinal node attribute data; and (4) novel discriminative learning <br\/>algorithms for learning very-large networks from partial samples of the <br\/>network and relevant learning theory. These methods will be applied to<br\/>the ENRON email network to explore the behavioral patterns under various <br\/>business operation conditions, and to analyze a longitudinal molecular <br\/>abundance profile measured from breast cancer cells to infer (alterations of) <br\/>networks under carcinogenic or tumor-suppressing environments. The results <br\/>are expected to advance the principles and technologies for network analysis, <br\/>and enable a wide-range of applications of broader interests.<br\/><br\/>The proposed research is also expected to have broad educational and <br\/>societal impact. As an interdisciplinary research effort, this project will <br\/>provide rich opportunities for multi-disciplinary educational and research <br\/>training, at both undergraduate and graduate levels. A thorough understanding <br\/>of social network structures in human populations can have significant impact <br\/>on important issues such as policy making or technology adoption. Knowledge of <br\/>cellular networks and its changes in response to exogenous interventions can <br\/>help reasoning disease causes and designing therapeutic schemes. Our methodological<br\/>and software deliverables can potentially facilitate such studies, improve the<br\/>cost-effectiveness of network data collection, and foster future development<br\/>in this area. <br\/><br\/>More details of this project can be found at http:\/\/www.cs.cmu.edu\/~epxing\/projects\/network.htm","title":"III-COR+RI: Novel Statistical Models and Algorithms for Network Modeling, Mining and Reverse Engineering","awardID":"0713379","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["518220"],"PO":["560586"]},"129416":{"abstract":"The Internet is a phenomenal success, but problems and weaknesses in<br\/>it have become apparent, and this has spurred a search for new<br\/>technologies and network architectures. Although technical innovation<br\/>will remain fundamental to the Internet's evolution, the importance of<br\/>this key infrastructure for society as a whole means that economic<br\/>aspects will be critical in determining what innovations are adopted.<br\/>This project, therefore, seeks to investigate -- both qualitatively<br\/>and quantitatively -- how economic factors mediate the eventual<br\/>success of new network architectures and technologies. Aspects of<br\/>interest include quantifying the benefits of virtualization in<br\/>enabling different levels of network integration; evaluating the<br\/>effect of a dominant incumbent (today's Internet) on emerging new<br\/>architectures; and devising models for quantifying the value of<br\/>architectural flexibility and openness in facilitating technology<br\/>adoption and service creation in the presence of market uncertainties.<br\/><br\/>The intellectual merit of the proposed research is in developing an<br\/>economic framework for reasoning about network technologies,<br\/>architecture alternatives and trade-offs. The goal is to inform the<br\/>design of new network architectures by accounting for both their<br\/>technical dimensions, and the economic mechanisms that will mediate<br\/>their success or failure. The broader impact of the project will be<br\/>in helping select network solutions that are likely to succeed in the<br\/>market place. The project will also foster a multi-disciplinary<br\/>curriculum involving economics, business and engineering perspectives.<br\/>This will both better prepare engineering students to succeed in a<br\/>world where understanding of economical forces is of paramount<br\/>importance, and promote interactions and collaboration among<br\/>engineering and business students.","title":"Collaborative Research: FIND - On The Economic Viability of Network Architectures","awardID":"0721610","effectiveDate":"2007-09-01","expirationDate":"2011-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["564485","496299"],"PO":["565090"]},"128206":{"abstract":"Increasingly, society relies on software systems to provide vital services. Consequently, it is critically important that this software be protected from unauthorized modification. For example, a malicious user may modify or tamper with a binary to circumvent protection or license mechanisms or introduce vulnerabilities that can be later exploited. Previous software-based anti-tamper and obfuscation research has attempted to provide solutions, but has failed to provide adequate protection under a realistic threat model, has failed to provide practical solutions, or has failed to provide protection against attacks in which an adversary uses sophisticated static and dynamic analyses.<br\/>This project seeks to address the shortcomings of current software-based technology for tamper-resistance and obfuscation. The approach taken is to meld innovative, ultra-efficient software dynamic translation technology with theoretically sound encryption technology and dynamic versions of static anti-tampering and obfuscation techniques. <br\/>The fundamental contributions expected from this project include: efficient methods for dynamically generating and inserting opaque predicates into running code, new dynamic techniques for program obfuscation, a new approach to self-checksumming that is stronger than previously proposed techniques, and new metrics for evaluating and measuring the strength of tamper-resistance techniques.<br\/>The consequences of this research also include several societal impacts. Malicious adversaries continue to find security flaws in and marshal attacks against critical software infrastructures. This research pursues a complementary, secondary defense by making it harder for malicious entities to analyze software to locate vulnerabilities and then use this information to develop attacks. The applicability of the results is expected to be very broad since the results can be used to make a wide variety of software (both user software as well as server software) tamper-resistant.","title":"CT-ISG: Robust and Efficient Tamper-Resistant Software","awardID":"0716446","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["385658"],"PO":["565327"]},"128217":{"abstract":"The main objective of this project is to develop simple, practical and provably effective cryptographic techniques for the security and privacy of biometric data. The proposed research will formulate rigorous notions of security and privacy for real world biometric data, which may be continuous and with complex similarity measures. This will be done by developing error-tolerant techniques that can be applied to achieve the targeted security and privacy requirements. The proposed approach is mainly based on recent devel-<br\/>opments in error-tolerant cryptography centered around the idea of a secure sketch. In fact, well known error tolerant schemes like fuzzy commitment and fuzzy vault can be considered as special cases of the general notion of secure sketch. The secure sketch framework is a promising approach for protecting biometric data. Not only is it more amenable to combination with signal processing techniques for application to real biometric data, but it also provides provable security under reasonable assumptions. The techniques developed will be implemented and an investigation of their performance in terms of false accepts and false rejects will be carried out along with and analysis of the trade-off between the performance and the security. Practical cryptographic protocols for biometric applications under a variety of threat models will also be developed. Furthermore, techniques to enhance security using multimodal biometrics and\/or multi-factor schemes will be studied.","title":"CT-ISG Security and Privacy of Biometric Templates: Theory and Practice","awardID":"0716490","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["559652"],"PO":["529429"]},"129207":{"abstract":"This project seeks to address fundamental gaps in the understanding of collective behavior, and to develop a methodology for software design for cyber physical systems that use sensing, communication, and actuation to accomplish tasks that are well beyond the capabilities of individual units. Specifically, the focus is on methodologies that will allow cyber physical systems to adapt to changing environmental conditions and be resilient to disturbances and attacks, and tools to translate design specifications for the group to software design specifications for individual units by essentially solving the inverse problem for networked cyber physical systems.<br\/><br\/>This research represents the cross pollination of research in molecular, cell and population biology, systems modeling, control theory and robotics. It brings novel modeling approaches and recent results in systems biology to bear on the problem of designing and architecting cyber physical systems. Specifically, it will establish a framework for designing and realizing algorithms for real-time, aggregated networked systems across multiple time-scales, and help develop the foundation for high-confidence software for reconfigurable, adaptive and resilient systems.<br\/><br\/>The project is expected to lay the foundation for a new community of researchers that include biologists, control theorists and roboticists through research workshops.","title":"CSR---CPS: Bio-Inspired Cyber Physical Systems","awardID":"0720801","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["553286","461485","526896"],"PO":["561889"]},"129449":{"abstract":"This project develops a technological infrastructure for deploying and using ad hoc airborne video sensor (AVS) networks. In particular, autonomous blimps are used as the airborne platform, and are equipped with a compact processing unit, sophisticated camera assembly, and certain sensing devices. The AVS network can be envisioned being used <br\/>for detection of unusual activities in emergency and disaster control situations, monitoring of unplanned events, etc.<br\/><br\/>One of the main research components involves development of efficient algorithms for various versions of the video coverage problems in the context of the AVS network. The second main research component of the research involves declarative representation and automated evaluation of high-level video activities. In addition to above, the project <br\/>also entails research issues that arise in the areas of robotics and computer vision. An important component of the work is development of two testbeds - one with a large number of autonomous indoor blimps with a modest camera set-up, and the other with a smaller number of larger autonomous outdoor blimps with a sophisticated camera set-up.<br\/><br\/>The broader impact of this project is new applications that the AVS network facilitates, especially those requiring response to unplanned emergencies and threats. The project also contributes to education and involvement of minority students in advances to science and engineering. The results of the project are disseminated over the web at http:\/\/www.cs.sunysb.edu\/~hgupta\/airborne.","title":"NOSS: Airborne Video Sensor Networks for Surveillance and Emergency Response","awardID":"0721701","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["477226","508251","486433",342999],"PO":["564993"]},"130692":{"abstract":"Modeling and simulations of crystallization\/solidification of materials for understanding a given material's microscopic structure and final properties have spawned significant advances in today's explorations of new nano-materials and devices in materials sciences and engineering. In the past decade, many computational models have been developed to partially simulate the crystallization and solidification on either microscopic or macroscopic scales. However, a generalized model to develop microscopic (molecular, meso-scale) calculations with macroscopic computations has not been developed, due to the model's complexity on multiple scales and validity of computational power.<br\/>This research involves developing a computational infrastructure that includes a large-scale microscopic and macroscopic model of crystallization\/solidification of nanostructure materials, and associated high performance computational algorithms and numerical methods, using the cyber-infrastructure-enabled computing resources and facilities. The investigators will develop an integrated software package which can systematically solve many challenges in the modeling and simulation of nanostructure material formation. The model begins with the atomic\/molecular interactions for the origin of nucleation by using parallel molecular dynamics (MD), and considers the mechanisms of nano-scale crystallization, nano-particle\/crystal formation and growth. The researchers employ thermal dynamics and the equilibrium theory to account for the microscopic liquid-state precipitation and\/or segregation, local thermal and special non-equilibriums, microstructure transition, particles and interactions, and phase change. They also consider the macroscopic transport phenomena and various defects at a macroscopic level. The computational infrastructure model fully lies in the large-scale parallel computing technologies bred by national cyber-infrastructure. Numerous tasks for the model computation are distributed across multiple computing platforms connected by high-speed networks, while each task executes a parallel computation; thus increasing computational power for the challenging problem.","title":"NSF-EMT: A Merging Multi-scale Model for Simulations of Crystallization\/Solidification of Nanostructured Materials on Large-scale Parallel Computing Systems","awardID":"0727007","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["554242",346811],"PO":["562984"]},"141461":{"abstract":"The diverse functions performed by a living cell during her life cycle are controlled and regulated through complicated gene- and protein- interaction networks. Any pattern of irregular behavior of genes in the network can lead to cell malfunctioning, cell death, or the emergence of diseases like cancer. It is therefore of crucial importance to recognize erroneous gene interaction patterns and compare them to those in healthy cells. For this type of study, one of the most frequently used bioengineering systems is the well known DNA microarray device. DNA microarrays consist of grids of spots containing unique genetic identifiers for each of the tested genes, capable of generating snapshots of gene activity in terms of selective DNA sequence annealing. Microarrays have also found many other applications in the field of molecular biology, most notably for the purpose of detecting hostile microbial agents in food, water, and in the air. One of the main drawbacks of current microarray designs is that they are, for the purpose of whole genome studies, severely underutilized; similarly, for biosensing applications, existing microarray systems cannot be used for simultaneous identification of a large number of microorganisms and their strains due to technological limitations.<br\/><br\/>The investigators study novel array architectures, termed compressed sensing DNA microarrays. The research involves finding DNA probes that serve as group identifiers for classes of microorganisms; designing sparse sensing matrices for DNA group identifiers; developing compressed sensing reconstruction algorithms capable of handling saturation effects arising due to high agent concentration levels; characterizing the fundamental trade-offs between distortion and sensor dimension for non-linear arrays; and, analyzing the complexity of integrating compressed sensing microarrays into existing biosensor networks.","title":"Collaborative Research: Design and Analysis of Compressed Sensing DNA Microarrays","awardID":"0821910","effectiveDate":"2007-09-15","expirationDate":"2012-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["518457"],"PO":["564898"]},"132881":{"abstract":"Abstract <br\/>The goal of this collaborative exploratory research project (0738652, Clement Yu, UIC and 0738727 Weiyi Meng, SUNY Binghamton) is to investigate the potential benefit of a dictionary-based approach for document retrieval. This project aims to demonstrate within one year that within a given domain, the use of multiple dictionaries (both domain specific dictionaries and general dictionaries) will obtain high retrieval effectiveness. The demonstration will be facilitated using existing TREC query and document collections. Rules for adding semantically related terms to queries that can yield high retrieval effectiveness within the selected domain will be identified. These rules will be carefully analyzed to obtain fundamental insights for the gain of effectiveness achieved due to the use of the dictionaries. This project is also to seek evidence that certain dictionary constructs (e.g., the frequency of use of a word in a context) can lead to significant gains in effectiveness if they are added to a dictionary. The research results from this project will lay the foundation in achieving longer-term goals that include the identification of domain independent principles of using different types of dictionaries in the same system, and the development of tools to add useful dictionary constructs across dictionaries and to assist users in query expansion semi-automatically when there are multiple dictionaries. It is expected that the proposed project can have a significant impact on search engine technology, including retrieval in specialized domains such as law and medicine, question-answering, blog retrieval and analysis, and enterprise search. Research results will be incorporated into several courses the PIs teach and students will be recruited to participate in the research activities. Research results will be disseminated through published papers as well as a textbook on Web-based search technology. The project Web site (http:\/\/www.cs.binghamton.edu\/~meng\/DocRetSGER.html) provides access to research results.","title":"SGER\/Collaborative Research: Intelligent Use of Dictionaries for Document Retrieval","awardID":"0738727","effectiveDate":"2007-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["434747"],"PO":["563751"]},"130582":{"abstract":"A key challenge before the semiconductor industry is coping with high errors rates resulting from the decreasing size of chip features. Transient faults, along with permanent defects and stochastic assembly, make it difficult to implement traditional architectures. Research has been done on routing around<br\/>defects and coping with large amounts of device variation. Little is known, however, about how to cope efficiently with high-rates of transient errors during computation. This research will take a new systematic approach to the tolerance of transient failures. The goal is to help the semiconductor industry to better understand the dimensions of the nanoscale reliability problem. This research has relevance to space-borne applications where error control can serve as an alternative to radiation hardening. <br\/><br\/>This research employs a sophisticated approach to fault-tolerant computation. First, it exploits differential reliability, that is, it examines the use of a small number of reliable elements to oversee a large number of<br\/>unreliable elements. Second it draws on the success of coding theory to explore both special and general methods to encode inputs and outputs of a potentially faulty computation, paying particular attention to a seminal approach taken by Spielman in 1996. By encoding computations, faults at the encoded outputs can then be detected and corrected. Third, it examines the use of small check computations followed by possible rollback, where most of the checking is done using unreliable elements. Allowing a computation to be<br\/>repeated in time, rather than space, reduces the overhead of fault free computations. The design work is expected to have immediate impact on practice whereas development of a general theory is expected to have a<br\/>longer-term impact.","title":"Nanoscale Coded Computation and Storage","awardID":"0726602","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["497005"],"PO":["562984"]},"133420":{"abstract":"Abstract<br\/><br\/>IIS - 0741326<br\/>Martin, James H.<br\/>University of Colorado at Boulder<br\/>Relevance Models for Digital Repository Management<br\/><br\/>This SGER addresses issues associated with repository development and management. A key issue to be addressed is automatic assessment of the \"relevance\" of a resource to a topical domain without the mediation of a human domain expert. To achieve this, the project will investigate, develop and evaluate machine learning methods for building relevance models. Previous work by the investigators with models \"trained\" to automatically judge quality of a resource will be applied. These will be used in conjunction with domain independent quality indicators. Among the general quality indicators explored to date are presence of graphics and explanatory illustrations, good writing style and structure, and authoritative references. The models are evaluated by comparing their performance and results with those of human experts. When performance of the models approximate expert human performance, tools can be produced that can expedite and simplify digital repository management.","title":"SGER: Relevance Models for Digital Repository Management","awardID":"0741326","effectiveDate":"2007-09-15","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["24532","501288"],"PO":["469867"]},"131121":{"abstract":"One of the main challenges of software engineering is verifying the correctness of software. In the eighties the methodology of program `result checking' and `result correcting' was introduced. This approach focuses on correctness of the code per input rather than full program verification.<br\/>The current investigation will revisit the result checking and correcting methodology, emphasizing a general complexity theoretic approach rather than the function specific approach pursued earlier.<br\/>The intellectual merit of the project is that it will broaden our understanding of how to design general purpose program checkers and correctors, teach methods to exploit fast heuristics without sacrificing correctness, and study, in depth, the relation between the property testing field and program checking and correcting. The project promises to have broad impact on the reliability of<br\/>software.<br\/><br\/>This research involves, the following directions:<br\/>1. Characterize general {\\it classes} of functions which posses efficient checkers and correctors.<br\/>2. Introduce a new model for program checking and correcting in which the checker and corrector<br\/>have access to a short advice string in addition to the program to be checked and corrected. The advice-string is computed off-line ahead of on-line checking of programs. Such model allows treating more general function families than previously done. In particular, it allows the design of a single checker and corrector for many functions, where each individual function is associated with a different advice string.<br\/>3. Pursue new measures of efficiency for program checkers and correctors which will circumvent some of the challenges which arise in the field. In the advice model, the length of the advice will be incorporated into the complexity of the checking procedure and may be traded with the number of on-line calls of the checker to the program to be checked.<br\/>4. Harness the remarkable progress made in the field of property testing to the testing and correcting of programs.<br\/>5. Explore how the notions of program testers and correctors may enable the convertion of fast heuristics into correct programs with improved average case running time.","title":"New Handles on Program Correctness","awardID":"0729011","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["562010"],"PO":["565251"]},"133783":{"abstract":"In modern organizations, people must work together to find and share information, to locate expertise, and to carry out a wide variety of information activities. However, in these collaborative environments, information behavior is still viewed from a primarily individual perspective. This misperception has lead to organizations creating processes and technologies that facilitate and support individual information behavior, but not collaborative information behavior (CIB). Few researchers have focused on the role that collaboration plays in information seeking and retrieval activities. This proposal addresses two critical questions: (1) What triggers collaborative information behavior? (2) How do team members respond to these triggers?<br\/><br\/>The goal of this research is to refine an emerging analytical model of collaborative information behavior by focusing on CIB triggers in a medical context. An ethnographic study will be conducted among distributed IT teams in a regional center and surrounding rural hospitals. The contributions of the project will be the identification of different categories of CIB triggers, an improved understanding of CIB, design criteria to support the development of collaborative information retrieval tools.<br\/><br\/>Broader impacts <br\/>A deeper conceptual understanding of CIB triggers and how people respond to them can lead to improving collaborative practices as people seek and share information needed to address critical issues in different environments. This improved understanding will also lead to the development of more robust information retrieval systems that will support collaboration amongst users during information seeking and retrieval activities. This will address the issues that are limiting, and in some cases, preventing people from effectively and efficiently using the vast amount of information content available to people as they collaborate to solve problems.","title":"SGER: Identifying Triggers for Collaborative Information Behavior: A Field Study of Rural Healthcare IT Teams","awardID":"0742860","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["559463","456075"],"PO":["565227"]},"131154":{"abstract":"Abstract:<br\/><br\/>Future wireless networks are composed of a massive number of nodes densely distributed in large geographical areas. Such networks are used in applications such as wide area environmental protection, transportation, automated agriculture, or wireless micro-sensing in civil infrastructure systems. Information generated by distributed sources is transported to the destinations by collaborative efforts of nodes that forward the traffic of each other; therefore, the information is diffused over routes composed of many hops, each contributing to a short range transmission. <br\/>Careful analysis of the networks with such large number of wireless nodes involves a prohibitive level of complexity. This complexity is due to the uncoordinated interactions between each pair of nodes in the network (e.g., due to interference of simultaneous transmissions); as a result, little is known about the behavior of massively dense wireless networks.<br\/><br\/>The introduced methodology models a dense wireless network by a continuum of nodes. The spatially continuous model of information flow is a very promising methodology to overcome the prohibitive complexity of conventional discrete space methods. The project is expected to produce powerful design and analysis tools for different purposes such as minimizing the number of required wireless nodes for a given spatial distribution of information sources, finding minimum required density of nodes in space, determining the placement of nodes, minimizing the transmit power of nodes, load balancing, etc. The project is an important step towards development of a theory of information flow in dense wireless networks. Such a theory is the wireless networking counterpart of the classical flow theory of other branches of science and engineering such as fluid dynamics, heat exchange, and electrostatics.","title":"Information Flow Theory in Dense Wireless Networks","awardID":"0729129","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["456214"],"PO":["432103"]},"134674":{"abstract":"Proposal No: 0747873 <br\/>PI: Gyorgy Buzsaki <br\/><br\/>Abstract:<br\/><br\/>This award supports the preparation and sharing of computational neuroscience data as part of an exploratory activity aimed at catalyzing rapid and innovative advances in computational neuroscience and related fields. The data to be shared in this project are physiological and anatomical data from the rat hippocampus, including (1) recordings from hippocampal CA1 neurons during open field foraging, (2) simultaneous intracellular and extracellular in vivo recordings from CA1 pyramidal cells and histological identities of those neurons, (3) quantitative information on the cellular connectivity of the hippocampal formation, and (4) axonal reconstruction data from in vivo preparations. Anatomical and physiological data will be cross-annotated to facilitate browsing and integration, and provided in a form that is compatible with widely used simulators. It is anticipated that these data will be useful for developing anatomically and physiologically realistic neural networks and understanding emergent behavior of neuronal populations, in particular, the mechanisms of memory.","title":"CRCNS data sharing: Physiological and anatomical properties of hippocampal neurons and connections in vivo","awardID":"0747873","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[357915],"PO":["564318"]},"131044":{"abstract":"Computational Foundations of Information Markets<br\/><br\/>Information markets are markets specifically designed to aggregate information distributed among autonomous agents by enabling trade in securities for which the ultimate payoff value depends on future events. In recent years, many information markets have been deployed on the Internet; the deployed markets include markets to aggregate information and opinions on political events, scientific and technological breakthroughs, movie box office receipts, and the public interest in new products and technologies. Research will be conducted into basic strategic properties of information markets, including the design of new market structures with attractive incentive properties, as well as the computational capacity of these markets to aggregate information. The results of this project will be of direct importance to the growing industry that is designing or deploying information markets. <br\/><br\/>Research will be conducted in three areas: (1) Developing and analyzing a strategic model of novel information market forms, and using it to characterize markets in which traders cannot profitably mislead other traders. (2) Analyzing the potential loss of informativeness when traders have external preferences over market outcomes, and developing composition principles that enable related markets to operate while controlling this information loss. (3) Characterizing the aggregates that can be computed, speed of computation, and communicative efficiency of information markets.<br\/>This research will tackle fundamental problems on strategic and computational aspects of information markets, as well as strengthen the connection between information markets and classic information theory.<br\/>Rigorous results in the studied areas will considerably advance our understanding of information markets.","title":"Computational Foundations of Information Markets","awardID":"0728768","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["505391"],"PO":["565251"]},"131165":{"abstract":"To automatically plan tasks involving contact between objects, accurate prediction of object motions is essential. Applications include collaborative human-robot manipulation, industrial automation, engineering design, and physics engines for computer games. The intermittency of contact and stick-slip behavior make it difficult to simulate multibody systems stably and accurately. Commercially available multibody simulation software has difficulty simulating even simple systems with contacts. As a result, users must resort to trial-and-error to find simulation parameters that yield believable, not necessarily accurate, results. The algorithms developed in this research project will lead to improved future versions of simulation products such as Adams and Working Model.<br\/><br\/>The primary sources of stability and accuracy problems in multibody simulation are polyhedral representations of smooth objects, decoupling of collision detection from the solution of the dynamic time-stepping subproblem, linearization of Coulomb friction model, and errors in model parameters. This research focuses on formulations, algorithm development and analysis of time-steppers to eliminate the first three error sources. The result will be a fully-implicit, stable, accurate, optimization approach to simulating systems of rigid objects undergoing intermittent contact; the objects will be modeled using implicit and parametric surface representations. No previous general method has been developed that combines dynamics and geometric constraints in a fully-implicit manner. By using the new time-stepper as a ``ground truth\" model, all previous models can be compared, so that for the first time, the error effects of the most common approximations can be quantified. This research will involve graduate and undergraduate students. The results will be incorporated into our simulation package and introduced in the robotics courses at RPI.<br\/>Outreach activities include summer Lego robotics activities for middle school students.","title":"Fully-Implicit Time Stepping Methods with Integrated Proximity Queries for Accurate Simulation of Multi-Rigid-Body Systems with Intermittent Contact","awardID":"0729161","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7933","name":"NUM, SYMBOL, & ALGEBRA COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["534411","534411","553786"],"PO":["565157"]},"133596":{"abstract":"Spelman College proposes the ARTSI (Advancing Robotics Technology for Societal Impact) Alliance in collaboration with Florida A&M University, the University of the District of Columbia, Hampton University, Morgan State University, Norfolk State University, Winston-Salem State University, the University of Arkansas-Pine Bluff, Carnegie Mellon University, Georgia Institute of Technology, Brown University, Duke University, the University of Alabama, the University of Washington, and the University of Pittsburgh. Seven of these partners are HBCUs and seven are Carnegie Research I institutions. Their collaboration joins the strengths of HBCUs in conducting outreach and education in a nurturing learning environment with those of the R1's for conducting world class research. The ARTSI Alliance will motivate students to pursue computer science careers by emphasizing the creativity and socially beneficial aspects robotics technology with hands-on projects, curriculum, and media. ARTSI activities will span the academic pipeline from K-12 through the faculty ranks. At the K-12 level, students will be recruited with community outreach using robotics and art, robotics road shows, and a robotics educational film online repository. At the undergraduate level, HBCU students will be exposed to new robotics curriculum, and they will be encouraged to pursue advanced training in graduate school through summer research experiences, collaborative, interdisciplinary robotics projects in the arts and health, instruction in technical film documentation, student virtual film festivals, annual robotics conferences, and instruction in entrepreneurship for computer science. At the faculty level, it will increase the number of HBCU faculty who educate students in robotics and involve students in robotics research by providing faculty mentoring, summer research experiences for underrepresented faculty at R1 robotics labs, robotics summer workshops, and development and dissemination of robotics educational material through a web-based portal. The Alliance will have industry partners, including Seagate, iRobot, Microsoft Research, and Juxtopia, as well as educational partners, including Florida-Georgia Louis Stokes Alliance for Minority Participation and Computer Science Teachers Association.","title":"Collaborative Research: BPC-A: ARTSI: Advancing Robotics Technology for Social Impact","awardID":"0742089","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7584","name":"ITR-BROADENING PARTICIPATION"}}],"PIcoPI":["554887",355232],"PO":["561855"]},"134333":{"abstract":"The purpose of this symposium is to explore the synergies between creative cognition and intelligent systems in a cross-disciplinary setting that fosters cooperation both in designing creative systems and in creatively designing systems. This focus on creativity in the context of intelligent systems has the potential for increasing innovation in existing fields of research as well as for defining new fields of study.<br\/><br\/>Major goals for the research presented and discussed in this symposium include:<br\/>Artificially Creative Systems: the goal is the development of new types of intelligent systems that produce or simulate creativity using novel approaches to reasoning, searching, and representing knowledge. These systems may be inspired by human creativity or by the possibilities of artificial systems that are beyond human capabilities.<br\/>Computational Models of Human Creativity: the goal is to construct cognitive models of human creativity that can be the basis for computational creativity.<br\/>Intelligent Systems for Supporting Creativity: the goal is to produce user interfaces, interaction design, decision support, and data modeling techniques that lead to the development of intelligent assistants that support the user in being more creative.","title":"Creative Intelligent Systems Symposium","awardID":"0746077","effectiveDate":"2007-09-15","expirationDate":"2009-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":["493953"],"PO":["424970"]},"131066":{"abstract":"Research Abstract<br\/><br\/><br\/>Multicasting, where common information is transmitted from a source to multiple destinations,is the core component of many network applications such as multimedia distribution, information update, group conferencing, etc. Creative encoding of network trac at the intermediate terminals can signicantly improve the throughput of a multicast over conventional replicate-and-forward approaches. Due to the open nature of the wireless medium, communication throughput of a wireless link depends on its transmission power and on the interference generated by nearby network terminals. The goal of this research is to develop a systematic framework for maximizing a general<br\/>multicast utility function via the joint optimization of transmission power, rate, and schedule,within the framework of network coding.<br\/><br\/>The investigators model a wireless ad hoc network by means of a topology graph, which contains point-to-point links and point-to-multipoint hyperarc links with coupled link throughput capacities. Under the assumption of optimal network coding, the research first develops an iterative gradient-steering\" optimization framework. A network utility maximization problem is converted<br\/>to a transmission scheduling problem that maximizes an approximated utility in its gradient direction, coupled with a steering vector update that continuously updates the approximated utility and its instantaneous gradient direction. The research then extends the framework to utility max-<br\/>imization for a network with multiple multicast sessions. Finally, the research develops distributed algorithms to optimize a global utility of a large scale network using local controllers. In addition to the planned research, the investigators will also try to extend the algorithm to ad <br\/>hoc networks with time varying channels where utility maximization requires efficient exploitation of the channel diversity gain.","title":"Collaborative Research: Systematic Optimization in Wireless Multicasting","awardID":"0728826","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["485630"],"PO":["564924"]},"126952":{"abstract":"The objective of this project is to develop a modeling framework in order to enable extensive use of prosodic information, such as pitch, duration and energy characteristics, in a large class of applications that call for spoken language understanding. For this purpose, prosodic features are extracted from the speech signal over regions defined by automatically detectable events. The result is a variable-length sequence of usually high-dimensional vectors, with mixed discrete and continuous distributions and undefined values. The focus of the project is the search for a transformation that, when applied to the prosodic features, results in a single vector that can adequately represent the important characteristics of the original sequence of prosodic features. The proposed transform is formed by projecting the distribution of the features in a certain sample onto a set of probability distributions represented by dynamic Bayesian networks in a predetermined dictionary.<br\/><br\/>The ultimate goal of the project is the creation of a general probabilistic model-based transform paradigm that can act robustly on complex feature sets. This work will therefore also contribute to other domains where features exhibit characteristics that are challenging for standard approaches. The tools and corpora developed during the project will be made available to the community. The results from this project will contribute to scientific knowledge on the use of prosodic information and increase the capabilities of spoken language understanding and dialog systems.","title":"RI: Statistical Modeling of Prosodic Features in Speech Technology","awardID":"0710833","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["441541"],"PO":["565215"]},"134586":{"abstract":"This is a proposal to develop and test new methods for conducting research in the history of contemporary computing. These are exploratory in nature, and are proposed in an effort to overcome the \"top down\" bias inherent in existing research methods that collect information preponderantly (or even exclusively) from pioneering or leading figures in the field. These proposed research methods will, in several distinct but complementary ways, provide insight, information, and documentation on a much wider and more diverse set of participants in the evolution of computing.<br\/><br\/>Consideration of these new research methods was prompted when planning for a wide-ranging historical study of NSF's FastLane system as an early model of scholarly cyberinfrastructure. Doing traditional oral histories with the eight to ten \"core\" NSF designers of FastLane was easy to envision. But research tools were simply not available to make a feasible study of the large and diverse set of FastLane users (e.g., NSF legacy staff, staff of sponsored projects administrations, and principal investigators). Doing traditional time-intensive oral histories with hundreds of users would require an unrealistically oversize research team. Moreover, there is a pressing question whether NSF succeeded in designing a system that could encourage - rather than frustrate - proposal submissions by PI's from universities that did not possess top-notch computing resources (especially PI's at HBCU and EPSCoR-state universities). Collecting a large and diverse set of data, from numerous PI's and SPA staff, is necessary to address this latter issue. These new research questions demanded new research tools and methods.<br\/><br\/>Broader Impact<br\/>The research tools proposed in this project have significant potential to transform existing research methods and practices in the history of computing, as well as in the closely related field of contemporary history of science, technology, engineering and medicine (STEM). The two tools - a web-based interview platform and a complementary 'wiki' site set up to elicit and record participants' varied perspectives - are promising attempts to develop potentially transformative research methods. Scholars studying the STEM domain have become increasingly aware that a proper understanding of advances in science and technology requires investigating the dynamics of institutions and organizations, including research on the achievements, attitudes, and perspectives of rank-and-file members, and not merely study of a small number of leading figures. By making possible the collection of larger and more diverse sets of qualitative data, these novel research tools and methods could even transform the broader public understanding of science and engineering.","title":"SGER - Research Methods for Contemporary History of Computing","awardID":"0747445","effectiveDate":"2007-09-15","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["485963","485962"],"PO":["388678"]},"133497":{"abstract":"This high-risk, high-payoff project seeks to make database management systems much more usable than they are today, through the introduction of a new presentation data model. Traditionally, database management systems have had two conceptual layers -- a physical layer comprising the actual implementation and a logical layer comprising a formal decomposition of a database into tables, rows, constraints, etc. The user interacts with the logical layer, and is shielded from physical layer implementation details. This project introduces a new presentation layer above the traditional logical layer. The user interacts with this presentation layer, and is shielded from logical layer details such as relational decomposition and joins. Through this means the root cause underlying much of the complexity of interacting with traditional database systems is eliminated. This project includes work both to develop the theoretical underpinnings of the presentation data model as well as to construct a prototype system representing a vertical slice through the three layers.<br\/><br\/>The broader impact of this project is in the potential for this project to greatly improve the way databases are used, not just by computer scientists but also by researchers in other disciplines and by the public at large. The project directly supports the training of one doctoral student, and indirectly impacts the education and training of several additional students, both graduate and undergraduate, through their participation in directed projects. The project web-site is http:\/\/www.eecs.umich.edu\/db\/usable","title":"SGER: An Exploration of the Presentation Data Model","awardID":"0741620","effectiveDate":"2007-09-15","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["533266"],"PO":["469867"]},"131077":{"abstract":"The diverse functions performed by a living cell during her life cycle are controlled and regulated through complicated gene- and protein- interaction networks. Any pattern of irregular behavior of genes in the network can lead to cell malfunctioning, cell death, or the emergence of diseases like cancer. It is therefore of crucial importance to recognize erroneous gene interaction patterns and compare them to those in healthy cells. For this type of study, one of the most frequently used bioengineering systems is the well known DNA microarray device. DNA microarrays consist of grids of spots containing unique genetic identifiers for each of the tested genes, capable of generating snapshots of gene activity in terms of selective DNA sequence annealing. Microarrays have also found many other applications in the field of molecular biology, most notably for the purpose of detecting hostile microbial agents in food, water, and in the air. One of the main drawbacks of current microarray designs is that they are, for the purpose of whole genome studies, severely underutilized; similarly, for biosensing applications, existing microarray systems cannot be used for simultaneous identification of a large number of microorganisms and their strains due to technological limitations.<br\/><br\/>The investigators study novel array architectures, termed compressed sensing DNA microarrays. The research involves finding DNA probes that serve as group identifiers for classes of microorganisms; designing sparse sensing matrices for DNA group identifiers; developing compressed sensing reconstruction algorithms capable of handling saturation effects arising due to high agent concentration levels; characterizing the fundamental trade-offs between distortion and sensor dimension for non-linear arrays; and, analyzing the complexity of integrating compressed sensing microarrays into existing biosensor networks.","title":"Collaborative Research: Design and Analysis of Compressed Sensing DNA Microarrays","awardID":"0728867","effectiveDate":"2007-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7797","name":"COMM & INFORMATION FOUNDATIONS"}}],"PIcoPI":["497441"],"PO":["564898"]},"125885":{"abstract":"This interdisciplinary project investigates human cognition of spaces to improve virtual environments, both from a user and an author's perspective. The objectives are to (1) improve virtual environments so that better learning can occur in them, and (2) develop authoring methods for virtual environments informed by the cognitive demands that people have when learning spaces. This research project should advance the design and authoring of virtual environments by leveraging human cognitive capabilities. The programs seeks to develop a system to increase the user's sense of presence and sensitivity to the environmental scale of virtual environments. It further seeks to develop locomotion interfaces to assist exploring large virtual environments from within small physical ones. A goal is to employ human-centered representations for locomotion in virtual environments and to develop methods for skill acquisition in virtual environments. This research proposal advances the scientific understanding of human cognition and learning as well. The research proposes studies that will be informative about the broad role that environmental geometry and self-representation play in perception, orientation, and navigation, while controlling factors that are extremely difficult, if not impossible, to control in the real world. A rigorous evaluation program for all components of the project is planned.<br\/><br\/>The importance of this proposal is that virtual environments provide people with opportunities to experience places and situations remote from their actual physical surroundings. Virtual environments allow the simulation of real-world events in a controllable and re-usable environment. They potentially allow people to learn about an environment which, for reasons of time, distance, expense, and safety, would not otherwise be available. Virtual environments could have a huge impact in education, entertainment, medicine, architecture, and training, but they are not widely used because of their expense and delicacy. The research program in this proposal should significantly improve the quality of learning in virtual environments, to reduce the time and cost of authoring virtual environments, and to overcome likely impediments to their widespread use. Moreover, this proposal builds a scientific program to develop a better understanding of the cognitive capabilities of humans in immersive virtual environments, and does so in a way that will inform the design process for such environments and our understanding of how humans reason about space.","title":"HCC: Design and Evaluation of Spatially Compelling Virtual Environments","awardID":"0705863","effectiveDate":"2007-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["376155","376156",334117,"486038"],"PO":["564456"]},"134245":{"abstract":"Proposal No: 0745685 <br\/>PI: Dario L. Ringach<br\/><br\/>Award Abstract:<br\/><br\/>This award supports the preparation and sharing of computational neuroscience data as part of an exploratory activity aimed at catalyzing rapid and innovative advances in computational neuroscience and related fields. The data to be shared in this project are single- and multi-unit recordings from primary visual cortex, obtained using either standard microelectrodes or micro-machined electrode arrays. Both spontaneous and stimulus driven activity are available in a number of different conditions, including standard receptive field characterizations (e.g., orientation tuning, spatial and temporal frequency tuning) and more specific experiments such as sub-space receptive field mapping and natural image sequences. Data from micro-machined electrode arrays also include local field potentials and surface EEG. It is anticipated that these data will be useful for studies of visual processing, population coding, and retinotopy, and that the large-scale high-dimensional data will be well suited for exploration by novel machine learning and statistical methods.","title":"SGER: CRCNS Data Sharing: Micro-machined Electrode Recordings from Primary Visual Cortex","awardID":"0745685","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[356987],"PO":["564318"]},"133057":{"abstract":"ABSTRACT<br\/>0739436<br\/>Ralph Cavin<br\/>Semiconductor Research Corporation<br\/><br\/>Integrated Circuit technology is enabling an expanding array of applications which themselves drive technology innovation. In this forum, we consider an extreme prototypical application as a vehicle to focus research efforts. Imagine that we desire to design and fabricate an active micron-sized system that performs in-vivo sensing and possibly interaction with a single living cell. The technological challenges that must be addressed to develop such a system are daunting and encompass almost every facet of integrated system technology including sensing information processing, energetics, communication, packaging, and possibly actuation. In this forum, we expect to examine these essential technologies from the point of view what may be<br\/>ultimately achievable, given our present comprehension of the projected future capabilities of science and integrated circuit technology. The ultimate goal is to obtain a forum consensus on future feasibility of the prototypical in-vivo systems.","title":"SRC Forum on Nano-Morphic Systems: Processes, Devices, and Architectures","awardID":"0739436","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["500150"],"PO":["562984"]},"127502":{"abstract":"The vast variability of the human speech signal remains a central challenge for Text-to-Speech (TTS) systems. The objective of this research is to develop TTS technologies that focus on elimination of concatenation errors, and accurate speech modifications in the areas of coarticulation, degree of articulation, prosodic effects, and speaker characteristics. The investigators are exploring an asynchronous interpolation model (AIM), which promises to provide for high-quality and flexible TTS. The core idea of AIM is to represent a short region of speech as a composition of several types of features called streams.<br\/>Each stream is computed by asynchronous interpolation of basis vectors.<br\/>Each basis vector is associated with a particular phoneme, allophone, or more specialized unit. Thus, the speech region is described by the varying degrees of influence of several types of preceding and following acoustic features. Using AIM, the investigators are also developing methods to optimally compress the acoustic inventories of TTS systems, given a size or a quality constraint, and to adapt the system to a new voice, given a few training samples. The system being researched forms a hybrid between traditional concatenative and formant-based synthesis, having advantages of both, resulting in a high-quality, optimized TTS system with voice adaptation capabilities. TTS has generally recognized societal benefits for universal access, education, and information access by voice. Our research will make it possible, for example, to build personalized TTS systems for individuals with speech disorders who can only intermittently produce normal speech sounds.","title":"HCC: High-Quality Compression, Enhancement, and Personalization of Text-to-Speech Voices","awardID":"0713617","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["562760","438631"],"PO":["565215"]},"126534":{"abstract":"The goal of this planning project is to assemble a multi-disciplinary and multi-institutional team of computer scientists, biologists, marine scientist, and environmental researchers to develop a CRI large community resource proposal for building a massive and heterogeneous data repository. The data repository will consist of biological, ecological, and geographical information science (GIS) related data that will enhance cutting-edge computing research in the Gulf of Mexico (GOM). The repository will incorporate new data, but will largely consist of existing data from a variety of ocean observing systems around the GOM and the Harte Research Institute (HRI) at Texas A&M University-Corpus Christi (TAMU-CC). The development of the repository will be an interdisciplinary effort involving researchers from computer science, GIS, marine science, biological science, and environmental science, etc. The unique coastal location of TAMU-CC is an ideal environment for the development of the repository. The primary activities of this planning project are: (1) soliciting and analyzing detailed requirements from the research community; (2) examining and identifying data sets from different GOM ocean observation systems and the HRI; and (3) investigating the alternative repository architectures. The research objective is to provide the research community with multi-dimensional data sets for managing, analyzing, storing, sharing, visualizing, querying, and disseminating. The inherent dimensionality of the repository will stimulate the development of novel research supporting integrated research in a wide range of computing areas. The integration of data from different ocean monitoring systems and the HRI will lead to further renewal of demands for the development of novel technologies designed for the organization and mining of the data to enhance computing research. The heterogeneous nature of weather, oceanic and coastal observation, and biological and ecological data?ranging from free-text, image, sound, video, and sensor readings to GIS airborne multi-spectral imaging?provides an excellent research resource and test-bed for development of novel computing technologies. Areas of possible concentration are data integration, database modeling, information storage and retrieval, data mining, human computer interaction, modeling and forecasting, visualization, parallel processing, etc. The integrated repository will not only aid research in the GOM by providing enormous amount of raw data, but also become a valuable resource for the public, local government officials, scientists, natural resource managers and educators. Once completed, the repository will serve as a data resource for students in interdisciplinary science courses. The<br\/>project will also have strong potential for extended outreach to other institutions in the GOM, including a K-12 outreach component.","title":"CRI: Planning - A Massive and Heterogeneous Data Repository for Computing Research on the Gulf of Mexico","awardID":"0708596","effectiveDate":"2007-09-01","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["528389",335719,335720,"444746","497703"],"PO":["565136"]},"133079":{"abstract":"The objective of this project is to further expand the concept of quasi-uniform gridding of the sphere and explore its potential for improvement of various aspects of modeling of the large-scale atmospheric flow, including prediction of hurricanes and downscaling of the regional climate. <br\/><br\/>The quasi-uniform rectangular grids (cubic and octagonal) that will be studied for global circulation models by the PI and his collaborators provide an attractive numerical paradigm because of their capability to efficiently handle the computing resources, high resolution in tropical and equatorial regions, and absence of strong singularities around geographical poles. A global modeling framework employing the concept of quasi-uniform grids has been recently developed and successfully preliminary tested by the PI using numerical infrastructure of the National Center for Environmental Predictions' (NCEP) regional model as a prototype. <br\/><br\/>A set of various expansions and implementations of the developed framework is used in this project. <br\/><br\/>The expansions include several variations of the quasi-uniform grids which will be able to describe the variable resolution; a new, curvilinear formalism that may further improve the efficiency; higher order Arakawa type schemes (4th and 6th order); a new innovative method for treatment of the lower boundary, and merging with NCEP's version of the non-hydrostatic Weather Research and Forecasting (WRF) model. <br\/><br\/>The most important of the implementations include testing of the variable resolution quasi-uniform framework in the medium range forecasting of hurricanes and in the regional climate simulations using data from the Stretched Grid Model Intercomparison Project. <br\/><br\/>The challenging novel ideas for numerical modeling of the large scale atmospheric flow, such as new global grids, new numerical schemes and new approach for treatment of the terrain constitute the intellectual merit of the research. <br\/><br\/>This research may deliver important new pointers for advancement of weather forecasting in general, and particularly the skill of hurricane prediction, by which it will realize the broader impact on the community. In addition, the developed numerical techniques will be transferable to other geophysical disciplines dealing with mapping of the Earth's surface, such as oceanography and seismology.","title":"Further Advancement and Implementations of a Global Framework of Quasi-Uniform Rectangular Grids","awardID":"0739518","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0600","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"7699","name":"ICER"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0602","name":"Division of DIV ATMOSPHERIC & GEOSPACE SCI","abbr":"AGS"},"pgm":{"id":"5740","name":"CLIMATE & LARGE-SCALE DYNAMICS"}}],"PIcoPI":[353962],"PO":["559935"]},"125225":{"abstract":"Rusinkiewicz<br\/>Princeton University<br\/><br\/><br\/>Abstract:<br\/><br\/>The development of computer-based methods for stylized depiction of 3D models promises to help scientists and engineers produce clear and compelling illustrations and visualizations. However, despite steady progress on making 3D acquisition inexpensive and practical, obtaining complete 3D models of complex objects remains challenging. This project investigates the creation of illustrations from a data type lying between simple 2D images and full 3D models: images with a surface normal stored at each pixel. These ``RGBN images'' have the potential of becoming a widely-used data type because of the ease, flexibility, and quality with which they may be acquired, and because they contain enough information to permit many analysis and depiction tasks. That is, they combine an acquisition process only mildly more complex than that for digital photographs with the power and flexibility of tools originally developed for full 3D models. Methods for RGBN shape analysis and nonphotorealistic rendering will allow for exploration and communication of surface shape and detail in domains such as medical and technical illustration, art history, and forensic analysis.<br\/><br\/>This project encompasses a comprehensive investigation of the RGBN image data type, with the aim of developing a practical pipeline for acquiring images with normals and generating stylized depictions. On the acquisition side, the project is developing hardware\/software acquisition systems for robustly acquiring RGBN images in contexts ranging from millimeter-scale objects through cityscapes, and including both static and moving objects. Next, the project includes a mathematical analysis of methods for signal processing on RGBN images, including scale-space analysis and derivative estimation. These signal processing techniques are used to develop methods for depicting shape and color, including shading, line drawing with suggestive contours and crease lines, exaggerated shading, and enhancement of depth discontinuities. Finally, RGBN analysis and processing algorithms such as texture analysis\/synthesis, inpainting, and similarity-based search are being developed.","title":"Images with Normals: Acquisition, Analysis, and Depiction","awardID":"0702580","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["456692"],"PO":["532791"]},"127414":{"abstract":"Recent advances in smart Electro-active Polymers (EAP) have created a unique opportunity to design true biologically-inspired robots. However, the ionic EAP actuator has been observed by many researchers that the wiring power line, to the respective electrode surface, is challenging, especially in multi-segment design applications and micro-scale actuation. In order to adequately design robust robotic systems that can be adaptable to a variety of unstructured and tortuous environmental conditions, it is necessary to have breakthroughs in the intelligent power supply and the control unit. In this proposal, we introduce an innovative approach to use a wireless link between EAP based target locomotion units and a remote control\/power unit. The remote unit can provide necessary intelligence to the target locomotion units by modulating both frequency and amplitude of the microwave to selectively actuate a different segment of the EAP actuator by using a specially coded patch antenna pattern on the electrode surface of the actuator. The proposed microwave control systems have a wide spectrum of future engineering applications where proper intelligence capabilities need to be provided to the local locomotion unit. The success of the proposal can lead to the development of Integrative Biomimetics cluster that will provide necessary foundation for education and outreach programs.","title":"RI: Collaborative Research: Intelligent Microwave Power Transmission and Control System for Artificial Muscle-Driven Biomimetic Robotic Systems","awardID":"0713083","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["434794"],"PO":["429182"]},"125115":{"abstract":"Computer graphics is commonly used for interactive visualization and rendering in video games, electronic commerce or scientific visualization. These applications often demand real-time results, including multiple bounces of light (global illumination), material changes and spatially-varying local lighting. Computer graphics is also increasingly used to prototype or design illumination and material properties, for industries as diverse as animation, entertainment, automobile design, and architecture. A lighting designer on a movie set wants to pre-visualize the scene lit by the final illumination and with objects having their final material properties -- be they paint, velvet or glass. An architect wants to visualize the reflectance properties of building materials in their natural setting. In many applications, much greater realism and faithfulness can be obtained if the lighting or material designer could interactively specify these properties. In this research, we are developing the theoretical foundations and next generation practical algorithms for high quality real-time rendering and lighting\/material design.<br\/><br\/>Our research involves both significant theoretical and practical components. We are developing a new theoretical framework for analyzing the dimensionality of local object regions and locally-low dimensional approximation. We also analyze the theory and practical algorithms for designing materials, while rendering the final scene with full global illumination. Because appearance is not linear in the BRDF, our formulation involves a multi-linear tensor representation to handle multiple bounces. For interactive rendering of scenes with local lighting, and for general lighting design, we are developing an approach that relights a scene given a full incident light field. Finally, one of the banes of precomputation-based approaches is the long time for precomputation, especially once global illumination effects are taken into account. We are developing the theory and algorithms for a new photon-mapping approach that substantially accelerates the process.","title":"Collaborative Research: Theory and Algorithms for High Quality Real-Time Rendering and Lighting \/ Material Design in Computer Graphics","awardID":"0701992","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":[332004],"PO":["532791"]},"127425":{"abstract":"Advances in imaging technologies (Magnetic Resonance Imaging, for example) have significantly accelerated brain disorder studies. There is an urgent need to integrate, index and model multimodal data across a large population in order to discover a more detailed understanding about process interaction in this very complex biological system. Current state-of-the-art computational and software technologies fall short in multimodality data integration and modeling, and integrated analysis of diverse neuroimaging datasets across human subjects. The overall aim of this proposal is to develop a novel, rigorous framework for integrated modeling and analysis of multimodality neuroimaging data based on Riemannian geometry, multivariate simplex splines, and statistical learning. <br\/><br\/>Intellectual Merits <br\/>This interdisciplinary research team will design a fundamental framework for advanced and integrated analysis of brain imaging data. All research activities will address the following major themes and objectives: (1) To explore new theoretic tools based on Riemannian geometry of 3-manifolds for the development of a novel Canonical Volumetric Model (CVM) which provides volumetric mapping of individual brain to a solid unit sphere with accurate matching across subjects; (2) To design hierarchical spherical trivariate simplex splines for compact representation, integration, indexing and visualization of multimodality heterogeneous imaging data with high efficiency and accuracy, which can further refine the intersubject registration through level-of-detail matching in a higher dimensional physical space based on the integration of the hierarchical spline volume with Lagrangian dynamics; (3) To design new statistical learning and mining methods to analyze simultaneously the variety of data across the broad range of spatial and temporal scales and human subjects in order to infer the dynamics of brain functions in neurological disease studies. <br\/><br\/>Broad Impacts <br\/>This research will contribute to the data-intensive brain study by offering an accurate, robust, and innovative scientific approach for analytic integration, statistical modeling, and quantitative analysis of a variety of brain imaging data. The proposed computational framework has the potential to be applied across multiple areas of brain research as well as in clinical diagnosis. It is likely that this work will impact a large number of patients with neurological diseases and will provide a commonly accepted standard infrastructure for use by many other researchers. The PIs'' research endeavors will be tightly integrated with a complementary set of educational objectives, including: (1) the development of new strategies for truly multi-disciplinary science education; (2) the enhancement of the existing curricula; (3) the doctoral training of graduate researchers; (4) the implementation of mentoring activities for students from underrepresented groups.","title":"III-CXT: Collaborative Research: Integrated Modeling and Learning of Multimodality Data across Subjects for Brain Disorder Study","awardID":"0713145","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["519258"],"PO":["565136"]},"127436":{"abstract":"The Participatory Virtual Theatre project explores the use of distributed 3D virtual spaces for live performance. The goal of the project is to create an infrastructure for the presentation of a theatrical performance in 3D virtual space over the Internet, where actors, crew, and audience share and participate from different physical locations in a single theatrical experience. The proposed approach involves the adaptation of existing 3D virtual reality systems in developing an intuitive interface, enabling interaction using the language of theatre. The project will address technical challenges involving coordination and synchronization of events between the physical world and the virtual stage and explore new models of interaction based on the theatrical paradigm. Comparisons between user experiences in a physical theatre and in the virtual space will be made.<br\/><br\/>The Virtual Theatre project serves as both a research project and an educational experiment. From a research perspective, it examines theatrical elements, both artistic and technical, and adapts these into processes and systems that enable theatrical control and interaction in a highly distributed virtual space. From an educational standpoint, the project has been incorporated into existing curriculum, allowing for first-hand student involvement in the research aspects of the project, thus creating a rich, co-laboratory experience for students in both technical and artistic disciplines.<br\/><br\/>The proposed infrastructure will enable a new means for not only experiencing live theatre, but for participating in it. This approach will be valid without the restriction of physical access to the performance space, thus expanding the accessibility of live theatre to all who have a high speed Internet connection. It will allow those who might not otherwise be able to perform in a physical world to experience participation in theatre first-hand in the virtual space. Furthermore, with theatre being such a natural framework for collaborative interaction, the theatrical paradigms defined might be applied to other collaborative applications not involving the stage. Finally, this project will promote further refinement of a curriculum that fosters collaboration between artists and technologists in an academic setting.","title":"HCC: Participatory Virtual Theatre: Live Performance in a 3D Virtual Space Distributed Over the Internet","awardID":"0713201","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[337958,337959],"PO":["564456"]},"125258":{"abstract":"Project ID: 0702705<br\/>Title: Recon_guration and Defect Tolerance in Quantum-dot Cellular Automata Based Nano-Devices<br\/>PI: Xiaobo Sharon Hu<br\/>Co-PIs: Marya Lieberman, Wolfgang Porod<br\/>Inst: University of Notre Dame<br\/><br\/><br\/><br\/>ABSTRACT<br\/>NSF Unit Consideration: CPA - Foundations of Computing Processes and Artifacts<br\/>The proposed work is on constructing reconfigurable logic and devising defect detection, diagnosis and tolerance techniques for Quantum-dot Cellular Automata (QCA) based nano-scale devices. QCA- based devices differ fundamentally from traditional CMOS ones. They have the potential to alleviate challenges from interconnects and power consumption as CMOS device sizes continue to shrink. Basic QCA constructs have been experimentally demonstrated with both semiconductor quantum dots and nano-magnets. Implementing QCA devices with molecular charge containers has also shown great<br\/>promise. Though being a promising computing paradigm, QCA faces a same challenge as all other nano-scale devices. That is, defect rates are expected to be high. Reconfigurable logic and defect tolerance design are considered to be two powerful means to circumvent the effects of high defect rates. This project will significantly extend the state-of-the-art in constructing reconfigurable logic under the QCA model.<br\/><br\/>Successful completion of the project will lead to both novel reconfigurable logic constructs and new defect detection and diagnosis schemes. The proposed work will help predict whether it is practical to fabricate large scale QCA-based reconfigurable circuits, and whether such circuits can become a strong contender as a post-CMOS computing alternative. The proposed work will have a significant impact not only within the design community but also in the physical science community. It will contribute new knowledge in designing reconfigurable logic and circuits in the context of charge-coupled computing models. It will also play an important role in providing valuable feedback to physical scientists working on exploring various technologies for implementing QCA devices. As an integral part of the proposed work, a new course module on QCA- based computing will be developed, which emphasizes the interdisciplinary nature in this exciting<br\/>research area. A systematic endeavor will be made in recruiting undergraduate students, especially from the under-represented groups, to participate in the project.","title":"Reconfiguration and Defect Tolerance in Quantum-dot Cellular Automata Based Nano-Devices","awardID":"0702705","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["560914","550624","490724"],"PO":["562984"]},"127458":{"abstract":"IIS - 0713295<br\/>Frischer, Bernard<br\/>University of Virginia Main Campus<br\/>II CXT - Enabling a 3D Digital Cultural Heritage Pipeline: From Aquisition to Publishing to Archiving<br\/><br\/>In this proposal, an interdisciplinary research team of computer scientists and domain experts in the humanities will investigate acquisition, archiving, and publication issues pertaining to 3D virtual environments of cultural heritage sites. The long-term objective is to create a center to \"\"Serve and Archive Virtual Environments\"\" (SAVE), which will ultimately exist as an open repository of scientifically authenticated 3D cultural heritage models. The project will create cost-effective tools to more easily capture the data necessary for the creation of the models. Tools for version control and methods for sustainability will be developed. The project's workplan includes:<br\/>- development of an innovative 3D acquisition system for efficient, easy creation of 3D models of cultural heritage sites;<br\/>- research into archiving and presentation issues for 3D model repositories;<br\/>- deployment of a pilot 3D cultural heritage model archive; and,<br\/>- implementation of a complete process for editorial review and publication of authenticated 3D models<br\/>The resulting 3D archive will made publicly available as an online resource.","title":"III CXT - Enabling a 3D Digital Cultural Heritage Pipeline: From Acquisition to Archiving to Publication","awardID":"0713295","effectiveDate":"2007-09-15","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["451788",338013],"PO":["564456"]},"129527":{"abstract":"This research project examines the problem of providing high data-rate wireless connectivity to users in indoor environments. The goal is to be able to reach gbps\/user rates even when there are multiple users present. The technology that we are researching is to use is the 60 GHz ISM spectrum whose special propagation properties make it ideally suited to this task. The approach taken is to use multiple, spatially-distributed smart antennas in a room to provide coverage where needed and when needed. All the antennas are connected to a single access point which allows us to dynamically change spectrum and link allocation among the users (as they move or as their needs change). Indeed, the design of the access point is also novel since it needs to support a gross throughput of several gbps.<br\/><br\/>The innovations in this work include the exploitation of the special properties of 60 GHz, design of algorithms for efficient spectrum reuse, support for multiple MAC protocols within a room to better adapt to user needs, a novel access point architecture, and a tight correlation between design of the system and user access patterns. The methodology being followed is primarily theoretical and simulation-based.<br\/><br\/>Providing high data-rate wireless access to users is an important problem given the drive to push more and more services through the wireless pipeline. This project differs from previous ones in that this project has the ambitious goal of delivering gbps\/user. The research is a mix of physical layer, MAC layer, and algorithmic design. The expected results will make significant contributions in the areas of spectrum allocation as well as novel access point designs. The work will also potentially impact future development standards for these environments.<br\/><br\/>One product of this project is a detailed Opnet\/Matlab simulation environment for 60GHz indoor communications. This is useful to the larger wireless research community and will also be incorporated into the curriculum for lab practicum. In terms of outreach, the PI collaborates with the Saturday Academy (SA) of PSU, which serves K-12 students. The PI's contribution to SA is to lecture on rudimentary concepts of high-speed wireless networking (and the future of this exciting area). The PI, with the help of SAs, will actively recruit high-school students, particularly minority and under-represented, to intern under the Apprenticeships in Science & Engineering program, in which interns explore and experience while contributing to this project.","title":"NeTS-WN: Gigabits\/Sec\/User","awardID":"0722008","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["518079"],"PO":["557315"]},"129769":{"abstract":"Proposal #: CNS 07-22868<br\/>PI(s): Erkip, Elza<br\/> Panwar, Shivendra S.; Wang, Yao<br\/>Institution: Polytechnic University of New York<br\/> Brooklyn, NY 11201-3840<br\/>Title: MRI\/Acq.: Experimental Platform for Wireless Multimedia Networking<br\/><br\/>Project Proposed:<br\/>This project, acquiring an experimental platform to support integrated research and educational activities on wireless multimedia networking, examines problems of limited bandwidth of the wireless channel, of<br\/>interference caused from multiple users operating in the same band, of rapid variations due to signal fading, of limited battery life of wireless devices, and of speed and reliability of wireless networking. The instrumentation consists of multiple radios based on software defined radio platforms, wireless nodes and open source drivers based on the IEEE 802.11 Wireless Local Area Network (WLAN) standard, DSP platforms enabling real time video encoding and wireless transmission, dynamic power scaling, and power measurement, and test equipment. The instrument supports research on:<br\/>. Cooperative wireless networking, Wireless video transmission, Energy efficient networking, and<br\/>. Integration of research and education through the Wireless Information Systems Lab.<br\/>The platform contributes to advance the state-of-the-art in multimedia wireless communications, not only enabling testing of new and existing algorithms, but also leading new theory founded on more realistic assumptions. <br\/>Broader Impacts: The instrument impacts new wireless technologies, serves to integrate research and education through the Wireless Information Systems Lab (WISL), enables the training of undergraduate and graduate students in wireless communication, and development of new courses for the curriculum. It contributes to the first efforts of implementing a fully cooperative network, whose benefits have been well established through theory and simulations. The experimental platform is expected to accelerate commercial developments in the field and impact current wireless standards. The impact on industry will be facilitated by the close relationship of the institution with Wireless Internet Center for Advanced Technology (WICAT) member companies.","title":"MRI: Acquisition of an Experimental Platform for Wireless Multimedia Networking","awardID":"0722868","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["525973","491898","559524"],"PO":["557609"]},"129417":{"abstract":"Mobile ad-hoc communication is starting to find real-world applications beyond its military origins, in areas such as vehicular communications and delay tolerant networking. As the RF spectrum is getting saturated by recent advances in wireless communications, enabling optical spectrum in wireless communications is the needed revolution for ultra-high-speed mobile ad-hoc networks (MANETs) of the future. This project explores the potential for free-space-optics (FSO) in the context of very-high-speed mobile ad-hoc and opportunistic networking. <br\/><br\/>Intellectual Merit: This project introduces basic building blocks for MANETs using FSO and prototypes multi-hop high-capacity FSO building blocks and protocols operating under high mobility. 3-d spherical structures covered with inexpensive FSO transceivers (e.g., VCSEL and photo-detector pair) solve issues relevant to mobility and line-of-sight (LOS) management via availability of several transceivers per node. Such structures facilitate electronic LOS tracking (i.e., ?electronic steering?) methods instead of traditional mechanical steering techniques. The project also investigates reliability protocols as management of logical datastreams through multi-interface FSO structures pose a major challenge. By abstracting FSO directionality and LOS characteristics, the project explores issues relating to routing and localization, and develops layer 3 protocols and FSO-MANET demonstration in a lab setting.<br\/><br\/>Broader Impact: Results of this research can revolutionize the MANET technologies by enabling optical spectrum. FSO has been used at high-altitude communications, and this project enables FSO communications at lower-altitudes and in ad-hoc settings. This research will provide a new application for solid-state lighting technology due to potential integration of illumination and communication functions. Other impact areas include: sensor networks, peer-to-peer networks leveraging directional overlay protocols, and military wireless applications such as UAV\/aircraft airborne networks and inter-ship communications.","title":"Collaborative Research: NeTS-NBD: Free-Space-Optical Mobile Ad-Hoc Networks (FSO-MANETs)","awardID":"0721612","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[342900,"562397"],"PO":["565090"]},"129428":{"abstract":"The BehaviorScope project seeks to develop a framework for understanding patterns and behaviors from sensor data and metadata in distributed multimodal sensor nodes. Patterns and behaviors (especially of humans) will be parsed by a hierarchy of probabilistic grammars and other mechanisms into a compact and more descriptive semantic form. These higher-level interpretations of the data will provide the necessary network cognition needed to provide services in many everyday life applications such as assisted living, workplace safety, security, entertainment and more. The project will use a lightweight camera sensor network as its primary platform and will focus on two types of spatio-temporal data processing. At the local sensor's field of view, this research will investigate the design of filters for robustly detecting humans as well as their gestures and postures. At a more macroscopic level, collections of sensors will coordinate to detect longer term patterns of behavior. The expected outcome is a new data interpretation framework that can understand the spatial and temporal aspects of data and respond to them with meaningful services. To collect real data and to demonstrate the developed concepts in practical applications, this work will use assisted living as the driver application. In this context, the developed sensor network will supervise the behaviors of elders living alone at home to generate daily activity summaries, post warnings and alarms when they engage in dangerous activities, and provide a variety of services that increase the autonomy and independence of these individuals.","title":"NeTS-NOSS: Collaborative Proposal: The BehaviorScope Project: Sensory Grammars for Sensor Networks","awardID":"0721634","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["460460","531850"],"PO":["564777"]},"128218":{"abstract":"Energy infrastructure is a critical underpinning of modern society that any compromise or sabotage of its secure and reliable operation will have a prominent impact on people's daily lives and the national economy. This project develops a hardware-in-the-loop reconfigurable system with embedded intelligence and resilient coordination schemes that would tackle the vulnerabilities of the power grid. This system differentiates itself from previous and existing research efforts in the following key aspects. First, it capitalizes and integrates new power electronic technologies in the system design to facilitate a more direct reconfiguration of the physical makeup of the grid. Second, it pushes the intelligence toward the lower level of the power grid such that local devices have the capability to make decisions and to react more quickly to contingencies. Third, it adopts control-theoretic real-time adaptation strategies for analytic assurance on providing desired dynamic responses to unpredictable system changes to efficiently maintain the availability of large distributed systems. Finally, the system is evaluated not only through simulation, it is also implemented and demonstrated on a microgrid testbed. The evaluation is conducted from three aspects, including real-time responsibility, fault resiliency, local collaboration capability. The power grid is a typical example of complex networks of highly interacting subsystems. Solving these fundamental problems to create a resilient power grid has a direct and immediate impact on this and other critical infrastructure. The project is coupled with a strong educational component including an innovative multi-university curriculum design, active recruitment of students from underrepresented groups supported by existing programs, and broad dissemination of research findings.","title":"Collaborative Research: CT-T: A Resilient Real-Time System for a Secure and Reconfigurable Power Grid","awardID":"0716492","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["527044","527045","521960","492080","554423"],"PO":["521752"]},"129439":{"abstract":"Programming a sensor network is difficult, since the programmer has to juggle low-level details of distributed computing with severe resource constraints, in the presence of noisy data and unreliable components. This project focuses on high-level specification of events and activities in sensor networks, since sensor networks are typically deployed for collaborative detection of events and activities. In particular, the project uses a declarative programming framework based on probabilistic logic for high-level specification of events in sensor networks. The probability distributions embedded in the user program are automatically learnt from training examples using standard machine learning techniques. The above approach facilitates high-level specification of sensor network applications, which is automatically translated into low-level distributed code running on individual sensor nodes. The user is thus freed from the burden of<br\/>worrying about low-level details.<br\/><br\/>The project focuses on the following three goals. The first goal is development of a query engine for efficient distributed evaluation of probabilistic deductive queries in sensor networks. The second goal is to develop techniques for efficient estimation (and distributed re-estimation) of probability distributions embedded in the given program. The third goal is to test the viability of the developed techniques by building two appropriate testbeds. The research project has a significant impact on the ease of programming various sensor network applications. The results of the project are disseminated over the internet at http:\/\/www.cs.sunysb.edu\/~hgupta\/TrainSense.","title":"NOSS: Declarative Framework for Learning and Evaluating Probabilistic Models of Events in Sensor Networks","awardID":"0721665","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["509519","518366","563568","477226","486433"],"PO":["557315"]},"129208":{"abstract":"Designing and implementing robust and high-performance distributed<br\/>systems remains a challenging, tedious, and error-prone task.<br\/>Building correct systems is difficult because of the asynchronous,<br\/>heterogeneous, failure-prone and adversarial environments <br\/>these systems are subject to. <br\/>Tracking the source of performance problems often <br\/>reduces to searching for a needle<br\/>in a haystack: among millions of individual message<br\/>transmissions, algorithmic decisions, and a large number of<br\/>participating nodes, which network link, computer, or low-level<br\/>algorithm results in performance degradations?<br\/><br\/>This research aims to create a programming environment for building<br\/>distributed systems, that includes <br\/>(1) programmings language that make the<br\/>structure of the system explicit in a manner that <br\/>allows the compilation of readable high-level descriptions into <br\/>high-performance implementations, and <br\/>(2) tools that can exploit the explicit structure to <br\/>perform automatic system level analyses that will<br\/>help developers locate, understand and fix behavioral anomalies in deployed systems. <br\/>By increasing our understanding of which aspects of the development process<br\/>are automatable, this research will show the high-level aspects <br\/>where human creativity needs to be focused, without paying the price of<br\/>performance penalties.<br\/>This research can lead to the availability of novel <br\/>architectures and services as an increasing <br\/>developer population is empowered to design and build<br\/>these systems","title":"CSR-PDOS: A Structured Development Environment for Building Robust, Higher Performance Distributed Services","awardID":"0720802","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["485593","529115"],"PO":["493916"]},"129329":{"abstract":"The goal of the project is to investigate link and routing protocols for<br\/>multi-hop wireless sensor networks that use a type of cooperative<br\/>transmission called opportunistic large arrays (OLAs). An OLA is a large<br\/>group of simple, inexpensive relays or forwarding nodes that behave<br\/>without coordination between each other, but they naturally fire together<br\/>in response to energy received from a single source or another OLA. Each<br\/>node has just one antenna, however because the nodes are separated in<br\/>space, they collectively provide diversity protection from multipath<br\/>fading and they can reap the spectrum efficiency of a<br\/>multiple-input-multiple-output (MIMO) system. It has been shown that under<br\/>sufficient conditions during broadcast, OLAs form concentric rings that<br\/>cover the whole network. Even when flooding the whole network, OLA<br\/>networks have been shown theoretically to have significant advantages over<br\/>conventional multi-hop networks in terms of reduced transmit energy, lower<br\/>node complexity, better connectivity, and shorter end-to-end delay.<br\/>Reduced energy consumption means sensor batteries last longer.<br\/><br\/>The project will further reduce the energy consumption of OLA networks by<br\/>limiting the flood to be more like a river, many nodes wide, exploiting<br\/>the ring structure to guide a message up to the sink. Developed protocols<br\/>will exploit the trade-off between diversity and spatial multiplexing<br\/>within OLAs to achieve connectivity while maximizing throughput. OLA link<br\/>layer protocols will enable the river to flow around obstacles such as<br\/>blockages or clusters of destroyed nodes, and resolve the situation when<br\/>rivers collide.","title":"NeTS-NoSS: Cooperative Communication for Wireless Sensor Networks","awardID":"0721296","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560261","562753"],"PO":["557315"]},"131760":{"abstract":"This project identifies three kinds of creative activities in Physics: deriving a new law from existing theory; asking what-if questions within the scope of a known theory; and deriving a falsifiable hypothesis for experimentation within a known theory. The basis for modeling the knowledge that can support these three activities is a constraint reasoning system. The project proposes to develop a creativity support tool on top of an existing constraint reasoning system that will support and encourage students to engage in creative activities.<br\/><br\/>Intellectual Merit: This project will extend the constraint reasoning model to include the knowledge needed and the flexibility required for its use as a creativity support tool in physics. The constraint representation and the rules for manipulating the constraints will be developed using the Eclipse constraint programming language. The flexibility for supporting creativity will be in the development of a flexible user interface.<br\/><br\/>Broader Impact: This project will develop a tool that encourages creativity in the context of physics courses at FIT. The students will be using and providing feedback on the tool, which will expose them to constraint modeling in physics and to the potential for creativity in physics. Research in creativity in FIT is likely to impact numerous students coming from local high-tech industries on Florida's Space Coast.","title":"Creativity in Physics: SGER","awardID":"0732566","effectiveDate":"2007-09-01","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":[349921],"PO":["424970"]},"130550":{"abstract":"The continuing advance in the performance of conventional computers is approaching some difficult fundamental barriers. Quantum computing is a new model for information processing, which promises performance beyond that possible for any conventional computer, at least for certain problems. However, quantum computers are very difficult to build. They require precise control over the interactions amongst a large group of small quantum systems while preventing them from interacting with anything else in their environment. The magnetic moments (spins) of electrons are promising candidates for small quantum systems since they naturally interact only weakly with their environment. Conventional electronic devices operate by controlling the motion of electrons, and it may be possible to harness this ability to control the interactions between the electrons' spins. However, instead of the thousands or millions of electrons which are used in conventional electronic devices, quantum computers must be engineered to control each individual electron.<br\/><br\/>This research involves controlling electrons floating in a vacuum about10nm above the surface of superfluid liquid helium. It has been predicted that under these conditions the spin coherence will be long much longer than when the electrons are moving in a solid as in conventional electronic devices. Ensemble pulsed electron spin resonance measurements will be conducted to measure the electrons' spin coherence, or at least to put a lower limit on the coherence time. Experimental work has already shown that packets with 100 or fewer electrons can be reliably moved across the surface of the helium. Experiments will be performed to isolate, move, and measure individual electrons on the helium surface. The students working on this project will learn skills to enable them to be productive researchers.","title":"Electron Spins on Liquid Helium for Quantum Computing","awardID":"0726490","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["490409"],"PO":["565157"]},"130682":{"abstract":"Biological systems hold the key to ultra-powerful computing using just microwatts of power; this research explores emulating this behavior in electrical systems. A novel, biologically inspired computing paradigm is being developed which could fundamentally change scientific and multimedia computing. This new computing approach simultaneously addresses a looming problem in semiconductor systems and many nano-electronics systems; that is, as feature sizes in computer chips are scaled down further, ideal behavior cannot always be guaranteed. In these systems, results of individual operations are described only statistically or probabilistically. A principal point of this research is to embrace probabilistic computing elements rather than to devise ways to make them ideal or deterministic. Recent research suggests that biological and other natural systems are probabilistic in nature. Thus, probabilistic technology provides a novel method to simulate biological, chemical, and neurobiological systems to reach previously unattainable simulation speeds and complexity. Additionally, many multi-media signal processing systems can take advantage of this computing approach to achieve tremendous gains in efficiency at the cost of imperceptible degradation in quality. <br\/><br\/>Probabilistic CMOS (PCMOS) allows a computing circuit to operate probabilistically and, as a result, achieve extreme power savings. A PCMOS circuit is a digital circuit where the supply voltage is lowered to sub-threshold levels; the output of the circuit is correct with some probability p < 1. The probabilistic nature of the computation may be artificially imposed or it may be a inevitable result of extreme semiconductor scaling. Furthermore, p can be precisely controlled using extant analog floating gate technology. This research uses PCMOS to perform computations and simulations that either require or can tolerate probabilistic behavior, specifically simulation of biological processes which can be extended to Monte Carlo simulations for any dynamical system. These methods allow orders-of-magnitude speed-up and substantially reduced power consumption. The research involves hardware, algorithmic, and theoretical aspects of probabilistic computing.","title":"Probabilistic computing and biological applications","awardID":"0726969","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7946","name":"BIO COMPUTING"}}],"PIcoPI":["550108","558209",346781,346782],"PO":["565223"]},"133740":{"abstract":"This is a 12-month standard award to support a Doctoral Colloquium program at the ACM Conference on Computer Supported Cooperative Work to be held in San Diego, CA (November 7-13, 2008). This will bring together 15 dissertation-stage doctoral students in the field of computer supported cooperative work (CSCW) for one and a half days of talks and interaction with five faculty members selected from among distinguished CSCW researchers. The students come from both the US and abroad, and represent a variety of CSCW subfields. This project provides support for the travel and lodging of the students as well as the direct expenses of putting on the Doctoral Colloquium at the meeting.<br\/><br\/>The focus of the CSCW Doctoral Colloquium is the students? doctoral dissertations. These represent state-of-the-art research in the field of computer supported cooperative work. The Doctoral Colloquium provides both an opportunity for these projects to be shaped through intellectual exchange as well as communicating the character of the work to a key group of young professionals.<br\/><br\/>Broader Impact<br\/><br\/>The Doctoral Colloquium has been highly successful in providing a forum for the initial socialization into the field of young doctoral scholars. It brings together the best of the next generation of CSCW researchers. This allows them to create a social network both among themselves and with several senior researchers, which plays a major role in their enculturation into the profession. Since the students and faculty are a diverse group on several dimensions (nationality, scientific discipline), the students? horizons are broadened at a critical stage in their professional development. Many of today?s leading CSCW researchers participated in earlier Colloquia.","title":"WORKSHOP: Computer Supported Cooperative Work Doctoral Research Consortium","awardID":"0742684","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["472141"],"PO":["388678"]},"132772":{"abstract":"One of the most important rights that Americans have is the right to vote. However, as has become apparent from recent national elections, current voting systems do not always adequately provide a way for all people, especially those with certain kinds of disabilities or who are unable to read, to vote independently, privately and securely. Statistics indicate this is a serious problem, in that up to one fourth of the adults in the United States are functionally illiterate, and almost one in five self-report a disability of some type. We can only expect the problem to become more acute in the future, because the likelihood of a disability increases with age, and people are living longer. Considerations such as these have led the PI to design a prototype direct recording electronic (DRE) voting system called Prime III, with the goal of achieving usable security - namely, a system that is secure and that voters trust, yet which is also easy to use. To this end, development of Prime III had two important research components: human-computer interaction (HCI) and security. HCI issues have been addressed in the prototype through a combination of spoken language, touch screen, and other multimodal technologies, in order to enhance the ability of people who previously could not do so to vote without assistance. With respect to security, concerns that have been noted by various experts (such as vulnerability to hackers, malignant workers, faulty code, lack of recount ability, and human error), have been addressed through solutions such as imposter files, multiple encryption techniques, and an open source format. An informal study conducted by the PI with the Prime III prototype on the campus of Auburn University yielded promising results, with the vast majority of users preferring Prime III over currently available alternatives. This funding will allow the PI to refine his initial designs for the system, and to conduct larger scale studies among voting populations such as the elderly, the functionally illiterate, and those who are visually impaired. Studies to be conducted with this funding will begin, specifically, at the Alabama Institute for the Deaf and Blind, and will continue in Uniontown, Alabama, whose Mayor, the honorable Phillip White, has graciously agreed to participate in the PI''s research.<br\/><br\/>Broader Impacts: Prime III will broaden the participation of voters with various disabilities including those with illiteracy issues. It is anticipated that the system will ultimately serve as a model for future human-computer interfaces where there is a need to blend usability issues with security concerns.","title":"Prime III: Studying Usability & Security in Electronic Voting for Everyone","awardID":"0738175","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["542299"],"PO":["565227"]},"131100":{"abstract":"There is a fundamental tension between our desire to aggregate data for useful purposes and our desire to protect the privacy of individuals. The canonical example is voting, in which we wish to add up votes without revealing any individual votes. Secure computation is a branch of cryptography that mediates and in some cases transforms this tension, allowing us to satisfy these conflicting needs to a far greater level than naively would seem possible. The research is primarily concerned with the basic theory of secure computation, determining under what conditions it is possible to obtain useful information from multiple sources of data while maximally protecting the privacy of this data. It also considers special cases under which secure computation may be particularly efficient and practical. Practical secure computation solutions would be useful for a number of applications, including electronic voting, e-commerce and access control systems.<br\/><br\/>Specific goals of this investigation include:<br\/>: Classifying the power of general classes of secure computation systems, particularly those with probabilistic output behavior.<br\/>: Further developing the theory of errorless reductions among secure computation primitives, in which the goals are achieved with certainty as opposed to merely with high probability.<br\/>: Developing more efficient protocols for voting systems with sophisticated vote-counting mechanisms (e.g., instant runoff voting), and for other preference aggregation problems.<br\/>: Finding ways to use extant information services as a means for implementing secure computations and as a resource for bridging the gap between abstract protocols and real systems.<br\/><br\/>Level of effort statement<br\/>We note that the amount of summer support recommended for the principal investigator has been reduced to one month per year. At the recommended level of support, the principal investigator will make every attempt to meet the original scope of the project, as well as his level of effort.<br\/>1","title":"Theory and Practice of Secure Computation","awardID":"0728937","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":[348026,"475121"],"PO":["565157"]},"133762":{"abstract":"The era of ubiquitous computing in the home is here, thanks to the popularity and affordability of communications, media, and storage devices. Today a home might be equipped with a broadband router, wireless access point, IP telephone, media center PC, networked attached storage (NAS), digital video recorder, music players, and game consoles capable of Internet play. However, this kind of ubiquitous computing, once hoped to be both invisible and seamless, is already showing its seams. Rather than making life simple and easy, today's technology often makes life more complex. People expect devices to work easily, intuitively, and to play nicely together. Instead, many consumers devote evenings and weekends to the overhead of connecting and configuring laptops, desktops, wireless networks, home theater systems, and other devices that promise new and exciting capabilities.<br\/><br\/>The research proposed here seeks to characterize the breakdowns and develop technical solutions that simplify how individuals incorporate networked digital devices into their homes and digital lifestyle. Fieldwork will identify breakdowns and solution methods for users of networked devices. The field study findings will articulate a set of requirements for a contextual recommendation system that will recommend approaches that simplify adoption and use of networked devices in the home. Focusing on interoperability with media devices could be considered high risk because the low rates of end-user adoption for these devices may make it difficult to find individuals who can participate in the research. An additional complication when addressing network interoperability is that these types of problems can often result in the home network being non-operational. Thus some common approaches for getting help, like searching the Internet, may not be not practical.<br\/><br\/>The intellectual merit of the proposed research is three fold. The proposed research will develop a new method (problem solving probes) to overcome methodological problems of studying the home network. The research will result in a situated typology of interoperability problems and solution approaches that users currently employ. Lastly, the results will be used to develop a prototype interoperability assistant that identifies where conceptual problems arise in a user?s home network. <br\/><br\/>The results of the research will have several broader impacts. The direct impacts are for the millions of users who are attempting to adopt a growing number of networked devices for the home. The infrastructure developed will reduce the overhead of resolving complex interoperability problems by identifying and recommending the most effective solutions. The results inform the design of devices and services aimed at solving network device interoperability in the digital home. Thus, this renews the promise of a more seamless computing environment in the home.","title":"HCC: Conceptualizing Interoperability Problem Solving in the Networked Home","awardID":"0742750","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["486167","543781"],"PO":["565227"]},"132794":{"abstract":"This project explores and establishes parallels between creative writing, more specifically poetry, and software engineering recognizing that both disciplines share the cultural frameworks common to writing practices: both employ a range of writing tools, both require incorporated knowledge and skills, and both involve communities of practitioners in everyday settings. In both disciplines, these frameworks enable human cognitive activity leading to innovation and discovery. By focusing on creativity and by modeling points of intersection and translation, the project provides a better understanding of these processes of innovation and discovery. How do creative writing and computer programming foster creativity? How do they define creative work and the creative writer or coder?<br\/><br\/>The broader impact of this research is a model for relations between creative writing practices and software engineering. The project creates synergistic relations between creative writers ? whether writers of poetry or of code ? to suggest possibilities for larger community-building between the disciplines. Furthermore, the project begins to re-model curriculum in light of computer programming as a creative writing practice.","title":"The Codework Project: Relations between creative writing and computer programming","awardID":"0738279","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":[353196],"PO":["424970"]},"134983":{"abstract":"The Computing Research Association will organize, staff, and administer this workshop to explore the research area of bio-inspired computation and encourage ideas that will spur development of this emerging field, as well as view presentation from current PIs in the biocomputational section of EMT. The workshop will help inform the multi-disciplinary bio-inspired computation community about current research efforts, enable dialogue and opportunities for future collaboration and cooperation, as well as update Federal and State agencies.","title":"WORKSHOP: Workshop on Bio-Inspired Computing, Arlington, VA , October 2007","awardID":"0749411","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["209556"],"PO":["565223"]},"131111":{"abstract":"Computational problems of curves and surfaces arise in many applications, including geometric modeling, graphics and visualization, engineering design and simulations. Most computational approaches to curves and surfaces fall under one of two viewpoints, called the Algebraic Approach and the Geometric Approach (respectively). The former approach leads to exact and complete algorithms, but these are usually inefficient and hard to implement. In the Geometric Approach, one avoids powerful algebraic techniques, in favor of numerical and simple subdivision methods. These are easier to implement, but more importantly, their complexity is adaptive, meaning that the complexity strongly depends on the input instances. Moreover, input instances with high complexity are atypical. For these reasons, most implementors prefer the Geometric Approach. Unfortunately, geometric algorithms are usually nonrobust, incomplete and have no guaranteed topological properties. Indeed, achieving robust geometric algorithms for curves and surfaces is widely viewed as the major open problem of geometric modeling. Recently, some robust adaptive algorithms for meshing curves and surfaces have been proposed, but some non-degeneracy conditions (e.g., non-singularity) remain.<br\/><br\/>This research addresses several basic problems within the Geometric Approach, including the intersection of curves and surfaces, and meshing of implicit surfaces. The achieved results represent two fundamental advances in the theory of algorithms: (1) For the first time, complete and fully adaptive algorithms for such problems have been constructed. The key to such algorithms is the judicious application of zero bounds, or their geometric analogues. (2) The complexity analysis of some adaptive algorithms for meshing is initiated. The analysis introduces novel amortization arguments, and suitable concepts of precision-sensitivity. This represents a new frontier in the analysis of algorithms. Both advances build upon the principal investigator's prior work in Exact Geometric Computation, and in the implementation of the open-source Core Library software. The new adaptive algorithms are validated via implementation in Core Library.","title":"Complete Adaptive Algorithms for Curves and Surfaces and their Complexity","awardID":"0728977","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7929","name":"COMPUTATIONAL GEOMETRY"}}],"PIcoPI":["409933"],"PO":["565157"]},"131232":{"abstract":"This major inter-disciplinary research effort will use virtual worlds as an exploratorium to theoretically extend and empirically model the dynamics of group behavior. In the process it will develop novel computational techniques for analyzing large-scale networks, which will have applicability across a wide variety of domains.<br\/><br\/>The most important and complex decisions made by governments and organizations occur in group contexts. A central challenge, spurred by new developments in information technologies (IT), is that the nature of groups and how they operate has changed radically. Today, many groups ? in social, political, and economic contexts - are ad hoc, agile, transient entities that emerge from a larger primordial network of relationships. For a short time, these groups accomplish a variety of tasks, and then they dissolve, only to be reconstituted later with a different configuration. While there is growing awareness of the socio-economic consequences of these groups, our understanding of how they form and their impact on effectiveness is severely limited.<br\/><br\/>This project will address this limitation by developing a theoretical framework that reflects the contemporary conceptualizations of groups. It proposes a network approach to modeling the eco-system of overlapping and constantly changing groups that constitute the fabric of contemporary society. It recognizes that empirically testing such a model poses formidable data collection challenges. However, a unique resource available to the research team is access to all behavioral traces (server logs) from one of the world''s largest Massively Multiplayer Online (MMO) games, EverQuest 2, which is particularly well-suited to theorize and empirically model the dynamics of group behavior. MMOs comprise tens of thousands of players who are at any one point in time coalescing in thousands of groups to accomplish \"\"\"\"quests\"\"\"\" and \"\"\"\"raids\"\"\"\" that involve a variety of activities similar to tasks we undertake in real life ? finding information or materials, making, selling or buying products and services. <br\/><br\/>Beyond the data collection challenge, the scale of the proposed research enterprise also poses significant computational challenges in uncovering and analyzing the complexities that govern the dynamics of group behavior in these virtual worlds. Using advanced computing applications and technologies, this project seeks to capture, infer, and model the networks that explain how groups emerge and how they function. Specifically, the researchers will use temporally evolving graphs to model such networks, and develop scalable algorithms to compute metrics of group behavior on them. Tying these complex and shifting individual and networked behaviors to traditional forms of analyses represents a novel interdisciplinary challenge in both scope and complexity.<br\/><br\/>The project will expand our knowledge of how groups form and operate in larger ecosystems of groups, individuals, and organizations. The analysis of logs generated from Virtual Worlds poses novel challenges from a computational perspective. This interdisciplinary investigation will result in new (1) information models for modeling the Virtual World, (2) data structuring and algorithmic techniques for data access and analysis, and (3) techniques for computational efficiency.<br\/><br\/> The knowledge and tools developed in this research will allow researchers to understand more fully, and practitioners to cultivate more effectively, the emergence and performance of ad hoc groups in contemporary society. It will also provide other disciplines with new computational and statistical modeling methodologies and tools, which should have considerable positive implications for future research in other disciplinary areas. The findings and deliverables of the proposed research will be immediately generalizable to training and education related to groups (beyond just MMOs or Virtual Worlds), social networks, and online games.","title":"Collaborative Research: DHB Virtual Worlds: An Exploratorium for Theorizing and Modeling the Dynamics of Group Behavior","awardID":"0729505","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["561056","532398",348394],"PO":["564456"]},"132332":{"abstract":"This project develops a novel extension to a computational theory of visual motion perception. The overall goal of the theory is to understand how humans perceive motion in their natural environment; in other words, to understand what goes on inside a person's brain when he or she sees birds flying, snowflakes falling, or other complex patterns of motion that occur in the natural visual world. Building on recent work modeling the appearance of a limited set of motion flow patterns, the present project explores a probabilistic approach, based on Bayesian Ideal Observers, to the representation, learning, and modeling of natural visual, and the use of learned probabilistic models in turn to synthesize pseudo-realistic stimuli. Pseudo-realistic stimuli are a novel class of visual stimuli, which have the appearance of natural visual stimuli but can be quantified and varied in a precisely controlled manner. Stimuli of this type have never been used before and offer the exciting prospect of experimentally understanding the behavior of visual systems when exposed to realistic but controlled stimuli. It is anticipated that understanding how the human visual system processes motion will enable development of more robust and powerful computer vision algorithms which will have many technological applications.","title":"A Computational Theory of Motion Perception Modeling the Statistics of the Environment","awardID":"0736015","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["549461"],"PO":["564318"]},"131122":{"abstract":"This project is exploring the integration of video and multiscale visualization facilities with computer vision techniques to create a flexible open framework to advance analysis of time-based records of human activity. The goals are to (1) accelerate analysis by employing vision-based pattern recognition capabilities to pre-segment and tag data records, (2) increase analysis power by visualizing multimodal activity and macro-micro relationships, and coordinating analysis and annotation across multiple scales, and (3) facilitate shared use of the developing framework with collaborators. Researchers from many disciplines are taking advantage of increasingly inexpensive digital video and storage facilities to assemble extensive data collections of human activity captured in real-world settings. The ability to record and share such data has created a critical moment in the practice and scope of behavioral research. The main obstacles to fully capitalizing on this scientific opportunity are the huge time investment required for analysis using current methods and understanding how to coordinate analyses focused at different scales so as to profit fully from the theoretical perspectives of multiple disciplines. Thus, any research using video or other time-based records in order to document or better understand human activity is a potential beneficiary of this research, and the long range objective is to better understand the dynamics of human activity as a scientific foundation for design.","title":"DHB: A Multiscale Framework for Analyzing Activity Dynamics","awardID":"0729013","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"7704","name":"Science of Learning Activities"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7319","name":"HSD - DYNAMICS OF HUMAN BEHAVI"}}],"PIcoPI":[348076,"550599","463668"],"PO":["564456"]},"134774":{"abstract":"In 2004, there were 64,675 bachelor degrees awarded to students majoring in engineering fields in the United States. Out of that total, women received 20.5% of the total degrees awarded, African Americans received 5%, Latin Americans received 6.9%, and Native Americans received approximately 0.5%. These percentages were disproportionate compared to their individual total population numbers within the U.S. for that same year. This SGER proposal argues that there is a major disconnect in the pipeline leading to the production and increase of undergraduate computer-engineering-related degrees by underrepresented student populations (i.e., female and minority students). To repair this disconnect, the focus must be on how young computer science and engineering students from underrepresented populations are trained and the inevitable obstacles students from these backgrounds face as they try to adapt to the culture of the computer science and engineering educational environments. This is essential to their professional success and the technological future of the United States since this is an ideal pool for finding the next generation of computer science and engineering professionals, technicians, and knowledge workers. This proposal provides a description of a laboratory apprenticeship training model that incorporates four major components for successfully achieving the increased recruitment, retention, training, and timely graduation rates of students from underrepresented and underserved backgrounds.","title":"SGER: A Model for Increasing Participation and Graduation Rates in Computer Engineering Related Disciplines","awardID":"0748418","effectiveDate":"2007-09-15","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["482361"],"PO":["564316"]},"131144":{"abstract":"This project seeks to provide effective and low-cost solutions to the power-reliability problem inhibiting the growth of the $250B global semiconductor industry today. This is the industry that manufactures integrated circuits (ICs) or micro-chips that lie at the heart of consumer electronics, communications and computing products such as cell-phones, lap-tops, personal digital assistants, modems, routers, and many others. Moore?s Law, a self-fulfilling prophesy driving innovation and growth in the industry since the 70s, predicts that the number of transistors per unit area will double every 18 months. Moore?s Law is under threat from two trends: emergence of nanometer non-idealities that make it hard to design reliable chips, and increased functionality demanded by new applications and standards resulting in high power consumption. This is then the power-reliability problem which threatens Moore?s Law. <br\/><br\/>In this project, the investigators are employing the power of signal processing theory and techniques to solve the power-reliability problem described above in the context of ICs for broadband communication systems by viewing nanometer ICs as noisy communication networks. The research is organized into three major activities. First, parameterized statistical behavioral models for digital signal processing (DSP)-specific blocks such as data-path, computation, memory, and on-chip communication blocks will be developed. Next, signal processing-inspired techniques will be investigated for designing robust and energy-efficient implementations of signal processing and communication systems by employing the behavioral models and using concepts from statistical signal processing theory such as adaptive filtering, detection and estimation, error-control and distributed and robust systems theory. Finally, a prototype test chip demonstrating the potential of one or more of the techniques will be implemented and tested in the final year of the project.","title":"Signal Processing to the Rescue of Moore's Law","awardID":"0729092","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":[348133,"551642"],"PO":["564898"]},"131034":{"abstract":"One of the main functions of theoretical computer science is to identify the central computational concepts and the algorithmic principles that underlie different computational problems and phenomena both within computer science, and across different disciplines. This project investigates some fundamental models and problems that arise and have been studied in different areas: computing Nash and other equilibria; computing optimal strategies and the values of competitive games (stochastic and other games); analysing basic stochastic models for evolution, like branching processes, and for language, like stochastic context-free grammars; and models that incorporate the fundamental primitives of probability and recursion like recursive Markov chains. Most of these models and problems have been studied mathematically for a long time, leading to development of rich theories. Yet, some of their most basic algorithmic questions are still not resolved.<br\/><br\/>Despite the broad diversity of these problems, there are indications that there is a common thread that runs through them. The goal and intellectual merit of the proposed research is to identify the common underlying algorithmic principles that are at the heart of these problems and others like them. Furthermore, the project seeks to develop efficient solutions for many of these problems, or to characterize rigorously the obstacles in obtaining such solutions. This research is expected to have a broad impact on a variety of areas. The concepts and models under investigation are fundamental in various disciplines, including economics, game theory, biology, and various areas of computer science. Characterizing the computational properties of the models, and providing efficient algorithms for their analysis, whenever possible, will be greatly beneficial.","title":"Research in Games, Fixpoints, and Approximation","awardID":"0728736","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["550946"],"PO":["562944"]},"131166":{"abstract":"NSF Division of Computer and Communications Foundations:<br\/>Theoretical Foundations<br\/>Program Solicitation NSF 07-525:<br\/>Information Theory of Channels with Missing Observations<br\/>Principal Investigators: Giuseppe Caire and Sergio Verd'u<br\/>University of Southern California Princeton University<br\/>Summary<br\/>This project takes a unified information theoretic approach to problems in transmission, compression, estimation and sensing in which observations may be missing from the available data. In many applications of current practical interest, data is subject to random erasures because of fading and\/or jamming (in wireless), packet dropping due to finite buffer sizes (in networks), impulse noise (in power and subscriber looplines), defective media (in magnetic recoding), faulty transducers (in sensor networks), reduced complexity<br\/>(in compressed sensing), link failure (in wired infrastructure of a cellular system), opportunistic signaling(in nonstationary channels), etc. It is of great theoretical and practical interest to assess the impact of the<br\/>missing data on the fundamental Shannon theoretic limits for reliable compression and transmission, as well as the estimation theoretic limits. Furthermore, new practical questions arise on how to best redesign<br\/>compression, coding, modulation, and filtering schemes to attain performance close to the fundamental limits in the presence of missing observations.<br\/>This project tackles a number of specific challenging and technologically relevant research problems that involve a variety of models with missing observations: Lossless and lossy compression of missing data,<br\/>when the erasure locations are known\/unknown at the compressor; Capacity of noisy channels subject to erasures, and in particular the effect of output erasures on the capacity of channels with memory; Minimum mean square error estimation and prediction with missing observations; Fountain codes for<br\/>simultaneous broadcast to several receivers with widely different missing information rates; Multiuser information theory for networks subject to erasures, including basic paradigms such as the multiaccess channel and the broadcast channel; Cellular networks with centralized processing and unreliable wired links (\"radio on fiber\" subject to link outages);Robustification of transceiver techniques such as orthogonal<br\/>frequency division multiplexing, feedback schemes, and dirty-paper coding which are notoriously sensitive to erasures; Revisiting the fundamental limits of compressed sensing (which can be interpreted as the concatenation of a full-rank random projection followed by random erasures of the projected coefficients) from the viewpoint of information theory.<br\/>This project aims at advancing discovery and understanding of communication and signal processing systems of relevance to current technology, at the crossroads of several research communities, and provides a fertile ground for training of graduate students in the disciplines of information theory, coding theory, estimation, signal processing, random matrix theory and networks.","title":"Collaborative Research TF: Information Theory of Channels with Missing Observations","awardID":"0729162","effectiveDate":"2007-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["508212"],"PO":["564924"]},"133597":{"abstract":"Spelman College proposes the ARTSI (Advancing Robotics Technology for Societal Impact) Alliance in collaboration with Florida A&M University, the University of the District of Columbia, Hampton University, Morgan State University, Norfolk State University, Winston-Salem State University, the University of Arkansas-Pine Bluff, Carnegie Mellon University, Georgia Institute of Technology, Brown University, Duke University, the University of Alabama, the University of Washington, and the University of Pittsburgh. Seven of these partners are HBCUs and seven are Carnegie Research I institutions. Their collaboration joins the strengths of HBCUs in conducting outreach and education in a nurturing learning environment with those of the R1's for conducting world class research. The ARTSI Alliance will motivate students to pursue computer science careers by emphasizing the creativity and socially beneficial aspects robotics technology with hands-on projects, curriculum, and media. ARTSI activities will span the academic pipeline from K-12 through the faculty ranks. At the K-12 level, students will be recruited with community outreach using robotics and art, robotics road shows, and a robotics educational film online repository. At the undergraduate level, HBCU students will be exposed to new robotics curriculum, and they will be encouraged to pursue advanced training in graduate school through summer research experiences, collaborative, interdisciplinary robotics projects in the arts and health, instruction in technical film documentation, student virtual film festivals, annual robotics conferences, and instruction in entrepreneurship for computer science. At the faculty level, it will increase the number of HBCU faculty who educate students in robotics and involve students in robotics research by providing faculty mentoring, summer research experiences for underrepresented faculty at R1 robotics labs, robotics summer workshops, and development and dissemination of robotics educational material through a web-based portal. The Alliance will have industry partners, including Seagate, iRobot, Microsoft Research, and Juxtopia, as well as educational partners, including Florida-Georgia Louis Stokes Alliance for Minority Participation and Computer Science Teachers Association.","title":"Collaborative Research: BPC-A: ARTSI: Advancing Robotics Technology for Social Impact","awardID":"0742098","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7584","name":"ITR-BROADENING PARTICIPATION"}}],"PIcoPI":["474702"],"PO":["561855"]},"131056":{"abstract":"Surface shape and quality have a visible impact on new product design and industrial competitiveness. This research addresses the fundamental challenge of smoothly joining multiple surface pieces without shape defects. The new approach separates shape design from surface representation and thereby gives more freedom to the designer while still delivering a standard representation required by industrial design cycles.<br\/><br\/>In the new approach, shape is locally defined by surface fragments, called guide surfaces. Guide surfaces need only obey few constraints. In a second step, the derivative jets of each guide surface are sampled and converted to curvature continuous parametric surfaces in standard representation. The research characterizes classes of guide surfaces, devises strategies for automatic guide surface construction and formalizes and analyzes the properties of jet sampling strategies in practical implementations.","title":"High-Quality Shape Design and Surface Representation","awardID":"0728797","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["486405"],"PO":["565157"]},"133487":{"abstract":"0741584 Erwig, Martin Oregon State University<br\/><br\/>This research starts from the observation that any design process essentially consists of making design decisions and that any designed artifact is ultimately the embodiment of a set of such design decisions. The PIs will develop a theory of design decisions and based on the theory, a design-by-example methodology.<br\/>Design decisions will be mathematically formalized as operations on attribute sets, which are used to represent the possibilities of the designed artifact along multiple dimensions. Groups of attributes can be combined into hierarchically structured and reusable design spaces. An important aspect is the explicit representation of design contexts to capture design constraints and external requirements properly. Design spaces can be further composed and modeled by relating design decisions to other design spaces and by integrating them with design contexts through constraints. In this model any design will be represented as a point in the design space, and ?design by example? means to navigate from one point to another by reversing design decisions and replacing them with different ones.<br\/>The broad impacts of this research include the application of the design theory to real application environments. A major challenge will be to demonstrate that the proposed design methodology can be successfully applied in practice and that the developed theory provides insights that support real-world design tasks. The PIs will perform exploratory research to establish a set of important real-world scenarios and example projects that can serve both as an evaluation testbed and as a guide when developing the theory. Letters of intent to participate in the research are included in the proposal from companies in the aerospace industry and NASA.<br\/>This research will also have a positive impact on the education of students that either directly participate in this project or will be exposed to the research through graduate level courses. Moreover, educational outreach will include high school students that participate as summer interns.","title":"SGER: A Theory of Design Decisions","awardID":"0741584","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7652","name":"SCIENCE OF DESIGN"}}],"PIcoPI":["548134","540516"],"PO":["564388"]},"125864":{"abstract":"Johns Hopkins University is organizing a six-week research workshop focused on Machine Learning for Language Engineering and striving for synergistic cross-fertilization with other areas of machine intelligence. This workshop brings together diverse teams of leading professionals and students, both graduate and undergraduate, in a cooperative and intensive effort to advance the state of the science in Language Engineering, which encompasses automatic speech recognition, natural language processing, machine translation, topic detection and tracking, information retrieval and extraction, summarization and question answering.<br\/>The primary goals of the workshop are to advance language engineering, to attract new students to the field and to prepare them for research by having them work alongside distinguished researchers on exciting problems.<br\/>The workshop projects are selected through an open call for proposals issued to the worldwide IIS community. The proposals are evaluated competitively at a planning meeting that draws together the projects' proponents, impartial experts from the relevant disciplines, and government representatives.<br\/>The graduate students are selected based on their research interest and performance by the proponents of the selected projects. The undergraduates are entering seniors selected through an open national search.<br\/>In addition to establishing new research directions and providing hands-on education to students, the workshop results will be widely disseminated and incorporated into continuing, large-scale, collaborative research efforts by participating faculty, graduate and undergraduate students from geographically diverse institutions. Valuable tools and data for IIS research will be created, and fruitful and long-lasting collaborations will be initiated between diverse and dispersed participants.","title":"RI: Cross-Cutting Research Workshops in Intelligent Information Systems","awardID":"0705708","effectiveDate":"2007-09-01","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"H229","name":"CIA"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"H262","name":"CIA"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"I163","name":"Defense Advanced Research Proj"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["521190","531055","445172","445173","438772"],"PO":["565215"]},"134224":{"abstract":"This Small Grant for Exploratory Research will develop and study a system to improve parent-professional communication about child development through improved data capture of home experiences. Advanced information technologies, particularly those embedded into natural environments like the home, present a novel, but currently untested opportunity for early detection of developmental delay in very young children. Positive results from this initial exploration could lead to a dramatic transformation in the tools available to researchers to detect and better understand developmental delay. Analogous to how the technologies of X-Rays and MRIs transformed the exploration of orthopedics and neurology, respectively, this project will explore the potential of computer-based tools to support the imaging of behavior to transform the science underlying childhood development.<br\/><br\/>Simplified behavior capture in the home is a technological approach that can rapidly catalyze a growing community of technology researchers interested in family-related applications. The specific goal of this research is to demonstrate how semi-automated analysis of video-recorded behaviors can connect the computational perception community to the behavioral sciences communities, through the specific challenges of early detection of autism. The earlier that educational interventions are started with atypically developing children, the more effective they are in helping the children cope with the disabilities. The broader impacts of this innovative research are expected to include improvements in educational and health-related assessment, and new tools for families to preserve rich records of their children's early development.","title":"SGER: Technologies to Support Early Detection of Developmental Delay in Children","awardID":"0745579","effectiveDate":"2007-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["563803",356936],"PO":["564456"]},"131078":{"abstract":"This is a proposal for funding in support of the 2007 edition of the Clemson Mini-Conference on Discrete Mathematics and Algorithms (which would be its 22nd consecutive year). The 2007 edition will have a mini-focus on the Mathematical and Combinatorial Theory of Communication.<br\/><br\/>This day-and-a-half long conference is held every year at Clemson University, Clemson South Carolina, on a Thursday and Friday, usually during the first two weeks of October. The Mini-Conference invites about a dozen speakers to give 40-minute talks on their current research. The speakers are chosen between the fields of Discrete Mathematics (including combinatorics, graph theory, operations research, coding theory, cryptography and discrete optimization), and algorithmic Computer Science (including computation theory, computational complexity and algorithms). This year the conference is tentatively scheduled for October 11-12.<br\/><br\/>Broader Impact and Intellectual Merit. The mini-Conference has hosted many of the major names in the field. Because of its relatively central location in the Southeast, it attracts students and faculty from several states, who would not otherwise be able to attend larger more costly conferences. Due to its established traditions, its low cost (in time and money) and its informality,<br\/>the mini-Conference permits a greater degree of interaction with the speakers than at large conferences. In addition, the conference strives for a demographically diverse group of speakers. For example, at the 18th mini-Conference, three of the 11 speakers were women, one a person with<br\/>disabilities. We also ensure that there is at least one \"\"young\"\" speaker, to provide exposure to new talent. For example, at the 19th mini-Conference we showcased a pair of REU students.","title":"Clemson Mini-Conference on Discrete Mathematics and Algorithms","awardID":"0728868","effectiveDate":"2007-09-01","expirationDate":"2008-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7351","name":"THEORETICAL FOUNDATIONS (TF)"}}],"PIcoPI":["382532",347972],"PO":["499399"]},"126612":{"abstract":"Proposal #: CNS07-09077<br\/>PI(s): Kiesler, Sara B. <br\/>Institution: Carnegie Mellon University <br\/> Pittsburgh, PA 15213-3890<br\/>Title: IAD: Laboratory for Research in Human-Robot Interaction<br\/><br\/>Project Proposed:<br\/>This project, developing a new generation of social robots for studies in human-robot interaction, aims at creating robots and modular robotics kits to be used to study robot social behavior, mutual understanding in human-robot communication, and the impact of assistants in group dynamics. The research involves understanding and testing theories of how these three aspects of human-robot interaction independently and interactively affect collaborative work and investigating how assistive robots can be designed best to aid people in domains such as health and aging. Designed to motivate and test theories, the work studies <br\/>. Fundamental laboratory research on behavioral characteristics of robots performing social tasks, especially as these characteristics reflect likeness;<br\/>. Controlled experiments and field studies of interpersonal communication and development of mutual understanding between robot and human, and<br\/>. Robots in work groups.<br\/>Aiming to better understand the societal impact of robots, a multidisciplinary team (robotics, computer science, social psychology, engineering, organization science, design) draws from and builds on basic research in cognitive and social psychology, and on recent research in robotics, computer graphics, and design. The team seeks a foundation for understanding and designing collaborative work with robots in critical environments like mines, hospitals, households with elderly or disabled residents, in challenging scientific settings and in situations in which the robot is remote.<br\/><br\/>Broader Impacts: This development contributes to public and student awareness of the human side of robotics. A life-size robot will be taken to school for educational purposes.","title":"CRI: IAD Laboratory for Research in Human-Robot Interaction","awardID":"0709077","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["519226"],"PO":["543539"]},"124445":{"abstract":"The goal of this project is to accelerate the pace of the revolution in the state of the art of integer and combinatorial optimization that has been taking place over the last 15 years, through research aimed at better convexification techniques, based primarily on the lift-and-project approach. The principal investigators intend to apply analytical tools of linear algebra, like projection, lifting, polarity, basis reduction, disjunctive modularization, convex hull generation, along with algorithmic techniques like pivoting, cutting plane generation, scaling techniques, separation procedures, etc. in three main directions of research: (i) how to reduce the computational cost of generating cuts with the required characteristics; (ii) how to produce new, stronger cuts, or groups of cuts with enhanced joint strength, capable of speeding up the convergence to a solution and yet stable enough not to cause numerical problems; and (iii) how to make better use of the cuts within the overall process of solving a mixed integer program, by better cut evaluation and selection techniques, etc. Together, these three lines of attack are expected to yield significant improvements in the algorithmic tool-kit of mixed integer and combinatorial optimizers. <br\/><br\/>If successful, the research will lead to a substantial enhancement of our ability to solve mixed integer and combinatorial optimization problems. Such progress would affect an extremely broad range of activities, from industrial production--supply chain management, sequencing and scheduling, assembly line balancing--to logistics, facility location and other aspects of distribution; from telecommunications network design to network operation; from airplane allocation to runways to gate allocation to airplanes and luggage delivery to passengers; from the scheduling of arrivals and departures of airplanes to scheduling the airplane crew assignments; from optimizing yield management to maximizing customer satisfaction in service operations. The tools developed here may turn out to be as useful in improving homeland security as in reinforcing our technological leadership.","title":"Mixed Integer and Combinatorial Optimization: Lift-and-Project and Polyhedral Combinatorics","awardID":"0653419","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"5514","name":"OPERATIONS RESEARCH"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"7446","name":"MATH PRIORITY SOLICITATION"}}],"PIcoPI":["539128","539129"],"PO":["502772"]},"134499":{"abstract":"Affect is deeply intertwined with cognition in humans and can influence problem solving and decision making strategies, or evaluations of social situations, among many others. For robots working with humans in teams this means that being aware of human affect and adapting their behavior based on human expectations about how to respond to human affect might not only lead to more natural interactions, but also improve the performance of human-robot teams. Currently, there is only one preliminary study that attempts to quantify objectively the effect of robotic affect expression on task performance in a mixed human-robot team.<br\/><br\/>This project will build collect further evidence for the utility of using affect mechanisms in robotic architectures. Specifically, the project will investigate whether selectively using affect modulations of spoken language output generated by the robot in response to human stress due to high cognitive load, detected either in the human voice or via physiological sensors attached to human subjects, can improve the performance of human-robot teams. Moreover, it will be determined if the outcomes depend on the frequency of interactions as well as the interaction distance, comparing face-to-face interactions with remote interactions via a video link.","title":"SGER: Investigating the Utility of Affect Mechanisms in Mixed Human-Robot Teams","awardID":"0746950","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["549200"],"PO":["403839"]},"128944":{"abstract":"Embedded applications are very demanding in terms of both performance and efficiency. To meet these demanding requirements embedded systems are turning to parallelism (for performance) and special-purpose hardware (for efficiency). This trend has created a pair of technology gaps in programming of embedded systems. First, few tools exist to map embedded applications to parallel systems. Second, using special-purpose hardware (ASICs) for the computationally demanding parts of applications makes it impossible to program these parts of the applications. <br\/><br\/>This project seeks to close both of these technology gaps. First, the project is developing a programming system for mapping embedded systems to parallel (multi-core) platforms. This system takes ?C? code, annotated with real-time constraints, and automatically partitions operations across multiple processors, placing data and coordinating communication and synchronization. The partitioning will be done to meet real-time constraints, to balance load, and to minimize energy consumed. Second, the project is developing a programmable multi-core platform that matches the efficiency of hard-wired (ASIC) logic on embedded kernels. The approach is to optimize data and instruction movement to eliminate much of the overhead and inefficiency of conventional processors. The design of the processor is then optimized to close the gap with ASICs.<br\/><br\/>This research is expected to enable a renaissance in embedded system design. It will enable rapid development of embedded systems for emerging multi-core platforms and will ensure that such systems operate efficiently and meet real-time constraints. It will also enable the rapid development of efficient embedded systems for applications and algorithms for which hard-wired modules do not exist. Overall, this research seeks to make possible the development of embedded systems that simply are not feasible with today's programming tools and platforms.","title":"CSR-EHS: An Enabling Substrate for Embedded and Hybrid Systems","awardID":"0719844","effectiveDate":"2007-09-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["400637"],"PO":["561889"]},"125677":{"abstract":"This is a collaborative research project (0704689: Yiming Yang, Carnegie-Mellon University; 0704628: Daqing He, University of Pittsburgh). Adaptive filtering (AF) is an open challenge in information retrieval, defined as the problem of incrementally learning about the topics of interest from user feedback (relevance judgments of the retrieved documents) over a chronologically processed stream of documents. The goal of this research project is to significantly improve adaptive filtering technologies. The approach consists of: (1) a new framework named the Enriched Vector Space Model (EVSM) that represents multi-type objects (including users, queries, topics, documents, Named Entities and sources of data), records the interactions among objects during the adaptive filtering process, and enables the comparison among objects based on both content similarity and relationship similarity; and (2) a system that bridges adaptive filtering, collaborative filtering, personalized active learning and Generalized Hubs and Authorities for effective learning about evolving interests of users. The experimental research is linked to educational benefits for graduate students via participation in the system implementation, data annotation, empirical evaluations and user studies in this project, as well as through course materials the Principal Investigators teach on the related topics and techniques. The results of this project will provide a significant contribution to the field of information search and to our understanding of how to effectively learn from multiple users, and how to combine multi-aspect user information in a new unified framework, with broad applications in information retrieval (web-based and enterprise search engines, for example) by giving them a major adaptive and personalization dimension.<br\/><br\/>The project Web sites (http:\/\/nyc.lti.cs.cmu.edu\/UserCentricAFCF\/ and http:\/\/amber.sis.pitt.edu\/UserCentricAFCF ) will be used to disseminate resulting publications, open-source code and annotated test data sets.","title":"III-COR: Collaborative Research: User-centric, Adaptive and Collaborative Information Filtering","awardID":"0704628","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["469267"],"PO":["563751"]},"125204":{"abstract":"Internet services have a characteristic of traffic burstiness. To protect premium customers from traffic surge without over-compromising the needs of basic clients, a stress-resilient server must be able to control the quality of multi-class requests in a coordinated way for fair and graceful performance degradation in stress conditions. The goal of this project is to develop an autonomic resource management system in the network edge in support of such service quality assurance models. <br\/><br\/>The resource management system features three key innovations. First is an application-level QoS-aware resource management framework for multi-class quality assurance. Its novelty lies in the ability to providing guarantees of client-perceived end-to-end page-view response time in multi-tier web sites. Second is a 2D service differentiation model that formulates the requirements of session-based workload in both inter-session and intra-session dimensions and relates it with a revenue maximization objective in e-commerce applications. Third novelty is a model-free self-tuning feedback controller that regulates the process of resource allocation dynamically and achieves a high degree of control robustness in both long and short time scales.<br\/><br\/>Edge servers are a critical building block of the Internet with profound impact on our economy and society. This research will advance discovery and understanding of the service quality assurance problems in servers under a stressed condition. By fusing the autonomic resource management technologies into current servers, this research will ultimately enhance the service availability and survivability to stress and DoS attacks. Research-based materials about Internet services will also be instilled into the undergraduate and graduate distributed computing curriculum.","title":"Modeling and adaptive feedback control for multi-class service quality assurance in stress-resilient Internet servers","awardID":"0702488","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["451038"],"PO":["565090"]},"125688":{"abstract":"One way industries harmonize the actions of individual organizations is via formal agreements on process and specification standards. Little is known about the mechanisms that drive this critical coordination so foundational to our national economic competitiveness. New information architecture technologies (e.g., XML) are rapidly replacing decades-old, stable formats (e.g., EDI), transforming the standards process in unforeseen ways. <br\/><br\/>This proposal empirically examines the development, adoption, implementation, and diffusion of industry-wide vertical information systems standards in three diverse industries: automotive, retailing, and mortgage finance. As standards diffusion is a complex interaction between independent organization-level action and collective industry-level action, the three case studies are grounded by data collection with a sample of 60 companies from each industry, which enables comparisons of relative success of a standard's adoption and use as well as its consequences. This is a unique multi-level approach, investigating the impact of collective action dynamics on specific IT design features. <br\/><br\/>Broader impacts: Improved electronic interorganizational collaboration has enormous potential to reduce transaction costs and develop more competitive industries. Such benefits can lead to lower prices for consumers. Moreover, the greater use of open Internet standards promises new opportunities for smaller organizations that were not able to enjoy the full benefits of earlier EDI approaches. The research will also produce materials for the education of practitioners and will advance the state of knowledge in several fields, including information systems and technology, management, industrial engineering, economics, sociology, and social informatics.","title":"Collaborative Research: Interorganizational Information System Integration Through Industry-wide Standardization: Technical Design Choices and Collective Action Dilemmas","awardID":"0704978","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["483279"],"PO":["564456"]},"127415":{"abstract":"This is an interdisciplinary inter-institutional collaborative research (0713087: Catherine Plaisant, University of Maryland College Park; 0712770: Jean Scholtz, Battelle Memorial Institute; 0713198: George Grinstein, University of Massachusetts Lowell) focuses on visual analytics (VA), i.e., the science of analytical reasoning facilitated by interactive visual interfaces. This project addresses an important aspect of visual analytics methods and tools, namely developing an evaluation infrastructure, as there is currently no general consensus on how to evaluate VA systems. It is especially difficult to assess their effectiveness as they combine multiple components (analytical reasoning, visual representations of data, computer human interactions, data representations and algorithms, tools for communicating the results of such analyses) integrated in complex systems. Further, it is difficult to assess the effectiveness without realistic data and tasks; hence, it is quite costly for each individual researcher to evaluate the effectiveness of their specific VA approach. <br\/><br\/>The goal of this project is to design and conduct initial tests of an evaluation infrastructure that will provide datasets with ground truth, supply guidance for experiments, test methodologies and metrics, and encourage collaboration and sharing of qualitative and quantitative results amongst researchers. Because visual analytics tasks vary widely, from maintaining awareness to assessing a situation, monitoring changes, solving crimes or dealing with emergencies, and are applicable to a variety of domains with different needs (e.g., business or intelligence analysis, medical research, emergency management), this project aims to bridge those diverse communities. The project Web site (http:\/\/www.cs.umd.edu\/hcil\/semvast\/) will include a sharable set of methods, tools and metrics for evaluation, and other results from this project. <br\/><br\/>Community wide, systematic evaluations of visual analytic systems will produce better understanding of the issues in the core research fields involved in visual analytics as well as the issues that cross between those research fields. The evaluation methodologies developed will benefit research activities as well as product development. This will lead to more effective systems and impact all visual analytics application domains. Classes in visual analysis are now being taught at the university level as well as in government agencies. Benchmarks and automated evaluation tools will be developed with professors and students and used in class projects and assignments.","title":"III-CXT: Collaborative Research: Scientific Evaluation Methods for Visual Analytics Science and Technology","awardID":"0713087","effectiveDate":"2007-09-15","expirationDate":"2010-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["440679"],"PO":["563751"]},"128999":{"abstract":"A growing class of embedded sensor networks deployed for scientific, engineering, industrial, and medical applications use sensors that, in aggregate, capture thousands or millions of samples per second. XStream is a signal-oriented stream processing system designed to analyze these high-rate data streams effectively and efficiently, targeting applications that combine signal processing and asynchronous event-stream processing operations.<br\/><br\/>The prototype XStream system demonstrates very high performance on a single-node system. XStream's signal-oriented optimizations yield 1000x performance improvements relative to commercial streaming databases that would process each sample as a separate tuple. This single-node prototype is being extended to support distributed operation in a heterogeneous network comprised of a mixture of wireless sensor nodes, user interface devices, and wired server farms. These extensions include network protocols and components to support distributed computation and in-network storage, improved support for multi-core, multi-processor server systems, and modifications to the WaveScript query language as needed to express and implement these features. To ground and validate the XStream design, these new features are being tested in fielded deployments implementing a bio-acoustic animal localization study.<br\/><br\/>XStream will extend the state of the art in both streaming database technology and high-rate sensor systems. In addition, XStream will become a powerful tool for building interactive and reactive sensing systems, with broad application to scientific inquiry, industrial and medical systems, and defense and homeland security. The XStream source code will be released for public use and we are already working with biologists and medical researchers to apply XStream in their domains.","title":"CSR-CSI: XStream, a Distributed Stream Processor for Heterogeneous Sensor Systems","awardID":"0720079","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["508283","525076"],"PO":["493916"]},"129505":{"abstract":"Many architectural elements of today's Internet implicitly assume that hosts remain attached to the network over extended periods of time. However, there is much to be gained by supporting a style of networking that does not require an end system to maintain full, ongoing connectivity in order to maintain its network \"presence.\" In this project we explore a style of networking that we term \"selectively-connected\", by which we mean an end system, can knowingly manage the extent of its network connectivity in response to internal or exterior events, as it anticipates changes in connectivity.<br\/><br\/>While selectively-connected networking also has applications for end systems that enter outage periods (e.g., a user closing a notebook, or a mobile device entering no-coverage area), one highly significant form of operation it can enable concerns placing end systems into some degree of \"sleep\" in order to operate with much greater energy efficiency. Such sleeping not only can benefit portable devices by greatly extending their battery lifetime, but can also realize energy savings at a national scale by enabling desktop systems and set-top devices to enter states of greatly reduced processing without sacrificing their network presence.<br\/><br\/>In this project the researchers undertake initial designs of new architectural components for better supporting selectively-connected networking, by which sleeping hosts can retain their standing in the network or delegate agents to act on their behalf during their absence. These span: exposing selective connectivity; evolving soft state into notions of \"proxyable\" or \"limbo\" state; facilitating host-based control; introducing \"assistants\" to work in concert with sleeping end systems; exploring primitives that applications might use to express the semantics they wish to preserve when selectively-connected; and considering network links that can themselves sleep when the end systems they serve are likewise sleeping.","title":"NeTS-FIND: Collaborative Research: Architectural Support for Selectively-Connected End Systems: Enabling an Energy-Efficient Future Internet","awardID":"0721933","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["562327","563433"],"PO":["565090"]},"127459":{"abstract":"Advances in imaging technologies (Magnetic Resonance Imaging, for example) have significantly accelerated brain disorder studies. There is an urgent need to integrate, index and model multimodal data across a large population in order to discover a more detailed understanding about process interaction in this very complex biological system. Current state-of-the-art computational and software technologies fall short in multimodality data integration and modeling, and integrated analysis of diverse neuroimaging datasets across human subjects. The overall aim of this proposal is to develop a novel, rigorous framework for integrated modeling and analysis of multimodality neuroimaging data based on Riemannian geometry, multivariate simplex splines, and statistical learning. <br\/><br\/>Intellectual Merits<br\/>This interdisciplinary research team will design a fundamental framework for advanced and integrated analysis of brain imaging data. All research activities will address the following major themes and objectives: (1) To explore new theoretic tools based on Riemannian geometry of 3-manifolds for the development of a novel Canonical Volumetric Model (CVM) which provides volumetric mapping of individual brain to a solid unit sphere with accurate matching across subjects; (2) To design hierarchical spherical trivariate simplex splines for compact representation, integration, indexing and visualization of multimodality heterogeneous imaging data with high efficiency and accuracy, which can further refine the intersubject registration through level-of-detail matching in a higher dimensional physical space based on the integration of the hierarchical spline volume with Lagrangian dynamics; (3) To design new statistical learning and mining methods to analyze simultaneously the variety of data across the broad range of spatial and temporal scales and human subjects in order to infer the dynamics of brain functions in neurological disease studies. <br\/><br\/>Broad Impacts<br\/>This research will contribute to the data-intensive brain study by offering an accurate, robust, and innovative scientific approach for analytic integration, statistical modeling, and quantitative analysis of a variety of brain imaging data. The proposed computational framework has the potential to be applied across multiple areas of brain research as well as in clinical diagnosis. It is likely that this work will impact a large number of patients with neurological diseases and will provide a commonly accepted standard infrastructure for use by many other researchers. The PIs'' research endeavors will be tightly integrated with a complementary set of educational objectives, including: (1) the development of new strategies for truly multi-disciplinary science education; (2) the enhancement of the existing curricula; (3) the doctoral training of graduate researchers; (4) the implementation of mentoring activities for students from underrepresented groups.","title":"III-CXT: Collaborative Research: Integrated Modeling and Learning of Multimodality Data across Subjects for Brain Disorder Study","awardID":"0713315","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["359637","424417"],"PO":["565136"]},"129429":{"abstract":"Rapid advances in portable computing and wireless technologies are creating deployments of many different types of radio access networks such as WWANs, WLANs, and WPANs with different transmission rates, coverage ranges, power-levels, mobility-levels, services and price-levels. <br\/><br\/>In such a heterogeneous architecture, devices equipped with multi-network interfaces (i.e., multi-mode terminals) should be capable of performing network selection, location update, paging, and horizontal and vertical handoff. <br\/><br\/>The objective of this proposal is to provide an integrated heterogeneous wireless network to support multi-mode terminals in the multi-network environment, where the terminals take advantage of multiple interfaces to satisfy the QoS requirements. This proposal introduces new horizontal and vertical cross-layer features that allow multi-mode terminals to opportunistically exploit the available multi-networks. These new features include network availability detection and link quality estimation, and use information from different layers across multiple interfaces, in order to decide which connectivity-alternative best matches the requirements of an application. The multi-mode protocol stack will be defined such that it does not require any modifications to existing protocols so that different wireless technologies can also support multi-connection handoff and multi-network interfaces. From the system's perspective, proposed solution can help improve the overall system performance by redirecting the traffic to appropriate networks. Such an effective solution for connection and handoff management can lead to drastic performance enhancements.","title":"NeTS-WN: Collaborative Research: Supporting Multi-mode Terminals in Integrated Heterogeneous Wireless Netowrks","awardID":"0721641","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["402054","345060"],"PO":["557315"]},"128219":{"abstract":"Abstract:<br\/><br\/><br\/> Anyone with a moderate amount of skill can intercept Internet mail<br\/><br\/> messages and private web pages to see what they say; can modify<br\/><br\/> messages in transit, changing their content without any trace; and<br\/><br\/> can send fake messages that are indistinguishable from legitimate<br\/><br\/> messages. Cryptography responds to these threats by scrambling and<br\/><br\/> unscrambling packets to protect against forgery and against<br\/><br\/> espionage. An attacker who forges a message can't scramble it in the<br\/><br\/> right way; when legitimate users' computers unscramble the message,<br\/><br\/> they see that it's a forgery and that it should be thrown away. An<br\/><br\/> attacker who intercepts a scrambled credit-card number can't figure<br\/><br\/> out the original number.<br\/><br\/><br\/><br\/> Unfortunately, cryptography is often too slow to deploy on busy<br\/><br\/> network servers. Widely used web sites such as google.com and<br\/><br\/> livejournal.com have installed all the necessary cryptographic<br\/><br\/> software but use it for only a small fraction of their web pages. <br\/><br\/> When a user tells his web browser to make a cryptographically<br\/><br\/> protected connection to https:\/\/www.google.com, Google redirects the<br\/><br\/> browser to http:\/\/www.google.com, turning off the cryptography!<br\/><br\/> Similar comments apply to SMTP (mail), DNS (name lookup), and other<br\/><br\/> Internet protocols: even when the necessary cryptographic software<br\/><br\/> has been written and installed, users are often forced to disable or<br\/><br\/> limit the software so that their computers are not overloaded. This<br\/><br\/> research responds by producing new speed records for the<br\/><br\/> cryptographic operations needed to protect the Internet. These<br\/><br\/> speedups allow cryptography to handle a larger fraction of the total<br\/><br\/> volume of Internet communication, reducing the Internet's overall<br\/><br\/> exposure to attack.","title":"CT-ISG: High-Speed Cryptography","awardID":"0716498","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["548359"],"PO":["565264"]},"130650":{"abstract":"Collaborative Research: Single Molecular Devices for Molecular Nanocomputing: Synthesis, Device Fabrication and Theory<br\/><br\/>As the current silicon complimentary metal-oxide-semiconductor (CMOS) technology continues to increase the speed, capacity and computational power of modern computers, it approaches the fundamental limit at which processors can no longer be made smaller, faster and cheaper. This collaborative project will investigate single-molecule electronic devices as fundamental building blocks for molecular nanocomputing, an emerging technology for the next generation of information systems beyond CMOS integrated circuitry. By bringing together the complimentary expertises in organic synthesis (the Yu group at the University of Chicago), device fabrication and electrical characterization (the Tao group at the Arizona State University), and nanoscale theory\/modeling (the Oleynik group at the University of South Florida) into a synergistic effort, the team will focus on the development of innovative computer technologies at the atomic and molecular levels using fundamental principles of nanoscience and engineering. This high-risk, high-return area of research promises revolutionary advances in developing faster and smaller computer chips beyond conventional silicon CMOS technology.<br\/><br\/>The research program includes three major thrusts: (1) to synthesize new \"designer\" molecules that will function as diodes, transistors, switches and information storage elements and with the help of theory\/modeling to establish a structure\/property relationship between a molecule's chemical nature and resulting electronic properties. (2) to assemble these \"designer\" molecules into nanocircuitry using STM, conducting AFM, and electrochemical break junctions for electrical characterization of single-molecule devices, and to control the electron transport in these molecules using electrochemical gating combined with the guidance from theory. (3) to develop fundamental operational principles of specific molecular devices using the theory of electron and hole resonant tunneling conduction, and to investigate molecule\/electrode contacts, negative differential resistance switches, molecular field effect and bipolar transistors. The tightly coupled, vertically integrated research and educational activities will provide a unique opportunity to nurture the next generation of scientists and engineers who will put the science beyond Moore's law into practice.","title":"Collaborative Research: Single Molecular Devices for Molecular Nanocomputing: Synthesis, Device Fabrication and Theory","awardID":"0726842","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7931","name":"COMPUTATIONAL BIOLOGY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7947","name":"NANOCOMPUTING"}}],"PIcoPI":["458060"],"PO":["565157"]},"129209":{"abstract":"The increasing prevalence of embedded devices, which account for over 99% of all CPUs manufactured today, drives the need for an advanced execution environment that addresses a number of important problems for embedded systems. Dynamic reprogramming, fault isolation and recovery, dealing with limited hardware resources, and automatic adaptation are but a few of the motivating issues. <br\/><br\/>Currently, many general-purpose computers use a virtual execution environment (VEE) in addition to the operating system to provide meta-execution functionality, including software and hardware compatibility, dynamic optimization, profiling, and security. The VEE transparently and automatically mediates, controls, and adapts an application as it executes on the target architecture. Despite the benefits, the power of VEEs has yet to be realized for embedded devices due to the memory and power constraints of these devices. Furthermore, the resource profiles of embedded devices lead to the need for new strategies to be explored and developed.<br\/><br\/>This project explores new virtualization technology specifically designed for the resource profiles of embedded devices. The research is making several fundamental advances in VEE technology including reducing the memory footprint, designing VEEs that function on the multitude of embedded platforms, and efficiently offloading large computation that cannot be performed on resource-constrained nodes. <br\/><br\/>Rather than focusing on a single VEE for a particular device, the ultimate goal is to explore the entire VEE design space continuum, evaluating the numerous design options and trade-offs for a variety of embedded devices. As a first step, this project explores new design points for three commonly used embedded devices: the PDA, the cell phone, and the sensor node.","title":"CSR--EHS: Virtual Execution Environments for Heterogeneous Embedded Devices","awardID":"0720803","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["438734","438733","543576"],"PO":["561889"]},"131651":{"abstract":"Collaborative Research: Algorithms for Near-Optimal Multistage Decision-Making under Uncertainty: Online Learning from Historical Samples<br\/><br\/>Abstract<br\/><br\/>Recent advances in information technologies enable firms to collect and maintain huge amounts of raw data regarding demand, sales history and other aspects of their operations. However, little is known about using this data effectively and efficiently within their decision-making processes, which can often be modeled as multi-stage stochastic optimization problems. In many application domains, such as supply chain management and revenue management, these give rise to complex problems, where the decision in each stage must be made under uncertainty about the future evolution of an underlying stochastic process. Traditional approaches to these problems assume that the uncertainty is defined through explicitly specified probability distributions that are known a priori; the knowledge of these distributions is crucial to the development of the corresponding optimization algorithms. However, in most practical situations the exact distributions are not known, and only historical data is available. This research project aims to develop a general-purpose sampling-based algorithmic framework for these models that, unlike traditional approaches, uses the raw historical data as the source of samples. First, we plan to develop sampling-based algorithmic approaches to approximately solve complex stochastic dynamic programming formulations, the dominant paradigm used for these problems. Second, we focus on sampling-based algorithms for models that combine optimization and learning simultaneously. A common theme between these two research thrusts, and a central feature of our research project, is the development of explicit quantitative analysis of the performance of our algorithms that provide guarantees on the sample-size needed to assure a specified error bound with respect to optimal solution for the true underlying probability distribution.<br\/><br\/>Consider a firm like Amazon that provides millions of different items to customers throughout the US. Clearly, it is important for the company to have the inventory that its customers want, since if an item is out of stock, then the customer is likely to purchase the item from elsewhere. On the other hand, maintaining extra inventory for undesired items has the disadvantage of tying up capital in obtaining them, using significant resources in warehousing this supply, which is further compounded by the risk of perishability and obsolesce. If one had a crystal ball with which one could predict the future, then the company could know how many requests there will be, day by day, for each of the items it sells, and therefore know how much of what should be on hand in each of its warehouses. Instead, one can model the future probabilistically (similar to what a weather forecaster does when saying that there is a 40% chance of showers tomorrow), and then one can cast the problem of making the optimal decisions for these inventory levels as a problem of maximizing the average profit that can be obtained (or minimizing the average costs incurred), where the notion of average is with respect to the randomness used to model our inability to exactly predict the future. This project has the goal of using past historical data as a means for modeling the predictions for future data, and then designing algorithms that produce provably near-optimal decisions based on this approximation. This type of decision-making in the face of uncertainty arises in a wide range of application domains, from selling different classes of airline<br\/>tickets for a portfolio of flight legs to manufacturing a suite of products that rely on overlapping sets of components. This project focuses on settings in which there are multiple stages of decision-making that must be made in the face of an evolving view of the predictions of future<br\/>requirements. The aim is to provide tools to automate such decision-making with algorithms that are guaranteed to quickly produce reliable solutions.","title":"MSPA-MCS: Collaborative Research: Algorithms for Near-Optimal Multistage Decision-Making under Uncertainty: Online Learning from Historical Samples","awardID":"0732175","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["391126","555822"],"PO":["565286"]},"132762":{"abstract":"The U.S National Committee for CODATA will organize a two-day international workshop in collaboration with the Organisation for Economic Co-operation and Development (OECD) to obtain an improved understanding of methods, models, and techniques to assess the specific effects of different access and reuse policies for online Public Sector Information (PSI). A summary report will be published by the National Academies in collaboration with the OECD at the conclusion of the project and the results will also provide input to the OECD Ministerial meeting that is tentatively scheduled for June 2008.<br\/><br\/>The Workshop will consider different approaches and levels of access to and reuse of public sector information. Participants will discuss variability in implementation and enforcement of established national access and reuse policies; the role that PSI and government policies play in governing such information play; the understanding of economic and non-economic effects of PSI online; and the effects of different access and reuse policies. The Workshop will address empirical data regarding the effects of PSI disseminated on the internet and different policy approaches to this dissemination. The Workshop will seek to identify, understand, and evaluate current methods and underlying criteria that are used in this area and to provide more solid frameworks for policy makers and information managers to assess the effects of different access and use policies.<br\/><br\/>The Workshop will consider public investment in PSI and economic activity based on the reuse of that information; the intangible, non-economic social benefits of different types of PSI; and educational, research, good governance, and various other applications for PSI to improve the welfare of society. <br\/><br\/>Additional issues to be discussed at the Workshop include the costs and benefits of different information policies on the information society and the knowledge economy. By understanding the strengths and weaknesses of the current assessment methods and their underlying criteria, the Workshop may be able to identify ways to improve and apply such tools to help rationalize the policies and clarify the special role of the internet in disseminating PSI, thus leading to increased efficiency and effectiveness of PSI investments and management and improvement and of their downstream economic and social results.","title":"The Socioeconomic Effects of Public Sector Information on Digital Networks: Toward a Better Understanding of Different Access and Reuse Policies","awardID":"0738128","effectiveDate":"2007-09-01","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7328","name":"ICSU"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0600","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"1679","name":"INTERNATIONAL COORDINATION ACT"}}],"PIcoPI":["499569"],"PO":[353098]},"131673":{"abstract":"The inference problems associated with high-dimensional genomic data offer fundamental challenges for modern statistics, machine learning, and data-mining research. Methods that have had success in this domain impose constraints on models incorporating notions of simplicity, smoothness, or robustness. The constraints are often formalized either as priors for Bayesian methods or as geometric criteria for machine learning methods. The heart of this proposal is to develop and relate the importance of the geometry underlying the data to probabilistic modeling. The specific research foci of the proposal are: 1) The exploitation of geometric assumptions for problems of model uncertainty and variable selection in high-dimensional models; 2) A Bayesian framework for the use of ancillary or unlabeled data in predictive modeling; 3) Theory, methods and computation for nonparametric Bayesian kernel models; 4) Novel methods for nonlinear dimension reduction for high-dimensional data from regularization and geometric perspectives.<br\/><br\/>The proposal develops theory, methods and computational tools for statistical modeling motivated by applications in functional genomics. Modern molecular biology has generated data of a rapidly escalating scale and complexity -- high-throughput genomics data, genetic and sequence information, proteomic and metabolomic data, and other forms of more traditional biomedical or clinical information. Modeling this data for predictive phenotypes of prognosis, diagnosis, and pathway deregulation as well as understanding relevant variables and their associations are fundamental challenges for modern statistics, machine learning, and data-mining research. These methodological developments will have impact on several other scientific areas including biology, engineering, environmental and health science, and social sciences.","title":"Collaborative Research: Probabilistic models and geometry for high dimensional data","awardID":"0732260","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["550819"],"PO":["565286"]},"133741":{"abstract":"This small grant for exploratory research investigates a promising new approach to checking the proper execution of software composed of components. An attractive method for developing new reactive software is to use ?off-the-shelf? third-party components that do not, or may not, exactly satisfy the desired requirements. To safely use such components, the use of run-time monitors is used to detect behaviors violating the requirements. Such requirements are usually composed of a safety part, whose run-time monitoring is well studied, and a liveness part, whose run-time monitoring is elusive. Most commonly, run-time monitors extract a safety property, that either over-approximates or under-approximate the original requirements, and thus tend to have a have high level of inaccuracy.<br\/><br\/>A novel class of methods is proposed that employs randomization for monitoring the liveness properties. Roughly speaking, the method occasionally tosses a coin to determine whether to give up achieving a liveness requirement. Such methods are highly accurate and enjoy the property of graceful degradation: the longer a liveness property is not satisfied, the more likely is it to be rejected by the monitor. The project also investigates novel methods for evaluating the accuracy of monitoring approaches to compare various algorithms. Finally, monitors are usually ?passive? -- they only observe the computation, but do not participate in them ? but this work explores ?active? monitors that cooperate with the component to generate a computation that satisfies the requirements.","title":"SGER: Monitoring Off-the-shelf Components","awardID":"0742686","effectiveDate":"2007-09-15","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["362818","550555"],"PO":["564388"]},"134962":{"abstract":"This project explores the development of methodologies for populating worlds with persistent, adaptive, collaborative, believable synthetic actors, referred to as Synthespians. These methods are extensions of adaptive models of learning and planning to accommodate the complex, dynamic environments in massive multi-player online games. The intellectual merit includes the development and evaluation of:<br\/>1. A behavior development language, with discovery, machine learning, and adaptation of behaviors directly integrated into the language, allowing for the rapid development and deployment of Synthespians.<br\/>2. A framework for the actors to recognize and discover plans by observing and modeling the activities of the other agents.<br\/>An expected outcome of this research is the ability to author complex virtual worlds with many participants that support intelligent and effective interaction between people and machines.<br\/><br\/>Broader Impact: A scientific understanding of how we interact with each other and collaborate will benefit from our ability to simulate complex environments with dynamic and evolving individual and group behaviors. In this project, building and modeling such environments and behaviors is done within a gaming context. This work will in the long run effect and change the fields of education and entertainment. In addition, being able to model large collaborative and interactive scenarios will also help us understand and model large social dynamics phenomenon of interest to sociologists and economists.","title":"SGER Collaborative Research: Persistent, Adaptive, Collaborative Synthespians","awardID":"0749316","effectiveDate":"2007-09-15","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["536597"],"PO":["565227"]},"131112":{"abstract":"The main focus of the research is to develop good algorithms for designing networks. With the popularity and ubiquity of the Internet, it has become important to develop simple and scalable algorithms to design good networks which offer the most flexibility and functionality. The<br\/>network designer has to build networks given only partial information and loose estimates of the traffic that will eventually be carried, to build networks knowing that faults will almost surely occur and to provision for handling these faults gracefully, and to do this in the most economic and efficient fashion. Along with this, the network designer today must take into account the heterogeneity of networks (which will include wireless and optical parts), and the fact that each<br\/>network has to interact with potentially many other networks. In addition, these interacting networks may be controlled by different entities having different pricing schemes and different incentive structures.<br\/><br\/>The investigators from Carnegie Mellon University and Bell Laboratories draw on their mix of backgrounds to mathematically model the problems faced in network design contexts, and to develop algorithmic tools and good algorithms with provable guarantees for these problems. To achieve these goals, the research adapts and augments a rich set of algorithmic techniques from linear and convex programming, stochastic optimization, metric embeddings, and randomization, as well as complexity-theoretic techniques that have developed in theoretical computer science over the past few years. The research reflects a collaboration between academia and research laboratories to transfer ideas, problems and algorithms between theory and practice: in particular, the research encourages students to learn problem modeling and solving, and to move between the<br\/>two environments gaining a balanced view of issues in network design. Research progress is propagated into the curriculum via specialized courses presenting the theoretical advances in the context of their applications, as well as basic courses teaching the fundamental ideas and techniques behind these research advances.","title":"Collaborative Research: Emerging Directions in Network Design and Optimization","awardID":"0728980","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":[348054],"PO":["562944"]},"133774":{"abstract":"This project develops a fundamentally new model for preserving location privacy in spatial query evaluation. The main novelty is that unlike the current approaches for location privacy, this model does not require an intermediate party between the client and server during the regular mode of communication. This feature is consistent with the typical encryption models where two parties, Alice and Bob, can communicate privately without sending their messages through a third party intermediator. <br\/><br\/>This is a high-risk research because devising an encryption scheme that maintains distance properties of space is hard. That is, with conventional encryption approaches, nearby objects in the original space are no longer close in the encrypted space. The idea is to devise a one-way transformation on the space such that the transformed space maintains the distance properties of the original space and hence spatial queries can be resolved efficiently in the transformed space. This transformation can be viewed as encryption of the space with a one-way transformation function that allows fast computation of its inverse given some extra knowledge, termed transformation-key.<br\/><br\/>The broader impact of this study is to enable many users with privacy concerns to utilize customized location services in their mobile devices without compromising their location privacy. This in turn would increase the customer base for many industries and government agencies in the areas of geospatial information systems, online maps, car navigation systems, Location-Based Services, and military\/intelligence operations. One PhD student is supported by this project. The encryption tools and the technical papers describing them will be disseminated through the project's web site: http:\/\/infolab.usc.edu\/projects\/LocationPrivacy\/.","title":"SGER: Blind Evaluation of Spatial Queries with Hilbert Curves to Preserve Location Privacy","awardID":"0742811","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["550740"],"PO":[355797]},"130386":{"abstract":"Optimization problems arise in engineering, business, and medicine.<br\/>Computational studies show that interior-point methods outperform others for solving large-scale problems. This research involves the development of techniques to improve interior-point methods for nonlinear and related optimization problems. Its intellectual merit is the solution of complex problems and their re-solution under changing conditions, two current deficiencies that must be addressed to keep these methods at the forefront of optimization technology. Test problems benefit the optimization community and researchers in applied fields by encouraging the use of appropriate modeling and solution techniques and the development of new ones as necessary. The broadest impact of this research is the social and financial gains achieved by solving problems that better reflect the real-world and by responding more effectively to a dynamic environment.<br\/><br\/>In order to improve and extend the use of interior-point methods, the investigators study (1) primal-dual penalty methods to improve warm-starting capabilities for solving closely related problems with changing data and problem size, (2) bilevel frameworks for solving mixed-integer nonlinear problems, with improved warm-starting and infeasibility identification schemes for nonlinear subproblems, and (3) incorporation of equilibrium and cone constraints into the nonlinear optimization framework using the primal-dual penalty approach. Another component of this research is the development and dissemination of a repository of applied problems with a variety of components, such as nonlinear functions, discrete variables, equilibrium constraints, and cone constraints, along with alternate data sets and parameter settings suitable for testing warm-start approaches. All work is incorporated into graduate courses and research. Course notes and test models are distributed on the WWW, and software is made available for free use on the NEOS Server.","title":"Efficient Interior-Point Methods for Mixed-Integer Nonlinear and Conic Programming","awardID":"0725692","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":[345986],"PO":["381214"]},"135600":{"abstract":"Proposal #: CNS 07-08199 07-08464<br\/>PI(s): Gupta, Rajiv; Gupta, Neelam Zhang, Xiangyu<br\/>Institution: University of Arizona Purdue University<br\/> Tucson, AZ 85721-0001 Wes Lafayette, IN 47907-2108<br\/>Title: IAD: Advanced Infr for Generation, Storage, and Analysis of Program Execution Traces <br\/><br\/>Project Proposed:<br\/>This collaborative project, developing an open source software infrastructure that is capable of tracing and analyzing long program executions, features customizability, extensibility, and most importantly, the capability of collecting prolific types of execution traces for realistic executions on single- and multi-threaded programs. The work is feasible due to the fact that, at present, checkpointing\/logging can be effectively combined with tracing through a technique called Execution Fast Forwarding (EFF) that enables scaling up tracing by orders of magnitude and availability of a highly compacted trace representation called Whole Execution Trace (WET) composed of static program representation that is annotated with dynamic traces including control flow, address, value, and a dependence trace that can contain complete program execution history in compacted form. Components of the infrastructure include<br\/>. Checkpointing\/logging environment that will execute a given binary on the supplied input to produce a set of checkpoints and logs which can be used to replay the execution;<br\/>. Execution fast forwarding components that will eliminate part of the execution that is not relevant to reproducing a given event;<br\/>. Tracing component to generate, compress, and store the WET (Whole Execution Trace) of a replayed execution interval; and<br\/>. Trace analysis component to provide an API that will enable users to access WET's with ease, without having to understand the low level detailed representation of WET.<br\/>Dynamic analysis techniques analyze traces of program executions to characterize the runtime behavior of programs. Distinctive runtime characteristics are then exploited in designing the systems to <br\/>. Develop highly reliable systems by detecting bugs, locating faults, and testing programs; <br\/>. Develop secure systems by detecting information leaks and unsafe behavior, and performing software marking; <br\/>. Validate and verify data by associating the output produced by highly complicated data processing procedures to the raw input data that can greatly facilitate verification of results;<br\/>. Develop hardware and software for highly optimized systems (e.g., embedded systems that must optimize performance, power, & memory usage) exploiting a wide range of runtime program characteristics (e.g., recurring code sequences to achieve compression, narrow width data to develop energy efficient cache designs & pipelines, etc.). <br\/><br\/>Broader Impacts: The infrastructure enables rapid prototyping for data verification, computer architecture, compilers, embedded systems, software engineering such as building testers and debuggers, security such as designing watermarking and information flow analysis tools. The uniform representation of logs and WETs provides standard interface to easily exchange traces. Moreover, encouraging synergy among projects, course projects will be designed and provided with the infrastructure.","title":"CRI: IAD An Advanced Infrastructure for Generation, Storage, and Analysis of Program Execution Traces","awardID":"0751949","effectiveDate":"2007-09-01","expirationDate":"2010-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7399","name":"CISE MINOR INST INFRA (MII) PR"}}],"PIcoPI":["549718"],"PO":["557609"]},"122532":{"abstract":"Formal static analysis is an approach which has great potential for improving the reliability of computer systems. One of the key techniques used in static analysis is abstraction. There are many different kinds of abstractions, but they all have essentially the same goal: to achieve scalability by sacrificing precision. Unfortunately, abstraction leads to the possibility of false errors: scenarios in which a bug is reported even though there is no actual bug in the system.<br\/><br\/>The main research hypothesis of this proposal is that many false errors can be eliminated by using a two-stage approach in which potential errors are subjected to further analysis by a tool whose focus is precision rather than abstraction. The second-stage tool provides precision on demand for a small and specific set of potential errors. The research will focus on novel techniques for precise analysis, performance, and scalability. These will be implemented and evaluated in the context of the Cascade tool: a fast, robust, and automatic tool providing precision on demand for static analysis of software.","title":"CAREER: Cascade -- Precision on Demand for Software Verification","awardID":"0644299","effectiveDate":"2007-09-01","expirationDate":"2014-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["550906"],"PO":["565264"]},"131123":{"abstract":"The methodologies of computational geometry will be applied to design, analyze, implement, and test algorithms for problems that arise in several application areas, including geometric network optimization, sensor networks, robotics, air traffic management, geometric modeling, manufacturing, computer-aided design, cartography, and graphics. The main project goal is the development of fundamental advances in geometric algorithms. Additionally, the project will strive to foster and deepen collaborations with researchers in application domains and industry, in order to formulate their algorithmic needs precisely and to make available algorithmic tools, insights from theoretical results, and software from experimental investigations.<br\/><br\/>The four problem areas are:<br\/> (a). Geometric Optimization and Networks -- optimal routing and network design in geometric contexts, including TSP variants, vehicle routing, constrained spanning trees, minimum-weight subdivisions, optimal route planning with various constraints, and survivable network design;<br\/> (b). Sensor Networks and Swarm Robotics -- sensor localization, sensor coverage and deployment, data field monitoring, and ad hoc networking for stationary or mobile (robotic) sensors;<br\/> (c). Air Traffic Management -- optimal use of airspace in the face of dynamic and uncertain constraints induced by weather and traffic congestion, sectorization (load balancing), and optimization of the network structure of the National Airspace System;<br\/> (d). Shape Approximation, Virtual Models, and Manufacturing -- shape approximation, collision detection, virtual prototyping, and manufacturing process planning.<br\/><br\/>The problems are attacked on two fronts: (1) Application of formal algorithmic analysis, attempting to prove the tightest possible bounds (upper and lower) on the worst-case or average-case time\/space, or approximation ratio for the problem; and (2) Development of solution techniques designed to be simple, fast, and practical, which are compared experimentally.","title":"Algorithmic Studies in Applied Geometry","awardID":"0729019","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["451713","471875"],"PO":["565157"]},"134885":{"abstract":"Geographic maps are one of the most traditional, familiar, and important visualizations in widespread use today. There is increasing understanding of the importance of visualization in providing insight into a vast amount of data to support critical reasoning and decision making in a variety of domains. Moreover, in the past few years, there has been a revolution in online access to map data and basic integration tools, enabling user driven applications from remote archaeological research to \"mashups\" mapping avian flu outbreak, military testing, local gas prices and far more. This represents a fundamental shift from few general-use map visualizations developed by expert cartographers to many specific map visualizations being developed by end users. As the latter utilize a growing number of mapping tools, new interaction methods and information management approaches are needed to reduce visualization complexity and improve usability. Yet research into map use has focused primarily on the artifact of visual representation and very little on the dynamic behavior of users' interactions with those representations. There are few guidelines for creating map visualizations that meet user needs, potentially limiting the effectiveness of these critical visualizations. Thus, there is a recognized need for a deep investigation into how people use maps to support the growing efforts in visualization and visual analytics.<br\/><br\/>This proposal addresses that need by using Human Computer Interaction techniques in to study the usability of map visualizations. Specifically, the project will address the following four questions: 1.) How do users interact with map visualizations? 2.) How do users deal with map complexity? 3.) How do elements of the map visualizations support user behavior? 4.) How do interactions vary across user and task context?<br\/><br\/>Specifically, the project will consist of two exploratory, observational studies of users performing a variety of map-based analysis tasks, examining their interaction behavior with map visualizations. Outcomes will identify the usability problems and issues that users face, as well as the common patterns of interaction for particular tasks and more generally across tasks. These initial results will lay the groundwork for theories on the use and design of interactive map visualizations, advancing our understanding of how users interpret geovisualizations. Because the problem has received very little scholarly attention, this project will be a foray into largely untested ideas. Further, given the recent explosion of interactive, online, and user-centered mapping, project outcomes have significant potential to establish transformative directions for geovisualization and human-centered computing. Outcomes will also ground work on automatically adapting and personalizing geovisualizations based on user and task contexts. <br\/><br\/>Broader Impacts<br\/>Geovisualization is a powerful mechanism to enable critical thinking and decision making involving spatial information, and geographic maps are the most widely used geovisualization. Understanding how people use and interact with maps will guide the improved design of these critical visualizations, potentially impacting a wide variety of domains, such as public health, environmental science, and emergency planning. This project represents a first-of-its-kind evaluation of geovisualizations from an interaction behavior point of view. Our preliminary results will provide design guidelines for interactive maps and demonstrate the value of interaction research in geovisualization.","title":"SGER - Studying Map Interaction Behavior","awardID":"0748983","effectiveDate":"2007-09-15","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["373254","550118"],"PO":["388678"]},"133686":{"abstract":"This project will develop a transderivational search engine based on the neurological condition known as synaesthesia in which two or more senses are crossed (e.g., when seeing a color causes one to hear a sound) to help people to discover connections between text, 1D audio, 2D image, 3D geometry and 4D motion data. The project is inspired by the ability of artists and designers to find analogies between diverse artifacts and bring them together to compose a coherent and novel narrative.<br\/><br\/>The intellectual merit of this research is the development of matching algorithms that suggest analogies across different media forms by looking at structural similarity within media content. The result will be a transformative technology at the intersection of art, computer graphics, machine learning, cognitive psychology, and human-computer interaction (HCI). Transderivational search will enhance the synaesthetic effect in analogy generation and will naturally lend itself to a wide range of brainstorming pursuits. Finding analogies between media of different forms (e.g., audio and 3D shapes) has not been explored, nor has there been much focus on non-literal search engines. Literal searches rely only on explicit meaning (e.g., the word ?three? and an image of the number 3) and categorization to determine similarity. Instead, this project will compare media samples by looking for structural similarity using analytical approaches such as statistical shape distributions, frequency analysis, and machine learning techniques to discover relationships between mixed- (multi-dimensional) media samples.<br\/><br\/>The broader impacts of this research are in advancing artificial intelligence through transderivational search (essential to language and cognitive processing) and in opening up new research questions on search technology. The educational impacts are in drawing more women and minorities into CS and improving retention in CS programs by showing the relevance of search technology to creative design and to multimedia management. The transderivational search tools will be used by students in introductory level CS courses to build basic media management software. Transderivational search can also serve as a testbed for exploring algorithms in high level CS courses on machine learning, computer vision and graphics.","title":"SGER Proposal: A \"Transderivational\" Search Engine for Creative Analogy Generation in Mixed-Media Design","awardID":"0742440","effectiveDate":"2007-09-15","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":["397074",355519],"PO":["424970"]},"131145":{"abstract":"Modeling Wireless Networks -- Excursions in the Theory of Random Graphs<br\/><br\/>ABSTRACT<br\/><br\/>We investigate three classes of random graph models, namely random connection graphs, random intersection graphs and a combination thereof known as Kryptographs. Both the models and research questions are driven by applications from the fields of wireless networking and sensor network security: <br\/>(i) Modeling one-hop connectivity in mobile ad-hoc networks; (ii) Modeling random key pre-distribution; and (iii) Achieving secure connectivity in wireless sensor networks via random key management.<br\/>Integrating geometric and non-geometric features, as is done in (iii), leads to new and challenging problems. The overall objective of this research is to develop the theoretical foundations to assess system performance, and to help dimension attending resources in wireless networks.<br\/><br\/>Technically, many of the questions of interest are asymptotic in nature (with the numbers of nodes becoming large) and take the following form: (i) Zero-one laws for graph properties such as graph connectivty and the absence of isolated nodes; (ii) Poisson convergence results which help shed some light on possible phase transitions; and (iii) Approximations to deal with finite node situations. <br\/>The techniques are probabilistic in nature, with an important place given to the method of first and second moments, and to the Stein-Chen method. Particular emphasis is given to exploring the sensitivity of the results with respect to model assumptions, e.g., distribution of node locations. <br\/>We expect to make contributions on a number of fronts, namely (i) Advance the study of random graphs, of both the geometric and non-geometric varieties, through probabilistic techniques; (ii) Develop more realistic models for one-hop connectivity in wireless networks; and (iii) Enhance one's understanding of the behavior of large scale wireless networks.","title":"Modeling Wireless Networks: Excursions in the Theory of Random Graphs","awardID":"0729093","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["518081"],"PO":["564924"]},"133455":{"abstract":"ALGORITHMS, COMBINATORICS AND GEOMETRY<br\/><br\/>Knowledge of mathematics and combinatorics is crucial to the design of combinatorial algo-<br\/>rithms. Conversely, questions or concepts arising in the applications sometimes give rise to<br\/>interesting mathematical problems, or can be used to solve mathematical problems. Hence,<br\/>any type of interaction between the discrete mathematics and the computer science commu-<br\/>nities is beneficial to both groups and must be encouraged.<br\/><br\/>The University of North Texas in Denton will host a workshop focusing on algorithms, com-<br\/>binatorics and geometry. The workshop would focus on the mathematical and algorithmic<br\/>problems arising from combinatorial and geometric structures.<br\/><br\/>It is anticipated that the talks would introduce a broad range of fundamental and recent re-<br\/>sults which would be of interest to the advanced and beginning researchers in combinatorics,<br\/>combinatorial and computational geometry, computational biology, geometric graph theory,<br\/>topology, theoretical computer science and graph drawing. It is further anticipated that the<br\/>workshop would bring together advanced researchers, as well as graduate students in many<br\/>areas of discrete mathematics and computer science and engineering, and hence foster and<br\/>facilitate collaboration and joint research among different communities. To disseminate the<br\/>knowledge presented at the workshop and to assess its impact, a special issue of a journal<br\/>will be selected for possible publication of a collection of the papers that relate to the main<br\/>theme of the workshop.","title":"Workshop on Algorithms, Combinatorics and Geometry","awardID":"0741406","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":[354802],"PO":["499399"]},"131156":{"abstract":"Recent progress in arithmetic combinatorics has benefited from a convergence of methods from analysis, ergodic theory, combinatorics, and graph theory. This new machinery has led to spectacular progress on long-standing open questions, such as the Green-Tao theorem on arbitrarily long arithmetic progressions in the primes. This research is a systematic exploration of applications of such new techniques to theoretical computer science.<br\/><br\/>Some of the analytic, graph-theoretic and combinatorial techniques have already had a number of applications to theoretical computer science, in such diverse areas as the design of sub-linear time algorithms, the construction of randomness extractors and the design of probabilistically checkable proofs. This research explores new applications of such techniques, as well as applications of the ergodic-theoretic techniques. This research is primarily concerned with a \"\"technology transfer\"\" from arithmetic combinatorics to computer science: increased collaboration between pure mathematicians working in arithmetic combinatorics and theoretical computer scientists will, however, be beneficial to both fields, and is likely to have a positive impact beyond theoretical computer science.","title":"Applications of Artihmetic Combinatorics in Computer Science","awardID":"0729137","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["517279"],"PO":["550329"]},"131167":{"abstract":"Abstract<br\/><br\/>The investigator will continue the development of a theory of self assembly. Self-assembly is the process by which objects autonomously combine to form structures. For example, atoms self-assemble to form molecules, molecules sometimes self-assemble into crystals. Self-assembly is now viewed as one of the fundamental approaches to the creation of nanostructures and, in particular, the creation of nanocomputers. A fully developed theory will enlighten us about all aspects of self-assembly from the practical to the abstract. The development of the theory is a fundamentally interdisciplinary endeavor making use of concepts from chemistry, biology, computer science, physics and mathematics and requires a new approach to graduate student education. Students receiving their Ph.D.s will be able to think in the paradigms of all branches of science. These new \"born interdisciplinary\" scientists will be properly positioned to make great discoveries in the future and to become leaders. <br\/><br\/>The nascent theory tells us that while self-assembling processes obey physical laws, they are also Turing universal. Ideally, the fully formed theory will seamlessly combine aspects of classical theories such as thermodynamics, statistical mechanics and differential equations with more modern theories such as computational complexity, information theory and combinatorics. Though a primary purpose of the theory is to guide the development of nanotechnology through self-assembly, the theory has wider implications. For example, the investigator will use the theory to address the issue of energy consumption during computation. The theory is quite rich mathematically and the investigator will apply it to questions arising in number theory.","title":"A Theoretical Foundation for Self-Assembly","awardID":"0729170","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7351","name":"THEORETICAL FOUNDATIONS (TF)"}}],"PIcoPI":[348187],"PO":["565157"]},"132267":{"abstract":"The 2007 Fall Workshop in Computational Geometry is being held at the IBM T.J. Watson Research Center in Hawthorne, New York. The workshop is jointly organized by Richard Pollack and Janos Pach of the Courant Institute of NYU, and Jonathan Lenchner of IBM and Polytechnic University, Brooklyn. The aim of the workshop is to bring together researchers from academia and industry, to stimulate collaboration on problems of common interest arising in geometric computing. Holding the workshop at IBM is intended to infuse the field of computational geometry with a set of fresh problems, and problem areas, coming from contemporary industrial applications. Following the tradition of the previous workshops on Computational Geometry, the format of the workshop is informal, extending over two days, with several breaks scheduled for discussions. There are invited speakers and an open problem session to promote a free exchange of questions and research challenges.","title":"2007 Fall Workshop on Computational Geometry","awardID":"0735377","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7351","name":"THEORETICAL FOUNDATIONS (TF)"}}],"PIcoPI":["381203","381205"],"PO":["565157"]},"133598":{"abstract":"Spelman College proposes the ARTSI (Advancing Robotics Technology for Societal Impact) Alliance in collaboration with Florida A&M University, the University of the District of Columbia, Hampton University, Morgan State University, Norfolk State University, Winston-Salem State University, the University of Arkansas-Pine Bluff, Carnegie Mellon University, Georgia Institute of Technology, Brown University, Duke University, the University of Alabama, the University of Washington, and the University of Pittsburgh. Seven of these partners are HBCUs and seven are Carnegie Research I institutions. Their collaboration joins the strengths of HBCUs in conducting outreach and education in a nurturing learning environment with those of the R1's for conducting world class research. The ARTSI Alliance will motivate students to pursue computer science careers by emphasizing the creativity and socially beneficial aspects robotics technology with hands-on projects, curriculum, and media. ARTSI activities will span the academic pipeline from K-12 through the faculty ranks. At the K-12 level, students will be recruited with community outreach using robotics and art, robotics road shows, and a robotics educational film online repository. At the undergraduate level, HBCU students will be exposed to new robotics curriculum, and they will be encouraged to pursue advanced training in graduate school through summer research experiences, collaborative, interdisciplinary robotics projects in the arts and health, instruction in technical film documentation, student virtual film festivals, annual robotics conferences, and instruction in entrepreneurship for computer science. At the faculty level, it will increase the number of HBCU faculty who educate students in robotics and involve students in robotics research by providing faculty mentoring, summer research experiences for underrepresented faculty at R1 robotics labs, robotics summer workshops, and development and dissemination of robotics educational material through a web-based portal. The Alliance will have industry partners, including Seagate, iRobot, Microsoft Research, and Juxtopia, as well as educational partners, including Florida-Georgia Louis Stokes Alliance for Minority Participation and Computer Science Teachers Association.","title":"Collaborative Research: BPC-A: ARTSI: Advancing Robotics for Societal Impact","awardID":"0742101","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7584","name":"ITR-BROADENING PARTICIPATION"}}],"PIcoPI":["542298","496333"],"PO":["561855"]},"131057":{"abstract":"Phenomena observed in nature often have symmetry properties, and so do the systems of differential, integral, and algebraic equations describing them. It has been observed, however, that symmetric equations are often the most challenging for processing by standard symbolic computation algorithms. Group actions provide a mathematical description of symmetries. Invariants, that is the quantities that are unaffected by the group action, play a crucial role in designing such algorithms. Symbolic Group-Invariant Computation involves computing invariants, rewriting a problem in terms of invariants, and processing the problem in terms of invariants. The long term objective is to develop and implement symbolic algorithms that take advantage of the symmetry information, and are general enough to be applicable to a wide range of problems in mathematics, science and engineering, that involve group actions, symmetries and invariants. The investigator integrates her research and educational objectives by involving graduate and senior undergraduate students in the project.<br\/><br\/>The initial focus of this research is on the following three open problems. (1) The investigator works on designing and implementing robust classification algorithms for geometric shapes undergoing various geometric transformations. The problem of computer image recognition provides motivation for this project. The method is based on integral invariants, rather than on the more traditional differential invariants. Development of the underlying theory of integral invariants is a part of this project. (2) The investigator works on the development and implementation of the classification algorithms for polynomials undergoing linear changes of variables. This long-standing open problem is addressed using a novel algebraic formulation of the moving frame method. Besides theoretical interest, such algorithms have application to polynomial solving and to signal processing. (3) The investigator works on the development and implementation of the automated symmetry reduction algorithms for differential equations and variational problems. The goal is to exploit the symmetries in order to obtain either explicit solutions or, at least, vital information about the solution set. The approach is based on the combination of the moving frame method, differential algebra algorithms and homological algebra techniques.","title":"Symbolic Group-Invariant Computation","awardID":"0728801","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7351","name":"THEORETICAL FOUNDATIONS (TF)"}}],"PIcoPI":["550490"],"PO":["550329"]},"125854":{"abstract":"Large scale corpora annotated at the sentence level have played a critical role in natural language research. They have enabled large scale integration of statistical knowledge (derived from the corpora) with linguistic knowledge leading to both technological and scientific applications, such as information extraction, question answering, summarization, and machine translation, among others. This approach is now being extended to the discourse level, thus going beyond the sentence level. Using a resource called the Penn Discourse Treebank (PDTB), a large scale corpus annotated with discourse structure along with the associated semantics, new major experimental work on discourse processing is being carried out, leading to the generation of more coherent summaries and texts, extraction of complex relations in texts, among others, as well as foundational research relevant to language technology. This work is also providing a deeper understanding of the relationship between sentence level and discourse level structures. While pursuing these goals, a variety of tools for making a productive use of the PDTB resource are also being developed. This research program is also coupled with a strong educational program involving training researchers in the PDTB methodology so that similar resources can be developed in other languages substantially divergent from English. This part of the research program has international components including collaboration with research groups in Czech Republic, India, and Finland. The international collaboration is funded by the NSF Office of International Science and Engineering.","title":"RI: Exploiting and Exploring Discourse Connectivity: Deriving New Technology and Knowledge from the Penn Discourse Treebank","awardID":"0705671","effectiveDate":"2007-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"1311","name":"LINGUISTICS"}}],"PIcoPI":["472144",334017],"PO":["565215"]},"133488":{"abstract":"Discriminatively trained conditional models have been applied with great success to language modeling problems for applications such as speech recognition and machine translation (MT), and have been demonstrated to consistently outperform generative modeling approaches. Unfortunately, in contrast to generative approaches, discriminative modeling is an exclusively supervised approach, requiring costly manually annotated training data. Yet there is an important difference between language modeling and other natural language processing (NLP) tasks that are modeled discriminatively. For other NLP tasks, sequences of words are the input, and some hidden structure is the output, e.g., parse trees; but for language modeling tasks, word sequences are the output given some input, such as a source language string being translated. Large text resources that are not paired with an input of interest nevertheless provide examples of well-formed outputs, which would be 'correct' for any inputs that producing it. The novel perspective in this exploratory proposal is recognizing this fundamental difference between typical NLP tasks, where there may be ample inputs but outputs must be manually annotated, from language modeling, where there are ample outputs with no corresponding input. This project explores methods for simulating inputs for observed word sequences, and for using these simulated inputs with a particular MT system to produce a set of alternative (confusable) word sequences to the original observed sequence. These sets of alternative sequences can then be used with conditional\/discriminative estimation techniques, despite the fact that no supervision (manual translation of source strings) was required to produce the training data.","title":"SGER: RI: Text-Based Discriminative Language Modeling","awardID":"0741585","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["467640","456647"],"PO":["565215"]},"131068":{"abstract":"In virtually all areas of computational science and engineering, numerical algorithms grind to a halt when confronted with problems involving real-world systems; chief among the reasons for this shortcoming is the \"tyranny of scales\". Phenomena occurring across large ranges of length and time scales are often critical for the operation of complex systems; unfortunately, few conventional algorithms are efficient and robust enough for computations involving more than a single scale of interest. Innovative algorithms are needed to overcome the difficulties inherent in multiscale modeling and analysis. Computational electromagnetics (CEM) is one area that stands to benefit from the development of efficient multiscale algorithms. While recently developed fast CEM algorithms allow the solution of problems of unprecedented size, these algorithms are designed primarily for geometrically single-scale structures, i.e., they are ineffective when applied to multiscale structures containing both multi- and sub-wavelength size features. <br\/><br\/>This research involves the development of FFT based algorithms for performing efficient multiscale electromagnetic analysis. The investigators are developing multi-scale extensions for state-of-the-art algorithms and incorporating them to CEM simulators. The resulting simulators will permit the numerically rigorous, fast and robust analysis of a variety of challenging electromagnetic problems, which ultimately will advance the understanding and design of complex engineering systems. Through this project, the investigators are improving the CEM research and education infrastructure at The University of Texas at Austin by introducing multiscale algorithmic concepts into graduate and undergraduate courses and by making advanced computing tools available for research. The findings of the study are being disseminated via research seminars at nearby universities in Texas, including those with significant underrepresented minority populations, and via interactive websites with graphical user interfaces.","title":"Fast Fourier Transform Accelerated Multiscale Algorithms for Computational Electromagnetics","awardID":"0728828","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["402081"],"PO":["565157"]},"131079":{"abstract":"PRICE AND ALLOCATION ALGORITHMS FOR MARKETS AND NETWORKED SOCIAL SYSTEMS<br\/><br\/>This project seeks a better understanding of the behavior of decentralized systems such as markets and traffic networks, via effective resource allocation and price determination for these systems.<br\/>This focusses on several problems: equilibrium market price discovery, measurement and control of traffic behavior, auctions for expiring resources, two-sided auctions for ordered goods and bidders (such as web advertisements).<br\/><br\/>The goal of the price discovery work<br\/>is to explain why price changes in market economies might work effectively by showing simple, independent, distributed algorithms that cause prices to converge quickly toward equilibrium values.<br\/>The traffic work<br\/>examines how network performance degrades in the presence of multiple large, selfish network users, and study methods to control this. <br\/>The two-sided auction work<br\/>investigates the design of markets where the buyers have agreed preferences for objects to be sold, and sellers have agreed preferences for who to sell to. The goal is to design real-time price and allocation mechanisms that allow bids from both buyers and sellers, while insuring both profitability and market efficiency.<br\/>The work on auctions for expiring items attempts to assign renewable resources to those bidders (that arrive and depart over time) who can derive the highest value from them. The goal is to design auctions in which it is in the bidders' best interests to bid their true valuation. Auctions with this property are easier both for bidders to figure out their optimal bid, and for auction designers to understand and predict the behavior of bidders.","title":"Price and Allocation Algorithms for Markets and Networked Social Systems","awardID":"0728869","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7932","name":"COMPUT GAME THEORY & ECON"}}],"PIcoPI":["450928"],"PO":["565251"]},"125524":{"abstract":"Tele-immersive environments allow people separated by distance to physically interact and communicate in real time inside a shared 3D virtual environment through the use of large camera networks that enable the capture and reconstruction of 3D images and sound and the subsequent integration of this multimedia data from geographically distributed sites. This project develops and deploys a next generation tele-immersive environment built for the common user who does not have the luxury of expensive supercomputing facilities and dedicated networks. More particularly, the vision of this project is to create a geographically distributed and cost effective tele-immersive environment that facilitates ordinary people performing physical activities in their homes or schools or doctor''s offices or job training facilities under the supervision of a trainer, therapist, or teacher who is not co-located.<br\/><br\/>The broader impact of this project is in facilitating physical interaction and communication of the elderly and persons with disabilities in their homes and work places with relatives, health care providers, and other service providers, in particular whenever they need some interaction during a period of rehabilitation, recovery or training. This project will also examine multimedia distributed communication using common Internet connectivity, which does not require high bandwidth or extremely expensive equipment, and thus may promote wider use of tele-immersive environments.","title":"HCC: Collaborative Research: PHYSNET: Physical Interaction Using the Internet","awardID":"0703756","effectiveDate":"2007-09-01","expirationDate":"2011-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[333202,"311520","473994"],"PO":["565227"]},"126987":{"abstract":"Abstract <br\/>Orthologous genes, or orthologs, are genes in different species <br\/>that have evolved directly from a common ancestral gene. <br\/>Genome-scale assignment of orthologs is a fundamental and <br\/>challenging problem in computational biology, and has a wide range <br\/>of applications in comparative genomics and functional genomics. <br\/>This project continues the development of the parsimony approach <br\/>for assigning orthologs between closely related genomes <br\/>which essentially attempts to transform <br\/>one genome into another by the smallest number of genome rearrangement <br\/>events including reversal, translocation, fusion, and fission, as well as <br\/>gene duplication events. The project addresses three key algorithmic <br\/>problems including (i) signed reversal distance with <br\/>duplicates, (ii) signed transposition distance with duplicates, <br\/>and (iii) minimum common string partition. Efficient solutions to each of <br\/>these problems are combined and incorporated into a software system for <br\/>ortholog assignment, called MSOAR. The project encompasses <br\/>genome-wide analysis of orthologous (and paralogous) relationships on <br\/>the human and mouse genomes to valdiate the approach, and more importantly, <br\/>to address several important evolutionary biological questions including <br\/>the characterization of gains and losses of duplicated genes in the <br\/>two genomes, the elucidation of gene movements in one genome with respect <br\/>to the other genome, and the quantification of different mechanisms of <br\/>gene duplication. <br\/><br\/>Intellectual merit. <br\/><br\/>The parsimony approach presents a novel method for performing genome-wide <br\/>ortholog assignment that takes into account both gene sequences and locations. <br\/>The above algorithmic problems are new in the literature and their solutions <br\/>likely require the introduction of novel algorithm design and analysis <br\/>techniques. The questions regarding gene duplication and quantification of <br\/>the duplication mechanisms in model species are of fundamental importance <br\/>in evolutionary biology. <br\/><br\/>Broader impact. <br\/><br\/>As ortholog assignment is a fundamental problem in comparative genomics and <br\/>has become a routine practice in almost all areas of genomics, MSOAR <br\/>will find itself a wide range of applications in biology and genomics. <br\/>Moreover, the research will provide the training opportunity for two computer <br\/>science graduate students in the interdisciplinary field of computational biology. <br\/><br\/>Information concerning this NSF project will be provided at the website: <br\/>http:\/\/msoar.cs.ucr.edu\/","title":"III-CXT: Collaborative Research: A High-Throughput Approach to the Assignment of Orthologous Genes Based on Genome Rearrangement","awardID":"0710945","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["489430"],"PO":["560586"]},"134016":{"abstract":"This exploratory research focuses on the development of algorithms for integrating spatial and temporal annotations over natural language text, thereby enabling the tracking of entities through space and time. This involves the use of lexical resources and the integration of two existing annotation schemes to create a representation capturing the movement of individuals through spatial and temporal locations. This representation is extracted automatically from documents using symbolic and machine learning methods.<br\/><br\/>This work builds on technologies that have emerged recently that parse the temporal structure of narratives. These techniques use the TimeML markup language to combine rule-based systems, machine learning, and temporal reasoning, and a markup scheme called SpatialML to map relative and absolute locations to geo-coordinates. Data structures from these schemes are then integrated with a representation of event arguments. Using a verb lexicon that captures the meaning of motion verbs, information about the participants involved in events described by such verbs is captured. Finally, these markup representations are mapped onto the appropriate ontological categories within the Standardized Upper Model Ontology (SUMO). <br\/><br\/>The results of this exploratory research are potentially significant, as there has to date been little research done on integrating spatial information extraction with other aspects of text understanding. Furthermore, by providing a mapping of the representations of temporal and spatial annotations over natural language texts to a standardized ontology such as SUMO, we hope to provide interoperability of resources to the community, while also leveraging the work done within the ontology research community.","title":"Inferring Spatio-Temporal Trajectories of Entities from Natural Language Documents","awardID":"0744196","effectiveDate":"2007-09-15","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"1311","name":"LINGUISTICS"}}],"PIcoPI":["562587"],"PO":["565215"]},"125667":{"abstract":"ChunkyStore: Physical Database Design for Next-Generation Databases<br\/><br\/>Traditional databases lay out tables on disk in a row-major format, but recent research has shown that other physical layouts (e.g., using a column-major format) can yield substantial (order-of-magnitude) performance gains in many applications. The broad goal of the ChunkyStore project is to explore this relationship between physical storage layouts and database performance. The primary mechanism for doing this is to partition database tables into \"chunks\" of varying numbers of co-located rows and columns and adaptively adjusting these chunks over time to optimize performance.<br\/><br\/>Specific techniques used to achieve this goal include: (1) investigation of the performance of different \"chunking\" algorithms under different workloads and applications, including scientific data management and data warehousing; (2) building an automatic storage designer that chooses the best chunking of tables based on models of historical workload patterns; (3) studying chunk-based representations and layout of non-tabular data, such as arrays of imagery (which are particularly important in scientific applications); and (4) using the storage designer, array management techniques, and various replication and distribution strategies to deploy a software system with high performance on large data sets.<br\/><br\/>ChunkyStore will substantially improve the performance of database systems and demonstrate that they can be used to manage a variety of scientific data. Education and dissemination efforts will be conducted via research papers, an open source release, several workshops for users, and integration with course projects in the graduate database systems class at MIT. For more information on ChunkyStore, including publications and source code, see http:\/\/db.csail.mit.edu\/chunkystore\/ .","title":"III-COR - ChunkyStore: Physical Database Design for Next-Generation Databases","awardID":"0704424","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["483585","525076"],"PO":["565136"]},"125678":{"abstract":"One way industries harmonize the actions of individual organizations is via formal agreements on process and specification standards. Little is known about the mechanisms that drive this critical coordination so foundational to our national economic competitiveness. New information architecture technologies (e.g., XML) are rapidly replacing decades-old, stable formats (e.g., EDI), transforming the standards process in unforeseen ways. <br\/><br\/>This proposal empirically examines the development, adoption, implementation, and diffusion of industry-wide vertical information systems standards in three diverse industries: automotive, retailing, and mortgage finance. As standards diffusion is a complex interaction between independent organization-level action and collective industry-level action, the three case studies are grounded by data collection with a sample of 60 companies from each industry, which enables comparisons of relative success of a standard's adoption and use as well as its consequences. This is a unique multi-level approach, investigating the impact of collective action dynamics on specific IT design features. <br\/><br\/>Broader impacts: Improved electronic interorganizational collaboration has enormous potential to reduce transaction costs and develop more competitive industries. Such benefits can lead to lower prices for consumers. Moreover, the greater use of open Internet standards promises new opportunities for smaller organizations that were not able to enjoy the full benefits of earlier EDI approaches. The research will also produce materials for the education of practitioners and will advance the state of knowledge in several fields, including information systems and technology, management, industrial engineering, economics, sociology, and social informatics.","title":"Collaborative Research: Interorganizational Information System Integration Through Industry-wide Standardization: Technical Design Choices and Collective Action Dilemmas","awardID":"0704629","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["562605"],"PO":["564456"]},"137789":{"abstract":"ABSTRACT<br\/><br\/>Directorate for Computer and Information Science and Engineering (CISE)<br\/>Division Computer and Network Systems (CNS)<br\/>Science of Design (SoD) Program<br\/><br\/>Proposal Number: 0613971<br\/>P\/I: Sherif Abdelwahed<br\/>PI's Department: Electrical Engineering - Computer Science<br\/>Institution: Vanderbilt University<br\/>Award: $ 199,866<br\/><br\/>Title: \"SoD-TEAM: Design for Adaptivity and Reliable Operation of Software Intensive Systems\"<br\/><br\/>This project addresses design techniques for Software-Intensive Systems (SIS). The scientific contribution of the project is the conversion of a significant segment of the design process of software-intensive systems, typically handled manually in an ad-hoc manner, into a systematic semi-automated process based on mathematical models and control-theoretic techniques. The model-based techniques and tools will simplify the development of a large class of distributed real-time and embedded software-intensive system, which will enable a major improvement in the ability to design and implement complex systems that will operate in uncertain environments in a cost-effective manner. The science and technology developed by this project will inform designers about how to build more effective and reliable systems. Along with the new design methodology proposed, the PIs will develop a set of tools that facilitate the design, analysis, and verification tasks, making it easier to design and analyze systems, while offering a higher degree of confidence in assured operations. In addition to the basic research component of the project, there is an educational component that will contribute to the development of practitioners in the field. Students at this institution are introduced to systematic methods for embedded system design and implementation using modeling, analysis, and verification tools developed by the R&D community. To provide students with more hands on experiences, project-related graduate-level courses will be developed that address issues in software-intensive system design and implementation on realistic test beds.<br\/><br\/><br\/>Program Manager: Anita J. La Salle<br\/>Date: July 11, 2006","title":"SoD-TEAM: Design for Adaptivity and Reliable Operation of Software Intensive Systems","awardID":"0804230","effectiveDate":"2007-09-01","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7372","name":"ITR-SCIENCE OF DESIGN"}}],"PIcoPI":["491916"],"PO":["557609"]},"128626":{"abstract":"This research will create new mathematical and numerical methods to study the dynamics of large proteins found in touch sensory neurons of C. elegans, a worm with one of the simplest touch sensory nervous system. The main issues are bridging the gap between relevant biological time scales, in this case the opening and closing of ion channels, and time scales accessible to direct molecular dynamics simulations which are much shorter. A step in this direction will be the creation of a new time and space adaptive scheme (AVI and HiGrid) which accelerates the sampling of the different protein conformations accessible at a given temperature. In addition, techniques (the string method and the ABF algorithm) to explore transition pathways between stable conformations of the system will be developed. The novelty of this approach is that the pathways are computed in terms of many collective variables instead of the Cartesian coordinates of the atoms as is usually done. This leads to greater robustness and physically more relevant pathways.<br\/><br\/>The ability to sense touch depends on nanometer sized ion channels located in the membrane of sensory neurons. When force is exerted in the skin these channels open to let a flow of ions go in or out of the cell, a phenomenon called gating. These nano-machines are part of a complex apparatus which converts mechanical force into electric signals and transports information from the skin to neurons. By bringing together expertise in biology, high performance computing and mathematics, the investigators will produce atomically accurate models of the gating mechanism in the only metazoan mechanotransduction channel known to date.","title":"Collaborative Research: Multiscale Methods for the Molecular Simulation of Sensory Mechanotransduction Channels","awardID":"0718349","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7334","name":"MATHEMATICAL BIOLOGY"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0709","name":"Division of BIOENGINEERING & ENVIRON SYSTE","abbr":"BES"},"pgm":{"id":"7446","name":"MATH PRIORITY SOLICITATION"}}],"PIcoPI":["521209","541394"],"PO":["230845"]},"127427":{"abstract":"This project will examine whether federal agency rulemaking can be improved with two innovations: a) multi-level deliberation (MLD), in which people discuss rulemakings in small groups that then select members to represent the group in a higher-level group and b) the combination of language technologies into an artificial discussion facilitation agent (DiFA). The project poses computer science challenges of combining several Natural Language Processing technologies (primarily Interactive QA, Dialogue Analysis, and Summarization) into a viable facilitation agent and in applying these technologies in an eclectic, multi-user discussion environment. We expect advances to be made within each component technology. For example, we hope to increase the utility of Dialogue Act tagging across applications and domains by using a set of general discussion tags for tracking and summarizing threads of discussion by combining dialogue structure and content analysis. We will also investigate how general our Question Answer approaches are. The social science herein breaks new ground in the nascent fields of e-rulemaking and democratic deliberation research. The project will advance research on measuring the quality of deliberation and the effects of deliberation and DiFA on individuals and communities. Research will involve four rulemaking experiments. The first three are subsets of the final one. The final 3X2 experiment crosses MLD, non-MLD deliberation, and non-deliberation with the presence or absence of DiFA. The success of the various conditions of these experiments will be measured using a multi-trait, multi-method approach that will include survey and focus group measures of agency official and participant perceptions and evaluations, a content analysis measure of the cognitive sophistication of rulemaking comments, both human-coded and automated content analyses of the quality of deliberation, measures of the impact of the deliberations on participants (knowledge, trust, citizenship), DiFA usage patterns, and continued participation in our user community.<br\/><br\/>The federal agency rulemaking comment process represents an important potential avenues by which the American public can affect how it is governed. Such comments can make agency officials aware of likely adverse effects of the proposed rules. Unfortunately, the current rulemaking comment process faces a number of social and organizational problems including poorly informed and distrustful participants, lack of dialog among participants that could sharpen their reasoning, and problems of scale such as the large number of comments generated. Researchers believe that most rulemaking comments are low in quality or redundant?a product of form letters used by public interest groups. Rulemaking is not a plebiscite, but an effort to identify reasons to accept or modify proposed rules. This project will seek to address the problems of existing rulemaking by immersing rulemaking participants in small discussion groups that will be assisted by discussion facilitation software. The software will use cutting-edge technologies to help answer questions, summarize discussion, and provide feedback and suggestions on their discussion. Discussion itself will be organized into a hierarchy of representative groups to help the best ideas spread among participants and rise to the top. The value of the technology and of the deliberation methods will be thoroughly tested using experimental methods and data collected via surveys, focus groups, and by the software. The project will advance research in several areas. In computer science, it will seek to apply natural language technologies in a more general setting than before. The technology created could have broad application. It will also combine several technologies into a discussion facilitator that may be more widely used. The project will also advance research on democratic deliberation by improving and testing measures of deliberative quality and by adding to knowledge of how deliberation affects citizens.","title":"Collaborative Research: Deliberative E-Rulemaking Decision Facilitation Project (DeER)","awardID":"0713149","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["343459",337938],"PO":["564456"]},"127438":{"abstract":"Computational and neurophysiological investigation of robust visual inference <br\/><br\/>Tai Sing Lee, Carnegie Mellon University <br\/><br\/>This project is a multi-disciplinary investigation of the computational principles and neural mechanisms underlying robust visual inference in primate systems and the exploitation of these principles to develop new statistics-based computer vision approaches for inferring 3D scene structures in visual images. An image of a real 3D scene is highly ambiguous and difficult to interpret because it could be generated by many possible combinations of the different physical causes, such as lighting, texture and shapes. Classical approaches in computer vision attempt 3D scene inference by modeling these image formation processes with simplified assumptions and then inverting these models. The PI proposes a statistical approach to better solve these problems by learning and exploiting the statistical priors on 3D shapes in the natural environment and their correlational structures with 2D images. The PI plans to develop efficient Bayesian belief propagation algorithms within the framework of probabilistic graphical models that allow flexible incorporation of rich statistical scene priors. The computational work will guide his investigation of the neural encoding of scene priors and the mechanisms of probabilistic inference in the primate early visual cortex using advanced electrophysiological techniques. A better understanding of the neural representations of priors and mechanisms of inference will represent a fundamental scientific advance in neuroscience and will also provide new insights for improving the statistics-based computational approaches for visual inference.","title":"Computational and Neurophysiological Investigation of Robust Visual Inference","awardID":"0713206","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0809","name":"Division of INTEGRATIVE ORGANISMAL SYS","abbr":"IOS"},"pgm":{"id":"7713","name":"ACTIVATION"}}],"PIcoPI":["550942"],"PO":["564318"]},"129506":{"abstract":"The focus of this project is on optimal resource allocation and control in collaborative cognitive radio networks (CRNs). Through opportunistic access to the available spectrum, CRNs aim at improving the utilization of network resources by achieving higher spatial reuse, programmable connectivity, and increased network availability. The research agenda includes centralized analytical formulations that aim at optimizing the operation of the bottom three layers as well as distributed routing and medium access protocols that implement the outcomes of such optimization. Joint optimization of spectrum, transmission powers, and rates for CR communications will be considered in the presence of several primary (spectrum-licensed) radio networks (PRNs). <br\/><br\/>No feedback from the PRNs will be assumed. Several formulations will be studied, which differ in the assumptions made on the channel dynamics (indirectly, user mobility), optimization window (packet vs. flow time scale), and availability or otherwise of power masks. Besides one-hop optimizations, the project will also consider multi-channel, multi-path optimizations at the packet and the flow time scales. The optimization results will then be integrated into the design of distributed channel access and path discovery\/maintenance protocols for opportunistic CRNs. Depending on the frequency bands of interest, fixed power masks on CR transmissions may or may not be available. Protocols will be developed for both cases. In the absence of a fixed power mask, statistical modeling of PR interference will be conducted and used in the design of a MAC protocol that supports a probabilistic guarantee on the outage rate of PR receptions. The treatment will extend to both connectionless and connection-oriented applications. The cross-disciplinary nature of this project is expected to have a profound impact on many wireless technologies used in both civilian and military applications, including sensor networks, mesh networks, military radios, and wireless LANs. The optimization framework provides a general methodology that can significantly improve the performance, connectivity, and inter-operability of resource-constrained wireless networks in general.","title":"NeTS-WN: Cross-Layer Optimizations and Adaptive Protocols for Opportunistic and Collaborative Cognitive Radio Networks","awardID":"0721935","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["540507","560117"],"PO":["564993"]},"127449":{"abstract":"This project seeks to provide automated methods for analyzing sky surveys to detect extra-solar planets via anomaly and novelty detection methods. Extremely large astronomical synoptic surveys will soon monitor much of the sky regularly, detecting vast numbers of interesting, variable astronomical objects. The objective of this proposal is to develop the tools necessary to exploit these new data in order advance discovery. The proposed work will explore the scientific analysis and modeling of massive datasets of light-curves (66 million light-curves now available, growing to 100 billion in a decade) from a broad range of perspectives. The unique complications posed by the data in this domain will drive research for data mining techniques to allow these analyses. A comprehensive framework of models and their relationships with the data will be developed that readily separates two kinds of interesting objects: (1) Rare objects that reveal special insights about the models; and (2) Potential truly novel objects that cannot be described by the models. New computationally tractable time series algorithms for novelty detection will be developed for these purposes.","title":"SEI: Collaborative Research: Discovering Unexpected Planets and Other Astronomical Oddities","awardID":"0713259","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["365889"],"PO":["565136"]},"134930":{"abstract":"A frontier for scientific collaboration is computer-supported cooperative work (CSCW), often codified and supported in collaboratories: computing infrastructures providing remote access to scientists, tools, databases, and instruments. A central aspect of and reason for scientific collaboration is creativity but we do not yet have a clear understanding of the relationship between collaboration and creativity in science. <br\/><br\/>This project will contribute to the basic science of creativity and to the empirical science of measuring creativity. Studies and theories of creativity in human computer interaction (HCI) contexts, and more specifically in real-world CSCW contexts, will advance this traditional area in psychology, which has tended to focus on static, and often unrealistic task situations. Second, this project will develop reusable metrics and measures of creativity in distributed scientific collaboration.<br\/><br\/>The Next Generation CiteSeer collaboratory (supported under a concurrent NSF Computing Research Infrastructure grant 0454052) will be used to identify and generalize requirements to support creative scientific collaboration in the context of distributed settings; develop and validate a multi-faceted framework to evaluate creativity as an embedded and long-term activity; codify and abstract critical incidents and breakdowns that occur during the longitudinal process of creativity.<br\/><br\/>Broader impacts<br\/>The goal of this project is to enhance the quality of creative collaborative interactions in the Next Generation CiteSeer collaboratory. Two obvious trends in the research practices of the CISE community are its use of Internet-based collaboration (primary through email) and its use of digital resources, such as the ACM Digital Library. The Next Generation CiteSeer project brings these two trends together in a collaboratory environment for CiteSeer-based collaboration. This project will help to enhance our understanding of how this infrastructure can facilitate creativity; findings that may transfer well to similar efforts. <br\/><br\/>CiteSeer has been a valuable research tool for the CISE community. Log analysis of CiteSeer usage shows that it is well used by Hispanic Serving Institutions and by Historically Black Colleges and Universities. These are institutions that for the most part lack adequate access to the scholarly literature. The project will provide additional service learning opportunities through classes and independent study projects for students, both undergraduate and graduate, to integrate their formal education with its practical application toward a real-world system such as CiteSeer.","title":"Sger: Investigating Requirements For Supporting Scientific Creativity In Collaboratories","awardID":"0749172","effectiveDate":"2007-09-15","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["549541",358483],"PO":["388678"]},"132884":{"abstract":"From its inception in 1987 as a part of NSF's overall inventory of high speed computing and communications infrastructure development, the NSFNET program was a pioneering force in academic computing infrastructure development and in the enhancement of research efforts through advanced network services. The NSFNET backbone, in its support of the broader set of NSFNET programs, linked scientists and educators on university campuses nationwide to each other and to their counterparts in universities, laboratories, government agencies, and research centers throughout the world. By design, NSFNET backbone made high speed networking available to national supercomputer centers and to inter-linked regional networks, which in turn worked to extend network availability to other research and educational organizations. Previously, only specific communities in computer science had limited access to networks such as CSNET, BITNET, and ARPANET, so the introduction of the NSFNET backbone represented a significant development in creating a unified and more comprehensive network infrastructure.<br\/><br\/>By combining high-speed networking and connections between the supercomputing centers and regional networks, NSF created a \"network of networks\" that served as the focal point of nationwide networking during a critical period of development and that formed the foundation of an immediate precursor to today's Internet. The project has had a lasting and significant impact over the intervening twenty years on the technology of network science, the revolution in communication, the fostering of global and multidisciplinary scientific interaction, and the practice of public and private partnership. To recognize this impact, Internet2 and Merit Network, Inc. propose a workshop to celebrate NSFNET's history and impact and to discuss and anticipate future applications and infrastructure development. The workshop is timed to mark the twentieth anniversary of the cooperative agreement, initiated in 1987, that advanced the NSFNET backbone to a truly high speed network. As one of the most significant parts of the Internet's development, the history and celebration of NSFNET represents a tool to help understand the future while learning from the past.<br\/><br\/>The intellectual merit of this workshop lies in its contributions to the advancement of knowledge in advanced networking; reflection on historic perspectives; impact on science, research, education, and industry; international implications; and consideration of the future. Because the workshop will include pioneers in advanced networking development and because its proceedings will be widely available, it is likely to have broad impact in education, and in enhancing the long-term study of network architecture and management. By gathering key individuals together to reflect on this key history and to determine how it can inform the future, a greater understanding of the development of the Internet and the role of advanced networking in society will be realized beyond the higher education community. The archived information will provide a resource for a broad spectrum of people, including students, scholars, and the public at large and will help illustrate the role of federally funded research in national economic development. The project has an extensive educational component including the participation of a group of K-12 students at the meeting and attending remotely from eight mega-conference centers and via real-time webcast.","title":"NSFNET: The Partnership that Changed the World","awardID":"0738738","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["427208"],"PO":["565090"]},"132785":{"abstract":"The NSF Workshop on Nanoelectronics, Nanophotonics and Plasmonics will address the major challenges in developing devices, logical gates, and algorithms to address the complex needs in computing and communication. This workshop will consist of sessions in which the invited experts and representatives of government laboratories and funding agencies will make presentations on their work and their vision of the future research directions. Current PIs funded under EMT program will review their work in the areas of nanoelectronics, nanophotonics and plasmonics. A panel discussion will follow with the objective to formulate a broad program of research on nanoelectronics, nanophotonics, and plasmonics. The participants, experts in these disparate field, will engage in discussions on potential areas where their research can lead to the possible establishment of new research fields that can yield novel solutions to the needs of the computing and informatics processing community. The eventual product of this two day discussions and brain storming will be a comprehensive report to be presented to the NSF on the current needs, challenges, and directions deemed as urgent and important by experts in these specific areas.","title":"WORKSHOP: NSF Workshop on Nanoelectronics, Nanophotonics and Plasmonics.","awardID":"0738246","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["520204","262203"],"PO":["565223"]},"124942":{"abstract":"Computational \"\"proof assistants,\"\" which allow users to construct axiomatic proofs of formally specified assertions, are currently used for two purposes: first, to verify ordinary mathematical proofs, and second, to verify that (descriptions of) hardware and software meet design specifications. This project will develop logical and computational methods to support both types of activities. Specific components of the project include: the development of formal libraries to support proofs in number theory and discrete geometry; the extraction of verification conditions from software component specifications and implementations in an assertive programming language known as Resolve; a classification of the types of inferences that arise in both domains; the development of logical methods for verifying these inferences automatically; and the development of educational materials and software that will make it possible to integrate these methods into undergraduate and graduate curricula in computer science and mathematics.<br\/><br\/>As mathematical proofs become more and more intricate, and now often rely on extensive computation, it is becoming increasingly difficult to verify that they are correct. Similarly, as hardware and software systems become more and more complex, it is becoming increasingly difficult to verify that they meet their design specifications. Doing so is especially important when resources, lives, and security depend on their correct behavior. This collaboration between mathematical logicians and computer scientists will develop methods to make it possible to verify that such mathematical and computational claims are valid, and that the arguments supporting them are free of errors. The project will also develop means of training the next generation of computer scientists and mathematicians to use these methods.","title":"Collaborative Research: Logical Support for Formal Verification","awardID":"0701260","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["508443","508444"],"PO":["565280"]},"133654":{"abstract":"Game As Life \/ Life As Game (GALLAG) is a research agenda exploring the boundary of physical and virtual lives. Gaming is becoming an increasing popular phenomenon that is having a profound effect on individuals and society. The GALLAG system will use sensors as the interface between digital and physical life. These sensors will detect the everyday physical activities that a person engages in. These activities will then be linked to games and game scenarios. Sensing aspects of individuals'' emotions and their interactions will be used, first, as a way to measure the impact of the GALLAG system and its scenarios on participants and, second, as an information channel to create a real-time feedback that enables the system to attend to and tailor itself to how participants'' emotional states. GALLAG will use ubiquitous computing and personally tailored game scenarios to integrate activities across the virtual and physical domains, holistically throughout everyday life, focusing on: meditation, sleep, and exercise. Influences and activities in the game scenarios will affect real life and vice versa influences and activities in life will affect the game. It is not known how people will respond to the GALLAG experience, if these synergies will be sufficiently engaging to users or if there are more fundamental barriers to the creation of long-term hybrid virtual\/physical experience that must be addressed to make them compelling and beneficial. To address these unknowns, several methods of experience and behavioral assessment, and environmental, contextual and physiological sensors will be used in conjunction with participatory design approaches that include end-user-programming, and iterative design and testing. The GALLAG approach can be used to become quickly aware of other people''s lives, as well. The status of another game player (perhaps a family member) can be observed through their profile and information. For example, elderly parent''s activities - even if the parents are not involved in the gaming activities - might be represented in a readily interpretable manner so that their children can better understand their wellbeing. This elderly parent might not know how to explain tell her doctor that she has been feeling fatigued or ill. GALLAG may enable her physician to better understand her condition by reviewing with her brief game-clips of her activities. It is not known how people will respond to the GALLAG experience, if these synergies will be sufficiently engaging to participants or if there are more fundamental barriers to the creation of long-term hybrid virtual\/physical experience that must be addressed to make them compelling and beneficial. As gaming becomes more of an important part of life, new opportunities arise to use emerging technologies to benefit individuals in their daily activities and life long aspirations. This agenda seeks to empower users to create their own synergies between their on-line activities and to help them achieve their personal real world aspirations.<br\/><br\/>Gaming is becoming an increasing popular phenomenon that is having a profound effect on individuals and society. Further, online role-playing games and interactive gaming interfaces are becoming more social and starting to engage participants in physical activity. This exploratory research has the potential to further extend the emerging avant garde ''real life games'' that are coordinated by digital means to further blur digital-physical-social barriers. Specifically, GALLAG seeks to study the coordination of digital life with real life to link real life behaviors with no immediate tangible reward with more immediate intrinsic reward in the virtual environments. An example of the potential of this strategy is the diabetics support software called DiaBetNet (http:\/\/www.dimagi.com\/case-studies-diabetnet.php). The game leads the child to a better understanding of diabetes and thereby increases his or her ownership of long-term health. As gaming becomes more of an important part of life, fantastic opportunities arise to use emerging technologies to benefit individuals in their daily activities and life long aspirations. This agenda seeks to empower users to create their own synergies between their on-line activities and to help them achieve their personal real world aspirations. Ultimately work from this GALLAG project may lead to ''Life Long Games'' that provide persistent, supportive, and actualizing experiences.","title":"Game As Life - Life As Game","awardID":"0742305","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["552861"],"PO":["564456"]},"135601":{"abstract":"The Global Environment for Network Innovation (GENI) is an experimental facility intended to support research in a wide variety of areas including communications, networking, distributed systems, cyber-security, networked services and networked applications. The goal of GENI is to enable researchers to experiment with radical network designs in a way that is far more realistic than any alternative available today. <br\/><br\/>The GENI Engineering Conference will be the GPO's regular open working meeting to support design, planning, construction and operation of the GENI facility. It is the place where researchers, developers, industrial and international partners and the GENI Project Office will regularly meet to advance GENI facility planning and prototyping, as well as to engage in interdisciplinary conversation and mutual education. <br\/><br\/>GENI will be a vital resource for communications research in coming years. Results from experiments on GENI are expected to enable new types of research, reveal new ideas and insights in communications, influence the design of products, and create new opportunities for industry. The GENI Engineering Conference has a central role to play in ensuring that this broader impact occurs. The conference serves as a place where industry, new researchers and students, researchers from diverse backgrounds, as well as the established communications research community can come together to discuss visions of the future of research, how we will achieve that future, and how we will carry those visions and achievements into the wider world. The inaugural meeting supported by this project will express this vision by offering extensive travel grants to make the community richer in its diversity.","title":"Support for First GENI Engineering Conference","awardID":"0751954","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}}],"PIcoPI":["521729"],"PO":["495796"]},"131135":{"abstract":"This project addresses some fundamental scientific questions in the areas of authenticity and trust for digital media. Such issues arise in applications such as forgery detection and characterization, digital fingerprinting for content protection, and transaction tracking. This project develops an analytical framework for solving challenging problems based upon fundamental principles and modern methods of statistical inference; develops novel algorithms; and assesses the reliability of the receiver's decisions.<br\/><br\/>The educational component of this project includes a summer research program for high school students and undergraduates that teaches them about the ethics and technology surrounding information digital rights management.<br\/><br\/>The research component of the project focuses on the following two thrusts. First, desynchronization-resilient authentication, exploiting recent advances in Bayesian recursive filtering and inference using graphical models. Second, blind fingerprinting (or traitor tracing), developing theory and codes for problems where the original signal is not available to the receiver.","title":"Statistical Inference Methods and Confidence Bounds for Signal Authentication and Traitor Tracing","awardID":"0729061","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["518625","475205","475207"],"PO":["564898"]},"133797":{"abstract":"The goal of this proposed research is to address the current problem that the deployment of Information and Communications Technologies (ICT) in the developing world sometimes fails due to problems with the usability and utility of those systems. This research hypothesizes that Human Computer Interaction (HCI) has much to offer ICT for development (ICT4D), but the methods and techniques also require customization to address the unique challenges of the developing world. The result of this proposed research will be an explanation of the methods and techniques of Human-Computer Interaction for Development (HCI4D), highlighting similarities and differences to HCI. It will do so through establishing a relationship with a partner institution in Africa, identified through a survey of tertiary Computing education in Africa. Joint with this institution, an HCI4D project intervention will be identified.<br\/><br\/>First and foremost this proposed research seeks to begin the process of creating an awareness of and a research agenda around the methods necessary to conduct HCI4D. Successful HCI4D interventions have the possibility of broadening the global Information Society to include those least served by ICTs. By making it possible for more people to interact with computers, this proposed research seeks to change technologically mediated human-human interaction, bringing an increasingly diverse population into the global society?supporting an increased range of interactions and cultures online. By examining the methods, and identifying differences between HCI4D and HCI, this proposed research also supports introspection of the values and assumptions held in techniques generated by and in use in the developed world.<br\/><br\/>This research expands the discipline of HCI into a new domain, the developing world. Results have much to contribute to the understanding of the values and assumptions built into existing methods. The effort will provide new and unusual examples of HCI research, those conducted in the developing world, not typically the source of examples for HCI, which will broaden student education.","title":"HCC-SGER Project Description: HCI4D, Understanding Human Centered Design in the Developing World","awardID":"0742939","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["450731"],"PO":["388678"]},"133203":{"abstract":"Research on effectively searching scientific workflows is limited. Existing work assumes that once workflow data is stored in a database, standard query languages can be directly used to access the data. Several challenges remain to be addressed in order to provide effective access to scientific workflows. First, workflows have unique structure, and a user query should be able to specify the structure of target workflows. Second, search requirements can be diverse according to user needs. Sometimes a scientific user knows exactly what s\/he is looking for, and prefers to issue a sophisticated structured query over complex workflow data in order to obtain precise search results. In other cases, scientists do not have a clear idea of what they are searching for, and\/or enjoy a simple search mechanism without needing to understand complex data schemas and query languages. The work is planned to enable semantic keyword search on scientific workflows, where relevant search results<br\/>will be intelligently inferred and returned in ranked order and to design a user-friendly and expressive query language by which users can express precise and sophisticated queries to retrieve scientific workflows. Common types of searches will be used to identify the logical operators that are essential to express these searches. Various indexing and labeling schemes will be designed to speed up processing. The proposed project will benefit scientists by enabling effective and efficient access to scientific workflows in a repository, so that they can reuse existing workflow designs, compare and analyze several workflows, and design new workflows guided by existing ones. By providing effective access to a scientific workflow repository, this research facilitates data sharing and collaborations among teams. The proposed project will not only make significant contributions to fundamental techniques for managing scientific workflows, but also deliver a generic and scalable system for scientific users to search workflows, thereby benefiting scientific collaboration. There are also significant educational and training objectives.","title":"SGER: Enabling Effective Access to Scientific Workflows","awardID":"0740129","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["233230"],"PO":["565136"]},"131036":{"abstract":"The arrival of the Internet and modern handheld communication devices is ushering in a remarkable revolution in the consumption of digital video technologies and products, and a resulting sea change in the nature and needs of the global information infrastructure. Digital video acquisition, networking, storage and display devices have advanced to an extraordinary degree of sophistication, leading to the rapid rise of many popular and globally deployed networked applications as Internet Video, Interactive Video on Demand (VoD), Video Telepresence, Video Phones, PDAs and other Wireless Video devices, Video Surveillance, HDTV, Digital Cinema etc. Monitoring and controlling the quality of broadcast video streams is essential towards improving quality of service (QoS). Yet, progress in methods for performing reliable video quality analysis has remained quite limited. <br\/><br\/>The research proposed here will create powerful Video Quality Assessment (VQA) algorithms that correlate highly with visual perception. The expected benefits of the proposed research are far-reaching. Methods for improving video Quality of Service (QoS) are a major emphasis of the world-wide cable, semiconductor, cell phone, and networking industries and considerable efforts are being expended on this topic. Successful VQA algorithms are likely to be deployed throughout the global wireline and wireless communication networks as well as in video acquisition and display devices. Breakthrough theories of video quality will enable the design of algorithms for video processing based on perceptual criteria - a decades-old holy grail of imaging science.","title":"Quality Assessment of Natural Videos","awardID":"0728748","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["485855"],"PO":["564898"]},"133104":{"abstract":"ABSTRACT<br\/>0739623<br\/>Marios C. Papaefthymiou<br\/>University of Michigan<br\/><br\/>Intellectual Merit<br\/>The continuing scaling of semiconductor process technology brings about new challenges in the design<br\/>of VLSI systems, while at the same time motivating new approaches for addressing them. Power density in<br\/>high-end integrated systems has already reached performance-limiting levels. Increased device variability<br\/>results in greater delay uncertainty, dictating the use of larger design margins and further limiting performance. Yet, silicon per device continues to decrease at exponential rates, enabling novel uses of silicon<br\/>area. This research project will investigate next-generation design technologies for the realization of nanoscale VLSI systems in silicon. Specifically, this project will focus on the exploration of so-called charge recovery design technologies that enable operation at new levels of power-efficiency while reducing uncertainty due to device variability. In conventional VLSI design, capacitors are switched abruptly between supply and ground, experiencing high peak currents and dissipating all their stored energy as heat across resistive devices. Furthermore, device variability leads to significant uncertainty in the clock arrival times of conventional distribution networks with buffers. In contrast to conventional integrated systems, charge-recovery designs switch capacitors gradually, maintaining low peak currents and returning any undissipated energy back to the power supply. Therefore, charge-recovery designs can potentially lead to substantial reductions in switching power and gate leakage. Moreover, since they rely on buffer-less resonant clock distribution networks, charge-recovery designs are also expected to yield substantial reductions in clock delay uncertainty. The significant potential of charge recovery has so far remained untapped, as it represents a departure from established design practices. The main objective of this project is to explore and assess the potential of charge-recovery technologies, including circuitry, design methodologies, and computing architectures for realizing nanoscale silicon-based VLSI systems with unprecedented levels of power efficiency and performance. <br\/>Broader Impacts<br\/>The proposed research is expected to have a significant impact on the realization of next-generation VLSI<br\/>systems, promoting discovery, teaching, and learning in novel design technologies that address key issues in<br\/>nanoscale process nodes. Broader outcomes of the proposed effort include the integration of research activities<br\/>into graduate-level courses, the development of lectures and projects for advanced undergraduate-level<br\/>courses, as well as the direct involvement of electrical engineering and computer science majors through<br\/>senior-level design projects. Consistent with the PI's proven record in promoting broad participation, the<br\/>proposed research and education activities will include participants from underrepresented groups.<br\/>A1","title":"SGER: Design Technologies for Nanoscale VLSI","awardID":"0739623","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["550681"],"PO":["562984"]},"125844":{"abstract":"This project addresses problems central to the design of decision-making strategies that enable computer agents to work effectively with people in heterogeneous groups that interact in carrying out complex activities. These mixed networks of people and systems arise in a wide variety of real-world applications as well as in virtual reality and simulation systems used for training. They occur in settings in which computer systems support people who are working together, those in which they act as proxies for individual people, and those in which groups of agents act autonomously (but alongside people) to carry out constituent tasks for which they are responsible. Despite mixed networks being wide spread, the design of agents that can operate in such settings has received less attention than the design of agents for multi-agent systems comprising only computer agents.<br\/><br\/>The inclusion of people in mixed networks presents novel problems for the design of autonomous agent decision-making mechanisms. This proposal focuses on the following three of these challenges, which have not been investigated sufficiently in prior work and which agent designers must address to construct systems able to work well with their human partners in mixed networks: (1) information exchange policies for agent competence and past behavior; (2) design of interruption management mechanisms for collaborative interactions; and, (3) learning and incorporation of models of social factors and organizational structures into decision-making mechanisms.","title":"HCC: Collaborative Research: Information Exchange and Social Factors in Human-Computer-Teamwork Decision Making","awardID":"0705587","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[333993],"PO":["565227"]},"134204":{"abstract":"Field programmable gate arrays (FPGAs) are capable of speedups ranging from the 10s to 1,000s over traditional general-purpose processors (CPUs) on frequently executed code segments. However, such speedups occur only when the capability of the FPGA is fully utilized. It is becoming increasingly apparent that the bandwidth into and out of the FPGA can quickly become a limiting factor in its utilization. It is possible to design and map a large circuit on an FPGA but not have the bandwidth to keep it busy. The proposed project explores techniques for partitioning code implemented either in hardware on FPGAs or as software running on CPUs of a multicore multiprocessor system that enable efficient use of parallel computing resources. Three specific models of CPU\/FPGA acceleration are explored that span a wide range of computing platforms: from embedded systems at the low end to high-performance multiprocessor systems at the high end. These models, along with applications suitable for the intended platforms, are used to identify and quantify performance parameters of CPU\/FPGA interaction that drive the proposed partitioning techniques. This exploratory research may pave they way for the design, implementation and evaluation of automated hardware\/software partitioning techniques for CPU\/FPGA multicore multiprocessor systems envisioned to be pervasive across the computing spectrum in the near future.","title":"SGER: Hardward\/Software Partitioning for Multiprocessor and Multicore Acceleration","awardID":"0745490","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["518640"],"PO":["550859"]},"134446":{"abstract":"Both the metagenomics and the biodiversity communities face a major challenge: capturing detailed data on the environmental and the ecological context from which samples are drawn. Without these 'metadata' (data about the primary, biological data), the value of the primary data is greatly diminished. To capture these different types of metadata, biologists\/ecologists need tools that allow them to survey the literature in the relevant areas, identify the key concepts and vocabulary in the articles, and extract data and metadata into an appropriate representation for further processing, querying and exchange. The goal of this research is to create a proof-of-concept demonstration of interactive tools for the capture and curation of metadata, working in close collaboration with the metagenomics and biodiversity communities to understand their requirements. The text mining community has demonstrated significant progress: results from the recent BioCreative workshop (April 2007) show that text mining tools can identify mentions of key biological entities in running text and map these mentions to associated unique identifiers (e.g., Entrez Gene identifiers) at 80-90% accuracy. Much of this progress has been driven by a close association between curators of mature biological databases and the text mining community. Groups such as GOA, MINT, IntAct, Flybase, MGI, SGD, Wormbase have expert curators, a documented curation process, and they produce large quantities of expert curated data. These resources have provided good testbeds for evaluating new tools against human curated \"gold standard\" test sets. The question now is how to apply this progress to create tools to support curators in an interactive process for extraction and mapping of critical information, such as gene\/protein identifiers, geospatial information, or habitat information. These tools will support emerging communities, such as the metagenomics and biodiversity communities; they also can be put into the hands of both ontology builders to speed design of ontologies, and authors for capture of metadata at the source, rather than relying on post-publication expert curation. This work will have impact in four distinct areas: first, it will support the metagenomics and biodiversity communities, to speed capture of metadata; second, it will provide new challenges to the text mining community, to integrate tools into an interactive pipeline to support real curation activities; furthermore, such interactive tools can have major impact on the ability to create new ontologies and controlled vocabularies, through exploration of concepts in the literature; and finally, such tools can provide a prototype for author-driven annotation, to support capture and encode metadata at the source, as a kind of \"automated spell-checker\" for annotations.","title":"SGER: Mining Metadata for Metagenomics","awardID":"0746650","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["389934"],"PO":["565136"]},"131058":{"abstract":"Recent research on multiple-input multiple-output (MIMO) communications has shown that deploying arrays at the transmitter and receiver can dramatically improve the capacity of wireless multipath channels. Since the physical size of a transceiver is often limited, increasing the number of array elements often requires closer inter-element spacing and leads to signal correlation and mutual coupling. Coupling can profoundly impact the received power, diversity and system capacity. Moreover, this impact depends essentially on aspects of the transceiver design, such as antenna matching and the dominant sources of noise.<br\/><br\/> <br\/><br\/>Intellectual Merit: This project seeks to develop a systems-level perspective on the design of compact array transceivers for wireless communications. The aim is to understand how antennas, matching networks, amplifiers and communications algorithms interact to determine overall performance, and to jointly optimize the design of these interacting subsystems. Three issues are addressed: (1) channel models which incorporate diverse noise sources, transceiver design and interference from other users for both narrowband and broadband channels; (2) the impact of different noise sources and propagation environments on the fundamental performance limits of coupled MIMO systems, as well as on performance of specific diversity and multiplexing techniques; (3) information-theoretic design criteria to jointly optimize the array, matching, amplifiers and communications algorithms.<br\/><br\/> <br\/><br\/>Broader Impacts: This multi-disciplinary project combines theoretical studies with experiments using an antenna testbed. The mix of theory and hardware demonstrations will provide opportunities for student participation at all levels. This work has the potential to significantly advance science and engineering by providing a more unified view of the RF front end and by developing new models, communications algorithms and matching techniques which may significantly improve wireless performance.","title":"Communications Theory Perspectives on the Design of Compact Multi-Antenna Wireless Transceivers","awardID":"0728803","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7935","name":"COMM & INFORMATION THEORY"}}],"PIcoPI":["560179","509517"],"PO":["564924"]},"124403":{"abstract":"This award supports the development of software infrastructure for large scale simulations of gravitational wave sources (numerical relativity) through a collaboration among researchers at Louisiana State University, Pennsylvania State University, and Rochester Institute of Technology. Recent breakthroughs have provided the numerical relativity community with the basic techniques in to evolve binary black holes for multiple orbits, including the merger and final black hole ring-down phases. Information from these computer simulations have the potential both to enhance the likelihood that ground-based and space-based gravitational wave detectors will recognize these gravitational wave signals from these exotic events and to improve the ability to determine the properties of these systems if signals are detected. The infrastructure to be developed, called XiRel, will build upon and integrate several well developed and widely used computational infrastructures and emerging standards, including Cactus and Carpet. The initial and primary focus of this project is the development of a highly scalable, efficient and accurate adaptive mesh refinement layer based on the existing Carpet driver, which will be fully integrated and supported in Cactus and optimized for numerical relativity. This project will be driven by the scientific goal to perform accurate simulations of black hole binaries with larger initial separations than currently possible, with un-equal masses and unequal spins, and providing reliable physical results critical for gravitational wave astronomy and astrophysics. This award is supported by the Division of Physics in the Mathematical and Physical Sciences Directorate and by the Division of Computing and Communication Foundations in the Computer and Information Science and Engineering Directorate.","title":"Collaborative Research: XiRel, a Next Generation Infrastructure for Numerical Relativity","awardID":"0653303","effectiveDate":"2007-09-01","expirationDate":"2008-11-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"7244","name":"COMPUTATIONAL PHYSICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["523449","555235","543783","543784"],"PO":["525727"]},"125855":{"abstract":"This project will seek ways to greatly simplify privacy policy creation for users. It is based on the premise that the use of contextual information from applications that help users to coordinate or communicate with others - such as their calendar, messaging contacts, and address books - can help in creating privacy policies for location-aware systems. In contrast to earlier work on privacy that focused on such location-independent applications as Web services, the focus in this project is primarily on privacy in location-aware systems where users carry devices that help determine their location. These include GPS-enabled cell phones, wireless PDAs, and laptops. This work will leverage a location-aware infrastructure called Whereabouts, which is deployed in the new Computer Science and Engineering building of the University of Michigan.<br\/><br\/>This research integrates three key concepts to simplify privacy policy specifications: (1) Privacy meta-policies: These are high-level rules that help map a user's context information. For example, a rule may make the user's location available to meeting participants near the start time of a scheduled meeting. (2) Privacy circles: These structures help users share privacy meta-policies with other users. The research will evaluate the hypothesis that privacy meta-policies will be much easier to share than low-level policy preferences that are typically available in existing privacy systems for ubiquitous computing. (3) Privacy mirrors: These are tools to help users understand the impact of their privacy meta-policies. In particular, a user can use a privacy mirror to see how a set of meta-policies would have revealed their location to other users for past events or scheduled future events.<br\/><br\/>The success of this work will help users coordinate and collaborate better with each other using location information, while safeguarding privacy. This is important, because location-aware computing infrastructures are starting to become widely available, but they have still not penetrated mainstream use. Better calendaring and coordination tools will also result from this research, and it will help push the frontiers on understanding how people can better manage their privacy in the context of location-aware systems.","title":"Rethinking Privacy Policies in Location-Aware Systems: Bridging the Gaps Getween Users Applications, and Policy Systems","awardID":"0705672","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7486","name":"INFORMATION PRIVACY & SECURITY"}}],"PIcoPI":["550044","430298"],"PO":["564456"]},"133247":{"abstract":"The exploratory research proposed here aims at feasibility study that will lead to development of theoretical and computational tools for rational design of optimized nonlinear optical materials with enhanced two-photon absorbing (TPA) properties. Their applications have many uses, including (but are not limited to) compact ultrafast switching devices, in both all-optical and electrooptical design schemes. The proposed project fulfills the goals of the CCF Division by extending fundamental capabilities in computer science and engineering with advances from theoretical chemistry and computational materials science. The new NLO<br\/>materials will enable photonic elements for computing and communications hardware that operates at the speed of light and can be tightly integrated with conventional semiconductor-based electronic elements.<br\/>Over the past few years the PI and his collaborators pioneered in application of timedependent Density Functional Theory methods to simulate two-photon absorption spectra and have shown the unprecedented accuracy of this approach. Therefore, the PI is well positioned to start work on development of new nonlinear optical materials and the computational tools necessary to design these materials. His capability is fortified through ongoing collaboration with experimentalists at CREOL, the recognized National leader in nonlinear optical materials characterization, and a college within the PI*s home institution.<br\/><br\/>The scientific merit of this proposal is in the use of proven Time-Dependent Density Functional Theory (TD-DFT) techniques for understanding the underlying principles and development of the practical applications in the computational design of NLO materials. New tools for computer-assisted materials design will be created and validated. More importantly, the new qualitative insights into correlations between electronic and molecular structure and NLO properties will be discovered using existing concepts. Specifically, this project will accomplish: <br\/>1) development of an efficient and practical scheme for NLO properties<br\/>calculations; <br\/>2) validation of this scheme against high-level ab-initio and the<br\/>published experimental data; <br\/>3) integration of research and education.<br\/><br\/>The broader impact of this project will include the the feasibility of TD-DFT for the rational design of<br\/>novel materials for fast photonic and optoelectronic switching devices, which open the venuesfor the progress in other nonlinear optical material applications, including 3D memory devices in<br\/>TPA regime, optical power limiting applications, up-converted lasing, chemical and biological<br\/>sensing, bio-imaging, photodynamic therapy for cancer treatment, etc. The new materials will<br\/>allow accelerated development of new hardware for HPC systems, portable on-board processors, and enhanced household multimedia devices. The proposed research provides graduate and postdoctoral students with a solid and advanced interdisciplinary education in the overlapping areas between computer science and engineering, chemistry, physics, optics and materials; areas where more trained scientists are needed. Two graduate students, already working on this project belong to underrepresented groups. The educational component of the project will make undergraduate chemistry more exciting, dynamic and<br\/>visual through the use of computer graphics.","title":"SGER: Rational Design of Nonlinear Optical Materials for Fast Optoelectronic Switching Applications.","awardID":"0740344","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["382580"],"PO":["565157"]},"126603":{"abstract":"0709025<br\/><br\/>CRI:MISER: A High-performance, Power-aware Cluster<br\/><br\/>Kirk Cameron<br\/><br\/>The insatiable performance demands of many critical computational science applications cannot be satisfied unless the power and energy requirements of emergent machines are reduced. High-performance, power-aware computing (HPPAC) has emerged as a promising approach to this problem. In HPPAC, power consumption is controlled by software to improve energy efficiency while meeting the performance needs of the application. The lack of power-aware cluster infrastructure of significant scale limits the type of power-aware computer science research conducted.<br\/><br\/>This infrastructure effort is building the MISER (Management Infra-Structure for Energy Reduction) cluster, a power-aware cluster to enable and evaluate energy reduction techniques for scientific applications at scale. This proposed infrastructure will consist of at least 64 rack mounted servers, for a total of at least 256 processor cores. At a minimum each node will have several power-aware processors and power-aware disks. The operating system will be open-source Linux for system software development. Systems will be connected with a high-end interconnect. The project will also extend the existing power measurement and control infrastructure (PowerPack) to the new cluster.<br\/><br\/>Twelve research projects, which span twelve faculty members across four departments, will be supported by the proposed power-aware MISER cluster. The participants have a history of mentoring women and minorities through the Multicultural Academic Opportunities Program (MAOP) where summer student interns participate in the project with a faculty mentor. Furthermore, the techniques will improve the energy efficiency of large scale systems, reduce waste and positively impact the environment.","title":"CRI: MISER: A High-performance, Power-aware Cluster","awardID":"0709025","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["563791","518306","402035"],"PO":["565272"]},"135326":{"abstract":"ABSTRACT<br\/>0750787<br\/>Cheng<br\/>Michigan State<br\/><br\/>The Problem. Computing technology now affects nearly every dimension of modern society: managing<br\/>critical infrastructure such as power grids and telecommunication networks; supporting electronic commerce<br\/>and medical information systems; and controlling the operation of aircraft and automobiles. This pervasiveness of computing technology, coupled with its rapidly increasing complexity, gives rise to the need for computer systems that are able to adapt to changing conditions. In the last decade, extensive research has been conducted on many aspects of self-adaptive software systems. Examples include adaptive software mechanisms [1 20]; software-architecture-based techniques for supporting dynamic adaptation [21 38]; adaptable and extensible operating systems [39 42]; and requirements-level and formal methods-based techniques [43 52]. This research has greatly improved our understanding of adaptive software and several key supporting concepts, including computational reflection [53 55], separation of concerns [12, 56], component-based design [57, 58], and transparent interception of program flow [59 61].<br\/>Despite these advances, designing an adaptive software system remains a very challenging task. We speculate<br\/>that much of the difficulty is due to the fact that adaptive software is being designed and implemented using<br\/>traditional tools and environments intended for the development of non-adaptive software. We contend that the<br\/>full potential of dynamically adaptive software systems cannot be realized without fundamental advances in<br\/>the corresponding development environments. Such environments must enable developers to explicitly address<br\/>those aspects of the design problem that distinguish adaptive systems from non-adaptive systems. These issues<br\/>include anticipating how the software may need to adapt in the future, constructing decision-making software<br\/>to govern the adaptation, and ensuring that system integrity is not compromised by adaptation.","title":"SGER: Applying Digital Evolution to Behavioral Models","awardID":"0750787","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["548851","472159","543568","425363"],"PO":["564388"]},"134237":{"abstract":"Abstract<br\/><br\/>In this SGER proposal, the PIs propose to develop novel tools that allow qualitative 3D vision from 2D images and video sequences. Most of today's approaches to visual object recognition essentially reduce this problem to one of pattern classification, where rectangular image patches are independently compared to stored templates to produce isolated object labels. The proposed research explores new research directions for the task of recovering the 3D layout of a scene from a single image and for using the 3D layout to help in recognizing object categories in a scene. Each of the research directions proposed for exploration has the potential of opening up an entire new set of approaches and algorithms and has the potential of defining an entire new field of Computer Vision, which the PIs call \"qualitative geometric reasoning\", as opposed to the traditional quantitative approaches which assume precise depth and dense measurements from stereo or SFM. By advocating the use of qualitative geometric reasoning, this body of work is expected to contribute to a radical change in the way the image interpretation and scene analysis problems are tackled in the computer vision community.<br\/><br\/>The proposed research is anticipated to result in new directions in the general area of geometric reasoning for scene analysis, which is a critical enabling technology for a wide range of applications including defense, health care, human-computer interaction, image retrieval and data mining, industrial and personal robotics, manufacturing, scientific image analysis, space exploration, surveillance and security, and transportation.","title":"Exploratory Research in Scene Analysis and Object Recognition","awardID":"0745636","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["402502","520920"],"PO":["500200"]},"139924":{"abstract":"To meet the bandwidth demand from the traffic explosion from emerging Internet applications like IPTV, VoIP, P2P, e-business and e-healthcare as well as large-scale science applications such as high energy nuclear physics, grid computing, and remote experimentation, optical networks using wavelength-division multiplexing (WDM) technology, which divides the enormous fiber bandwidth into a large number of wavelengths, is the foremost solution. The rapid advances in dense WDM technology with hundreds of wavelengths per fiber and world-wide fiber deployment have brought about a tremendous increase in size of the photonic switches or cross-connects, the cost and difficulty associated with controlling such large cross-connects. This project investigates developing a multi-granular switching framework to reduce the complexity, cost, and size of both electronic and optical switches. The key efforts involve the investigation of reliable waveband switching, multi-granular services, and related theoretical modeling. In particular, the project will explore design of multi-layer and single-layer photonic cross-connect architectures, optimal wavelength grouping (or wavebanding), waveband protection\/restoration schemes, and reliable dynamic provisioning of multi-granular services. The project seeks to yield a fundamental understanding of multi-granular optical networks. <br\/><br\/>Broader Impacts: <br\/><br\/>While the results from this research will advance the state-of-the-art knowledge in wavelength-division multiplexing (WDM) networks, they may also be extended to other networks (e.g., with time or code division multiplexing technology) providing multi-granular switching. The proposed project will develop and transfer technology to stimulate the optical networking industry. By involving both undergraduate and graduate students in the research, incorporating research agenda into both undergraduate and graduate lectures and course projects, and disseminating findings at technical conferences and journals, the project will also help train the future scientists and engineers in high demand fields related to optical networking. The course materials developed in this project will establish a new paradigm for integrating research and education in high-speed networking.","title":"CAREER: A Design of Multi-granular Switching Framework for Optical Networks","awardID":"0813555","effectiveDate":"2007-09-01","expirationDate":"2012-04-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["486191"],"PO":["564993"]},"125888":{"abstract":"With the advent of increasing numbers of increasingly smart machines, there is a growing need to develop technologies that are not only smart, but sensitive to the people and the other machines around them, and sensitive to the context in which they are used. Such an understanding will permit the development of technologies that can coordinate their interactions with humans in a more natural, seamless and fluid fashion. To meet these goals, this research program focuses on three critical yet under-studied contexts of interaction, each of which represents a different constraint upon interpersonal communication: (1) the physical context of shared visual access, (2) the social context of rapport, and (3) the biological context of aging. While some research has been conducted on each of these contextual factors, none has addressed their interaction, nor gathered them into one broader conception of the role of context in interpersonal coordination. This research applies a theory-driven design approach that includes experimental studies, theory development, computational modeling, system implementation and evaluation. In particular, the research program proposes: a) A rigorous study of human-to-human communication using elicitation experiments to develop a more detailed understanding of interpersonal communication across a range of contexts; b) A formalization of the findings into computationally explicit forms that provide predictions of behavior and capture the observed behavioral patterns; c) Integration of the models into a dialogue manager that is implemented within a larger computational architecture; and, d) Evaluation of the implemented system by having untrained humans interact with the system in such a way as to evaluate its effectiveness and reveal gaps in the underlying models as well as in our theoretical understanding.<br\/><br\/>The outcome of this research will advance our theoretical understanding of the role various contextual factors play during interpersonal communication. The results will be useful to a variety of scientific communities including those that study basic human communication (e.g., psychologists, linguists and communication researchers) and those that study interactive computational systems (e.g., computer scientists, computational linguists, and interaction designers). The research will also provide practical design guidelines and a general computational model that describes how machines can make intelligent choices on the basis of these contextual factors during everyday interactions. At a practical level, the general computational model can be applied by technologists developing many different technologies, such as embodied agents, large-scale displays, ubiquitous computing, in-car navigation, and assistive technologies for the elderly and those with cognitive impairments.","title":"HCC: Coordinating Communication: Visual, Social & Biological Factors in Grounding for Humans and Agents","awardID":"0705901","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[334127,"562931","496760"],"PO":["564456"]},"135458":{"abstract":"National Science Foundation <br\/>CISE\/CNS<br\/>Form 7 Review Analysis and Recommendation<br\/><br\/>Proposal Number: 0751316<br\/>PI: Patrick Winston <br\/>Institution: Massachusetts Institute of Technology <br\/><br\/><br\/>Title: SGER: Explorations in Fine-Grained Security for Host and Network Application<br\/><br\/>Proposal Abstract<br\/><br\/>This research project explores a variety of applications of and models for fine-grained security. The topics include information sharing and collaboration, tracing integrity and data provenance through computations and across network hosts, semantic accountability and traceability, network architectures utilizing security-tagged packets, as well as appropriate models for authorization systems. Although fine-grained security has not been broadly studied up to now, recent proposals for advanced information sharing systems and word-level manipulation of security data by new computer architectures demand better understandings of the applications where fine-grained security can deliver important benefits as well as the difficulty of formulating and implementing necessary security models. The range of applications is vast -- from digital libraries, scientific collaboration to legal citation, government and medical processes, intelligence and decision-making in distributed organizations, and even, Internet-based political discourse. Despite the high risk of this exploratory research, the expected payoffs will be very high if manageable approaches are identified for these wide-scope applications. The research methodology involves characterizing an exemplary application, analyzing how it benefits from fine-grained data manipulation, designing core implementation mechanisms, and proposing appropriate security models to assure integrity, confidentiality, and availability. The deliverables are a series of reports each of which discuss an application and its corresponding security model","title":"SGER: Explorations in Fine-Grained Security for Host and Network Applications","awardID":"0751316","effectiveDate":"2007-09-01","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["536919"],"PO":["529429"]},"134248":{"abstract":"This project will (a) investigate how to best leverage the unique affordances of virtual worlds such as Second Life in to investigate the sociocognitive processes involved in innovation; and (b) create a research infrastructure to greatly advance the capacity in the learning sciences to conduct research in virtual worlds such as Second Life (SL). Key to (a) is refining and expanding an existing early-stage SL-based activity that will elicit innovative group behaviors. Key to (b) is exploring and addressing the highly technical challenges in ?instrumenting? the Second Life task environment and analyzing data using automated data analysis tools. This automated data analysis will correlate expert ratings, derived from manually applied ratings developed through an evidence-centered design process, with results of latent semantic analysis techniques applied to group process and product data. This research infrastructure will be tested through a pilot study with five groups, each consisting of four individuals. The proposed research is high-risk given the difficulty in automatically collecting data on activity and communication in the virtual environment; many technical challenges related to implementing automated data collection will need to be resolved. In addition, the technology innovation is constrained by the requirements of learning sciences research as well as by the constraints of the technical capabilities, social norms and user expectations associated with the SL environment, and requirements of other applications with which the SL platform will be used.<br\/><br\/>The use of virtual worlds to create innovative teaching and learning environments shows great promise. This, coupled with the explosive growth in the use of virtual worlds generally and Second Life (SL) in particular for social, business, and learning purposes, drives a need to increase capacity in the learning sciences to use such environments for learning and research. This project will contribute to knowledge about the use of virtual worlds for research and learning in the following ways: (1) it will develop methods for automatically capturing data people?s (avatars?) and objects? behavior inside virtual worlds, including avatar-avatar interactions and avatar-object interactions; then (2) use this instrumented SL environment as a research tool to study characteristics of social interaction in the context of group collaborations that are associated with innovation; and (3) analyze the unique affordances of virtual worlds as learning environments. In addition, we will explore the feasibility of using latent semantic analysis, a statistical approach to analyzing the content of texts, to analyze characteristics of groups? collaborative problem solving associated with innovation. This project is high risk because technical challenges in implementing automated data capture in SL need to be addressed, and there is a lack of existing exemplars or published research on such methods.","title":"Adaptive Expertise in Second Life","awardID":"0745694","effectiveDate":"2007-09-15","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["487391","487391",356996],"PO":["565227"]},"128946":{"abstract":"Multi-core technology promises an inexorable increase in hardware-level<br\/>parallelism and leaves software developers with two challenges: (1) How<br\/>to utilize large numbers of processors in order to achieve higher performance,<br\/>and (2) How to verify the correctness of scalable concurrent programs. This<br\/>project explores these challenges through the development of a new programming<br\/>model called \"relativistic programming\".<br\/><br\/>Relativistic programming targets shared-memory architectures, but rather than<br\/>present a consistent global view of memory it allows each processor to have<br\/>its own relativistic view of memory, containing fresher or staler values than<br\/>other views. By imposing minimal constraints on each processor's execution,<br\/>relativistic programming is intended to achieve the scalability characteristics<br\/>of message passing while embracing the shared memory architecture of modern<br\/>multi-core hardware. Relativistic programming primitives enable fine-grain<br\/>control over the visibility of events in the execution of a concurrent program<br\/>and negate the need to switch among two different programming models for local<br\/>and remote parts of a computation.<br\/><br\/>This research involves formally defining the relativistic programming<br\/>model, exploring its support for formal verification, static and run-time<br\/>analysis, and developing tools and techniques to facilitate and promote its<br\/>wide-spread use in operating system kernel development.","title":"CSR---PDOS: A Relativistic Programming Model for Scalable Multi-Core Architectures","awardID":"0719851","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[341680,341681],"PO":["535244"]},"135117":{"abstract":"Proposal 0750011<br\/>\"A Simulation Platform, for Research on Developmental Robotics\"<br\/>PI: Benjamin J. Kuipers<br\/>University of Texas at Austin<br\/><br\/>ABSTRACT<br\/><br\/>The goal of this project is to investigate the development of high-level concepts about objects and actions from low-level sensor input data. The project will take a developmental robotics approach: that is, it will use AI\/robot models to investigate how concepts can be learned from an agent's own sensorimotor experience with its world. While it is possible to build some of this knowledge by hand, such knowledge tends to be incomplete and short-lived. Thus, for an autonomous agent to cope truly robustly with the complexity and diversity of real-world situations--and to be able to do so in more than short-lived robotic experiments--it is imperative for it to be able to use its own understanding of rich sensory input and motor actions to build its own models and concepts. In this paradigm, learning initiates with basic developmental learning to acquire and ground high-level concepts and then continues with life-long learning to adapt to changes in the world and in the robot's own capabilities. The initial thrust of this project will be to create a simulated baby robot model, which will then be evaluated. Once the baby robot is successful, the project will investigate whether the same methods will allow creation of sufficiently high-fidelity simulated models of apes or corvids (crows).","title":"SGER: A Simulation Platform for Research on Developmental Robotics","awardID":"0750011","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["534124"],"PO":["387198"]},"127505":{"abstract":"Since its inception, the field of Robotics has striven to build versatile and reliable systems that demonstrate the capability to plan, adapt and survive in uncertain and unstructured environments as well as perform cooperative tasks. The intellectual merit of the proposed project lies in the definition and development of an integrated methodology for the study of the above problems in simulation, but under realistic physical constraints. In the above context, this proposal will develop algorithms to plan for robotic mechanisms under complex constraints by pursuing the combination of sampling-based planners with physical simulators. The proposal will also study motion generation and robot coordination in uncertain, unstructured and dynamic environments and develop frameworks to ensure the safety of the involved robots as well as compliance with physical constraints. The problems we propose to work on are interrelated; yet they can be treated separately. Considered together, they constitute a framework for augmenting the capabilities of modern robotics systems and are not constrained to address one problem in isolation or one particular system. The broader impact of the project will be implemented through the development and distribution of software for popular sampling-based planners, and a number of training and mentoring activities.","title":"RI: Robot Planning and Coordination under Physical Constraints","awardID":"0713623","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["557516"],"PO":["543539"]},"127417":{"abstract":"Proposal 0713109<br\/>\"Planning with Complex Constraints and Preferences by Nonlinear Programming and Constraint Partitioning\"<br\/>PI: Yixin Chen<br\/>Washington University<br\/><br\/>ABSTRACT<br\/><br\/>This project aims to develop efficient algorithms for solving complex planning problems that arise from many applications such as manufacturing, aerospace engineering, emergency planning, and workflow scheduling. Two main goals of this research are to improve the expressiveness of planning models and to reduce the computational costs. The key innovation of this project is a unified, efficient, and extendible framework for complex planning with trajectory constraints and preferences.<br\/><br\/>Most existing planning techniques have difficulty in supporting more expressive models due to limitations in their formulations and search methods. This project will develop a new nonlinear programming model for planning. It will provide a formalism to accomodate complex features such as trajectory constraints and numerical objectives. To reduce the search cost, this project is developing a constraint partitioning approach that decomposes the constraints of a planning problem into much simpler subproblems. Previously used in the SGPlan planner, this approach has been proved effective. However, with the new complex features, the original partitioning strategies become inadequate. The project will develop new non-linear planning formulations and partitioning methods in order to exploit the structure of complex planning problems. Constraint partitioning may achieve orders of magnitudes speedup and greatly alleviate the exponential explosion of the search space.<br\/><br\/>This research has several broader impacts. There are many potential applications, ranging from production management to aerospace engineering. This project will apply its results to mobile computing to support the rapid development of mobile devices such as cellular phones and PDAs. The planners to be developed will be made publicly available to provide state-of-the-art AI tools for users from various disciplines.","title":"Planning with Complex Constraints and Preferences by Nonlinear Programming and Constraint Partitioning","awardID":"0713109","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["560534"],"PO":["562760"]},"127428":{"abstract":"Planning to achieve a goal requires knowledge of objects, actions, preconditions, and consequences. These abstract concepts are at a much higher level than the ''pixel-level'' sensory and motor interfaces between an embodied robot and the continuous world. Our goal is to show how high-level concepts of object and action can be learned autonomously from experience with low-level sensorimotor interaction. <br\/><br\/>We hypothesize that these concepts are part of a larger package of foundational concepts that can be learned in approximately the following sequence: using motion to discriminate objects from background; detecting tight, reliable control loops to distinguish self from non-self objects; learning preconditions and consequences of actions applied to objects; identifying ''grasp'' actions that temporarily transform a non-self object to a self object; learning actions and effects that are achievable only with such an object (a tool!).<br\/><br\/>The learning process depends on representing sensorimotor interaction with the world as a stochastic dynamical system. A ''curiosity'' drive rewards improvements in prediction reliability. Evaluation uses a simulated robot child with two arms, stereo vision, and a tray of blocks and other objects. This research will help robots learn their own high-level concepts, and could provide insights into human learning disabilities.","title":"RI: Robot developmental learning of objects, actions, and tools","awardID":"0713150","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["534124"],"PO":["562760"]},"127439":{"abstract":"This project will develop Content-Based Access Control (CBAC), a system for access control on content sharing sites. The development of this system involves three research efforts. First, the research will develop and extend techniques for the automatic content analysis, to categorize entries on content-sharing sites and identify potential readers. Second, it will implement a CBAC system for creating and enforcing content-based access control policies. Third, it will develop techniques for adapting these policies automatically based on observation of users' content, behavior and context. This research will be evaluated in the context of PLoG, a Privacy\/Policy aware blogging system. <br\/><br\/>The popularity of social networking sites, blogging, and other content-sharing sites has exploded, resulting in more personal information and opinions being available with less access control than ever before. However, many sites provide only the most rudimentary of access control mechanisms: a document can be either completely private or completely public. Even the best provide only general role classifications such as private, friends-only, and world-readable, making it impossible for a user to place multiple facets of his or her life into a single, controlled repository. The consequences of poor access control mechanisms have been well-documented. For example, some bloggers have lost their jobs or become victims of stalking. <br\/><br\/>This interdisciplinary project will develop an access control system that is easy for users to understand and administer. To support the system, it will develop new and extended techniques for automatic categorization of text and multimedia objects, access control policy authoring and maintenance, and automatic adaptation of access control policies. These techniques will enable the millions of people who contribute to content sharing sites to better control the information they share with others.","title":"Content-Based Access Control for Blogs and Social Networks","awardID":"0713211","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7486","name":"INFORMATION PRIVACY & SECURITY"}}],"PIcoPI":["510424","369058"],"PO":["564456"]},"129518":{"abstract":"Wireless sensor networks have the potential to revolutionize research areas and<br\/>industries that require the distributed collection and aggregation of data,<br\/>e.g., civil engineering, biology, and geology. However, to date their impact<br\/>has fallen short of this potential. This is not surprising; wireless sensor<br\/>networks are difficult to design and program. Experts in application domains<br\/>such as biology and civil engineering have neither the training in embedded<br\/>system programming and design required to develop adequate wireless sensor<br\/>networks, nor the time or inclination to become embedded systems designers.<br\/>For wireless sensor networks to live up to their potential, they must be easy<br\/>for application experts to design and program instead of requiring embedded<br\/>systems design expertise.<br\/><br\/>This project seeks to put wireless sensor network design and deployment within<br\/>the reach of applications experts. This project will identify a small set of<br\/>application archetypes, described in terms meaningful to application<br\/>developers, that capture the most common application structures. Each<br\/>archetype will be backed by a compilable specification written in a simple<br\/>high-level archetype-specific language. After customization, a specification<br\/>will be passed to a synthesis algorithm to produce a working hardware-software<br\/>system. Synthesis of efficient wireless sensor networks would be intractable<br\/>without an appropriate hardware-software platform. Therefore, this project<br\/>will also determine the particular types of hardware and software components<br\/>necessary to enable support for wide range of archetypes. A configurable<br\/>hardware-software platform will be developed based on these findings.","title":"Collaborative Research: NeTS-NOSS: Sensor Network Synthesis - Opening the Use of Wireless Sensor Networks to Application Experts","awardID":"0721978","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["540138","540138","359330",343191,"550572"],"PO":["565303"]},"130641":{"abstract":"The Biomimetic Real-time Cortex (BioRC) project aims to design, simulate, and construct nano-circuits that model portions of the cortex, where logic and reasoning occur. The nano-circuits designed under this research could find application in autonomous vehicle control, facial recognition, and advance our understanding of biological neural processes. This project also includes development of predictive mathematical models to determine the feasibility of constructing large-scale cortical emulations in hardware. With the brain's large number of interconnections and the need for long term learning, several problems arise in large, real-time, hardware-based emulations; scale, interconnectivity and plasticity. To meet the dynamic needs of such emulations and to deal with interconnectivity and scale problems, the technological requirements of autonomous assembly and reconfiguration are also being evaluated.<br\/><br\/>Using a bottom up methodology, nano-electronic circuits, including learning apparatuses, from a single neuron to a column of neurons, are being simulated using the latest carbon nanotube and nanowire device models. The circuits implement common neural phenomena and mechanisms, including ion channels, dendritic computation, spike bursts and spike trains. Circuits are being designed with the ultimate goal of scaling to cortical-sized networks, to be implemented in future 3-dimensional nano-circuits and with awareness of possible dynamic hardware technologies including autonomous assembly and reconfiguration. In the near term, simplified neural circuits are being constructed using nanotubes and nanowires. Bottom-up chemical synthesis and top-down nanofabrication are combined to assemble nanowires and carbon nanotubes into hierarchical structures to be used as building blocks for cortical circuits. Ancillary to this activity is the development of mathematical models of neural size and interconnectivity that are used to evaluate solutions to the interconnection problem and determine feasibility of a synthetic cortex.","title":"Biomimetic Cortical Nanocircuits","awardID":"0726815","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":[346677,"442245"],"PO":["565223"]},"133600":{"abstract":"Spelman College proposes the ARTSI (Advancing Robotics Technology for Societal Impact) Alliance in collaboration with Florida A&M University, the University of the District of Columbia, Hampton University, Morgan State University, Norfolk State University, Winston-Salem State University, the University of Arkansas-Pine Bluff, Carnegie Mellon University, Georgia Institute of Technology, Brown University, Duke University, the University of Alabama, the University of Washington, and the University of Pittsburgh. Seven of these partners are HBCUs and seven are Carnegie Research I institutions. Their collaboration joins the strengths of HBCUs in conducting outreach and education in a nurturing learning environment with those of the R1's for conducting world class research. The ARTSI Alliance will motivate students to pursue computer science careers by emphasizing the creativity and socially beneficial aspects robotics technology with hands-on projects, curriculum, and media. ARTSI activities will span the academic pipeline from K-12 through the faculty ranks. At the K-12 level, students will be recruited with community outreach using robotics and art, robotics road shows, and a robotics educational film online repository. At the undergraduate level, HBCU students will be exposed to new robotics curriculum, and they will be encouraged to pursue advanced training in graduate school through summer research experiences, collaborative, interdisciplinary robotics projects in the arts and health, instruction in technical film documentation, student virtual film festivals, annual robotics conferences, and instruction in entrepreneurship for computer science. At the faculty level, it will increase the number of HBCU faculty who educate students in robotics and involve students in robotics research by providing faculty mentoring, summer research experiences for underrepresented faculty at R1 robotics labs, robotics summer workshops, and development and dissemination of robotics educational material through a web-based portal. The Alliance will have industry partners, including Seagate, iRobot, Microsoft Research, and Juxtopia, as well as educational partners, including Florida-Georgia Louis Stokes Alliance for Minority Participation and Computer Science Teachers Association.","title":"Collaborative Research: BPC-A: ARTSI: Advancing Robotics Technology for Societal Impact","awardID":"0742106","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7584","name":"ITR-BROADENING PARTICIPATION"}}],"PIcoPI":["551205","502937"],"PO":["561855"]},"134931":{"abstract":"This project explores the development of methodologies for populating worlds with persistent, adaptive, collaborative, believable synthetic actors, referred to as Synthespians. These methods are extensions of adaptive models of learning and planning to accommodate the complex, dynamic environments in massive multi-player online games. The intellectual merit includes the development and evaluation of:<br\/>1. A behavior development language, with discovery, machine learning, and adaptation of behaviors directly integrated into the language, allowing for the rapid development and deployment of Synthespians.<br\/>2. A framework for the actors to recognize and discover plans by observing and modeling the activities of the other agents.<br\/>An expected outcome of this research is the ability to author complex virtual worlds with many participants that support intelligent and effective interaction between people and machines.<br\/><br\/>Broader Impact: A scientific understanding of how we interact with each other and collaborate will benefit from our ability to simulate complex environments with dynamic and evolving individual and group behaviors. In this project, building and modeling such environments and behaviors is done within a gaming context. This work will in the long run effect and change the fields of education and entertainment. In addition, being able to model large collaborative and interactive scenarios will also help us understand and model large social dynamics phenomenon of interest to sociologists and economists.","title":"SGER Collaborative Research: Persistent, Adaptive, Collaborative Synthespians","awardID":"0749181","effectiveDate":"2007-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["508256","559402"],"PO":["565227"]},"120653":{"abstract":"Lamar University, Beaumont proposes the INcreasing Student Participation In REsearch Development Program (INSPIRED) to engage and develop female and minority computer scientists. The program includes an enriched undergraduate research experience that includes mentoring, tutoring, and other support, and activities that are designed to dispel some of the misconceptions that make computer science unpopular for women and minorities. INSPIRED students are paid to perform research and participate in mentoring and outreach functions for an average of fifteen hours per week. The students can earn research credit hours for their work. They work in teams under the direction of Computer Science faculty members who serve as mentors and role models. The teams include students from all levels, freshmen through seniors. Graduate students help lead the research teams. The higher-level students help to train and mentor the lower-level students and inspire them to reach the next level. INSPIRED students get experience not only in research but also in teamwork, leadership, writing papers and making professional presentations, all of which contribute towards their professional development. Career Counseling and Graduate Study Seminars help bridge graduating INSPIRED students to professions or advanced study in computing. Participation in Computer Science conferences, CS Research Seminars and CS Careers Forums exposes students to the richness, breadth, and many beneficial applications of Computer Science and dispels the misconception that CS is by nature a narrow, non-inclusive endeavor. <br\/>INSPIRED also has outreach components for middle and high school students and entering freshmen. These activities include one and five day summer camps and visiting road shows. INSPIRED students play an active role in the summer camps and road shows, thus inspiring others to engage in Computer Science. INSPIRED students also gain teaching experience in conducting workshops during the Week of Welcome. The focus of these workshops is exposing entering first time freshmen to the diverse field of computer science. INSPIRED students have the opportunity to share their research experiences and accomplishments, while encouraging other female and minority students to explore computer science as a field of study.","title":"BPC-DP: INcreasing Student Participation In REsearch Development (INSPIRED) Program","awardID":"0634288","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7584","name":"ITR-BROADENING PARTICIPATION"}}],"PIcoPI":["362731","390833",320549],"PO":["561855"]},"124921":{"abstract":"Computational \"\"proof assistants,\"\" which allow users to construct axiomatic proofs of formally specified assertions, are currently used for two purposes: first, to verify ordinary mathematical proofs, and second, to verify that (descriptions of) hardware and software meet design specifications. This project will develop logical and computational methods to support both types of activities. Specific components of the project include: the development of formal libraries to support proofs in number theory and discrete geometry; the extraction of verification conditions from software component specifications and implementations in an assertive programming language known as Resolve; a classification of the types of inferences that arise in both domains; the development of logical methods for verifying these inferences automatically; and the development of educational materials and software that will make it possible to integrate these methods into undergraduate and graduate curricula in computer science and mathematics.<br\/><br\/>As mathematical proofs become more and more intricate, and now often rely on extensive computation, it is becoming increasingly difficult to verify that they are correct. Similarly, as hardware and software systems become more and more complex, it is becoming increasingly difficult to verify that they meet their design specifications. Doing so is especially important when resources, lives, and security depend on their correct behavior. This collaboration between mathematical logicians and computer scientists will develop methods to make it possible to verify that such mathematical and computational claims are valid, and that the arguments supporting them are free of errors. The project will also develop means of training the next generation of computer scientists and mathematicians to use these methods.","title":"Collaborative research: logical support for formal verification","awardID":"0701187","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["508269"],"PO":["565280"]},"133633":{"abstract":"This project undertakes the first steps necessary to learn which simplifications and transformations in medical text increase understanding. A corpus of documents from sites such as WebMD, government health sites, patient educational material and patient blogs will be compared for grammatical and vocabulary features and their frequency of occurrence in both complex and simplified document styles. The goal will be to find structures, - new or previously found by others to be associated with understanding, - that appear in one set but not in the other, or with significantly lower frequency. This corpus will then be used to develop a second corpus with sentences containing the difficult linguistic structures and a parallel corpus with simplified versions. A user study will help relate understanding to specific structures and vocabulary. The project will focus on seniors because they constitute a large and growing portion of health information consumers. If successful, this project will lead to the development of a metric that reflects text characteristics associated with comprehension difficulties and the development of an \"\"intra-lingual machine translation\"\" program to move from difficult to easier-to-understand text. The intellectual merit lies in discovery of systematic differences in linguistic features in health and medical text that can be measured and that are associated with understanding by senior readers. The project is especially suitable as a SGER project because studies are necessary to evaluate the degree to which automatic text simplification can help. Such automatic simplification of medical information must be absolutely accurate. \"\"Simplifications\"\" that result in a different meaning are not acceptable within the healthcare field. At the same time, it must be fully automatic if it is be useful in simplifying the vast amounts of text already on line and that continues to be produced. High quality, fully automatic machine translation is currently not achievable on unrestricted text, so this research goal must be classified as of fairly high risk. However, limitation of the domain to medical texts and the application to within-language \"\"translation\"\" make this goal more plausible.<br\/><br\/>Millions of people read health information online but many lack understanding of this information. Such misunderstanding of health information increases the number of unwise decisions and leads to poorer health and higher healthcare costs. Even a small improvement in readers' understanding will have a significant impact because it may lead to fewer unwise decisions. The broader impact lies in computational approaches to automatic simplification of medical texts and the impact that even a small increase in understanding may have on healthcare. This research, if successful, will point the way towards structures in text suitable for automatic simplification of medical texts. This has the potential to make the vast amount of web-based medical and health information more accessible to consumers, resulting in more informed patients, and ultimately better outcomes. The research may also provide some guidelines for the newly emerging phenomenon of electronic communication between healthcare providers and patients.","title":"SGER: U3 - Understanding User Understanding","awardID":"0742223","effectiveDate":"2007-09-15","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[355341,355342,355343],"PO":["388678"]},"133754":{"abstract":"This funding will support 35 researchers and graduate students to participate in a Workshop on Mobile Devices for Children, to be held November 2007 in the Human-Computer Interaction Lab at the University of Maryland. The workshop will be conducted over a two-day period and activities will include participant presentations, analysis of existing research areas, and brainstorming of future research avenues. The PIs will invite approximately 10 senior researchers and industry experts to participate and hold a general call for participation for the remaining slots. In addition, 25% of the slots will be specifically designated for graduate students. <br\/><br\/>In recent years, researchers have been exploring the use of mobile devices for children's educational applications in a number of areas: from data collection by children for field research, to participatory physical simulations, to use as mobile guides, to exploring mobile childrens digital libraries. These mobile devices have ranged from PDAs and mobile phones to Internet Tablets and Ultra-Mobile PCs. Given this important new area of research, it is critical that work for children be highlighted and understood by the greater research community. Possible broader impacts include new research initiatives and collaborations, and dissemination of workshop results to a wider community. Along this line, the PIs will produce a special journal issue which compiles the results of the discussions and presentations. In addition, they will developing an online repository of workshop outcomes on the University of Maryland Human Computer Interaction Laboratory website.","title":"HCC: Workshop on Mobile Devices for Children","awardID":"0742712","effectiveDate":"2007-09-15","expirationDate":"2008-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["426438","518152"],"PO":["564456"]},"133996":{"abstract":"The goals of this project are fourfold: (1) develop techniques that will advance the capabilities of robots to interact with humans; (2) increase undergraduate and graduate research interest and opportunities; (3) increase interest in the sciences by pre-college students; (4) increase acceptance by the general public of robots in everyday life. A robot will be constructed and required methodologies developed to produce a robotic entity capable of significant robot\/human interaction. The robot will be designed to function primarily as a campus tour guide but will also be used for demonstrations at area high schools and middle schools to achieve the goal of increasing interest in the sciences. The robot will have the capability to respond, in as human like fashion as possible, to humans in which it comes in contact. While touring campus locations, JagBot will be able to \"see\", \"hear\" and \"speak\" when dealing with the tour participants. JagBot will be able to share relevant information with the tour participants, answer questions and slightly modify the tour to satisfy their requests.","title":"SGER: JagBot - An Autonomous Robotic Campus Tour Guide","awardID":"0744070","effectiveDate":"2007-09-01","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[356386,356387,"472582"],"PO":["564316"]},"133523":{"abstract":"In many communication, education, and entertainment contexts, people interact with others via some type of digital representations of themselves. This research project examines two types of such representations: 1) virtual humans that behave like a specific individual but looks different from that individual on a specific dimension, and 2) virtual humans that look like a specific individual but perform some novel action which that individual has never done. In the first category, pilot work has demonstrated that people's behavior conforms to the visual features of their representations. In the second category, pilot work has demonstrated that people model the behavior of digital representations more when the representation looks like them than when it does not. The current project explores the strength, duration, and processes behind this effect in terms of interactivity. Specifically, the project will develop the technical aspects of making oneself appear to change in real-time?get older, younger, taller, more attractive, as well as the psychological implications of seeing oneself change shape or social category. This work is risky because a) it is unclear if a human will respond in a natural way to an altered version of the self, b) the computer algorithms that take a three-dimensional face modeled after a specific user have never been tested in terms of changing the age, gender, and attractiveness of a specific face, and c) no researchers have ever tested the implications of being in virtual reality weeks after the exposure to a digital model.<br\/><br\/>Humans have relied upon abstract representations of themselves for centuries?painted portraits and statues have been one of the cornerstones of historical art. However in the digital age, representations are much more dynamic and transformable than their physical counterparts. Given that a substantial portion of the population are spending literally hours per day interacting via digital representations (e.g., voices on cell phones, characters in online games, profiles on social network web sites such as Facebook), understanding the ramifications of this phenomenon is crucial. For example, how long do the effects last, and what parameters contribute (e.g., interactivity, similarity, etc.) most? The current proposal has the potential to change the way we think about the implications of interacting with online versions of one another, and consequently relates to the fields of communication, psychology, education, and computer science. In sum, in the world in which people have identities in digital space, understanding how those digital representations relate to the physical self is paramount.","title":"Exploring the Behavioral and Facial Similarities of Humans and their Virtual Representations","awardID":"0741753","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["553205"],"PO":["564456"]},"133644":{"abstract":"Efficient support for continuous queries on massive data streams is critical in many application areas, including publish\/subscribe, traffic monitoring, sensor networks, and algorithmic trading. Thus, designing data stream management systems (DSMS) to support such queries efficiently and reliably represents a vibrant area of current research. Unfortunately, DSMS cannot yet support efficiently the very complex mining queries required to extract new patterns and knowledge from data streams-- although they are needed in important applications, such as intrusion detection and other security tasks. DSMS designed to support mining tasks are called Inductive DSMS (since they induce new knowledge from data). This project's objective is to develop the enabling technology for Inductive DSMS by (i) designing faster data stream mining algorithms, and (ii) extending DSMS to support efficiently mining tasks expressed in the DSMS query language, and (iii) building an Inductive DSMS prototype and evaluating it on data mining testbeds. <br\/><br\/>Data mining technology is having a major impact on diverse applications domains, including business, security, and science. However, mining the massive data streams that represent the lifeblood of the information age has proven very difficult: this is the first project addressing this challenge. A broad range of scientific, educational, and economic activities will benefit greatly once the vision of Inductive DSMS becomes reality. Project funds will support PhD students pursuing research on DSMS and data mining. The new technology will enrich several graduate courses. Dissemination is through publications, reports, and demos available from: http:\/\/wis.cs.ucla.edu\/idsms.","title":"SGER: Efficient Support for Mining Queries in Data Stream Management Systems","awardID":"0742267","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["542091"],"PO":["563727"]},"131114":{"abstract":"The increasingly sophisticated methods for measuring and visualizing brain activity have opened up important areas of basic research in psychiatry, psychology, and neurology. These new neuroimaging modalities pose new opportunities and challenges for the signal processing community. One such challenge is the quantification of the interactions between signals recorded at different sites, also known as the functional integration in the brain. The current imaging modalities do not provide a measure of the functional interaction between electrical or magnetic activity recorded at different sites. In order to gain a better understanding of how the brain processes information, it is crucial to quantify these interactions between its subsystems. This research involves developing two complementary signal processing methods for quantifying the connectivity patterns in the brain based on the electroencephalogram (EEG) recordings.<br\/><br\/>The investigator develops two types of time-varying measures of connectivity to quantify the functional integration in the brain: 1) Time-varying measures of coherence that separate the effects of amplitude correlation and phase synchrony from each other and quantify the synchrony between pairs of signals; 2) Information-theoretic measures on the time-frequency plane that quantify the complexity of individual signals, as well as the interdependence between pairs of signals. These measures are applied to EEG data sets, in particular to the study of psychopathologies such as schizophrenia. The investigator's approach offers significant improvements over the conventional EEG processing techniques since a number of factors crucial to understanding the dynamics of brain signaling, i.e. time, frequency, phase, space and information flow, are integrated into one joint representation.","title":"Signal Processing for Quantifying the Functional Integration in the Brain","awardID":"0728984","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["518268"],"PO":["564898"]},"131125":{"abstract":"The main focus of the research is to develop good algorithms for designing networks. With the popularity and ubiquity of the Internet, it has become important to develop simple and scalable algorithms to design good networks which offer the most flexibility and functionality. The<br\/>network designer has to build networks given only partial information and loose estimates of the traffic that will eventually be carried, to build networks knowing that faults will almost surely occur and to provision for handling these faults gracefully, and to do this in the most economic and efficient fashion. Along with this, the network designer today must take into account the heterogeneity of networks (which will include wireless and optical parts), and the fact that each<br\/>network has to interact with potentially many other networks. In addition, these interacting networks may be controlled by different entities having different pricing schemes and different incentive structures.<br\/><br\/>The investigators from Carnegie Mellon University and Bell Laboratories draw on their mix of backgrounds to mathematically model the problems faced in network design contexts, and to develop algorithmic tools and good algorithms with provable guarantees for these problems. To achieve these goals, the research adapts and augments a rich set of algorithmic techniques from linear and convex programming, stochastic optimization, metric embeddings, and randomization, as well as complexity-theoretic techniques that have developed in theoretical computer science over the past few years. The research reflects a collaboration between academia and research laboratories to transfer ideas, problems and algorithms between theory and practice: in particular, the research encourages students to learn problem modeling and solving, and to move between the<br\/>two environments gaining a balanced view of issues in network design. Research progress is propagated into the curriculum via specialized courses presenting the theoretical advances in the context of their applications, as well as basic courses teaching the fundamental ideas and techniques behind these research advances.","title":"Collaborative Research: Emerging Directions in Network Design and Optimization","awardID":"0729022","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["550590"],"PO":["565251"]},"133798":{"abstract":"This project investigates human creativity as a basis for: creating computational models of such creativity; advancing the area at the intersection of artificial intelligence and software engineering known as automatic programming; and developing educational technology to better teach computer programming. The project advances computational creativity with a new theoretical model of creativity in computer programming, steps toward a significant contribution to automatic programming, and insights into better education in computer programming. The project will devise a formal theory of computer programming as a creative process. This formal theory would place clear constraints on an overarching computational theory of domain-independent human creativity. Some initial implementations and corresponding demonstrations of the formal theory will be engineered. As a precursor to the formal theory, a general architecture of programming creativity will be developed. The project will develop algorithm-sketches showing how the creativity of human programmers can by exploited to develop a new approach to automatic programming. <br\/><br\/>The formal models of computational creativity and automatic programming will provide guidance as to how to better train computer programmers. Students will be exposed to computational models of programming creativity that integrate deductive, inductive, and abductive reasoning. Students will also be introduced to the role of diagrammatic thinking and reasoning in visualizing data structures and transformations on such data structures during the creative\/exploratory part of programming. An emphasis on creativity in the teaching of programming will entice a greater number of students to pursue computer science.","title":"SGER: Creativity and Computer Programming: A New Research Program","awardID":"0742946","effectiveDate":"2007-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":["443288",355860],"PO":["424970"]},"131499":{"abstract":"One of the most important goals for our military and homeland security personnel is to catch people who are planning to attack our military and civilian facilities before they strike. This project proposes to identify, interpret, and develop procedures for automatically measuring the types of behavioral clues exhibited by people who intend on attacking, particularly when they attempt to conceal or fabricate their true intentions. Although research has shown that there is no one signal or behavior that reveals whether a person is concealing his or her intentions or telling a lie, researchers agree that most behavioral clues to deceit are person specific, which require determining a baseline reading of the person's normal behavior and calibrating changes from that baseline. This project improves on prior research because it will examine behaviors that are elicited in more realistic, high stake scenarios, and will do it without attaching any instruments to the person, while applying automatic machine learning systems to take each indicator behavior and identify which changes are best able to identify a person as truthful or lying. This procedure will then produce a prototype that examines video of both checkpoint and 'sit down' interrogation sessions and automatically produces a single integrated score of deception\/malfeasance likelihood. <br\/><br\/>The broader impact of this project is that it will bring together behavioral, computer, and engineering scientists to apply their state of the art tools to creating a system with the potential for identifying a potential terrorist before he or she attacks. The synergy generated by this rare combination of skills and knowledge between the researchers will advance knowledge not only in this specific topic but also in areas of research such as social psychology, computer vision and automatic machine learning. Finally, this project will maintain this synergy momentum by training future generations of not only Ph.D. and Postdoctoral students, but will also be applied to ongoing counter-terrorism training programs.","title":"EXP-LA: Deceit Indication Through Person Specific Behavioral Dynamics","awardID":"0731115","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"7653","name":"EXPLOSIVES & RLTD THREATS EXP"}}],"PIcoPI":["548306",349177,349178],"PO":["565136"]},"125812":{"abstract":"Flapping flight provides high maneuverability for indoor environments.<br\/>To achieve robust intelligence for tasks such as search and indoor<br\/>navigation, the maneuverability of an ornithopter will be combined<br\/>with a learning approach which makes minimal assumptions about the<br\/>nature of disturbances and obstacles. We propose to develop<br\/>algorithms for ornithopters to cooperate in sensing and navigation in<br\/>typical indoor environments without prior maps. Our research will be<br\/>verified with full three dimensional dynamic simulation, a<br\/>multi-tethered laboratory test-bed, as well as with actual indoor<br\/>flying ornithopters.<br\/><br\/>The key research issues to be addressed in this work are:<br\/>1) improved ornithopter mechanics and aerodynamics<br\/>2) robust ornithopter flight control strategies<br\/>3) learning algorithms for cooperative navigation<br\/>of ornithopters using only simple sensor information<br\/><br\/>This research will advance understanding of high maneuverability<br\/>flapping wing vehicles for indoor flight. By combining research from<br\/>the levels of mechanics to learned behavior in a real indoor<br\/>environment, we will test how performance at each level can be<br\/>integrated to achieve robust intelligence.<br\/><br\/>Our project will provide interdisciplinary education for students in<br\/>achieving robust intelligence through the combination of mechanics,<br\/>sensing, control, and learning. This research can lead to flying<br\/>robots which can robustly enter unknown and hazardous indoor<br\/>environments, potentially keeping rescue workers out of harms way.","title":"RI: Collaborative Research:Robust Ornithopter Flight - from Engineering Models to Cooperative Indoor Maneuvers","awardID":"0705429","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["401938","420868"],"PO":["491702"]},"134777":{"abstract":"Securing data, information and applications accessible through the web or otherwise is a major goal for many organizations. While there have been many developments in data and applications security research including enforcing access control policies, trust negotiation, and securing web services, the data and applications security community currently lacks a coherent direction for research and development. Therefore the objective of this project is to host a workshop that examines the developments in data and applications security, determines the challenges that need to be addressed and establishes a research agenda for the next decade. The workshop participants are leading experts in the areas of information security and data and knowledgement management from academia, industry and government agencies. The workshop program includes individual presentations as well as breakout session discussions and presentations. The workshop is planned to take place in spring 2008. The workshop agenda, participants, position papers, and report will be made available to the public via the workshop website: http:\/\/www.utdallas.edu\/~lkhan\/NSF-DAS-Workshop.htm","title":"Data and Applications Security: Research Directions and Opportunities","awardID":"0748433","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["551857","562519"],"PO":["565136"]},"131147":{"abstract":"The efficient use of bandwidth will be a critical factor in determining the scalability of the next-generation Internet. The investigator studies the question of how much efficiency is gained in a network by giving nodes the capability to encode and decode information in the process of transmitting it, a paradigm known as network coding. The research aims for a more complete understanding of the capabilities and limitations of network coding in structurally complex networks, to be achieved using tools from the theory of algorithms, combinatorial optimization, and computational complexity. <br\/><br\/>The research delineates a role for the theory of algorithms and combinatorial optimization within the study of network coding, incorporating core notions such as approximation algorithms and primal-dual techniques. Exact algorithms for computing the achievable rate region are sought in special classes of network coding problems, most notably for multiple unicast sessions in undirected graphs. Approximation algorithms are sought for general graphs; it is likely that non-trivial approximation algorithms will highlight purely structural features of network coding problems ( e.g. succinct certificates of infeasibility) which will spur further progress in the area. The relationship between network coding rates and other graph parameters, including the maximum concurrent multicommodity flow rate and parameters based on edge cuts, will be explored. Finally, the research investigates the achievable rate region for network coding problems in which nodes have bounded storage.","title":"Combinatorial and Algorithmic Aspects of Network Coding","awardID":"0729102","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["406684"],"PO":["565251"]},"131169":{"abstract":"\"Quantum Algorithms for Data Stream\"<br\/>Wim van Dam, University of California, Santa Barbara<br\/><br\/>In this project the investigator develops new algorithms for processing data streams that are much larger than the internal memory of the quantum computer that executes the quantum algorithm. Such algorithms are especially relevant in an \"online\" setting where the computer deals with a continuous and unpredictable flow of information that has to be processed in real time without the possibility of storing the information for further analysis. The research of this project focuses on the question how much better (future) quantum mechanical computers will be at performing such tasks in comparison with our current, classical computers.<br\/><br\/>While N quantum bits can carry no more than N bits of classical information, there is ample evidence from earlier work on quantum finite automata and quantum communication that for specific tasks the required amount of quantum bits can be significantly lower than the required number of classical bits. Here it is investigated if these kinds of quantum improvements can also be obtained in the data stream model. The research applies ideas from the theory of quantum computation to the new setting of data stream algorithms, which gives a computational model that sits at the intersection of the theories of quantum finite automata and quantum communication complexity. As quantum devices in the near future will most likely have a very limited amount of memory, this data stream model is arguably more realistic, from an experimental point of view at least, than the general quantum circuit model with its more generous assumptions regarding the availability of memory.","title":"Quantum Algorithms for Data Streams","awardID":"0729172","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7351","name":"THEORETICAL FOUNDATIONS (TF)"}}],"PIcoPI":["548398"],"PO":["565157"]},"125845":{"abstract":"III-COR: Collaborative Research: Graceful Evolution and Historical <br\/>Queries in Information Systems-- a Unified Approach <br\/><br\/>Database schema evolution represents a constant in the life cycle <br\/>of Information Systems, and is the source of major costs for <br\/>maintenance, upgrading, and service down time. The traditional <br\/>schema revision process depends on the installation of a new <br\/>schema along with the revised database, and a converted set of <br\/>applications (laboriously rewritten to work with this schema). <br\/>Instead, this project develops the novel enabling technology <br\/>whereby the schema evolution problem is reduced to coordinating <br\/>mappings between multiple concurrent versions of the schema, <br\/>applications, and the database. This is realized by the <br\/>Meta-Manager system which provides integrated management of <br\/>evolving (i) data, and (ii) metadata, and efficiently supports the <br\/>(iii) mappings, and (iv) software artifacts needed for graceful <br\/>schema evolution. Further, the Meta-Manager allows for <br\/>preservation and querying of database history while it assists the <br\/>user in planning how to evolve the current schema version with <br\/>``what-if'' evolution scenarios. The functionality and performance <br\/>of the system is validated using various testbeds, such as, the <br\/>San Diego Supercomputing Center's Storage Request Broker, which <br\/>hosts scientific data for various research groups ranging from <br\/>astrophysicists to biologists. <br\/><br\/>This novel and timely approach provides a unified solution to both <br\/>the evolution and preservation of information systems. Because of <br\/>the key role played by information systems, a broad range of <br\/>scientific, educational, and economic activities will benefit from <br\/>these advances. <br\/><br\/>Results are disseminated via publications, reports and <br\/>demos available from the project web sites: <br\/><br\/>http:\/\/www.cs.ucr.edu\/~tsotras\/meta-manager <br\/>http:\/\/wis.cs.ucla.edu\/projects\/meta-manager <br\/>http:\/\/db.ucsd.edu\/people\/alin\/meta-manager","title":"III-COR: Collaborative Research: Graceful Evolution and Historical Queries in Information Systems-- a Unified Approach","awardID":"0705589","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["409520","518657"],"PO":["469867"]},"131059":{"abstract":"Effective Dimensions in the Theory of Computing<br\/><br\/> Abstract<br\/><br\/>The investigator recently developed effective fractal dimensions in <br\/>order to measure the density of information in large data objects.<br\/>In this project, he and his group are using these dimensions to<br\/>extend the theoretical foundations of high-precision scientific<br\/>computing, to study prediction and compression of data streams that <br\/>are truly massive relative to available computational resources, <br\/>and to attack fundamental questions concerning the number of <br\/>computation steps required to solve complex problems.<br\/><br\/>The research on foundations of scientific computing is incorporating <br\/>multiresolution processing of data from continuous geometric domains<br\/>in order to develop an algorithmic extension of geometric measure<br\/>theory in Euclidean spaces. Investigations of prediction and <br\/>compression are focused on computation by finite-state devices and<br\/>extend methods of ergodic number theory. Computational complexity<br\/>research topics include derandomization, diagonalization, and <br\/>dimension characterizations of time-bounded Kolmogorov complexity.<br\/>Overall, the project is developing new analytic methods for use in<br\/>theoretical computer science, working to achieve a greater unity <br\/>between computational complexity and information theory, and <br\/>training young researchers to cross traditional boundaries in the<br\/>conduct of rigorous research.","title":"Effective Dimensions in the Theory of Computing","awardID":"0728806","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7351","name":"THEORETICAL FOUNDATIONS (TF)"}}],"PIcoPI":["531355"],"PO":["565157"]},"125746":{"abstract":"One way industries harmonize the actions of individual organizations is via formal agreements on process and specification standards. Little is known about the mechanisms that drive this critical coordination so foundational to our national economic competitiveness. New information architecture technologies (e.g., XML) are rapidly replacing decades-old, stable formats (e.g., EDI), transforming the standards process in unforeseen ways. <br\/><br\/>This proposal empirically examines the development, adoption, implementation, and diffusion of industry-wide vertical information systems standards in three diverse industries: automotive, retailing, and mortgage finance. As standards diffusion is a complex interaction between independent organization-level action and collective industry-level action, the three case studies are grounded by data collection with a sample of 60 companies from each industry, which enables comparisons of relative success of a standard's adoption and use as well as its consequences. This is a unique multi-level approach, investigating the impact of collective action dynamics on specific IT design features. <br\/><br\/>Broader impacts: Improved electronic interorganizational collaboration has enormous potential to reduce transaction costs and develop more competitive industries. Such benefits can lead to lower prices for consumers. Moreover, the greater use of open Internet standards promises new opportunities for smaller organizations that were not able to enjoy the full benefits of earlier EDI approaches. The research will also produce materials for the education of practitioners and will advance the state of knowledge in several fields, including information systems and technology, management, industrial engineering, economics, sociology, and social informatics.","title":"Collaborative Research: Interorganizational Information Systems Integration Through Industry-wide IS Standardization: Technical Design Choices and Collective Action Dilemmas","awardID":"0705186","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["409223"],"PO":["564456"]},"126604":{"abstract":"Proposal #: CNS 07-09044 <br\/>PI(s): Guevara Noubir <br\/>Institution: Northeastern University <br\/> Boston, Ma 02115-5005<br\/>Title: IAD Equipment for Cross-Layer Wireless Protocols Design and Prototyping <br\/><br\/>Project Proposed:<br\/>This project, developing and implementing a networking technology leading to \"ambient intelligence,\" requests test and measurement equipment to develop further a current project on heterogeneous wireless networks. The work aims to empower people through an appropriately designed robust and secure digital environment that is aware of their location, context, and needs. In order to enable ubiquitous computing in practice, it is essential to build robust, scalable, and secure wireless networks that can accommodate a wide variety of mobile devices. Prototyping and experimentation serve to validate the developed protocols. A set of radio-frequency instruments enables the following research endeavors:<br\/>. Better and faster testing, debugging, and troubleshooting of RF boards;<br\/>. Digitizing and generating signals at arbitrary frequencies; and<br\/>. Accurate signal measurement and signal generation<br\/><br\/>Broader Impacts: The work impacts society through a digital environment that will be aware of the presence of people and their context, and will be sensitive to their needs. Application areas involve ubiquitous\/pervasive computing, resiliency, and quick recovery from nature and man-made disasters, and provision of safety services for a better quality of life for the elderly and disabled. Using the capability of wireless communication to connect the physical world to the cyber-world presents other advantages, such as monitoring bridges, roads, tunnel structures, water quality, control of temperature of the home according to the presence and location of people, etc. On the educational front, the equipment helps students to better understand the intricacies of radio propagation through experimentation and measurement; moreover, a course will be upgraded and undergraduate students will be involved.","title":"CRI: IAD Equipment for Cross-Layer Wireless Protocols Design and Prototyping","awardID":"0709044","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}}],"PIcoPI":["518182"],"PO":["557609"]},"125878":{"abstract":"Intellectual Merits. <br\/>The characterization of land cover and usage over large geographical regions, as well as the near\/long-term forecasting of changes in land use, is a key problem in geo-informatics that is particularly important for regions that are subject to rapid ecological changes or urbanization. At present, the data and knowledge required for detailed and accurate characterization is scattered across both traditional (GIS) spatial data sources and across remotely sensed data, and their associated models, none of which inter-operate well. This research will develop a comprehensive framework for efficient and accurate mapping, monitoring and modeling of land cover and changes in usage over large regions. This endeavor involves three complementary activities: (i) large scale classification of remote sensing imagery using advanced learning methods, including transfer learning, active learning and manifold based data descriptors; (ii) next-generation spatial modeling using ensembles for forecasting land transformations; and (iii) integration of GIS and remote sensing data by distributed, privacy aware learning, integrating taxonomies obtained from different data sources and portal building. A plan of interaction with various stakeholders is proposed to ensure that the results are meaningful and actionable. This project will result in substantial advances in analysis of remotely sensed data over extended regions and lead to a substantial reduction in the uncertainty of long-term forecasts of change. Concurrently, the chosen application domain will also provide a concrete setting that motivates several new data mining problems, leading to new algorithmic formulations and solutions that benefit the broader data mining community. <br\/><br\/>Broader Impacts. <br\/>This project is designed to have many, diverse broader impacts. First is the involvement of application scientists in the remote sensing and modeling communities who will benefit from advanced methods in machine learning. The research results will be brought into the classroom through new graduate courses. Popular science lectures for middle and high school are also planned since the subject matter and results can be conveyed meaningfully to this audience in a visual way that emphasizes issues of broader concern, such as the impact of ecological changes and urban sprawl. Two project-wide workshops are proposed that will also involve stakeholders (e.g., planners) who would directly benefit from the results and provide valuable feedback. A portal will be created in year 3 to provide access to data, code and toolkits produced by the project. Results will be disseminated in each of the three main disciplines represented within the project through scholarly publications. Finally, tools will be developed so that they may eventually be incorporated into Commercial Off The Shelf software, such as GIS and remote sensing software.","title":"III-CXT: Collaborative Research: Advanced learning and integrative knowledge transfer approaches to remote sensing and forecast modeling for understanding land use change","awardID":"0705815","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["485856"],"PO":["469867"]},"134007":{"abstract":"This research attempts to identify and measure the effect of perceptual and contextual features on sketch recognition, and use these results to create effective classifiers to recognize low level shapes and constraints that will identify all possible interpretations along with a ranking for use by higher-level recognition systems. Contextual features to be examined include whether users are drawing or viewing a shape, whether users are viewing the beautified or hand-drawn shape, accompanying hand movements, domain knowledge, and accompanying shapes in the diagram. User studies in perception will determine how geometric features co-vary and how shapes should be varied to agree with human perception. <br\/><br\/>Graphical diagrams are an important part of the educational process. Unfortunately, they are time-consuming to correct and are usually omitted from the testing process despite evidence that testing aids in learning of subject material. Sketch recognition systems can be built to recognize hand-drawn diagrams, but they currently take a long time to build and require expertise in sketch recognition. This project has the potential to provide foundational work that could lead to the development of a tool to allow instructors, without sketch recognition expertise, to build their own sketch recognition tools. Further, this project proposes to build geometric primitive and constraint recognizers based on perception and context to make the creation of sketch recognition systems more intuitive for non-experts in sketch recognition by better matching computer-based recognition to perceptual and contextual expectations. The results from this project will be implemented in the LADDER\/GUILD technologies to 1) improve recognition results, making the sketch recognition systems more useful for instructors, and 2) improve automatic generation of shape descriptions to simplify sketch system creation, making it more practical for instructors to use the system.","title":"Developing Perception-based Geometric Primitive-shape and Constraint Recognizers to Empower Instructors to Build Sketch Systems in the Classroom","awardID":"0744150","effectiveDate":"2007-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["492700"],"PO":["388678"]},"126505":{"abstract":"Proposal #: CNS 07-08199 07-08464<br\/>PI(s): Gupta, Rajiv; Gupta, Neelam Zhang, Xiangyu<br\/>Institution: University of Arizona Purdue University<br\/> Tucson, AZ 85721-0001 Wes Lafayette, IN 47907-2108<br\/>Title: IAD: Advanced Infr for Generation, Storage, and Analysis of Program Execution Traces <br\/><br\/>Project Proposed:<br\/>This collaborative project, developing an open source software infrastructure that is capable of tracing and analyzing long program executions, features customizability, extensibility, and most importantly, the capability of collecting prolific types of execution traces for realistic executions on single- and multi-threaded programs. The work is feasible due to the fact that, at present, checkpointing\/logging can be effectively combined with tracing through a technique called Execution Fast Forwarding (EFF) that enables scaling up tracing by orders of magnitude and availability of a highly compacted trace representation called Whole Execution Trace (WET) composed of static program representation that is annotated with dynamic traces including control flow, address, value, and a dependence trace that can contain complete program execution history in compacted form. Components of the infrastructure include<br\/>. Checkpointing\/logging environment that will execute a given binary on the supplied input to produce a set of checkpoints and logs which can be used to replay the execution;<br\/>. Execution fast forwarding components that will eliminate part of the execution that is not relevant to reproducing a given event;<br\/>. Tracing component to generate, compress, and store the WET (Whole Execution Trace) of a replayed execution interval; and<br\/>. Trace analysis component to provide an API that will enable users to access WET's with ease, without having to understand the low level detailed representation of WET.<br\/>Dynamic analysis techniques analyze traces of program executions to characterize the runtime behavior of programs. Distinctive runtime characteristics are then exploited in designing the systems to <br\/>. Develop highly reliable systems by detecting bugs, locating faults, and testing programs; <br\/>. Develop secure systems by detecting information leaks and unsafe behavior, and performing software marking; <br\/>. Validate and verify data by associating the output produced by highly complicated data processing procedures to the raw input data that can greatly facilitate verification of results;<br\/>. Develop hardware and software for highly optimized systems (e.g., embedded systems that must optimize performance, power, & memory usage) exploiting a wide range of runtime program characteristics (e.g., recurring code sequences to achieve compression, narrow width data to develop energy efficient cache designs & pipelines, etc.). <br\/><br\/>Broader Impacts: The infrastructure enables rapid prototyping for data verification, computer architecture, compilers, embedded systems, software engineering such as building testers and debuggers, security such as designing watermarking and information flow analysis tools. The uniform representation of logs and WETs provides standard interface to easily exchange traces. Moreover, encouraging synergy among projects, course projects will be designed and provided with the infrastructure.","title":"CRI: IAD An Advanced Infrastructure for Generation, Storage, and Analysis of Program Execution Traces","awardID":"0708464","effectiveDate":"2007-09-01","expirationDate":"2010-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["550848"],"PO":["557609"]},"125669":{"abstract":"Humans naturally use dialog and gestures to discuss complex phenomena and plans, especially when they refer to physical aspects of the environment while they communicate with each other. Existing robot vision systems can sense people and the environment, but are limited in their ability to detect the detailed conversational cues people often rely upon (such as head pose, eye gaze, and body gestures), and to exploit those cues in multimodal conversational dialog. Recent advances in computer vision have made it possible to track such detailed cues. Robots can use passive measures to sense the presence of people, estimate their focus of attention and body pose, and to recognize human gestures and identify physical references. But they have had limited means of integrating such information into models of natural language; heretofore, they have used dialog models for specific domains and\/or were limited to one-on-one interaction. Separately, recent advances in natural language processing have led to dialog models that can track relatively free-form conversation among multiple participants, and extract meaningful semantics about people's intentions and actions. These multi-party dialog models have been used in meeting environments and other domains. In this project, the PI and his team will fuse these two lines of research to achieve a perceptually situated, natural conversation model that robots can use to interact multimodally with people. They will develop a reasonably generic dialog model that allows a situated agent to track the dialog around it, know when it is being addressed, and take direction from a human operator regarding where it should find or place various objects, what it should look for in the environment, and which individuals it should attend to, follow, or obey. Project outcomes will extend existing dialog management techniques to a more general theory of interaction management, and will also extend current state-of-the-art vision research to be able to recognize the subtleties of nonverbal conversational cues, as well as methods for integrating those cues with ongoing dialog interpretation and interaction with the world.<br\/><br\/>Broader Impacts: There are clearly many positive societal impacts that will derive from this research. Ultimately, development of effective human-robot interfaces will allow greater deployment of robots to perform dangerous tasks that humans would otherwise have to perform, and will also enable greater use of robots for service tasks in domestic environments. As part of the project, the PI will conduct outreach efforts to engage secondary-school students in the hope that exposure to HRI research may increase their interest in science and engineering studies.","title":"HRI: Perceptually Situated Human-Robot Dialog Models","awardID":"0704479","effectiveDate":"2007-09-01","expirationDate":"2008-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7632","name":"HUMAN-ROBOT INTERACTION"}}],"PIcoPI":["388677","515704"],"PO":["565227"]},"127517":{"abstract":"This research project enables next generation dialogue systems to be able to collaborate with a user without the limitations of system-initiative interaction, in order to solve complex tasks in an optimal manner. The research develops reinforcement learning (RL) strategies to learn dialogue policies that are mixed-initiative. The specific aims of this are to (a) extend RL to mixed-initiative dialogue interaction; (b) allow the system policy to adapt to different user types, such as people with poor memory, or poor problem-solving skills; and (c) simultaneously learn the policy for the simulated user. <br\/><br\/>This approach will allow more advanced dialogue systems to be deployed, such as assisting the elderly so they can live independently longer, and helping provide health care information to rural areas. The proposed research project will result in a toolkit that will allow a wide range of users to easily develop dialogue policies. The toolkit will (a) allow students to be effectively trained in this area, (b) lower the barrier for other researchers to contribute to the field, and (c) help transfer this new technology to industry.","title":"HRI: Learning Mixed-Initiative Dialogue Strategies","awardID":"0713698","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["551154"],"PO":["565227"]},"127429":{"abstract":"Abstract<br\/><br\/>In this project, we will develop novel methods to enable inference in large-scale graphical models, emphasizing the construction of models of unstructured environments from a vast number of sensor measurements. Creating models of the world from large amounts of noisy sensor data is an inference problem of vast proportions for which current methods do not scale up well. In keeping with the most recent literature, we model such inference problems using graphical models. However, in contrast to the literature we use factor graphs rather than belief nets, and show that there is a close and hithereto under-exploited connection between Factor Graphs and the sparse linear algebra literature. This connection enables cross- fertilization between inference in graphical models and sparse linear algebra. In particular, we will develop a novel graphical model paradigm, the BayesTree, inspired by the representations used in the so-called multifrontal factorization methods from sparse linear algebra.<br\/><br\/>In terms of intellectual merits, these developments are novel and are expected to significantly advance the areas of large-scale mapping and 3D modeling in the fields of robotics and computer vision. <br\/>However, we expect these new classes of algorithms to have broad impact beyond robotics in vision, in every fields where vast amounts of data needs to be processed and condensed in a parametric model. We expect the new graphical language we introduce to significantly improve understanding of exact inference in graphical models, as we feel this has been largely inaccessible but to advanced researchers in the field. By stressing the connections between the modest Gaussian elimination algorithm from linear algebra and more advanced inference methods such as the junction tree algorithm, we hope to enable a new generation of researchers that will truly understand these connections and hence be able to make revolutionary contributions in many fields.<br\/><br\/>Progress reports will be regularly updated at http:\/\/ www.cc.gatech.edu\/~dellaert\/graphs\/","title":"RI: Inference in Large-Scale Graphical Models","awardID":"0713162","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["485377"],"PO":["429182"]},"130971":{"abstract":"Complexity problems in cross-layer optimization for wireless sensor networks have rekindled interest in the quest for a distributed algorithm that would simultaneously handle routing, task assignment, and information fusion, scale gracefully with the network size, and display resilience to node failure. Although various obstacles to this goal remain, belief propagation, and its close cousin expectation propagation, provide many attributes that such a distributed algorithm would require. Indeed, recent works attest to the potential of belief propagation for such tasks as network averaging, node detection, network diagnostics, routing, and even missile defense. This collaborative research project brings together researchers in statistical inference and wireless communications to (i) rephrase random sensor deployment strategies as a sparse dependency structure among parameters; (ii) advance expectation propagation as a distributed algorithm to harmonize many sensor network tasks; (iii) extend convergence results from iterative decoding to inference in sensor networks; and (iv) open novel design and optimization tools in sensor networks as by-products of the work.<br\/><br\/>In particular, the investigators show how common network inference tasks, including intruder detection, sensor localization, and channel estimation, can be viewed as particular instances of the expectation propagation algorithm passing messages between network nodes. Message passing here consists of soft information exchange, reminiscent of the mature field of iterative decoding. Convergence tools of iterative decoding, including density evolution and EXIT chart analysis, are extended to the network inference problems under consideration. Additional insights and new design tools for sensor networks emerge as natural by-products, ultimately targeting the inference capacity of such networks, and how this capacity may be optimized versus sleep strategies and energy consumption.","title":"Collaborative Research: Distributed Estimation in Wireless Sensor Networks via Expectation Propagation","awardID":"0728521","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["564924"],"PO":["564898"]},"129519":{"abstract":"Research has shown that Heterogeneous Sensor Networks (HSNs) can significantly improve the performance of sensor networks. To achieve better performance, we adopt an HSN model consisting of a small number of powerful high-end sensors (H-sensors) and a large number of low-end sensors (L-sensors). The objective of this project is to investigate innovative network architectures of HSNs, and develop energy-efficient, self-healing schemes and routing protocols for HSNs. We plan to build an integrated research and education program. The research components of the project consist of the following two parts: <br\/>. Investigating efficient and robust network architectures of HSNs.<br\/>We will investigate innovative network architectures for two different types of HSNs: HSNs where the locations of H-sensors are controllable and NOT controllable. We will determine the optimal density of H-sensors and L-sensors, and the optimal locations of H-sensors to minimize the cost of sensor nodes while ensuring a network lifetime and coverage requirement. We propose a novel Density-Varying-Deployment scheme for H-sensors. We will also design robust clustering schemes that can tolerate H-sensor failures and provide reliable network structures.<br\/>. Designing self-healing and energy-efficient schemes and routing protocols for HSNs.<br\/>The primary functionality of wireless sensor networks is to sense the environment and transmit the acquired information to a base station for further processing. Thus, routing is an essential operation in sensor networks. Typical sensor nodes are small, unreliable devices with limited energy supply. The routing protocols should be energy-efficient and robust to sensor failures, and be able to find new paths when nodes fail. By utilizing powerful H-sensors, we will design self-healing, energy-efficient routing protocols for HSNs which take into consideration of data fusion. <br\/>The research is tightly coupled with an educational program that includes the following four themes, <br\/>1) Mentoring graduate and undergraduate students, and recruiting students of underrepresented groups in North Dakota and Tennessee to participate in the project. <br\/>2) Developing a new graduate course-Wireless Sensor Networks. <br\/>3) Field study of sensor networks. Sensor networks have been deployed in several farms in North Dakota for agricultural monitoring and several chemical\/nuclear plants in Tennessee for hazard monitoring. We will take students to the farms and plants to study how to improve the performance of these real sensor networks by applying our research results. <br\/>4) Integrating research and education together by setting up a Heterogeneous Sensor Network Lab. <br\/>The Intellectual Merits include:<br\/>1) In this research, we will develop innovative network architectures for two different kinds of HSNs, i.e., the locations of H-sensors are controllable or not. <br\/>2) We will design energy-efficient and self-healing routing protocols for HSNs, which are robust to node failures and prolong network lifetime. <br\/>The Broader Impacts are:<br\/>Recruiting students of underrepresented groups, including female, low incoming, first generation, Native American, and African American students in North Dakota","title":"NeTS NOSS: Collaborative Research: Towards Robust and Self-Healing Heterogeneous Wireless Sensor Networks","awardID":"0721980","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[343194],"PO":["564777"]},"130664":{"abstract":"Collaborative Research: Single Molecular Devices for Molecular Nanocomputing: Synthesis, Device Fabrication and Theory<br\/><br\/>As the current silicon complimentary metal-oxide-semiconductor (CMOS) technology continues to increase the speed, capacity and computational power of modern computers, it approaches the fundamental limit at which processors can no longer be made smaller, faster and cheaper. This collaborative project will investigate single-molecule electronic devices as fundamental building blocks for molecular nanocomputing, an emerging technology for the next generation of information systems beyond CMOS integrated circuitry. By bringing together the complimentary expertises in organic synthesis (the Yu group at the University of Chicago), device fabrication and electrical characterization (the Tao group at the Arizona State University), and nanoscale theory\/modeling (the Oleynik group at the University of South Florida) into a synergistic effort, the team will focus on the development of innovative computer technologies at the atomic and molecular levels using fundamental principles of nanoscience and engineering. This high-risk, high-return area of research promises revolutionary advances in developing faster and smaller computer chips beyond conventional silicon CMOS technology.<br\/><br\/>The research program includes three major thrusts: (1) to synthesize new \"designer\" molecules that will function as diodes, transistors, switches and information storage elements and with the help of theory\/modeling to establish a structure\/property relationship between a molecule's chemical nature and resulting electronic properties. (2) to assemble these \"designer\" molecules into nanocircuitry using STM, conducting AFM, and electrochemical break junctions for electrical characterization of single-molecule devices, and to control the electron transport in these molecules using electrochemical gating combined with the guidance from theory. (3) to develop fundamental operational principles of specific molecular devices using the theory of electron and hole resonant tunneling conduction, and to investigate molecule\/electrode contacts, negative differential resistance switches, molecular field effect and bipolar transistors. The tightly coupled, vertically integrated research and educational activities will provide a unique opportunity to nurture the next generation of scientists and engineers who will put the science beyond Moore's law into practice.","title":"Collaborative Research: Single Molecular Devices for Molecular Nanocomputing: Synthesis, Device Fabrication and Theory.","awardID":"0726897","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["538954"],"PO":["565223"]},"133832":{"abstract":"The project investigates the effectiveness of a dedicated ITenabled collaboration space, a collaboratorium, for stimulating multidisciplinary research, pedagogy and collaboration. Technologies such as immersive video for teleconferencing\/surveillance and Radio Frequency ID tags will create an open yet secure studio and playroom for agile development by students and faculty in multi-disciplinary courses such as ?Innovation and Invention in IT? and in extracurricular interdisciplinary projects. The physical wiki so created will be a shared collaborative environment for creation of tools and technologies that can support further creativity and collaboration. It will be a laboratory for investigating how creative multidisciplinary interaction leads to technological innovation, how a technology-enabled environment can attract multidisciplinary collaborators, facilitate their activities and inspire creativity, research, and learning. It will also be a showcase, within the Institute and beyond, of tools and practices used most effectively by participants.","title":"SGER: Collaboratorium for Interdisciplinary Creativity","awardID":"0743114","effectiveDate":"2007-09-15","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":[355949,"564189"],"PO":["424970"]},"132864":{"abstract":"The goal of this collaborative exploratory research project (0738652, Clement Yu, UIC and 0738727 Weiyi Meng, SUNY Binghamton) is to investigate the potential benefit of a dictionary-based approach for document retrieval. This project aims to demonstrate within one year that within a given domain, the use of multiple dictionaries (both domain specific dictionaries and general dictionaries) will obtain high retrieval effectiveness. The demonstration will be facilitated using existing TREC query and document collections. Rules for adding semantically related terms to queries that can yield high retrieval effectiveness within the selected domain will be identified. These rules will be carefully analyzed to obtain fundamental insights for the gain of effectiveness achieved due to the use of the dictionaries. This project is also to seek evidence that certain dictionary constructs (e.g., the frequency of use of a word in a context) can lead to significant gains in effectiveness if they are added to a dictionary. The research results from this project will lay the foundation in achieving longer-term goals that include the identification of domain independent principles of using different types of dictionaries in the same system, and the development of tools to add useful dictionary constructs across dictionaries and to assist users in query expansion semi-automatically when there are multiple dictionaries. It is expected that the proposed project can have a significant impact on search engine technology, including retrieval in specialized domains such as law and medicine, question-answering, blog retrieval and analysis, and enterprise search. Research results will be incorporated into several courses the PIs teach and students will be recruited to participate in the research activities. Research results will be disseminated through published papers as well as a textbook on Web-based search technology. The project Web site (http:\/\/www.cs.binghamton.edu\/~meng\/DocRetSGER.html) provides access to research results.","title":"SGER\/Collaborative Research: Intelligent Use of Dictionaries for Document Retrieval","awardID":"0738652","effectiveDate":"2007-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["389044"],"PO":["563751"]},"133601":{"abstract":"Providing virtual training has become an increasingly important method for training skills that are risky, expensive, or otherwise infeasible to carry out in the real world (e.g., military operations). One long standing question has been how well skills learned in a simulated training environment can be transferred to real world practice. The simulated world differs from the real world in a number of aspects. In particular, there are significant differences in sensory, motor, and perceptual features. Advances in embodied cognitive science have consistently demonstrated how the human body, and the environment which the body inhabits, together form a complex system in producing mental activities. However, most studies that have been reported thus far only examined small incremental differences in cognitive processes as predicted by the embodied versus classic cognitive science. There are few studies that have investigated whether the incremental differences will translate into tangible consequences in learning new skills. The central hypothesis being investigated in this research project is whether there are differences in how people perceive and enact risky versus non-risky actions in the simulated versus the real world. One of the major difficulties in such studies is to create simple parallel task environments that are amenable to controlled experimentation but can be scaled up for real world applications. This research project accomplishes this by selecting everyday actions that can be inherently risky and uses methods that examine the time course in which event perception unfolds. For perceiving actions, participants will perform perceptual segmentation tasks, have their eye movements recorded, and answer questions regarding the memory of actions. For enacting actions, participants will indicate how they would complete the actions. <br\/><br\/>The long-term practical objective of this research is to provide an empirical basis for developers of simulated training environments in the following three areas: 1) determining the appropriate level of specifications for perceptual and sensory information; 2) determining the appropriate level of instructions to either highlight or compensate some of the significant differences that result from enacting actions in the simulated world; and, 3) determining what actions can be learned via simulations versus what actions ought to be learned via real world practices. This research project brings together an interdisciplinary integration of theory and empirical research from the fields of embodied cognitive science, artificial intelligence, human-computer interaction, and robotics. Cognitive psychology has not begun, until recently, to understand how humans spontaneously segment the constant flux of multimodal information into discrete events and exert cognitive control over the ongoing world. This research project goes a step forward towards conceptualizing human and complex machine behaviors in terms of the multimodal segmentations of the incoming world. The better design of simulated environments will result from this understanding and will benefit all of society, in which we are increasingly interacting with technology and being trained in technology driven learning environments.","title":"The Role of Sensorimotor and Perceptual Features in Perceiving and Enacting Actions","awardID":"0742109","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["409690","409691","409689"],"PO":["565227"]},"133612":{"abstract":"Spelman College proposes the ARTSI (Advancing Robotics Technology for Societal Impact) Alliance in collaboration with Florida A&M University, the University of the District of Columbia, Hampton University, Morgan State University, Norfolk State University, Winston-Salem State University, the University of Arkansas-Pine Bluff, Carnegie Mellon University, Georgia Institute of Technology, Brown University, Duke University, the University of Alabama, the University of Washington, and the University of Pittsburgh. Seven of these partners are HBCUs and seven are Carnegie Research I institutions. Their collaboration joins the strengths of HBCUs in conducting outreach and education in a nurturing learning environment with those of the R1's for conducting world class research. The ARTSI Alliance will motivate students to pursue computer science careers by emphasizing the creativity and socially beneficial aspects robotics technology with hands-on projects, curriculum, and media. ARTSI activities will span the academic pipeline from K-12 through the faculty ranks. At the K-12 level, students will be recruited with community outreach using robotics and art, robotics road shows, and a robotics educational film online repository. At the undergraduate level, HBCU students will be exposed to new robotics curriculum, and they will be encouraged to pursue advanced training in graduate school through summer research experiences, collaborative, interdisciplinary robotics projects in the arts and health, instruction in technical film documentation, student virtual film festivals, annual robotics conferences, and instruction in entrepreneurship for computer science. At the faculty level, it will increase the number of HBCU faculty who educate students in robotics and involve students in robotics research by providing faculty mentoring, summer research experiences for underrepresented faculty at R1 robotics labs, robotics summer workshops, and development and dissemination of robotics educational material through a web-based portal. The Alliance will have industry partners, including Seagate, iRobot, Microsoft Research, and Juxtopia, as well as educational partners, including Florida-Georgia Louis Stokes Alliance for Minority Participation and Computer Science Teachers Association.","title":"Collaborative Research: BPC-A: ARTSI: Advancing Robotics","awardID":"0742150","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7584","name":"ITR-BROADENING PARTICIPATION"}}],"PIcoPI":["558854"],"PO":["561855"]},"131676":{"abstract":"The inference problems associated with high-dimensional genomic data offer fundamental challenges for modern statistics, machine learning, and data-mining research. Methods that have had success in this domain impose constraints on models incorporating notions of simplicity, smoothness, or robustness. The constraints are often formalized either as priors for Bayesian methods or as geometric criteria for machine learning methods. The heart of this proposal is to develop and relate the importance of the geometry underlying the data to probabilistic modeling. The specific research foci of the proposal are: 1) The exploitation of geometric assumptions for problems of model uncertainty and variable selection in high-dimensional models; 2) A Bayesian framework for the use of ancillary or unlabeled data in predictive modeling; 3) Theory, methods and computation for nonparametric Bayesian kernel models; 4) Novel methods for nonlinear dimension reduction for high-dimensional data from regularization and geometric perspectives.<br\/><br\/>The proposal develops theory, methods and computational tools for statistical modeling motivated by applications in functional genomics. Modern molecular biology has generated data of a rapidly escalating scale and complexity -- high-throughput genomics data, genetic and sequence information, proteomic and metabolomic data, and other forms of more traditional biomedical or clinical information. Modeling this data for predictive phenotypes of prognosis, diagnosis, and pathway deregulation as well as understanding relevant variables and their associations are fundamental challenges for modern statistics, machine learning, and data-mining research. These methodological developments will have impact on several other scientific areas including biology, engineering, environmental and health science, and social sciences.","title":"Collaborative Research: Probabilistic models and geometry for high dimensional data","awardID":"0732276","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["513688"],"PO":["565286"]},"133865":{"abstract":"This SGER project aims at developing novel methodologies for designing information dissemination and discovery routing protocols to support transaction management in large heterogeneous mobile ad-hoc networks (MANETs), incorporating probabilistic reliability, performance and trust-aware guarantees into its formulation. While mobile ad-hoc networks promise to change the distributed systems communication paradigm and the ways people access and manipulate information, as well as develop applications, the design of such protocols remains a major challenge for MANETs. As their topology changes dynamically, the reliability of links is significantly lower than for fixed infrastructures, resource distribution is asymmetric, the organizational structure is adhoc, and hardware devices and software components are heterogeneous. <br\/><br\/>The impact of this project is very high as the results will enable successful deployment of the next generation of MANETs and the design of highly scalable management systems. These systems will support a wide spectrum of applications ranging from homeland security, emergency and crisis management, disaster recovery, military battlefield coordination, transportation, as well as complex social applications, such as distributed gaming and the management of distributed learning services. This project funds Ph.D students to pursue research in the areas of distributed data management and MANETs. Publications, technical reports, software and experimental data from this research will be disseminated via the project web site (http:\/\/multimedia.ece.euic.edu\/IDD\/).","title":"SGER: Reliable Information Dissemination and Resource Discovery in Mobile Environments","awardID":"0743331","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["406718","532978"],"PO":["469867"]},"132776":{"abstract":"Continuous development and improvement of chip multi-processors (CMPs) is expected to allow the integration of a large number of processor cores on a multicore chip in the near future. Thus, it is extremely important to explore efficient designs for future CMPs to enable such integration to result in scalable performance. This exploratory project investigates heterogeneous CMP design alternatives that leverage from previous research on single core processors to achieve good utilization of core resources, high per core performance, good multicore scalability, and better core yield over CMP designs composed of homogeneous cores.","title":"SGER - Exploring the Future Chip Multiprocessor Designs","awardID":"0738185","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["359600"],"PO":["559883"]},"132666":{"abstract":"Workshop on New Research Frontiers in Shape, Solid, and Physical Modeling<br\/>PI: Hong Qin, SUNY at Stony Brook<br\/>Abstract:<br\/>On June 2-6, 2008, State University of New York at Stony Brook (Stony Brook University) will be hosting<br\/>and co-sponsoring Stony Brook Modeling Week. The Stony Brook Modeling Week comprises two<br\/>prestigious symposia that are being held consecutively, namely, the annual Solid and Physical Modeling<br\/>Symposium (to be held on June 2-4, 2008) and the annual International Conference on Shape Modeling and<br\/>Applications (to be held on June 4-6, 2008). The first of these two conferences, the ACM Symposium on<br\/>Solid and Physical Modeling (SPM) is co-sponsored by the Association For Computing Machinery Special<br\/>Interest Group on Computer Graphics (ACM SIGGRAPH). It is an annual international forum for the exchange<br\/>of recent research results in applications of spatial modeling and computations in design, analysis,<br\/>simulation, and manufacturing, as well as in emerging biomedical, geophysical, and other relevant areas.<br\/>The second conference, the International Conference on Shape Modeling and Applications (SMI) is cosponsored<br\/>by the Institute of Electrical and Electronic Engineers Computer Society (IEEE-CS) and provides<br\/>an international forum for the dissemination of new computational techniques for modeling and processing<br\/>digital representations of shapes and their properties to a diverse community of experts across a wide range<br\/>of areas. These two conferences together traditionally had formed the International Convention on Shapes<br\/>and Solids in 2004 and 2005, respectively.","title":"Workshop Support: Workshop on New Research Frontiers in Shape, Solid, and Physical Modeling","awardID":"0737658","effectiveDate":"2007-09-01","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["416071"],"PO":["532791"]},"135944":{"abstract":"This project addresses fundamental flaws in Internet-routing infrastructure using both theoretical analysis and practical tools. The results not only improve the security of the current Internet, but also advance principles of secure routing design useful for next-generation protocols. The project advocates a different approach than previous work in this area by formally defining comprehensive requirements for protocol security, rather than imposing new technologies to address one or two specific exploits.<br\/><br\/>The Border Gateway Protocol (BGP) provides best-effort connectivity between the component networks of the Internet, a task called interdomain routing. However, BGP lacks any security mechanism, allowing accidental router misconfiguration or intentional attacks that have far-reaching effects on network stability and traffic flow. Furthermore, simply adding security mechanisms is insufficient because BGP also lacks the guarantee that specification-compliant inputs always produce stable routes across the network.<br\/><br\/>This project addresses these shortcomings through research on various assumptions that guarantee good routing behavior and on methods to verify or enforce these assumptions to prevent deviation from that behavior. We identify and address attacks that have previously been studied as well as new attacks that have not yet received attention in the literature. We target incremental-deployment benefits and computational efficiency as primary desiderata; thus, our solutions can offer incentives for immediate adoption without system-wide changes. Through its educational component, our project introduces students to cross-disciplinary research. This encourages collaboration in research projects and allows development of coursework integrating security, networking, and theory for a timely application domain.","title":"Collaborative Research: CT-ISG: Mitigating Exploits of the Current Interdomain Routing Infrastructure","awardID":"0753492","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["478168"],"PO":["565239"]},"131225":{"abstract":"In any technology field, there is always some set of core concepts that dominate the agenda for research and practice. As a field progresses that set evolves, with new concepts replacing old ones. This project will model the dynamic social system through which technological concepts come to be perceived and understood. The primary research question is: How do the actions and opinions of individual actors give rise to more globally accepted concepts in a technology field, and how do such micro-macro dynamics change over time? That question will be answered by using an iterative process in which computational analysis of text is used to populate a model of salient aspects of social dynamics. Interpretations based on that model will then be used to guide refinement and enrichment of the computational analysis. This \"computationally-supported case study\" process offers a promising new approach to building and testing theories for social science research. By coupling focused extraction and classification for high-volume multi-source data with a multi-concept computational analysis strategy the project will create a new middle ground between today's richly analyzed but narrowly focused case studies and the presently available scalable but relatively shallow techniques, such as citation analysis. The project will focus on Information Technology as an exemplar field, leveraging the broad and accessible discourse on that topic found in vast collections of formal and informal sources. Text analytic techniques from information retrieval and computational linguistics will be adapted to detect specific concepts, and to connect those concepts with the people who write about them and with attitudes that those people express. An early goal will be to explain the extent to which the popularity of concepts results from social actors' actions and opinions. Contributions of this research are expected to include a scalable analytical framework that can affordably be extended to a broad range of other technologies, and a deeper understanding of the types of leverage that can be obtained from emerging text analytic techniques to enable new approaches to social science research.","title":"DHB: Scalable Computational Analysis of the Diffusion of Technological Concepts","awardID":"0729459","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7319","name":"HSD - DYNAMICS OF HUMAN BEHAVI"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["543582","547983","508790"],"PO":["565215"]},"135603":{"abstract":"This project is aimed at developing scalable as well as highly efficient techniques for performing Dynamic Information Flow Tracking (DIFT) in multithreaded programs.<br\/>The approach being developed is based upon dynamic instrumention of binaries to perform information flow tracking so that the application source code is not required and applications involving dynamically generated code can be handled. For achieving scalability, a novel strategy based upon the integration of checkpointing logging with fine-grained tracing is being used. Initially the program is executed with logging turned on. When DIFT needs to be performed, the execution of relevant execution intervals is replayed and fine-grained tracing is selectively performed.<br\/>For achieving further efficiency, idle cores on a multicore processor are being used.<br\/>Dynamically, a monitoring thread is generated by analyzing the application binary and the monitoring thread and the application execute concurrently on different cores.<br\/>By achieving scalability and efficiency, the developed techniques can be applied to realistic programs such as server programs. The DIFT techniques are being evaluated in context of following applications: (debugging) bug location and avoidance; (security) software attack detection and location of vulnerability; and (data validation) maintaining lineage of scientific data.","title":"CSR-AES-RCS: Scalable and Efficient Dynamic Information Flow Tracking in Multithreaded Programs","awardID":"0751961","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["549718"],"PO":["493916"]},"122535":{"abstract":"Proposal ID: 0644316<br\/>Title: CAREER: A Synergistic CAD Framework for Nanometer Design and Process<br\/>Integration<br\/>PI: David Pan<br\/>Institution: UT Austin<br\/><br\/>Abstract:<br\/><br\/>After four decades of Moore's Law empowered by CMOS scaling, the semiconductor industry is facing unprecedented design and manufacturing challenges. The industry is stuck with the 193nm optical lithography as the dominant integrated circuit manufacturing process, which is likely to remain so for at least another 5 years, for 45nm, 32nm, and even 22nm technology nodes. A prominent feature of the deep sub-wavelength lithography is its proximity, layout-dependent effect. It is estimated that the lithography and design-related yield losses may contribute to 80% or more of the total yield loss in nanometer designs. However, it is not well captured in existing design flows, from modeling to optimization. <br\/><br\/>This project will develop a synergistic computer aided design (CAD) framework that enables holistic design and process integration. It will resort to the root causes of yield losses by developing a set of design-oriented yet variation-aware manufacturing\/yield models, as well as geometrical and electrical characterizations using predictive virtual silicon images. Thus it will help to eliminate significant amount of uncertainties for yield analysis and optimization. Meanwhile, guided by the modeling framework, novel CAD algorithms will be developed at various abstraction levels and architecture explorations will be performed for multi-objective design\/manufacturing optimizations. The project will further investigate design and process integration issues for emerging technologies such as nanolithography and hybrid CMOS\/post-CMOS processes.<br\/><br\/>The integrated education component of the project will train a diverse body of students in this highly crosscutting and important area, where the intersection and co-evolution of circuit design, CAD and manufacturing create an excellent opportunity for exposing students to multiple engineering disciplines. Taken together in a holistic manner, this project aims at filling the critical gaps between design\/CAD and manufacturing\/process to further extend the scaling and economic benefits of the Moore's Law.","title":"CAREER: A Synergistic CAD Framework for Nanometer Design and Process Integration","awardID":"0644316","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["535167"],"PO":["562984"]},"134877":{"abstract":"The dramatic increase in the availability of data from various sources is creating many fundamental challenges in computing, storage, communication, and human computer interaction issues for data mining. Scientists, engineers, and businesses are faced with problems that involve understanding complex networked observations, massive simulation data sets, and ubiquitous sensory data streams. These heterogeneous data sources should be linked and analyzed for discovering the next frontiers of science, arts, and technology. We also need to look beyond the current cyber-infrastructure and explore how the next generation of networked data mining applications will support such large-scale, ubiquitous, multi-source, and data intensive domains. <br\/><br\/>This workshop on Next Generation Data Mining and Cyber Enabled Discovery for Innovation (NGDM-07) brings together data mining researchers, scientists and engineers from diverse backgrounds along with domain experts for various emerging problems that are relevant to Cyber Enabled Discovery for Innovation (CDI). NGDM-07 focuses on the areas of: data mining in sciences, engineering and digital humanities; data mining for security and surveillance with information privacy and security considerations; multimedia data mining; pervasive computing and ubiquitous data mining; and the web, semantics, and data mining. <br\/><br\/>The interdisciplinary nature of the workshop provides a forum for the participants to cooperatively analyze the state of the art in data mining and its role in CDI and formulate new data mining research directions, and outline development or infrastructure issues and activities that are fundamental in supporting CDI challenges. The workshop participants will also discuss fruitful collaborative and synergistic activities that will foster creation of CDI environments.<br\/><br\/>The workshop will generate a report detailing future directions of data mining research and will suggest promising modalities of research with an aim to foster innovation and technology transfer. The workshop website (http:\/\/www.cs.umbc.edu\/~hillol\/NGDM07\/) also includes links to other relevant material.","title":"Next Generation Data Mining and Cyber-Enabled Discovery for Innovation (NGDM'07) Workshop","awardID":"0748951","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["421169"],"PO":["563751"]},"131005":{"abstract":"Algorithms and Markets<br\/><br\/><br\/>The notion of a market has undergone a paradigm shift with the Internet -- totally new and highly successful markets have been defined and launched by Internet companies such as Google, Yahoo!, Amazon, MSN and Ebay. This, and the availability of massive computational power for running these markets in a centralized or distributed manner, has motivated an algorithmic study of markets. This is the primary focus of the PI's research.<br\/>The PI's research also involves work on some fundamental open problems in the theory of algorithms -- determining the integrality gap of the bidirected cut relaxation for the metric Steiner tree problem and studying the complexity of design problems arising from counting problems.<br\/><br\/>The work on algorithms for markets involves handling the case of concave utility functions, developing distributed models and algorithms for computing market equilibria, obtaining algorithmically-amenable market models for some of the new markets, and developing an algorithm for the Adwords problem assuming a stochastic arrival model for the queries. <br\/><br\/>This research will contribute to the Primary Priority Area, Advances in Science and Engineering (ASE), and will promote Economic Prosperity and Vibrant Civil Society (ECS). <br\/>Its broader impacts involve the training of graduate students and the dissemination of research results via papers, courses, lectures and workshops.","title":"Algorithims and Markets","awardID":"0728640","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["516928"],"PO":["562944"]},"131126":{"abstract":"Localization refers to a set of sensors estimating the precise location of a source using information related to their relative position to the source. This information can be distance, bearing, power level, and time difference of arrival. Localization is a fundamental component of a number of emerging applications, spanning the detection of biological threats, pervasive computing, where locating printers and computers permits a computer to send its print job to the nearest printer, in sensor networks, where individual sensors must know their own positions, and an emerging multibillion dollar wireless localization industry.<br\/><br\/>It is important to ensure that localization occurs in an efficient and time critical manner. This in turn depends on how the sensors are delpoyed. Thus, this study considers the issue of sensor deployment, as well as the development of computationally efficient algorithms that exploit this deployment to achieve efficient and time critical localization. Prior work considers this only from the perspective of the number of relative position measurements that are available for each source. This approach largely ignores the characteristics of the actual algorithms that perform localization. In general linear localization algorithms have poor noise performance, and instead it is better to consider nonlinear algorithms that may have false stationary points. Accordingly, the investigator will provide nontrivial regions surrounding sensors such that should the source lie within these regions then the localization algorithms are globally convergent.","title":"Globally Convergent Localization in Sensor Networks","awardID":"0729025","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["541994"],"PO":["564898"]},"131137":{"abstract":"Systems for information storage, gathering, or communication should be designed with careful attention to how the information will eventually be used. Often data are used without regard to their ordering; e.g., most databases are accessed by searching, and order is irrelevant to statistics like means, medians, etc. The observation that order can be irrelevant is powerful because sometimes ignoring order dramatically improves compression. Remarkably, in some situations the reduction in bits can approach 100%. This project seeks to develop theory, algorithms, and applications for communication when ordering is fully or partially irrelevant. The theoretical aspect includes establishing performance bounds when very little is known about the information source prior to encoding and when ordering is partially maintained. The algorithmic focus is on computationally-efficient algorithms with limited buffering requirements. Lowering the required communication rates in networked data gathering could enable cheaper, smaller and<br\/>lower-power devices and thus hasten the deployment of large-scale and battery-operated sensing systems. <br\/><br\/>The genesis of this project is the following order reduction: Communicating any nontrivial sequence of n (ordered) symbols requires a number of bits that is linear in n; however, disregarding order<br\/>lowers the rate to O(log n) when the source alphabet is finite. Results for universal coding over countable alphabets and rate-distortion problems also show large differences between the<br\/>ordered and unordered communication problems. The project aims to establish fundamental bounds on compressing unordered data (discrete-and continuous-valued sources, with or without full distributional knowledge); develop compression techniques (scalar and vector quantizers, indexing, refinement); and apply data set (as opposed to sequence) compression in practice. Extending the results to partial preservation of order could have important consequences for conventional compression.","title":"Compressing Unordered Data: Theory, Algorithms, and Applications","awardID":"0729069","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["508043"],"PO":["564898"]},"133799":{"abstract":"Fire emergency response teams work in stressful, dangerous environments where effective team cognition can mean the difference between life and death. This research explores the field of non-mimetic simulation. This new form of abstract learning environment is grounded in work practice, yet it does not directly mimic concrete aspects of real life. Mixed reality game designs will be developed to simulate team interactions like those found in emergency response situations. Integrating inexpensive, portable global positioning sensors, wearable computing systems, and direct human-to-human communication, location-aware mixed reality games afford players a high level of immersion through situated embodied interaction that connects physical and virtual worlds. Participants will need to communicate with each other efficiently in order to respond to tough real-time demands. Non-mimetic simulations, in the form of location-aware team game designs, will mirror the information flow and communication structure of firefighting teams without mimicking fire and smoke. Game designs will be based on an ethnography of fire emergency response work, to capture salient abstract features of team cognition stress in practice. Evaluation will be performed with fire emergency response and university students, and will utilize mixed methods, both quantitative and qualitative, that explore participants' ability to coordinate and communicate, and their engagement with the game. Previous reviews of this research identified it to be high-risk, high-payoff, citing the need to to explore the efficacy of the non-mimetic simulation method. The identification of salient abstract features of the base environment that need to be simulated is a new area of research. Further, sensor reception limitations of GPS and Wi-Fi technology, which are known as seams, will need to be integrated into the designs.<br\/><br\/>Fire emergency responders need team skills in order to effectively protect lives and property. This research develops location-aware mixed reality game systems for teaching fire emergency response team cognition stress through non-mimetic simulation. The goal of these systems is to enable learning critical team skills in safe environments. Non-mimetic simulations of team cognition stress may serve as important components of education for all people who work in teams. These include astronauts, air traffic controllers, and all areas of emergency response, including emergency call center operators, police, and paramedics. Further, these simulation methods may be applicable to teams of knowledge workers and students, in science, technology, engineering, math, and other fields. This research will expand our understanding of learning technologies, situated practice, and team cognition, with potentially great impact on the way in which fire emergency response teams, and other types of teams, are trained. Non-mimetic simulation, coupled with embodied interaction, promises to be an interesting and new field of educational research. Furthermore, this research will expand our understanding of the use of mixed reality systems, an exciting mode of human computer interaction that is just now becoming technologically accessible.","title":"SGER: Non-Mimetic Simulation of Fire Emergency Response Team Cognition Stress through a Mixed Reality Game","awardID":"0742947","effectiveDate":"2007-09-01","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["531380"],"PO":["564456"]},"132149":{"abstract":"Id: 0734761<br\/>PI: Kathryn Sanders (Rhode Island College)<br\/>Title: Workshop for Investigating the Issues Involved in Implementing a Data Repository for Empirical CS Education Data<br\/><br\/>This award is for a workshop to discuss the key challenges in constructing and maintaining a repository of empirical computer-science education research data. If the workshop participants respond positively, the workshop will serve as the basis for a larger grant proposal to develop the repository itself. Empirical computer-science education research is a growing field. There is a growing consensus with regard to methods, an increasing number of publications, and even a new conference devoted to the topic. Nevertheless, the research community does not yet have common data sets. Such data sets are widely used in other fields. There are clear advantages to publishing data. If researchers publish their data, other researchers can replicate their analysis. In addition, new tools and techniques for analysis can be developed, once it becomes possible to compare them directly on the same data sets. Nevertheless, there are numerous logistical issues to be solved before setting up such a repository. By gathering members of the empirical computer-science education research community together, the researchers want to determine whether there is interest in such a repository, and if so, begin to build a consensus as to the form it should take. The workshop will produce a report and if the report is positive, then plan to submit a proposal to NSF for development of the repository itself.","title":"Workshop for Investigating the Issues Involved in Implementing a Data Repository for Empirical CS Education Data","awardID":"0734761","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":[351137,"393428"],"PO":["564181"]},"125857":{"abstract":"This project addresses the acute privacy challenge of home-based health care based on ubiquitous computing, or ubicomp, where vulnerable populations risk enforced technological intimacy. It will employ the well-defined \"\"design for values\"\" method to create an innovative toolkit that can be used by our aging population, their caregivers, and designers to ensure privacy and autonomy in home-based ubicomp.<br\/><br\/>Ubiquitous computing integrates technology into our everyday environments, fundamentally altering privacy by creating continuous, detailed data flows. Ubicomp will result in an environment that is aware, active and responsive. It creates an aware environment through the pervasive distribution of sensors. It is active because sensor data are processed and examined. It is responsive in that the technology acts on the environment based on processed data. As ubicomp is networked, the data and decisions have the potential to be observed from any connected locale on the planet.<br\/><br\/>Design for privacy is complicated by the fact that privacy is a socially constructed value that differs significantly across environments and individuals. Currently, design for privacy requires a user who understands the social implications of ubicomp technology, demands a design that respects privacy, and articulates specific technical design requirements. Design for privacy also requires a ubicomp designer with mastery of privacy enhancing technologies, security mechanisms, and a profound understanding of privacy. Neither of these is a reasonable burden. This research will decrease the burdens for both parties.<br\/><br\/>This project will create a system for designing highly customized privacy\u00ac-enhancing ubicomp. The privacy framework that consists of three integrated, complementary components. The first component is a participant tool for eliciting individual elder privacy concerns, making it easy for non-technical people to express privacy concerns. The second is a designer tool that translates elder concerns into technical choices or suggestions. The third is a privacy-enhancing code library for ubicomp sensors that vastly simplifies privacy-sensitive design, including data filtering, access control list creation, and integration of cryptographic privacy enhancing technologies.<br\/><br\/>The broader impacts of the project include: (1) development of multidisciplinary curriculum that will engage over 40 students in the research project; (2) a living laboratory to enable research and curricular activities in business, nursing, health and other disciplines; (3) expansion of the potential for privacy-enhanced home-based healthcare; (4) the development of tools to ensure that older people make their own choices about home monitoring and protection of their privacy and autonomy, and (5) a design tool and code library that enable ubicomp designers to easily embed appropriate privacy-enhancing and strong security-protecting mechanisms in home-based ubicomp without requiring expertise in privacy or security.","title":"HCC: Privacy in Home-Based Ubicomp","awardID":"0705676","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["537066","486499",334027,"409862"],"PO":["564456"]},"125758":{"abstract":"IIS 0705359, IIS 0705215<br\/><br\/>III-COR: Collaborative Research: Mining Biomedical <br\/>and Network Data Using Tensors Christos Faloutsos (christos@cs.cmu.edu) CMU <br\/>Vasileios Megalooikonomou (vasilis@cis.temple.edu) Temple Univ.<br\/><br\/>Given a large collection of functional Magnetic Resonance (fMR) images over time,<br\/>how can one find patterns and correlations? Similarly, given a never-ending stream <br\/>of network traffic information, how can one monitor for anomalies, intrusions, <br\/>and potential failures? The main idea behind this proposal is to treat both <br\/>problems using the theory of tensors. Despite the seemingly wide differences in <br\/>the two settings, they both boil down to finding patterns in multidimensional <br\/>arrays, sparse or dense. Tensors are exactly generalizations of matrices, <br\/>and correspond roughly to ``DataCubes'' of data mining. Matrix analysis <br\/>and decompositions are part of the standard toolbox for data mining, <br\/>providing methods for dimensionality reduction, pattern discovery and<br\/>``hidden variable'' discovery. Extending these tools to higher dimensionalities <br\/>is valuable and tensors provide the tools to do this generalization. <br\/>However, these tools have not yet been put to use in large volume data mining. <br\/>This is the main contribution of this proposal. The investigators propose <br\/>(a) to design tensor decomposition algorithms that scale for large datasets,<br\/>with special attention to sparse datasets, and to never-ending streams of data <br\/>and (b) to apply them on two driving applications, fMRI data analysis and network<br\/>data analysis.<br\/> <br\/>The investigators propose to analyze large volumes of fMRI data performing<br\/>the following sub-tasks: cluster voxels with similar behavior over time for<br\/>a given subject and\/or task or across subjects and\/or tasks, <br\/>classify patterns of brain activity, and detect lag correlations<br\/>and spatio-temporal patterns among fMRI time sequences. <br\/>The investigators also propose to perform the following inter-related <br\/>tasks on multiple GigaBytes of network flow data: anomaly detection, <br\/>pattern discovery, and compression.<br\/><br\/>Both of these applications are important for medicine, health management,<br\/>and for computer and national security. Analysis of fMRI data can help understanding<br\/>how the brain functions, which parts of the brain collaborate with what other parts, <br\/>and whether there are variations across subjects and across task-related activities. <br\/>For the network traffic monitoring setting, fast detection of anomalies is important,<br\/>to spot malware, port-scanning attempts, and just plain non-malicious failures.<br\/><br\/>The educational goals include incorporating the research findings in <br\/>advanced graduate courses at CMU (15-826) and at Temple (9664, 9665)<br\/>and proposing tutorials in leading conferences in databases, <br\/>data mining and bio-informatics audiences.<br\/><br\/>For further information see the web page: <br\/>http:\/\/knight.cis.temple.edu\/~vasilis\/research\/tensors.html","title":"III-COR: Collaborative Research: Mining Biomedical and Network Data Using Tensors","awardID":"0705215","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["409593"],"PO":["560586"]},"126649":{"abstract":"Proposal #: CNS 07-09249<br\/>PI(s): Pena-Mora, Feniosky<br\/> Contractor, Noshir S..; Forsyth, David A., Murphy; Robin R., von Ahn, Luis<br\/>Institution: University of Illinois - Urbana-Champaign<br\/> Champaign, IL 61820-7406<br\/>Title: IAD:A Pressing Need for Observation, Facilitation and Computer Support of Group Interactions for Advancing US National Priorities-Homeland Security and Economic <br\/><br\/>Project Proposed:<br\/><br\/>This project, planning the development of a Mobile Incident Coordination Laboratory (MICL), addresses the pressing need for effective coordination and collaboration among critical responders to ensure an efficient response to extreme events that threaten national economy and homeland security. Studies reveal two pressing needs: to<br\/>. Improve research tools for observing first responders interactions in complex socio-technical contexts and<br\/>. Develop computer tools and methodologies that support these interactions.<br\/>MICL will consist of six main components: a mobile coordination post built on a truck chassis, a customized light hovercraft vehicle, two personal mobile platforms, two robotic miniature helicopters, two miniature ground robotic systems, and ten personal rugged wearable computer systems. All components will be equipped with robust and interoperable communication hardware, data persistence, and audio\/video capture and processing devices, with related software to securely capture, store, transmit, and provide feedback regarding on-scene data gathering in chaotic environments. Currently, researchers are compelled to use stationary laboratories away from the disaster site to conduct inherently dynamic and mobile research; MICL should facilitate work in location affected by extreme events. This work supports <br\/>. Understanding of underlying principles, adequate uses of IT and appropriate algorithms that govern interaction among diverse responders and organizations;<br\/>. Integration of secure data models & communication frameworks that support group interactions in extreme conditions;<br\/>. Development of a computer infrastructure to support interactions among first responders to reduce the negative impacts that extreme events have on homeland security and national economy;<br\/>. Integration of many academic areas including civil engineering, architecture, computer science, sociology, business, education that focus on interactions of key users in chaotic contexts, bringing real-world challenges.<br\/><br\/>Broader Impacts: Addressing needs benefiting national security, this infrastructure provides first responders aid to address critical issues such as security and vulnerability, along with expertise to prepare, respond, and recover from disaster. Moreover, it addresses education and training in this vibrant area.","title":"CRI: IAD - A Pressing Need for Observation, Facilitation and Computer Support of Group Interactions for Advancing United States National Priorities--Homeland Security and Economic","awardID":"0709249","effectiveDate":"2007-09-01","expirationDate":"2010-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1631","name":"CIVIL INFRASTRUCTURE SYSTEMS"}}],"PIcoPI":["457204","532398","508612","530563","565226"],"PO":["388678"]},"127518":{"abstract":"Improvisation is a hallmark of highly productive face-to-face discussion that leads to innovative news ideas or insights. Despite the importance of improvisation, computational tools to support discussion have focused on supporting a fixed repertoire of activities such as multiple choice assessment, idea gathering, ranking, or concept mapping. To support the moves involved in improvisation, we theorize the need for playful, participation-oriented technologies. Such technologies must be highly flexible and support a range of representations, e.g., not just text but sketches and domain-specific notation. Meta-processes for improvisation impose an orthogonal requirement: the need to reflect on artifacts from new perspectives and then transform them into new representations. This project investigates roles that technology can play in a particular form of agile performance called \"\"disciplined improvisation.\"\" In this work we will (1) develop a theoretical framework for supporting disciplined improvisation, (2) adapt a prototype classroom tool called \"\"Group Scribbles\"\" for the context of disciplined improvisation, and (3) investigate methods for iteratively evaluating systems for their degree of support for disciplined improvisation.<br\/><br\/>Ultimately, this project aims to shed new light on how technology can assist us in real-time as we learn and solve problems with the people around us. We anticipate that our findings will lead to better software and hardware for classroom teachers and discussion facilitators more generally. This work builds on prior research into Computer Supported Cooperative Work, but breaks new ground by studying how computer-based tools can support the twists and turns of live performance.","title":"HCC: Supporting Disciplined Improvisation During Face-to-Face Discussion","awardID":"0713711","effectiveDate":"2007-09-01","expirationDate":"2010-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[338158,"524325","558256",338161],"PO":["565227"]},"127408":{"abstract":"The goal of this research project is to develop efficient and practical methods for the management, measurement, and visualization of privacy in computer systems and networks. The approach consists of: designing a framework for protecting sensitive information in online transactions; formulating quantitative measures of the effort required to infer individual private information from statistical aggregate data; and visualizing the private information disclosed in online activities as well as threats to privacy. The linked educational effort addresses the teaching of privacy concepts in introductory computer science courses. The results of the project enable the deployment of Internet applications with strong privacy assurance for users and service providers. These results are disseminated on the project Web site<br\/>(http:\/\/www.ics.uci.edu\/~goodrich\/projects\/privacy\/).","title":"IPS: Collaborative Research: Privacy Management, Measurement, and Visualization in Distributed Environments","awardID":"0713046","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7486","name":"INFORMATION PRIVACY & SECURITY"}}],"PIcoPI":["521484"],"PO":["565136"]},"129509":{"abstract":"Prevention of jamming attacks is critical to the successful deployment of ad hoc or mesh networks. The objective of this project is to consider the problem of jamming in a holistic way and design a framework towards coping with these attacks. The framework will unify the functionalities of deterring, detecting, and alleviating the effects of jamming. <br\/><br\/>Unlike previous efforts this research will (a) exploit physical layer capabilities such as the tunability of power\/rate and the use of smart antennas to cope with jamming and (b) design solutions that are based on strong experimental foundation. Furthermore, the design will seek to address jamming attacks by not only external adversaries but also internally compromised nodes that send large volumes of seemingly legitimate data. The project will encompass the following tasks: (i) Extensive experiments to understand the impact of jamming and identification of behavioral traits during a jamming attack. (ii) Design of methods to obfuscate traffic patterns such that the jammer will be unable to target important nodes or locations in the network (iii) Use of the experimental knowhow in the design of the framework for detecting jamming attacks and (iv) Exploiting physical layer capabilities such as rate\/power and smart antennas to cope with attacks. <br\/><br\/>This research is expected to broadly impact successful future deployments of vehicular and municipal ad hoc\/mesh networks. It will also be tightly knit with educational programs that will augment wireless teaching laboratories and introduce cross-disciplinary courses that bridge the physical and higher layers.","title":"Collaborative Research: NeTS:WN : Coping with Jamming Attacks in Ad hoc \/ Mesh Networks","awardID":"0721941","effectiveDate":"2007-09-01","expirationDate":"2012-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["550738"],"PO":["557315"]},"131732":{"abstract":"The 15th IEEE International Conference on Network Protocols (ICNP) and associated events, including a workshop on network protocol security, will be held October 16-19, 2007, in Beijing, China. ICNP has traditionally been a single-track 3-day meeting of around 30 paper presentations. The conference has typically attracted an attendance of about 120-125 international participants. The size of the meeting is often noted by the participants as an advantage-big enough to be worthwhile, but small enough to promote higher-quality interactions among the participants than may be possible at larger conferences like SIGCOMM and INFOCOM. At the same time, ICNP ranks high in citation impact. According to CiteSeer, ICNP ranks second only to SIGCOMM among networking conferences, and ranks in the top 11% of all computer science publication venues in terms of impact. The high impact is a consequence of the consistently high-quality research presented at the conference. This travel grant supports graduate students attending institutions in the United States as well as junior faculty belonging to or serving under-represented groups of computer science researchers. The travel grant program has two components: (1) Outreach to a wider graduate student population; and (2) Outreach to minority faculty or faculty serving minority students (e.g., EPSCOR institutions). About twenty awards to graduate students and ten awards to faculty members will be supported.<br\/><br\/>The objective of the proposal is to widen the audience attending ICNP and, as a result, raise the level of interactions between attendees, and the potential for new collaboration, new investigations, and higher quality research. In addition, this year's conference will be held in China for the first time. By encouraging U.S. participants to attend ICNP 2007, we hope to raise the awareness of U.S.-based researchers of activities taking place in the important China arena, and to foster the understanding and collaboration among the international participants. We believe that support funds by the NSF will be invaluable to enable the attendance of many U.S.-side attendees and to help offset the expenses of foreign travel for these attendees.<br\/><br\/>Broader Impacts. Conference attendance is a crucial part of the life of a researcher. By creating new opportunities for students and faculty-especially those from under-represented groups-to attend a high-quality conference, this project will benefit the research community in several ways. The students and faculty themselves benefit from the opportunity to meet and interact with many other researchers in a favorable setting, and from seeing research presented that may be related to what they are working on, or may inspire them to try a new direction. The research community benefits from the improvement of the students in the pipeline, and the introduction of new researcher perspectives. And everybody benefits from increased diversity of participants attending the conference. The 2007 meeting in Beijing will also bring a unique opportunity for the international participants to learn more about networking research in China.","title":"Student & Minority Faculty Travel Grant Program to Attend ICNP 2007","awardID":"0732475","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["438434"],"PO":["565090"]},"130522":{"abstract":"In conventional digital electronics, binary bits 0 and 1 are represented by different amounts of charge stored in the active region of a device. Switching between bits requires changing the amount of charge, which necessitates a current flow through the device and associated power dissipation. This is a fundamental drawback of charge based electronics. Instead, if binary bits are represented by anti-parallel spin polarizations of an electron placed in a static magnetic field, then switching between bits would simply require flipping the spin without physically moving charges in space and causing a current flow. This can reduce power dissipation in computing machinery by orders of magnitude. In the long run, this allows higher bit density and faster computing speed.<br\/><br\/>This research will be focused on studying single spin based digital computing systems and logic gates. Quantum mechanical calculations will be carried out to show that power dissipation in these gates is extremely small. Spurred by the recent demonstration that organic nanostructures sustain spin memory for a long time (nearly 1 second at 100 K; Nature Nanotechnology, 2, 216, (2007)), quantum dots of organic semiconductors will be fabricated and the spin relaxation times of electrons (T1 and T2) will be measured as a function of temperature to establish the viability of a new computing technology based on spins in self assembled organic nanostructures. Graduate and undergraduate students will be trained in spin based computing, self assembly, magnetotransport measurements, and electron spin resonance spectroscopy. K-12 outreach will be accomplished through the training of 3-4 high school students (9th and 12th grade minority students) through the Richmond Area Program for Minorities in Engineering (RAPME) hosted by the PI?s university every summer.","title":"Single Spin Logic and Matrix Element Engineering: A New Nanoelectronic Computing Paradigm for Ultra Low Power Dissipation","awardID":"0726373","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["541220"],"PO":["565157"]},"130665":{"abstract":"Despite the tremendous improvements in computational power of recent years, machine-vision systems are still far from replicating the efficiency, robustness, and speed of biological systems. A critical difference between organisms and machines lies in the acquisition of visual information. Unlike computers, biological vision systems are not passively exposed to the visual scene. Instead, they actively seek useful information by means of goal-directed behavior. It is a long-standing proposal that forging a tight link between behavior and perception may be critical for developing more efficient machine-vision algorithms. <br\/><br\/>While examining a scene, humans coordinate eye movements with small movements of the head and body. Coordinated head\/eye movements provide 3D information in the form of parallax, the different apparent motion of stationary objects at different distances. To examine the impact of this behavior in 3D vision, this project integrates computer modeling of the visual cortex with experiments in robotic vision and human psychophysics. The specific aims of this project are to: (a) measure the influence of coordinated head\/eye movements on the accuracy of depth and distance judgments in human observers; (b) measure the 3D information resulting from head\/eye movements by replicating human motor activity in an anthropomorphic robot; and (c) model the extraction and the autonomous calibration of the parallax resulting from head\/eye movements in the parietal cortex of macaques. By coupling a neural model of the brain with a robot that replicates human behavior, this research establishes a direct link between human and machine vision studies. It has the potential of providing new insights on the brain as well as opening the way to the development of new algorithms in machine vision.","title":"Active Depth Perception in Primates and Machines","awardID":"0726901","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":[346735,"491424"],"PO":["565223"]},"130445":{"abstract":"FAST ALGORITHMS FOR MODELS OF INCOMPRESSIBLE FLOW<br\/><br\/>Howard C. Elman<br\/>Department of Computer Science and<br\/>Institute for Advanced Computer Studies<br\/>University of Maryland<br\/>College Park, MD 20742<br\/><br\/><br\/>This project concerns development, analysis and testing of efficient algorithms for solving systems of equations arising from models of flow of incompressible fluids. The development of such algorithms is of broad potential use for understanding scientific phenomena and constructing engineering tools involving fluid flows. Examples include biological flows such as blood flow in the heart or veins and arteries; dispersal of environmental pollutants in rivers or groundwater; design of microfluidics devices, which are used in diagnosis of diseases and identification of pathogens in fluids; and atmospheric and oceanic phenomena.<br\/>Understanding such processes through purely experimental techniques is prohibitively expensive or impossible, whereas the use of modelling together with computational solution enables basic understanding of the physics by providing information about quantities such as flow rates, pressures, and concentrations of solvents. This research involves the development of fast computational algorithms that allows models to be resolved quickly and inexpensively by computer simulation.<br\/><br\/>The research is focused on two classes of problems: algebraic eigenvalue problems that arise from analysis of the stability of solutions of the steady-state incompressible Navier-Stokes equations; and linear and nonlinear systems of equations that arise when thermal and chemical effects are coupled with models of incompressible flow. For both problem classes, discretization leads to the requirement to solve a sequence of large-scale linear systems of equations. We study efficient preconditioning techniques for these systems that take advantage of the structure of the problems. In addition to the impact on applied science, development of efficient solvers addresses fundamental mathematical and computational questions such as the impact of mathematical structure on algorithm development and the identification of stable flows in complex geometries.","title":"Fast Algorithms for Models of Incompressible Flow","awardID":"0726017","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["485207"],"PO":["562984"]},"130566":{"abstract":"In this grant supplement to encourage collaboration with Japanese researchers in cyber security, Professor Nirwan Ansari from New Jersey Institute of Technology and Professor Nei Kato from Tohoku University will study these topics that are important for securing next generation networks:<br\/><br\/>(1) Network attack detection technology for next generation networks,<br\/>(2) Energy efficient secure sensor networks, and<br\/>(3) New security technology combined with QoS control scheme<br\/><br\/>Next generation networks are defined in this project as consisting not only the traditional fixed networks but also cellular networks, ad-hoc networks, sensor networks, and even satellite networks. Eventually all communications, e.g., data and voice, will be conveyed on next generation networks; yet, these networks and their usage introduce considerable heterogeneity into networking, which makes difficult seamlessly and securely interconnecting these different networks. In particular, security issues encountered in one type of network are intertwined with those of other networks, thus creating many complicated and difficult issues. Conventional methods are not enough cope with these challenges in next generation networks; new approaches and new concepts are needed.","title":"Supplemental funding request for Strategic International Cooperative Program between NSF and JST: 'Advanced Security Technologies for Next Generation Ubiquitous Networks'","awardID":"0726549","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["550852"],"PO":["529429"]},"134812":{"abstract":"ABSTRACT<br\/><br\/>CISE Special Projects FY07<br\/><br\/>Id: CCF 0748615<br\/>PI: Shirley Ann Becker (Florida Institute of Technology)<br\/>Title: NSF CPATH Southeast Town Hall Meeting<br\/><br\/>The Directorate for Computer and Information Science and Engineering<br\/>(CISE) at the National Science Foundation has initiated a program, \"CISE<br\/>Pathways to Revitalized Undergraduate Computing Education (CPATH)\", aimed at transforming and revitalizing undergraduate computing education on a national scale. The CPATH initiative provides a means of engaging the community in alliances and activities that can shape a positive future for undergraduate computing education.<br\/><br\/>This proposal addresses the pursuit of the CPATH vision as put forth by the CISE in the hosting of a one-day regional meeting to be held in Orlando, Florida in early December 2007. The southeast region of the U.S. will be targeted in reaching out to colleges and universities and other stakeholders to address the issue of revitalizing undergraduate computing education. These stakeholders, inclusive of industry, professional organizations, community colleges, and government, will come together to formulate and implement plans for transforming undergraduate computing education in the United States. The proposed regional meeting, hosted by Florida Institute of Technology, will provide for a collective dialogue to be started regarding the future of undergraduate computing education. The regional meeting will use as a foundation the CPATH initiative to assist participants in developing concrete plans and activities in the revitalization of undergraduate computing education. The regional meeting will provide a venue for building alliances among community participants in the development and implementation of action plans.<br\/><br\/>The regional meeting will be broadly publicized throughout the southeast region with an emphasis on institutions within an easy driving distance of the meeting. The intention is for local and regional participants to come together to pursue the CPATH vision in the revitalization of undergraduate computing education. The outcomes of the regional meeting, from both focus sessions and group sessions, will be disseminated electronically to those attending the meeting. They will also be posted on the NSF CPATH Southeast Town Hall Web site for virtual dissemination throughout the United States.","title":"NSF CPATH Southeast Town Hall Meeting","awardID":"0748615","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[358205],"PO":["564388"]},"132997":{"abstract":"The College of New Jersey proposes a Demonstration Project to broaden participation in computing by exposing Middle School students to the emerging field of interactive journalism. Journalism has undergone a profound shift due to the Internet and now provides a good venue for engaging students who might not see themselves as ?computing types.? Through interactive journalism, these students will have hands-on experience writing, information gathering and analysis, and using digital media, from graphics to still media to animation and video. Underlying both journalism and the computing disciplines are foundational principles of information access and dissemination, fact analysis, process description, and decision-making for results presentation. Balanced presentations of the journalistic processes and the underlying computational thinking, should engage students and dispel many of the misconceptions they may have about computing careers. In addition, this program will help students navigate the culture of a traditional computing classroom, while improving their academic preparation for entry into existing undergraduate programs. Program activities include a weeklong summer Interactive Journalism Institute, follow on activities through the school year, training for teacher and undergraduate mentors, and outreach to parents. The predicted outcomes include increased skill in core computing concepts, increased awareness of requisite skills for computing careers, and increased enrollment in high school courses that lead to careers in computing.","title":"Broadening Participation in Computing via Community Journalism for Middle Schoolers","awardID":"0739173","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7584","name":"ITR-BROADENING PARTICIPATION"}}],"PIcoPI":["471780","498339","498340"],"PO":["561855"]},"133734":{"abstract":"This collaborative research project seeks to explore the applicability of paradigms from the art world to the science of software design. The project will build and evaluate a framework called ARTISAN for service oriented architecture by developing a new model called ?Movie View? to provide an immersive and animated graphical representation for facilitating the design process for Service Oriented Architecture. This shall include ?Movie-Showing,? a form of process modeling for software systems design. The project will implement a prototype to map between story-telling methods, using the Unified Modeling Language (UML) models, and movie-showing methods. An application based on ARTISAN for use in an emergency-response setting shall be implemented as proof of concept. The intellectual merit of the proposal lies in recognizing common elements of the design process in apparently disparate fields and exploring the value of adding a visually rich simulation element to the software design life cycle. <br\/><br\/>The project will incorporate design paradigms from the art and film world into the software design curriculum. A new software engineering course shall be introduced and an existing software engineering course modified for using and evaluating ARTISAN. The didactic component will feature guest lectures on design in art and film, and carefully chosen projects that experiment with incorporating enabling features of these external paradigms. The didactic component of the project will give participating students the skills necessary to be the leaders of the next generation of software system designers.","title":"SGER: ARTISAN - Art Inspired Service Oriented Architecture Design","awardID":"0742666","effectiveDate":"2007-09-15","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7652","name":"SCIENCE OF DESIGN"}}],"PIcoPI":[355687,355688,355689,355690,355691],"PO":["565227"]},"134977":{"abstract":"Historically, recommender systems have primarily been concerned with recommending items to users, for example, books and movies. More recently, explicit social recommender systems have emerged, which can be categorized as social-matching (i.e., recommending individuals to each other either online or face-to-face) or social-interaction-space matching (recommending various social venues such as club meetings, political events, or online chat rooms). Researchers have begun to lay clear intellectual foundations for the exploration of the former, but not the latter. In fact only a handful of these systems have been deployed and none has used real-time models or hybrid recommendations of physical or virtual spaces.<br\/><br\/>The proposed project will examine the utility of various social-interaction-space recommendation system designs through rapid prototyping and evaluation in both the field and laboratory. This core components model will be achieved through an exploration of the character of chat-channel recommendations for large complex online (AustNet IRC network) and physical (NJIT campus) spaces. The ultimate goal is to build and sustain community that will result in the development of design guidelines and a theoretical framework that will inform system developers and HCI\/CSCW researchers.<br\/><br\/>Broader Impacts<br\/>Using computer technology to improve people's navigation of their social environment so that they can easily coordinate with others in activities of interest is a simple way to improve social connectivity and social capital. This is an important concern, as individuals embedded in richly connected social environments are better able to handle personal setbacks such as financial failures and illness, provide social support for others, and advance their career. Local communities and neighborhoods that have high levels of social interaction are more likely to engage in collective action, and support economic development. Systems that increase such interactions are therefore of enormous social value. This SGER will enable the exploration of a largely untested way to improve social navigation, namely deploying synchronous (near real time) social-interaction-space (chat rooms, meeting rooms, clubrooms, lecture halls, etc.) recommender systems. The project will also benefit the research community through the release of usage data from the field trials (in a suitably sanitized form) and open source software applications. Finally, the novel profiling matching algorithms and privacy mechanisms developed for this class of systems, and understanding of determinants of use of such systems, will be applicable in the government and business sectors, as well as in academia.","title":"SGER: Synchronous Social-Interaction-Space Recommender Systems: Core Components Model Development and Assessment","awardID":"0749389","effectiveDate":"2007-09-15","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["538322"],"PO":["388678"]},"131105":{"abstract":"The next generation of wireless standards are aimed at providing high speed communication to mobile users. Two of the most promising technologies that can dramatically increase the information rate without the increase of power or spectrum are those that exploit multiple antennas and finite-rate feedback from the receiver to the transmitter. The benefit of side information at the transmitter is significant in regimes that happen to fit the requirements of high speed downlink communication by mobile devices, where there are more transmit than receive antennas. Among the post Third Generation wireless technologies, most of them, such as WiMax, Super3G\/LTE (Long Term Evolution), 802.11n, employ MIMO-OFDM technology. It is anticipated that this research will lead to methods for significantly increased spectral efficiencies in these technologies.<br\/><br\/>The proposed research is on wireless communications ranging from its fundamental underpinnings in information theory to the analysis and optimization of novel and practicable communication architectures that exploit a few bits of feedback per channel realization. Mechanisms exist for providing finite-rate feedback and methods by which the wireless channel fluctuations can be exploited with this feedback will be investigated. Because of the enormous potential of multi-antenna systems, the fundamental limits with finite-rate feedback, namely ergodic and outage capacities, will be characterized and low complexity methods with near-optimal performance will be designed and analyzed for multi-antenna (MIMO) communication for single- and multi-carriers (OFDM) systems. The nature of the problems which are at the heart of the proposed research demand collaboration across the fields of information theory, quantization, error-correction coding, random matrices and large deviation theory. This research is expected to also motivate new mathematical discoveries that are expected to find broader applications in other areas.","title":"Multi-antenna Communications with Finite-Rate Feedback","awardID":"0728955","effectiveDate":"2007-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":[348039,"508378"],"PO":["564924"]},"133536":{"abstract":"SGER: Perceptually-inspired Algorithms for Shape Processing and Abstraction<br\/>Doug DeCarlo<br\/>Rutgers University<br\/><br\/>Abstract<br\/><br\/>When an artist draws a particular shape, they omit, distort and abstract various aspects of its structure to make it more recognizable and understandable. For instance, cartographers simplify shape details on maps to make them easier to use. In accomplishing this, artists use their own eyes to judge the effects of their decisions, in order to reach a successful depiction. Computers don't have this luxury and must approach this differently. <br\/><br\/>This research develops a computational approach to processing and abstracting shape that is based upon models of human visual perception. Our system can thus make predictions about what shape the viewer will see, and can therefore make effective depictions of simplified or distorted shapes. Our approach processes shapes in terms of local symmetries, and organizes them into a collection of perceptual parts. Certain parts are removed and manipulated in order to produce the desired abstract depiction of the original shape.","title":"SGER: Perceptually-inspired Algorithms for Shape Processing and Abstraction","awardID":"0741801","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":[355043],"PO":["532791"]},"122536":{"abstract":"This research project investigates models and methodologies for designing and managing multi-core processor resources under the extreme manufacturing variations and in-field hard failures projected for near future technology generations. These phenomena are governed by laws of probability and can be appropriately handled by methods that address the underlying uncertainty. Synergistic hardware and system software elements play a central role in achieving these goals through design forecasting, resource provisioning, self-discovery, and autonomic management. Hardware will be designed to support adaptation and in-field monitoring. System software will read in situ sensors, apply statistical inference, and use on-line learning strategies to build run-time knowledge about on-chip resources. This knowledge will be used to tune the processor for performance, power, and reliability.<br\/><br\/>Manufacturing variation and operational stress will make it increasingly difficult to benefit from raw technology scaling and will potentially limit the commercial and societal impact of computing in the billion transistor era. This research addresses these challenges by enabling the design and management of efficient, reliable, multi-core processors. This project will have educational impact through research training of graduate students and incorporation of research findings into existing undergraduate and graduate courses. Members of underrepresented groups will benefit from mentoring efforts and will be active participants in research.","title":"CAREER: Hardware\/Software Support for Probabilistic Architectures","awardID":"0644332","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["485831"],"PO":["366560"]},"134999":{"abstract":"Tabletop 2007, the 2nd IEEE International Workshop on Horizontal Interactive Human-Computer Systems, will be held in Newport, Rhode Island on October 10 -12. The workshop, sponsored by the Institute of Electrical and Electronics Engineers, has become a leading and uniquely focused forum for the presentation and discussion of research and practice relating to the design of tabletop systems, which is an emerging subfield of human computer interaction. The aim is to share research methods and results in order to advance tabletops as a platform for further development. Research papers typically cover all manner of topics related to tabletop computers: input and interaction methods, hardware design, usability testing, augmented reality and 3D interaction; multi-surface system design, gesture-based system design, multi-modal methods, tangible user interfaces, auditory user interfaces, collocated and distributed collaborative systems, development tools, interfaces and experience design, and ubiquitous computing and smart environments. These topics are examined in a variety of settings and user populations, including children and education, command and control (such as military and homeland security), design and entertainment, health care, home and family, the workplace, and special needs populations. The organizers expect that Tabletop 2007 will bring together approximately 100-150 professionals and researchers, product vendors, users, and other interested parties from around the world, to share information and advances in tabletop computing. Research reports published in the workshop proceedings are heavily refereed and widely cited.<br\/><br\/>Inclusion of a large number of graduate students in the conference is a key to making it a success for years to come. The Student Volunteer Program, though new to Tabletop, is modeled after similar programs that have proven successful elsewhere in providing a means for promising graduate students to attend the conference at a significantly reduced cost in exchange for providing minimal services to the conference such as help with equipment setup and registration. The goals are to build a cohort group of new researchers who will then have a network of colleagues across the world, to guide the work of these new researchers by giving them access to senior experts in the research field who can coach them and give advice, to provide encouragement and support for the selection of interactive system design research topics, to make it easier for promising new entrants into the field to attend their research conference, to illustrate the interrelationship and diversity of Tabletop research, and to make the new entrants' experience at the Tabletop workshop an enjoyable and rewarding experience so as to encourage them to return in future years. Participants will have full access to all conference events. They will be selected on the basis of materials submitted by applicants in response to a call for participation, but the PI will make special efforts to recruit graduate students from historically under-represented groups.<br\/><br\/>Broader Impacts: The Tabletop Student Volunteer Program will bring together the best of the next generation of researchers in the design of tabletop systems. It will provide an opportunity both for the students' research to be shaped and improved through intellectual exchange, as well as for the students to discuss and communicate the character of their work to a key group of their peer professionals. It will also allow them to create a social network both among themselves and with several senior researchers, which plays a major role in their enculturation into the profession. This is especially critical for PhD students in Tabletop research, which is highly interdisciplinary. Because the students and faculty are a diverse group across several dimensions (scientific discipline, academic background, and research specialization), the students' horizons are broadened at a critical stage in their professional development.","title":"Tabletop 2007 Student Volunteers","awardID":"0749493","effectiveDate":"2007-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["519872"],"PO":["565227"]},"131127":{"abstract":"The diverse functions performed by a living cell during her life cycle are controlled and regulated through complicated gene- and protein- interaction networks. Any pattern of irregular behavior of genes in the network can lead to cell malfunctioning, cell death, or the emergence of diseases like cancer. It is therefore of crucial importance to recognize erroneous gene interaction patterns and compare them to those in healthy cells. For this type of study, one of the most frequently used bioengineering systems is the well known DNA microarray device. DNA microarrays consist of grids of spots containing unique genetic identifiers for each of the tested genes, capable of generating snapshots of gene activity in terms of selective DNA sequence annealing. Microarrays have also found many other applications in the field of molecular biology, most notably for the purpose of detecting hostile microbial agents in food, water, and in the air. One of the main drawbacks of current microarray designs is that they are, for the purpose of whole genome studies, severely underutilized; similarly, for biosensing applications, existing microarray systems cannot be used for simultaneous identification of a large number of microorganisms and their strains due to technological limitations.<br\/><br\/>The investigators study novel array architectures, termed compressed sensing DNA microarrays. The research involves finding DNA probes that serve as group identifiers for classes of microorganisms; designing sparse sensing matrices for DNA group identifiers; developing compressed sensing reconstruction algorithms capable of handling saturation effects arising due to high agent concentration levels; characterizing the fundamental trade-offs between distortion and sensor dimension for non-linear arrays; and, analyzing the complexity of integrating compressed sensing microarrays into existing biosensor networks.","title":"Collaborative Research: Design and Analysis of Compressed Sensing DNA Microarrays","awardID":"0729029","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["486456","560640"],"PO":["564898"]},"131028":{"abstract":"\"Biochemical reactions in vivo are regulated by elaborate control circuits that modulate their activity in response to internal and external signals. The RNA world hypothesis suggests that such sophisticated biochemical organization can be achieved with nucleic acids alone, and indeed DNA and RNA have been shown to provide a versatile construction material for engineering molecular structures and devices, including catalytic and logical control elements as well as small circuits. The design of biochemical circuits is likely to play as large a role in biological engineering as the design of electrical circuits has played in the engineering of electro-mechanical devices, motivating the development of methods to construct large and complex circuits of nucleic acid gates for digital and analog tasks.<br\/><br\/> In this project, the investigators will integrate previously developed nucleic acid circuit components into a unifying design framework, develop improved circuit components, construct circuits of increasing complexity, and develop a compiler that takes an abstract specification of (analog or<br\/>digital) circuit function and produces a biochemical implementation using automatically-designed DNA molecules. Example circuits include amplifiers, oscillators, latch memories, a chemical Rossler attractor displaying chaotic dynamics, and a digital circuit for binary addition.\"","title":"EMT: Toward Large Scale Integrated Nucleic Acid Circuits","awardID":"0728703","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["558957","549568"],"PO":["565223"]},"131039":{"abstract":"The design of efficient wireless networks presents exciting challenges which are markedly different from their counterparts in wire-line networks. Of particular interest is the perceived vulnerability of wireless networks to security attacks. Ensuring network robustness against various types of security threats is, therefore, one of the important design objectives.<br\/><br\/>This project adopts a new optimistic perspective in which the wireless medium is viewed as a resource instead of a liability. In particular, we identify three principles, namely opportunism, cooperation and feedback by which the wireless channel can be efficiently exploited to counter passive eavesdropping attacks. The first research thrust is dedicated to developing an opportunistic secrecy framework in which the multi-path fading fluctuations are used to create an advantage for the legitimate destination(s) over<br\/>the eavesdropper(s). Our investigations seek to characterize the fundamental limits of opportunistic secrecy and develop low complexity protocols capable of leveraging the corresponding performance gain. The second research thrust aims to: 1) develop novel cooperation strategies inspired by the secrecy constraint, 2)<br\/>derive sharp secrecy capacity results for certain instances of the relay-eavesdropper channel and 3) identify the scaling behavior of cooperative secrecy protocols in large scale hierarchical and ad-hoc<br\/>wireless networks. Finally, the third thrust involves characterizing the fundamental limits of secure communication over closed loop channels and the structure of the corresponding feedback policies in<br\/>the context of memoryless, fading and multi-user channels.","title":"Opportunism, Cooperation and Feedback for Wireless Secrecy","awardID":"0728762","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":[347888],"PO":["564924"]},"125726":{"abstract":"Proposal 0705103<br\/>\"Contextual Investigation of Constraint-Based Dynamic Scheduling\"<br\/>PI: Martha Pollack<br\/>University of Michigan<br\/><br\/>ABSTRACT <br\/><br\/>This project aims to develop techniques for a variety of important scheduling problems that occur frequently, yet are inadequately addressed by current techniques. The research will be done in the context of a particular application--patient scheduling for medical clinics and it will involve a Michigan clinic that works with patients with traumatic brain injury. This application context has three characteristics that make it challenging. First, it is dynamic, in that events, such as patient appointments, as well as constraints on the times of the events change over time. Second, it involves both hard constraints (e.g., that no appointments can be scheduled earlier than a given time), as well as so-called \"soft\" constraints that represent preferences over alternative schedules (e.g., that a particular patient prefers afternoon appointments, or that it is better not to have large gaps between the appointments a patient has on a given day). Third, it is interactive: a human being is responsible for specifying events, constraints, and preferences.<br\/><br\/>To create an effective scheduler, we will extend a well-studied class of constraint-satisfaction systems: Satisfiability Modulo Theory (SMT) solvers. A key goal of this project is to enable SMT solvers to perform optimization efficiently and to develop algorithms for solving sequences of problems in a way that minimizes change across solutions while still producing near-optimal results. The project will also develop interfaces that make it possible for lay users to describe richly expressive constraints and preferences on schedules.<br\/><br\/>The broader impact of the work includes the potential usefulness of the techniques to key applications including clinic scheduling; the exposure of graduate students to contextual research; and the development of real-world problem sets for undergraduate courses.","title":"Contextual Investigation of Constraint-Based Dynamic Scheduling","awardID":"0705103","effectiveDate":"2007-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["370281","370281",333698],"PO":["543539"]},"126947":{"abstract":"The goal of this research project is to develop a novel unified computational framework for data representation, multi-scale material modeling, and visualization of heterogeneous datasets that will support information integration, access and analysis. The technical solution is uniquely founded upon the mathematically rigorous theory of multivariate simplex splines, which have until now remained severely under-explored in data modeling and visualization. The research activities have the following four major themes: (1) the comprehensive study of new important theoretical properties of multivariate simplex splines and key numerical algorithms, with an emphasis on mathematical rigor, efficiency, accuracy, and robustness; (2) the development of new, robust techniques for modeling complex geometry\/topology and representing volumetric multidimensional material distributions over any tetrahedral domains; (3) the development of data visualization technologies for simplex splines; and (4) application of simplex splines to a wide range of problems in modeling and visualization through the algorithm design and toolkit implementation. <br\/><br\/>All of these activities are expected to move us one step closer to our ultimate, longer-term goal of generally promoting volumetric splines as robust, general, and strikingly powerful data modeling approaches for use in information integration and relevant applications. Research results of this project will be disseminated through the project's website (http:\/\/www.cs.sunysb.edu\/~qin\/research.html).","title":"III-COR: Multivariate Simplex Splines for Data Modeling and Visualization","awardID":"0710819","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["416071"],"PO":["563751"]},"137606":{"abstract":"Individuals who are severely paralyzed as a result of spinal cord injuries, stroke, cerebral palsy, etc generally find it extremely difficult to carry out everyday tasks without continuous help. In this research, the PI will develop a new assistive technology to enable individuals who are severely paralyzed to convey their intentions to their environment by accessing a portable computer or personal digital assistant. The PI's approach is based on the observation that the tongue and mouth occupy an amount of sensory and motor cortex in the human brain rivaling that of the fingers and the hand. As a consequence, the tongue and mouth are inherently capable of sophisticated motor control and manipulation tasks with many degrees of freedom. The tongue is connected to the brain via the hypoglossal nerve, which generally escapes severe damage in spinal cord injuries. Tongue muscle is similar to heart muscle, in that it does not fatigue easily. Furthermore, the tongue is not influenced by the position of the rest of the body, which can be adjusted for maximum user comfort. These advantages, coupled with the accessibility of tongue movements without penetrating the skin, suggest that the tongue might be employed as an excellent intermediate connection to the brain to establish a noninvasive brain-computer interface. The PI will explore this possibility in the current project within the context of a new device called the Tongue Drive System (TDS). TDS consists of an array of magnetic sensors located either inside the mouth (e.g., attached to the outer surfaces of the teeth via an orthodontic brace) or outside of it near the user's cheeks (e.g., mounted on a headset similar to head-worn microphones). The sensor array measures the magnetic field of a small permanent magnetic tracer, the size of a grain of rice, which is attached to the tongue by means of tissue adhesives, implantation, piercing, or clipping. Sensor signals are transmitted wirelessly to the external PC\/PDA, where the data are processed to determine in real time the coordinates, orientation, and relative motion of the magnet with respect to the array of sensors. This information is then used to control the movements of a cursor on the PC\/PDA screen and to perform all other functions that an able-bodied individual can do with a mouse computer input device. The PC\/PDA will have WiFi or Bluetooth connections to a number of other devices, including a desktop computer and powered wheelchair, in the user's environment.<br\/><br\/>Broader Impacts: This research will help the most severely disabled individuals, particularly<br\/>quadriplegics, to lead more active, self-supportive, satisfying, and productive lives. Paralysis is considered to be one of the most expensive types of disabilities. Solutions such as the TDS will help reduce healthcare and assisted-living costs, increase the employability of people with disabilities, and allow users to participate more fully in society while relieving the burden on family members and caregivers.","title":"Tongue Drive: A Tongue Operated Magnetic Sensor Based Assistive Technology For People With Severe Disabilities","awardID":"0803184","effectiveDate":"2007-09-17","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0709","name":"Division of BIOENGINEERING & ENVIRON SYSTE","abbr":"BES"},"pgm":{"id":"5342","name":"Gen & Age Rel Disabilities Eng"}}],"PIcoPI":["561584"],"PO":["565227"]},"125869":{"abstract":"It is estimated that American Sign Language (ASL) is used by up to 2 million people in the United States. Yet many resources that are taken for granted by users of spoken languages are not available to users of ASL, given its visual nature and its lack of a standard written form. For instance, when an ASL user encounters an unknown sign, looking it up in a dictionary is not an option. With existing ASL dictionaries one can easily find what sign corresponds to an English word, but not what English word (or, more generally, what meaning) corresponds to a given sign. Another example is searching for computer files or web pages using keywords, which is now a frequent activity for computer users. At present, no equivalent for keyword search exists for ASL. ASL is not a written language, and the closest equivalent of a text document is a video sequence of ASL narration or communication. No tools are currently available for finding video segments in which specific signs occur. The lack of such tools severely restricts content-based access to video libraries of ASL literature, lore, poems, performances, or courses. The core goal of this research is to push towards making such resources available, by advancing the state-of-the-art in vision-based gesture recognition and retrieval. This poses challenging research problems in the areas of computer vision, machine learning, and database indexing. The effort will focus on the following: developing methods for learning models of sign classes, given only a few training examples per sign, by using a decomposition of signs into phonological elements; designing scalable indexing methods for video lexicons of gestural languages that achieve sign recognition at interactive speeds, in the presence of thousands of classes; creating indexing methods for spotting signs appearing in context in an ASL video database; incorporating linguistic constraints to improve performance of both lower-level vision modules, such as hand pose estimation and upper body tracking, and higher-level learning and indexing modules; and explicitly designing methods that can work with error-prone vision modules that often provide inaccurate or ambiguous outputs. The PIs will create two demonstration systems: an ASL lexicon containing a comprehensive database of ASL signs; and a \"Sign Language Google\" that can search for specific signs in large databases of ASL video content. The systems will be trained and evaluated using thousands of video sequences of signs performed in isolation and in context by native ASL signers. This usage data will be valuable for studying co-articulation effects and context-dependent sign variations. The signs collected will include the full list of ASL signs appearing in the first three years of standard college ASL curricula.<br\/><br\/>Broader Impacts: The methods developed in this project will enable sign-based search of ASL literature, lore, poems, performances, courses, from digital video libraries and DVDs, a capability which will have far-reaching implications for improving education, opportunities, and access for the deaf. These algorithms also aim to enable video-based queries of ASL lexicons, and eventually full-fledged dictionaries with metalinguistic information about signs and examples of usage. By enabling those learning ASL to \"look up\" a sign they do not know, this technology promises to transform the way students of ASL (both deaf and hearing), parents of deaf children, sign language interpreters, and linguists learn about signs they encounter. The algorithms developed in this effort may well lead to more robust ASL recognition systems, which can handle natural signing with a large lexicon of signs and the technology will also advance the state of the art in gesture recognition and synthesis systems. The large linguistically annotated corpus of native ASL produced as part of this effort will itself be an important resource.","title":"HCC: Large Lexicon Gesture Representation, Recognition, and Retrieval","awardID":"0705749","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["475203","472054"],"PO":["565227"]},"133019":{"abstract":"Proposal 0739286<br\/>\"RI: Travel Support for AI in Robotics Workshop\"<br\/>PI: Sebastian Thrun<br\/>Stanford University<br\/><br\/>ABSTRACT<br\/><br\/>This award will help subsidize the participation of seven American scientists in a workshop in Japan on \"cognitive robotics\", that is, robotics that integrates highly sophisticated mechatronic robotics with advanced AI and cognitive modeling. The workshop will bring together experts in mechatronic capabilities--a particularly strong aspect of robotics in Japan--and experts in AI and cognitive modeling--a particularly strong aspect of fifty-years plus of AI research in the United States--to address the problem of cognitive robotics. The workshop will be held Nov.30-Dec.1 at the Keidanren Conference Facility in Gotemba, Japan. While there are great strengths for tackling cognitive robotics in the USA and in Japan, to date there has been little scientific interaction, cooperation, and exchange between the two communities. To facilitate such a fruitful exchange, AFOSR's Asian Office of Aerospace Research and Development, initiated this meeting. This award will help subsidize the participation of seven US scientists in this Workshop.","title":"RI: Travel Support for AI in Robotics Workshop","awardID":"0739286","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[353783],"PO":["387198"]},"126606":{"abstract":"0709048<br\/><br\/>CRI: IAD Research Infrastructure for Emerging Networked Systems and Applications<br\/><br\/>Zhi-Li Zhang<br\/><br\/>The past few years have seen the emergence of large-scale community-driven and peer-to-peer Internet applications and services exemplified by Skype, YouTube, wikis and other Web 2.0 applications. Many of these applications do not rely on centralized servers for their operations or central authorities for management, making trust and security essential to their proper operation and management. In addition, these applications are characterized by demand of large amount of computational, communication and storage resources that must be provided in a decentralized manner on a largely unreliable and untrusted network. <br\/><br\/>The goal of this project is to establish the Minnesota Emerging Networked Systems and Applications (MENSA) Research Infrastructure for advancing research on emerging Internet-scale, community-oriented, networked systems and applications at the University of Minnesota (UMN). This infrastructure supports the research of several PIs at UMN that are addressing the challenges of emerging applications at several levels: from the application to the network and system levels. The PIs bring a unique blend of expertise in networking and distributed systems, grid computing, cryptography and security, data mining and machine learning, and theory. Broader Impact: The MENSA facility also provides an ideal \"hands-on'' learning environment for teaching students important data analysis, system building and experimental skills that are critical for today's IT workforce. In a broader social context, enabling the creation of emerging Internet-scale, user-driven, community-oriented, networked systems and applications, many of which are too futuristic to have yet been contemplated, will bring significant benefit to users and the society at large.","title":"CRI: IAD Research Infrastructure for Emerging Networked Systems and Applications","awardID":"0709048","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["543509","422435","543510","548224","557452"],"PO":["434241"]},"126529":{"abstract":"0708573<br\/><br\/>CRI: IAD ? Computing Infrastructure for Research-Based Learning (CIRBL)<br\/><br\/>John Fernandez<br\/><br\/>Texas A&M University-Corpus Christi (TAMUCC), a Hispanic-Serving Institution (HIS) will build the Computing Infrastructure for Research-Based Learning (CIRBL). The CIRBL vision is to provide computing research opportunities for faculty and students and to enhance the computing education of students of the predominantly Hispanic population of the Coastal Bend region. In order to retain Hispanic students and increase their enrollment, it is imperative that Hispanic students experience a program that is founded on active faculty research and engaging research-based learning. CIRBL will enhance Hispanic education while supporting new and aggressive computing research. The critical objectives of CIRBL are to provide the infrastructure necessary to: a) increase and enhance computing research at TAMUCC, b) involve more graduate and undergraduate students in research, and c) enhance the recruitment and retention of computer science students, especially through research-based learning. In order to raise computing research to a new level, CIRBL includes infrastructure to support new research efforts within the department.","title":"CRI: IAD - Computing Infrastructure for Research-Based Learning (CIRBL)","awardID":"0708573","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7399","name":"CISE MINOR INST INFRA (MII) PR"}}],"PIcoPI":[335702,"559273","528389","444746","533297"],"PO":["565272"]},"124109":{"abstract":"The UCLA Institute for Pure and Applied Mathematics (IPAM) will offer Research in Industrial Projects (RIPS)- Beijing, a summer program for undergraduates, starting in 2007. The goal is to integrate an international research experience with the established and successful RIPS format. The students will gain not only a better appreciation for the applications of math and the demands of industrial research, but will also benefit from an international research experience.<br\/><br\/>Microsoft Research Asia (MSRA) will sponsor five projects, each involving cutting-edge mathematics, at Microsoft's Beijing facility. Ten U.S. students and 10 Chinese students will work on teams of four, with two members from each country. Each team will have a faculty mentor (recruited by IPAM) and an industry mentor (representing the MSRA research group). The students will engage in research for 8 weeks and ultimately present a final report as well as give an oral presentation to the research group. <br\/><br\/>The RIPS-Beijing program will add to the pipeline each year 10 top US students and 10 top Chinese students who will have experienced working at one of the world's most exciting industrial research centers as part of an international team, and experiencing first-hand the power of mathematics to solve important real-world problems. We expect that most of the U.S. students will find this research experience attractive and compelling, and will decide to go on to graduate school and to careers utilizing their capability to work in an Asian setting. The faculty mentors from the U.S. who participate each year will acquire skills in guiding a team and in working in an international setting. The cooperation between IPAM and MSRA in jointly running this program will lay the groundwork for further joint activities as well.","title":"IRES: International Research in Industrial Projects for Students (Beijing)","awardID":"0652051","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7316","name":"EAPSI"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}}],"PIcoPI":["535441","558604"],"PO":["553073"]},"127508":{"abstract":"PI: Song-Chun Zhu<br\/>Institution: University of California - Los Angeles<br\/><br\/>Title: Large Scale Object Recognition and Ground Truth Representation Using Stochastic Image Grammar<br\/><br\/>The proposed project is aimed at three objectives, (1) studying a common representational framework for learning and modeling hundreds of object categories, especially to account for the large intra-category variations; (2) constructing a large ground truth database with a minimum of one million objects annotated semi-automatically for learning and testing; and (3) building a robust large scale object recognition and image parsing system. The core to this proposal is a stochastic context sensitive image grammar for effective visual knowledge representation and robust Bayesian inference. The proposed stochastic image grammar combines the reconfigurability of stochastic context free grammar (SCFG) with the contextual constraints of graphical<br\/>(MRF) models. This stochastic grammar model has strong compositional power for representing large intra-class structural variations and recursive structures for scalable computing, and can be learned from a relatively small sample set. To make the large scale modeling and learning framework practical, the PI has been constructing a large scale ground truth database in collaboration with the Lotus Hill Institute (LHI) in China.<br\/> The current database contains over 500,000 images manually parsed hierarchically using a semi-automatic vision system, in 240 object categories and 20 scene categories. All the data are represented uniformly in a large And-Or graph structure for learning and testing. We propose to continue collecting and annotating up to 1,000,000 images and construct a series of benchmarks during this project period.<br\/><br\/>The proposal develops core techniques for large scale object recognition which can be used as the foundation for building a wide range of applications in commercial and defense industry, such as intelligence image search, security and surveillance, autonomous vehicle, and assisting the blind and visually impaired. The ground truth database shall be the world largest in its detailed parsing and annotation.<br\/>A selected portion of this large dataset will be publicized for learning and benchmark evaluation.<br\/>It is expected to have a significant impact in the vision community, and it may also help researchers studying human perception in cognitive science by providing more realistic stimuli and natural image statistics.<br\/><br\/> Progress of this project will be reported through the following webpage<br\/><br\/>http:\/\/civs.stat.ucla.edu\/Category_Recognition","title":"RI: Large Scale Object Recognition and Ground Truth Representation Using Stochastic Image Grammar","awardID":"0713652","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["546023","456867"],"PO":["564316"]},"129609":{"abstract":"This CPATH project develops, implements and disseminates a transformational model that illuminates new pathways to careers in informatics for new communities. The iCUBED model is based on the notion that levels of engagement in computation can be viewed on a continuum from novice to very technical levels and that students from any discipline and point on the continuum should have courses and programs that meet their needs and discipline interests. The iCUBED model provides the inside reform within the computer science department, the interdisciplinary reform to infuse informatics into various disciplines, and the institutional reform to provide the administrative and infrastructure support for this transformation. The project includes the implementation of a campus wide interdisciplinary informatics minor, student community building and engagement activities, discipline-specific and interdisciplinary workshops, and dissemination on a national level.<br\/><br\/>The intellectual merit of this project lies in the strong research basic for the transformation and the excellent project team with extensive expertise in their disciplines and in educational innovation. The project design includes educational transformation accompanied by institutional change as well as broad community outreach. There is clear potential for a national model to emerge which could inform and enhance the informatics community across the nation.<br\/><br\/>The broader impacts of this project include the outreach to many disciplines and the increased opportunities for students and faculty to involve informatics in their studies and professional careers. The project offers a flexible approach that is cost effective, adaptable, and scalable for any size university. Thus the iCUBED model has the potential to have nation-wide impact by disseminating a model that will change the way faculty and students think about, learn, and practice informatics.","title":"CPATH EAE: iCUBED: Informatics and Computation throughout Undergraduate Baccalaureate EDucation","awardID":"0722327","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["384292",343510,343511,343512],"PO":["564181"]},"130962":{"abstract":"One of the most important obstacles in deployment of high data rate, low cost, and power efficient multicarrier communication systems is the cost of front-end RF amplifiers. Multicarrier modulations offer the promise of low complexity equalization, adaptability to frequency selectivity of the channel, and efficient use of available bandwidth in cognitive networks. However, multicarrier signals consist of linear superposition of many subcarriers leading to large peak to average power ratio (PAPR) and implying the need for highly linear power amplifier. In particular, RF power amplifier becomes substantially power inefficient and expensive when its linearity region increases to accommodate signals with large PAPR. Any nonlinearity introduced by the power amplifier can cause large out-of-band leakage and reduce the transmit range of the link.<br\/><br\/>While the worst case PAPR is quite large, it has been established by the investigators that the likelihood of having large peaks is small and there exist codes of almost full rate with PAPR bounded by a constant. Existing coding schemes, however, provide low PAPR and large minimum distance at the cost of substantially reducing the transmission rate. This research involves addressing both existential and algorithmic aspects of coding schemes for PAPR reduction. This research develops both probabilistic techniques and new algorithms to prove the existence and to construct pragmatic codes that not only provide low PAPR and high rate but also lead to optimizing other parameters such as capacity loss, minimum distance and out-of-band leakage.","title":"Collaborative Research: Low Peak to Average Power Multicarrier Signals via Coding: Fundamental Limits and Algorithms","awardID":"0728484","effectiveDate":"2007-09-01","expirationDate":"2010-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":[347588],"PO":["432103"]},"130523":{"abstract":"DNA Nanotechnology is a branch of science that enables scientists to build nanomechanical devices and regular arrays, using the information content of designed DNA molecules; the components of such species are usually DNA 'tiles' made from molecules designed to branch. The effectiveness and diversity of these constructs can be enhanced markedly by getting the tiles to self-assemble according to logical operations, rather than by a single design. This research involves programming a series of tiles to organize a group of DNA nanomechanical devices according to a given input. The devices consist of two different related types of molecules, so that when one rotates a robot arm in one direction, the other rotates it in the opposite direction, thereby leading to molecular choreography. This choreography will be used to modify the contents of a load carried by a walking device past the robot arms. The importance of this system is that it will prototype programmable molecular-scale assembly lines, capable of algorithmically organizing and relocating potential nanoelectronic components into desired arrangements that will result in useful circuitry.<br\/><br\/>This research involves using TX DNA tiles that correspond to Wang tiles to simulate a finite state machine with output, to design the initial base row for the arrangement. According to the coding of the base row, specific TX tiles and 2-state-device-containing cassettes containing robot arms and PX-JX2 devices are then organized into a 2D array. A walker equipped with cargo will move across the platform that has been organized. The cargo is then modified as a consequence of the computation that creates the array.","title":"Collaborative Research: EMT - Programmable Molecular Movements","awardID":"0726378","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["554823"],"PO":["565223"]},"130644":{"abstract":"Lab-on-a-chip (LoC) technology has enabled miniaturization and integration of conventional bench-scale experiments to a single chip comprising on-chip components, such as channels, valves, and mixers. <br\/>Currently, LoCs are designed as application-specific chips, where a new LoC is designed for every assay by creating and connecting on-chip components to match the steps of the assay. (i.e., n assays need n LoC designs). Unfortunately, this application-specific approach (1) incurs considerable design effort, turn-around time, and cost for each assay and (2) reduces productivity because it requires LoC engineers to know the assay specifics and LoC users to know the constraints of the LoC.<br\/><br\/>To address these limitations, this project will design and prototype a general-purpose, programmable LoC (PLoC) which does not implement any specific assay and instead employs software to translate an assay into an equivalent \"executable\" which is run on the PLoC. The executable breaks down the assay into a sequence of basic steps called \"fluid instructions\", which are implemented in hardware. The set of fluid instructions implemented by a PLoC is called its \"fluid instruction set\", and any assay can be executed on the PLoC if the assay can be translated using the PLoC's fluid instruction set (i.e., n assays use 1 PLoC design instead of requiring n LoC designs). Compared to LoCs, the PLoC has significantly lower design effort and faster turn-around time due to one-time design of a single chip, and lower cost due to economy of volume. The clean separation between hardware and assay achieved by the fluid instruction set and the software translator (called \"the fluidic compiler\") vastly improves the productivity of LoC users and LoC engineers.","title":"Collaborative research: Architecture and Prototype for a Programmable Lab-on-a-Chip","awardID":"0726821","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["550778","471049","518316"],"PO":["559883"]},"130666":{"abstract":"Collaborative Research: Single Molecular Devices for Molecular Nanocomputing: Synthesis, Device Fabrication and Theory<br\/><br\/>As the current silicon complimentary metal-oxide-semiconductor (CMOS) technology continues to increase the speed, capacity and computational power of modern computers, it approaches the fundamental limit at which processors can no longer be made smaller, faster and cheaper. This collaborative project will investigate single-molecule electronic devices as fundamental building blocks for molecular nanocomputing, an emerging technology for the next generation of information systems beyond CMOS integrated circuitry. By bringing together the complimentary expertises in organic synthesis (the Yu group at the University of Chicago), device fabrication and electrical characterization (the Tao group at the Arizona State University), and nanoscale theory\/modeling (the Oleynik group at the University of South Florida) into a synergistic effort, the team will focus on the development of innovative computer technologies at the atomic and molecular levels using fundamental principles of nanoscience and engineering. This high-risk, high-return area of research promises revolutionary advances in developing faster and smaller computer chips beyond conventional silicon CMOS technology.<br\/><br\/>The research program includes three major thrusts: (1) to synthesize new \"designer\" molecules that will function as diodes, transistors, switches and information storage elements and with the help of theory\/modeling to establish a structure\/property relationship between a molecule's chemical nature and resulting electronic properties. (2) to assemble these \"designer\" molecules into nanocircuitry using STM, conducting AFM, and electrochemical break junctions for electrical characterization of single-molecule devices, and to control the electron transport in these molecules using electrochemical gating combined with the guidance from theory. (3) to develop fundamental operational principles of specific molecular devices using the theory of electron and hole resonant tunneling conduction, and to investigate molecule\/electrode contacts, negative differential resistance switches, molecular field effect and bipolar transistors. The tightly coupled, vertically integrated research and educational activities will provide a unique opportunity to nurture the next generation of scientists and engineers who will put the science beyond Moore's law into practice.","title":"Collaborative Research: Single Molecular Devices for Molecular Nanocomputing: Synthesis, Device Fabrication and Theory","awardID":"0726902","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["502725"],"PO":["565223"]},"131645":{"abstract":"The Telluride Workshop on Neuromorphic Cognition Engineering<br\/>Neuromorphic engineers design and fabricate artificial neural systems whose detailed architecture, design, and computational principles are based on those of biological nervous systems. Over the past 12 years, this research community has focused on the understanding of low-level sensory processing and systems infrastructure; efforts are now expanding to apply this knowledge and infrastructure to addressing higher-level problems in perception, cognition, and learning.<br\/>The annual three-week intensive Workshop (held in Telluride, Colorado) consists of background lectures (from leading researchers in biological, cognitive, computational, engineering and learning sciences), practical tutorials (from state-of-the-art practitioners), hands-on projects (involving established researchers and newcomers\/students), and special interest discussion groups (proposed by the workshop participants). For researchers in this community, this is the premier workshop for training students, initiating collaborations, and in-depth discussions on scientific issues.<br\/>In this workshop and through the Institute for Neuromorphic Engineering (INE), the mission is to promote interaction between senior and junior researchers; to educate new members of the community; to introduce new enabling fields and applications to the community; to promote on-going collaborative activities emerging from the Workshop, and to promote a self-sustaining research field.<br\/>Specific Goals for the period of 2007-2012: While there is no question that the Workshop has been very successful in its mission, three new challenges have been identified for the Workshop: 1) with a rapidly expanding community in both the U.S. and Europe, the Workshop experience needs to reach more people without increasing the size of the Workshop, 2) as larger and more challenging projects are tackled, more opportunities for group interactions are needed throughout the year, and 3) as more complex questions are asked at the system-level, more voices from cognitive neuroscience are needed.<br\/>To meet these new challenges, a new version of the Workshop is envisioned with: 1) an expanded theme to focus on Perception, Cognition, and Learning, 2) an expanded constituency, educational mandate and research focus to incorporate members of the NSF Science of Learning Centers (SLC), 3) to create a two-part Workshop series (to allow yearlong collaborations and deeper investigation into large scale projects), one held in the U.S. and funded by U.S. resources and the other held in Europe and supported by European resources and 4) a modified Workshop schedule to emphasize training at the beginning of the workshop to provide a needed focus on education for both beginners and experts alike. The infusion of new researchers (from the SLCs) that focus on learning at multiple scales (from synapses to classroom) will provide the needed knowledge, new collaborations, and new perspectives to move the community towards cognitive-level neuromorphic systems. <br\/>Broader impact of the Workshop to the public: The Telluride Neuromorphic Cognition Engineering Workshop will continue its tradition of public interaction. In particular, there will be a continuation of the educational program for K-12 students (based on neuromorphic\/robotics design kits), undergraduate and graduate students (Workshop courses, new classes\/lectures at participants? universities and REU), and to established researchers (exposure to new areas in the field). The workshop will also continue to educate the Telluride community with public lectures on the latest developments\/issues in the field.<br\/>Recruitment of minorities and women to the field will be continue by organizing lectures at various Universities, particularly HBCUs (Morgan State U., MD, Lincoln U., PA, Morehouse College, Atlanta, GA, and others). By sending presenters to institutions local to their home universities, minimal funding will be required and provide the most likely connections for future collaborations. The Institute for Neuromorphic Engineering, currently housed at the University of Maryland (College Park, MD), will arrange the logistics. The lectures and other teaching materials developed at the workshop will also be made available to all interested parties and posted on the INE website. <br\/>Lastly, the workshop will continue to develop the researchers and leaders for the emerging field of biologically-inspired systems, cognitive\/learning systems, robotics and implantable electronics. Various agencies and governments have recognized that smart devices (such as interactive humanoid robots) that mimic living organisms will have great academic and commercial value in future.","title":"Annual Telluride Workshop on Neuromorphic Cognition 2007-2012","awardID":"0732155","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0400","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"7704","name":"Science of Learning Activities"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7607","name":"ENERGY,POWER,ADAPTIVE SYS"}}],"PIcoPI":["531848","531851","531852"],"PO":["560906"]},"133834":{"abstract":"Ubiquitous pixels is a grand vision shared by many researchers in graphics, vision, and HCI. Conceptually, ubiquitous pixels envisions pixels being lit everywhere and anywhere around the user and are used both as information carriers and interaction agents. A system of ?sea of projectors and cameras? has been identified as the right medium to push the envelope to achieve this vision. But even after a decade, only a small part of the vision has been realized. The reason for this is the complexity of the problem and a common belief that many parts of the problem are intractable. This project involves an analysis of the feasibility of achieving ubiquitous pixels under various conditions of known and unknown display and device (projectors and cameras) parameters. The project will identify the aspects of the problem, if any, that are theoretically intractable as against those that are limited by current technology. <br\/><br\/>Intellectual Merit: The project will identify constraints and guidelines that would make ubiquitous pixels realizable to those on display surfaces, projectors, cameras and other sensors that are used in interactive environments. The project will specify the theoretical constraints that should be imposed on these devices that will make this problem tractable. The project will set a research agenda by identifying the fundamental set of physical features that need to be provided in the device and the environment to make ubiquitous pixels feasible.<br\/><br\/>Broader Impact: The primary long-term impact of this proposal lies in advances made to realize ubiquitous pixels - pixels anywhere and everywhere. Ubiquitous pixels have a tremendous potential to change the way we interact with the environment in the future. Specifically, the project will advance the frontier of research to create pack-and-go high resolution displays where one can pack multiple display units at the back of their car trunk, deploy them on any environment in minutes, dismantle them and take them elsewhere when needed. It can also make advances for next generation visualization, training and simulation systems that are entirely seamless with an order of magnitude greater resolution than current displays (from millions to billion pixels by using hundreds of projectors) and can scale easily to accommodate the incredible rate of the growth of data in the recent years.","title":"SGER: Analysis of Solution Space to Achieve Ubiquitous Pixels","awardID":"0743117","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["472359"],"PO":["565227"]},"131656":{"abstract":"Collaborative Research: Algorithms for Near-Optimal Multistage Decision-Making under Uncertainty: Online Learning from Historical Samples<br\/><br\/>Abstract<br\/><br\/>Recent advances in information technologies enable firms to collect and maintain huge amounts of raw data regarding demand, sales history and other aspects of their operations. However, little is known about using this data effectively and efficiently within their decision-making processes, which can often be modeled as multi-stage stochastic optimization problems. In many application domains, such as supply chain management and revenue management, these give rise to complex problems, where the decision in each stage must be made under uncertainty about the future evolution of an underlying stochastic process. Traditional approaches to these problems assume that the uncertainty is defined through explicitly specified probability distributions that are known a priori; the knowledge of these distributions is crucial to the development of the corresponding optimization algorithms. However, in most practical situations the exact distributions are not known, and only historical data is available. This research project aims to develop a general-purpose sampling-based algorithmic framework for these models that, unlike traditional approaches, uses the raw historical data as the source of samples. First, we plan to develop sampling-based algorithmic approaches to approximately solve complex stochastic dynamic programming formulations, the dominant paradigm used for these problems. Second, we focus on sampling-based algorithms for models that combine optimization and learning simultaneously. A common theme between these two research thrusts, and a central feature of our research project, is the development of explicit quantitative analysis of the performance of our algorithms that provide guarantees on the sample-size needed to assure a specified error bound with respect to optimal solution for the true underlying probability distribution.<br\/><br\/>Consider a firm like Amazon that provides millions of different items to customers throughout the US. Clearly, it is important for the company to have the inventory that its customers want, since if an item is out of stock, then the customer is likely to purchase the item from elsewhere. On the other hand, maintaining extra inventory for undesired items has the disadvantage of tying up capital in obtaining them, using significant resources in warehousing this supply, which is further compounded by the risk of perishability and obsolesce. If one had a crystal ball with which one could predict the future, then the company could know how many requests there will be, day by day, for each of the items it sells, and therefore know how much of what should be on hand in each of its warehouses. Instead, one can model the future probabilistically (similar to what a weather forecaster does when saying that there is a 40% chance of showers tomorrow), and then one can cast the problem of making the optimal decisions for these inventory levels as a problem of maximizing the average profit that can be obtained (or minimizing the average costs incurred), where the notion of average is with respect to the randomness used to model our inability to exactly predict the future. This project has the goal of using past historical data as a means for modeling the predictions for future data, and then designing algorithms that produce provably near-optimal decisions based on this approximation. This type of decision-making in the face of uncertainty arises in a wide range of application domains, from selling different classes of airline<br\/>tickets for a portfolio of flight legs to manufacturing a suite of products that rely on overlapping sets of components. This project focuses on settings in which there are multiple stages of decision-making that must be made in the face of an evolving view of the predictions of future<br\/>requirements. The aim is to provide tools to automate such decision-making with algorithms that are guaranteed to quickly produce reliable solutions.","title":"MSPA-MCS: Collaborative Research: Algorithms for Near-Optimal Multistage Decision-Making under Uncertainty: Online Learning from Historical Samples","awardID":"0732196","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["562312","506614"],"PO":["565286"]},"130567":{"abstract":"Small-scale, few-bit quantum computers have now been realized in laboratories around the world, with technologies ranging from superconductors to trapped ions. However, this new computing technology will only be useful if large-scale machines with thousands to tens of millions of quantum bits can be realized. Because of the inherent high error rate of quantum devices, the key to large-scale quantum computation will be realistic application of fault-tolerance techniques to construct reliable systems from unreliable technologies. <br\/><br\/>Using new ideas from quantum codes, recently available data from implementation technologies, and new concepts for optimization of circuit reliability, this project addresses the challenge of large-scale fault-tolerant quantum computation in three areas. First, the investigators will study the requirements for fault-tolerant encoded operations. Second, the project will explore optimized circuits for quantum fault-tolerant architecture. Third, the investigators will perform a technology performance evaluation to <br\/>determine how well several implementation technologies can realize large-scale fault-tolerant quantum computation.","title":"Collaborative Research: EMT: Novel Operations, Circuit Optimization, and Technology Evaluation for Large-Scale, Fault-Tolerant Quantum Computing","awardID":"0726554","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7928","name":"QUANTUM COMPUTING"}}],"PIcoPI":["486140"],"PO":["565157"]},"130578":{"abstract":"Pattern recognition, as a subtopic of machine learning, is defined as the act of taking in raw data and acting based on the category of the data. This research explores the possibility to analyze outputs from multiple activated sensors using networks of downstream molecular logic gates with adjusted connections, and as a result obtain a classification, that is, a single output of 1 (Action) or 0 (No Action). <br\/><br\/>Logic gates based on nucleic acid catalysts (deoxyribozymes) accept and analyze one or more oligonucleotides as inputs, and produce a response, such as catalytic activity, usually visualized by an increase in fluorescence. The oligonucleotides that serve as inputs for logic gates can be incorporated into oligonucleotide-based recognition regions (aptamers). Such design can be used to construct a purely molecular expert system based on deoxyribozymes and aptamers, which will be compatible with physiological conditions, and will not use electronic components, or human inputs. The eventual goal of this research is to construct autonomous therapeutic molecular devices that recognize and correct changes in metabolic states.","title":"Enzymatic Networks for Pattern Recognition: Basic Principles and Applications","awardID":"0726586","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["459219"],"PO":["565223"]},"133614":{"abstract":"Spelman College proposes the ARTSI (Advancing Robotics Technology for Societal Impact) Alliance in collaboration with Florida A&M University, the University of the District of Columbia, Hampton University, Morgan State University, Norfolk State University, Winston-Salem State University, the University of Arkansas-Pine Bluff, Carnegie Mellon University, Georgia Institute of Technology, Brown University, Duke University, the University of Alabama, the University of Washington, and the University of Pittsburgh. Seven of these partners are HBCUs and seven are Carnegie Research I institutions. Their collaboration joins the strengths of HBCUs in conducting outreach and education in a nurturing learning environment with those of the R1's for conducting world class research. The ARTSI Alliance will motivate students to pursue computer science careers by emphasizing the creativity and socially beneficial aspects robotics technology with hands-on projects, curriculum, and media. ARTSI activities will span the academic pipeline from K-12 through the faculty ranks. At the K-12 level, students will be recruited with community outreach using robotics and art, robotics road shows, and a robotics educational film online repository. At the undergraduate level, HBCU students will be exposed to new robotics curriculum, and they will be encouraged to pursue advanced training in graduate school through summer research experiences, collaborative, interdisciplinary robotics projects in the arts and health, instruction in technical film documentation, student virtual film festivals, annual robotics conferences, and instruction in entrepreneurship for computer science. At the faculty level, it will increase the number of HBCU faculty who educate students in robotics and involve students in robotics research by providing faculty mentoring, summer research experiences for underrepresented faculty at R1 robotics labs, robotics summer workshops, and development and dissemination of robotics educational material through a web-based portal. The Alliance will have industry partners, including Seagate, iRobot, Microsoft Research, and Juxtopia, as well as educational partners, including Florida-Georgia Louis Stokes Alliance for Minority Participation and Computer Science Teachers Association.","title":"Collaborative Research: BPC-A: ARTSI: Advancing Robotics Technology for Societal Impact","awardID":"0742156","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7584","name":"ITR-BROADENING PARTICIPATION"}}],"PIcoPI":["389974"],"PO":["561855"]},"134945":{"abstract":"This is funding to support both a doctoral research symposium (workshop) and the student volunteers program at the 11th International Symposium on Wearable Computing 2007, to be held October 10-12 in Boston, and sponsored by the Institute of Electrical and Electronics Engineers (IEEE). ISWC is a leading international forum for the presentation of research and practice relating to all aspects of wearable systems, including (but not limited to) hardware, battery life, electronic textiles, heat dissipation, sensor networks, software architectures, operating systems, privacy, human interfaces, formal evaluation methodologies, and the use of wearables in augmented reality and training, for the enablement of the elderly and people with disabilities, and for a host of consumer, industrial, medical, and wellness applications. The conferences are typically attended by approximately 250 professionals from around the world, and bring together researchers, product vendors, fashion designers, textile manufacturers, users, and all other interested parties to share information and advances in this highly interdisciplinary field. Research reports published in the ISWC Proceedings are heavily refereed and widely cited. The ISWC'07 Doctoral Consortium, which will take place on October 10, will bring together approximately 10 dissertation-stage doctoral students, for presentations and interactions with a panel of faculty members. The students will come from both the United States and abroad, and represent the best of the next generation of researchers in a variety of ISWC subfields. Because participants are selected chiefly on the grounds of research excellence, their work represents the state-of-the-art; even so, the Doctoral Consortium provides an opportunity for these projects to be shaped and improved through intellectual exchange, as well as for the students to present and communicate the character of their work to a key group of their peer professionals. The Student Volunteer Program, on the other hand, provides a means for promising upcoming researchers who are not yet ready to participate in the Doctoral Consortium to attend the conference and have full access to all activities at a significantly reduced cost, in return for simple services to the conference such as equipment setup and help at the registration desk. The PI will take proactive steps to ensure that for both the Doctoral Consortium and the Student Volunteers Program, participation criteria will include appropriate diversity factors.<br\/><br\/>Broader Impacts: The doctoral symposium will help expand the participation of young researchers pursuing graduate studies in this field, by providing them an opportunity to gain wider exposure in the community for their innovative work and to obtain feedback and guidance from senior members of the research community. It will further help foster a sense of community among these young researchers, by allowing them to create a social network both among themselves and with senior researchers at a critical stage in their professional development. Because the students and faculty constitute a diverse group across a variety of dimensions, including nationality\/cultural and scientific discipline, the students' horizons are broadened to the future benefit of the field. This should in turn improve U.S. competitiveness in mobile personal computing and communications, areas in which Europe and Asia currently hold the lead.","title":"IEEE ISWC 2007: International Symposium on Wearable Computers","awardID":"0749234","effectiveDate":"2007-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["517810"],"PO":["565227"]},"133625":{"abstract":"Spelman College proposes the ARTSI (Advancing Robotics Technology for Societal Impact) Alliance in collaboration with Florida A&M University, the University of the District of Columbia, Hampton University, Morgan State University, Norfolk State University, Winston-Salem State University, the University of Arkansas-Pine Bluff, Carnegie Mellon University, Georgia Institute of Technology, Brown University, Duke University, the University of Alabama, the University of Washington, and the University of Pittsburgh. Seven of these partners are HBCUs and seven are Carnegie Research I institutions. Their collaboration joins the strengths of HBCUs in conducting outreach and education in a nurturing learning environment with those of the R1's for conducting world class research. The ARTSI Alliance will motivate students to pursue computer science careers by emphasizing the creativity and socially beneficial aspects robotics technology with hands-on projects, curriculum, and media. ARTSI activities will span the academic pipeline from K-12 through the faculty ranks. At the K-12 level, students will be recruited with community outreach using robotics and art, robotics road shows, and a robotics educational film online repository. At the undergraduate level, HBCU students will be exposed to new robotics curriculum, and they will be encouraged to pursue advanced training in graduate school through summer research experiences, collaborative, interdisciplinary robotics projects in the arts and health, instruction in technical film documentation, student virtual film festivals, annual robotics conferences, and instruction in entrepreneurship for computer science. At the faculty level, it will increase the number of HBCU faculty who educate students in robotics and involve students in robotics research by providing faculty mentoring, summer research experiences for underrepresented faculty at R1 robotics labs, robotics summer workshops, and development and dissemination of robotics educational material through a web-based portal. The Alliance will have industry partners, including Seagate, iRobot, Microsoft Research, and Juxtopia, as well as educational partners, including Florida-Georgia Louis Stokes Alliance for Minority Participation and Computer Science Teachers Association.","title":"Collaborative Research: BPC-A: ARTSI: Advancing Robotics Technology for Societal Impact","awardID":"0742197","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7584","name":"ITR-BROADENING PARTICIPATION"}}],"PIcoPI":["464114"],"PO":["561855"]},"120337":{"abstract":"ABSTRACT<br\/><br\/>In the proposed work, the PIs will investigate methods to construct a new paradigm for training manual skills using computer-mediated collaboration termed \"Sympathetic Haptics.\" Sympathetic Haptics is a term that PIs have proposed to define technologies that allow a student to \"sympathetically\" feel (in the sense of touch or movement) what another person is feeling when he or she does an activity (for instance, how it feels to play a piano chord, or use a surgical tool). These methods can be used to teach novices how to perform such tasks in the way that an expert does them. Applications and aspects of these advanced learning technologies for Science, Technology, Engineering, and Mathematics (STEM) will be systematically investigated in a variety of domains using test-beds developed as part of this effort. One motivation behind the proposed work is the availability of haptics simulation technologies ranging in scale from simple force feedback joysticks to advanced 6 degrees of freedom (DOF) special purpose haptics devices, along with the software and hardware means for connectivity among these devices. These technologies will allow people to capture, store and communicate various force sensations from individual to individual, and may one day allow people to reach out and touch people, and share physical skills just as one would share videos and audio text messages today.<br\/><br\/>The proposed work will address four objectives: First, it will develop a framework for capturing attributes of force and motion applied by a teacher during skilled manual tasks. Second, it will develop a methodology to transmit and\/or synthetically simulate the patterns of force and motion. Third, and most significantly, the concept of Sympathetic Haptics itself will allow a student to actively track with special assistance, motions made by a skilled teacher, and hence experience the forces and haptics effects involved in executing the skilled task. Fourth, this system will not only allow the student to experience what the teacher recorded, but also allow the student to repeat the process over and over again as a learning tool.","title":"Sympathetic Haptics: Learning Through Computer Mediated Skill Transfer","awardID":"0632618","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1707","name":"ADVANCED LEARNING TECHNOLOGIES"}}],"PIcoPI":[319516,319517],"PO":["564318"]},"131106":{"abstract":"Research Abstract<br\/><br\/><br\/>Multicasting, where common information is transmitted from a source to multiple destinations, is the core component of many network applications such as multimedia distribution, information update, group conferencing, etc. Creative encoding of network trac at the intermediate terminals can significantly improve the throughput of a multicast over conventional replicate-and-forward approaches. Due to the open nature of the wireless medium, communication throughput of a wireless link depends on its transmission power and on the interference generated by nearby network terminals. The goal of this research is to develop a systematic framework for maximizing a general multicast utility function via the joint optimization of transmission power, rate, and schedule, within the framework of network coding.<br\/><br\/>The investigators model a wireless ad hoc network by means of a topology graph, which contains point-to-point links and point-to-multipoint hyperarc links with coupled link throughput capacities. Under the assumption of optimal network coding, the research first develops an iterative gradient-steering\" optimization framework. A network utility maximization problem is converted to a transmission scheduling problem that maximizes an approximated utility in its gradient direction, coupled with a steering vector update that continuously updates the approximated utility and its instantaneous gradient direction. The research then extends the framework to utility maximization for a network with multiple multicast sessions. Finally, the research develops distributed algorithms to optimize a global utility of a large scale network using local controllers. In addition to the planned research, the investigators will also try to extend the algorithm to ad hoc networks with time varying channels where utility maximization requires efficient exploitation of the channel diversity gain.","title":"Collaborative Research: Systematic Optimization in Wireless Multicasting","awardID":"0728966","effectiveDate":"2007-09-15","expirationDate":"2011-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["501350"],"PO":["564924"]},"134747":{"abstract":"This award will support a US-China collaborative workshop to exchange information and develop a research agenda for syndromic surveillance (defined below) within the larger context of infectious disease informatics. The workshop will take place in late 1997 in Beijing China, with attendees consisting equally of US and Chinese researchers and health practitioners, including government and academic experts. A workshop in this topic is appropriate because of increasing concern over the deadly and costly threats of infectious diseases caused by natural disasters or bioterrorism attacks. New methodologies are needed for identifying and tracking emerging infectious diseases and epidemic outbreaks. While traditional disease surveillance often relies on time-consuming laboratory diagnosis and the reporting of notifiable diseases is often slow and incomplete, a new breed of public health surveillance systems has the potential to significantly speed up detection of disease outbreaks. These new, computer-based surveillance systems offer valuable and timely information to hospitals as well as to state, local, and federal health officials. They are capable of real-time or near real-time detection of serious illnesses and potential bioterrorism agent exposures, allowing for a rapid public health response. This public health surveillance approach is generally called syndromic surveillance, which is defined as \"an ongoing, systematic collection, analysis, and interpretation of 'syndrome'-specific data for early detection of public health aberrations.\" The rationale behind syndromic surveillance lies in the fact that specific diseases of interest can be monitored by syndromic presentations that can be shown in a timely manner such as nurse calls, medication purchases, and school or work absenteeism. In addition to early detection and reporting of monitored diseases, syndromic surveillance also provides a rich data repository and highly active communication system for situation awareness and event characterization. Multiple participants provide interconnectivity among disparate and geographically separated sources of information to facilitate a clear understanding of the evolving situation. Researchers from a wide range of backgrounds will participate, including but not limited to epidemiology, statistics, applied mathematics, information systems, computer science and machine learning\/data mining. Approximately 25 individuals will participate.","title":"US\/China Digital Government Collaboration: US-China Infectious Disease Informatics and BioSurveillance Workshop","awardID":"0748308","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["387279"],"PO":["371077"]},"122416":{"abstract":"The grail of next-generation wireless networks is providing real-time services for delay-sensitive applications. Delay sensitive applications such as voice-over-IP, require that the wireless networks provide quality of service (QoS) guarantees, e.g., data rate, delay bound, and delay bound violation probability. However, the unreliability of wireless channels makes it particularly challenging to design QoS provisioning mechanisms for wireless networks.<br\/><br\/>In wireless networking, the area of providing QoS assurance with an emphasis on delay constraints is usually called delay constrained wireless networking. This project is concerned about provisioning statistical delay guarantees. The problem is challenging since both delay-bound violation (caused by queueing) and bit errors (due to channel noise) need to be addressed. To address this challenge, research is conducted in three aspects: 1) theoretic performance limits -- developing a joint coding and queueing approach to addressing the challenging issue of quantifying the probability of both physical-layer bit errors and link-layer delay bound violation, 2) algorithm design -- developing an observer-controller model and a joint estimation\/control approach to designing QoS provisioning mechanisms that explicitly provide statistical delay guarantees, and 3) experimentation -- developing a software-radio-based testbed, implementing and evaluating the algorithms over the testbed.<br\/><br\/>The joint coding and queueing approach will not only yield important principles in design methodologies for delay-constrained wireless networking, but also advance the union of information theory and queueing theory. The research will have a big impact on supporting delay sensitive applications such as mobile TV. The research findings will be disseminated through conferences and journals.","title":"CAREER: Delay-Constrained Wireless Networking: Where Shannon Meets Erlang","awardID":"0643731","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["486052"],"PO":["557315"]},"131007":{"abstract":"Sensor networks are one of the fastest growing network technologies. At the same time, however, they present new challenges. On the one hand, the sensors are given ambitious tasks of computing global properties using constantly changing and geographically distributed data. On the other hand, the sensors are significantly limited in their storage space, computation power, and communication bandwidth. To achieve their goals, sensornets need new theoretical foundations that integrate storage, computation, and communication, and enable the sensornet to pull its various resources together and funnel them toward its tasks.<br\/><br\/>This project aims to create a formal framework for integrating storage, computation, and communication in sensornets. The proposed research assimilates three theories (sketching, property testing and network coding), into a synergetic design that greatly improves the communication throughput, while allowing for cheap computation and reduced storage space. Specifically, the proposed research consists of two components:<br\/><br\/>- Network Sketching: a new architecture for sensornets that performs on-demand in-network compression of the data.<br\/>This approach enables (lossy) compression of spatially correlated data at multiple sensors; manages network congestion by reducing data resolution as opposed to dropping some of the measurements; and naturally combines wireless network coding with sketching to boost the throughput of the wireless network.<br\/><br\/>- Temporally Coherent Property Testing: a new computational model that extends the theory of property testing to a stream of temporally correlated data.<br\/>This new paradigm enables quantifying the complexity of repeatedly checking for a particular property, and reduces the computational needs of sensor networks.","title":"Fast Approximate Algorithms for Wireless Sensor Networks","awardID":"0728645","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":["517766","560190","560189"],"PO":["565251"]},"134329":{"abstract":"With the universal deployment of mobile and cellular communications<br\/>and the proliferation of wireless LAN technology, today's society is becoming<br\/>firmly dependent on wireless networking technologies. As wireless networking<br\/>continues to advance with new services and applications, researchers have an<br\/>increasing interest in understanding the limits of current and future wireless<br\/>networks. To a large extent, many of the performance limits associated with<br\/>wireless networks are deeply intertwined with underlying physical layer<br\/>technologies. From a research perspective, technology advances at the physical<br\/>layer usually introduce new problems at the networking layer that cannot be<br\/>addressed by simply extending existing theories and algorithms. In many cases,<br\/>due to the disruptive nature of new physical layer technologies, problems at<br\/>the network level are extremely challenging and call for the development of new<br\/>theories and algorithms. Such new theoretical developments usually require<br\/>interdisciplinary expertise in networking, wireless communications, algorithms,<br\/>and optimization.<br\/><br\/>The objective of this workshop is to gather a group of researchers from<br\/>multiple disciplines to explore the important issues involved in developing a<br\/>comprehensive future research agenda to bridge the gap between wireless<br\/>networking technologies and advances at the physical layer. A final workshop<br\/>documenting the presentations, discussions, summary, and recommendations of the<br\/>two-day workshop will be made available for public dissemination via a web<br\/>site. Our expectation is that such findings will offer timely input to the<br\/>wireless networking research community, and will have a long-term impact on<br\/>future research.","title":"Workshop on Bridging the Gap Between Networking Technologies and Advances at the Physical Layer","awardID":"0746057","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["564848"],"PO":["434241"]},"125507":{"abstract":"Americans are living longer and more fulfilling lives. They desire to live as independently as possible. But independent lifestyles come with risks, such as debilitating falls and deteriorating health resulting from inadequate care. To address these issues, researchers are developing \"smart home\" technologies to enhance the safety of residents and monitor their health conditions using sensors and other devices. In particular, the continuous assessment of physical function is a key indicator of initial decline in health and functional ability. Identifying and assessing problems while they are still small can provide a window of opportunity for interventions that will alleviate the problem areas before they become catastrophic. In this project, the PI will lead a multidisciplinary team comprised of researchers in computer science and engineering, nursing, and medical informatics dedicated to developing and evaluating technology to keep older adults functioning at higher levels and living independently. They will leverage ongoing research at a unique local eldercare facility (TigerPlace) to study vision-based recognition methods for multi-person environments designed to capture continuous and automated assessments of older adults' physical function. Project objectives include: to collect video data of staged scenarios in realistic multi-person settings using older adult participants, thereby producing a body of labeled data; to utilize the collected labeled data, develop and evaluate algorithms for analyzing video in a way that preserves privacy, extracts the pose sequences of multiple persons, tracks the movement of inanimate objects, and generates assessments and summarizations of the observed activities and physical function; to evaluate the effectiveness of the summarization and assessments by showing the video and extracted information to gerontology experts and obtaining feedback; and to assess the perceptions and attitudes of older adults towards video monitoring by showing them the processed (\"anonymized\") video and extracted information. To achieve these goals, the PI and her team will advance the state of the art in markerless motion capture of human pose and gait, color vision-based object recognition, activity recognition in a home setting, automatic assessment of physical function through passive sensing, and understanding fundamental privacy issues for older adults.<br\/><br\/>Broader Impacts: This research will impact technology, health care, policy, quality of life for older adults, and peace of mind for their families. Advances in technology have implications for other areas, including fitness and physical rehabilitation. These strides will assist health care providers to identify potential health problems and keep older adults independent longer. This, of course, means happier lives for the older adults and their families. Offering a model for eldercare technology may also provide policy makers with information to guide decisions about services for older people.","title":"HCC: Elder-Centered Recognition Technology for the Assessment of Physical Function","awardID":"0703692","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["537126","561794","561792","475599",333153],"PO":["565227"]},"128917":{"abstract":"The Fresh Breeze Project concerns a multi-core chip <br\/>architecture that addresses the need for better programming <br\/>support for parallel computation, including composability<br\/>of parallel programs. This is accomplished by<br\/>supporting global virtual memory, employing a novel memory<br\/>model based on fixed-size chunks, and virtualizing processing<br\/>resources through fine-grain scheduling of threads of<br\/>computation using an on-chip scheduler.<br\/>A cycle-accurate simula\u00adtion of the architecture serves<br\/>for testing and evaluating the architecture in<br\/>illustrative applications.<br\/><br\/>Many functions of a conventional operating <br\/>system relating to memory management, file system support, <br\/>and process scheduling are replaced by hardware features in the <br\/>Fresh Breeze architecture. In consequence, Fresh Breeze <br\/>operating software differs substan\u00adtially from a conventional<br\/>operating system. The Fresh Breeze architecture provides<br\/>special classes of computing objects: futures to support<br\/>data streams and guards to support transactions.<br\/>The Fresh Breeze multithread program execution model is supported <br\/>directly by the Fresh Breeze architecture, so these features <br\/>are available for writing support soft\u00adware for user authentication, <br\/>resource management, input\/output facilities, and directory and<br\/>file management. It is planned to make an FPGA implementation<br\/>of the Fresh Breeze architecture available to interested<br\/>institutions by means of the RAMP prototyping infrastructure.<br\/><br\/>Benefits of the project include the <br\/>possibility of a powerful new computing platform with effective <br\/>support for the development of robust software for parallel <br\/>computing, leading to higher programmer productivity and <br\/>performance. Benefits to the broader community<br\/>include better computing facilities for goals such as<br\/>accurate weather forecasting, drug design, and sustainable<br\/>development.","title":"CSR-AES: User Support Software for a Fresh Breeze Computer System","awardID":"0719753","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["517820"],"PO":["535244"]},"125529":{"abstract":"Tele-immersive environments allow people separated by distance to physically interact and communicate in real time inside a shared 3D virtual environment through the use of large camera networks that enable the capture and reconstruction of 3D images and sound and the subsequent integration of this multimedia data from geographically distributed sites. This project develops and deploys a next generation tele-immersive environment built for the common user who does not have the luxury of expensive supercomputing facilities and dedicated networks. More particularly, the vision of this project is to create a geographically distributed and cost effective tele-immersive environment that facilitates ordinary people performing physical activities in their homes or schools or doctor''s offices or job training facilities under the supervision of a trainer, therapist, or teacher who is not co-located.<br\/><br\/>The broader impact of this project is in facilitating physical interaction and communication of the elderly and persons with disabilities in their homes and work places with relatives, health care providers, and other service providers, in particular whenever they need some interaction during a period of rehabilitation, recovery or training. This project will also examine multimedia distributed communication using common Internet connectivity, which does not require high bandwidth or extremely expensive equipment, and thus may promote wider use of tele-immersive environments.","title":"HCC: Collaborative Research: PHYSNET: Physical Interaction Using the Internet","awardID":"0703787","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["563532","346555","526901"],"PO":["565227"]},"132812":{"abstract":"Proposal 0738341<br\/>\"Exploring the Feasibility of a Virtual Video Archive\"<br\/>PI: Bruce G. Buchanan<br\/>AAAI<br\/><br\/><br\/>ABSTRACT<br\/><br\/>Many early demonstrations of Artificial Intelligence (AI) programs and many lectures of the field's pioneers explaining basic AI topics have been captured on videotape and film, but few of these have been preserved in archival form or have been accessible from a common web portal. This historical record is threatened and vulnerable to loss as time passes because of format incompatibility and deterioration of original materials. For videos that have already been digitized, much work is needed to index and edit materials, so that they are useful to students, teachers, and the public at large, and that the relevant materials can be accessed with much more ease than is the case today, where materials, even if available on the web, are not catalogued or organized in a coherent manner. <br\/><br\/>This project will explore the feasibility of a low-cost plan to collect and preserve the video record of significant scientific events in the history of AI. Information will be collected in a \"virtual archive\" that will contain original tapes and movies critical to the intellectual history of the field. It will be integrated with the current AAAI AITopics portal, which at present contains information on central AI topics (e.g., machine learning, knowledge representation, speech, robotics). AITopics will be re-designed so that both the new video pages and the existing document pages have the same look-and-feel. The project will exploit the 'wiki' model of knowledge sharing to collect information about AI-related videos and to move original videotapes and movies from the hands of individuals into long-term archival storage. In doing so, the project will develop a set of procedures for preservation, and for the growth and use of the website by the community of AI scientists and students.","title":"\"Exploring the Feasibility of a Virtual Video Archive\"","awardID":"0738341","effectiveDate":"2007-09-15","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["550649"],"PO":["387198"]},"130634":{"abstract":"A key challenge before the semiconductor industry is coping with high errors rates resulting from the decreasing size of chip features. Transient faults, along with permanent defects and stochastic assembly, make it difficult to implement traditional architectures. Research has been done on routing around<br\/>defects and coping with large amounts of device variation. Little is known, however, about how to cope efficiently with high-rates of transient errors during computation. This research will take a new systematic approach to the tolerance of transient failures. The goal is to help the semiconductor industry to better understand the dimensions of the nanoscale reliability problem. This research has relevance to space-borne applications where error control can serve as an alternative to radiation hardening. <br\/><br\/>This research employs a sophisticated approach to fault-tolerant computation. First, it exploits differential reliability, that is, it examines the use of a small number of reliable elements to oversee a large number of<br\/>unreliable elements. Second it draws on the success of coding theory to explore both special and general methods to encode inputs and outputs of a potentially faulty computation, paying particular attention to a seminal approach taken by Spielman in 1996. By encoding computations, faults at the encoded outputs can then be detected and corrected. Third, it examines the use of small check computations followed by possible rollback, where most of the checking is done using unreliable elements. Allowing a computation to be<br\/>repeated in time, rather than space, reduces the overhead of fault free computations. The design work is expected to have immediate impact on practice whereas development of a general theory is expected to have a<br\/>longer-term impact.","title":"Collaborative Research: Nanoscale Coded Computation and Storage","awardID":"0726794","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":[346661],"PO":["562984"]},"133802":{"abstract":"The goal of this project is to develop theory and implementation foundations for VGRAM, a technique that uses variable-length, high-quality grams from a collection of strings to support approximate queries on the collection. The research plan includes four tasks: 1)developing methods for VGRAM to decide an optimal set of grams automatically without requiring user-defined parameters, 2)integrating VGRAM into relational database management systems for adoption, 3) using VGRAM to support approximate keyword search in documents, and 4) evaluating VGRAM using two real applications, one for integrating Web information about family reunification and one for integrating medical information. <br\/><br\/>The research results will have significant impacts on society as approximate string queries are needed in many applications, such as data integration and record linkage. This project supports two PhD students to pursue research in the areas of text retrieval and database systems. Publications, technical reports, software and experimental data from this project will be disseminated via the project web site (http:\/\/flamingo.ics.uci.edu\/).","title":"SGER: Answering Approximate String Queries Using Variable-Length Grams","awardID":"0742960","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["385755"],"PO":["563727"]},"130777":{"abstract":"Abstract<br\/>As the demand of error-free data transmission and storage increases, error control becomes increasingly important in data communication and storage systems. Today very sophisticated error control mechanisms are being used in a broad range of communication and data storage systems to achieve reliable data transmission and storage, such as wireless, satellite, optical, digital video broadcast, network communications, hard disc drives, compact disks, and many others. This research is to devise methods for constructing good error control codes and developing efficient error control mechanisms that have great potential to achieve error-free information transmission and data storage for the future generation of data communication and storage systems.<br\/>This research investigates several very promising algebraic methods for systematic construction of binary and q-ary high performance and efficiently encodable quasi-cyclic (QC) LDPC codes for AWGN, random erasure, erasure-burst and error-burst channels. Specical subjects investigated include: (1) a united approach based on nite fields for constructing binary and q-ary QC-LDPC codes; (2) a masking technique that adjusts column and row weights of the parity-check matrices of the constructed codes to yield performance close to Shannon limit; (3) construction of codes for both random and burst erasure channels that<br\/>yield good performance when decoded iteratively; and (4) a new simple algorithm for decoding cyclic codes, including LDPC codes, over error-burst channel. Preliminary results are impressive. The q-ary LDPC codes constructed significantly outperform comparable RS codes decoded with any existing algebraic soft-decision decoding algorithm.","title":"A Unified Finite Field Approach for Constructing Quasi-Cyclic LDPC Codes for AWGN, Binary Erasure, and Burst Channels","awardID":"0727478","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["450215","450216"],"PO":["564924"]},"130546":{"abstract":"Most installed Ethernet backbones based on multi-mode fibers operate at bit rate of about 1Gb\/s, which is inadequate for current and emerging demands. With the advent of high-speed (40 Gb\/s and beyond) fiber optic transmission systems, advanced signal processing and coding schemes for such systems should be carefully designed and optimized in a principled way. Traditionally, optical systems perform a minimal amount of signal processing. Owing to advances in technology, today it is possible to perform sophisticated signal processing functions in optical systems. This could bring enormous flexibility resulting from the opportunity to employ low-cost and adaptive signal processing circuits that is not practical in the optical domain. <br\/><br\/>This project focuses on the development of new design paradigm and advanced algorithms for high-speed fiber optic systems. In particular, it encompasses in-depth investigations on the design of coded modulation schemes, high-speed decoding algorithms, and highly efficient multi-carrier transmission techniques, for very-high speed optical communications. A large arsenal of digital and statistical signal processing tools will be explored, including coset codes, dense lattices, frame theory, and Monte Carlo signal processing. In addition to conducting theoretical analysis, computational procedures will be developed to facilitate the analytical work. The new concepts and algorithms developed under ideal conditions will be tailored to operate in practical systems with various constraints. It is expected that the proposed research will not only enhance our understanding of the fundamental underpinnings of complex fiber optic systems and develop novel signal processing concepts and methods, but also produce new and powerful tools for physical layer solutions for future high-speed optical systems.","title":"Advanced Signal Processing for High-speed Optical Fiber Systems","awardID":"0726480","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["475040"],"PO":["564898"]},"130557":{"abstract":"\"Theoretical Foundations for Reliable Computing in Unreliable Mobile ad hoc Networks\"<br\/>Nancy Lynch, MIT CSAIL<br\/><br\/>This project is developing theoretical foundations---formal models, complexity measures, abstract problem definitions, algorithms, and impossibility results---to explain what can and what cannot be computed reliably in realistic, unreliable mobile ad hoc networks (MANETs). The long-range goal of this work is to provide guidance for building high quality, reliable, high performance applications for such networks. Motivating applications include data management, communication, and coordination (e.g., of people, robots, or vehicles).<br\/><br\/>The assumed MANET model consists of a collection of mobile nodes, moving according to specified constraints. A special ``real world'' component provides the mobile nodes with approximate information about the current time and their own locations. Nodes communicate using local wireless radio broadcast, subject to realistic message delivery constraints. A ``contention manager'' component encapsulates strategies such as exponential backoff, advising nodes about when they are likely to be able to transmit successfully. A ``collision detector'' component provides (possibly unreliable) information to each node about messages that it might not have received.<br\/><br\/>Some problems being studied arise directly from MANET applications. <br\/>Others describe abstractions that are intended to simplify the task of writing applications, such as leader and cluster management services, group membership services, location services, and virtual networks. The need for reliability arises from reliability requirements of the applications and from the need for abstractions with clear guarantees.<br\/><br\/>Results being sought are:<br\/>(1) Definitions of realistic MANET models.<br\/>(2) Definitions of application and abstraction problems with strong reliability requirements.<br\/>(3) Efficient algorithms and corresponding impossibility results for these problems.<br\/>(4) Integration of individual algorithmic results to yield end-to-end guarantees for high-level problems in terms of the basic MANET model.","title":"Theoretical Foundations for Reliable Computing in Unreliable Mobile ad hoc Networks","awardID":"0726514","effectiveDate":"2007-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["517826"],"PO":["565264"]},"130568":{"abstract":"Advances in information technology have resulted in the emergence of new environments, such as mobile ad hoc networks, wireless sensor and actor networks, large-scale Grid and peer-to-peer networks, which in<br\/>essence are constituted by networked autonomous nodes. Although these environments present enormous potential to facilitate new applications and services, they also pose difficult design challenges--these environments are intrinsically dynamic, unreliable, and large scale. Traditional design approaches that assume that the system is composed of reliable components, and\/or that the system is of relatively small scale are not applicable in such environments. In addition, approaches that are based on central and\/or<br\/>explicit control over the system as a whole either introduce a single point of failure or make the system not adaptable, which are not applicable in such environments either. It is therefore critical to explore new design paradigms and approaches that do not suffer from these defects.<br\/><br\/>The phenomenon of self-organization is pervasive in nature, where biological organisms self-organize a large number of unreliable and dynamically changing components to develop diverse functions. In addition,<br\/>these biological organisms possess the desirable properties of robustness to failure of individual components, adaptivity to changing conditions, and lack of explicit central coordination. This research seeks inspiration from the study of swarm behavior in nature, such as slime mold, to design and analyze robust, autonomic networking protocols for the aforementioned environments. This project aims to develop autonomic networking protocols based upon bottom-up modeling of simple, interacting units. The advantage to this approach is that one can reduce the dimensionality of the complex system to a small set of primitive<br\/>functions and parameters governing the simple units that comprise the system. In particular, the investigators seek to model the behavior of slime mold physarum plasmodium to design autonomic networking protocols for wireless sensor and actor networks.","title":"Biology Inspired Autonomic Networking Protocols: Analysis and Implementation","awardID":"0726556","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["538152","528443"],"PO":["432103"]},"130227":{"abstract":"The ORBIT Radio Grid as a Flexible Large-Scale Community Testbed for Next-Generation Wireless Network Research<br\/><br\/>The 400-node ORBIT radio grid facility at Rutgers was developed under the NSF NRT program (2003-07) with the objective of enabling realistic and reproducible wireless network experiments at scale. The ORBIT radio grid was first made available to research users on an informal basis in Oct 2005, and since then, has rapidly become a de-facto community resource for evaluation of emerging wireless network architectures and protocols. ORBIT is also being used as a proof-of-concept platform for validating wireless aspects of NSF?s GENI future Internet infrastructure.<br\/><br\/>This project is aimed at supporting community release of the ORBIT radio grid testbed on a more formal basis. This involves several key technical upgrades necessary to support emerging experimental needs, as well as enhancements to service software and operations staffing necessary for a 24\/7 shared testbed facility. Specific work items to be carried out in this project include:<br\/>? Feature upgrades including support for software-defined radios, improved topology and mobility control, and wired + wireless network emulation.<br\/>? Virtualization of the radio grid to support multiple simultaneous experiments.<br\/>? Improved ORBIT user portal, along with enhanced software and operations support services.<br\/>? ?ORBIT kit? development and establishment of an open-source software repository.<br\/>Major deliverables of the project include community release of the ORBIT radio grid testbed with enhanced technical and service support features in year 2, followed by an upgrade with GNU\/URSP2 software radios in year 3.","title":"The Orbit Radio Grid as a Flexible Large-Scale Community Testbed for Next-Generation Wireless Network Research","awardID":"0725053","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}}],"PIcoPI":["564746","553648","531726",345567],"PO":["565303"]},"133626":{"abstract":"Spelman College proposes the ARTSI (Advancing Robotics Technology for Societal Impact) Alliance in collaboration with Florida A&M University, the University of the District of Columbia, Hampton University, Morgan State University, Norfolk State University, Winston-Salem State University, the University of Arkansas-Pine Bluff, Carnegie Mellon University, Georgia Institute of Technology, Brown University, Duke University, the University of Alabama, the University of Washington, and the University of Pittsburgh. Seven of these partners are HBCUs and seven are Carnegie Research I institutions. Their collaboration joins the strengths of HBCUs in conducting outreach and education in a nurturing learning environment with those of the R1's for conducting world class research. The ARTSI Alliance will motivate students to pursue computer science careers by emphasizing the creativity and socially beneficial aspects robotics technology with hands-on projects, curriculum, and media. ARTSI activities will span the academic pipeline from K-12 through the faculty ranks. At the K-12 level, students will be recruited with community outreach using robotics and art, robotics road shows, and a robotics educational film online repository. At the undergraduate level, HBCU students will be exposed to new robotics curriculum, and they will be encouraged to pursue advanced training in graduate school through summer research experiences, collaborative, interdisciplinary robotics projects in the arts and health, instruction in technical film documentation, student virtual film festivals, annual robotics conferences, and instruction in entrepreneurship for computer science. At the faculty level, it will increase the number of HBCU faculty who educate students in robotics and involve students in robotics research by providing faculty mentoring, summer research experiences for underrepresented faculty at R1 robotics labs, robotics summer workshops, and development and dissemination of robotics educational material through a web-based portal. The Alliance will have industry partners, including Seagate, iRobot, Microsoft Research, and Juxtopia, as well as educational partners, including Florida-Georgia Louis Stokes Alliance for Minority Participation and Computer Science Teachers Association.","title":"Collaborative Research: BPC-A: ARTSI: Advancing Robotics Technology for Societal Impact","awardID":"0742198","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7584","name":"ITR-BROADENING PARTICIPATION"}}],"PIcoPI":["531513","464036"],"PO":["561855"]},"133516":{"abstract":"This is funding to support a doctoral research symposium (workshop) of approximately 8 promising doctoral students from the United States and abroad, along with distinguished research faculty. The event will take place in conjunction with the 20th ACM Symposium on User Interface Software and Technology (UIST 2007), to be held October 7-10 in Newport, Rhode Island, and sponsored by the Association for Computing Machinery's Special Interest Group on Human Computer Interaction (SIGCHI). The UIST conference is the premiere forum for presenting research results and innovations in the software and technology of human computer interaction. It brings together researchers and practitioners from diverse areas that include traditional graphical user interfaces, virtual and augmented reality, multimedia, new input and output devices, CSCW, ubiquitous computing and others. Although UIST is a long-standing annual conference, this workshop will be just the 5th doctoral research symposium associated with the conference (NSF has supported these events from their inception). The three goals of the workshop are to increase the exposure and visibility of the participants' work within the community, to help establish a sense of community among this next generation of researchers, and to help foster their research efforts by providing substantive feedback and guidance from a group of senior researchers in the area in a supportive and interactive environment. Student participants will make formal presentations of their work during the workshop, and will receive feedback from a faculty panel. The feedback is geared to helping students understand and articulate how their work is positioned relative to other research, whether their topics are adequately focused for thesis research projects, whether their methods are correctly chosen and applied, and whether their results are appropriately analyzed and presented. Student position papers will be published in the UIST Conference Companion, and the students will also present posters relating to their work at a special session the first night of the conference. <br\/><br\/>Broader Impacts: The doctoral symposium will help expand the participation of young researchers pursuing graduate studies in this field, by providing them an opportunity to gain wider exposure in the community for their innovative work and to obtain feedback and guidance from senior members of the research community. It will further help foster a sense of community among these young researchers, by allowing them to create a social network both among themselves and with senior researchers at a critical stage in their professional development. Because the students and faculty constitute a diverse group across a variety of dimensions, including nationality\/cultural and scientific discipline, the students' horizons are broadened to the future benefit of the field.","title":"WORKSHOP: UIST 2007 Doctoral Symposium","awardID":"0741721","effectiveDate":"2007-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["506686"],"PO":["565227"]},"131217":{"abstract":"Abstract <br\/>This major inter-disciplinary research effort will use virtual worlds as an exploratorium to theoretically extend and empirically model the dynamics of group behavior. In the process it will develop novel computational techniques for analyzing large-scale networks, which will have applicability across a wide variety of domains. <br\/><br\/>The most important and complex decisions made by governments and organizations occur in group contexts. A central challenge, spurred by new developments in information technologies (IT), is that the nature of groups and how they operate has changed radically. Today, many groups ? in social, political, and economic contexts - are ad hoc, agile, transient entities that emerge from a larger primordial network of relationships. For a short time, these groups accomplish a variety of tasks, and then they dissolve, only to be reconstituted later with a different configuration. While there is growing awareness of the socio-economic consequences of these groups, our understanding of how they form and their impact on effectiveness is severely limited. <br\/><br\/>This project will address this limitation by developing a theoretical framework that reflects the contemporary conceptualizations of groups. It proposes a network approach to modeling the eco-system of overlapping and constantly changing groups that constitute the fabric of contemporary society. It recognizes that empirically testing such a model poses formidable data collection challenges. However, a unique resource available to the research team is access to all behavioral traces (server logs) from one of the world''s largest Massively Multiplayer Online (MMO) games, EverQuest 2, which is particularly well-suited to theorize and empirically model the dynamics of group behavior. MMOs comprise tens of thousands of players who are at any one point in time coalescing in thousands of groups to accomplish \"\"\"\"\"\"\"\"quests\"\"\"\"\"\"\"\" and \"\"\"\"\"\"\"\"raids\"\"\"\"\"\"\"\" that involve a variety of activities similar to tasks we undertake in real life ? finding information or materials, making, selling or buying products and services. <br\/><br\/>Beyond the data collection challenge, the scale of the proposed research enterprise also poses significant computational challenges in uncovering and analyzing the complexities that govern the dynamics of group behavior in these virtual worlds. Using advanced computing applications and technologies, this project seeks to capture, infer, and model the networks that explain how groups emerge and how they function. Specifically, the researchers will use temporally evolving graphs to model such networks, and develop scalable algorithms to compute metrics of group behavior on them. Tying these complex and shifting individual and networked behaviors to traditional forms of analyses represents a novel interdisciplinary challenge in both scope and complexity. <br\/><br\/>The project will expand our knowledge of how groups form and operate in larger ecosystems of groups, individuals, and organizations. The analysis of logs generated from Virtual Worlds poses novel challenges from a computational perspective. This interdisciplinary investigation will result in new (1) information models for modeling the Virtual World, (2) data structuring and algorithmic techniques for data access and analysis, and (3) techniques for computational efficiency. <br\/><br\/>The knowledge and tools developed in this research will allow researchers to understand more fully, and practitioners to cultivate more effectively, the emergence and performance of ad hoc groups in contemporary society. It will also provide other disciplines with new computational and statistical modeling methodologies and tools, which should have considerable positive implications for future research in other disciplinary areas. The findings and deliverables of the proposed research will be immediately generalizable to training and education related to groups (beyond just MMOs or Virtual Worlds), social networks, and online games.","title":"Collaborative Proposal: DHB Virtual Worlds: An Exploratorium for Theorizing and Modeling the Dynamics of Group Behavior","awardID":"0729421","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["532009"],"PO":["564456"]},"131349":{"abstract":"0730206<br\/>Oh<br\/><br\/>Humanoids are bipedal robots engineered to mimic human locomotion, balance and coordination. The Honda ASIMO and KAIST HUBO are adult-sized humanoids that have captured public interest and have given researchers insight on issues ranging from balance disorders to cognition and perception. This 5-year PIRE project teams U.S. and Korean universities (Drexel University, University of Pennsylvania, Virginia Tech, Swarthmore College, Bryn Mawr Women's College, Korea Advanced Institute of Science and Technology (KAIST), Seoul National University and Korea University) to advance humanoids.<br\/><br\/>The critical technical gap that prevents a vertical advance in robotics is the lack of universally available platforms to reproduce results and validate hypotheses. This PIRE's goal is to provide humanoid platforms to a wide audience of researchers by developing a 3-tier tool set based on KAIST's HUBO humanoid: (1) virtual-HUBO is a free and open emulator for testing AI and IT concepts; (2) mini-HUBO is a low-cost 20-inch tall version of the full-sized humanoid for implementing algorithms; and (3) online-HUBO is a tethered version of the full-size humanoid that is accessible for researchers over the internet. This 3-tier approach provides little to no barriers to entry to humanoid research. These platforms will provide U.S. scientists and engineers the opportunity to leverage U.S. leadership in artificial intelligence (AI) and information technology (IT) to advance humanoid abilities in perception, cognition and social interaction.<br\/><br\/>To reach the next generation of robotic scientist and engineers, the PIRE team is working closely with the Philadelphia Please Touch Museum (PTM) to design exhibits featuring HUBO to inspire and motivate students to pursue science and engineering careers.<br\/><br\/>This PIRE project engages each member's unique resources, including electro-mechanical design (Korean collaborators), virtual-HUBO (Bryn Mawr), online-HUBO and co-op program (Drexel), mini-HUBO (Virginia Tech), advanced locomotion (UPenn) and human-robot interaction (Swarthmore). The 6-month co-op cycles (twice per year) at KAIST provide 20 U.S. undergraduates with an international research experience to cultivate skills and appreciation for effective global teaming and research. Shorter but more frequent visits by graduate students and faculty serve similarly functions but also ensure research goals and objectives are met. Lastly, Drexel's School of Education and Senior Personnel assess student performance, global teaming, and engineering skill acquisition. <br\/><br\/>This PIRE is supported by the Office of International Science and Engineering (OISE) and the Robust Intelligence (RI) Cluster of the Division of Information and Intelligent Systems (IIS) found within the Directorate for Computer and Information Science and Engineering (CISE).","title":"PIRE: Humanoids - Universally Accessible Infrastructures to Advance Capabilities","awardID":"0730206","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7742","name":"PIRE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["492593","492593","439956","412446","403839","553287","435880"],"PO":["399099"]},"131118":{"abstract":"The emergence of large networks like the Web and the Internet is one of the most profound shifts in focus in computer science since its perception. Unlike a single computer, these networks are simultaneously built, operated, and used by multiple parties with a diverse set of goals and with constantly changing degree of cooperation and competition. One of the main challenges faced by computer science today is to successfully build and manage systems used by such diverse set of users. The future of much of the complex technology developed today depends on our ability to ensure that participants cooperate despite their diverse goals and interests. <br\/><br\/>The project uses the tools of game theory for studying the behavior of such a diverse, competing and cooperating set of users in networks modeling the interaction between parts of information and computer systems controlled by different parties. Each participant in an algorithm is viewed as a player in a non-cooperative game, where each player acts to selfishly optimize his or her own objective function. The research approaches some of the traditional algorithmic questions in networks from the perspective of game theory ranging from how networks are formed by cooperating selfish users, how such networks are used to disseminate information, how economies work on such networks. In each case the main issue considered by this project is the quality loss due to selfish behavior of the participants. The project aims to understand what are simple and natural frameworks that lead to efficient systems.","title":"Games on Networks and Quantifying the Resulting Solutions","awardID":"0729006","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["516907"],"PO":["565251"]},"132218":{"abstract":"This is funding to support attendance by approximately 10 graduate students in a doctoral consortium (workshop) to be held in conjunction with the Ninth International Conference on Multimodal Interfaces (ICMI07), which will take place November 12-15, 2007, in Nagoya, Japan, and is sponsored by the Association for Computing Machinery (ACM). ICMI is the foremost conference representing the growing interest in next-generation perceptive, adaptive and multimodal user interfaces, systems, and applications, which are especially well-suited for interpreting natural communication and activity patterns in real-world environments. The emergence of these new interfaces, systems and applications represents a radical departure from previous computing, and is rapidly transforming the nature of human-computer interaction by creating more natural, expressively powerful, flexible and robust means of interacting with computers. The theme of this year's conference is once again multimodal collaboration through different platforms and applications. The conference will focus on major trends and challenges in this area, including distilling the development of a roadmap for future research and commercial success. New topics of interest this year include multimodal applications in the vehicular environment, human-robot interfaces, and interfaces for music and amusements. The 4-day event will bring together researchers from academia and industry from around the world to present and discuss the latest multi-disciplinary work in the field. The invited talks, panels, single-track oral and poster presentations will facilitate interaction and discussion among researchers. Participants in the doctoral consortium will get to showcase their ongoing thesis work, either orally or via posters, in a special \"spotlight session\" during which they will receive feedback from an invited committee composed of approximately half a dozen senior personnel (including the conference General and Program Chairs). As in previous years, students funded under this award will all be U.S. residents enrolled at U.S. institutions of higher education. Additional information about the ICMI07 conference is available at http:\/\/www.acm.org\/icmi\/2007.<br\/><br\/>Broader Impacts: The doctoral consortium will give students exposure to their new research community, both by presenting their own work and by observing and interacting with established professionals in the field. It will encourage students at this critical time in their careers to begin building a social support network of peers and mentors. Participants will be selected with the goal of increasing the breadth of participation at ICMI, with priority given first to minority students, female students, students from geographically under-represented states, and finally to students whose advisors or departments have insufficient funds to otherwise support their participation in ICMI.","title":"Student Participant Support for International Conference on Multimodal Interfaces 2007; November 12-15, 2007 in Nagoya, Japan","awardID":"0735077","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["515704"],"PO":["565227"]},"126509":{"abstract":"Proposal #: CNS 07-08469 <br\/>PI(s): Wang, Bin<br\/> Pei, Yong; Wu, Zhiqiang<br\/>Institution: Wright State University <br\/> Dayton, OH 45435-0001<br\/>Title: IAD: Instr. of Measurement and Test System for Open Spectrum Wireless Communication and Networking <br\/><br\/>Project Proposed:<br\/><br\/>This project, instrumenting a complete measurement and test system for open spectrum wireless communication and networking research, addresses <br\/>. Intelligent soft-decision cognitive sensing paradigm, <br\/>. Spectrum mobility and routing schemes via proactive spectrum access, and <br\/>. Cross-layer design approaches for providing differential quality-of-service (QoS) and quality assured multimedia services over next generation wireless networks.<br\/>Providing hands-on experience, the instrument will serve as a tool for education and training students for their capstone design projects and for independent research projects. Enhancing curricula, the project facilitates research and education in wireless communication, cross-layer design, dynamic spectrum access, cognitive radio, sensor networks, and multimedia services over wireless. The project also facilitates development and demonstration of a software defined radio-based wireless communication and networking laboratories. Preliminary work utilized a GNU software platform. The technologies developed are expected to make aspects of wireless transmission, reception, and networking programmable by allowing intelligent exploitation of the portion of the spectrum that is allocated but unused or underused.<br\/><br\/>Broader Impacts: Successful exploration of the issues enabled by the instrument can have significant scientific and engineering impact; additionally, the project impacts curricula and may result in enhancement of courses at the graduate and undergraduate levels, strengthening the bond between research and education.","title":"CRI: IAD Instrumentation of a Measurement and Test System for Open Spectrum Wireless Communication and Networking","awardID":"0708469","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["559204","552264","352533"],"PO":["557609"]},"130953":{"abstract":"The emergence of the Internet is one of the most profound shifts in focus in Computer Science since its inception. Traditionally, Computer-Science research has focused primarily on understanding how best to design, build, analyze, and program computers. Research focus has now shifted to the question of how best to design, build, analyze, and operate networks and the distributed applications that run on top of them. Satisfactorily answering these questions will require the development of a Theory of Networked Computation (ToNC) that is analogous to the Theory of (single-machine) Computation that Computer-Science researchers have already developed. In particular, it will be important to investigate the theoretical foundations of routing in next-generation networks.<br\/> This work will complement ongoing experimental research by examining three foundational aspects of next-generation routing systems: (1) Policy-based, interdomain routing (focusing on distributed algorithmic mechanisms, payment protocols, solution concepts, and privacy), (2) New routing paradigms (focusing on the intrinsic properties of protocols that are not fully distributed, do not require consistent state, or do not use topology-dependent addressing), and (3) New measures of the complexity of routing protocols (focusing on the notion of dependency complexity recently put forth in the networking-research community). <br\/>The PIs have consistently played a leading role in ToNC-community formation. The lead PI is the co-chair of the GENI Scientific Council and is thus positioned to pave the way for ToNC-community participation in GENI, which could result in the development of network services with novel functionality and provable properties.","title":"Collaborative Research: SING: Foundations of Next-Generation Routing","awardID":"0728443","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":["450982"],"PO":["565251"]},"130975":{"abstract":"This research involves understanding the computational complexity of<br\/>fundamental machine learning problems. In particular, the<br\/>investigators study which classic learning problems are unlikely to<br\/>admit efficient solutions. In terms of broader impact, this line of<br\/>research aids practitioners and algorithm designers as it outlines<br\/>fundamental stumbling blocks for creating powerful learning systems.<br\/>For example, can we reduce difficult open problems from cryptography<br\/>(e.g., factoring) and complexity theory (e.g., NP-complete languages)<br\/>to certain problems in machine learning? If so, this provides strong<br\/>evidence that particular machine learning problems are hopelessly<br\/>intractable. Another avenue of research is to prove unconditional<br\/>lower bounds on the resources required to infer functions in<br\/>restricted learning models.<br\/><br\/>The intellectual merit of the research lies in finding new reductions<br\/>between problems in cryptography and complexity theory-- in particular<br\/>communication complexity-- and problems from learning theory. For<br\/>example, the PI studies the impact of lattice-based cryptography in<br\/>machine learning and examines its implications for the DNF learning<br\/>problem. Additionally, the PI researches the use of communication<br\/>complexity to rule out learning simple concept classes via small sets<br\/>of arbitrary features. We further delineate the role of Fourier<br\/>analysis in proving lower bounds in the well known model of<br\/>Statistical Query learning. Finally, this research investigates the<br\/>relationships between NP-completeness and circuit complexity to<br\/>general questions about proper learning and distribution-specific<br\/>query learning.","title":"The Computational Intractability of Machine Learning Tasks","awardID":"0728536","effectiveDate":"2007-09-01","expirationDate":"2012-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["451925"],"PO":["565157"]},"130623":{"abstract":"This research addresses the mechanism of coupled oscillations in calcium ion and cellular ATP\/ADP driven by mitochondria, which is directly related to the defect in pulsatile insulin secretion in<br\/>diabetes.<br\/><br\/>The oscillation mechanism is studied at different scales, from an individual mitochondrion, to the coupling among multiple (100 to 200) mitochondria in a single cell, to the coupling among multiple (1,000 to 10,000) cells in a single pancreatic islet. After initially developing a rigorous mathematical modeling framework for multiscale modeling and simulation, the framework is applied to develop a model for the<br\/>oscillation mechanism in a single mitochondrion. These models are then coupled together using spatial information to represent multiple mitochondria and the coupled oscillation in a single cell. Finally, massively parallel computation is used to simulate the coupled oscillation among multiple cells in a single pancreatic islet. This project rigorously tests the hypothesis that synchronization of the oscillations at all scales is necessary for the correct secretion of insulin.","title":"Multiscale Modeling, Simulation, and Sensivitity Analysis of Biochemical Systems Motivated by Pulsatile Insulin Secretion","awardID":"0726763","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7931","name":"COMPUTATIONAL BIOLOGY"}}],"PIcoPI":[346629,346630,"560196"],"PO":["565223"]},"132703":{"abstract":"Background:<br\/>This small grant will support an initial collaboration with a Chinese reseaercher on the topic of LiDAR (Light Detection And Ranging) and its use in flood disasters. LiDAR is an active sensor approved by the US Federal Emergency Management Agency (FEMA) for construction of digital terrain models (DTMs) and digital elevation models (DEMs). DTMs and DEMs, together with appropriate GIS data, are key sources for the construction of digital flood insurance rate maps. FEMA-specified LiDAR products are primarily designed for terrestrial floodplain mapping applications. In this project, the collaborative work focuses on multispectral data aggregation and 3D visualization. Data from New Orleans and from Hefei China will be integrated. The goal of the research is to answer the following question: Can 3D models be generated and related strategic planning questions answered; i.e., given a flood stage, can the flooded area be visualized, can possible breaching locations be identified, and can elevations of water around building footprints be determined? The China\/US team plan two tasks to address these questions. First, a method will be developed to render photogrammetric and processed images over the ?surface? of the reconstructed 3D model from LiDAR data. The second task will be to develop an integrated visualization tool.<br\/><br\/>Intellectual Merit: <br\/>Fusing sensory data from such vastly different modalities using signal-level<br\/>methods is challenging. The collaborative research with the Chinese partner will result in a new product that provides a powerful and straightforward tool for disaster planning and response teams to estimate or evaluate environmental and economic impacts. Finally, LiDAR data itself will become a much more valuable tool for the communities that possess it. This multi-disciplinary research team includes three computer scientists and an environmental engineer.<br\/><br\/>Broad Impacts: <br\/>The research contributes to scholarship and public policy in three significant ways:<br\/>1. the results will demonstrate methods which are available for quantifying present and past floodplain states using extant data. It is expected that this will be useful to state and federal agencies responsible for environmental assessment and remediation.<br\/>2. research ties between China and the US will be strengthened. <br\/>3.there is the possibility of more accurate assessment of tax liabilities by all jurisdictions.","title":"SGER: US\/China Digital Government Collaboration: A New Tool for Economic and Environmental Planning - Expanding the Boundaries of LiDAR","awardID":"0737861","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[352939,"461421","385819"],"PO":["427499"]},"133803":{"abstract":"The goal of this workshop is to collaboratively determine successful strategies for promoting creativity in IT based on the experiences of a diverse group of leading practitioners. Creative activity leading to major innovation is a critical component of the American competitiveness initiative, not only for driving innovation in IT research and development, but also for advancing our pedagogical approaches to educating and preparing scientists for the future. There is a need to establish a formal collective basis for critically examining the role of creativity in IT research and education in order to support structured dialog, disseminate findings and broaden understanding.<br\/><br\/>To begin this process, this workshop brings together leaders engaged in fostering creativity within a variety of disciplines to share their experiences and success stories. Topics addressed will include diverse perspectives on fostering creativity; integrating creative and scientific disciplines; formalizing and measuring success factors in encouraging creativity; and creativity through the exchange of ideas in electronic publication forums. The presentations and the surrounding conversations that will shape, extend and evolve common ideas will be collected into an edited electronic publication that will be part of the dynamic creativeIT wiki.","title":"Workshop: Success factors in fostering creativity in IT research and education","awardID":"0742966","effectiveDate":"2007-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":["563297",355871],"PO":["424970"]},"132956":{"abstract":"The University of South Florida (USF) together with Hillsborough Community College (HCC) proposes a series of coordinated programs designed to broaden the participation of Hispanic as well as other underrepresented minority students in computing. The proposed programs will establish the educational pathway and provide the support that students need to make successful transitions at critical points in their educational journey from the community college to the baccalaureate level and from the baccalaureate to the graduate level. The programs are built upon the strengths of the partnering institutions: HCC?s successful personalized advising, mentoring, and tracking initiatives and USF?s research experience with undergraduates are utilized as recruiting, retention, and enhancement tools. A personalized advising service and two summer programs combining research and academic courses are proposed to recruit, retain, and prepare community college students on their path toward 4-yr universities. The advising service will track students very closely to make sure they take and continue in the chosen path. The academic courses, with an important programming and math component, will allow the transfer students to meet the academic requirements for admission to the Department of Computer Science and Engineering at USF. The research component will pave the way for them to participate in the Research Experiences for Undergraduates (REU) programs later on. These summer programs will be designed and implemented by USF and HCC professors, creating a new learning community that will extend to HCC classrooms on a permanent basis. USF?s REU programs for juniors and seniors will be utilized to help transfer students graduate and prepare them for graduate school and the work force. These research programs are also meant to create a learning community among these students, and the graduate students and professors at USF.","title":"BPC-DP: CSTEP: Computer Science TransfEr Programs","awardID":"0739020","effectiveDate":"2007-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7584","name":"ITR-BROADENING PARTICIPATION"}}],"PIcoPI":["473743",353592,"473744",353594],"PO":["561855"]},"130668":{"abstract":"Controlling the quantum state of very small devices is important for future technology. In particular, controlling the state of superconducting (SC) qubits (i.e., artificial atoms) offers the opportunity to study fundamental quantum mechanics and illuminating analogies with atomic physics. In addition, new forms of computing might be possible when controlling the quantum mechanical state of SC qubits. This research studies several aspects of the physics of SC qubits. <br\/><br\/>Projects studied in this project include: (1) quantum computing (QC) schemes based on Josephson qubits coupled through nonclassical microwave fields; (2) switchable and scalable circuit designs involving inductive couplings, as opposed to the usual capacitor-based couplings for charge qubits; (3) circuits <br\/>with a Current-Biased Josephson Junction (CBJJ) acting as a bus (a SC JJ qubit analog of the ion-trap QC set-up, with the CBJJ acting as the ?information bus? between qubits); (4) quantum tomography; (5) several properties of SC qubits inside a cavity (which we first proposed in 2001, and which was implemented experimentally in 2004) as well as how to generate single photons on demand by placing a SC JJ qubit inside a micro-cavity; (6) explore ways to generate an arbitrary superposition of photon states, including cat states, using SC JJ qubits. All of this while simultaneously interacting with experimentalists trying to implement these.","title":"Controlling Superconducting Qubits","awardID":"0726909","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":[346742],"PO":["565157"]},"134914":{"abstract":"While researchers have considered tracking annotations on 2D physical surfaces, this project explores the issues for tracking annotations on 3D physical models to accommodate complex objects, track annotations in difficult conditions, and consider the compatibility with 3D printing technology. During the early stages of design, designers do not want to work within the complexity of a CAD system and prefer to work with physical models. Linking the edits and annotations on a physical model with a digital model allows the benefits of digital models to be available while working with physical models. The intellectual merit of this project is in evaluating the feasibility for tracking annotations on physical objects in comparison to fully digital interfaces for early stage design. A new passive optical tracking method will be developed to accommodate complex objects, tracking in difficult conditions, and 3D printing technology. This project will impact the way in which designers use rapid prototyping by integrating edits on physical models with digital models. These techniques will be used in teaching architecture students and influence the expanding role of physical models in design.","title":"Capturing Freehand Annotations and Edits on Physical 3D Models","awardID":"0749094","effectiveDate":"2007-09-15","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["475376"],"PO":["565227"]},"133715":{"abstract":"The determination of homology by pair-wise sequence alignments is notoriously insensitive because many proteins with similar structure and function often have only 8-10% sequence identity ? well below the detection threshold required for conventional methods. It has been shown that by transforming protein sequences into vectors of properties associated with sequence and structure can significantly improve the task of finding these remote homologues (proteins with low sequence identity). However, existing feature-based methods are limited to classifying a protein into a family, which means that proteins cannot be classified unless they fall into a pre-defined family. Methods devised to overcome this caveat by assessing pair-wise similarity have primarily relied on network propagation because of the extremely large training space needed for pair-wise training. For example, a small benchmark dataset of 4000 proteins equates to over 8 million pairs. Unfortunately, these network propagation methods have demonstrated only marginal improvement over the state-of-the-art PSI-BLAST method. This is largely because (1) only a small limited number of features are used and (2) the underlying reliance of the network propagation method to a similarity network derived from BLAST scores. Thus, the use of statistical discrimination methods to answer the pair-wise question has remained beyond reach in the homology detection field. This limitation is a serious technological gap for large-scale genome sequencing since automated annotation is not possible without highly reliable homology detection. The development of a biologically-driven integrated protein feature representation will significantly improve the task of remote homology detection. Additionally, the use of a SVM, which only requires a linear computation for the classification task, will offer a fast computation time. These two components ? faster sequence comparisons and improved sensitivity ? will break a long standing time\/sensitivity paradigm in the field of remote homology detection. The proposed pair-wise SVM implementation can also be applied to other large real - world diverse science and engineering problems characterized by classification through association. The PI already has a joint faculty appointment to WSU and is currently serving as a committee member for two students. For the proposed work, one additional Ph.D. graduate student from the WSU computer science department will perform thesis work on components of the proposed project, giving her hands-on access to unique supercomputing facilities.","title":"Structural and Functional Property Integration for Protein Sequence Feature Representations to Enable Advanced Machine Learning Remote Homology Detection","awardID":"0742553","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[355632],"PO":["565136"]},"133616":{"abstract":"This research will develop and apply new machine learning methods to model individual behavior in the context of collective problem-solving. The experimental task in earlier empirical research with human subjects was to solve challenging distributed computational problems on networks, such as graph coloring, from only local information. The goal of the new work is to develop machine learning methods whose outputs can accurately reconstruct and predict collective behavior from individual models, and can shed light on related questions such as the empirical diversity of strategies within a human population, and its importance for effective collective behavior.<br\/><br\/>This project contributes in novel ways to several distinct research communities, including machine learning, sociology, economics, and related fields. It integrates research and education in two ways: by giving both graduate students and undergraduates the experience of participating in a cutting-edge research study, and by providing new curriculum for a course entitled \"\"Networked Life.\"\"","title":"Machine Learning for Collective Behavior","awardID":"0742171","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["486003"],"PO":["564456"]},"135937":{"abstract":"Background<br\/><br\/>In this project the PI argues that many applications, related to software reliability and software protection, require automated comparison of original and the transformed versions of the program.<br\/>The goal of this comparison is to match instructions from two versions that correspond to each other. The PI refers to this process of automatically unmasking the effects of program transformations as matching.<br\/><br\/>Intellectual Merit:<br\/><br\/>-The PI propose to develop nearly accurate dynamic matching algorithms which are designed to <br\/>-Use execution histories to find mapping between code that appears to be different but<br\/> behaves the same during an execution. <br\/>-Perform matching at binary level.<br\/>-Use matching to compare execution histories of the two versions at regular<br\/> intervals and report the set of unmatched statements. <br\/>-Combination of techniques that use Diablo to produce a static program representation and runtime algorithms that process Valgrind generated traces for compression are being implemented to produce Whole Execution Traces (WETs). <br\/>-Deposit in a WET database and accessed by the Dynamic Matching module to carry out matching.<br\/><br\/><br\/>Broader Impact<br\/><br\/>The PI has involved 2 PhD students in the preliminary work carried out for the proposed research.<br\/>These students are expected to finish their degrees by the end of the proposed project. In addition, other graduate and undergraduate students in Programming Languages classes taught by the PI will use the infrastructure in their class projects.<br\/><br\/>Initially the research results produced by this project will be incorporated into the above courses taught by the PI. Later PI will develop a dedicated course on Dynamic Techniques. The labs and lectures prepared will be freely made available through the project website. <br\/><br\/>Once such a course is ready, the PI will also undertake a book writing project to produce a formal text in the broader area of dynamic analysis.<br\/><br\/>Although the initial goal of this research is to develop dynamic unmasking techniques for optimized and obfuscated code, the dynamic information analysis infrastructure that is being developed will also be useful in other areas of research such as performance analysis and debugging. Therefore, the infrastructure produced will be have a broader impact by being useful to other researchers as well.","title":"ST-CRTS: Dynamic Unmasking of Compiler Optimizations and Obfuscations","awardID":"0753470","effectiveDate":"2007-09-01","expirationDate":"2010-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}}],"PIcoPI":["549718"],"PO":["565272"]},"120339":{"abstract":"ABSTRACT<br\/>With the proliferation of learning objects (LOs) online, both teachers and students are often frustrated in locating those that will meet their specific instructional and learning needs. A key component of this problem is that learning objects that are currently available typically are not based on learning research, do not contain embedded guidance on how they should be used, and do not adhere to common standards. Thus, the long-range goal of the project research team is to augment LOs with empirical usage intelligence how an LO should be used, how it has been used, and how it has impacted instruction and learning that will result in radical improvements in learning and instruction. With this embedded intelligence, learners and teachers will be able to identify the LOs that match their needs, educational and experiential backgrounds, and mode of learning or teaching. Learning management systems will also be able to more effectively sequence learning objects to build courses. To take a significant step toward this long-range goal, this project will be guided by an integrated and multidisciplinary approach in pursuit of the following specific technology and learning goals:<br\/>Technology Goal 1: Create an Intelligent Learning Object Guide (iLOG) that tracks, diagnoses, and tags the empirical usage intelligence of learning objects.<br\/>Technology Goal 2: Revise and convert the online course materials for an undergraduate introductory CS course (CS1, already developed at the University of Nebraska-Lincoln [UNL]) into learning objects.<br\/>Learning Goal 1: Identify the salient learner attributes and content\/pedagogical characteristics that can be empirically tracked to impact learning. <br\/>Learning Goal 2: Measure the impact of active learning and elaborative feedback on student learning with learning objects.<br\/>In terms of technical innovations, our proposed project will (1) add to the Shareable Content Object Reference Model (SCORM) metadata standard to include empirical usage history and statistics on each learning object, (2) result in a framework and a software system (i.e., iLOG) to empower learning objects with empirical usage intelligence, (3) develop advanced computer-based tracking and analysis tools that provide robust quantitative information on student understanding and learning progress and (4) develop SCORM-compliant learning objects for the CS1 course that are interoperable across a variety of platforms and Learning Management Systems. In terms of research advances, our proposed project will advance our knowledge of (1) student conceptual learning processes, (2) creation of new strategies for using contemporary technology-based instructional approaches, (3) matching of instruction to meet specific needs and preferences of learners, and (4) anomaly diagnosis for intelligent systems such as iLOG interacting with human subjects in uncertain and dynamic learning environments.","title":"iLOG: Embedding and Validating Empirical Usage Intelligence in Learning Objects","awardID":"0632642","effectiveDate":"2007-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1707","name":"ADVANCED LEARNING TECHNOLOGIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["526198","521703","412961"],"PO":["564318"]},"131108":{"abstract":"Reduction in fabrication dimensions has resulted in significant increase in the randomness associated with the fabricated parameters of large scale digital circuits. This has begun to severely impact the manufacturing yield and therefore the profitability of the semiconductor industry. In this research the investigators are focusing on developing formal optimization schemes for synthesizing large scale digital circuits while proactively considering randomness induced yield loss as an optimization criteria.<br\/><br\/>As a key intellectual merit, specific digital circuit optimization problem instances that can be modeled as convex programs are being investigated in presence of fabrication randomness. Using a sound mathematical understanding of the nature of the yield loss function, customized optimization algorithms are being developed. Some of these algorithms leverage the special mathematical structure of the problem instances (convexity of the yield loss function in some special cases). For such instances the investigators study modifications of formal convex optimization methods (like cutting plane\/interior point etc.) for improving the rates of convergence. In cases where such mathematical properties do not exist, efficient heuristics are being developed. A key agenda under investigation is how should such optimization schemes be integrated with statistical estimation methods (which measure the yield loss for a specific solution instance and are known to be very slow). Improving the productivity and profitability of the semiconductor industry, improving the applicability of nanotechnology (where manufacturing randomness is a major concern) and improving the teaching infrastructure through graduate and undergraduate student training are key broad impacts of this work.","title":"Optimization Schemes for Large Scale Digital Circuits in Presence of Fabrication Randomness","awardID":"0728969","effectiveDate":"2007-09-15","expirationDate":"2011-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["541967"],"PO":["562984"]},"131119":{"abstract":"Inverse problems play an important role in the solution of many engineering tasks. Traditional implementations of solutions to inverse problems are centralized and rely on a large server for computation. However, the emergence of complex systems has led to the requirement to deploy solutions to inverse problems on a large scale. For example, modern surveillance systems demand that vision processing systems contain an increasing collection of cameras and are charged with targeting a large number of objects. The main difficulty is that classical solutions to inverse problems perform very poorly as the dimensionality of the system increases; e.g., the computational complexity of video tracking systems rises exponentially with an increase in the number of targets and cameras. This project investigates novel approaches to the design of solutions to inverse problems based on collaborative methods in large-scale image and video processing systems. <br\/> <br\/>This research project develops a new methodology to the design of collaborative systems such as video tracking of multiple targets from multiple camera systems. The premise of the approach to collaborative processing is the graphical decomposition of complex dynamical systems. A collaborative approach to multi-object tracking and multi-camera tracking is pursued by allowing collaboration between multiple trackers associated with individual targets and cameras to achieve the same performance as a centralized system at a much lower complexity. The approach to collaborative systems is designed to exploit the computing facilities available throughout a large network and can thus scale with the size of the network and number of targets. The methodology developed provides a paradigm shift in the design of image and video processing systems. More information is available on the project web site: http:\/\/www.ece.uic.edu\/~ds\/InteractiveVision.html. <br\/><br\/>3. Level of Effort Statement: The reduction of the number of graduate students from two to one per year will impact the scope of the effort that will be pursued in this project. Specifically, the main focus will be devoted to the use of graphical and probabilistic methods for the design of distributed methods for multiple object video tracking from multiple cameras. As a result, the proposed activities on the use of optimal control for multiple target tracking will be eliminated since they require a different set of skills and background by the student. Nonetheless, the PI will do his best to ensure that most of the proposed effort will be addressed despite the reduced number of graduate students.","title":"InteractiveVision: Collaborative Multiple-Input-Multiple-Output Inverse Problems with Application in Image and Video Processing","awardID":"0729007","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["415103"],"PO":["564898"]},"125806":{"abstract":"This project addresses problems central to the design of decision-making strategies that enable computer agents to work effectively with people in heterogeneous groups that interact in carrying out complex activities. These mixed networks of people and systems arise in a wide variety of real-world applications as well as in virtual reality and simulation systems used for training. They occur in settings in which computer systems support people who are working together, those in which they act as proxies for individual people, and those in which groups of agents act autonomously (but alongside people) to carry out constituent tasks for which they are responsible. Despite mixed networks being wide spread, the design of agents that can operate in such settings has received less attention than the design of agents for multi-agent systems comprising only computer agents.<br\/><br\/>The inclusion of people in mixed networks presents novel problems for the design of autonomous agent decision-making mechanisms. This proposal focuses on the following three of these challenges, which have not been investigated sufficiently in prior work and which agent designers must address to construct systems able to work well with their human partners in mixed networks: (1) information exchange policies for agent competence and past behavior; (2) design of interruption management mechanisms for collaborative interactions; and, (3) learning and incorporation of models of social factors and organizational structures into decision-making mechanisms.","title":"HCC: Collaborative Research: Information Exchange and Social Factors in Human-Computer-Teamwork Decision Making","awardID":"0705406","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[333902],"PO":["565227"]},"130954":{"abstract":"NSF Division of Computer and Communications Foundations:<br\/>Theoretical Foundations<br\/>Program Solicitation NSF 07-525:<br\/>Information Theory of Channels with Missing Observations<br\/>Principal Investigators: Giuseppe Caire and Sergio Verd'u<br\/>University of Southern California Princeton University<br\/>Summary<br\/>This project takes a unified information theoretic approach to problems in transmission, compression, estimation and sensing in which observations may be missing from the available data. In many applications of current practical interest, data is subject to random erasures because of fading and\/or jamming (in wireless), packet dropping due to finite buffer sizes (in networks), impulse noise (in power and subscriber looplines), defective media (in magnetic recoding), faulty transducers (in sensor networks), reduced complexity<br\/>(in compressed sensing), link failure (in wired infrastructure of a cellular system), opportunistic signaling(in nonstationary channels), etc. It is of great theoretical and practical interest to assess the impact of the<br\/>missing data on the fundamental Shannon theoretic limits for reliable compression and transmission, as well as the estimation theoretic limits. Furthermore, new practical questions arise on how to best redesign<br\/>compression, coding, modulation, and filtering schemes to attain performance close to the fundamental limits in the presence of missing observations.<br\/>This project tackles a number of specific challenging and technologically relevant research problems that involve a variety of models with missing observations: Lossless and lossy compression of missing data, when the erasure locations are known\/unknown at the compressor; Capacity of noisy channels subject to erasures, and in particular the effect of output erasures on the capacity of channels with memory; Minimum mean square error estimation and prediction with missing observations; Fountain codes for simultaneous broadcast to several receivers with widely different missing information rates; Multiuser information theory for networks subject to erasures, including basic paradigms such as the multiaccess channel and the broadcast channel; Cellular networks with centralized processing and unreliable wired links (\"radio on fiber\" subject to link outages); Robustification of transceiver techniques such as orthogonal frequency division multiplexing, feedback schemes, and dirty-paper coding which are notoriously sensitive to erasures; Revisiting the fundamental limits of compressed sensing (which can be interpreted as the concatenation of a full-rank random projection followed by random erasures of the projected coefficients) from the viewpoint of information theory.<br\/>This project aims at advancing discovery and understanding of communication and signal processing systems of relevance to current technology, at the crossroads of several research communities, and provides a fertile ground for training of graduate students in the disciplines of information theory, coding theory, estimation, signal processing, random matrix theory and networks.","title":"Collaborative Research: TF: Information Theory of Channels with Missing Observations","awardID":"0728445","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["550344"],"PO":["432103"]},"130602":{"abstract":"Lab-on-a-chip (LoC) technology has enabled miniaturization and integration of conventional bench-scale experiments to a single chip comprising on-chip components, such as channels, valves, and mixers. <br\/>Currently, LoCs are designed as application-specific chips, where a new LoC is designed for every assay by creating and connecting on-chip components to match the steps of the assay. (i.e., n assays need n LoC designs). Unfortunately, this application-specific approach (1) incurs considerable design effort, turn-around time, and cost for each assay and (2) reduces productivity because it requires LoC engineers to know the assay specifics and LoC users to know the constraints of the LoC.<br\/><br\/>To address these limitations, this project will design and prototype a general-purpose, programmable LoC (PLoC) which does not implement any specific assay and instead employs software to translate an assay into an equivalent \"executable\" which is run on the PLoC. The executable breaks down the assay into a sequence of basic steps called \"fluid instructions\", which are implemented in hardware. The set of fluid instructions implemented by a PLoC is called its \"fluid instruction set\", and any assay can be executed on the PLoC if the assay can be translated using the PLoC's fluid instruction set (i.e., n assays use 1 PLoC design instead of requiring n LoC designs). Compared to LoCs, the PLoC has significantly lower design effort and faster turn-around time due to one-time design of a single chip, and lower cost due to economy of volume. The clean separation between hardware and assay achieved by the fluid instruction set and the software translator (called \"the fluidic compiler\") vastly improves the productivity of LoC users and LoC engineers.","title":"Collaborative Research: Architecture and Prototype for a Programmable Lab-on-a-Chip","awardID":"0726694","effectiveDate":"2007-09-15","expirationDate":"2011-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["545111"],"PO":["565157"]},"130965":{"abstract":"Complexity problems in cross-layer optimization for wireless sensor networks have rekindled interest in the quest for a distributed algorithm that would simultaneously handle routing, task assignment, and information fusion, scale gracefully with the network size, and display resilience to node failure. Although various obstacles to this goal remain, belief propagation, and its close cousin expectation propagation, provide many attributes that such a distributed algorithm would require. Indeed, recent works attest to the potential of belief propagation for such tasks as network averaging, node detection, network diagnostics, routing, and even missile defense. This collaborative research project brings together researchers in statistical inference and wireless communications to (i) rephrase random sensor deployment strategies as a sparse dependency structure among parameters; (ii) advance expectation propagation as a distributed algorithm to harmonize many sensor network tasks; (iii) extend convergence results from iterative decoding to inference in sensor networks; and (iv) open novel design and optimization tools in sensor networks as by-products of the work.<br\/><br\/>In particular, the investigators show how common network inference tasks, including intruder detection, sensor localization, and channel estimation, can be viewed as particular instances of the expectation propagation algorithm passing messages between network nodes. Message passing here consists of soft information exchange, reminiscent of the mature field of iterative decoding. Convergence tools of iterative decoding, including density evolution and EXIT chart analysis, are extended to the network inference problems under consideration. Additional insights and new design tools for sensor networks emerge as natural by-products, ultimately targeting the inference capacity of such networks, and how this capacity may be optimized versus sleep strategies and energy consumption.","title":"Collaborative Research: Distributed Estimation in Wireless Sensor Networks via Expectation Propagation","awardID":"0728496","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7938","name":"SENSOR NETWORKS"}}],"PIcoPI":["539473"],"PO":["564898"]},"130987":{"abstract":"One of the most important obstacles in deployment of high data rate, low cost, and power efficient multicarrier communication systems is the cost of front-end RF amplifiers. Multicarrier modulations offer the promise of low complexity equalization, adaptability to frequency selectivity of the channel, and efficient use of available bandwidth in cognitive networks. However, multicarrier signals consist of linear superposition of many subcarriers leading to large peak to average power ratio (PAPR) and implying the need for highly linear power amplifier. In particular, RF power amplifier becomes substantially power inefficient and expensive when its linearity region increases to accommodate signals with large PAPR. Any nonlinearity introduced by the power amplifier can cause large out-of-band leakage and reduce the transmit range of the link.<br\/><br\/>While the worst case PAPR is quite large, it has been established by the investigators that the likelihood of having large peaks is small and there exist codes of almost full rate with PAPR bounded by a constant. Existing coding schemes, however, provide low PAPR and large minimum distance at the cost of substantially reducing the transmission rate. This research involves addressing both existential and algorithmic aspects of coding schemes for PAPR reduction. This research develops both probabilistic techniques and new algorithms to prove the existence and to construct pragmatic codes that not only provide low PAPR and high rate but also lead to optimizing other parameters such as capacity loss, minimum distance and out-of-band leakage.","title":"Collaborative Research: Low Peak to Average Power Multicarrier Signals via Coding: Fundamental Limits and Algorithms","awardID":"0728572","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":[347677],"PO":["432103"]},"133804":{"abstract":"This project develops new human-computer interfaces for controlling knowledge dissemination based on the way that humans interact in a musical ensemble performance, aiming to pioneer new computer interfaces that will allow us to interact with electronic content through gestural control. The project postulates that creative artistic design and use of sensor-based human input to a computing environment is a key element in defining next-generation research and teaching tools, and uses a creative design process through experimental exploration. The project leverages the availability of a unique virtual simulation and design environment, the UCSB Allosphere, a spherical, three-story multi-modal immersive visualization\/sonification device. The Allosphere represents the next generation of collaborative immersive environments, and for prototyping novel interface metaphors based on creative input, its unique simulation capabilities will prove invaluable. The goal is to develop next-generation ?musical ensemblestyle? user interfaces for controlling artistic performances, interactive scientific explorations, and instructional experiences on large electronic stages, such as select full-dome planetaria. It is anticipated that this willlead to major contributions for teaching in electronic classrooms, in which the walls will be covered by large-scale interactive displays.","title":"Artistic Group Performance as a Model for Novel Collaborative Multimodal Human-Computer Interfaces","awardID":"0742968","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":["466630","518684"],"PO":["424970"]},"130306":{"abstract":"One million adults are diagnosed each year in the United States with cognitive impairments (CI). Many of these individuals are unable to travel unassisted outside their residences to participate in community or social activities, which results among other things in social isolation for this growing segment of our society. While assistive technology (AT) holds great promise for helping people with CI achieve independence, studies show these users frequently abandon AT systems due to (an eventual) misalignment between personal user goals and abilities, and the functionality delivered by the system. Whereas unimpaired users may learn and adapt their behavior to exploit system functionality, loss of cognitive abilities makes this infeasible for CI users. Previous work by the PI in developing AT for CI users has shown that the problem of device abandonment can be mitigated by personalizing AT design to the particular goals and capabilities of the user, and then re-designing as those capabilities change over time. One result of this prior research is a framework for assessing and characterizing the personal and contextual requirements (PC-RE) of the user. The PI has applied this model to build personalized systems that align with user goals, support monitoring for long-term requirements discrepancies, and guide re-design. Longitudinal studies have shown that this \"assess-personalize-build-monitor-adapt\" approach is effective for representative CI populations, but unfortunately it is largely ad hoc and clearly cannot scale to provide the large numbers of personalized systems needed by the growing CI population. In this project the PI will address these deficiencies by developing and formalizing a novel design approach that supports rapid, cost-effective mass-personalization of AT systems. The approach provides a new software development mode the PI calls a Software Pharmacy. Operationally, a Software Pharmacy takes a formal PC-RE specification (a prescription) embodying the goals, requirements, and skills of an individual user, and from it generates a self-monitoring, self-adaptive set of system software meeting those needs. An underlying development model based on techniques from social science, PC-RE, software product-lines, and dynamic requirements monitoring will provide the capabilities supporting rapid production, re-configuration, and re-design in a feedback\/control development cycle. The PI will formalize the development model, operationalize it for a set of travel-assistant devices, and empirically test effectiveness of the design paradigm in a set of longitudinal studies with CI users. Resulting models, methods, exemplars, and tools will be transferred to the Design Science and AT development communities.<br\/><br\/>Broader Impacts: Researchers currently lack both methods and tools supporting effective, low cost software personalization. This work will provide design methods, models, examples, and tools supporting end-to-end development of personalized AT system software. These artifacts as well as the theory, examples, and data from experimental application will support Design Scientists in addressing a wide range of emerging problems in creating software systems for individuals who currently lack access (user-appropriate technology) or demand systems fitted to their individual capabilities and needs. Results will also be useful to commercial developers for developing new systems that better support social integration for people with CI.","title":"Software Pharmacies: Design of Personalized Assistive Devices for People with Cognitive Impairments","awardID":"0725368","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7652","name":"SCIENCE OF DESIGN"}}],"PIcoPI":["449118","449119"],"PO":["565227"]},"133749":{"abstract":"Simulation of deformable objects is central for progressing virtual reality research. The challenging task is to meet the conflicting demands of real-time interactions and accuracy. To generate natural 'feeling' from virtual reality, visual and haptic feedbacks require high refresh rates of 30 and 1000 Hz?C respectively. However, any physically accurate and realistic virtual object modeling is computationally expensive. The goals of this research project are as follows. 1) Development of new algorithms for accurate deformation of non-rigid virtual objects with a large number of vertices in real-time. The new algorithms will improve the Finite Element Method (FEM) which has physically accurate models but needs intensive computation. To meet the requirements of robustness and satisfactory visual results, the proposed model will be built based on a tetrahedral mesh structure. A preprocessing stage will be used to compute a set of elementary deformations of the model to obtain real-time performance. To simulate cutting in the dynamic deformation system, the model will be successively recomputed to remove the tetrahedron at the contacting places with haptics. 2) Simulation of deformable objects in real-time virtual reality applications. Two simulations will be developed: needle insertion into the skin for medical practices; and DNA extraction from agarose and polyacrylamide gels for biological experiments. 3) Testing and evaluating of the deformation to achieve optimal simulations, which will be performed by engineering, biology, and nursing students at Purdue University Calumet (PUC). <br\/><br\/>The proposed research will improve the fundamental knowledge and enhance the realism and immersion of haptic virtual reality. The applications in this research will benefit medical practices and biological experiments. The simulation data will be used as a basis for developing future projects on virtual reality. The long term goals of the proposed research are to 1) advance the state-of-the-art virtual reality technologies, and 2) broaden the virtual reality applications in multiple areas such as education, health care, and manufacturing, as well as bring improvements in such issues as safety, time, space and equipment, and cost efficiency. Course enrichment and student involvement will enhance the engineering program at PUC, which is located in an economically disadvantaged region.","title":"Accurate and Real-time Deformation in Haptic Virtual Reality","awardID":"0742700","effectiveDate":"2007-09-01","expirationDate":"2009-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["538512"],"PO":["565227"]},"131208":{"abstract":"This interdisciplinary project teams a social psychologist, a mathematician, two computer scientists, and a sociologist in research that combines a mathematical model of collective behavior with software for image tracking, classification, simulation, and animation. The hypothesis to be tested is that behavior in a large crowd results primarily from social influence within and between small groups, in contrast to existing models, which operate at the level of the individual or of the entire collective. The model unifies these approaches and allows for comparative assessment by varying the importance given to individual factors versus properties of the entire collective versus the influence of small-group interaction. Validation of the model will be based on novel computer vision analyses of videos of crowds of varying nature, structure, and size. The theory and the tools to be developed by this project can assist personnel in law enforcement, emergency management, and event management to minimize violence, speed up evacuations, and reduce accidental injury. The automated tracking software will provide real-time information far beyond what human observers can accurately determine.","title":"DHB: The Process of Collective Behavior: Validation of a Unified Mathematical Model Using Computer Vision Tracking","awardID":"0729363","effectiveDate":"2007-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7319","name":"HSD - DYNAMICS OF HUMAN BEHAVI"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["491302","531866","518440",348303],"PO":["565227"]},"133639":{"abstract":"Spelman College proposes the ARTSI (Advancing Robotics Technology for Societal Impact) Alliance in collaboration with Florida A&M University, the University of the District of Columbia, Hampton University, Morgan State University, Norfolk State University, Winston-Salem State University, the University of Arkansas-Pine Bluff, Carnegie Mellon University, Georgia Institute of Technology, Brown University, Duke University, the University of Alabama, the University of Washington, and the University of Pittsburgh. Seven of these partners are HBCUs and seven are Carnegie Research I institutions. Their collaboration joins the strengths of HBCUs in conducting outreach and education in a nurturing learning environment with those of the R1's for conducting world class research. The ARTSI Alliance will motivate students to pursue computer science careers by emphasizing the creativity and socially beneficial aspects robotics technology with hands-on projects, curriculum, and media. ARTSI activities will span the academic pipeline from K-12 through the faculty ranks. At the K-12 level, students will be recruited with community outreach using robotics and art, robotics road shows, and a robotics educational film online repository. At the undergraduate level, HBCU students will be exposed to new robotics curriculum, and they will be encouraged to pursue advanced training in graduate school through summer research experiences, collaborative, interdisciplinary robotics projects in the arts and health, instruction in technical film documentation, student virtual film festivals, annual robotics conferences, and instruction in entrepreneurship for computer science. At the faculty level, it will increase the number of HBCU faculty who educate students in robotics and involve students in robotics research by providing faculty mentoring, summer research experiences for underrepresented faculty at R1 robotics labs, robotics summer workshops, and development and dissemination of robotics educational material through a web-based portal. The Alliance will have industry partners, including Seagate, iRobot, Microsoft Research, and Juxtopia, as well as educational partners, including Florida-Georgia Louis Stokes Alliance for Minority Participation and Computer Science Teachers Association.","title":"Collaborative Research: BPC-A: ARTSI: Advancing Robotics Technology for Societal Impact","awardID":"0742252","effectiveDate":"2007-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7584","name":"ITR-BROADENING PARTICIPATION"}}],"PIcoPI":["464121","464119"],"PO":["561855"]},"133529":{"abstract":"This proposal requests funds for a \"Million Book Project\" partners research and coordination meeting to be held on November 2-4, 2007, at Carnegie Mellon University in Pittsburgh, Pennsylvania. Annual project partners'<br\/>meetings have been held since 2002 in locations at the primary participating nations: China in 2002, India in 2003, the United States in 2004, China in 2005, and Egypt in 2006. The Million Book Project was begun in 2000, aiming to be the most ambitious mass digitization project ever undertaken. The initial goal was to digitize and provide free-to-read access to one million books by 2007. A $3M ITR grant was made by the NSF and highly leveraged by international partners. To date the Project has scanned over 1.4 million books in China, India and Egypt, in the process stimulating new research in areas associated with large-scale, multi-lingual database storage, retrieval and presentation of results. This meeting will continue valuable ongoing processes of communication, planning, interaction and coordination necessary to continue progress. Key topics to be explored include machine translation and summarization, intellectual property and rights management issues, improving and providing centralized access to the metadata, usability issues, growing the collection, diversity, dissemination, education and others.","title":"Million Book Project Partners Meeting: Grant for a Research and Coordination Meeting","awardID":"0741787","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[355022,"461693"],"PO":["433760"]},"136829":{"abstract":"Our physical world presents an incredibly rich set of observation modalities, such as heat, light, moisture, pressure, motion, etc. Recent advances in wireless sensor networks (WSNs) enable the continuous monitoring of various physical phenomena at unprecedented high spatial densities and long time durations and, hence, open new exciting opportunities for numerous scientific endeavors. Because sensor nodes are battery-powered, the most critical challenge in WSNs is minimizing the use of power, of which the most energy-consuming operation is data transmission. Given the commonly high correlations of sensed data in time and space, an analytical framework for correlation studies and new data gathering protocols is fundamentally important to reduce communication costs through lossless data compression in WSNs. This project is devoted to the fundamental investigation of exploiting temporal correlation In WSNs, for sustaining monitoring in harsh and possibly hostile environments, through an integrated theoretical and empirical approach. From this project, a novel, analytical, adaptive multimodal predictive transmission framework based on predictive coding is developed, for environmental monitoring WSN engineering, to achieve substantial energy savings and, hence, to significantly extend the lifetime of WSNs. Based on the developed framework, a new data gathering protocol suite is designed and implemented. Furthermore, a real-world environmental monitoring WSN testbed in a hilly watershed is deployed for evaluation and validation. Our interdisciplinary education plan uses the built WSN testbed and integrates our research results and new insights into education practice to provide hands-on training and experience for undergraduate and graduate students in both environmental and IT fields.","title":"NeTS-NOSS: Collaborative Research: Investigating Temporal Correlation for Energy Efficient and Lossless Communication in Wireless Sensor Networks","awardID":"0758372","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["550733"],"PO":["565303"]},"141746":{"abstract":"0716452<br\/>Jelena Mirkovic<br\/>University of Delaware<br\/><br\/>0716829<br\/>Peter Reiher<br\/>UCLA<br\/><br\/>CT-ISG: Collaborative Research: Enabling Routers to Detect and Filter Spoofed Traffic<br\/><br\/><br\/>IP spoofing exacerbates many security threats.If spoofing were eliminated or sufficiently reduced, defenses against DDoS, distributed scanning and intrusions would be much simplified and more effective. Of particular interest are spoofing defenses that will be both practical (cheap to deploy and operate) and effective (provide significant benefit in sparse deployment. This project develops two such defense mechanisms: (1) Clouseau, which enables routers on asymmetric paths to accurately infer associations between the route descriptor and the source address. It will support multiple associations (in case of multipath routing) and will promptly update associations when routes change. Clouseau will be integrated with two very effective spoofing defenses: route-based filtering and hop-count filtering, and will protect deploying networks from spoofed traffic. (2) RAD, which helps networks protect themselves from reflector attacks.<br\/><br\/>Clouseau and RAD will operate completely autonomously. <br\/>Deployment of Clouseau at as few as 50 chosen Internet autonomous systems, together with RBF or HCF, will reduce amount of spoofed traffic on the Internet to less than 3%. In isolated deployment, Clouseau with RBF or HCF will reduce spoofed traffic received by the deploying network to less than 3%. RAD system will offer a significant protection from reflector attacks in isolated deployment and an almost perfect protection when RAD is deployed in the Internet core. <br\/><br\/>This research is leading to a significant reduction of spoofed traffic in the Internet. All code will be released to the public, and graduate and undergraduate students will receive valuable training from participation in this project.","title":"CT-ISG: Collaborative research: Enabling Routers to Detect and Filter Spoofed Traffic","awardID":"0823121","effectiveDate":"2007-09-01","expirationDate":"2011-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550312"],"PO":["497499"]},"132826":{"abstract":"This project takes a new approach to understanding human creativity, based on cognitive modeling of creative thought in a musical domain. Cognitive models developed by the Fluid Analogies Research Group (FARG) at the Center for Research on Concepts and Cognition (CRCC) in the past three decades have provided new insight into a wide variety of creative tasks such as solving analogy problems, extrapolating number sequences, and designing typefaces. The domain of music provides an opportunity to extend these techniques for the study of fundamental mechanisms of cognition and creativity. Specifically, the proposed research aims to develop a novel model of music cognition that simulates the creative processes involved in music ? not, however, in the composition or improvisation of music, but in the seemingly much simpler and more common act of music perception. How is music perception creative? Perception is an active process where the brain interprets sensory inputs, and transforms the raw input into a compressed format. Far from being a passive, robotic algorithm, this process of interpretation is quite dynamic and influenced by cognitive context. Such perception is not only subjective, but creative, as evidenced by its generation of novel internal representations of sensory data. A central tenet of the philosophy underlying this work is that the exact same processes that drive the creative perception of sensory input also give rise to the high-level generation of creative thoughts, ideas, and works of art.","title":"Musicat: a computational model of creativity in a musical domain","awardID":"0738384","effectiveDate":"2007-09-01","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":[353273],"PO":["424970"]},"130307":{"abstract":"Throughout the history of technology, modular design has proven to be an effective way to deal with system complexity. Modular design is also routinely applied to software-intensive systems. Software, however, is different from hardware. Specifically, the fact that software can programmatically affect other software broadens the options for modularization. The very nature of modules can be redefined in ways that would be impractical in hardware. Aspect-Oriented Programming (AOP) has recently put forth one of those redefinitions. In AOP, some modules called ''aspects'' directly address the crosscutting nature of some design concerns by modeling those concerns from outside the modules to which the local effects belong.<br\/><br\/>This research will conduct a large-scale empirical validation of the design hypothesis put forth by AOP, and will leverage it to derive principles for modular design. The AOP hypothesis has three sub-hypotheses: (1) Complex software must cope with the existence of cross-cutting concerns; using traditional procedure- or object- oriented design, those cross-cutting concerns show up as design elements scattered throughout several modules and tangled with other concerns within those modules; (2) Scattering and tangling are ''bad'' for the design process; (3) The alternative composition mechanisms embodied in an aspect-oriented language like AspectJ are ''''better'''' than the traditional ones. The empirical validation of AOP will be enabled by an infrastructure called Sourcerer, developed for collecting, searching, and analyzing software on the very-large scale of Open Source software available on the Internet. More broadly, this research will investigate methodologies for conducting empirical research in Open Source software.","title":"Large Scale Empirical Validation of the Aspect-Oriented Design Hypothesis","awardID":"0725370","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7652","name":"SCIENCE OF DESIGN"}}],"PIcoPI":["551111","518206"],"PO":["564388"]},"131649":{"abstract":"Collaborative Research: Algorithms for Near-Optimal Multistage Decision-Making under Uncertainty: Online Learning from Historical Samples<br\/><br\/>Abstract<br\/><br\/>Recent advances in information technologies enable firms to collect and maintain huge amounts of raw data regarding demand, sales history and other aspects of their operations. However, little is known about using this data effectively and efficiently within their decision-making processes, which can often be modeled as multi-stage stochastic optimization problems. In many application domains, such as supply chain management and revenue management, these give rise to complex problems, where the decision in each stage must be made under uncertainty about the future evolution of an underlying stochastic process. Traditional approaches to these problems assume that the uncertainty is defined through explicitly specified probability distributions that are known a priori; the knowledge of these distributions is crucial to the development of the corresponding optimization algorithms. However, in most practical situations the exact distributions are not known, and only historical data is available. This research project aims to develop a general-purpose sampling-based algorithmic framework for these models that, unlike traditional approaches, uses the raw historical data as the source of samples. First, we plan to develop sampling-based algorithmic approaches to approximately solve complex stochastic dynamic programming formulations, the dominant paradigm used for these problems. Second, we focus on sampling-based algorithms for models that combine optimization and learning simultaneously. A common theme between these two research thrusts, and a central feature of our research project, is the development of explicit quantitative analysis of the performance of our algorithms that provide guarantees on the sample-size needed to assure a specified error bound with respect to optimal solution for the true underlying probability distribution.<br\/><br\/>Consider a firm like Amazon that provides millions of different items to customers throughout the US. Clearly, it is important for the company to have the inventory that its customers want, since if an item is out of stock, then the customer is likely to purchase the item from elsewhere. On the other hand, maintaining extra inventory for undesired items has the disadvantage of tying up capital in obtaining them, using significant resources in warehousing this supply, which is further compounded by the risk of perishability and obsolesce. If one had a crystal ball with which one could predict the future, then the company could know how many requests there will be, day by day, for each of the items it sells, and therefore know how much of what should be on hand in each of its warehouses. Instead, one can model the future probabilistically (similar to what a weather forecaster does when saying that there is a 40% chance of showers tomorrow), and then one can cast the problem of making the optimal decisions for these inventory levels as a problem of maximizing the average profit that can be obtained (or minimizing the average costs incurred), where the notion of average is with respect to the randomness used to model our inability to exactly predict the future. This project has the goal of using past historical data as a means for modeling the predictions for future data, and then designing algorithms that produce provably near-optimal decisions based on this approximation. This type of decision-making in the face of uncertainty arises in a wide range of application domains, from selling different classes of airline<br\/>tickets for a portfolio of flight legs to manufacturing a suite of products that rely on overlapping sets of components. This project focuses on settings in which there are multiple stages of decision-making that must be made in the face of an evolving view of the predictions of future<br\/>requirements. The aim is to provide tools to automate such decision-making with algorithms that are guaranteed to quickly produce reliable solutions.","title":"MSPA-MCS: Collaborative Research: Algorithms for Near-Optimal Multistage Decision-Making under Uncertainty: Online Learning from Historical Samples","awardID":"0732169","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":[349617],"PO":["565286"]},"133607":{"abstract":"Spelman College proposes the ARTSI (Advancing Robotics Technology for Societal Impact) Alliance in collaboration with Florida A&M University, the University of the District of Columbia, Hampton University, Morgan State University, Norfolk State University, Winston-Salem State University, the University of Arkansas-Pine Bluff, Carnegie Mellon University, Georgia Institute of Technology, Brown University, Duke University, the University of Alabama, the University of Washington, and the University of Pittsburgh. Seven of these partners are HBCUs and seven are Carnegie Research I institutions. Their collaboration joins the strengths of HBCUs in conducting outreach and education in a nurturing learning environment with those of the R1's for conducting world class research. The ARTSI Alliance will motivate students to pursue computer science careers by emphasizing the creativity and socially beneficial aspects robotics technology with hands-on projects, curriculum, and media. ARTSI activities will span the academic pipeline from K-12 through the faculty ranks. At the K-12 level, students will be recruited with community outreach using robotics and art, robotics road shows, and a robotics educational film online repository. At the undergraduate level, HBCU students will be exposed to new robotics curriculum, and they will be encouraged to pursue advanced training in graduate school through summer research experiences, collaborative, interdisciplinary robotics projects in the arts and health, instruction in technical film documentation, student virtual film festivals, annual robotics conferences, and instruction in entrepreneurship for computer science. At the faculty level, it will increase the number of HBCU faculty who educate students in robotics and involve students in robotics research by providing faculty mentoring, summer research experiences for underrepresented faculty at R1 robotics labs, robotics summer workshops, and development and dissemination of robotics educational material through a web-based portal. The Alliance will have industry partners, including Seagate, iRobot, Microsoft Research, and Juxtopia, as well as educational partners, including Florida-Georgia Louis Stokes Alliance for Minority Participation and Computer Science Teachers Association.","title":"Collaborative Research: BPC-A: ARTSI: Advancing Robotics Technology for Societal Impact","awardID":"0742123","effectiveDate":"2007-09-15","expirationDate":"2011-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7584","name":"ITR-BROADENING PARTICIPATION"}}],"PIcoPI":["542301"],"PO":["561855"]},"133728":{"abstract":"Music conducting is a sophisticated form of gestural communication. Despite centuries of practice, there is no consensus regarding even what is communicated, much less how the information is encoded and decoded. This project develops simultaneous advances in the nature of conducting through instrumentation and measurement; and in the techniques for sensing, detection, and interpretation of human gesture. The project records conducting gestures using wearable, wireless sensors and synchronizes gestural data with video and audio. Working closely with musicians and conductors, the project will develop new hypotheses about conducting gestures, develop new sensors to capture relevant information, and then use machine learning to create a conducting gesture recognition system. The results are a characterization of the information conveyed by conductors and an improved generation of wearable sensors and techniques for sensing human motion.<br\/><br\/>The broader impact of this work includes expanding the role of experimental science in the arts, especially music. Through work with professional and student orchestras, the methods and benefits of research will be clearly communicated to non-scientists. This work will also benefit society through a better understanding of conducting and music. This new understanding may also lead to new techniques for music education. Another application of this work is the creation of interactive exhibits at museums where people can conduct a virtual orchestra, and perhaps people will someday enjoy conducting a personal electronic orchestra at home. Advances in gestural sensing have enormous potential in the field of health care. Using human motion to detect levels and types of activity as well as emotional state could offer great benefits, allowing computers to monitor recovery from injury, at-risk patients, and the elderly.","title":"SGER: Decoding the Human Conducting Gesture","awardID":"0742609","effectiveDate":"2007-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":[355671,"397882","492191"],"PO":["424970"]},"134949":{"abstract":"This project proposes novel strategies for the automatic capture of teamwork in crowded spaces. The initial goal is to develop new methods for acquisition of people and artifact locations using diverse modalities, including machine vision and radiofrequency identification (RFID). Following, software will be developed in order to integrate these observations and track team members and artifacts over time. Ultimately probabilistic reasoning will be used to identify team tasks based on these unified observations. The representative domain of trauma resuscitation is an ideal environment for this work since the roles and tasks of players are well-defined and the flow of work follows a general schema regardless of the patient's injuries. The system will be tested in simulated trauma scenarios using a robotic mannequin patient. <br\/><br\/>There are two key benefits of this work. First, the process of deriving system requirements for computerized teamwork support systems demands analyzing a large number of observations of current practices. Automatic transcription and tagging of teamwork will allow for efficient capture and interpretation of events and is preferable to more tedious and error-prone observations by experts. Second, automatic tracking of team activities is a needed initial step in the development of \"smart rooms\" that provide computerized support of teamwork. <br\/><br\/>The core contribution of this project will be a proof-of-concept system integrating tracking of actors and medical objects using computer vision and RFID tracking. The proposed approach will develop novel algorithms and methods for (i) vision-based person tracking in crowded collaborative environments and (ii) fusion of unreliable data from multimodal sensors to achieve reliable recognition of human activities. <br\/><br\/>Broader Impacts<br\/>The scientific importance of this work is in the need to tag video observations. Many forms of videos are of repetitive behaviors, whether in surveillance applications, work situations, or other uses. In all such cases, applying a grammar to the video, and matching actions and sounds to that grammar, has the possibility of greatly simplifying the job of work analysis - a critical phase in the development process of computer support for complex, high-risk human activities. This work will also provide the foundation for implementing decision aids in environments such as trauma resuscitation and related medical domains that lack effective methods for instrument tracking of work.","title":"SGER - Vision and RFID for Multimodal Tracking of Working Teams","awardID":"0749246","effectiveDate":"2007-09-15","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["419981","121525","409115","518508"],"PO":["388678"]},"125808":{"abstract":"Flapping flight provides high maneuverability for indoor environments.<br\/>To achieve robust intelligence for tasks such as search and indoor<br\/>navigation, the maneuverability of an ornithopter will be combined<br\/>with a learning approach which makes minimal assumptions about the<br\/>nature of disturbances and obstacles. We propose to develop<br\/>algorithms for ornithopters to cooperate in sensing and navigation in<br\/>typical indoor environments without prior maps. Our research will be<br\/>verified with full three dimensional dynamic simulation, a<br\/>multi-tethered laboratory test-bed, as well as with actual indoor<br\/>flying ornithopters.<br\/><br\/>The key research issues to be addressed in this work are:<br\/>1) improved ornithopter mechanics and aerodynamics<br\/>2) robust ornithopter flight control strategies<br\/>3) learning algorithms for cooperative navigation<br\/>of ornithopters using only simple sensor information<br\/><br\/>This research will advance understanding of high maneuverability<br\/>flapping wing vehicles for indoor flight. By combining research from<br\/>the levels of mechanics to learned behavior in a real indoor<br\/>environment, we will test how performance at each level can be<br\/>integrated to achieve robust intelligence.<br\/><br\/>Our project will provide interdisciplinary education for students in<br\/>achieving robust intelligence through the combination of mechanics,<br\/>sensing, control, and learning. This research can lead to flying<br\/>robots which can robustly enter unknown and hazardous indoor<br\/>environments, potentially keeping rescue workers out of harms way.","title":"RI:Collaborative Research: Robust Ornithopter Flight - from Engineering Models to Cooperative Indoor Maneuvers","awardID":"0705419","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["558467"],"PO":["543539"]},"131902":{"abstract":"The 21st ACM Symposium on Operating Systems Principles (SOSP 2007) is scheduled for October 14-17, 2007. This conference, spanning the last 40 years, has been the leading forum for innovative research in operating systems. SOSP 2007 brings together leading researchers in the field and features the best and brightest of the Ph.D. candidates in computer systems. The conference limits distractions and participants focus on the presentation and discussion of the latest results and trends in the field. Topics include the performance, functionality, and security of kernels, file systems, and networks, ubiquitous and mobile computing, sensor networks, overlay and peer-to-peer communications, and power management. The present NSF proposal requested funding to support the attendance of 22 US-based graduate students. Participation in leading conferences is an extremely important part of the graduate school experience, providing the opportunity to interact with more senior researchers and to be exposed to leading edge work. The support requested in this proposal makes possible the participation of students who would be otherwise unable to attend. Some supported students will also be presenters and co-authors of the select set of papers accepted into the conference program. Others actively participate through the poster and work-in-progress sessions of the program. This conference is an important part of the pipeline of researchers as they progress from graduate students to researchers known to others in the field, and continue to research careers in both academia and industry research labs.","title":"Student Travel for 21st Association of Computing Machinery Symposium on Operating Systems Principles","awardID":"0733112","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[350324],"PO":["557609"]},"130604":{"abstract":"NSF 0726698 ? Biochemical Computing: Experimental and Theoretical Development of Error Correction and Digitalization Concepts<br\/><br\/>PI: Evgeny Katz, co-PI: Vladimir Privman<br\/> <br\/>Abstract<br\/><br\/>This research is directed towards the developments of new concepts in biochemical computing. Biocomputing shows promise of providing the mechanisms to better couple ordinary electronics with the signaling of biological organisms. On the conceptual level, it will further understanding of how living organisms manage to control extremely complex and coupled biochemical reactions, i.e., interpret metabolic pathways in the language of information theory. Biocomputing systems of even moderate complexity will allow effective interfacing between complex physiological processes and implantable biomedical devices and will be able to operate in nanobiorobotic and sensing systems. Great advances have been made in biocomputing research in recent years. However, to be practical, as well as compatible with ordinary electronics, biocomputing should be researched for ways to minimize\/correct errors and develop \"digitalization\" concepts. This challenge is taken up in the present research program. Experimental exploration as well as theoretical modeling and optimization are performed for new systems based on encoded DNA sequences, enzymes and DNAzymes that show promise for digital biochemical computing, including the first attempt for an experimental realization of error correction.<br\/> <br\/>The experimental approach includes information processing using encoded DNA sequences, DNAzyme-biocatalyzed reactions and the use of DNA-functionalized magnetic nanoparticles. The error-free DNA sequences are purified using the hybridization procedure with the DNA-functionalized magnetic nanoparticles, amplified by a PCR technique and used as input signals for DNAzyme-based logic gates. Digital XOR and NAND logic gates, copying (fanout), error correction by utilizing redundancy, and signal rectification, are demonstrated. Electronic and optoelectronic probes of the encoded DNA sequences are used to read out the results.","title":"Biochemical Computing: Experimental and Theoretical Development of Error Correction and Digitalization Concepts","awardID":"0726698","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["475949","545613"],"PO":["565223"]},"130967":{"abstract":"The emergence of the Internet is one of the most profound shifts in focus in Computer Science since its inception. Traditionally, Computer-Science research has focused primarily on understanding how best to design, build, analyze, and program computers. Research focus has now shifted to the question of how best to design, build, analyze, and operate networks and the distributed applications that run on top of them. Satisfactorily answering these questions will require the development of a Theory of Networked Computation (ToNC) that is analogous to the Theory of (single-machine) Computation that Computer-Science researchers have already developed. In particular, it will be important to investigate the theoretical foundations of routing in next-generation networks.<br\/> This work will complement ongoing experimental research by examining three foundational aspects of next-generation routing systems: (1) Policy-based, interdomain routing (focusing on distributed algorithmic mechanisms, payment protocols, solution concepts, and privacy), (2) New routing paradigms (focusing on the intrinsic properties of protocols that are not fully distributed, do not require consistent state, or do not use topology-dependent addressing), and (3) New measures of the complexity of routing protocols (focusing on the notion of dependency complexity recently put forth in the networking-research community). <br\/>The PIs have consistently played a leading role in ToNC-community formation. The lead PI is the co-chair of the GENI Scientific Council and is thus positioned to pave the way for ToNC-community participation in GENI, which could result in the development of network services with novel functionality and provable properties.","title":"Collaborative Research: SING: Foundations of Next-Generation Routing","awardID":"0728500","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["560562"],"PO":["565251"]},"132804":{"abstract":"As human reliance on computational tools increases, there is a critical need to support not only routine tasks but also creative activities. The aims of this research are to increase our understanding of the computational character of creative cognition and to transform this understanding into artifacts that support the creative processes in humans. We will focus on the use and retrieval of cross-domain analogies, an ability that has been implicated in creative cognition.<br\/><br\/>The proposed research will produce a new class of methods that exhibit computational creativity through cross-domain analogy and that involve a novel combination of two ideas. One is that the processes of analogical mapping and retrieval are goal directed, which places strong constraints on their operation. The other is that problem statements and solutions are indexed by abstract schemas that support the retrieval of relevant structures even when they have minimal surface similarity. Together, these assumptions should support robust retrieval and mapping of cross-domain analogies, which in turn should lead to novel software tools that aid human creativity. <br\/><br\/>Although the primary focus of this project is on scientific creativity, the same mechanisms and techniques will prove useful in a variety of goal-directed settings that involve computer-mediated creative work, including many aspects of design. In addition to publishing scientific papers, the software for analogical mapping and retrieval will be available to the broader scientific community. In the longer term, the techniques for indexing structures in terms of abstract schemas have considerable potential for aiding the design process and for improving search for content on the World Wide Web.","title":"Computational Approaches to Creativity Through Goal-Directed Cross-Domain Analogy","awardID":"0738317","effectiveDate":"2007-09-15","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":["559662","490305"],"PO":["424970"]},"131957":{"abstract":"This project pursues a computational model of creativity that has analogical reasoning as its basis, with a focus on biologically inspired design. The goals of this project are to (1) understand the nature and role of biological analogies in innovative engineering design, (2) develop computational models of the content, structure and processes of the cross-domain analogies in biologically-inspired engineering design, and (3) develop interactive environments for supporting engineers in making analogies to biological systems. The specific objectives of the proposed exploratory project are to (i) analyze biological analogies in engineering design in terms of current computational models of analogy, and (ii) develop a paper-and-pencil computational theory of cross-domain analogies in biologically-inspired engineering design. <br\/><br\/>The project analyzes observations of design teams engaged in biologically-inspired engineering design to build a paper-and-pencil computational theory of cross-domain analogies in innovative design, which should lead to interactive tools for supporting biological analogies in engineering design. The project lays the foundation for a new computational model of innovative design based on analogies to biological systems. <br\/><br\/>Broader Impacts: Biologically-inspired design has become an important and increasingly wide-spread movement in innovative design for environmentally-conscious sustainable development. The proposed study will help define our longer-term research program of developing a computational model of biologically-inspired innovation and an interactive environment for supporting biologically-inspired engineering design. This study will also provide insights into learning occurring in courses in biologically-inspired design, and suggest ways of enhancing quality of learning.","title":"SGER: Towards a Computational Model of Biological Analogies in Innovative Engineering Design","awardID":"0733363","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7655","name":"ITR-CreativeIT"}}],"PIcoPI":["539354"],"PO":["424970"]},"120727":{"abstract":"Abstract<br\/><br\/>The Network for Computational Nanotechnology (NCN) was established in 2002 and has grown to be a national resource serving the research community in the emerging field of nanoscience and nanotechnology. The NCN is producing new knowledge, simulation approaches, numerical algorithms, and open-source software to help realize the promise of nanoscience. NCN researchers are carrying out simulation and modeling research in three key fundamental research themes: nanoelectronics, nanoelectromechanical systems\/nanofluidics, and nanobiology and medicine. The modeling and simulation tools are available to a broader research community through a web-based cyberinfrastructure, the nanoHUB, located at www.nanoHUB.org. The capabilities of the nanoHUB have been enhanced by the NSF National Middleware Initiative (NMI). The total number of annual users of the educational and resources services on the nanoHUB have grown from under 2000 in 2002 to more than 15,000 in 2006. NanoHUB also offers courses, seminars and tutorials that are being used as educational tools in support of nanoscience and engineering curricula by 692 U.S. colleges and universities. Over the next five years, NCN plans to continue to introduce new formats for instructional delivery, which will allow access to nanoHUB services anytime, anywhere. In addition, it is expected that there will be a strong demand in industry and academe for students well versed in the simulations offered through the NCN research platforms, as well as computer science and engineering students who are engaged in the development and deployment of nanoHUB. <br\/><br\/>The Network for Computational Nanotechnology is a partnership between Purdue University, Norfolk State University (NSU), Northwestern University (NWU), Stanford University (SU), the University of Florida (UF) at Gainesville, the University of Illinois at Urbana-Champaign (UIUC), and the University of Texas at El Paso (UTEP). Through NSF support NCN brings together a community of theorists, computational scientists, and device engineers in nanoscale science and engineering research to address the modeling and simulation challenges in understanding nanoscale phenomena and realizing integrated nanosystems. In addition, NCN has formed strategic partnerships with two Nanoscale Science and Engineering Centers (NSEC) at the University of California Berkeley (UCB) and Columbia University, the on-line MultimediaEducational Resource for Learning and Online Teaching (MERLOT), and the Northwestern University National Center for Learning and Teaching in Nanoscale Science and Engineering. With the approval of the renewal request, faculty from the UC, Berkeley NSEC will join the core NCN team.<br\/><br\/>The vision of NCN is to provide a future in which a diverse community, united by a common culture and enabled by a shared cyberinfrastructure, uses theory, modeling, and simulation to accelerate the transformation of nanoscience to nanotechnology. The NCN team engages in research to explore nanoscale phenomena and devices through the integration of computational research, simulation, and experimentation. Based on this work, the NCN develops, modifies, and installs software tools ? tools to perform simulations on nanoscale systems -- and makes these tools available to a user community through the nanoHUB website, which is enabled by Purdue?s computing infrastructure. <br\/><br\/>The mission of the NCN is to create, deploy and operate a national resource for theory, modeling, and simulation in nanotechnology using the cyberinfrastructure to build and serve diverse communities spanning research, design, manufacturing, education and outreach. This mission is embodied in the nanoHUB and supported by research, education and outreach. The NCN?s goals and objectives are to: (a) carry out research that addresses key challenges through theory, modeling, and simulation; (b) provide professional leadership that brings communities together to identify challenges and move the field ahead; (c) develop new software tools needed for this new field; (d) lower barriers that limit the use of simulation by experimentalists and educators and equip them to be critical, effective users; (e) develop and deploy cyberinfrastructure that efficiently and robustly delivers services for simulation, education, and collaboration; (f) educate and develop a workforce to increase the number and diversity of students and faculty engaged in nanotechnology; (g) disseminate the results of its work and (h) engage the broader community through universally available web technology. <br\/><br\/>NCN is making an important impact on the integration of theoretical and experimental nanoscale research through the delivery of computationally intensive modeling and simulation tools that are being used by almost 3500 simulation users as of February 2006. In addition, NCN is producing educational materials that impact a broad range of users both in research and education. In ad","title":"Network for Computational Nanotechnology","awardID":"0634750","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0700","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"7681","name":"ENG NNI SPECIAL STUDIES"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7564","name":"COMMS, CIRCUITS & SENS SYS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"1675","name":"NANOSCALE: SCIENCE & ENGIN CTR"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"7219","name":"NANOTECHNOLOGY UNDERGRAD EDUCA"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"7237","name":"NANO NON-SOLIC SCI & ENG AWD"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"7604","name":"NANOSIMULATON GROUPS\/NETWORK"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0708","name":"Division of EMERGING ENGINEERING TECHNOLOG","abbr":"EET"},"pgm":{"id":"1467","name":"MATERIALS PROCESSING AND MANFG"}}],"PIcoPI":["520672","520672","535139","535139","535140","456988","503860"],"PO":["431774"]},"132827":{"abstract":"Many proposed technological solutions to future disasters involve the use of wireless cellular technology. However, these same networks become quickly saturated soon after a disaster and remain saturated for critical periods. This project will capture data on cell phone usage (and other communication modes) in terms of when, with whom (what relationship with subject), and for how long the calls take place, and whether the calls are incoming or outgoing. Such data should help in the modeling of communication network behavior in such situations and in understanding how such technologies may be utilized or extended in future emergencies in any community. The goal of this exploratory research is to capture time sensitive communications and other ephemeral data regarding the tragic events surrounding the Virginia Tech (VT) shootings on April 16, 2007. These data will be available for further analyses by multiple interested groups in order to plan for future emergency response and critical peer-to-peer communication. <br\/><br\/>Intellectual Merit: The intellectual merit of this exploratory research is two fold: 1) it contributes to the body of knowledge regarding emergency response and disaster management via mobile communication networks; and 2) it provides a model of communication behavior among ordinary citizens during the first 24 hours of a crisis. The data to be collected can be used to visualize communication patterns and emergency response networking, can reveal support networks for communication and information, and can lead to policy analysis and debate regarding mobile communication, emergency preparedness and response. <br\/><br\/>Broader Impact: The results from this study have the potential to affect the general public and emergency response groups in communities across the US. By understanding the citizen usage and network impact of mobile communication during a crisis in a geographic area, network overload can be mitigated while critical interpersonal communication can be accommodated. This research will also consider problems with the user interface for typing under duress on a small keyboard; and cell phone use by citizens with low computing or reading literacy (such as, the elderly, lower socioeconomic groups, and non-native English speakers) who may not be completely comfortable in English or in cell phone text usage.","title":"SGER: Capturing Ephemeral Communication Data from the Virginia Tech Tragedy","awardID":"0738390","effectiveDate":"2007-09-15","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["486496","550464"],"PO":["427499"]},"132838":{"abstract":"This is funding to support a research colloquium at the annual AECT (Association for Educational Communication & Technology) conference to be held in Anaheim, California October 23-27, 2007. The funding will provide stipends for 20-30 junior faculty and graduate students to participate in the research consortium and accompanying poster session. A virtual community will be developed for communication following the colloquium. A goal of the Association for Educational Communications and Technology (AECT) is to facilitate humane learning through the systematic development, utilization, and management of learning resources, which include media in educational settings. Yet, despite research initiatives underway among its members, most are employed within programs where external funding has not been a priority historically (e.g., in Colleges of Education) and the prospects for advancing research collaborations among most junior faculty and graduate students is inherently constrained. The purpose of this colloquium is to provide a forum during which successful NSF-funded scholars personally mentor junior scholars and graduate students in the nuances of developing a systematic program of inquiry, successful grant proposals, and disseminating research across a range of technology R&D problems and issues. <br\/><br\/>Bringing young and creative researchers to AECT 07 will help advance an important and socially valuable research field. NSF funding will significantly impact the careers of the next generation of researchers by enabling a number of them to take part in both the conference as well as the research colloquium. The students and junior faculty will have an opportunity to gain wider exposure in the community for their innovative work, and to obtain feedback and guidance from senior members of the research community. Participation will also help foster a sense of community among these young researchers, by allowing them to create a social network both among themselves and with senior researchers at a critical stage in their professional development. The PI has indicated that he will act to assure participation by members of traditionally under-represented institutions, and will pay close attention to inclusion of minorities and women.","title":"Fostering Research: A Colloquium for Technology Researchers","awardID":"0738462","effectiveDate":"2007-09-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["456561","469941"],"PO":["565227"]},"134906":{"abstract":"Proposal No: 0749056<br\/>PI: Yang Dan<br\/><br\/>Award Abstract:<br\/><br\/>This award supports the preparation and sharing of computational neuroscience data as part of an exploratory activity aimed at catalyzing rapid and innovative advances in computational neuroscience and related fields. Investigators Yang Dan, Tim Blanche, Jack Gallant, and Frederic Theunissen will make several data sets available, each exploring different aspects of sensory coding: (1) cortical slice data acquired in order to examine the effects of complex spike trains in the induction of long-term synaptic modification; (2) recordings of primary visual cortical neurons made during stimulation with complex stimuli, white noise, and natural images; (3) recordings from visual area V4 during stimulation with parametrically varying bars, rings and gratings; (4) recordings from visual areas V1, V2, and V4 during stimulation with a rapid dynamic sequence of gratings; (5) recordings of neurons at three levels of the avian auditory system during stimulation with complex synthetic and natural sounds; and (6) large-scale neuronal recordings from primary visual cortex made with multi-site electrode arrays that allow simultaneous recording from more than a hundred single units at once. It is anticipated that these data will be useful for the study of spatial and temporal neural coding, nonlinear receptive field properties, learning rules, hierarchical processing strategies, and other aspects of the analysis of complex sensory information.","title":"CRCNS Data Sharing: Neurophysiological Studies of Sensory Coding","awardID":"0749056","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["384399","546744","503433","513166"],"PO":["564318"]},"133729":{"abstract":"This SGER project addresses the largely open problem of motion planning of a high-degree-of-freedom robot (such as a manipulator, a mobile manipulator, or a humanoid robot, etc.) working in a mostly unknown or uncertain and dynamic environment with unknown obstacle motions. A novel real-time adaptive motion planning approach is proposed to tackle the problem. The project focuses on investigating key issues to make the approach feasible beyond simulation in the real world with imperfect sensing. Real-world experiments will be conducted for validation. <br\/><br\/>The proposed research will significantly advance the state of the art in robot motion planning to enable more adaptive and autonomous robots and promise to broaden the application potential of robotics. This project will provide comprehensive training to student researchers in robotics. The research results could be used to attract students of all levels, especially under-represented groups, to science and technology. This project will also help enhancing outreach activities of the PI's lab related to high school students.","title":"Real-Time Adaptive Motion Planning","awardID":"0742610","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["475621"],"PO":["403839"]},"122509":{"abstract":"Zhijie Shi<br\/>University of Connecticut<br\/>0644188<br\/>CAREER: Novel Primitives and Side-Channel Countermeasures in the Design and Implementation of Cryptographic Algorithms<br\/>Panel ID: 070111<br\/><br\/>Astract<br\/><br\/>The enormous number of successful attacks attests to the fact that computer security is a complex issue. It requires research in many layers and components in computer systems, and becomes even more challenging when resource-constrained systems like mobile computing devices and sensor nodes are considered. <br\/>As critical elements of the security of computer systems, cryptographic algorithms are used to achieve basic security functions such as confidentiality, data integrity, and authentication. This research addresses both the design and implementation of cryptographic algorithms. The research studies novel operation primitives that can be added to processors for enhanced cipher and cryptographic hash function designs and lead to ultra-efficient cryptographic algorithms for resource-constrained environments. The research in the implementations of cryptographic algorithms focuses on the defending mechanisms that can be incorporated into the design processes of cryptographic algorithms and computer systems and lead to comprehensive and effective countermeasures to thwart side-channel attacks. Furthermore, the research outcomes of this project will be integrated into a processor design tool to facilitate further study and fast real-world adoption of the research outcomes.<br\/>The broader impact of this project is to reveal the relations between the cryptographic properties of individual operations and the overall security strength of cryptographic algorithms and to understand the impact of side-channel attacks on the design of cryptographic algorithms and computer systems. The open-source improvements to design tools will make the research results readily available to designers and thus enables the widespread deployment of secure implementations of cryptographic algorithms and hardware security mechanisms.","title":"CAREER: Novel Primitives and Side-Channel Countermeasures in the Design and Implementation of Cryptographic Algorithms","awardID":"0644188","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550179"],"PO":["565239"]},"130627":{"abstract":"The goals of the interdisciplinary research in quantum information science are to understand and demonstrate how quantum phenomena can dramatically advance the fundamental capabilities of information <br\/>processing devices. In this context, the investigator seeks to (a) determine the differences between the computational power and limitations of quantum computers and those of classical computers and <br\/>(b) to find new quantum speed-ups for classically difficult problems. Building upon these results, this research explores how these quantum algorithms will allow one to solve more efficiently larger instances of <br\/>computationally hard real-life problems, such as those arising in optimization theory, signal processing, and cryptography.<br\/><br\/>In computational complexity theory, BPP and BQP denote ?Bounded error Probabilistic time? and ?Bounded error Quantum Polynomial time, respectively. Roughly speaking, they represent the classes of problems <br\/>that can be efficiently solved on classical and quantum computers. The exact relationship between them remains unknown, although there is strong evidence that BQP is strictly larger than BPP. To understand what features separate these classes, the investigator will determine purely classical (quantum-free) problems in linear algebra and topology that characterize the power of BQP. This research also involves the <br\/>examination of the potential (and limitations) of a new quantum method for solving hidden subgroup and shift problems that present a general framework for designing quantum algorithms. This method relies upon <br\/>tools from representation theory such as the Schur and Clebsch-Gordon transforms.","title":"Novel Quantum Algorithms for Problems in Linear Algebra, Topology, and Group Theory","awardID":"0726771","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7928","name":"QUANTUM COMPUTING"}}],"PIcoPI":["357424"],"PO":["565157"]},"133917":{"abstract":"Abstract<br\/><br\/>This SGER proposal sets forth a one year research plan to explore two exciting and fundamentally new directions, namely (1) discovering significant scenes and objects in photo collections available on the internet and (2) reconstructing dense geometry from these online photo collections.<br\/><br\/>The scale, diversity, and unorganized nature of photos posted on the Internet present major challenges to existing computer vision techniques. This SGER proposal describes key solutions to address these challenges. The first goal is to devise techniques to automatically infer the content of image collections, by identifying the significant scenes and objects that are contained therein. For example, it may be possible to deduce all of the popular tourist sites, statues, paintings, and other artifacts of Rome from the nearly one million photos on Flickr. This requires having to compute canonical views of these scenes and objects, that together cover the most interesting aspects of these scenes.<br\/>The second goal is to develop multi-view stereo techniques (MVS) that can operate effectively on such uncontrolled and highly variable image sets. Because lighting, camera response, and foreground clutter can differ substantially from image to image, new stereo matching algorithms are required. The PIs will develop strategies for selecting which views to combine, explore matching metrics to factor out lighting and camera variations, and ultimately leverage lighting variations to combine photometric and geometric stereo.<br\/><br\/>Ultimately, this research can lead to the creation of a geometry crawler that scours the Internet for objects to reconstruct such an approach could be used, given sufficient compute time and compute power, to automatically create 3D models for all of the world's well- photographed sites, cities, landscapes, and objects.<br\/><br\/>The outcome of this research consists of tools that can automatically discover and describe scenes and reconstruct geometric models from Internet collections. This outcome will enable a host of important applications, ranging across 3D visualization, localization, communication, and recognition, that go well beyond traditional computer vision problems and can have broad impacts for the population at large.<br\/>In addition, the proposed work will create a large set of new resources for a range of audiences. First, the output of the research will be massive datasets of registered imagery for many world sites and dense 3D reconstructions of those same sites. This data will be distributed broadly to help advance research in the computer vision community. The data will also be made available for many other purposes, such as computer graphics research into image-based rendering, cultural heritage, localization efforts, and scientific visualization.","title":"Discovering and Reconstructing Scenes from Photos on the Internet","awardID":"0743635","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["533242","438138"],"PO":["564316"]},"130529":{"abstract":"DNA Nanotechnology is a branch of science that enables scientists to build nanomechanical devices and regular arrays, using the information content of designed DNA molecules; the components of such species are usually DNA 'tiles' made from molecules designed to branch. The effectiveness and diversity of these constructs can be enhanced markedly by getting the tiles to self-assemble according to logical operations, rather than by a single design. This research involves programming a series of tiles to organize a group of DNA nanomechanical devices according to a given input. The devices consist of two different related types of molecules, so that when one rotates a robot arm in one direction, the other rotates it in the opposite direction, thereby leading to molecular choreography. This choreography will be used to modify the contents of a load carried by a walking device past the robot arms. The importance of this system is that it will prototype programmable molecular-scale assembly lines, capable of algorithmically organizing and relocating potential nanoelectronic components into desired arrangements that will result in useful circuitry.<br\/><br\/>This research involves using TX DNA tiles that correspond to Wang tiles to simulate a finite state machine with output, to design the initial base row for the arrangement. According to the coding of the base row, specific TX tiles and 2-state-device-containing cassettes containing robot arms and PX-JX2 devices are then organized into a 2D array. A walker equipped with cargo will move across the platform that has been organized. The cargo is then modified as a consequence of the computation that creates the array.","title":"Programmable Molecular Movements","awardID":"0726396","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["506031"],"PO":["565223"]},"130716":{"abstract":"Abstract: The University of California Riverside is awarded a grant to develop biologically inspired computational models for visual perception. Perceptual systems take raw sensory input like digital photographs\/movies and identify the objects they contain. Decades have been spent trying to develop perceptual systems, with only modest success. The key innovation of this research is that it incorporates the biological constraints neuroscientists have identified that guide the developmental of natural perceptual systems into the automated development of computational perceptual systems. The project involves an interdisciplinary team and a close collaboration between a computer scientist and a cognitive psychologist. The systems developed in this research learn to work in a way that is similar to biological systems. <br\/><br\/>The project develops a new paradigm for incorporating domain-specific knowledge in this case, biological constraints into evolutionary computation to develop innovative visual systems. This approach systematically addresses the complexity and magnitude of the object detection\/recognition problem in real-world environments. The research generates computational innovations to permit the development of evolutionary learning systems that can utilize developmental neuropsychological constraints. These include (a) cooperative coevolution that allows components of a task to evolve in an environment in which cooperation improves fitness, (b) smart crossover and mutation operators that retain effective components over generations of computational evolution, and (c) a minimum description length constraint that selects operators based on efficiency of description in addition to goodness of fit. The goal of these innovations, collectively and individually, is to reduce the volume of the search space that the evolutionary learning process must traverse to allow it to solve the perceptual problem. The project will use several publicly available databases to demonstrate the results.","title":"BioCOMP: Biologically Inspired Computational Model for Perception","awardID":"0727129","effectiveDate":"2007-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7931","name":"COMPUTATIONAL BIOLOGY"}}],"PIcoPI":["553703",346881],"PO":["565223"]},"134908":{"abstract":"Code switching is a natural linguistic phenomenon in which a speaker mixes two or more languages or dialects, or two or more linguistic registers from the same language. Extensive sociolinguistic studies have been dedicated to this widespread and common phenomenon and there has been some prior work in formal linguistics, but to date it has not been considered a problem of interest to the computational linguistics community. However, in this age of globalization and the current explosion in information and web access, more and more spontaneously generated linguistic data from around the world are being made available to the computational research community. Such data abounds with code switching in its different forms, so there is a real need for computational linguists to address code switching as a central research problem. <br\/><br\/>This exploratory research effort addresses the issues of how to process code switching automatically. It examines the different aspects of code switching, allowing for the creation of better-principled algorithms based on a clear understanding of the phenomenon. The main questions revolve around morphological and syntactic constraints on switching and how these constraints can be modeled computationally. One of the outcomes of this research is the annotation of significant amounts of data exhibiting code switching in different languages, most likely Arabic, Hindi and Spanish. This research aims at initiating a formal study of code switching in a computational framework, which both increases our understanding of the phenomenon, and develops algorithms for processing natural language data that manifests code switching.","title":"SGER: Automatic Processing of Natural Language Code Switching","awardID":"0749062","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0404","name":"Division of BEHAVIORAL AND COGNITIVE SCI","abbr":"BCS"},"pgm":{"id":"1311","name":"LINGUISTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["507533","560340",358423],"PO":["376990"]},"129090":{"abstract":"This research addresses several key deficiencies of existing systems used in real-time and embedded computing. These deficiencies include: (1) a rigid system structure, leading to inflexibility in the way system services are organized and isolated from each other, (2) a semantic gap between the needs of applications and the services offered by the system, and (3) a lack of support for managing time as a first-class resource. The research addresses these deficiencies by developing a component-based system for safe, predictable and efficient execution of application-specific services on a range of hardware platforms. In terms of safety the research seeks to ensure the dependability of a collection of software components, so that system integrity is not compromised, and the extent to which errant or untrustworthy code may impact the resource usage of other components is limited.<br\/><br\/>The research is developing a system that is flexible in its placement of isolation boundaries around component services. The uses of hardware isolation features (e.g., paging, segmentation, virtualization technologies) on processors such as the x86 and ARM are investigated. Trade-offs in the communication overheads between components are studied, along with mechanisms and policies that dynamically adjust the isolation granularity of component services (hence inter-component communication costs) to ensure predictable service delays. This work is expected to form the basis for ongoing research into the design of systems that ensure a high degree of software dependability, including fault isolation at a minimum, while guaranteeing their timely execution. It is expected this will lay foundations for implementing future systems in a wide range of embedded computing domains, particularly those that encompass cyber-physical systems.","title":"CSR --- EHS: The Design and Self-Organization of Component-based Systems for Dependable and Predictable Embedded Computing Environments","awardID":"0720464","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["68374"],"PO":["493916"]},"131916":{"abstract":"This award provides NSF support for student travel for a workshop, specifically for women, to be held in conjunction with the 21st ACM Symposium on Operating Systems Principles (SOSP 2007) will be held at Skamania Lodge in Stevenson, WA, October 14 - 17, 2007. <br\/><br\/>SOSP has been the premier forum for operating systems research. Held every two years, and accepting only 20-25 papers, the conference is highly selective. The SOSP meeting occurs every two years, focused on theories, principles, and practice in operating systems research. The Systers electronic community was formed at the 1987 SOSP. Participation by women has not increased in the interim. In recognition of this anniversary and addressing the continuing need to encourage greater diversity in the discipline, this workshop for women graduate and undergraduate students is held prior to the conference. The workshop is designed as a community building event, serving both to educate more women about the opportunities in systems research and to support women who have started working in the field.","title":"Student Travel Support for a Discipline Specific Workshop for Women at 21st Symposium on Operating Systems Principles","awardID":"0733156","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7584","name":"ITR-BROADENING PARTICIPATION"}}],"PIcoPI":["353750"],"PO":["561889"]},"130706":{"abstract":"Interactive physically based modeling, simulation, and analysis of digitized real-world models are extremely challenging tasks. Physically based simulation approaches, such as finite element methods based on continuum mechanics, are computationally intensive, which makes them impractical for simulating and visualizing large-scale complex data in real-time. The introduction of geometric mapping in this research provides Euclidean parametric domain and regular structure inherent to complex geometric shapes, and provides efficient tools (such as GPU-based computation) to speed up the simulation process. <br\/><br\/>This research tackles the speed bottleneck of physical simulation and visualization of deformable models by exploring the relationship between conformal and harmonic geometric mapping with physically based simulation, and develops efficient algorithms that allow users to perform real-time physical simulation, collision detection, material modeling, and visualization of large-scale, complicated geometric data. In particular, efficient and robust algorithms are investigated to enable dynamic space & time adaptive physical deformation of thin-shells and volumetric objects, by exploiting novel numerical methods to solve PDEs\/ ODEs on graphics hardware, based on surface and volumetric mappings. The PI investigates novel GPU-based hierarchical collision detection algorithms for deformable models, using multiresolution geometry images to represent the bounding deformation trees as dynamic textures in the graphics hardware, to efficiently detect both inter-objects collision and self-collision of deformable models during simulations. This research project also develops powerful GPU-based multiresolution modeling and parallel visualization methods to efficiently represent and render heterogeneous material properties of the simulated deformable models. This investigation has broad impacts on an array of applications spanning physical science, mechanical engineering, medicine, K-12 education, training, and entertainment.","title":"Physical Simulation of Deformable Models Based on Geometric Mapping","awardID":"0727098","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7933","name":"NUM, SYMBOL, & ALGEBRA COMPUT"}}],"PIcoPI":["502215"],"PO":["565157"]},"130707":{"abstract":"Abstract<br\/><br\/>For the past decades, technology scaling has been the driving force for the worldwide semiconductor industry. With the relentless reduction of transistor's feature size, industry has achieved larger-scale of integration, higher operation speed, and lower fabrication cost. However, the scaling of passive devices such as inductors, which are vital for communication and computation chips, is tremendously lagging behind. Consequently, the major portion of today's communication chip is occupied by the inductors, not active transistors. The intrinsic nature of the current planar lithographic technology limits the utility of the components that are more efficient with 3D structures. A properly designed and fabricated 3D spiral inductor with much smaller size could produce comparable performance a large planar inductor of several hundred microns square would. <br\/>DNA scaffold-based assembling strategy has been demonstrated to form versatile, including 3D structures, and additional functionalities can be designed and incorporated into the assembly through specific chemical recognition groups. Combined with parallel process to integrate functional structures onto wafer and into circuits, they offer many opportunities that could greatly improve system's performance. <br\/>This research involves the fundamental synthesis and integration of DNA-directed self-assembled inductors (SAIs), and the novel circuit applications rendered by this potential new capability. Specifically, the investigators study: 1) the chemical synthesis of 3D DNA spirals, and the attachment of various nanoparticles and therefore, different functionalities, to the DNA spirals; 2) the development of reliable ways to achieve parallel integration of such SAIs onto wafer surface and to form electrical connections to the leads, and further testing of the inductor performances; 3) the behavior of these novel inductors using simulation tools, and novel circuit designs based on the 3D SAIs.","title":"Self-assembled Inductors: A New Paradigm in Nanoelectronics Design","awardID":"0727100","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["555498","543501","491854","560299"],"PO":["562984"]},"129180":{"abstract":"Cyber-Physical Systems (CPS) are those computer-based systems that have an intimate coupling with the physical world, which range from the nano-world to systems of systems. Envisioned CPS are complex systems that are composed of hardware components and software components and that must interact with a dynamically changing environment. Many CPS applications are safety critical and thus it is important to ensure they work safely and reliably.<br\/><br\/>Component-based engineering has been widely accepted as an approach to facilitate the design of complex systems. It is based on the premise that a complex system can be designed by decomposing it into simpler components and then by composing the components using interfaces that abstract component complexities.<br\/><br\/>The goal of the proposed work is to develop a compositional framework of components that serve as building blocks of CPS. The approach is to define the notion of a component that includes physical components (sensors and actuators) and computation tasks mapped to hardware platforms. The component is abstracted by a resource interface. Based on this notion, the project aims at the development of compositional analysis techniques for CPS based on compositional analysis of concurrent systems and hierarchical real-time scheduling","title":"CSR--CPS: Component-based Development of Cyber-Physical Systems","awardID":"0720703","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["553656","553657"],"PO":["561889"]},"129191":{"abstract":"As software systems have grown in size, complexity and cost, it has become increasingly difficult to deliver software bug-free to end users, which result in many software failures during production runs at the user site. While much work has been conducted on software failure diagnosis, most previous work focuses on off-site diagnosis (i.e. diagnosis at the development site with involvement of programmers) and thereby is insufficient to diagnose production-run software failure at the user site. <br\/><br\/>To effectively address production-run failures, we propose a novel approach that automatically performs on-site software failure diagnosis right at the moment of a software failure and provide programmers a detailed diagnosis report regarding the occurred failure, including bug type, bug location, likely root cause, fault propagation chain, failure-triggering input, failure-triggering execution environment, potential temporal fixes, etc, without violating user?s privacy concerns or imposing large overhead during normal execution. To achieve the ambitious goal, the proposed research tightly integrates innovations from multiple layers: (1) Low-overhead operating and run-time system support to capture the failure moment without imposing large overhead during normal execution. (2) A novel, extensible, customizable, human-like failure diagnosis protocol. (3) Novel program analysis techniques that are specifically designed for on-site failure diagnosis. (4) Leverage existing and emerging hardware support and simple hardware extensions to reduce overhead.(5) A library-based API to allow applications to control or customize the diagnosis process if necessary.","title":"CSR---PDOS: Online Production-Run Software Failure Diagnosis at the User Site","awardID":"0720743","effectiveDate":"2007-09-01","expirationDate":"2010-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["551063","542046","551097"],"PO":["535244"]},"129390":{"abstract":"There is an expected shortage in bandwidth resources due to the recent success of, and hence the explosive demand for, wireless services and networks. This expected shortage is not so much due to the scarcity of bandwidth, but due to its inefficient use. There exist plenty of ``opportunities\" available along time and frequency dimensions that wireless networks can potentially exploit. It is therefore important to develop a new way of exploiting these opportunities effectively and efficiently.<br\/><br\/>Recent technological advances make it possible to realize SDRs (Software-Defined Radios) or smart radios that, unlike traditional radios, can switch from one frequency to another at minimum cost, thereby enabling ''opportunistic'' spectrum access along time and frequency dimensions. SDRs empower next-generation wireless networks with adaptive and dynamic multi-band access, but introduce several unique cross-layer challenges. On the other hand, the newly-emerging MIMO (Multiple-Input Multiple-Output) technology has great potential for significant throughput enhancements, better interference suppression, and substantial energy savings. SDRs and MIMOs together form a complete means of enabling opportunistic spectrum access along not only time and frequency dimensions (via SDR), but also space dimension (via MIMO). <br\/><br\/>This project will, therefore,<br\/>1. Model, characterize, and analyze the maximum achievable throughput in MIMO-equipped wireless networks;<br\/>2. Derive guidelines for network designers to determine the optimal parameters of wireless networks;<br\/>3. Develop innovative techniques that exploit MIMO to reliably support and maintain QoS in MIMO wireless networks; and<br\/>4. Implement and evaluate the performance of the developed techniques via simulation and experimentation on a multi-band capable wireless testbed that we are currently building with commercial off-the-shelf components.<br\/><br\/>The intellectual merit of the proposed research will be: (1) establishment of both theoretical and practical foundations for next-generation wireless networks to be built with advanced technological components such as SDRs and MIMO; (2) design guidelines for selecting the optimal parameters of wireless networks equipped with these advanced components; (3) solutions to the bandwidth-shortage problem, which is key to next-generation wireless networks; and (4) innovative techniques enabling next-generation wireless networks to support and maintain QoS of multimedia applications. <br\/><br\/>This research will also make broader impacts on: (1) basic research by providing fundamental solutions to challenging problems to be encountered in future wireless networks; (2) regulatory bodies such as FCC by providing rigorously-proven solutions and guidelines for establishing flexible and efficient spectrum policies; and (3) undergraduate and graduate education via integration of research, teaching, and learning, especially the use of the developed solutions and their implementations on the proposed testbed in students' classes and independent study projects.","title":"NeTS-WN: Opportunistic Bandwidth Sharing Using MIMO: Beyond Time and Frequency","awardID":"0721529","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["553551","508426"],"PO":["557315"]},"128191":{"abstract":"Encryption and signatures are two of the most fundamental cryptographic tools, enabling private and authentic communication. Yet, their adoption in applications, such as email, distributed storage, digital rights management and health care systems, has been slow. A primary reason is that many common operations that arise when using these tools in practice create (sometimes insurmountable) key management problems. This research studies how to design encryption and signature schemes with greater key management flexibility.<br\/><br\/>In particular, this research focuses on situations where data encrypted (or signed) under one cryptographic key needs to be re-encrypted (or re-signed) under another cryptographic key by a semi-trusted proxy given special information. For example, suppose Alice wants her mail server to forward her encrypted email to Bob without being able to read her messages. Investigators will broaden the theoretical foundations of proxy re-cryptography and work with industry partners to evaluate their performance in practice. The research will study the application of proxy re-signatures for maintaining the integrity of dynamic content distribution of documents on the Web.<br\/><br\/>Graduate students and women researchers will be involved in all aspects of this project, collaborating on both the theory and practice. Techniques derived from this research will be incorporated into cryptography and computer security courses at both universities.<br\/><br\/>Thus, this project will help develop future well-rounded scientists able to design and apply cryptographic tools.","title":"CT-ISG Collaborative Research: New directions and applications of proxy re-cryptography","awardID":"0716386","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["554404"],"PO":["565264"]},"129060":{"abstract":"The InterGridSolve project is developing an environment that will enable scientists to easily harness Grid resources provided by Computational Services Providers (CSPs) ranging from federally funded TeraGrid to commercially available services such as those provided by Amazon Elastic Compute Cloud (EC2). In order to support the Scientific Computing Environments (SCEs) that many scientists use in their work (e.g., Matlab, Octave), and to incorporate flexible computing models, the research is enhancing GridSolve, a pre-existing brokered RPC environment. GridSolve is based on the GridRPC API proposed by the Open Grid Forum (OGF) and uses function handles and sessions to make remote procedure calls on Grid resources. GridSolve includes resource scheduling, execution monitoring and fault tolerance. General purpose data movement mechanisms (i.e., data handles) are being designed and added to GridSolve in order to enable workflow applications. The data handle mechanisms are to be proposed as extensions to the GridRPC API. Tools to enable workflow applications on Grid resources using data handles in GridSolve are being explored, and several classes of workflow applications (such as simple DAGs) are being implemented. <br\/><br\/>Broader Impact: This project will enable computational scientists across multiple domains to use their accustomed SCEs to access Grid resources made available by various service providers, and to run computationally intensive, workflow jobs on these resources.","title":"Collaborative Research: CSR-AES InterGridSolve: A Virtualized, General Purpose, and Interoperable Grid Computing Environment for Computational Science","awardID":"0720359","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["335186"],"PO":["493916"]},"129181":{"abstract":"The AToMS (Automatic Tuning of MPI Software) project is investigating a software system that can automatically improve the performance of large-scale scientific applications. Scientific codes that demand more and more computing resources are critical to modern science, but too often scientists must spend time constructing programs that run fast at the expense of doing their primary research. As computers contain an increasing number of computing elements, the problem worsens. The goal of the AToMS project is to begin to address this issue by applying automatic application tuning.<br\/><br\/>An optimizing compiler transforms programs into sematically equivalent ones that perform better. When dealing with any complicated architecture it is difficult to know which transformations will improve performance. Auto-tuning takes the approach of trying many transformations and empirically evaluating the resulting versions. AToMS performs this auto-tuning with a combination of a static analysis based code transformation engine (called ASPhALT) and runtime support in the OpenMPI library. The combination of compile-time and run-time support allows for code restructuring to overlap computation and communication and the creation of optimized data-packing routines. In addition, code can be generated to take advantage of multicore processor<br\/>architectures.<br\/><br\/>Intellectual Merit: The merit of the proposed pro ject is in gaining understanding about what is required to support automatically tunable MPI programs. Broader Impacts: This project will impact the high-performance and scientific computing community and users of parallel computers by making it easier to achieve good performance.","title":"Collaborative: CSR-AES: System Support for Auto-tuning MPI Applications","awardID":"0720712","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["527984","561820"],"PO":["535244"]},"128092":{"abstract":"Proposal Number: 0716389<br\/>PI: Rafail Ostrovsky<br\/>Institution: University of California, Los Angeles <br\/>Lead<br\/><br\/>Proposal Number: 0716199<br\/>PI: Brent Waters<br\/>Institution: SRI International<br\/>Sub<br\/><br\/>Proposal Number: 0715739<br\/>PI: Dan Boneh<br\/>Institution: Stanford University<br\/>Sub<br\/><br\/>Proposal Number 0716230<br\/>PI: Dawn Song<br\/>Institution: Carnegie Mellon University<br\/>Sub<br\/><br\/><br\/><br\/>Title: Collaborative Research CT-T: Cryptographic Techniques for Searching and Processing Encrypted Data<br\/><br\/><br\/><br\/><br\/><br\/>In this proposal we consider the question of what constitutes identities in cryptography. Typical examples of identities include your name and your social-security number, or your fingerprint\/iris-scan, or your address, or your (non-revoked) Public-Key coming from some trusted public-key infrastructure. In many situations, however, where you are defines your identity. For example, we know the role of a bank-teller behind a bullet-proof bank window not because he or she shows us her<br\/>credentials but by merely knowing her location. In this proposal, we ask the following question: is it possible to have the \"\"geographical position\"\" of a party take part in defining the set of credentials<br\/>she has? What are the new possibilities in terms of what we can achieve in this setting?<br\/><br\/>First, we propose to consider the central task in this setting, i.e.,<br\/>securely verifying the position of a device. Despite much work in this area, we have preliminary results that show that in the \"\"vanilla\"\" (i.e., standard) model, the above task (i.e., of secure<br\/>positioning) is impossible to achieve.<br\/><br\/>We propose to study the proof of position in the bounded storage model (i.e. where we assume some bound on the total memory of the adversary).<br\/>In this setting, we wish to achieve two tasks: secure positioning, and position-based key exchange. While the question of secure positioning has been asked in the past, no satisfactory answers exist. <br\/><br\/>The second question (of position-based key exchange) has not been asked in the past. We also ask a broader question: whether position-based Secure Multi-Party Computation can be achieved in this setting.","title":"Collaborative Research: CT-T: Cryptographic Techniques for Searching and Processing Encrypted Data","awardID":"0715739","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["521488"],"PO":["565239"]},"126091":{"abstract":"The introduction of statistical techniques in computer vision has yielded a number of interesting algorithms able to partially solve certain constrained recognition problems. However limitations on computing power and available training data impose certain difficult tradeoffs which are rarely quantified so that choices of parameters and models are typically done in an ad-hoc manner. These tradeoffs can only be quantified in a context where the statistical properties of the objects and their appearance in the images are well defined, yet this is far from the case in real images. The alternative, which is the goal of this project, is to perform an analysis of the same issues in a synthetic stochastic setting, using a generative model for images. Object classes are stochastically generated and instantiated in the images, together with clutter, occlusion and noise. The generative model should be rich enough to qualitatively pose the same problems as real images, yet sufficiently simple to enable quantitative analysis; hence this is not an attempt to synthesize real images. Questions regarding the limits of feasibility of various tasks such as detection and classification as a function of key parameters defining the generative model is analyzed quantitatively, in particular the analysis of the tradeoff between accuracy and computation time. The emphasis on integrating computation time in the analysis gives rise to new types of statistical questions, and new forms of asymptotic regimes as a function of the image resolution, the number of distinct classes and their variability. The hope is that the proposed framework will offer a setting in which systematic algorithmic choices can be made and contribute to the development of concrete computer vision algorithms.<br\/><br\/>Computer vision algorithms have produced some partial solutions to some constrained problems such as face detection, hand written digit recognition, or face recognition in severely restricted settings. Since a proper theoretical foundation for the field is lacking, a wide variety of algorithms have been proposed based on ad-hoc choices and it is difficult to assess what components of the different approaches are the most useful, which elements should be extended further and which elements should be dropped. The first step in laying a theoretical foundation for computer vision algorithms is a statistical description of the population of images. Since this is very hard to define the investigators propose to study a synthetically generated world of images, which is much simpler but which gives rise to qualitatively similar tradeoffs and challenges. In this synthetic setting the investigators will rigorously quantify the tradeoffs and hopefully be able to draw important conclusions with respect the algorithmic applications.","title":"Synscenelab: A statistical analysis of feasibility and computability of scene interpretation in synthetic stochastic images","awardID":"0706816","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1269","name":"STATISTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[334604],"PO":["565309"]},"129490":{"abstract":"There has been a remarkable increase in download of content provided by both traditional commercial suppliers as well those by amateurs. Users have very diverse computer equipment ranging from handheld devices to desktops, and downloaded items range from simple stock quotes to news stories to full movies. Such highly heterogeneous circumstances will be predominant in the networks of the near future. Current schemes for content download are inefficient at addressing the mentioned heterogeneity. The goal of this project is to obtain new and improved schemes that would result in better access to content for the users while improving the network utilization.<br\/> <br\/>The research will focus on three coding techniques to attack the problem: rateless coding at the application layer, network coding at the network layer, and collaborative coding at the physical layer. Quantitative and qualitative limitations of network and rateless coding in heterogeneous environments will be studied to develop new practical coding schemes appropriate in such circumstances. Another research direction is to investigate and analyze mechanism to make networks more uniform using physical layer collaborative transmission schemes. An assessment will be made on how this process affects the performance of the higher layer coding schemes. <br\/><br\/>Broader Impact: The research, if successful, will improve the efficiency and availability of data in networks. This has the potential to benefit directly and indirectly the population at large. In addition, this collaborative research has the potential to obtain fundamental new insights at the interface of coding and information theory and combinatorial optimization. Several PhD students will be supported and trained in interdisciplinary areas and they would also obtain valuable industrial experience.","title":"NeTS-NBD: Collaborative Research Coding and Transmission Schemes for Content Download","awardID":"0721888","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["402458","348167"],"PO":["565090"]},"129380":{"abstract":"In large and complex communication networks, architectural decisions regarding functionality allocation are often more important than the details of resource allocation algorithms themselves. This NSF-funded project aims to develop a scientific foundation for designing network architectures by building upon recent successes in understanding protocols as optimizers and layering as mathematical decompositions. In particular, the PIs at five institutions collaborate to conduct a wide range of closely-connected research activities that substantially improve upon the state-of-the-art. Starting from a convex optimization formulation of the architecture design problem, the project investigates a wide range of alternative decompositions that provide different scalability, convergence, and complexity tradeoffs. The PIs then determine whether the properties of these alternative architectures continue to hold under stochastic network dynamics and non-convex objectives and constraints, and develop new architectural designs from a careful study of such dynamics. Mathematically, this project leads to a long-overdue union between network optimization and stochastic networks theory, and enables a systematic approach to leverage advances in general non-convex optimization.<br\/><br\/>Broader Impact: This project has clear synergy with the NSF's GENI initiative. The research provides a strong, analytic foundation for the design of future network architectures, including clean-slate solutions that deviate from todays Internet. The exploration of new ways to decompose functionality, with the influence of network dynamics and non-convexity in mind, will result in new protocols and mechanisms that can be evaluated in the GENI infrastructure.","title":"FIND: Collaborative Research: Towards An Analytic Foundation for Network Architectures","awardID":"0721484","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["382234"],"PO":["565090"]},"128291":{"abstract":"Title: Collaborative Research: CT-ISG: Accurate Sampling of the Internet<br\/><br\/>for Effective Anomaly Detection<br\/><br\/><br\/><br\/>Abstract:<br\/><br\/><br\/><br\/>Sampled traffic data has been increasingly used as input for anomaly<br\/><br\/>detection systems, as the high link speeds make it impossible to<br\/><br\/>examine each and every packet. This raises an important question of<br\/><br\/>whether sampling has a (negative) impact on the accuracy\/effectiveness<br\/><br\/>of anomaly detection, and if so how to mitigate this effect.<br\/><br\/><br\/><br\/>Intellectual Merit: This project systematically studies the question<br\/><br\/>mentioned above from the following three angles. First, we will<br\/><br\/>identify traffic features that are critical for a wide range of<br\/><br\/>anomaly detection schemes and quantify how much they are distorted by<br\/><br\/>various sampling schemes. Second, we will design new sampling or<br\/><br\/>measurement techniques that preserve enough accuracy to support<br\/><br\/>effective anomaly detection, while being cost-effective and<br\/><br\/>light-weight. Third, we will study how to correlate the NetFlow<br\/><br\/>samples obtained at the edge routers with the information-rich data<br\/><br\/>generated using existing data streaming algorithms, for much better<br\/><br\/>anomaly detection than pure sampling. The new scientific knowledge<br\/><br\/>learned through this research will provide us with much better<br\/><br\/>technologies to monitor large high-speed networks for anomalous<br\/><br\/>behaviors.<br\/><br\/><br\/><br\/>Broader impact: The results will be broadly disseminated through<br\/><br\/>publications, invited talks and tutorials, and open-sourcing of<br\/><br\/>software developed for this project. The PIs' collaboration with<br\/><br\/>tier-1 ISP's will facilitate the transfer of technology from research<br\/><br\/>environment to actual managing of production networks. Research<br\/><br\/>results will be incorporated into information security curriculum.<br\/><br\/>Both PIs have been actively engaging under-represented groups in<br\/><br\/>research and higher education and will continue and expand these<br\/><br\/>efforts.","title":"Collaborative Research: CT-ISG: Accurate Sampling of the Internet for Effective Anomaly Detection","awardID":"0716831","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["551132"],"PO":["529429"]},"128060":{"abstract":"The main goal of High-Performance, Power-Aware Computing (HPPAC) workshop is to provide a timely forum for the exchange and dissemination of new ideas, techniques, and research in power-aware, high-performance computing. HPPAC will present research that reduces (1) power, (2) energy consumption, or (3) heat generation, with little or no performance penalty. The workshop will:<br\/>. provide a forum that brings together international experts and researchers interested HPPAC;<br\/>. provide a venue for presentation and discussion of recent results related to HPPAC;<br\/>. disseminate recent HPPAC research by publishing peer-reviewed workshop proceedings; and<br\/>. promote awareness of HPPAC across the scientific community through proceedings and a web site.","title":"High-Performance Power-aware Computing Workshop (HPPAC)","awardID":"0715533","effectiveDate":"2007-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}}],"PIcoPI":["563791"],"PO":["565272"]},"129391":{"abstract":"This project centers on investigating network architectures and abstractions for system-level optimization of wireless networks operating in an interference-limited regime. The central idea is to coordinate network transmissions so they are 'aligned' with the character of the traffic and environment.<br\/><br\/>The research leverages data mining techniques to generate coarse traffic abstractions, capturing the salient characteristics of the spatio-temporally-diverse traffic and environment. These abstract traffic loads drive a slower time-scale system-level optimization of coordinated transmission schedules across neighboring base stations, while allowing faster (local) dynamic scheduling driven by the realizations of individual user traffic and dynamic interference. The research draws on tools from adaptive, robust and stochastic optimization for both analysis and algorithmic development. The research agenda is unique in that it develops an integrated view and foundational design principles needed to realize the coupling of individual user dynamics with problems ranging from measuring and abstracting user population traffic\/environment to network coordination. Preliminary results suggest that this approach has the potential to enable substantial reductions in interference and average power usage, while increasing coverage and service uniformity.<br\/><br\/>This work can drive beneficial changes in current and future wireless technologies and standards. U.T. Austin's Wireless Networking and Communications Group's (WNCG) strong ties with industry provide concrete opportunities for this work to have a broader impact. In addition, this project includes education-based initiatives, including curriculum development, training of graduate students, and involvement of undergraduates, exposing them to research and industry in an integrated manner.","title":"NeTS-WN: Network Architecture and Abstractions for Environment and Traffic Aware System-Level Optimization of Wireless Systems","awardID":"0721532","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560221","541981"],"PO":["557315"]},"128181":{"abstract":"Energy infrastructure is a critical underpinning of modern society that any compromise or sabotage of its secure and reliable operation will have a prominent impact on people's daily lives and the national economy. This project develops a hardware-in-the-loop reconfigurable system with embedded intelligence and resilient coordination schemes that would tackle the vulnerabilities of the power grid. This system differentiates itself from previous and existing research efforts in the following key aspects. First, it capitalizes and integrates new power electronic technologies in the system design to facilitate a more direct reconfiguration of the physical makeup of the grid. Second, it pushes the intelligence toward the lower level of the power grid such that local devices have the capability to make decisions and to react more quickly to contingencies. Third, it adopts control-theoretic real-time adaptation strategies for analytic assurance on providing desired dynamic responses to unpredictable system changes to efficiently maintain the availability of large distributed systems. Finally, the system is evaluated not only through simulation, it is also implemented and demonstrated on a microgrid testbed. The evaluation is conducted from three aspects, including real-time responsibility, fault resiliency, local collaboration capability. The power grid is a typical example of complex networks of highly interacting subsystems. Solving these fundamental problems to create a resilient power grid has a direct and immediate impact on this and other critical infrastructure. The project is coupled with a strong educational component including an innovative multi-university curriculum design, active recruitment of students from underrepresented groups supported by existing programs, and broad dissemination of research findings.","title":"Collaborative Research: CT-T: A Resilient Real-Time System for a Secure and Reconfigurable Power Grid","awardID":"0716337","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["381789"],"PO":["521752"]},"128192":{"abstract":"Proposal Number: 0716389<br\/>PI: Rafail Ostrovsky<br\/>Institution: University of California, Los Angeles <br\/>Lead<br\/><br\/>Proposal Number: 0716199<br\/>PI: Brent Waters<br\/>Institution: SRI International<br\/>Sub<br\/><br\/>Proposal Number: 0715739<br\/>PI: Dan Boneh<br\/>Institution: Stanford University<br\/>Sub<br\/><br\/>Proposal Number 0716230<br\/>PI: Dawn Song<br\/>Institution: Carnegie Mellon University<br\/>Sub<br\/><br\/><br\/><br\/>Title: Collaborative Research CT-T: Cryptographic Techniques for Searching and Processing Encrypted Data<br\/><br\/><br\/><br\/><br\/><br\/>In this proposal we consider the question of what constitutes identities in cryptography. Typical examples of identities include your name and your social-security number, or your fingerprint\/iris-scan, or your address, or your (non-revoked) Public-Key coming from some trusted public-key infrastructure. In many situations, however, where you are defines your identity. For example, we know the role of a bank-teller behind a bullet-proof bank window not because he or she shows us her<br\/>credentials but by merely knowing her location. In this proposal, we ask the following question: is it possible to have the \"\"geographical position\"\" of a party take part in defining the set of credentials<br\/>she has? What are the new possibilities in terms of what we can achieve in this setting?<br\/><br\/>First, we propose to consider the central task in this setting, i.e.,<br\/>securely verifying the position of a device. Despite much work in this area, we have preliminary results that show that in the \"\"vanilla\"\" (i.e., standard) model, the above task (i.e., of secure<br\/>positioning) is impossible to achieve.<br\/><br\/>We propose to study the proof of position in the bounded storage model (i.e. where we assume some bound on the total memory of the adversary).<br\/>In this setting, we wish to achieve two tasks: secure positioning, and position-based key exchange. While the question of secure positioning has been asked in the past, no satisfactory answers exist. <br\/><br\/>The second question (of position-based key exchange) has not been asked in the past. We also ask a broader question: whether position-based Secure Multi-Party Computation can be achieved in this setting.","title":"Collaborative Research: CT-T: Cryptographic Techniques for Searching and Processing Encrypted Data","awardID":"0716389","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["533831","521734"],"PO":["529429"]},"129171":{"abstract":"The AToMS (Automatic Tuning of MPI Software) project is investigating a software system that can automatically improve the performance of large-scale scientific applications. Scientific codes that demand more and more computing resources are critical to modern science, but too often scientists must spend time constructing programs that run fast at the expense of doing their primary research. As computers contain an increasing number of computing elements, the problem worsens. The goal of the AToMS project is to begin to address this issue by applying automatic application tuning.<br\/><br\/>An optimizing compiler transforms programs into sematically equivalent ones that perform better. When dealing with any complicated architecture it is difficult to know which transformations will improve performance. Auto-tuning takes the approach of trying many transformations and empirically evaluating the resulting versions. AToMS performs this auto-tuning with a combination of a static analysis based code transformation engine (called ASPhALT) and runtime support in the OpenMPI library. The combination of compile-time and run-time support allows for code restructuring to overlap computation and communication and the creation of optimized data-packing routines. In addition, code can be generated to take advantage of multicore processor<br\/>architectures.<br\/><br\/>Intellectual Merit: The merit of the proposed pro ject is in gaining understanding about what is required to support automatically tunable MPI programs. Broader Impacts: This project will impact the high-performance and scientific computing community and users of parallel computers by making it easier to achieve good performance.","title":"Collaborative: CSR-AES: System Support for Auto-tuning MPI Applications","awardID":"0720678","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["558550","486083","558548"],"PO":["493916"]},"126290":{"abstract":"The project augments our existing WebBase facility, by adding computation and storage servers. WebBase (http:\/\/dbpubs.stanford.edu:8091\/~testbed\/doc2\/WebBase\/) is a facility that crawls targeted portions of the Web at regular intervals. The system thereby creates unique time series of topic or domain focused snapshots.<br\/><br\/>Existing snapshots include quarterly collections of all government Web sites, collected over several years, a number of 2005 daily crawls over 350 sites that were relevant to hurricane Katrina, and daily crawls of sites related to several California elections. The purpose of these collections is to enable computing research that will make large Web archives accessible to historic and other analysis. The system is enabling web research, at Stanford and elsewhere, on topics such as filtering, searching and tagging of web resources. The system also enables research by social scientists who are studying social, political and cultural trends.","title":"CRI: CRD Analysis Toolbenches for Web Archives","awardID":"0707464","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["447448"],"PO":["563751"]},"125080":{"abstract":"Computer graphics is commonly used for interactive visualization and rendering in video games, electronic commerce or scientific visualization. These applications often demand real-time results, including multiple bounces of light (global illumination), material changes and spatially-varying local lighting. Computer graphics is also increasingly used to prototype or design illumination and material properties, for industries as diverse as animation, entertainment, automobile design, and architecture. A lighting designer on a movie set wants to pre-visualize the scene lit by the final illumination and with objects having their final material properties -- be they paint, velvet or glass. An architect wants to visualize the reflectance properties of building materials in their natural setting. In many applications, much greater realism and faithfulness can be obtained if the lighting or material designer could interactively specify these properties. In this research, we are developing the theoretical foundations and next generation practical algorithms for high quality real-time rendering and lighting\/material design.<br\/><br\/>Our research involves both significant theoretical and practical components. We are developing a new theoretical framework for analyzing the dimensionality of local object regions and locally-low dimensional approximation. We also analyze the theory and practical algorithms for designing materials, while rendering the final scene with full global illumination. Because appearance is not linear in the BRDF, our formulation involves a multi-linear tensor representation to handle multiple bounces. For interactive rendering of scenes with local lighting, and for general lighting design, we are developing an approach that relights a scene given a full incident light field. Finally, one of the banes of precomputation-based approaches is the long time for precomputation, especially once global illumination effects are taken into account. We are developing the theory and algorithms for a new photon-mapping approach that substantially accelerates the process.","title":"Collaborative Research: Theory and Algorithms for High Quality Real-Time Rendering and Lighting\/Material Design in Computer Graphics","awardID":"0701775","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["485160"],"PO":["532791"]},"129480":{"abstract":"The eFIT (Enabling Future Internet innovations through Transit wire) project aims to enable future innovations by ensuring strong universal connectivity at the architectural level. Innovations are enabled by the abundant and affordable computing resources provided by Moore's Law, and universal connectivity provided by the Internet. Computing resources are likely to become more plentiful and affordable, but the universal connectivity provided by the Internet is facing major challenges, as demonstrated by the prevalent use of network address translation (NAT) and accelerated growth of the global routing table. The current Internet architecture provides end-to-end connectivity by putting both user networks and Internet service providers (ISPs) in the same address and routing spaces. User networks and ISPs have different purposes, distinct characteristics, and are moving in almost opposite technological directions. However the inter-dependency between network users and ISPs imposed by the existing architecture creates a major roadblock to future Internet innovations.<br\/><br\/>When a system grows larger in size by orders of magnitude, a change in form becomes necessary. The eFIT design enables innovation by first focusing on universal connectivity. eFIT places user networks and provider networks in different address and routing spaces, removing the inter-dependency between the two worlds. With eFIT, users can simply treat the Internet transit core as a transit wire with strong universal connectivity, while providers are insulated from the various problems caused by explosive growth in user networks. Therefore both users and providers will be able to innovate freely on their own without any architectural constraints.<br\/><br\/>Broader Impact: This new architecture design will have a broad impact on the research community, service providers, and Internet users. eFIT enables graduate students to explore new directions for fundamental problems such as security. Even more broadly, it will liberate Internet users from the current architectural constraints and encourage a new wave of application innovations.","title":"NeTS-FIND Collaborative Research: Enabling Future Internet innovations through Transit wire (eFIT)","awardID":"0721859","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["543560"],"PO":["565090"]},"128270":{"abstract":"CT-ISG: Visualization-Based Characterization and Analysis of Network Traffic<br\/>PI: Kwan-Liu Ma, University of California at Davis<br\/>Project Period: 09\/01\/2007 - 08\/31\/2008<br\/>Project Summary<br\/>For an organization to maintain trustworthy and normal operation of computing systems, one strategy is to closely monitor the traffic in and out of its networks for detecting anomalies, and responding to and tracking down attacks in a robust and timely manner. However, characterizing the communication activities and content across all network protocol layers, domains, and<br\/>applications can result in vast amounts of information. Current representation and interpretation methods for such Internet-wide decentralized information are still quite rudimentary. Automated methods often fail to cope with the dynamic nature of the systems and operations. In order to drastically increase our capability to achieve cyber security, we propose to develop a new visualbased network traffic characterization technology with which massive data flows be intelligently summarized into visual forms that can be efficiently employed in subsequent analysis steps. The resulting visualization, often highly abstracted notion of the data, makes what hidden in the information of excessive scale perceivable. We will place our focus on the development of visual means and interaction methodologies coupled with machine learning for characterizing network traffic and connectivity information. Our study intends to use massive and exhaustive collections of session summary data provided by our collaborators at the Lawrence Livermore<br\/>National Laboratory. Our research results will thus directly benefit working analysts. We would like to eventually incorporate such new visualization based approach into all facets of a cyber security information management system, assisted by our collaborators at the Intel Corporation,in order to drastically enhance the effectiveness, usability and extensibility of both reactive and<br\/>proactive systems to fight malicious cyber attacks and abuse. This one-year project gives us the opportunity to work towards this direction.","title":"CT-ISG: Visual Characterization and Analysis of Network Traffic","awardID":"0716691","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["552243"],"PO":["529429"]},"129381":{"abstract":"This project investigates a new class of abstractions to simplify network design and configuration which is (i) task-driven, i.e., captures the intended performance, security, manageability, or resilience of a network design; and (ii) network-wide, i.e., captures the requirements of the network as a whole rather than of individual devices. It is a radical departure from prior efforts that merely model the underlying protocols and mechanisms.<br\/><br\/>The focus is on enterprise networks, an area largely unexplored by researchers. Through bottom-up studies of actual enterprise network designs, the project obtains insights into the goals operators have for their networks. The studies employ unique ?white-box? methodologies involving extensive and iterative interactions with operators.<br\/><br\/>The project develops abstractions, along with the rationale and criteria for measuring their effectiveness in three areas: (i) implementation of security and resilience policies; (ii) use of VLANs to simplify management; and (iii) network evolution through planned maintenance. It demonstrates the power of these abstractions in simplifying both top-down network design, and validation of network properties. More specifically, it develops the theory for ?configurators?, or systems that can generate box level configuration from high-level design requirements, and a pre-selected set of protocols and mechanisms, and it investigates ?semantic auditing? techniques for formally verifying that a network's existing box-level configuration produces the intended network behavior. <br\/><br\/>Broader Impact: The research aims to produce fundamental knowledge and principles for turning network design and configuration into a science. It will also help enhance the coverage of network management in undergraduate and graduate curriculum. A new graduate class on Network Management will be created at Purdue and the usability of abstractions will be validated using controlled studies involving students training to become IT professionals.","title":"Collaborative Research: NBD: An Abstraction Driven Approach to Characterizing and Designing Networks with Analyzable Properties","awardID":"0721488","effectiveDate":"2007-09-01","expirationDate":"2011-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["508447"],"PO":["564993"]},"125092":{"abstract":"0701832<br\/>Jagannathan, Suresh<br\/>Purdue University<br\/><br\/>Kala: An Efficient and Scalable Time Travel Infrastructure for Concurrent Systems Suresh Jagananthan<br\/><br\/>The notion of time travel, the ability of an implementation to revert a concurrent computation to an alternative feasible global state is investigated. Recent work on software transactions or speculative execution provide a constrained form of time-travel: when a transaction aborts due to a serializability violation, the transaction's effects are reverted. Similarly, the effects of a speculative thread can be undone if data dependency violations are detected. However, the policies that dictate when a transaction or a speculative action must abort, and where computation resumes, are very rigid, are not specified by the programmer, and often over-constrained.<br\/><br\/>The broader ramifications of time travel and revocation on programming language design and specification, compiler analysis, and runtime implementation is the focus of this research. Effective support for time travel can enable a number of new programming abstractions for concurrent programming. This research entails the development of abstractions that revert computation based on programmer-specified invariants, specification techniques that define relations among program states used to guide revocation strategies, static analyses that identify equivalences among states, and compiler and runtime structures to enable efficient reversion of control and state.","title":"Kala: An Efficient and Scalable Time Travel Infrastructure for Concurrent Systems","awardID":"0701832","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["558390"],"PO":["564388"]},"129470":{"abstract":"Wireless ad hoc\/sensor networks are playing an increasingly important role in our lives, for which collaboration among distributed nodes is crucial for their success. While most existing approaches for node collaboration are restricted to local and link behavior, this research takes a new, network-wide view: a general methodology, belief propagation (BP), is employed to provide a systematic, accurate, and yet flexible framework for collaborative information processing and dissemination in wireless networks. <br\/>Belief propagation is a computing algorithm operating on graphical models, while in wireless networks there is a communication graph reflecting connectivity topology. This research investigates the synergy of the two: where the computing graph meets the communication graph. First, it provides design guidelines and analytical tools to facilitate application of BP in wireless networks, leading to distributed, robust, scalable, and energy-efficient communication and network protocols. Meanwhile, the impact of real communication constraints on the design and analysis is explicitly studied. Extension to generalized BP and hybrid architectures is also addressed. Throughout this research, application-specific and data-centric approaches, and cross-layer approaches, are actively explored to facilitate design and analysis and improve performance. <br\/>This research lies in the interface of networking, communications, and computing, and relies heavily on tools from information theory, communication theory, Bayesian inference, graphical theory and models, and communication\/computation\/information complexity. Its outcome may advance the theory and practice of these areas, and contribute to the evolution of next-generation wireless networks. The multi-disciplinary nature of this research also lends itself to cross-disciplinary education and well-rounded training of students.","title":"WN: Collaboration of Networked Nodes through Belief Propagation: Where Computing Meets Communications","awardID":"0721815","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["544836"],"PO":["557315"]},"128260":{"abstract":"Only two number-theoretic assumptions --- hardness of factoring and of<br\/><br\/>computing discrete logarithms --- underlie essentially all public-key<br\/><br\/>cryptosystems in widespread use today. For lower-level primitives<br\/><br\/>such as hash functions, random number generators, and stream ciphers,<br\/><br\/>the situation is even worse: existing provably-secure constructions<br\/><br\/>are too inefficient to compete with practical alternatives such as<br\/><br\/>SHA-1 or AES, and so the primitives in use today have no rigorous<br\/><br\/>justification for their security.<br\/><br\/> <br\/><br\/>This research will investigate new classes of computational<br\/><br\/>assumptions based on lattices. Based on these assumptions, the<br\/><br\/>investigators will seek to design cryptographic primitives that are<br\/><br\/>both provably secure and comparably efficient to existing, deployed<br\/><br\/>schemes. The research will explore the use of lattices to construct<br\/><br\/>basic cryptographic primitives, including hash functions, pseudorandom<br\/><br\/>generators, shared-key authentication protocols, public-key encryption<br\/><br\/>schemes (including those secure against chosen-ciphertext attacks),<br\/><br\/>and digital signatures. The educational component of this work will<br\/><br\/>focus on educating graduate students as well as developing <br\/><br\/>introductory-level surveys of lattice-based cryptography.","title":"Collaborative Research: CT-ISG: Efficient Cryptography Based on Lattices","awardID":"0716651","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["519626"],"PO":["565264"]},"129481":{"abstract":"A global regulatory effort is underway to allow secondary spectrum trading by license holders and flexible access by end-users. Preliminary evidence in early incarnations of secondary spectrum markets indicates a sophisticated market structure and suggests that realizing full potential of deregulated spectrum entails overcoming fundamental technical and economic challenges.<br\/><br\/>This project has the following research objectives: (i) Development of pricing strategies that capture network-wide effects of interference and that render secondary spectrum markets profitable for license holders; (ii) Design of market rules that facilitate new entrants and improve end-user perception in economic and performance terms; (iii) Development of resource discovery and monitoring algorithms that allow market participants to efficiently and securely utilize network services. These objectives are pursued in an integrated analytical framework that includes techniques of dynamic stochastic optimization, game theory, incentive engineering and tractable teletraffic modeling of large wireless networks.<br\/><br\/>This project promotes healthy deregulation of the wireless communication sector and shows promise for societal impact in view of the attendant economic activity and effective utilization of an important national resource. The educational component involves curriculum innovation aimed at facilitating the interaction between regulatory and technical communities, extracurricular activities in amateur radio, and outreach to members of minority and under-represented groups.","title":"WN: Collaborative Research: Management of Secondary Markets in Deregulated Wireless Networks","awardID":"0721860","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["486132","451601"],"PO":["557315"]},"127193":{"abstract":"The goal of this research project is to facilitate the sharing of information across enterprise boundaries, by facilitating the integration of separately constructed data bases. Because such data bases never have identical content, it is necessary to write transforms (or adaptors) to convert such disparate data into a common form. The construction of such transforms is widely believed to be a major cost of data integration projects. <br\/>The purpose of the Morpheus project is to capture a large number of such transforms in a repository by crawling the web for publicly available ones and providing high level tools for efficient transform construction. In addition, powerful browsing tools are anticipated that allow users to locate \"\"\"\"interesting\"\"\"\" transforms quickly in the repository by providing keyword search of documentation, search within a classification hierarchy of transforms, search by the provenance of transforms, as well as search by the input\/output characteristics. <br\/>Morpheus is expected to dramatically reduce the cost of writing and maintaining data integration transforms, which will ease the difficulty of future data integration projects. <br\/>This project will support graduate students at both Massachusetts Institute of Technology and University of Florida. In addition, transform construction will be used as student exercises in data base classes at both institutions. Further information can be obtained from the project web site: http:\/\/www.cise.ufl.edu\/~jhammer\/morpheus\/ where research results will be disseminated and prototype code will be available.","title":"III-COR: Collaborative Research: The Morpheus Data Transformation Management System","awardID":"0711891","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["483585"],"PO":["469867"]},"129382":{"abstract":"One of the key problems in today's Internet is that basic measuring and monitoring functionality has not been built in from the outset.<br\/>Although infrastructure has been added and ad hoc solutions have been created to allow monitoring and measurement of various Internet behaviors, we still don't know a great deal more about the Internet. The next-generation Internet will require an infrastructure that gives more emphasis to self-monitoring and self-measurement from the beginning. This research focuses on the value of providing a near-ubiquitous, flexible hashing infrastructure that allows approximation schemes for a variety of network measurement and monitoring tasks. The focus is motivated by the great value of deploying hash-based structures, including their relative simplicity, flexibility, and cost-effectiveness. <br\/><br\/>Broader Impact: The goal of such an infrastructure would not only be to handle issues that have already arisen in today's network, but also to provide a general framework for handling additional, currently unknown problems that may arise in the future. It is anticipated that such an infrastructure will prove sufficiently valuable that it will be made part of the standard architecture for Internet devices.","title":"NeTS FIND: A Network-Wide Hashing Infrastructure for Monitoring and Measurement","awardID":"0721491","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560092"],"PO":["565090"]},"128293":{"abstract":"Abstract:<br\/><br\/><br\/><br\/>This research considers the question of what constitutes identities in cryptography. Typical <br\/><br\/> examples of identities include a person's name and social-security number, or fingerprint\/iris-scan, <br\/><br\/> or address, or a (non-revoked) Public-Key coming from some trusted public-key infrastructure. In <br\/><br\/> many situations, however, where the person is located defines his or her identity. For example, <br\/><br\/> we know the role of a bank-teller behind a bullet-proof bank window not because he shows us his <br\/><br\/> credentials but by merely knowing his location. One of the questions that this research focuses <br\/><br\/> on is the following: is it possible to have the \"\"geographical position\"\" of a device take part in <br\/><br\/> defining the set of credentials this device has? What are the new possibilities in terms of what <br\/><br\/> can be achieved in this setting? First, this research examines the central task in this setting, <br\/><br\/> i.e., securely verifying the position of a device. Despite much work in this area, our preliminary <br\/><br\/> findings show that in the \"\"vanilla\"\" (i.e., standard) model, the above task of secure positioning is <br\/><br\/> impossible to achieve. <br\/><br\/><br\/><br\/> This research focuses on a different model: to study the proof of position in the bounded storage <br\/><br\/> model (i.e. where we assume some bound on the total memory of the adversary). In this setting, <br\/><br\/> this research aims to achieve various tasks including secure positioning, position-based key exchange, <br\/><br\/>and more general position-based secure functionalities. The broader impact of this project is to first id<br\/><br\/>entify various flaws in previous attempts; second, to propose a new framework where rigorous proofs <br\/><br\/>are in fact possible; third, to open this important area of research for further study by putting <br\/><br\/>it on solid theoretical foundations. The overall aim of this project is to develop a principled <br\/><br\/>approach to position-based cryptography, to define key problems, and to establish both impossibility <br\/><br\/>results and new frameworks that are provably secure.","title":"CT-ISG: Foundations of Position Based Cryptography","awardID":"0716835","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["533831"],"PO":["565264"]},"129151":{"abstract":"Large-scale applications distributed across thousands of machines over the wide area network are difficult to build and maintain. To enable sharing <br\/>of data across machines, many applications use specialized storage and data transfer tools such as a DHT, scp or GridFTP. Although file systems are <br\/>successful in becoming a common building block for cluster applications, it remains unclear if file systems could provide similar benefits to wide area distributed applications. This research describes a novel wide-area file system, WheelFS, that allows distributed application developers to use a generic file system interface to store and share application data easily among wide-area machines. <br\/><br\/>Two new approaches make WheelFS attractive for use by distributed applications. First, WheelFS provides semantic cues for application developers <br\/>to express desired tradeoffs among failure resilience, data consistency and file system performance at the granularity of individual files and directories.<br\/>Second, WheelFS optimizes wide area data transfer by writing application data <br\/>to local disks and reading a cached copy from a nearby machine whenever possible.<br\/><br\/>This project demonstrates the uselessness of WheelFS via the experience of building a number of distributed applications, such as a cooperative web cache, a data-intensive Grid application, a distributed digital library and a<br\/>PlanetLab measurement utility.","title":"CSR-PDOS: ISG: Collaborative Research: Building distributed, wide-area applications using WheelFS","awardID":"0720644","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["518136"],"PO":["535244"]},"129393":{"abstract":"As sensing devices become increasingly sophisticated, more widely deployed in the real world, and more advanced in their capabilities, they are being deployed in richer, more diverse, and more sophisticated applications (such as providing visitor guides, monitoring patients in the home, or managing workflows). This project develops a new general-purpose programming model, group-based programming, for developing an emerging class of sensor applications that monitor heterogeneous data and abstract it into higher-level concepts like events, phenomena, and workflows. Group-based programming develops a unified, declarative framework for integrating heterogeneous data into abstract groups (sets of devices) and the data streams (views) they produce; composing groups and views; and, equally importantly, expressing communication, security, and privacy constraints. It synthesizes ideas and techniques from databases and data integration, real-time-systems, and streaming algorithms, in order to provide a higher-level framework for application development. The project develops an efficient runtime support layer for group-based programming across a broad array of sensor devices of different types, with automatic optimization capabilities that exploit the underlying properties of the underlying network and devices. Finally, it validates the suitability of this model across a variety of applications in hospital and home health care. The project will train two graduate students and a variety of summer students at the undergraduate and\/or high school level, will develop a graduate\/undergraduate course in sensor network applications, and will result in publicly available software.","title":"NeTS\/NOSS: ASPEN: Abstraction-based Sensor Programming Environment","awardID":"0721541","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["517980","460517","553656","486185"],"PO":["565303"]},"129162":{"abstract":"Recent years have seen a rapid growth of enterprise data centers that host thousands of high-density blade servers and provide outsourced commercial IT services. There are two key challenges for effectively operating a modern data center. First, different customers have to be assured by meeting their required service-level agreements (SLAs) such as response time and throughput. Second, power consumption has to be controlled in order to reduce operation costs, and avoid failures caused by power capacity overload or system overheating due to increasing high-density.<br\/><br\/>This project aims to develop a holistic management framework which controls power consumption and required application-level SLAs simultaneously with theoretical guarantees on both. This cross-layered framework features a constrained multi-input-multi-output control model to manage multiple blade servers at the cluster level. In sharp contrast to traditional solutions that rely on heuristic-based management schemes, this research adopts a rigorous design methodology that is based on a control-theoretic foundation for systematically developing control strategies, with analytic assurance of control accuracy and system stability. This project also develops decentralized control algorithms for large-scale application services running on a large number of servers in a data center. In addition, related challenges such as system controllability guarantee and thermal management will be addressed.","title":"CSR---PDOS: A Holistic Framework for Power and Performance Control in Data Centers","awardID":"0720663","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["554423"],"PO":["535244"]},"128194":{"abstract":"National Science Foundation <br\/>CISE\/CNS <br\/>Form 7 Review Analysis and Recommendation <br\/><br\/>Proposal Number: 0716368 <br\/>PI: Daniel Lopresti <br\/>Institution: Lehigh University <br\/>Lead <br\/><br\/>Proposal Number: 0716393 <br\/>PI: George Nagy <br\/>Institution: Rensselaer Polytechnic Institute <br\/>Sub <br\/><br\/>Proposal Number: 0716647 <br\/>PI: Elisa H. Barney Smith <br\/>Institution: Boise State University <br\/>Sub <br\/><br\/>Proposal Number: 0716543 <br\/>PI: Christopher Borick <br\/>Institution: Muhlenberg College <br\/>Sub <br\/><br\/><br\/><br\/>Title: Collaborative Research CT-T: Following the Paper Trail: Reliable Processing of Voting Records for Trustworthy Elections <br\/><br\/><br\/>Proposal Abstract <br\/><br\/>Provisions for the inclusion of a physical record, in the form of hand- or machine-marked ballots, or as a Voter Verified Paper Audit Trail (VVPAT), are central to guaranteeing safe and secure elections. However, the processing of such records during the initial counting of votes or in the conduct of audits has raised its own set of problems which span broad technical and social boundaries. <br\/><br\/>The aim of this project is to study issues that currently make paper records more of a nuisance than an integral component in trustworthy voting systems. Specifically, the principal investigators are working to characterize the statistical distribution of mark sense errors as a function of ballot layout and quality in optical scanning, to examine approaches for unbiased visual auditing based on ballot images, to investigate the possibility that a concept known as homogeneous class display (HCD) can facilitate manual recounts, and to evaluate recognition errors that may arise in processing the VVPAT used with Direct Recording Electronic (DRE) systems. They are also interested in the effects these issues have on procedures for testing the paper handling components of voting systems in accordance with operational constraints, including the modest training received by most poll workers. This work on voting technologies is supported by ? and supports ? a planned survey and focus groups they are conducting to measure voter confidence and acceptance and to identify common misconceptions and concerns, including accessibility to disabled voters. Beyond its broad impact on the development of more reliable and trustworthy voting technologies, this project more generally has implications for the highly accurate computer processing of any information encoded in human readable form.","title":"Collaborative Research: CT-T: Following the Paper Trail: Reliable Processing of Voting Records for Trustworthy Elections","awardID":"0716393","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["371109"],"PO":["529429"]},"129195":{"abstract":"Applications utilizing garbage collection often require up to five times more heap memory than similar applications using explicit memory management. In large server applications, such poor memory utilization can cause the throughput performance to degrade ungracefully, leading to unstable systems and unexpected failures.<br\/>The goal of this project is to develop a memory-efficient garbage collection framework for these servers. The framework has three components not existing in today's commercial garbage collectors: compartmental heaps, phase-based garbage collection invocation policy, and priority page eviction policy. Collectively, these three components allow any garbage collectors utilizing our framework to perform more efficiently while requiring less memory. The ultimate result is an increase in the throughput performance and a predictable and graceful throughput degradation behavior of these servers under extreme memory demands.<br\/><br\/>The success of our proposed work will help promote the transfer of the technologies developed into practice through the industry collaborations and into the classroom through the various related courses. In a broader context, the proposed work will improve the performance and robustness of server applications including application servers and web services, which are the foundations of web based applications serving millions of users each day.","title":"CSR--PDOS: Memory Efficient Garbage Collection Framework for Java Server Applications","awardID":"0720757","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":[342311],"PO":["493916"]},"127491":{"abstract":"This project studies three aspects of human linguistic communication: the language used in the communication (for example, whether formal or informal), the topology of the social network of the communicators (for example, whether the the speaker is embedded in a single tight-knit group), and the roles the communicators occupy in an organization (for example, whether the speaker is an upper-level manager, or an administrative assistant). In the past, computer scientists and sociologists have analyzed these aspects in isolation, while sociolinguists and linguistic anthropologists have elaborated qualitative joint models. The ever-increasing flow of electronic communication offers new opportunities to analyze and quantitatively model these aspects of communication.<br\/><br\/>The project uses the Enron email corpus as a testbed for the development of computational joint models of these three aspects of communication, focusing on linguistic features (such as topic, genre, and speech act) and topological abstractions (such as subgroup analysis) that can be reliably and automatically analyzed in electronic communication. The work is being evaluated via concrete prediction tasks, such as the prediction of a person's organizational role based on the topology and linguistic content of their communication, and the prediction of how likely two people are to communicate in the future based on a limited sample of their communications.<br\/><br\/>The work is expected to have various potential applications, both for the general public, in the form of improved human-computer interaction for email clients and software that accesses email, and for the law enforcement and intelligence communities, in the development of automated techniques for discovering leadership and predicting communicative behavior.","title":"RI: Email, Social Networks, and Organizations: Investigating How We Use Language to Create and Navigate Social and Organizational Relations","awardID":"0713548","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["507533"],"PO":["565215"]},"127392":{"abstract":"Proposal 0712956 <br\/>PI: Todd Zickler<br\/>Institution: Harvard University<br\/><br\/>Title: RI: Toward Shape from Specular Reflections under Real-world Illumination<br\/><br\/>Abstract:<br\/>The recovery of shape information from image data is a central problem in computer vision, and decades of research have led to the development of computational tools for inferring shape from a variety of visual cues, including shading, texture, color, and shadows. An important visual cue for shape is specular reflection. Specular<br\/>(mirror-like) surfaces are abundant in both natural and man-made environments. Metal, glass, the wavy surface of a pond, and glazed ceramics are a few examples. Specular surfaces reflect incident light toward an observer without attenuation, and when they are curved, they present a distorted version of their illumination environment that contains very rich information about their shape. While perceptual studies suggest that humans make use of this visual cue, the underlying mechanisms are not yet known, and computational tools for inferring shape from specular reflections under real-world illumination do not yet exist. Instead, due to the complexity of the relationship between a specular shape and its images, previous analysis has been limited to controlled, unnatural environments and\/or very limited types of surfaces. This proposal moves in a fundamentally different direction by specifically considering arbitrary smooth surfaces in uncontrolled, real-world illumination conditions. This seemingly difficult task is made manageable by a novel approach with two key components: 1) the consideration of far-field illumination environments in which the environment-surface distance is large relative to the relief of the surface; and 2) the analysis of ``specular flow''---the dense motion field on the image plane that is induced by the relative movement between a specular surface and its environment. This approach provides a unique balance between tractability and practical validity, and it may be a pivotal step in furthering our understanding of a powerful visual cue.<br\/><br\/>Progress reports for this project will be regularly updated at http:\\\\www.eecs.harvard.edu\\~zickler","title":"RI: Toward Shape from Specular Reflections under Real-world Illumination","awardID":"0712956","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["515747"],"PO":["564316"]},"129350":{"abstract":"In large and complex communication networks, architectural decisions regarding functionality allocation are often more important than the details of resource allocation algorithms themselves. This NSF-funded project aims to develop a scientific foundation for designing network architectures by building upon recent successes in understanding protocols as optimizers and layering as mathematical decompositions. In particular, the PIs at five institutions collaborate to conduct a wide range of closely-connected research activities that substantially improve upon the state-of-the-art. Starting from a convex optimization formulation of the architecture design problem, the project investigates a wide range of alternative decompositions that provide different scalability, convergence, and complexity tradeoffs. The PIs then determine whether the properties of these alternative architectures continue to hold under stochastic network dynamics and non-convex objectives and constraints, and develop new architectural designs from a careful study of such dynamics. Mathematically, this project leads to a long-overdue union between network optimization and stochastic networks theory, and enables a systematic approach to leverage advances in general non-convex optimization.<br\/><br\/>Broader Impact: This project has clear synergy with the NSF's GENI initiative. The research provides a strong, analytic foundation for the design of future network architectures, including clean-slate solutions that deviate from todays Internet. The exploration of new ways to decompose functionality, with the influence of network dynamics and non-convexity in mind, will result in new protocols and mechanisms that can be evaluated in the GENI infrastructure.","title":"FIND: Collaborative Research: Towards An Analytic Foundation for Network Architectures","awardID":"0721380","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560222"],"PO":["565090"]},"129471":{"abstract":"The full coverage model, where every point in the deployment region must be covered by at least one sensor, is pervasive in the wireless sensor network community. For applications that involve tracking movements at large scale such as tracking of thieves and robbers fleeing with stolen objects, tracking of animals in forests, and tracking the spread of forest fire, using the full coverage model makes sensor deployment prohibitively expensive. No sound model currently exists that can be used for systematic deployment of such large scale applications.<br\/><br\/>This project proposes a novel model of coverage called Trap Coverage that can be used for systematic deployment of sparse sensor networks, while ensuring frequent tracking of movements of interest. Most existing theoretical and systems work are not applicable to this new model because of the inherent sparsity of the network implied by the trap coverage model. The overall goal of this project is to establish a strong foundation for all large scale movement tracking applications and address the key systems issues faced in such applications. The project applies rigorous mathematical analysis, experimentation on a large scale sensor network testbed, and real-life deployment of a campus-wide object tracking system called AutoWitness to design, develop, and evaluate the algorithms and protocols developed in this project. In addition to providing hands-on research experience to undergraduate and graduate students in building a real wireless sensor network, the AutoWitness system is expected to help reduce property thefts in a university campus.","title":"NeTS-NOSS: Collaborative Research: Doing More with Less: Tracking Movements Using a Sparse Sensor Network","awardID":"0721817","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["542039"],"PO":["565303"]},"128261":{"abstract":"The rapidly growing demand of 3D holographic imaging systems has created a significant interest in many disciplines. However, these scanned images reveal human body details and raise privacy concerns. In this project, the team develops: 1) a virtual test bed for privacy-aware imaging. Similar to the \"phantoms\" widely used in medical studies, the team intends to develop a device-independent test database that can simulate the output of a 3D human body scanner for a broader research community. 2) The team develops robust and fast algorithms for segmenting human bodies and detecting private body parts. Many machine learning algorithms are coordinate-dependent and limited by the training data space. Existing algorithms only work within small bounding boxes that do not warrant an acceptable performance. In this project, the team uses innovative Analogia Graph and Relative Template Matching algorithms for speed and accuracy. 3) The team develops the algorithm for detecting anomalous objects on human body using curvature measurement and spatial density filtering models. Finally, 4) the team develops a method for assessing the visual privacy algorithms based on detection accuracy, privacy and aesthetic measurements. <br\/><br\/>The anticipated results will have broader impacts on privacy-aware security in airports and other large infrastructures. It can benefit custom-fit products that are designed from personal 3D scanning data. It can be used in reconstruction of ancient artifacts in digital archeology. In addition, it can be applied to medical diagnoses, such as virtual colonoscopy. Finally, this project can benefit multidisciplinary education of human-centric systems.","title":"CT-ER: Privacy Algorithms for Human Imaging Systems","awardID":"0716657","effectiveDate":"2007-09-01","expirationDate":"2008-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["423885"],"PO":["427499"]},"129482":{"abstract":"Wireless ad hoc networking has become a critical technology enabling node communications without network infrastructure. However, current technologies do not provide satisfactory performance in terms of capacity, connectivity, and delay. Recently, several cooperation schemes have been proposed to improve the network performance. They significantly depart from the traditional point-to-point link abstraction and conventional network architectures and will have a profound impact on the network performance and design.<br\/><br\/>The goal of this research is to develop the foundations and practical algorithms for applying emerging cooperation schemes in wireless ad hoc networks. These schemes include (i) cooperative communications where multiple nodes intentionally transmit concurrently at the physical layer, for example, cooperative diversity, distributed multiple-input multiple-output (MIMO), and distributed beamforming, (ii) network coding where nodes combine data received from neighbors and then transmit these combinations to their neighbors to reduce the number of transmissions and improve throughput, (iii) cooperative infrastructure where infrastructure (e.g., wired base stations) is overlaid over wireless ad hoc networks. This research will develop fundamental performance bounds for cooperative networks, as well as new algorithms and mechanisms for providing network-level services.<br\/><br\/>The broader impacts of this project include the dissemination of research results through journal and conference publications, and a strong education component that promotes teaching, training, and learning through the active involvement of research students. Education materials will be developed and disseminated for a new course to be taught jointly at the two universities.","title":"NeTS-WN: Collaborative Research: Cooperative Wireless Networking: Foundations and Practice","awardID":"0721861","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["545655","545656"],"PO":["557315"]},"129130":{"abstract":"In large and complex communication networks, architectural decisions regarding functionality allocation are often more important than the details of resource allocation algorithms themselves. This NSF-funded project aims to develop a scientific foundation for designing network architectures by building upon recent successes in understanding protocols as optimizers and layering as mathematical decompositions. In particular, the PIs at five institutions collaborate to conduct a wide range of closely-connected research activities that substantially improve upon the state-of-the-art. Starting from a convex optimization formulation of the architecture design problem, the project investigates a wide range of alternative decompositions that provide different scalability, convergence, and complexity tradeoffs. The PIs then determine whether the properties of these alternative architectures continue to hold under stochastic network dynamics and non-convex objectives and constraints, and develop new architectural designs from a careful study of such dynamics. Mathematically, this project leads to a long-overdue union between network optimization and stochastic networks theory, and enables a systematic approach to leverage advances in general non-convex optimization.<br\/><br\/>Broader Impact: This project has clear synergy with the NSF's GENI initiative. The research provides a strong, analytic foundation for the design of future network architectures, including clean-slate solutions that deviate from todays Internet. The exploration of new ways to decompose functionality, with the influence of network dynamics and non-convexity in mind, will result in new protocols and mechanisms that can be evaluated in the GENI infrastructure.","title":"FIND: Collaborative Research: Towards An Analytic Foundation for Network Architectures","awardID":"0720570","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["531675","561963"],"PO":["565090"]},"129493":{"abstract":"This project's driving vision is to provide under-resourced urban communities with cost-effective wireless mesh networks, mobile access, and transformational applications including health sensing. This vision will be realized and test-driven via a deployed experimental wireless mesh network in an under-resourced Houston community with experimental mobile devices distributed to community residents. Residents of the community will be engaged with ethnographically-driven qualitative inquiry and analysis to better understand their needs, usage, and user-perceived performance of the wireless infrastructure. This project presents an unprecedented opportunity to holistically study all components of a wireless system, from the end user to the mesh backhaul.<br\/><br\/>With a multi-disciplinary approach spanning wireless networking, mobile computing, and ethnographic techniques, this project will make fundamental contributions in (i) theory and development of predictable and resilient mesh network services, (ii) design and deployment of usable and energy-efficient mobile access, and (iii) ethnographic evaluation of user impact in under-resourced urban communities.<br\/><br\/>This project will produce new technologies for optimizing wireless mobile computing and understanding the technological needs of under-resourced urban communities. The experimental deployment in an under-resourced and primarily Hispanic Houston community will provide low-cost access to IT for its residents. Its success will demonstrate the possibility to achieve affordable, economically-sustainable, wireless broadband access for all. The project will offer opportunities for minority students in the universities and the served neighborhoods. Our extensive collaboration with community leaders, equipment manufacturers, and health-care providers will help transfer technologies and lessons for future IT deployments.","title":"NeTS-WN: Collaborative Research: Mesh Networks for Under-Served Urban Communities: Engaging Users and Integrating Mobile Access and Health Sensing","awardID":"0721894","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["548310","548312"],"PO":["557315"]},"129141":{"abstract":"With increased device miniaturization and commoditization, a new breed of embedded real-time systems, comprising what we designate as Cyber-Physical Infrastructures (CPIs), are increasingly being embedded in physical buildings at home, work, schools, malls, airports, hospitals, etc. By virtue of its utility-like nature, a CPI is likely to cater to the needs of various constituents, supporting any number of applications, some of which may be critical whereas others may be elective or even recreational. Harnessing the power of such CPIs will hinge on a streamlined process whereby relatively unsophisticated programmers are able to rapidly develop and deploy applications without having to understand or worry about the underlying, possibly complex CPI resources and runtime support, while at the same time allowing for the certification of the developed application with respect to safety properties. <br\/><br\/>This project focuses on an integrated approach to the programming and safety verification of CPI applications by recognizing that \"types\" and \"type systems\", which have proven to be instrumental in the evolution of modern programming languages, could be used to encapsulate safety properties related to the performance and reliability of CPI applications. To that end, this project aims to develop type systems that are able to support the compositional verification of real-time and QoS properties of CPI applications, the incorporation of these novel type systems into a high-level programming language, and the use of such a language in the development of prototype CPI application to demonstrate the premise of casting safety and correctness properties as types.","title":"(CSR--EHS\/CPS) Leveraging Type Systems for the Development of High-Assurance Cyber-Physical Systems and Appications","awardID":"0720604","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["526817","562061","438360"],"PO":["561889"]},"128173":{"abstract":"Collaborative Research: CT-ISG: Secure Capacity of Wireless Networks<br\/><br\/>The last decade has witnessed an amazing growth in wireless communications and networking applications. More and more subscribers are relying solely on their wireless communication and computing devices for communicating sensitive information. Preserving the security of wirelessly transmitted information is becoming ever more challenging, yet essential. This important issue is currently dealt with at the higher layers of the protocol hierarchies, yet the need to deal with it in physical layer is imminent as the security of many cryptographic algorithms is hard to evaluate and has caused disappointment in the past. In addition, there is rising interest in large networks of low-complexity transmitters including sensor nodes and RF-ID tags that may not have room for complicated and computationally intensive cryptographic algorithms.<br\/><br\/>The main design goal up to date, for wireless communications and networking at the lower protocol layers, has been to provide high data rate, reliable communication to as many users as possible, by efficiently dealing with the challenges of the radio channel and sharing limited wireless resources. Capacity maximization oriented research has been agnostic to the security requirements of information transmitted. At the same time, security of the information transmitted has been dealt with at the upper layers of the protocol hierarchy, and has been agnostic to the capacity of the underlying network. This project brings together the two most important issues in wireless network design, i.e., information capacity and information security, exposing the tight coupling between the two, and aims to identify design principles for high-capacity and provably-secure wireless networks.<br\/><br\/>This project takes an information theoretic approach to provide guarantees on information security and information reliability for wireless networks. The research includes the development of a comprehensive wireless network design framework that aims at achieving high capacity and secure transmission for all users. Accounting for the existence of a variety of malicious entities and a variety of levels at which these entities are capable to harm the network, the investigators identify the following fundamental research directions: (i) establishing the secrecy capacity of fundamental building blocks of wireless networks, i.e., the maximum rate of reliable information transmission in the presence of intelligent eavesdroppers; finding ways in which the legitimate system entities, i.e., transmitters and receivers, can cope with the security threats at the physical layer; (ii) identifying the fundamental tradeoffs between user cooperation between friendly nodes and the security and the confidentiality of relayed information; (iii) revisiting the notion of wirelessly transmitting channel state information (CSI) in the presence of security threats; identifying conditions under which this well-accepted notion to improve capacity may create security vulnerabilities, and developing methods to deal with this; (iv) introducing the notion of securing the network by utilizing the degrees of freedom in the communication channel available as a result of employing multiple antennas (MIMO links); (v) identifying the impact of the physical layer on the medium access and networking layers and developing secure cross-layer solutions.<br\/><br\/>The results of this project will help identify fundamental design trade-offs for capacity versus security for a variety of wireless networks, and will provide design principles for future wireless communication systems achieving the secure capacity limits. The project is a collaborative effort between the PI at Penn State and the PI at University of Maryland.","title":"Collaborative Research: CT-ISG: Secure Capacity of Wireless Networks","awardID":"0716311","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["548269"],"PO":["497499"]},"129152":{"abstract":"This research focuses on the design, implementation, and evaluation of an advanced execution system, called REEact (Robust Execution Environment), which dynamically adapts an application's execution to the runtime resources landscape originating from the sources of heterogeneity in a next generation multi-core (CMP) chip.<br\/>The sources of heterogeneity of interest are those that arise from process variation that impacts the maximum performance of individual cores and memory blocks, from power optimizations such as DFVS that result in varying core performance over time and core shut down due to thermal emergencies, and from reliability effects resulting in cores that must be disabled due to permanent faults that occur in the field. REEact is a type of virtual execution environment (VEE) that mediates, controls, and adapts the application's execution. It employs a combination of techniques to adapt both the hardware resources and the application's software code to accommodate the heterogeneous nature of the CMP to provide the best performance and power solution where not all of the CMP cores and\/or memory blocks are available. <br\/>This research impacts CMP technology by enabling the use of these architectures for high performance computing. With effective strategies for managing heterogeneity, scientists, consumers and business people will more effectively use high-performance applications, leading to greater advances in areas such as pharmaceutical development, financial market forecasting, and environmental science model\u00acing. This research impacts both undergraduate and graduate students through their involvement in the research projects and through courses and course modules on CMPs.","title":"Collaborative Research: CSR-AES: REEact: A Robust Execution Environment for Fragile Multicore Systems","awardID":"0720645","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["507752","542016"],"PO":["493916"]},"129394":{"abstract":"Mobile ad-hoc communication is starting to find real-world applications beyond its military origins, in areas such as vehicular communications and delay tolerant networking. As the RF spectrum is getting saturated by recent advances in wireless communications, enabling optical spectrum in wireless communications is the needed revolution for ultra-high-speed mobile ad-hoc networks (MANETs) of the future. This project explores the potential for free-space-optics (FSO) in the context of very-high-speed mobile ad-hoc and opportunistic networking. <br\/><br\/>Intellectual Merit: This project introduces basic building blocks for MANETs using FSO and prototypes multi-hop high-capacity FSO building blocks and protocols operating under high mobility. 3-d spherical structures covered with inexpensive FSO transceivers (e.g., VCSEL and photo-detector pair) solve issues relevant to mobility and line-of-sight (LOS) management via availability of several transceivers per node. Such structures facilitate electronic LOS tracking (i.e., ?electronic steering?) methods instead of traditional mechanical steering techniques. The project also investigates reliability protocols as management of logical datastreams through multi-interface FSO structures pose a major challenge. By abstracting FSO directionality and LOS characteristics, the project explores issues relating to routing and localization, and develops layer 3 protocols and FSO-MANET demonstration in a lab setting.<br\/><br\/>Broader Impact: Results of this research can revolutionize the MANET technologies by enabling optical spectrum. FSO has been used at high-altitude communications, and this project enables FSO communications at lower-altitudes and in ad-hoc settings. This research will provide a new application for solid-state lighting technology due to potential integration of illumination and communication functions. Other impact areas include: sensor networks, peer-to-peer networks leveraging directional overlay protocols, and military wireless applications such as UAV\/aircraft airborne networks and inter-ship communications.","title":"Collaborative Research: NeTS-NBD: Free-Space-Optical Mobile Ad-Hoc Networks (FSO-MANETs)","awardID":"0721542","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["551119"],"PO":["564993"]},"133090":{"abstract":"Proposal 0739563<br\/>\"\"Representation and Learning of Musical expression in Melody\"\"<br\/>PI: Christopher S. Raphael<br\/>Indiana University<br\/><br\/><br\/>ABSTRACT<br\/><br\/>Music exists on several levels. One view is in terms of the directly observable attributes of a musical score, such as notes and rhythms written in traditional symbolic music notation by a composer. Another view is in terms of the audio stream corresponding to an expressive rendering of the score. Between these two extremes--the atomic sub-components and an expressive performance--there are many levels. Only some of these have well-developed representations and analyses. The goal of this project is to develop a representation of an intermediate layer that can explain the association between the lowest note level and the top expressive level and to develop a system for expressive rendering of continuously controlled music that will begin with melody represented as a note list with an analysis of the harmonic structure and produce an expressive audio corresponding to a performance of it. To achieve this goal, the project aims to develop a representation for capturing the expressive elements of the notes--their prosodic function--for instance, their implicit musical direction and stress. The project will also study the relationship between this mid-level representation and continuous audio in an actual rendition of the music. For this aspect, the project will employ a \"\"Theramin\"\" model for audio that continuously modulates the pitch and amplitude of a sinusoidal tone. Such a model is capable of representing a variety of expressive musical elements including dynamics and vibrato.<br\/><br\/>This project will pursue the following specific tasks: (1) development of a small corpus of expression-annotated music; (2) development of a system for automatically computing the prosodic annotation from the symbolic melody and harmony representations; and (3) development of a system for automatically generating the Theramin representations from prosodically annotated melody and harmony. The use of machine learning methods will be employed in this project to predict Theramin representations that resemble those of a training corpus; these will also be used in evaluation.","title":"Representation and Learning of Musical Expression in Melody","awardID":"0739563","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["535948"],"PO":["387198"]},"127470":{"abstract":"This project investigates a novel approach for assessing the fluency and<br\/>grammaticality of alternative translation hypotheses that are created within<br\/>search-based Machine Translation (MT) systems. This task, commonly termed<br\/>\"Language Modeling\" (LM), has been explored primarily in the context of speech<br\/>recognition; however, current state-of-the-art language models (LMs) are not<br\/>effective at distinguishing between more fluent grammatical translations and<br\/>their poor alternatives. In contrast, the proposed approach, \"Discriminative<br\/>Knowledge-Rich Language Modeling\" (DKRLM), is explicitly designed to find the<br\/>most fluent and grammatical translations within the search space by comparing<br\/>the linguistic features of the translation hypotheses against very large<br\/>\"clean\" monolingual corpora. The intuition is that more grammatical<br\/>translation hypotheses should contain higher proportions of features seen in<br\/>the large corpora. An important contribution of the project is in exploring<br\/>different types of linguistic features to identify those that are most<br\/>informative for the comparisons. Moreover, discriminative training is<br\/>performed to incorporate the features into a system-independent scoring<br\/>function, replacing traditional LMs in MT systems. The broader impacts of the<br\/>proposed work include both broader adoption for the methodology as well as<br\/>wider use of the new DKRLM functions to other search-based NLP applications<br\/>that aim at generating fluent grammatical text. This includes search-based<br\/>approaches to Speech Recognition, Natural Language Generation (NLG), Optical<br\/>Character Recognition (OCR), Summarization, and others.","title":"RI: Collaborative Research: Discriminative Knowledge-Rich Language Modeling for Machine Translation","awardID":"0713402","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8010","name":"Computing in the Cloud"}}],"PIcoPI":["502549"],"PO":["565215"]},"126381":{"abstract":"The Lemur Toolkit (http:\/\/www.lemurproject.org) has become a standard resource for researchers in the field of information retrieval. The combination of very efficient indexing tools, support for a variety of retrieval models, and a powerful query language has enabled a wide variety of research projects. In this collaborative project, W. Bruce Croft, University of Massachusetts - Amherst and Jamie Callan, Carnegie Mellon University are extending the toolkit with new features, search techniques, efficiency improvements, and evaluation measures to broaden the range of research it can support and to keep up-to-date with the latest research. One feature in particular is a toolbar for the acquisition and analysis of user data, such as clickthrough, that is the basis for improving many Web search techniques. This new feature helps the academic community study these techniques and will include explicit controls for safeguarding the privacy of the data and anonymizing subsets for research. The toolkit is already in use in educational and research environments world-wide and the extensions are likely to support new research leading to more effective search engines. This in turn will have a significant impact on Web users by improving the quality of retrieved results.","title":"CRI: CRD - Supporting User Data, Privacy, and Evaluation in the Lemur Toolkit","awardID":"0707801","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["507668","541869"],"PO":["543481"]},"127481":{"abstract":"The Digital Age has brought about unprecedented growth in the amount<br\/>of data being generated, the number of data consumers, and the<br\/>diversity of their interests and locations. Traditionally, users poll<br\/>sources for information, but for many applications, polling is hardly<br\/>scalable and may miss important events. The alternative offered by<br\/>publish\/subscribe systems is to push notifications to users with<br\/>matching interests. This approach suits many applications, ranging<br\/>from personal, commercial, medical, to environmental, military, and<br\/>security. However, traditional publish\/subscribe systems are becoming<br\/>inadequate for advanced applications, where users want to receive<br\/>information that has been filtered, joined, and summarized, and only<br\/>when certain conditions are met.<br\/><br\/>This project aims at building a next-generation publish\/subscribe<br\/>system to face the new challenges. The PIs propose an end-to-end<br\/>solution consisting of techniques from subscription processing and<br\/>indexing to dissemination network design, which work together to<br\/>support efficient and powerful subscription functionalities, allowing<br\/>users to control precisely what they want and when they want it.<br\/><br\/>One main feature distinguishing the proposed approach from previous<br\/>work is joint consideration of subscription processing and<br\/>notification dissemination. Traditionally, these problems are<br\/>considered separately by database and networking communities.<br\/>However, there exists a wide spectrum of interesting alternatives for<br\/>interfacing processing with dissemination. The PIs propose a<br\/>promising approach that allows complex, stateful subscriptions to be<br\/>handled by simple, stateless dissemination mechanisms, with a clean<br\/>system design that is easy to implement and scale. A cost-based<br\/>optimizer, inspired by database query optimization, chooses the best<br\/>processing and dissemination strategies jointly and dynamically.<br\/><br\/>Besides system building, this project tackles many new algorithmic<br\/>challenges, including, e.g., scalably processing a large number of<br\/>complex subscriptions; exploiting event and subscription<br\/>characteristics to combat worst-case complexity; balancing semantic<br\/>similarity and network proximity in dissemination network design; and<br\/>efficiently maintaining statistics for high-dimensional events and<br\/>subscriptions.<br\/><br\/>Broader Impact:<br\/><br\/>Bringing together their expertise in databases and algorithms, the PIs<br\/>have a track record of collaborating with each other and with<br\/>researchers outside computer science. A planned application of the<br\/>system is to help ecologists with environmental monitoring.<br\/><br\/>The PIs are committed to integrating research and education, and in<br\/>particular undergraduate research, by following their tradition of<br\/>involving undergraduates through REU and department fellowships. The<br\/>PIs are collaborating on an effort supported by the Department of<br\/>Education, to increase workforce diversity for women, minorities, and<br\/>persons with disabilities. They also participate in an internship<br\/>program for underrepresented groups, which provides minority students<br\/>opportunities to perform paid summer research with Duke faculty<br\/>members.<br\/><br\/>Project URL: http:\/\/www.cs.duke.edu\/dbgroup\/prosem\/","title":"III-COR: Scalable Publish\/Subscribe: Unifying Data Processing and Dissemination","awardID":"0713498","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["554177","508314"],"PO":["543481"]},"129681":{"abstract":"Proposal #: CNS 07-22575<br\/>PI(s): Gerber, Naomi L.<br\/> DeJong, Kenneth A.; Duric, Zoran<br\/>Institution: George Mason University <br\/> Fairfax, VA 22030-4443<br\/>Title: MRI\/Dev.: New Instrumentation to Measure Upper Extremity Motion for Research and Teaching in Rehabilitation Science, Bioengineering and Robotics<br\/> <br\/>Project Proposed:<br\/>This project, developing new instrumentation for the study of upper extremity activity in humans and mobile robots, aims to assist people with impaired extremity function in maintaining independence and employment. The work integrates independent advances in quantitative data collection through haptic technologies, wireless myoelectric sensors, motion capture technologies, and computer vision to solve some of the challenges in designing robots that extend capabilities in friendly and hostile environments. Since a primary shortcoming of existing instrumentation for upper extremity activity is lack of quantitative data collection that does not interfere with natural movement, a newly developed wireless instrumentation quantifies upper extremity motion to assess requirements for human function and robotic activity. The instrumentation captures and integrates in real time kinematic, kinetic (force and torques data), kinesthetic (proprioceptive), myoelectric data, and computer vision and motion analysis data, specifically integrating force data collected from haptic devices, 6-degrees-of-freedom motion data collected from wireless electromagnetic sensors (\"flock of birds\"), myoelectric data from strategically placed surface electrodes, and motion analysis data collected from digitized visual data. Thus, the project enables<br\/>. Combining existing instrumentation to permit real time feedback to subjects or robots to correct movement patterns, extinguish muscle activity, and\/or reduce force;<br\/>. Quantifying stereotypic upper extremity activities ranging from a fluid, continuous pointing task to a high torque power grip activity;<br\/>. Breaking movement patterns and their associated forces into simpler components or primitives (an approach that has been very effective in providing useful graphic-user interface in current haptic research); and<br\/>. Assessing which combinations are most significant to completer various tasks.<br\/>The instrumentation also allows exploring tele-control of force feedback to explore feasibility of its use in robotic control and assistive technology for people with upper extremity impairments, particularly for robots in hostile environments and for people in remote areas.<br\/><br\/>Broader Impact: The instrumentation will also be used for supporting existing and new courses on motion analysis, human-machine computer science, haptics and rehabilitation science. Moreover, it contributes to interdisciplinary collaborations within the institution and with a small business. The infrastructure is likely to be commercialized, and the research results disseminated through usual venues.","title":"MRI: Development of New Instrumentation to Measure Upper Extremity Motion for Research and Teaching in Rehabilitation Science, Bioengineering and Robotics.","awardID":"0722575","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":[343773,343774,343775],"PO":["557609"]},"129450":{"abstract":"Wireless mesh networks are becoming an important mode of high-speed Internet access, especially in parts of the country and the world that are poorly served by wireline providers. In addition, an increasing number of sensor networks rely on mesh protocols. This proposal seeks to dramatically improve the total network capacity and individual data transfer throughput in these networks using the following mutually-reinforcing ideas:<br\/><br\/>1. Partial Packet Recovery (PPR) - a method used to determine which bits are likely to be correct in any given packet reception using physical layer hints, derived from modified wireless physical layers. PPR will lead to more robust reception and fewer retransmissions, and thus the opportunity to use both more aggressively concurrent channel access algorithms and higher bit-rates.<br\/><br\/>2. Channel access using conflict maps, a protocol to aggressively exploit concurrent transmissions whenever they are likely to succeed, using measured observations of past success and failure. This technique will lead to more accurate, less conservative transmission decisions than existing techniques, thereby increasing spatial reuse.<br\/><br\/>3. Bit-wise opportunistic routing (Bit-ExOR), which takes advantage of the fact that a transmission often results in different receivers correctly receiving different subsets of the bits in the transmission. Each node uses PPR and forwards the correct portions of a packet, while collaborating with other nodes to avoid duplicate forwarding.<br\/><br\/>This project could have a long-term impact on the right protocol architecture for wireless networks - one in which error recovery and forwarding occur at the \"bit-level'' (at bit-range granularities), rather than at the packet-level, and where channel access uses observations of the fate of the individual bits in previous transmissions to maximize concurrency. The resulting abstraction is a \"bit-switched network\", a modest but potentially powerful twist on packet switching.","title":"NeTS-WN: Bit-Switched Wireless Networks","awardID":"0721702","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["508283","541752"],"PO":["565303"]},"128141":{"abstract":"Proposal: 0716203<br\/>Shih-Fu Chang<br\/>Columbia University<br\/>CT-ISG: Trustworthy Media: Blind Passive Media Forensics for Content Integrity Verification<br\/><br\/>Abstract:<br\/><br\/>Digital audio-visual content can nowadays be modified and simulated with unprecedented realism. In response to the challenge of malicious media manipulation, we propose to develop new theories, methods, and a comprehensive suite of tools that can be used to verify content integrity in both audio and visual modalities at multiple levels under diverse contexts. The results will have significant impacts in scientific areas as well as many practical applications of national interest, such as trustworthy news reporting, surveillance security, intelligence gathering, criminal investigation, financial transactions, and medical information management. Our efforts will be based on an important paradigm, called blind passive media forensics, which fundamentally differs from conventional approaches using cryptographic signatures and watermarking. The proposed methods extract latent, unique signatures from the signals and sensing devices to detect tampering anomalies, so that verification requires only the media content at hand without any additional information or preparation. Specifically, we propose a systematic framework for device signature consistency checking and a joint multi-modal approach for verifying media integrity. We will also analyze various attack scenarios, construct rigorous benchmark datasets and performance metrics, and take proactive steps in disseminating results and promoting awareness of this critical area through public testing of online systems.","title":"CT-ISG: Trustworthy Media: Blind Passive Media Forensics for Content Integrity Verification","awardID":"0716203","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["563299","554699"],"PO":["497499"]},"129472":{"abstract":"The design of wireless ad-hoc networks faces a number of unique challenges in wireless communications including 1) co-channel interference among active links in a neighborhood, and 2) time-varying channel conditions over fading channels. Experimental data reveals that, in many realistic scenarios, fading effects can often adversely affect the MAC layer, and the coupling between the timescales of fading and MAC calls for a unified PHY\/MAC design. Due to the distributed nature of ad hoc communications, little work has been done to develop channel-aware, distributed scheduling for throughput maximization. There are virtually no systematic studies on channel-aware scheduling for real-time traffic under latency constraints. <br\/><br\/>A principal goal of this project is to fill this void and build a theoretic foundation for channel-aware, distributed scheduling in wireless ad-hoc networks, for both elastic traffic and inelastic traffic. With the goal of developing a framework for unified PHY\/MAC optimization, the proposed research consists of three thrusts. The first two thrusts investigate distributed opportunistic scheduling for elastic traffic and focus on throughput maximization from network-centric and user-centric perspectives, respectively. The third thrust focuses on channel-aware scheduling for network models under explicit delay constraints, for real-time traffic. The proposed research draws on a combination of fundamental tools in scheduling, stochastic optimization, game theory, and control theory. This project will open a new avenue for exploring channel-aware distributed scheduling for ad-hoc communications.<br\/><br\/>The PIs expect that the proposed work will culminate in the formulation of both new fundamental theories and advanced design methodologies for wireless ad hoc networks, and will have a significant impact on many wireless applications including wireless LANs and wireless mesh networks. In addition to the technical impacts, the broader impacts of the proposed research also include educational elements.","title":"NeTS-WN: Collaborative Research: Channel-Aware Distributed Scheduling for Optimal Throughput and Latency: A Unified PHY\/MAC Approach","awardID":"0721820","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["518327"],"PO":["557315"]},"128262":{"abstract":"This project applies recent techniques in transactional computing to the problem of preventing unwanted declassification of secure information. Regulating the nature and amount of information that is declassified for complex software system is difficult; even when leaks are identified, suitably repairing the computation is usually not possible. The project develops ideas inspired from language-centric transactional computing to support information flow security by encapsulating critical regions that (a) either cannot be analyzed effectively statically or (b) declassify some set of confidential data. Isolation and atomicity properties of transactional regions ensure the approach is safe even in a multi-threaded environment.<br\/>The technical issues associated with controlled declassification are examined from an entirely new perspective--rather than attempting to prevent statically any leaks from occurring, this research explores approaches that dynamically monitor when leaks occur, transparently reverting program state to an earlier safe context when leaks are identified. This security model encapsulates untrusted operations and library functions within monitored regions, allowing only information explicitly marked as declassified to escape the region scope. As regions run in isolation, they ensure that they can not be influenced by non-monitored code, nor can they influence its outcome. The monitoring infrastructure leverages transactional mechanisms to track memory use, and restore program state when declassification violations are detected.<br\/>The broader impacts are significant. Information flow and declassification are critical problems to cyber-infrastructure, homeland security, and commercial interests. Techniques that provide scalable, transparent, and effective solutions to this problem are of immediate benefit to current government and business initiatives.","title":"CT-ER: Controlled Declassification with Software Transactional Memory","awardID":"0716659","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["549800","558390",339984],"PO":["529429"]},"129362":{"abstract":"Recent advances in multiple-input-multiple-output (MIMO) technology show that much higher spectrum efficiency and capacity gain can be achieved by the use of multiple antennas at a node. The benefits of substantial improvement in capacity at no cost to additional spectrums have positioned MIMO as a breakthrough technology in wireless communications. Although MIMO is an active research area in the wireless communications community, there is very limited knowledge on how to apply MIMO technologies to improve network capacity in a multi-hop wireless network environment, perhaps because unlike existing wireless mesh networks, which are conceptually simple and relatively easy to characterize, the mathematical characterization of a MIMO-based mesh network involves space domain and requires complex matrix operations. Specifically, the unique MIMO channel matrix and potential spatial multiplexing introduce new research problems at multiple layers. <br\/> <br\/>This project aims to systematically address fundamental theories and algorithms for future MIMO-enabled mesh networks. Specifically, there are three main thrusts in this project: (1) developing tractable cross-layer matrix representation and theoretical models from a networking perspective; (2) conducting analysis of theoretical bounds and capacity limits for MIMO networks; and (3) developing distributed algorithms for MIMO networks. <br\/> <br\/>An important objective of this project is to develop cross-disciplinary educational materials and courses. The plan is to bridge the gap between computer networking and wireless communications curriculums via new cross-disciplinary courses. In addition, this project also includes research experience for undergraduates and special opportunities for under-represented students.","title":"NeTS-WN: Capacity Problems for MIMO-Enabled Wireless Mesh Networks","awardID":"0721421","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["564848"],"PO":["557315"]},"128152":{"abstract":"This research involves a detailed study of the connections between Cryptography and Computational Learning Theory. Cryptography is about manipulating information in order to achieve confidentiality, integrity, privacy, etc., while learning theory is about efficiently extracting information from some unknown object. Learning theory provides a rigorous basis for the practically important field of machine learning, and cryptography plays a similar role for the crucial area of computer security. In this research the investigators work to obtain new cryptographic results based on the presumed hardness of various problems in computational learning theory, and work to obtain new learning results via cryptography, thus extending and deepening the current understanding of both areas and the connections between them. The research is integrated with a plan to achieve broader impact through education by developing an advanced course on the connections between cryptography and learning theory at Columbia University and advising and guiding a diverse group of graduate students in their development as researchers and educators.<br\/><br\/>In more detail, the research involves (i) constructing and applying new cryptographic primitives, such as public-key cryptosystems and pseudorandom generators with very low circuit complexity, from learning problems that are widely believed to be hard; (ii) continuing ongoing work on exploring the average-case learnability of various well-studied concept classes such as decision trees and DNF formulas; (iii) applying computational hardness of learning to establishing computational hardness of learning for various Boolean function classes, using tools from cryptography; (v) working to obtain computational separations between pairs of well-studied learning models by showing that learning problems that have polynomial-time algorithms in one model are intractable (under a cryptographic assumption) in the other model; and (vi) exploring the foundational issue of what are the minimal assumptions required to prove computational hardness of learning.","title":"CT-ISG: Cross-Leveraging Cryptography with Learning Theory","awardID":"0716245","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7927","name":"COMPLEXITY & CRYPTOGRAPHY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550576","485875"],"PO":["565264"]},"129483":{"abstract":"The eFIT (Enabling Future Internet innovations through Transit wire) project aims to enable future innovations by ensuring strong universal connectivity at the architectural level. Innovations are enabled by the abundant and affordable computing resources provided by Moore's Law, and universal connectivity provided by the Internet. Computing resources are likely to become more plentiful and affordable, but the universal connectivity provided by the Internet is facing major challenges, as demonstrated by the prevalent use of network address translation (NAT) and accelerated growth of the global routing table. The current Internet architecture provides end-to-end connectivity by putting both user networks and Internet service providers (ISPs) in the same address and routing spaces. User networks and ISPs have different purposes, distinct characteristics, and are moving in almost opposite technological directions. However the inter-dependency between network users and ISPs imposed by the existing architecture creates a major roadblock to future Internet innovations.<br\/><br\/>When a system grows larger in size by orders of magnitude, a change in form becomes necessary. The eFIT design enables innovation by first focusing on universal connectivity. eFIT places user networks and provider networks in different address and routing spaces, removing the inter-dependency between the two worlds. With eFIT, users can simply treat the Internet transit core as a transit wire with strong universal connectivity, while providers are insulated from the various problems caused by explosive growth in user networks. Therefore both users and providers will be able to innovate freely on their own without any architectural constraints.<br\/><br\/>Broader Impact: This new architecture design will have a broad impact on the research community, service providers, and Internet users. eFIT enables graduate students to explore new directions for fundamental problems such as security. Even more broadly, it will liberate Internet users from the current architectural constraints and encourage a new wave of application innovations.","title":"NeTS-FIND: Collaborative Research: Enabling Future Internet innovations through Transit wire (eFIT)","awardID":"0721863","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["475179"],"PO":["565090"]},"129131":{"abstract":"Abstract<br\/><br\/>Peer-to-peer (P2P) systems have recently evolved into complex, self-organizing entities that provide a scalable, efficient, and decentralized platform for many Internet applications. To support and continue expanding this important field, this project develops fundamental analytical and experimental understanding of P2P networks under user churn, which is a term describing dynamic behavior of P2P systems in which arrivals and departures are not synchronized. This work builds upon a synergy of three components - analytical modeling of churn, resilience, and routing performance of heterogeneous P2P networks; experimental sampling of churn and verification of obtained results in real networks; and integration of P2P research into graduate and undergraduate student education at Texas A&M University. The expected impact of the project is the delivery of a deeper understanding of emerging P2P networks and unveiling of novel theoretical, experimental, and educational aspects of these systems to a broad range of audiences.","title":"CSR -- SMA: Bridging Analytical and Empirical Understanding of Churn in Decentralized P2P Systems","awardID":"0720571","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550669"],"PO":["493916"]},"129373":{"abstract":"Wireless mesh networks are becoming popular for ubiquitous and low-cost wireless broadband connectivity. However, they, suffer from serious interference problems which limit their capacity. We use TDMA scheduling to address these performance problems. We use a SINR-based physical interference modeling for realism, and various forms of diversities - such as transmit power control, directional antennas, multiple channels, and rates - to maximize performance. We also introduce a measurement-based modeling technique to make the physical interference modeling practical. We support these innovations by experimental studies. Our goal is developing a complete set of algorithms, protocols, and system solutions that target \"managed\" mesh networks. The protocol solutions include the routing layer and below, and are compatible with existing Inter-networking protocols for the transport layer and up.<br\/><br\/>The project's intellectual merit has the following components: (i) New protocols for TDMA scheduling with diversity and physical interference modeling, (ii) integration of scheduling with routing, (iii) measurement-based modeling of physical interference, and (iv) simulation modeling and testbed experiments to support the protocol innovations.<br\/><br\/>The project contributes to the education and training of graduate students in the two universities -Georgia Tech and Stony Brook University. The project gains leverage from existing international collaborations of PIs with IIT-CNR in Italy and CDAC in India, and strengthens this collaboration. Finally, success in this project means low cost, ubiquitous broadband connectivity. It competes well with WLANs and wired connectivity, and is expected to level the technological playing field.","title":"NeTS-WN: Collaborative Research: A Measurement-Driven Physical-Interference-Based Approach for the Design of Mesh Networks","awardID":"0721455","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["563568"],"PO":["565090"]},"129032":{"abstract":"The EncoreJ project is developing tools and libraries for transparent rewriting of Java code, making distributable Java applications resilient in the face of execution node reconfiguration and failure. Developers control the system, but EncoreJ automatically rewrites compiled Java code, as packages are loaded, adding support for creating, accessing, and computing upon local and remote objects, and for resilience in the face of system failures and reconfigurations. EncoreJ further interfaces with a variety of persistence mechanisms (e.g., databases), both for providing fundamental resilience (saving\/restoring information) and for coordinating recovery with the mechanisms of the external database.<br\/><br\/>EncoreJ exploits resiliency support to make it easy to reconfigure applications as the host platform evolves, adding and removing resources dynamically; e.g., a virtual node might go down and be replaced by another, in order to force work to move to a newly available system. Programmers describe \"\"on the side\"\" (without modifying source code), how to place, move, and replicate objects and computations; the source code remains the primary mechanism for expressing algorithms clearly without hard-coded details of distribution or resilience.<br\/><br\/>The EncoreJ tools and prototype are a platform for research by the wider community working on policies\/algorithms for migration, replication, scheduling, etc., in Grid systems. The focus is a convenient and flexible platform, powerful and extensible, without over-commitment to any particular policies or strategies. EncoreJ builds on readily available and standard systems (Java virtual machines and packages) to ensure wide applicability and easy distribution and adoption.<br\/><br\/>This award is seed funding for project development.","title":"CSR-AES Collaborative: Encore\/J: Transparently Recoverable Java for Resilient Distributed Computing","awardID":"0720242","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550864"],"PO":["493916"]},"128196":{"abstract":"The secure transmission of information from a source to a destination is typically handled via encryption algorithms. In many instances, data that may or may not undergo encryption prior to transmission can be manipulated to encode messages. With successful encodings, seemingly innocuous channels, e.g., documents, data streams, audio, video, can operate covertly for secret message transmission in various applications, e.g., collusion in finance, electronic information\/auction markets, transaction sequences, advertising applets, simulation. Such transmissions violate the principles of data integrity, security, and privacy, and can be a threat to the functioning of organizations that utilize the applications. The goal of this project is to study, design and implement algorithms for the generation and detection of hidden messages in dynamic contexts. To this end the research focuses on a unified framework that analytically and experimentally examines various forms of message encodings in synthesized data, exploiting inherent structure and nondeterminism in data to confound detectability. The first part of the work focuses on generation methodology, based on statistically synthesized data. Message encodings that are theoretically hard to detect become candidates for the second part of the work which is detection, based on pattern recognition techniques, statistics and heuristics. Core components of the work are both theoretical and experimental, with a focus on the limits of detectability. The topics of study include novel synthesizing methods and applications, probabilistic encoding algorithms, blind detection algorithms and benchmark generation.<br\/><br\/>The project is strongly motivated by fundamental research questions, with broad impacts on application areas such as those mentioned above, all of which are of importance to computer, commerce, and homeland security. An integral part of the work is the development of a benchmark generator which can be used as a testbed for new detection algorithms. By demonstrating how covert channels can operate in diverse applications and disciplines the project will foment cross-disciplinary research in security. It will involve Ph.D research students, support the development of new material in the secure computing curriculum, in graduate\/undergraduate courses and research seminars. Results of the work, in the form of publications, reports, algorithms, software and experimental data, will be made available at: http:\/\/www.cs.purdue.edu\/research\/PaCS\/spots.html.","title":"CT-ISG: Dynamic Covert Channels: Generation and Detection of Hidden Messages","awardID":"0716398","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":[339805],"PO":["543481"]},"129098":{"abstract":"This research focuses on the design, implementation, and evaluation of an advanced execution system, called REEact (Robust Execution Environment), which dynamically adapts an application's execution to the runtime resources landscape originating from the sources of heterogeneity in a next generation multi-core (CMP) chip.<br\/>The sources of heterogeneity of interest are those that arise from process variation that impacts the maximum performance of individual cores and memory blocks, from power optimizations such as DFVS that result in varying core performance over time and core shut down due to thermal emergencies, and from reliability effects resulting in cores that must be disabled due to permanent faults that occur in the field. REEact is a type of virtual execution environment (VEE) that mediates, controls, and adapts the application's execution. It employs a combination of techniques to adapt both the hardware resources and the application's software code to accommodate the heterogeneous nature of the CMP to provide the best performance and power solution where not all of the CMP cores and\/or memory blocks are available. <br\/>This research impacts CMP technology by enabling the use of these architectures for high performance computing. With effective strategies for managing heterogeneity, scientists, consumers and business people will more effectively use high-performance applications, leading to greater advances in areas such as pharmaceutical development, financial market forecasting, and environmental science model\u00acing. This research impacts both undergraduate and graduate students through their involvement in the research projects and through courses and course modules on CMPs.","title":"Collaborative Research: CSR-AES: REEact: A Robust Execution Environment for Fragile Multicore Systems","awardID":"0720483","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["560516"],"PO":["493916"]},"127350":{"abstract":"IIS - 0712793<br\/>Karger, David R<br\/>Massachusetts Institute of Technolog<br\/>III-COR:Data Homesteads: Tools to let Scientific Users Harvest, Husband, and Share Structured Information<br\/><br\/>Focusing on the domain of biology, this project will develop a suite of tools that will enable scientists to integrate data from multiple web sources, to help visualize and manipulate this integrated data, and to republish this newly integrated data to the larger scientific community on the web. This project aims to make web-based, complex data integration into an activity that can be performed by individual scientists on an ad hoc basis, collecting, manipulating, and publishing precisely the information that they want to work with. We address three aspects of the data integration problem. The project has four tasks: (1) develop tools that let non-programmers collect the information they wish to integrate, extracting it from numerous non-cooperating web sites, or from data repositories with disparate schemata, and structuring it into an integrated data model, (2) develop ontologies and tools that let users build their own task-specific information management applications, (3) develop ontologies and tools that let users build their own task-specific information management applications. The work will be evaluated by assembling a broad reference corpus of web data sources, primarily in biology, and measuring the ability of the components to collect, integrate, and redisseminate data from these sources. In addition, formative and summative user studies of the tools will be performed in the lab, tools will be deployed for biologists'use in their own work.","title":"III-COR: Data Homesteading: Tools to let Scientific Users Harvest, Husband, and Share Structured Information","awardID":"0712793","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["486265","549925"],"PO":["565227"]},"127471":{"abstract":"The goal of this research project is to develop efficient and practical methods for the management, measurement, and visualization of privacy in computer systems and networks. The approach consists of: designing a framework for protecting sensitive information in online transactions; formulating quantitative measures of the effort required to infer individual private information from statistical aggregate data; and visualizing the private information disclosed in online activities as well as threats to privacy. The linked educational effort addresses the teaching of privacy concepts in introductory computer science courses. The results of the project enable the deployment of Internet applications with strong privacy assurance for users and service providers. These results are disseminated on the project Web site<br\/>(http:\/\/www.ics.uci.edu\/~goodrich\/projects\/privacy\/).","title":"IPS: Collaborative Research: Privacy Management, Measurement, and Visualization in Distributed Environments","awardID":"0713403","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7486","name":"INFORMATION PRIVACY & SECURITY"}}],"PIcoPI":["521367"],"PO":["469867"]},"127493":{"abstract":"This is a project to develop a new approach to interruptibility and related issues in instant messaging (IM) and mobile communications. Computer mediated communication is hampered by impoverished social cues related to when it is appropriate for an information system to interrupt a person or carry out some other action that might be appropriate at some times and not others. This problem is more pronounced when computing becomes more pervasive and as people are increasingly always online and always reachable. In the case of IM, the old method of alerting users to one's status no longer functions well. Although computers have access to many embedded sensors, automated assistance for alleviating inappropriate IM interruptions remains elusive. In a world in which users are \"\"available\"\" for some purposes, but not for others, one indication of interruptibility no longer fits the needs of users. <br\/><br\/>This research will explore how sensor data coupled with machine learning techniques and mass-collaboration could be leveraged to support users' social decisions. By learning users' preferred description of their place - in light of their position, activity, time, etc. - an intelligent user interface could present communication partners with information about a user's current status, ideally their \"\"context.\"\" This shifts the burden of determining interruptibility from the realm of the computer to the social realm of the users, where it belongs. This approach treats context as an evolving communication of environmental data. Central to this approach is a way in which users are motivated to submit training data that translates sensor data to semantic labels. <br\/><br\/>The work will be carried out in three phases. Phase I: Development, deployment and testing of a context-aware IM client, Nomatic*Gaim. This client will be used as a data collection mechanism for mappings of sensor data to semantic labels that will train machine learning algorithms. Under the auspices of a controlled user study, this software will be deployed, and researchers will observe the language that humans use to disclose context. Phase II: Organic ontologies will be constructed from correlations in the data set using statistical tests. These ontologies will form a language structure on which the vocabulary of Phase I can be placed. The models from Phase I coupled with the structure learned in Phase II will be incorporated into a user interface that assists users with setting their context status and that gracefully degrades as confidence in predictions gets lower. Evaluations of this phase will be conducted using user-interface evaluation techniques that will quantitatively and qualitatively judge the effectiveness of automatic labeling. Phase III: The newly developed IM techniques will be incorporated into a mobile phone version of Nomatic*Gaim that will then be evaluated in a parallel study to Phase I. This will enable researchers to understand differences between laptop and cell-phone mobility. <br\/><br\/>This research will push the boundaries of effective social communication in an \"\"always online\"\" culture. Effective semantic context labeling promises to have a broader impact on computing by becoming a resource which prompts software to act in new ways. For example, when a user is in a library the volume of their device can be lowered; when a user is on a boat, tide tables and maritime weather reports can be automatically obtained and displayed more prominently. The software and research artifacts will be incorporated into existing undergraduate research plans and will help to seed the development of computer science curriculum organized around the idea of computing with location.","title":"HCC: Computing Place Context","awardID":"0713562","effectiveDate":"2007-09-01","expirationDate":"2012-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[338100],"PO":["564456"]},"129440":{"abstract":"Most existing wireless sensor systems and protocols are based on two-dimensional design, where all sensors are distributed in a two dimensional plane. This assumption is somewhat justified for applications where sensors are deployed on earth surface and where the height of the network is smaller than transmission radius of a sensor. However, 2D assumption may no longer be valid if a sensor network is deployed in space, atmosphere, or ocean, where nodes of a network are distributed over a 3D space and the differences in the third dimension is too large to ignore. This project focuses on designing novel geometric approaches to solve various topology control and position-based routing problems in 3D sensor networks. Although many geometric topology control protocols and position-based protocols have been studied in 2D sensor networks, the design of 3D networks is surprisingly more difficult than the design in 2D. Many properties of the network require additional computational complexity, and a number of problems cannot be solved by extensions or generalizations of 2D methods. Facing up with these challenges, this project seeks to study new geometric approaches for 3D sensor networks. The expected results include: (1) various localized algorithms to efficiently construct 3D geometric topologies in order to maintain network connectivity, conserve energy and enable energy efficient routing; (2) new 3D position-based routing methods which can guarantee the delivery of packets or the power efficiency of their routes; (3) integrated 3D geometric approaches to address the joint design of topology and routing where these two issues are strongly coupled and fundamentally influenced by geometry.","title":"NeTS-NOSS: Topology and Routing Design for Three-Dimensional Sensor Networks: Geometric Approaches","awardID":"0721666","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["251870"],"PO":["557315"]},"129451":{"abstract":"This project is building cooperating networks of cameras that can be used to reconstruct three-dimensional (3D) features, produce images from novel viewpoints, match trajectories or objects against known patterns, or combine these tasks to provide a powerful, flexible monitoring system.<br\/><br\/>High data rates and precise calibration requirements present challenges that are not faced by earlier, simpler sensor networks.<br\/>The bandwidth required to transmit video data from hundreds or thousands of cameras to a central location for processing would be enormous.<br\/><br\/>Instead, this project is building low-power smart cameras that process video data in real time, extracting features and 3D geometry from the raw images of cooperating cameras. These compressed results, still somewhat bandwidth intensive, are stored in the network until required by users. Content-based routing techniques enable queries against a space-time representation of the data. Query processing occurs in-network, greatly reducing bandwidth requirements.<br\/><br\/>Camera networks must calibrate precisely, discover and track objects, route view requests to viable cameras, and avoid unnecessary transmissions. Content-routing techniques that will allow cameras to find common features---critical for calibration, search, and tracking.<br\/>These techniques allow features to be stored and processed near their acquisition point, avoiding wasted communication. Integrated, application-specific compression techniques further reduce overhead.<br\/><br\/>This project also aims to simplify the engineering effort in building 3D sensornet applications. A space-time ``cube'' abstraction is used to represent the data of the entire sensornet, throughout time. A declarative language is used to specify feature patterns for search and tracking. High-level features can be described as compositions in space-time of simpler features. These descriptions are compiled to use the data-centric protocols to implement data selection, search, or tracking without data centralization.","title":"NeTS-NoSS: Sensing in Three Dimensions with Smart Cameras","awardID":"0721703","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["483626","408988",343006],"PO":["565090"]},"129220":{"abstract":"This project seeks to leverage advances in virtual machine computing to enhance the foundations of automated resource management for virtual server infrastructure. It focuses on architecture, mechanisms, and policies for autonomic hosting centers that sense-and-respond to adapt automatically to changes in traffic demands or resource conditions, while holding human administrative burdens constant. It addresses key elements of a computing service utility: configuring and instantiating operating system images and services, binding them to server resources, and controlling their interactions<br\/>at the system and application level.<br\/><br\/>The research includes development and evaluation of a Web-based laboratory and testbed software for research in autonomic data centers and adaptive services. The testbed responds to a need for new tools that is recognized in the autonomic computing research community, and it has potential to accelerate progress in autonomic computing research. The core capability of the testbed is a set of mechanisms to enable self-monitoring and adaptation by the hosted services and the autonomic data center itself. The testbed provides facilities for users to develop and install controllers for all aspects of resource management policy and adaptation, and experiment with selected workloads and faultloads interactively. It will provide researchers and students with prepackaged deployable applications and integrated load generation, with functions to modulate the request stream along various dimensions and experiment with controller policies and their interactions.<br\/><br\/>The project also involves research in self-managing services, controller policies, and analysis of instrumentation data. These elements of the project use the testbed as a tool for experimental evaluation.","title":"CSR---VCM: Foundations for a Programmable Self-Managing Hosting Center","awardID":"0720829","effectiveDate":"2007-09-01","expirationDate":"2011-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["553906","550820"],"PO":["493916"]},"128252":{"abstract":"Messaging systems are a critical application for the Internet, but systems like Internet email based on the SMTP protocol are beset by many problems such as abuse of access control for email in-bins (SPAM), authentication (phishing and other types of fraud), confidentiality (where end-to-end encryption is still a challenge), and reliability. Important application areas such as the medical and financial sectors have turned to other mechanisms. For example, the Centers for Disease Control and Prevention (CDC) standards for messaging envision an architecture in which communications are based on web services, an emerging XML-based foundation for distributed computing. Financial entities like banks and mutual funds have developed techniques where back-end server systems implement their own secure messaging while users are notified of messages by SMTP and use browsers to access messages. This architecture has emerged as a widespread ad hoc work-around to achieve a practical solution but without the deeper analyses (especially for security) for ensuring its rigorous foundations.<br\/><br\/>This project will develop new architectures and strategies for secure messaging systems based on attribute-based security and messaging. In this approach, attributes of principals are the primary foundation for access control, routing, and security transformations. Attribute-Based Access Control promises greater flexibility and integration than access control lists and roles. Attribute-Based Messaging makes messaging more dynamic and targeted. Attribute-Based Encryption allows only the principals with specified attributes to decrypt messages. The project will advance these three attribute-based techniques and assess their effectiveness in a web-services application.","title":"CT-ISG: Attribute-based Security and Messaging","awardID":"0716626","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["553855",339952,"521634"],"PO":["529429"]},"129583":{"abstract":"CCF-0722221<br\/><br\/>CPATH CB - Computing and Undergraduate Engineering: A Collaborative Process to Align Computing Education with Engineering Workforce Needs <br\/><br\/>PI: Thomas F. Wolff <br\/><br\/>American industries require employees with strong computation-based problem solving skills. Traditionally, industry needs have been couched in terms of proficiency with specific applications rather than around functional capabilities. Also traditionally, academic institutions have developed curricula that address disciplinary principles without regard to industry needs. These two \"traditions\" have hindered industries from meeting their needs, and academic institutions from meeting their societal responsibilities. This CPATH Community Building (CB) project addresses these problems. <br\/><br\/>Project investigators will develop, implement, and evaluate a process to create an academic\/industry community as a lynchpin of curricular change. The specific project goal is to demonstrate the process in the context of meeting industrial needs for computational problem solving. <br\/><br\/>Project participants are Michigan State University (lead institution), Lansing Community College, the Corporation for a Skilled Workforce, Western Michigan University, and representatives of ABET, Inc. The project team consists of academic representatives from MSU and LCC and representatives from technology-based companies in mid-Michigan via CSW and the Mid-Michigan Innovation Team (MMIT), lead group in the mid-Michigan US Department of Labor WIRED initiative. WMU will evaluate the development process. Generalization of the process for aligning curricular change and industry needs is expected.","title":"CPATH CB: Computing and Undergraduate Engineering: A Collaborative Process to Align Computing Education with Engineering Workforce Needs","awardID":"0722221","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["425147","425149","443055","562208","425151"],"PO":["562944"]},"129231":{"abstract":"As one of the oldest tools discovered by human, sticks come in different shapes and sizes to serve such purposes as self-defense, hunting, walking, or simply for fun. This smart stick project aims to add sensing and computing capabilities to sticks for a broad range of applications: walking assistance (fall alert), barrier detection (guides for the vision-impaired), location reporting and inquiry (terrain navigation). It also explores new interface techniques for cyber physical system (CPS) designs. Three different types of sticks (quad and simple walking sticks, guide sticks and walkers) will be used as the physical platforms for our study. Mini-gyro and pressure sensors will be used to generate raw data for pedestrian motion sensing. And digital filters will be developed to model and monitor pace states using low power FPGA or microcontrollers. This research will advance knowledge in how to design plug-and-play architectures for CPS building blocks. The broad impacts of this project consist of: creating new technological capabilities on a ubiquitous physical platform; assisting users who rely on sticks to improve their quality of life; providing a meaningful scenario for undergraduate students to explore their design abilities.","title":"CSR-CPS: Smart Sticks","awardID":"0720863","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["368857"],"PO":["561889"]},"129473":{"abstract":"This project will explore the role of barter-exchange incentives for cooperation in wireless networks. While cooperative wireless techniques show great promise, they also assume a degree of trust and a form of \"selfless\" behavior that may not be realistic. Cooperating terminals will accrue benefits, but they will also incur costs (wasted battery energy being an obvious example). Over time, benefits might logically be expected to exceed costs for most participants, but in the short term there will be winners and losers, and we cannot realistically assume that enlightened self-interest will prevail. <br\/><br\/>The sizable literature on incentive mechanisms for wireless networks has emphasized abstract mechanisms in which nodes receive some form of credit for helping other nodes. These prior efforts often mimic the operation of a complex economy. In doing so, they illustrate the difficulties inherent in this approach. The efficient operation of a complex economy requires such enablers as a stable currency, a system of credit and credit-worthiness, a shared understanding of what things are worth, and a good deal of record keeping. It may be that this complexity is not warranted here, and that a simpler approach, based on the mechanisms of barter and exchange, can provide the necessary incentives for the degree of cooperation we require.<br\/><br\/>In this project, we propose to explore the roles and limitations of barter-exchange incentive mechanisms for wireless networks. The specific research tasks include mechanisms for inducing cooperation between nodes by exchange of bandwidth, network connectivity, and content. <br\/><br\/>The barter-exchange mechanisms proposed here provide a means to compensate terminals for temporal inequities in benefits and costs. Further, they also provide a mechanism by which cognitive radios can organize themselves into networks and\/or operate efficiently in shared spectrums. The research proposed here is of great relevance to the anticipated deployment of cognitive radio networks including those planned for the wireless subnets of the GENI facility. The proposed educational supplement to the research activities here will also train graduate students in cooperative communications, an area of emerging interest in wireless data communications.","title":"NeTS-WN: A Joule for your Byte: Barter-Exchange Incentive Mechanisms for Wireless Networks","awardID":"0721826","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["463100","475434"],"PO":["564777"]},"129121":{"abstract":"Building power-efficient and high-performance embedded systems demands hardware\/software (HW\/SW) co-design and, therefore, co-verification. The growing complexity of embedded systems generates an acute need for scalable co-verification. The central objective of this project is to develop a unified approach to component-based HW\/SW co-verification of embedded systems, which effectively integrates model checking into component-based development of embedded systems and leverages component-based system architectures for scalable co-verification. The core of this approach is the synergistic integration of three innovative concepts: (1) a unified property specification language that supports uniform and coherent property specification for hardware and software, thus enabling compositional reasoning across the HW\/SW semantic boundary; (2) a unified component model that provides a uniform representation for hardware and software components, thus enabling component-based abstraction and refinement; and (3) a platform concept that captures domain-specific knowledge, in particular, architectural patterns, which provides support for automatic formulation and decomposition of system and component properties. This integration has potential for substantially advancing the state of the art in scalable co-verification of embedded systems based on effective leverage of component-based architectures and systematic reuse of verification effort. This project has broad impact through two separate venues: (1) technology transfer to industrial partners and (2) dissemination through course delivery to undergraduate and graduate students. In addition to traditional outreach efforts to recruit minorities and women through lectures and science fairs, opportunities for internships are provided to students participating in this project.","title":"CSR---EHS: Component-Based Hardware\/Software Co-Verification of Embedded Systems","awardID":"0720546","effectiveDate":"2007-09-15","expirationDate":"2012-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["559275"],"PO":["561889"]},"129242":{"abstract":"The researchers at Stanford University are developing a Java based transactional programming language and a Java Virtual Machine (JVM) environment that unifies memory level transactions and application level transactions such as those supported by the widely used application server environment J2EE. The Java based programming language includes a single set of constructs based on transactions that allow programmers to specify the parallelism, reliability expectations, and consistency requirements in a distributed application. The JVM based runtime system manages the execution of user-specified transactions across the resources available in the system. The unified transactional memory environment will allow programmers of commercial and scientific applications to achieve considerable programmability, performance, and reliability advantages compared to current programming environments.","title":"CSR---AES: Universal Transactions","awardID":"0720905","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["556787","556786"],"PO":["493916"]},"128153":{"abstract":"Storage of medical record information in electronic format and the sharing of this information among different health care organizations have the potential to produce enormous improvements in health care systems' quality and efficiency. At the same time, the proliferation and sharing of electronic medical records present serious risks, due to the extremely sensitive nature of the information. The goal of this project is to develop new techniques for the storage, maintenance, and control of sensitive data that permit open sharing among legitimate users while protecting the data against unauthorized use and disclosure.<br\/><br\/>The research in this project has two components: (1) a new approach to information protection referred to as cross-layer identity and access management (IAM), and (2) research on health system needs and usability issues. Cross-layer IAM research investigates an architecture and mechanisms in which access control and other security-related functions are tightly coordinated between different information access layers of the complex software stack that is present in health care environments; including secure storage, logical data access, and application layers, and finally the application presentation layer in the end devices employed by users to access the system. In the second project component, health systems are being studied to identify and define roles, access requirements, and common use-case scenarios within a representative health care organization. <br\/><br\/>The project will have a number of broader impacts. Healthcare organizations will be actively engaged, through the participation of Children's Healthcare of Atlanta, and through outreach to other organizations in this sector. New courses that cover security for healthcare IT systems will also be developed and offered to students in existing graduate programs in information security and health systems.","title":"CT-T: MedVault - Ensuring Security and Privacy for Electronic Medical Records","awardID":"0716252","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["562577","549757",339704,"521101"],"PO":["497499"]},"129374":{"abstract":"The observation and control of our physical world will expand dramatically using the temporally and spatially dense monitoring afforded by wireless sensor networks technology. Their success is nonetheless determined by whether the sensor networks can provide a high quality stream of data over a long period. Most previous efforts focus on devising techniques to save the sensor node energy and thus extend the lifetime of the whole sensor network. However, with more and more deployments of real sensor systems, in which the main function is to collect interesting data and to share with peers, data quality has been becoming a very important issue in the design of sensor systems. <br\/><br\/>In this project, the investigator undertake a novel approach that detects deceptive data through considering the consistency requirements of data, and study the relationship between the quality of data and the multi-hop communication and energy-efficient design of networked sensor systems. The project consists of four components, including (1) formal models for data consistency and data dynamics, (2) APIs to manage the data consistency, (3) protocols to detect deceptive data and improve the quality of collected data, and (4) several cross-layer protocols to support data consistency and filtering of deceptive data. These four components are integrated into a prototype called Orchis. In addition to technical papers that report the research results, this project will also produce a suite of software tools that will be made available to the community.","title":"NeTS-NOSS: Consistency Model Driven Deceptive Data Detection and Filtering in Wireless Sensor Networks","awardID":"0721456","effectiveDate":"2007-09-01","expirationDate":"2011-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["563661"],"PO":["557315"]},"129495":{"abstract":"There has been a remarkable increase in download of content provided by both traditional commercial suppliers as well those by amateurs. Users have very diverse computer equipment ranging from handheld devices to desktops, and downloaded items range from simple stock quotes to news stories to full movies. Such highly heterogeneous circumstances will be predominant in the networks of the near future. Current schemes for content download are inefficient at addressing the mentioned heterogeneity. The goal of this project is to obtain new and improved schemes that would result in better access to content for the users while improving the network utilization.<br\/><br\/>The research will focus on three coding techniques to attack the problem: rateless coding at the application layer, network coding at the network layer, and collaborative coding at the physical layer. Quantitative and qualitative limitations of network and rateless coding in heterogeneous environments will be studied to develop new practical coding schemes appropriate in such circumstances. Another research direction is to investigate and analyze mechanism to make networks more uniform using physical layer collaborative transmission schemes. An assessment will be made on how this process affects the performance of the higher layer coding schemes. <br\/><br\/>Broader Impact: The research, if successful, will improve the efficiency and availability of data in networks. This has the potential to benefit directly and indirectly the population at large. In addition, this collaborative research has the potential to obtain fundamental new insights at the interface of coding and information theory and combinatorial optimization. Several PhD students will be supported and trained in interdisciplinary areas and they would also obtain valuable industrial experience.","title":"NeTS-NBD Collaborative Research: Coding and Transmission Schemes for Content Download","awardID":"0721899","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["550375"],"PO":["565090"]},"129154":{"abstract":"The thesis of this research is simple: Byzantine fault tolerance (BFT) techniques and technology trends are nearing an inflection point where significant production deployment of BFT systems can be made viable.<br\/>This research aims to (1) develop new BFT technologies sufficient to make BFT deployable in a range of production systems and (2) construct significant prototype BFT systems whose costs and performance are comparable to deployed systems that use replication to tolerate a much narrower range of faults. If this work is successful and if technology trends continue, we believe it will become attractive for service providers to trade increasingly inexpensive hardware for the piece of mind provided by BFT replication.","title":"CSR-PDOS: BFT: The Time is Now","awardID":"0720649","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["466839","466840"],"PO":["561889"]},"129396":{"abstract":"A global regulatory effort is underway to allow secondary spectrum trading by license holders and flexible access by end-users. Preliminary evidence in early incarnations of secondary spectrum markets indicates a sophisticated market structure and suggests that realizing full potential of deregulated spectrum entails overcoming fundamental technical and economic challenges.<br\/><br\/>This project has the following research objectives: (i) Development of pricing strategies that capture network-wide effects of interference and that render secondary spectrum markets profitable for license holders; (ii) Design of market rules that facilitate new entrants and improve end-user perception in economic and performance terms; (iii) Development of resource discovery and monitoring algorithms that allow market participants to efficiently and securely utilize network services. These objectives are pursued in an integrated analytical framework that includes techniques of dynamic stochastic optimization, game theory, incentive engineering and tractable teletraffic modeling of large wireless networks.<br\/><br\/>This project promotes healthy deregulation of the wireless communication sector and shows promise for societal impact in view of the attendant economic activity and effective utilization of an important national resource. The educational component involves curriculum innovation aimed at facilitating the interaction between regulatory and technical communities, extracurricular activities in amateur radio, and outreach to members of minority and under-represented groups.","title":"WN: Collaborative Research: Management of Secondary Markets in Deregulated Wireless Networks","awardID":"0721545","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["562302"],"PO":["564777"]},"129165":{"abstract":"One approach to performance improvements for computational science problems is the use of alternative computing engines, such as field programmable gate arrays and graphics processing units, to execute portions of an application. We refer to such systems as architecturally diverse computing systems. We are attacking the challenge of effective application development for architecturally diverse computing systems by making significant progress in two essential areas: 1) compilers and 2) performance monitors and debuggers. First, we are investigating compilation techniques for mapping partitioned applications onto the disparate computational resources of a diverse system and supporting the required communications between those resources. This investigation includes the automated support of legacy APIs for commonly used libraries. Second, we are building a performance monitoring and debugging environment for diverse systems that has the following<br\/>properties: it is non-intrusive with respect to the application being monitored and it supports data collection concerning rare events. The result of this research will be a significantly increased ability to design, develop, and successfully deploy a wide set of general-purpose applications on architecturally diverse computational platforms.<br\/><br\/>Improved computational capabilities will have a dramatic impact on every scientific discipline that utilizes computational science techniques.<br\/>Computational science has already had a significant, broad impact on the natural sciences, national defense, weather forecasting, and a host of other areas. This research is aimed explicitly at improving the ability of computational scientists to accomplish their goals.","title":"CSR---AES: Application Development for Architecturally Diverse Computing Systems","awardID":"0720667","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["511556","525751"],"PO":["493916"]},"129176":{"abstract":"This project strives to improve the state-of-the-art in architectural<br\/>simulators in two ways: (i) by enabling users to determine if an architectural<br\/>simulator correctly models the key aspects of a real hardware system; and (ii)<br\/>by helping simulator implementors to identify weaknesses in their simulators.<br\/>This problem is critical because much architectural research today uses<br\/>simulations; if the simulators are not accurate then the results from the<br\/>simulator may be misleading. Prior work validates simulators by using<br\/>aggregate metrics (e.g., do the simulator and the real hardware execute a<br\/>program in a similar number of total cycles?). This validation does not<br\/>consider whether or not the simulator and the hardware exhibit similar<br\/>time-varying behavior.<br\/><br\/>A key innovation of this project is that it embraces techniques from the field<br\/>of non-linear dynamics. These techniques are well suited for computer systems<br\/>for two reasons. First, computer systems are non-linear at all levels (e.g.,<br\/>the cost of a cache miss is not fixed and instead depends on many factors) and<br\/>thus linear techniques will be of only limited use. Second, many aspects of<br\/>computer systems are unknown (e.g., the hardware manufacturer may not reveal<br\/>the full specifications of the hardware) or unmeasurable (e.g., it may not be<br\/>possible to measure how often a particular event occurs deep down in the<br\/>hardware). Non-linear dynamics techniques are specifically designed to deal<br\/>with such missing information.","title":"CSR---SMA: Validating Architectural Simulators Using Non-Linear Dynamics Techniques","awardID":"0720692","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["530767","530767","461768"],"PO":["565255"]},"129187":{"abstract":"The InterGridSolve project is developing an environment that will enable scientists to easily harness Grid resources provided by Computational Services Providers (CSPs) ranging from federally funded TeraGrid to commercially available services such as those provided by Amazon Elastic Compute Cloud (EC2). In order to support the Scientific Computing Environments (SCEs) that many scientists use in their work (e.g., Matlab, Octave), and to incorporate flexible computing models, the research is enhancing GridSolve, a pre-existing brokered RPC environment. GridSolve is based on the GridRPC API proposed by the Open Grid Forum (OGF) and uses function handles and sessions to make remote procedure calls on Grid resources. GridSolve includes resource scheduling, execution monitoring and fault tolerance. General purpose data movement mechanisms (i.e., data handles) are being designed and added to GridSolve in order to enable workflow applications. The data handle mechanisms are to be proposed as extensions to the GridRPC API. Tools to enable workflow applications on Grid resources using data handles in GridSolve are being explored, and several classes of workflow applications (such as simple DAGs) are being implemented. <br\/><br\/>Broader Impact: This project will enable computational scientists across multiple domains to use their accustomed SCEs to access Grid resources made available by various service providers, and to run computationally intensive, workflow jobs on these resources.","title":"Collaborative Research: CSR---AES: InterGridSolve: A Virtualized, General Purpose, and Interoperable Grid Computing Environment for Computational Science","awardID":"0720731","effectiveDate":"2007-09-01","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["558550",342281,342282],"PO":["493916"]},"129088":{"abstract":"Networked dynamical systems are found throughout the national infrastructure.<br\/>Examples of such systems are seen in the national power grid, wastewater networks, and the national transportation system. As these networks grow in size, weak coupling across the network can blossom into system wide disturbances whose effects are felt over large geographical regions. There is, therefore, a compelling national need to devise more robust and cost-effective techniques for managing such networked systems. This project addresses this need through a self-triggered approach to decentralized control. In this approach, network subsystems use their current state information to determine the rate at which information must be exchanged to assure the networked system?s global L2 stability. These rates are cast as quality-of-service (QoS) constraints on the network?s traffic. This project uses these QoS constraints to develop soft real-time algorithms for scheduling message passing in networked control systems. The novel aspect of this work is that the resulting soft real-time control system provides guarantees on application performance that have traditionally been seen in hard real-time systems. The project is transferring the self-triggered technology to the private sector through collaborations with industry on a project that uses embedded sensor-actuator networks to control the frequency of combined-sewer-overflow (CSO) events. This CSO network is a good example of a networked cyber-physical system. To support the training of engineers qualified to manage such systems, this project is developing a set of lectures on the mathematical foundations of cyber-physical systems.","title":"CSR-EHS:Integrating Decentralized Control and Real-Time Scheduling for Networked Dynamical Systems","awardID":"0720457","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["526924","550624"],"PO":["561889"]},"131090":{"abstract":"This project involves the development of fundamental algorithms and software tools for the efficient simulation of multi-scale, biological systems. The target application for these tools is the simulation of the adaptive human immune system response to viral infections. The multi-scale nature of these applications arise from the different length and times scales inherent in inter-cellular and intra-cellular processes. At the inter-cellular level, the movement and interaction of a variety of human cells, viruses, and antibodies must be modeled. <br\/>However, at the intra-cellular level, chemical pathways are simulated by complex network models that occur at much smaller time and length scales.<br\/><br\/>To make such computationally challenging simulations tractable, this project addresses two main research directions. First, the algorithms and software necessary for an efficient, multi-scale, agent-based software framework will be developed. These algorithms include efficient solution methods for the diffusion of biological agents, diffusion with drift (cell chemotaxis), and fluid flow. Second, to make the intra-cellular processes tractable, a novel model repository scheme will be developed whose goal is to achieve orders-of-magnitude improvement in computational time. The intellectual merits of this proposal will result from progress in the development of the fundamental algorithms required to enable the simulation of multi-scale, biological systems. The broader impacts of the project lie in the exposure of graduate students to multi-disciplinary research as well as in enabling an important class of applications. For example, collaborators in biology will be able to develop models for the adaptive immune system response to Epstein-Barr and influenza viral infections with the aim of developing more effective disease intervention strategies.","title":"Fundamental Algorithms to Enable the Simulation of Multi-Scale Biological Systems","awardID":"0728901","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["485861",347998],"PO":["565223"]},"135490":{"abstract":"The discipline of symbolic computation provides advanced software for cyber-enabled discovery and innovation. Symbolic methodologies and programs are applied to problem solving and model discovery in<br\/><br\/>--scientific computing,<br\/>--physics,<br\/>--mathematics,<br\/>--inter-system communication protocols and standards,<br\/>--categorical language design, generic programming and compilation,<br\/><br\/>and more. Due to the complexity of the arising computations, parallel and distributes environments are coming into use, symbolic and numeric approaches are combined into hybrid methods, and semantic verification and output certification (e.g., through Las Vegas randomization and numerical error analysis) are performed.<br\/><br\/>We propose to gather in late October or early November 2007 in Washington DC a group of 24--30 invited internationally recognized experts from academia and industry in both symbolic computation and its CDI applications disciplines (e.g., numerical computing, physics, mathematics, computing language design and compilation, parallel and distributed computation, program interface design) for a one and one half day workshop. The objectives of our workshop are to discuss and produce a report on possible research directions and their synergies for CDI through symbolic computation, both in the symbolic computation and the applications disciplines. Novel uses of symbolic computation can be sparse model construction by hybrid symbolic\/numeric methods, sparse exact matrix computations for problems from physics and mathematics, multi-level parallel software design for polynomial system solution and non-linear optimization, high-level categorical and verifiable program design, algorithm synthesis, and more.","title":"Workshop on Advanced Cyber-Enabled Discovery & Innovation (CDI) Through Symbolic and Numeric Computation","awardID":"0751501","effectiveDate":"2007-09-15","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7351","name":"THEORETICAL FOUNDATIONS (TF)"}}],"PIcoPI":["485433"],"PO":["499399"]},"127351":{"abstract":"There has been a recent proliferation of industrial-strength synchronous collaborative systems, however, there has been little research comparing the performance of their distributed architectures, even though inadequate performance can be a show-stopper. In systematically examining this architectural design space, this project will provide a critical foundation for what is currently the ''black art'' of collaborative system design. This will have broad ranging impact in both research and industry. <br\/><br\/>The architecture design space will be modeled by several architecture parameters (e.g., transport protocol, server configuration, I\/O scheduling), system parameters (e.g., network latency, processing power) and task parameters (e.g., I\/O size, think time) that impact performance. Equations will be developed that give the value of the time, along key metrics such as join, leave, response, feedthrough, and task-completion, as a function of the architecture, system, and task parameters. Experiments will be performed to validate these equations using logs of different kinds of collaborations such as multi-user presentations, chats, and scientific visualizations. This novel experimental test bed will enable performance comparisons that have not been possible before. <br\/><br\/>Broader impact: The analytic model resulting from this research will allow application and infrastructure developers to determine the range of architectures they should implement. It will provide scientists, engineers, writers, and other users of collaboration technology a better understanding of the design space so they can choose the correct architecture to fit their needs while appreciating the performance consequences of that choice. In addition, the project infrastructure will form the first proof-of-concept system supporting the entire space of collaborative architectures, a novel research test-bed for experimentation, and a vehicle for teaching collaboration architectures. The multi-user activity logs created for these experiments will be publicized so that they can become benchmarks, in both academic and industrial research, used to compare performance of new architectures.","title":"HCC: Evaluating the Performance of Distributed Synchronous Collaboration Architectures","awardID":"0712794","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["533215"],"PO":["550147"]},"127472":{"abstract":"Shape is a powerful visual cue for recognizing objects in images, segmenting images into regions corresponding to individual objects, and, more generally, understanding the 3D structures of scenes. However, to be able to exploit shape information, we need reliable ways of detecting fragments of object boundaries, a difficult problem in itself. This project investigates possible solutions to these problems. Specifically, it explores ways to reliably detect occluding boundaries by focusing on the question of combining motion cues with appearance cues for better detection of occlusion boundaries. In addition, the project explores different ways in which boundaries can be used in key vision tasks by investigating the integration of boundary information in segmentation and category recognition.<br\/><br\/>The project is expected to generate advances in two areas: 1) detecting boundary information from images as shape cues and 2) using boundary information in segmentation and recognition tasks. In the first area, it extends the current approaches for contour detection to include motion cues. This is motivated by the availability of temporal information in many practical applications. Assuming that we can extract boundary fragments, the issue of using them effectively in segmentation and recognition remains an open question. The project will make substantial contributions toward answering that question, including integrating boundary information with image segmentation and recognition algorithms.<br\/><br\/> The project will result in advances that are directly relevant to a wide range of applications. In particular, the ability to reliably detect boundaries from image sequences is crucial in all applications that involve the analysis of videos for object discovery, recognition, and segmentation. The project is also expected to contribute to the development of more reliable category recognition algorithms based on shape representations, an enabling technology in a wide variety of fields including defense, health care, human-computer interaction, image retrieval and data mining, industrial and personal robotics, manufacturing, scientific image analysis, surveillance and security, and transportation. Although the project focuses primarily on automatic segmentation and recognition, it will also contribute to human-assisted segmentation and image editing, a technology area that is becoming increasingly important with the advent of consumer video and image editing tools. An additional expected product of the project is the generation of a corpus of labeled data, including motion data.<br\/><br\/>URL: http:\/\/www.cs.cmu.edu\/~hebert\/boundaries\/","title":"RI: Detecting Boundaries for Segmentation and Recognition","awardID":"0713406","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["520920"],"PO":["564318"]},"127241":{"abstract":"The primary goal of this project is to provide a novel framework and software that will empower users to more effectively understand and apply information discovered in large distributed data environments. The approach is to provide tested and novel data analytics techniques, supported by a framework that integrates expertise and insight of human users. The novel combination of the skills, abilities and experience of human users with the sheer processing power of distributed computation provides an extraordinary synergistic information-processing potential -- termed Interactive Automation. This framework places the user explicitly in the center of the Design, Execution, and Analysis processing modes, allowing them to switch between these contexts fluidly as well as react and guide the runtime processing of complex, distributed and dynamic datasets. <br\/><br\/>A secondary goal is to provide an authoritative, accurate, anonymized and openly available set of ground truth data in the law enforcement domain. At present, no such ground truth dataset currently exists, and currently analytics tools are evaluated using proprietary, confidential or otherwise closed datasets. Stable releases of the system modules, documentation, related publications and results from usability studies are available at the project website (www.dimacs.rutgers.edu). The broader impacts of this work lie regionally with our partners (in law enforcement, medicine and education), and broadly through dissemination of the dataset and software in academia and industry. In addition, the availability of the dataset will support related research efforts by providing a foundation for objective, comparative and scientific analysis of law enforcement data analytics tools.","title":"III: Visual Analytics for Steering Large-Scale Distributed Data Mining Applications","awardID":"0712139","effectiveDate":"2007-09-01","expirationDate":"2012-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["451739"],"PO":["563751"]},"127362":{"abstract":"A completely new focus in robotics research is proposed. The purpose is to enable automatic dispensing and mixing of highly viscous bio-samples which has important applications in life sciences including drug screening, protein crystallization, and protein expression. Since the volume to deal with is extremely small at the micro- or nano-liter scale, and viscosity causes the samples to stick to everything, robotic handling of such bio-samples is extremely challenging. Three novel methods are proposed to solve the problems. The first method is an innovative micro-capsule with micro-channel for mixing viscous bio-samples using centrifugation such that no contact is needed. The second method is soft-hard compliance of robotic motion for delivering bio-samples into tiny micro-capsules, for which a micro force-sensing device based on piezo-resistance and visco-elasticity is to be invented. The third method is a programmable robotic spinning device which generates adequate centrifugal forces in real-time for mixing bio-samples. The three new methods will lay a foundation for high-throughput dispensing and mixing of bio-samples using robust intelligence in robotics. In addition, the project will bring a broader impact to life sciences, education, and economy.","title":"RI: Robust Robotic System for Live Microarrays in Life Sciences","awardID":"0712845","effectiveDate":"2007-09-01","expirationDate":"2011-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["518511"],"PO":["543539"]},"127483":{"abstract":"Search technology today is dominated by search engines such as the one provided by Google where for a given query string s , a set D of documents is retrieved with the aid of an algorithm that ranks the elements of D on the basis of how many other documents link to it. This research will investigate the issues involved in the development of a search engine that supports geographic location retrieval, and its deployment in a setting involving digital government applications where it is also desirable to retrieve documents on the basis of spatial proximity. <br\/><br\/>Intellectual Merit: (1) Identifying geographic references in documents is a challenging issue and is necessary for advanced search applications. This is especially true in the case of users who want to browse large collections of documents that are not necessarily on the web and to explore and discover spatial relationships either in the same document or in a collection of documents. (2) Increasingly, users are looking for documents that contain spatially proximate content. Thus the traditional method of ranking by the link structure of the web is not appropriate. Determining the geographic focus of a document is a difficult task but is necessary in applications such as those dealing with documents on the hidden web, which is a set of documents, usually proprietary, that is for internal use of an organization and is often not available on the Internet. This means that there are few, if any links to these documents, and thus popular internet search strategies are not applicable. (3) Treating spatial content of documents as a first-class citizen, in the sense that a geographic scope is reported for each document that is retrieved regardless of whether the query has a spatial component, is difficult given the need to resolve issues related to aliasing (realizing that ''''Los Angeles'''' and ''''LA'''' are the same) and ambiguity (different interpretations for ''''London''''). (4) Developing query optimization and execution strategies for queries that involve both a textual and spatial component. (5) Developing effective techniques for measuring spatial similarity other than proximity, as well as techniques for measuring combinations of spatial and textual similarity. This includes the adaptation of the skyline operator. <br\/><br\/>Broad Impacts: The ability to retrieve documents on the basis of spatial proximity makes for a better search experience and will lead to more relevant results. The tools to be developed will also extend the reach of search engines from being restricted to documents on the internet to documents that reside on the hidden web. The deployment of these tools in government web sites via collaboration with the grant''s digital government partners has the effect of empowering citizens to find out what their government is doing, thereby leading to a more informed citizenry.","title":"III: SpatioTextual Extraction of Document on the Web for Digital Government Applications","awardID":"0713501","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"H312","name":"NSA"}}],"PIcoPI":["551003","564282"],"PO":["563751"]},"129430":{"abstract":"Aggregations of massively deployed sensors are expected to create sophisticated sensing, computation, communication and control platforms called Networked Sensor Systems (NSS) that will pervade society, revolutionizing the way in which we live and work. In order to scale, these systems must be largely autonomous, decentralized entities whose corporate resources can be made available to authorized users. Such autonomous, geographically-dispersed NSS are increasingly recognized as key to numerous applications ranging from healthcare to smart homes and homeland security. For example, autonomous NSS can assist first responders, often in inhospitable environments, by locating survivors, identifying danger areas and enhancing user awareness of the situation The resource-constrained sensors, the wireless communication medium, the large-scale deployment, combined with the mobility of users, the close interaction with the physical environment and the highly sensitive nature of mission-critical operations pose formidable challenges to autonomous NSS design. The key inter-related technical contributions of this project are: (1) Dynamic task-based networking supporting application-level tasks and queries while hiding resource-level details; (2) Smart AFN mobility subject to changing application requirements and network conditions; and (3) providing secure ANSWER operation and multi-level secure interactions with in-situ mobile users. ANSWER prototype can serve as a tool to explore mobile user behavior in ubiquitous networks under varying environmental and network conditions. This project will leverage programs at VT, UMBC, and ODU to actively recruit and involve under-represented groups in innovative multi-disciplinary hands-on experiments in ubiquitous networking, security and sensor systems. The research results will be disseminated via the project's Web site (http:\/\/www.nve.vt.edu\/cias\/cycarenet\/ANSWER).","title":"Collaborative Research-NETS-NOSS: AutoNomouS netWorked sEnsoR Systems (ANSWER)","awardID":"0721644","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["534304"],"PO":["564777"]},"128231":{"abstract":"National Science Foundation <br\/>CISE\/CNS <br\/>Form 7 Review Analysis and Recommendation <br\/><br\/>Proposal Number: 0716368 <br\/>PI: Daniel Lopresti <br\/>Institution: Lehigh University <br\/>Lead <br\/><br\/>Proposal Number: 0716393 <br\/>PI: George Nagy <br\/>Institution: Rensselaer Polytechnic Institute <br\/>Sub <br\/><br\/>Proposal Number: 0716647 <br\/>PI: Elisa H. Barney Smith <br\/>Institution: Boise State University <br\/>Sub <br\/><br\/>Proposal Number: 0716543 <br\/>PI: Christopher Borick <br\/>Institution: Muhlenberg College <br\/>Sub <br\/><br\/><br\/><br\/>Title: Collaborative Research CT-T: Following the Paper Trail: Reliable Processing of Voting Records for Trustworthy Elections <br\/><br\/><br\/>Proposal Abstract <br\/><br\/>Provisions for the inclusion of a physical record, in the form of hand- or machine-marked ballots, or as a Voter Verified Paper Audit Trail (VVPAT), are central to guaranteeing safe and secure elections. However, the processing of such records during the initial counting of votes or in the conduct of audits has raised its own set of problems which span broad technical and social boundaries. <br\/><br\/>The aim of this project is to study issues that currently make paper records more of a nuisance than an integral component in trustworthy voting systems. Specifically, the principal investigators are working to characterize the statistical distribution of mark sense errors as a function of ballot layout and quality in optical scanning, to examine approaches for unbiased visual auditing based on ballot images, to investigate the possibility that a concept known as homogeneous class display (HCD) can facilitate manual recounts, and to evaluate recognition errors that may arise in processing the VVPAT used with Direct Recording Electronic (DRE) systems. They are also interested in the effects these issues have on procedures for testing the paper handling components of voting systems in accordance with operational constraints, including the modest training received by most poll workers. This work on voting technologies is supported by ? and supports ? a planned survey and focus groups they are conducting to measure voter confidence and acceptance and to identify common misconceptions and concerns, including accessibility to disabled voters. Beyond its broad impact on the development of more reliable and trustworthy voting technologies, this project more generally has implications for the highly accurate computer processing of any information encoded in human readable form.","title":"Collaborative Research: CT-T: Following the Paper Trail: Reliable Processing of Voting Records for Trustworthy Elections","awardID":"0716543","effectiveDate":"2007-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":[339898],"PO":["521752"]},"127384":{"abstract":"The goal of the proposed research is to develop deterministic motion-planning algorithms to accomplish system-wide reconfiguration of connected clusters of mobile, modular robots, including undergraduate students in all aspects of algorithm development. The first part of this project involves the incremental development and analysis of a suite of algorithms that together comprise a complete deterministic motion planner. The planner is ?complete? in the sense that it will reconfigure a system of n modular, mobile robots, from a connected initial configuration into any equal-sized connected goal configuration. We seek a distributed solution to this problem that is reasonably efficient and provably near-optimal, in terms of number of robot moves and overall reconfiguration time. We have already made progress on the development, analysis, and simulation of algorithms that form the basis for a complete planner for a robotic system composed of hexagonal robots and have also begun to develop algorithms that are resilient to the presence of obstacles in the reconfiguration environment. In the second part of this project, we will focus on making our algorithms adaptive to uncertainty and different module types. The algorithms will be verified experimentally using a number of different visualization tools.","title":"RI(RUI): Motion Planning Algorithms for Self-Reconfigurable Robotic Systems","awardID":"0712911","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[337841],"PO":["562760"]},"128121":{"abstract":"Service-oriented architectures (SOAs) enable the dynamic integration of services implemented on heterogeneous computer systems. An advantage of SOAs is that they provide high-level, semantically-rich services by abstracting the low-level details of their implementation. The availability of useful services such as Google's and Amazon's web service APIs has fostered applications that integrate a number of services to provide novel, more complex functionality.<br\/><br\/>As the service-oriented model is increasingly adopted, there is a need for rigorous approaches to model trust in SOAs and ensure trust in the composition of services, in the form of service-based applications. These approaches should guarantee that by composing services that satisfy certain trust properties one will obtain an application that satisfies the desired trust properties.<br\/><br\/>The goal of this project is to develop novel tools and techniques for the modeling and analysis of trust properties of SOA-based applications. More precisely, the goal of this research is to develop a framework that leverages formal models of trust, automated, and interactive verification techniques, and program analysis techniques to address trust properties of single services and of their compositions, at both the interface and implementation levels.<br\/><br\/>The broader impact of this research will be a comprehensive framework that provides a number of techniques and tools for the modeling, analysis, and enforcement of trust properties in SOA-based applications. These tools and techniques will provide a more trustworthy infrastructure for the implementation of SOA-based applications in governmental, military, and private environments.","title":"CT-T: Modeling and Analyzing Trust in Service-Oriented Architectures","awardID":"0716095","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["402618","486421","535035"],"PO":["565327"]},"128242":{"abstract":"To motivate undergraduate students for interdisciplinary research at the intersection of communication, cryptography, wireless networking, and embedded systems, we introduced a course called Secure Wireless Robots on Mission (SWARM). SWARM is laboratory-focused with the goal of designing, and building rescue-mission oriented heterogeneous wireless systems, operating in adversarial environments. It integrates a team-based competition as a pedagogical tool to motivate and challenge the students. It uses state of the art technologies such as multi-hop sensor networks, cell phones programming, Bluetooth communication, and basic robotics. Teams are allowed to use any denial of service attack (e.g., jamming, replaying). We propose to expand SWARM into a sequence of two courses SWARM I, and SWARM II and open it to both CS\/EE undergraduate and graduate students. The students will be required to form mixed teams. SWARM I will deal with building the hardware platform for the embedded wireless communication and robot control, and the software libraries for secure communication and control. SWARM II will focus on developing a multi-hop control and communication system with robustness against adversarial attacks. We aim at extending the SWARM pedagogical approach, to attract and to prepare a future workforce in cyber security by providing them a controlled environment to explore and to test new research results. We intend to transfer our research results and technologies to the classrooms, to stimulate students? interest, and to obtain feedback from classroom activities. We will also develop materials such as hardware prototypes and software libraries to be shared with the education community.","title":"CT-ISG: Secure Localization: An Education and Research Joint Approach","awardID":"0716581","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["528405","518182"],"PO":["529429"]},"129573":{"abstract":"TITLE: Can Humanitarian Open-Source Software Development Help Revitalize Undergraduate Computing Education?<br\/><br\/>PI: Ralph Morelli (ralph.morelli@trincoll.edu)<br\/><br\/>This community building project creates a diverse community of individuals from academic computing departments, social service organizations, and computing and IT corporations, to test the hypothesis that humanitarian free and open-source software development (H-FOSS) can help revitalize undergraduate computing education. The project will capitalize on two contemporary interests that are under served in computing curricula: the open-source development model, as a way to teach software engineering; and, service-learning, as a means by which students and faculty can contribute to the surrounding community. A software development version of the Habitat for Humanity model will be investigated: instead of building houses, students and faculty will learn computing by building software systems that benefit humanity. To combat the computing-is-coding myth, community-based summer and academic year internships will demonstrate that computing is working together with other people to design and develop solutions to real problems. By engaging students and faculty from participating schools in summer institutes, credit courses, spring-break community-help projects, and an academic curriculum workshop, the project will develop a portable and sustainable educational model that attracts socially engaged students to the computing discipline, bridges the divide between town and gown, and builds truly useful humanitarian software.","title":"CPATH CB: Collaborative: Can Humanitarian Open-Source Software Development Help Revitalize Undergraduate Computing Education?","awardID":"0722199","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["513893","425111"],"PO":["562944"]},"129463":{"abstract":"Data transfer is a defining task of a network. This project, uswarm, proposes a novel data-transfer architecture inspired by recent, tremendously successful swarming systems such as BitTorrent. The project pursues the following, rather exploratory, question: can swarms form the basis of a universal data-transfer architecture for a future Internet and if so, what is an appropriate architecture? Natural systems with swarm-like properties are known to be extremely robust both for an individual and for the system as a whole. The technical motivation is to make Internet data transfer: 1) scalable, 2) fault-tolerant, and 3) incentive-compatible, a trio of properties difficult to achieve using existing solutions. The research underlying uswarm will: 1) develop an in-network BitTorrent-like substrate deliver practically all data, not just large files, 2) exploit in-network storage and locality of data accesses, 3) analyze availability and human wait-time improvements of one large integrated swarm as opposed to BitTorrent-like isolated swarms, 4) analyze new traffic engineering knobs and routing choice naturally enabled by uswarm, 5) develop novel incentive strategies for integrated swarms accounting for network-level incentive issues, 6) analyze the interaction of selfish behavior with routing and congestion control using game-theoretic techniques. <br\/><br\/>Broader Impact: If successful, this project will fundamentally improve Internet data transfer by enabling: 1) critical information dissemination resistant to denial-of-information attacks, 2) delay-tolerant network applications, and 3) novel social networking applications. The proposed work includes undergraduate as well as international teaching and outreach activities integrated with the proposed research activities.","title":"NeTS-FIND: A Swarming Architecture for Internet Data Transfer","awardID":"0721779","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["497218","545655"],"PO":["565090"]},"128253":{"abstract":"We live in the information age, a time when data and knowledge is plentiful and easily moved, processed and mined by machines. This makes it easier to discover knowledge and more efficiently manage our affairs but also increases concerns about information confidentiality, privacy and trust. Balancing these will be a defining challenge in the coming decades and is particularly urgent today in organizations responsible for national defense, law enforcement, emergency services, and public health and safety. The 9\/11 Commission addressed this in their report and called for \"a paradigm change from Need to Know to Need to Share\". This project will explore one concrete aspect of this shift -- how executable policies can help organizations enhance their ability to share information and access while still maintaining appropriate levels of security, confidentiality and privacy.<br\/><br\/>The University of Maryland, Baltimore County, the University of Texas at San Antonio and the University of Texas at Dallas will build on existing work at our three institutions to develop and refine a a conceptual framework for computational policies to support information sharing in a need to share environment. Our framework will integrate and extend our work on access control (RBAC), usage control (UCON) and deontic policies (REI), grounding them in ontologies expressed in the Semantic Web language OWL. We will use it to design a policy specification language and enumerate required software artifacts and tools. Finally, we will study the framework applicability to realistic applications such as the management of healthcare records and homeland security related data.","title":"CT-T: Collaborative Research: A Semantic Framework for Policy Specification and Enforcement in a Need to Share Environment","awardID":"0716627","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["563576","558176",339957,"533183"],"PO":["529429"]},"129584":{"abstract":"Proposal Number: 0722234<br\/><br\/>Title: CPATH CB: Connecting Computing Educators Within and Outside the Traditional Boundaries<br\/><br\/>PI: Lillian Cassel<br\/><br\/>The primary focus of this one-year activity will be workshops to bring together those in the computing education community, across the subdomains of that group, and others who are integrating the fruits of computational thinking into a wide variety of disciplines. It is common to find curricula in the arts (music, graphical design), business (accounting, economics), sciences (biology, chemistry, physics), and social sciences with computational courses in their curriculum. In the one year of this project, the workshops will focus on identifying the scope of the similarities and differences among these communities and in identifying ways in which the computing community can best serve the entirety of the expanded community. The project will begin the integration of the computing ontology into the organization of curricular materials and the use of social software to deliver essential information. A centralized website will provide RSS feeds with news about computing education, blog entries about computing education, links to resources, and other community oriented information (e.g., conference calendars). Workshop participants will include faculty from all of the computing disciplines, industry representatives, students, and faculty from disciplines we do not usually think of as computing intensive.","title":"CPATH CB: Connecting Computing Educators Within and Outside the Traditional Boundaries","awardID":"0722223","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}}],"PIcoPI":["531150","563440"],"PO":["562944"]},"129111":{"abstract":"Embedded real-time systems span a wide range of application domains including consumer electronics, motion and transportation control, automotive systems, building control, process control, industrial automation, aerospace and defense, and network elements. For example, a modern automobile has tens of microcontrollers, which must coordinate and control actuators in real-time. Failure to act on time can lead to damage to property and even loss of life. Hence, these systems must often satisfy multiple requirements: timeliness, jitter, fault-tolerance, safety, security and dynamic modalities. However, the bulk of the development of these systems continues to be at a low level of abstraction. Policies dealing with concurrency, end-to-end timing requirements, jitter constraints, exception-handling, failure management, safety issues and security concerns are hardwired into the architecture. Subsequently, the system implementation is directly coupled with the details of underlying run-time environments including OS interfaces, communication protocols adopted and programming languages used. The end-result is the creation of stove-pipe architectures and implementations that are very hard, a posteriori, to understand, analyze, validate, modify and maintain. Model-based development of embedded real-time systems is aimed at elevating the level of abstraction at which these systems are designed, analyzed, validated, coded and tested. The use of a holistic and coherent multi-dimensional model across all behaviors enables model-based design to generate systems that are correct by construction. It thus offers the promise of representing necessary functional and para-functional (sometimes called non-functional) behaviors at a level that is easy to understand, reuse, analyze formally, validate rigorously, and significantly easier to modify and maintain. This project is developing a model-based design and development toolset called SysWeaver that (i) models in an integrated fashion functional and para-functional concerns along with hardware configurations of distributed real-time systems, (ii) validates functional and para-functional behaviors at the modeling level, (iii) generates complete runtime code for these systems, (iv) helps collect run-time measurements to provide richer annotations of the models required for (say) worst-case timing analysis. The software tools are made available for free download and use.","title":"CSR---EHS: SysWeaver: A Holistic Model-Based Design and Development Environment for Distributed Real-Time Systems","awardID":"0720527","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["461012"],"PO":["561889"]},"129474":{"abstract":"This project aims at defining, optimizing and implementing a novel underwater sensor network architecture, called SEA-Swarm (Sensor Equipped Aquatic Swarm), that consists of a large number of low cost underwater sensors that operate and move as a group (swarm) with water current and dispersion. The proposed SEA-Swarm architecture will enable a whole new era of observations, monitoring and explorations in the aqueous environment. Such tool will be by its very essence multidisciplinary and is expected to foster a broad collaboration between researchers in networking and communications and other scientific communities, such as environmental sciences, marine biology and coastal surveillance and security. A number of technological challenges shall be addressed by this project, along with the related fundamental research aspects: a new generation of underwater acoustic communications modems is to be designed based on OFDM, achieving unprecedented data rates thanks to Doppler compensation and MIMO space-time signal processing techniques. Cooperative communication protocols, driven by the information theoretic relay channel, are synergistically optimized jointly with a new energy efficient geo-routing algorithm. In essence, all the nodes in a virtual pipe from source to destination cooperate to reliably deliver the message. For reliable data transport, network coding for erasure correction and packet combining for energy efficiency is investigated. Finally, efficient localization schemes based on underwater GPS and nodes with dedicated data-collection functions (data mules) are advocated in order to tackle the mobility and the topology randomness problems due to the swarm nature of the network. The cross-layer design involving the above aspects is validated through a dedicated simulation environment (Aqua-Sim). A cost-effective over-the-water acoustic communication testbed shall be developed by USC in order to provide proof of concept of the basic network algorithms. Finally, an underwater testbed proof of concept is planned in synergy with other existing projects such as MyPond and MySound at U-Conn, and at the UCLA Marina Aquatic Center. The theoretical and experimental work at all three collaborating teams shall involve graduate students and also expose undergraduate students to state-of-the art communication engineering projects, developed in the framework of the above mentioned testbeds.","title":"Collaborative Research NeTS-NOSS: SEA-Swarm: A Rapidly Deployable Underwater Sensor Network","awardID":"0721834","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["546033","526410"],"PO":["564777"]},"129243":{"abstract":"Today's software systems suffer from poor reliability and security,<br\/>with software errors costing the U.S. economy upwards of $60 billion<br\/>annually. This situation is likely to get worse, as the complexity of<br\/>software systems increases without a matching increase in the<br\/>effectiveness of software quality tools and techniques. The situation<br\/>is particularly challenging for concurrent systems, which pose<br\/>significantly higher difficulties for software quality tools, yet are<br\/>becoming more widespread with the growing use of multicore machines.<br\/><br\/>Static analysis software-quality tools are very precise but do not<br\/>scale well to large codes. Testing is easy to use but for good<br\/>coverage requires extensive test suites. We propose to bridge the gap<br\/>between ad hoc testing and static analysis by combining them in a new<br\/>scalable technique called predictive testing. Predictive testing uses<br\/>static program analysis to maximize the effectiveness of a given<br\/>test-suite for finding in the testing stage bugs that could manifest<br\/>in real production runs. Although predictive testing tools use complex<br\/>static analysis and automated theorem proving techniques internally,<br\/>all of this complexity is hidden from the user by a testing usage<br\/>model. For this reason, we expect that such tools can be easily<br\/>integrated into existing software engineering processes and will be<br\/>usable even by unsophisticated developers.","title":"CSR --- SMA: Predictive Testing of System Software","awardID":"0720906","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["451874","451873"],"PO":["493916"]},"128154":{"abstract":"Energy infrastructure is a critical underpinning of modern society that any compromise or sabotage of its secure and reliable operation will have a prominent impact on people's daily lives and the national economy. This project develops a hardware-in-the-loop reconfigurable system with embedded intelligence and resilient coordination schemes that would tackle the vulnerabilities of the power grid. This system differentiates itself from previous and existing research efforts in the following key aspects. First, it capitalizes and integrates new power electronic technologies in the system design to facilitate a more direct reconfiguration of the physical makeup of the grid. Second, it pushes the intelligence toward the lower level of the power grid such that local devices have the capability to make decisions and to react more quickly to contingencies. Third, it adopts control-theoretic real-time adaptation strategies for analytic assurance on providing desired dynamic responses to unpredictable system changes to efficiently maintain the availability of large distributed systems. Finally, the system is evaluated not only through simulation, it is also implemented and demonstrated on a microgrid testbed. The evaluation is conducted from three aspects, including real-time responsibility, fault resiliency, local collaboration capability. The power grid is a typical example of complex networks of highly interacting subsystems. Solving these fundamental problems to create a resilient power grid has a direct and immediate impact on this and other critical infrastructure. The project is coupled with a strong educational component including an innovative multi-university curriculum design, active recruitment of students from underrepresented groups supported by existing programs, and broad dissemination of research findings.","title":"Collaborative Research: CT-T: A Resilient Real-Time System for a Secure and Reconfigurable Power Grid","awardID":"0716253","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["381746"],"PO":["529429"]},"128286":{"abstract":"Experience shows that most programmers can't write secure code. Few applications have the luxury of being written by security-conscious programmers, and thus the vast majority of all software is untrustworthy. At the same time, operating systems and networks have spectacularly failed to control the damage caused by subverted software.<br\/><br\/>However, one technique--information flow control--has proven capable of limiting damage by buggy and even malicious software. The military has long used this technique to protect sensitive data against Trojan horses, but retrofitting existing operating systems with information flow control is a lengthy and difficult process, often unable to keep pace with the evolution of commodity software.<br\/><br\/>We intend to develop a clean-slate infrastructure for distributed applications in which the lowest-level abstractions are specifically designed to control information flow. We will re-think the architecture of operating systems, networks, and even processors to realize an infrastructure that relies on a small, highly-secure, and, at least in part, mechanically checkable trusted computing base. On top of this base, we will implement interfaces that resemble the network programming APIs to which Unix programmers are accustomed.<br\/><br\/>Our infrastructure will aim to give programmers as much freedom as possible to structure their applications, subject only to information flow constraints. Our motivating application will be scalable Internet web sites replicated across multiple servers.","title":"CT-T: A Clean-Slate Infrastructure for Information Flow Control","awardID":"0716806","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["448745","462739","556787","560546"],"PO":["565327"]},"129144":{"abstract":"The complexity of enterprise data centers has grown steadily in recent<br\/>years, primarily due to continuous evolution resulting from small<br\/>incremental changes to system hardware and software. This project<br\/>focuses on a modeling and analysis approach for improving the<br\/>manageability of complex data centers. The project focuses on (i)<br\/>scalable, adaptive monitoring techniques for very large data centers,<br\/>(ii) multi-scale modeling of complex data-center applications, and<br\/>(iii) model-driven analysis to predict system performance, bottlenecks<br\/>and capacity requirements. The adaptive monitoring approach involves<br\/>the use of statistical data mining and learning to dynamically vary<br\/>what systems are monitored and when. The multi-scale models involve<br\/>capturing system behavior at large, medium and small scales by<br\/>modeling application interactions at different levels of abstraction:<br\/>at the data center level, at the application level, and at the<br\/>individual server level. Model-driven analysis brings together<br\/>adaptive monitoring and the multi-scale models for capacity<br\/>provisioning, bottleneck detection and performance prediction. The<br\/>modeling and analysis techniques will be validated using real-world<br\/>data center applications running on a Linux-based data center testbed.<br\/>Broader impacts include source code release and sharing of anonymized<br\/>trace data to enable further experimentation by other researchers and<br\/>the participation of undergraduate students in this research via<br\/>summer REU projects.","title":"CSR-SMA: Measurement, Modeling and Analysis of Large Complex Data Centers","awardID":"0720616","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["558563"],"PO":["493916"]},"129386":{"abstract":"The Internet is a phenomenal success, but problems and weaknesses in<br\/>it have become apparent, and this has spurred a search for new<br\/>technologies and network architectures. Although technical innovation<br\/>will remain fundamental to the Internet's evolution, the importance of<br\/>this key infrastructure for society as a whole means that economic<br\/>aspects will be critical in determining what innovations are adopted.<br\/>This project, therefore, seeks to investigate -- both qualitatively<br\/>and quantitatively -- how economic factors mediate the eventual<br\/>success of new network architectures and technologies. Aspects of<br\/>interest include quantifying the benefits of virtualization in<br\/>enabling different levels of network integration; evaluating the<br\/>effect of a dominant incumbent (today's Internet) on emerging new<br\/>architectures; and devising models for quantifying the value of<br\/>architectural flexibility and openness in facilitating technology<br\/>adoption and service creation in the presence of market uncertainties.<br\/><br\/>The intellectual merit of the proposed research is in developing an<br\/>economic framework for reasoning about network technologies,<br\/>architecture alternatives and trade-offs. The goal is to inform the<br\/>design of new network architectures by accounting for both their<br\/>technical dimensions, and the economic mechanisms that will mediate<br\/>their success or failure. The broader impact of the project will be<br\/>in helping select network solutions that are likely to succeed in the<br\/>market place. The project will also foster a multi-disciplinary<br\/>curriculum involving economics, business and engineering perspectives.<br\/>This will both better prepare engineering students to succeed in a<br\/>world where understanding of economical forces is of paramount<br\/>importance, and promote interactions and collaboration among<br\/>engineering and business students.","title":"Collaborative Research: FIND - On the Economic Viability of Network Architectures","awardID":"0721510","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["543509",342812],"PO":["565090"]},"128176":{"abstract":"This project addresses transparent Damage Quarantine and Recovery (DQR), an important problem faced by a large number of mission\/life\/business-critical applications and information systems that must manage risk, business continuity, and assurance in the presence of severe cyber attacks. Today, these critical applications still have a ?good? chance to suffer from a big ?hit? from attacks. Due to data sharing, interdependencies, and interoperability, the hit could greatly ?amplify? its damage by causing catastrophic cascading effects, which may ?force? an application to halt for hours or even days before the application is recovered. <br\/><br\/>Traditional failure recovery techniques, though mature in handling random failures, cannot solve the DQR problem due to several fundamental differences between failure recovery and attack recovery. DQR is not a new concept, but there is still a big gap in engineering practical DQR capabilities for real-world applications, and no prior DQR techniques address Web Services or Service-Oriented Architectures. In this project, we will take a holistic approach and make an integrated set of innovative contributions on four fundamental aspects of DQR: theories, mechanisms, applications, and systems. The proposed innovations include the first theory that integrates recoverability and quarantinability, the first DQR scheme that uses mark-based causality tracing to replace read-write-dependency analysis, a novel DQR scheme that does ?cleaning-free? recovery, and the first set of DQR theories and mechanisms for Web Services. In addition, complete open-source DQR tools and systems will be prototyped.","title":"Collaborative Research: CT-T: Transparent Damage Quarantine and Recovery in Transactional Applications and Web Services","awardID":"0716323","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["540637"],"PO":["529429"]},"129397":{"abstract":"The survival of critical sensor data that is collected during manmade or natural disasters is arguably more important than traditional sensor-network design objectives, such as prolonging the sensors' lifetime. Under this project, a sensor data ghosting framework is being developed. This framework creates minimal data redundancy, known as sensor data ghosts, which roam around the sensor network toward a sink. Under sensor failures, the data ghosts are expedited toward the sink for their timely recovery. Recovery of the sensor data at the sink becomes feasible due to the availability of just enough data (generated due to data ghosting). <br\/>Coding and networking solutions are being developed and integrated in a synergetic manner to achieve sensor data survivability and persistence. In particular, network coding approaches that map efficient channel codes over network graphs are being developed. On the networking side, a novel topology evolution solution that is capable of reacting rapidly to random failures and providing expedited delivery of critical data to the sink is being researched. This topology evolution approach rearranges a traditional sensor-network geometric topology toward a small-world network topology, which allows a small number of long-haul \"shortcuts\" toward the sink. Related networking research, such as directed diffusion and prioritized forwarding, is also being investigated under topology evolution. In addition to enabling new levels of sensor data survivability, this project has significantly broader theoretical and practical impact than the target sensor application. This includes the development of new types of \"codes on network graphs\" and approaches in adaptive network topologies.","title":"NOSS: Sensor Data Ghosting: A Framework for the Survival of Critical Data under Sensor Failures","awardID":"0721550","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["554511"],"PO":["557315"]},"129188":{"abstract":"Significant pieces of our nation's critical infrastructures depend on automation systems that operate under tight safety and timing constraints. Critical infrastructure security, bottling and packaging, material and container handling, automated manufacturing, on-board ship systems, locomotion systems, airport baggage handling, and amusement park rides are a few examples of such systems. With over a trillion dollars of installed base in North America, and over $90 Billion dollars forecasted revenues for year 2008, these systems represent an important class of embedded real-time systems. However, there are serious design and operational problems in existing automation systems. Rigid architectures and proprietary\/inflexible implementations have resulted in systems that are difficult to operate and maintain. This project addresses research issues that are critical for incorporating advances in networked embedded computing into automation systems with flexible topologies. Technology support for atomic and coordinated actions enables cooperative operation in complex, coupled automation systems. A real-time middleware framework for sensor-actuator systems is being developed, providing services for node-level execution, scheduling, synchronization, mode-management, and fault management. By incorporating these advances, it is possible to reduce costs, achieve fine-grained control, improve safety, and design automation systems with flexible topologies for a variety of applications such as automotive assembly lines, chemical process industries, warehouses, airport baggage carousels, amusement park rides and package distribution centers. By focusing on the specific domain of automation systems, this project seeks to drive several innovations that include: targeted integration of sensors and actuators in low-cost nodes, dynamic re-configurability of wireless sensor networks driven by exception conditions, exploitation of redundancy to mask individual node or sensor failures, a scalable infrastructure, monitoring of large-scale operations, performance under constrained conditions, specialized algorithms and communication protocols that address real-life automation requirements, and inter-operability with current automation systems.","title":"Collaborative Research: CSR-EHS: Real-time Sensor-Actuator Systems for Automation","awardID":"0720736","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["525578"],"PO":["561889"]},"129199":{"abstract":"This project is developing new techniques for programming \"irregular\"<br\/>parallel applications on high-performance highly parallel platforms,<br\/>in collaboration with the Chapel programming language team at Cray,<br\/>Inc. The project addresses several core issues for such applications.<br\/>First, the work is extending Chapel's existing support for<br\/>user-defined irregular data distributions by adding general language<br\/>features for specifying optimized handling of special cases, which are<br\/>usually essential for adequate performance. Second, the project is<br\/>designing and evaluating software transactional memory (STM)<br\/>algorithms that scale to very large scale systems (e.g.,<br\/>distributed-memory clusters), in contrast to previous STM work that<br\/>has focused on smaller-scale (cache coherent) systems. Third, a<br\/>(separately funded) component of the overall research project is<br\/>developing deterministic language mechanisms for parallel computations<br\/>on pointer-based data using a type and effect system for expressing<br\/>parallelism and proving noninterference.<br\/><br\/>If successful, this research will improve ease of programming and<br\/>deliver high performance for a wide range of applications that are<br\/>especially challenging for programmers today, namely, \"irregular\"<br\/>applications. Further, the work aims to achieve two kinds of direct<br\/>technology transfer to industry: contributions to the Chapel language<br\/>and compiler effort at Cray, and contributions to the joint language<br\/>design effort in the DARPA HPCS program. The major research<br\/>artifacts, including the language specification and compiler<br\/>prototype, will be made available as free, open source software for<br\/>the research community to use. The dynamic compiler infrastructure<br\/>for high-performance parallel programs should be a particularly<br\/>valuable tool for further research in this area.","title":"CSR-AES: Language, Compiler and Run-time Support for Irregular Applications in Emerging High-productivity Languages","awardID":"0720772","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["542046"],"PO":["551712"]},"131080":{"abstract":"SING: Toward a Theoretical Foundation of<br\/>Anonymous Wireless Networking<br\/><br\/>Abstract<br\/><br\/>As wireless networking increasingly dominates our means of communication, the need for privacy and security has gained prominence. Wireless networks, owing to the unprotected communication medium, are vulnerable to unauthorized access of networking information. For example, by merely observing transmission times of packets, a passive eavesdropper can decipher source-destination pairs and paths of data flow in a network. Unauthorized retrieval of such information, known as traffic analysis, is a violation of user privacy. It also provides crucial information for the jamming of network traffic and launching of a denial-of-service attack.<br\/><br\/>This research aims to establish an analytical framework for achieving anonymity in wireless networks. The key objectives are to establish a theoretical framework upon which provably anonymous and secure protocols for multiple access communication and anonymous networking can be developed and analyzed. Drawing ideas of anonymous mixing from Internet privacy, timing channel analysis from information theory, and intrusion detection from statistical inference of point processes, countermeasures against passive and active means of compromising anonymity are investigated. Parallel to the well known rate-secrecy trade-off in point-to-point communications, fundamental tradeoffs between anonymity and network performance metrics, such as throughput and delay, are investigated. Scheduling and routing protocols are developed to prevent unauthorized release of networking information to passive and active adversaries.","title":"SING: Toward a Theoretical Foundation of Anonymous Wireless Networking","awardID":"0728872","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["531874"],"PO":["432103"]},"131091":{"abstract":"This research involves the development of statistical theories and methods related to the Generalized Cauchy density (GCD). The developed GCD?based theories and methods will be applied to a suite of contemporary problems not adequately addressed by traditional Generalized Gaussian density (GGD) and currently popular Alpha-Stable density based methods. The GCD combines the advantages of the GGD and Alpha -Stable distributions in that it possesses heavy algebraic tails (like Alpha-Stable distributions) and closed form expressions (like the GGD) across a flexible family of densities. This research thus develops a unified body of GCD?based theories\/methods and applies them to a broad array of contemporary challenging applications dominated by heavy?tailed statistics.<br\/><br\/><br\/>Specifically, the investigators study the followings: (1) Density Fitting and Parameter Estimation ? Optimal methods for GCD fitting and density parameter estimation, and fast, accurate, suboptimal parameter estimation techniques, (2) Robust Detector\/Estimator and Filter Design ? Optimal GCD?based detectors\/estimators\/filters based on statistical criteria, including maximum likelihood (ML), maximum a posterior (MAP), and general Bayesian approaches, (3) Error Norm Development ? Development and analysis of norms that arise naturally from the GCD family, (4) Applications ? The application of developed theory and algorithms to contemporary engineering problems: (a) Communications (powerline communications, atmospheric noise cancellation, robust amplitude\/frequency estimation, and signal\/noise modeling), (b) biomedical signal processing (ECG enhancement, speckle suppression, and protein sequence clustering), (c) networking (transferred and\/or stored file size modeling, load?balancing, scheduling, routing and switching in the Internet), (d) adaptive signal processing (development of robust gradient adaptive algorithms and system identification), and (e) image processing (watermark detection, DCT\/wavelet coefficients modeling and diffusion).","title":"Generalized Cauchy Distribution Theory for Statistical Signal Processing, Communications and Networking Applications","awardID":"0728904","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["550478",348001],"PO":["564898"]},"133071":{"abstract":"This project is aimed at creating design schemas principles for knowledge creation and communication using parameterized narratives. The desired result are design schemas in the form of (1) prototypes for authoring environments that will put the procedural, simulation-building power of the computer in the hands of domain experts and writers allowing them to create multisequential and multiform scenarios without requiring them to program; (2) prototypes of presentation environments for users of such scenarios that will foreground the contrasts between instantiations, providing juxtapositions that will clarify complex causal chains and interrelationships in multi-causal scenarios; as well as (3) a summary set of design principles illustrated by appropriate schematic mockups that will contextualize these prototypes and focus a larger conversation on how to use narrative abstraction and story-related game mechanics to support the understanding of complex systems.","title":"SGER: SNAPS: Schemas for Narrative Authoring and Presentation Systems","awardID":"0739497","effectiveDate":"2007-09-15","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["231681"],"PO":["433760"]},"127450":{"abstract":"There has been successful research on establishing metric representations of the environment required together with motion planning for any navigation task. Such metric maps require though excessive amounts of storage to memorize the robots' trajectories and all landmark positions. On the other hand, animals have excellent navigation capabilities based on visual sensing and simple path integration.<br\/><br\/>The technical approach can be summarized in the modeling of places and the map creation. An abstraction hierarchy is introduced for the visual modeling of places with the layers of feature landmarks, salient regions, and objects. A novel image similarity score will be used for tracking as well as loop closing and is robust to perceptual aliasing. Objects are learned from training sets of appearances of salient landmarks and in the highest abstraction level places are labeled depending on their object content and the constellation of objects in space. Topological maps are made of nodes labeled with place labels and associated with an action to neighboring nodes obtained from the relative pose between the two places. Learning of the maps will happen in the space of all possible topologies of place sets. A collaboration with biologists will try to cross-validate hypotheses based on visual inputs obtained from the animal's viewpoint.","title":"RI: Collaborative Research: Bio-inspired Navigation","awardID":"0713260","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["549664"],"PO":["564316"]},"127461":{"abstract":"The essence of music is structure, or as the composer Edgar Varese put it, music is \"organized sound.\" For centuries, people have responded to their enjoyment of music by studying and describing that structure, yet there is still no satisfactory description of what music is, much less how or why it works. Furthermore, there is very little work that can truly be said to start from the minimum of assumptions and attempt to define music simply in terms of whatever statistical regularities actually occur in a large body of real, polyphonic music. The PI's goal in this project is to begin to construct such a definition. To this end he will develop algorithms that describe and explain musical structure using automatic signal analysis and machine learning. These algorithms will lay the foundation for software that mines a database of many thousands of examples of music audio for recurrent structures and patterns at successively higher levels. (The PI argues that in order to work with very large databases it is critical to start from audio, rather than notated forms, since this is the only 'canonical form' in which all music exists; by the same token, audio is the representation closest to the original music.) The software will use these detected structures to create rich but compact descriptions of the realizations of music, which complement and extend human musicological insights. Such software will enable the implementation of tools that revolutionize the way listeners find and organize music, by empowering them to describe their interests in terms of objective, yet relevant, properties of the music audio itself. For similar reasons, the new algorithms may lead to a fully automated system for music recommendation based on analysis of a listener's existing collection in terms of high-level attributes identified in the analysis, as well as to advances in other music-processing applications such as automatic accompaniment and computer-aided composition.<br\/><br\/>Broader Impacts: Because music is important in the lives of so many people, new technologies that can afford insight into the structure and 'function' of music have very broad potential impact. Project outcomes will likely generalize to enable the discovery of high-level, hierarchic structure from large databases in other, analogous domains such as multimedia content analysis and natural language processing, and they ultimately may also cast light on the techniques used to represent complex information within the brain. A significant aspect of the project is a plan for outreach to school-age students tied in to an existing summer school and public school program operated by Columbia University. The strong appeal of music to all people, but particularly to school-age students, presents an opportunity to broaden interest in science and technology by developing and deploying a set of classroom materials and other tools, which middle- and high-school students and teachers can use to analyze and modify the music of their own choice.","title":"HCC: Data-Driven Music Audio Understanding","awardID":"0713334","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["554699",338021],"PO":["565227"]},"125162":{"abstract":"Modern microprocessors contain multiple computing elements (cores) that can perform different computations in parallel. Such multi-core processors, however, must share certain hardware resources (e.g., caches, bus bandwidth, power). Current multi-core implementations do not provide any explicit management of the shared resources, thereby resulting in \"free-for-all\" behaviors where some cores can consume a large and unfair portion of the shared resources. Such an undisciplined approach can lead to severe performance degradations for the other cores, and even lower overall\/aggregate system performance. This project proposes to adapt ideas and techniques from online\/Internet auctions to manage shared resources in multi-core processors. The central idea is that by providing each core with a limited budget, all cores will \"play nicely\" since no single core will be able to take control of an unfair portion of the shared resources. Furthermore, each core can intelligently bid on the resources that it will benefit the most from, leading to improved per-core and overall system performance. An additional advantage of leveraging existing online auction algorithms is that significant analysis has already gone into proving various properties of these algorithms, thereby providing a strong theoretical foundation for the proposed multi-core resource management techniques.","title":"Economic Mechanisms for Dynamic Resource Patitioning in Multi-Core Processors","awardID":"0702275","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":[332127],"PO":["559883"]},"129530":{"abstract":"The performance of civil infrastructures plays an important role in maintaining the<br\/>quality of life of the U.S. citizens as well as in the nation's defense systems. The project attacks several<br\/>critical issues involved in the new generation of smart civil infrastructure system with built-in sensor<br\/>network. Performance assessment of civil infrastructure is usually a long-term task (i.e. several years) the<br\/>power supply for the sensor network becomes a problem, especially for the embedded sensors in<br\/>structures. The first focus is to provide a reliable energy harvesting method for the sensors and a power<br\/>management plan for the sensor network. For long-term performance assessment, processing the large<br\/>amount of data obtained from the sensor network is a difficult and important task, the second focus is how<br\/>to configure the sensor network and assemble the measured data in a more meaningful way in order to use<br\/>the available information to predict future structural performance. To this end, this project is to develop<br\/>an integrated Power Aware Sensor-Simulation Network system for long-term performance<br\/>assessment of concrete infrastructures. The system consists of three subsystems<br\/>including an energy harvesting and power management system for the sensors, a combined sensor-based<br\/>numerical simulation system, and a massively parallel computing system for the numerical calculations.<br\/>Built-in sensors have found their applications not only in civil, and aerospace structures, but<br\/>also in mechanical engineering and medical devices such as artificial hearts. Therefore, the<br\/>research will have a great impact in many areas of science and technologies.","title":"NOSS: An Integrated Power Aware Sensor-Simulation Network System for Long-Term Performance Assessment of Concrete Infrastructures","awardID":"0722023","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["517075","398834",343227],"PO":["564993"]},"129772":{"abstract":"Proposal #: CNS 07-22890<br\/>PI(s): King III, B. Alex<br\/> Taylor, Jamie R.<br\/>Institution: Austin Peay State University <br\/> Clarksville, TN 37044-0001<br\/>Title: MRI\/Acq.: Distributed Computing Cluster for Multidisciplinary Research, Rsch Training, and Educ<br\/><br\/>Project Proposed:<br\/>This project, acquiring a versatile high-performance computing cluster that will enable multi-disciplinary research, services physics and astronomy, chemistry, computer science and information technology, and mathematics. The requested equipment consists of a computer cluster (16 nodes, each two dual-core processors), three control nodes (1 master and two I\/O nodes), a RAID storage subsystem, a tape drive, and necessary compilers and computational software. Research projects involve:<br\/>. Data mining of large astronomical databases,<br\/>. Coherent synthesis of high-harmonics,<br\/>. Understanding of noncovalent assembly of macromolecules.<br\/>. Application of parallel techniques to traditional applied mathematical methods, and<br\/>. Tension supported truss systems (tensegrities).<br\/><br\/>Broader Impacts: The instrument creates new opportunities for undergraduate research, contributing to train undergraduates in the use of high-performance cluster technology. Undergraduate capstone projects will be directed in Computational and Numerical Methods and Computer Science. The facility might enable students to perform graduate studies in applied sciences.","title":"MRI: Acquisition of a Distributed Computing Cluster for Multidisciplinary Research, Research Training, and Education at Austin Peay State University","awardID":"0722890","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0302","name":"Division of ASTRONOMICAL SCIENCES","abbr":"AST"},"pgm":{"id":"1216","name":"GALACTIC ASTRONOMY PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"1765","name":"CONDENSED MATTER & MAT THEORY"}}],"PIcoPI":["347573","347574"],"PO":["557609"]},"127473":{"abstract":"Proposal Number: IIS-0713409<br\/>Proposal Title: \"Staged Database Systems: Maximizing Locality through Service-based Data Management\"<br\/>PI: Anastasia Ailamaki<br\/>Affiliation: <br\/>Computer Science Department<br\/>School of Computer Science<br\/>Carnegie Mellon University<br\/><br\/><br\/>Database software architectures have traditionally followed the client-server paradigm, where requests are treated as processes and contect-switching is performed by the operating system. Unfortunately, microarchitectural design moves towards the opposite direction: Memory hierarchies are becoming deeper, requiring better software locality, and chip multiprocessors enable unprecedented degrees of parallelism, unacheavable by current database systems.<br\/><br\/>The proposal details the design, implementation, and evaluation of a Staged Database System, which uses the Service-Oriented Architectures<br\/>(SOA) paradigm for high-performance relational Database Management Systems (DBMS). The new system will (a) alleviate the mismatch between DBMS software behavior and modern CPU architectural features, (b) provide a rich infrastructure for optimizing resource scheduling, and<br\/>(c) improve scalability and configurability of data management on multiprocessors and networks of workstations.<br\/><br\/>The intellectual merit of the project is in that (a) it promotes interdisciplinary work across several areas (databases, compilers, computer architecture, performance modeling), and (b) that the scientific papers stemming from the results will likely influence the way people think about building large systems (not only database systems). Such a system will have direct societal impact to the millions of people who are now using database backends directly or indirectly through web applications and services. Finally, the project will have significant educational impact, as it will serve as a vehicle to (a) train graduate students to building systems and to experiment both in a real system testbed and in simulation, (b) develop new interdisciplinary courses, and (c) disseminate the research results through talks, seminars, and publications.<br\/><br\/>Finally, the PI has long demonstrated her dedication to training students from underrepresented groups. She has been offering seminar talks, organized panels, and regularly attended the Grace Hopper Conference for Women in Computing. She has also had numerous female PhD and intern students, and she intends to continue devoting resources to attracting women to computer systems research.<br\/><br\/>Further information concerning the project can be found at the web page:<br\/>http:\/\/www.cs.cmu.edu\/~StagedDB\/","title":"III-COR: Staged Database Systems: Maximizing Locality through Service-based Data Management","awardID":"0713409","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["485986","342331"],"PO":["469867"]},"128210":{"abstract":"Malicious activity on the Internet is a significant threat to both individuals and institutions. Over the past few years, network honeypots have emerged as an important tool for measuring and understanding the details of cyber attacks. The objective of the proposed research is to stimulate the development of next generation Internet security systems and forensic tools based on automated, indepth analysis of malicious activity and malicious software (malware) observed in network honeypots. The research program to achieve these capabilities will address four critical challenges: (1) efficient malware collection, (2) identification of evasion and obfuscation techniques embedded in the malware, (3) full understanding of malware intent and logic, and (4) the full exercise of malware functionality during runtime execution. The technical approach to address these challenges, which is referred to as Informed Malware Execution (IME), is comprehensive in its use of techniques drawn from a variety of disciplines including network security, forensic analysis, static and dynamic program analysis, and binary instrumentation. The broader impacts of this project are that it will enable a deep understanding of malware logic and execution, and lead to more effective, generalized (non-instance-specific) network security. The expected results of this work include research papers describing new malware analysis methods, prototype software for malware collection and analysis, and datasets collected from network honeypots. The project also includes education and outreach activities that will develop course materials on practical aspects of network security, and provide training for graduate students involved in all aspects of the research.","title":"Collaborative Research: CT-T: Logic and Data Flow Extraction for Live and Informed Malware Execution","awardID":"0716460","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["402290","459025"],"PO":["565239"]},"129541":{"abstract":"This project aim at defining, optimizing and implementing a novel underwater sensor network architecture, called SEA-Swarm (Sensor Equipped Aquatic Swarm), that consists of a large number of low cost underwater sensors that operate and move as a group (swarm) with water current and dispersion. The proposed SEA-Swarm architecture will enable a whole new era of observations, monitoring and explorations in the aqueous environment. Such tool will be by its very essence multidisciplinary and is expected to foster a broad collaboration between researchers in networking and communications and other scientific communities, such as environmental sciences, marine biology and coastal surveillance and security. A number of technological challenges shall be addressed by this project, along with the related fundamental research aspects: a new generation of underwater acoustic communications modems is to be designed based on OFDM, achieving unprecedented data rates thanks to Doppler compensation and MIMO space-time signal processing techniques. Cooperative communication protocols, driven by the information theoretic relay channel, are synergistically optimized jointly with a new energy efficient geo-routing algorithm. In essence, all the nodes in a virtual pipe from source to destination cooperate to reliably deliver the message. For reliable data transport, network coding for erasure correction and packet combining for energy efficiency is investigated. Finally, efficient localization schemes based on underwater GPS and nodes with dedicated data-collection functions (data mules) are advocated in order to tackle the mobility and the topology randomness problems due to the swarm nature of the network. The cross-layer design involving the above aspects is validated through a dedicated simulation environment (Aqua-Sim). A cost-effective over-the-water acoustic communication testbed shall be developed by USC in order to provide proof of concept of the basic network algorithms. Finally, an underwater testbed proof of concept is planned in synergy with other existing projects such as MyPond and MySound at U-Conn, and at the UCLA Marina Aquatic Center. The theoretical and experimental work at all three collaborating teams shall involve graduate students and also expose undergraduate students to state-of-the art communication engineering projects, developed in the framework of the above mentioned testbeds.","title":"Collaborative Research NeTS-NOSS: SEA-Swarm: A Rapidly Deployable Underwater Sensor Network","awardID":"0722073","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["508212"],"PO":["557315"]},"129783":{"abstract":"Proposal #: CNS 07-22936<br\/>PI(s): Livny, Miron<br\/> Dasu, Sridhara R.; De Pablo, Juan J.; DeLuca, Paul M.; Schwartz, David C<br\/>Institution: University of Wisconsin - Madison<br\/> Madison, WI 53715-1218<br\/>Title: MRI\/Acq.: Acq of the Second Phase of the Grid Laboratory of Wisconsin (Glow-II)<br\/><br\/>Project Proposed:<br\/>This project, acquiring the hardware resources needed to refresh and expand the computing power of GLOW, expands the reach, scope, and capacity of the institutional grid while conducting a broad and compute intensive research agenda. GLOW-II spans ten domains--Biostatistics and Medical Informatics, Chemical and Biological Engineering, Chemistry, Computer Sciences, Engineering Physics, Genomics, Genetics, Materials Science and Engineering, Medical Physics, Physics and Astrophysics--each with significant computational needs. The laboratory, consisting of eight physical sites, provides the necessary hardware, software, and support infrastructure for the development and experimental evaluation of grid-aware scientific applications. Within GLOW-II new HTC technologies will be harnessed and new organizational structures will be established to meet the computational needs of leading-edge research in the biological and physical sciences. GLOW-II enables cross-fertilization of active research pursuits within the CS department, particularly developers of distributed technologies and tools, providing the CS group with a larger and diverse real-life distributed environment that is an integral part of the national cyberinfrastructure. The technologies, applications, and organizational structures of this computing environment can provide the power to transform scientific processes and methodologies. The success of GLOW and the underlying High Throughput Computing (HTC) technologies that power it have inspired and influenced many campus grids helping shape the campus-grid centric vision of the Open Science Grid (OSG).<br\/><br\/>Broader Impacts: GLOW-II interdisciplinary impacts span across all ranks of the scientific community. Computing throughput, and consequently the size and complexity of the problems studied, will be increased. The infrastructure enables development of new IT technologies in response to explicit needs and their evaluation in real-life settings. Changing the national cyberinfrastructure landscape and pioneering new scientific computing paradigms, new domains will be engaged and students and system administrators will be trained. Outreach, education, and training programs will ensure inclusion of students, educators, and next generation researchers.","title":"MRI: Acquisition of the Second Phase of the Grid Laboratory of Wisconsin (GLOW-II)","awardID":"0722936","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}}],"PIcoPI":["560467","486198","399913","542480","479847"],"PO":["557609"]},"129431":{"abstract":"The eFIT (Enabling Future Internet innovations through Transit wire) project aims to enable future innovations by ensuring strong universal connectivity at the architectural level. Innovations are enabled by the abundant and affordable computing resources provided by Moore's Law, and universal connectivity provided by the Internet. Computing resources are likely to become more plentiful and affordable, but the universal connectivity provided by the Internet is facing major challenges, as demonstrated by the prevalent use of network address translation (NAT) and accelerated growth of the global routing table. The current Internet architecture provides end-to-end connectivity by putting both user networks and Internet service providers (ISPs) in the same address and routing spaces. User networks and ISPs have different purposes, distinct characteristics, and are moving in almost opposite technological directions. However the inter-dependency between network users and ISPs imposed by the existing architecture creates a major roadblock to future Internet innovations.<br\/><br\/>When a system grows larger in size by orders of magnitude, a change in form becomes necessary. The eFIT design enables innovation by first focusing on universal connectivity. eFIT places user networks and provider networks in different address and routing spaces, removing the inter-dependency between the two worlds. With eFIT, users can simply treat the Internet transit core as a transit wire with strong universal connectivity, while providers are insulated from the various problems caused by explosive growth in user networks. Therefore both users and providers will be able to innovate freely on their own without any architectural constraints.<br\/><br\/>Broader Impact: This new architecture design will have a broad impact on the research community, service providers, and Internet users. eFIT enables graduate students to explore new directions for fundamental problems such as security. Even more broadly, it will liberate Internet users from the current architectural constraints and encourage a new wave of application innovations.","title":"NeTS-FIND: Collaborative Research: Enabling Future Internet innovations through Transit wire (eFIT)","awardID":"0721645","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["545336"],"PO":["565090"]},"126285":{"abstract":"0707437<br\/><br\/>III-COR: Infrastructure for Development and Testing of Next-Generation, Data-Centric Cluster Management Software<br\/><br\/>Jeffrey F. Naughton<br\/><br\/>This proposal funds the purchase of a cluster of processors on which to develop and test cluster management software that exploits database system technology to improve system manageability, usability, and scalability. One particularly important problem facing cluster management systems is the vast amounts of data such systems must handle - both system data and user data. The central goal of the proposed work is the invention, implementation, and evaluation of data-centric (rather than process-centric) cluster management techniques.<br\/><br\/>This project is intended to have an impact on users running their computations on the cluster managed by the prototype system, to have an impact on the design of future computational cluster management systems, and ultimately to contribute to the increased efficiency (both computational efficiency deriving from better use of hardware and human efficiency deriving from an easier-to-use system) provided to the users of future cluster computing systems.","title":"CRI: III-COR: Infrastructure for Development and Testing of Next-Generation, Data-Centric Cluster Management Software","awardID":"0707437","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["499351",335067,"451905"],"PO":["565136"]},"129200":{"abstract":"Exponential increases in transistor densities at each new technology generation have allowed us to build chips with greatly enhanced capabilities and functionality. The last twenty years have witnessed the introduction and adoption of numerous architectural advances at the processor level, as computer architects have successfully translated increases in transistor budgets to performance. Unfortunately, effective hardware policies for managing and controlling these complex artifacts have not advanced commensurately. Most policies are ad hoc at best, and generally incapable of providing important functionalities like anticipating the long-term consequences of decisions (planning), or generalizing from experience obtained through decisions executed in the past to act successfully in new situations (learning).<br\/><br\/>At the same time, the artificial intelligence and machine learning communities have made tremendous strides in designing computer programs and algorithms that learn about their environment and improve automatically with experience. The proposed inter-disciplinary work will develop methodologies based on such a technology to design efficient, adaptable, and self-optimizing on-chip hardware policies. The project will concentrate on chip multiprocessors, in which opportunities for hardware management promise to be numerous and challenging. If successful, this approach may set off a change in the way computer architects think about and conduct research on computer architecture design.<br\/><br\/>The project will apply machine learning technology in two ways: (1) tools for the systematic design of optimized management policies that can then be installed in hardware (e.g., ROM-based circuits); and (2) self-optimizing hardware agents that implement efficient policies, can learn from their environment, and improve automatically with experience.","title":"CSR---SMA: Computer Architecture Optimization: A Machine Learning Approach","awardID":"0720773","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[342321,"499395"],"PO":["565255"]},"129211":{"abstract":"Adaptive Real-Time Scheduling for Grid Computing<br\/><br\/>Automated performance control and resource management is crucial for the successful continued evolution of grid computing. An important first step is new scheduling algorithms and analysis techniques that provide high performance with assured quality-of-service (QoS), while also simplifying the management of grid resources. The long-term goal of this research is to investigate and develop adaptive real-time scheduling theory and technology for grid computing. Specifically, this project is developing adaptive real-time scheduling theory and technology for divisible grid applications executing in heterogeneous clusters. This project has three aims: (1) To establish real-time theoretical foundations to guide the design of efficient divisible load scheduling algorithms. The application of divisible load theory, design of scheduling algorithms and schedulability analysis techniques are investigated. 2) To develop scheduling theory and tools in heterogeneous clusters that support resource reservations for real-time grid computing. and 3) To design real-time cluster-based scheduling algorithms that are adaptive and robust to system uncertainties. The integration of adaptive feedback control theory and real-time divisible load scheduling are investigated. Research results will be disseminated to the research community via published papers, public domain tools, and participation in conferences. Once the tools are mature and robust, they will be made available to the Open Science Grid community.","title":"CSR-AES: Adaptive Real-Time Scheduling for Grid Computing","awardID":"0720810","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["451312","486378","77700"],"PO":["493916"]},"129332":{"abstract":"A global regulatory effort is underway to allow secondary spectrum trading by license holders and flexible access by end-users. Preliminary evidence in early incarnations of secondary spectrum markets indicates a sophisticated market structure and suggests that realizing full potential of deregulated spectrum entails overcoming fundamental technical and economic challenges.<br\/><br\/>This project has the following research objectives: (i) Development of pricing strategies that capture network-wide effects of interference and that render secondary spectrum markets profitable for license holders; (ii) Design of market rules that facilitate new entrants and improve end-user perception in economic and performance terms; (iii) Development of resource discovery and monitoring algorithms that allow market participants to efficiently and securely utilize network services. These objectives are pursued in an integrated analytical framework that includes techniques of dynamic stochastic optimization, game theory, incentive engineering and tractable teletraffic modeling of large wireless networks.<br\/><br\/>This project promotes healthy deregulation of the wireless communication sector and shows promise for societal impact in view of the attendant economic activity and effective utilization of an important national resource. The educational component involves curriculum innovation aimed at facilitating the interaction between regulatory and technical communities, extracurricular activities in amateur radio, and outreach to members of minority and under-represented groups.","title":"Collaborative Research: WN: Management of Secondary Markets in Deregulated Wireless Networks","awardID":"0721308","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["517945"],"PO":["564777"]},"129574":{"abstract":"The goal of this project is to develop a model for a campus wide computation initiative that will transform undergraduate computing education in the institution and academic environment. The activities that make up this model will engage in computation students and faculty who are outside the typical computing community. The transformation is achieved through the involvement of (1) faculty leaders inside the computing community in teaching and research collaborations with faculty and students from outside the computing community, and (2) faculty and industrial partners who develop programs that highlight the increasingly important role of computation in their respective industries. The two colleges have developed and will implement a coordinated model for a computation initiative that will (1) attract non-traditional CS students to take introductory computing courses (not computer literacy courses) and (2) encourage faculty from non-CS departments to develop discipline specific courses that build on the introductory computation courses and incorporate higher level computation skills. The model is based on the framework of a curriculum in computational methods that includes a core of courses that addresses common applications of computation across disciplines, followed by additional discipline specific courses within other departments that focus on computation activities in those fields. The strategies that will be developed and implemented for transforming undergraduate computing education, specifically fostering change in the attitudes of students and faculty and increasing the visibility of computation, will serve as a blueprint for implementing similar changes at other institutions. Dissemination of the model for a campus wide computation initiative, along with strategies for implementation, will make it possible for the changes to be replicated at other institutions. This will ultimately result in increased competence and familiarity with computing skills amongst all graduates, particularly in the sciences, and a more visible role and presence for computing in the academy.","title":"CPATH EAE: Campus Wide Computation Initiative - A New Model for Computing Education","awardID":"0722203","effectiveDate":"2007-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["543064"],"PO":["565136"]},"129101":{"abstract":"The on-going shift in processor technology to favor multicore<br\/>multiprocessors is opening new opportunities for software speculation,<br\/>where program code is speculatively executed to improve speed at the<br\/>cost of having to monitor for errors and the risk of having to<br\/>re-execute code when an error happens.<br\/><br\/>This project develops a new, behavior-based approach, which allows a<br\/>user or a profiling tool to parallelize or optimize a program based on<br\/>partial information about the program code and the input. It mainly<br\/>develops two programming techniques: Behavior-oriented parallelization<br\/>(BOP), which speculatively executes possibly parallel regions, and<br\/>Fast track, which uses software speculation to support the use of<br\/>unsafely optimized code.<br\/><br\/>The exponential increase in microprocessor performance over the past<br\/>30 years has had incalculable impact on science, commerce, government,<br\/>and quality of life. Continuing this revolution through the coming<br\/>decade will depend on a large degree of processor-level parallelism.<br\/>Behavior-based oftware speculation promises to improve the performance<br\/>of existing, sequential software and of new software that reuses an<br\/>existing code base. It simplifies parallelization and should thus<br\/>improve the productivity of future software development. The outcome<br\/>of this proposal will be a suite of techniques for general-purpose<br\/>software, and new tools that will be transitioned to industrial<br\/>partners wherever possible, and will be used in both undergraduate and<br\/>graduate courses.","title":"CSR-AES: Collaborative Research: Behavior-Based Speculative Parallelization and Optimization on Desktop Multiprocessors","awardID":"0720499","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["551005"],"PO":["493916"]},"129343":{"abstract":"This project studies three fundamental problems to improve the performance of wireless mesh networks. <br\/><br\/>(1) Managing delay and jitter. One fundamental problem affecting the performance of current mesh networks is the hop-by-hop relaying of data, resulting in significant per-hop and per-packet delay and\/or jitter. This project designs a new MAC paradigm and a distributed method of scheduling data transmissions in a path-aware manner, to eliminate per-packet delay and jitter while minimizing per-hop delays. <br\/><br\/>(2) Capacity analysis and utility optimization. As an augmentation to the large amount of simulation studies on multi-channel<br\/>multi-radio mesh networks, this project develops a general theoretical model to analyze both unicast and broadcast capacities of mesh networks, and applies the model to optimally assign channels to maximize capacity, as well as optimizing application-specific utility functions relevant to user-perceived network performance. <br\/><br\/>(3) Channel assignment for dynamic spectrum access mesh networks. Recent advancement in cognitive radio technology and regulatory reform in spectrum policy offer dynamic spectrum access (DSA) capability to mesh networks via providing dynamically available channels. This project adopts a cross-layer and path-centric approach for assigning dynamic channels in<br\/>DSA mesh networks to achieve high spectrum utilization and traffic throughput. <br\/><br\/>Through developing innovative protocols, analysis and optimization models, this project promotes development of high-performance multi-radio, multi-channel, and DSA-capable mesh networks. The research on DSA mesh networks potentially facilitates the communication among different emergency management divisions in disaster rescues operations. This project also benefits the underrepresented minority students through education and research.","title":"NeTS-WN: Collaborative Research: Toward High-Performance Mesh Networks","awardID":"0721361","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["528443"],"PO":["564993"]},"128254":{"abstract":"Recent dramatic drops in the cost of radio Frequency Identification<br\/>(RFID) equipment, along with corresponding increases in performance and attention from the popular media, have ignited wide-spread government and corporate interest in massive RFID deployments.<br\/>Meanwhile, privacy and security concerns began to dominate the public's views. Ubiquitous RFID tagging has enormous potential economic benefits: it will enable new discoveries, business models, and economic activity, as well as improve health care, national security, and the overall quality of life. Opposite these RFID-based capabilities and benefits is the fundamental right to privacy.<br\/>Interestingly, it is possible to simultaneously realize both of these diametrically opposed goals (information transparency vs. individual privacy), but viable solutions are mathematically subtle and technologically complicated.<br\/><br\/>This project will address the fundamental question of how to resolve the inherent tension between the conflicting goals of information ubiquity and privacy, in the context of reliable RFID technology. By drawing upon a rich set of techniques that lie at the confluence of algorithms, mathematics, randomization, cryptography, and VLSI design, this research will develop methodologies that will enable RFID technology to realize its full potential, while still preserving privacy and security. This project will investigate and test new approaches to RFID security, privacy, and reliability, under reasonably general and realistic conditions. The broader impact of this research lies in increasing the trustworthiness and utility of future RFID systems, and exploring their benefits to society, the economy, and national security.","title":"CT-ISG: New Directions in Reliability, Security and Privacy for Radio Frequency Identification (RFID) Systems","awardID":"0716635","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["486396"],"PO":["565239"]},"129233":{"abstract":"The economics of supporting a growing number of Internet-based applications has created a demand for server consolidation, and thus a resurgence of interest in virtualization. Virtualization systems for commodity hardware virtualize processor, memory, and I\/O devices in software. Although this enables these systems to support a wide range of hardware, it also leads to significant overheads.<br\/><br\/>We have developed Concurrent, Direct Network Access (CDNA), a new I\/O virtualization architecture combining software and hardware that reduces the overhead of network virtualization. This architecture provides untrusted virtual machines safe, direct access to the network interface. While CDNA dramatically improves the efficiency of I\/O virtualization, a notable gap between native and virtualized I\/O performance still exists.<br\/><br\/>This project's objective is to eliminate this performance gap without sacrificing the generality and manageability of software-based I\/O virtualization. This leads to three main thrusts. First, we are working to mitigate the remaining overheads of the CDNA I\/O virtualization architecture, which include memory protection and the scheduling of interrupts. Second, we are developing mechanisms to support full virtualization, memory protection using IOMMU hardware, and protected DMA by a conventional NIC. This will improve the generality of the CDNA I\/O virtualization architecture. Finally, we are developing mechanisms to enable migration among systems with and without CDNA and to provide mechanisms for network resource provisioning. This will facilitate system managament for virtualized servers using the CDNA I\/O virtualization architecture. Altogether, this research will make CDNA a complete I\/O virtualization solution that provides efficient, general, and manageable I\/O virtualization.","title":"CSR\/PDOS: Concurrent, Direct Network Access: High-performance, Low-overhead Network I\/O Virtualization","awardID":"0720878","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["551076","551027"],"PO":["535244"]},"129365":{"abstract":"The wireless network of the future is envisioned to be a seamless integration of several existing and emerging wireless networks. A key enabler for this network of the future is the cognitive software defined radio (SDR) which takes advantage of programmable hardware modules to dynamically and adaptively modify the functionality of various radio subsystems. The goal of this research is to facilitate seamless integration of wireless networks where information sent from a source to a destination can traverse multiple links that belong to heterogeneous underlying networks. The design and operation of the resulting hybrid wireless network is determined by three characteristics of future software defined radios: Cognition, Collaboration, and Competition. Research results will demonstrate how inherently competitive SDRs (i) work together to learn about current local network conditions; and (ii) use this information to construct adaptive links and routes across these local networks (and \"non-networks\") so that end-to end quality of service requirements are met. Specific research outcomes will include distributed, collaborative algorithms that aid cognitive SDRs in spectrum sensing and hybrid wireless network formation.<br\/><br\/>This research will impact both commercial and military service providers who wish to extend network capacity and coverage by interconnecting existing and emerging wireless systems. The PIs aim to demonstrate broader impact of hybrid wireless networks by offering short workshops that educate rural Pennsylvania communities on its benefits. Additionally, research results will be disseminated and incorporated into wireless communications and networking courses at the respective institutions.","title":"NeTS-WN: Collaborative Research: Cognition, Collaboration, and Competition in Hybrid Wireless Networks","awardID":"0721433","effectiveDate":"2007-09-01","expirationDate":"2012-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[342763],"PO":["557315"]},"129486":{"abstract":"The goal of this proposal is developing advanced algorithmic theory that will lead to real-life implementation in wireless networks. In particular, we will experiment with some advanced and algorithmic ideas inspired by the past algorithmic work of the PI. <br\/><br\/>We are going to leverage the practical solutions that we used in the Wave Relay system at Johns Hopkins, which combines two new components: the Pulse Protocol for scalability of routing and topology update, and the Medium Time Metric, which is a routing metric tailored for wireless networks. <br\/><br\/>The Pulse protocol has optimized for large scale and mobility and is better scalability properties than AODV, DSR in simulations. In fact, simulations show Pulse protocol to scale for up to 5,000 mobile nodes. It uses a proactively-constructed tree with on-demand shortcuts on that tree. It can be viewed as combination of proactive and reactive methods.<br\/><br\/>The Medium Time Metric exploits the multi-rate capability of modern wireless devices to minimize consumption of the shared wireless medium. This cross layer approach incorporates per-packet feedback from the physical and medium access control layers to dramatically increase efficiency and elasticity of both unicast and multicast routes. It is vastly superior to minimum hop routing metric, and has been shown to outperform other proposed metrics for wireless networks, such as ETX metric.<br\/>However, it is possible to augment the quality of routing using new algorithmic ideas.<br\/><br\/>First direction of improvement is to replace Medium Time Metric with load-based metric, that we call the opportunity cost, which provides incentives to users to avoid congested areas by pricing them higher compared to the un-congested areas. It is possible to prove that this yields near-optimal performance. However, this introduces the danger of oscillations. Our recent theoretical work shows how to overcome this problem in wired networks. Moreover, these methods work for the continuous case rather than for more discrete all-or-nothing setting that is necessary to accomplish QoS requirements.<br\/>We are currently examining appropriate extensions to wireless networks to achieve best cross-layer design incorporating both routing and MAC layers.<br\/><br\/>Another issue that needs to be investigated is feasibility of propagating topology updates thru the network in a proactive manner, as it may make the resulting solution non-scalable. We have significant theoretical accomplishments in the area of scalability of routing that we would like to apply in this setting such as designing the first provably memory-efficient and communication-efficient routing schemes, and peer-to-peer directories for tracking mobile users. We would like to apply these methodologies for improved scalability of routing in wireless networks. Specifically, we would like to extend the Pulse protocol to work with multiple trees and will be studying theoretically justified methods of constructing such trees","title":"NeTS-WN: Agile Wireless Ad Hoc Networks","awardID":"0721875","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["343097","373540"],"PO":["434241"]},"128166":{"abstract":"In biology, a vaccine is a weakened strain of viruses or bacteria which is intentionally injected into the body for the purpose of stimulating antibody production. The immunity generated in this way will protect the body from the same type of viruses in the future. Inspired by this idea, this research aims at developing techniques that automatically generate vaccine exploits to detect and diagnose vulnerabilities inside commodity software, and protect them from potential exploits through vulnerability-specific signatures. An example of such a vaccine is a \"\"weakened\"\" buffer-overflow exploit with its jump address scrambled: it causes an exception to a vulnerable program when attempting to hijack the program's control flow, from which a forensic analysis can uncover the underlying vulnerability.<br\/>The idea of vaccines offers an innovative avenue to address the grave threat posed by software security flaws, which has been fundamentally hampering the progress of the Internet. This project develops vaccine techniques to protect vulnerable software in both reactive and proactive fashions. Reactive vaccines can quickly detect zero-day exploits and generate signatures without reliance on source or binary code. The project focuses on applying the technique to protect Internet services. Proactive vaccines are used for automatically discovering software vulnerabilities from the sources such as software patches and creating tentative remedies. This technique enables timely protection of vulnerable software even before the attacker can figure out an exploit. This research also provides a great opportunity to foster the education missions in the area of Security Informatics.","title":"CT-ISG: Automatic Generation of Vaccine Exploits to Protect Commodity Software","awardID":"0716292","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["486098"],"PO":["561889"]},"129145":{"abstract":"The availability and robustness of the I\/O system is crucial to large-scale applications that generate and analyze terabytes of data. Storage systems are vulnerable to numerous hardware failures (I\/O and metadata server crashes) and contribute to as much as 25% of all system failures. Actually, highly available data storage for high end computing is becoming increasingly more critical as high-end computing systems scale up in size. To achieve high availability storage systems, a challenging issue is to characterize the availability metric in addition to performance of these systems.<br\/><br\/>This research investigates high-availability data and I\/O services and benchmarking. The investigators take an organized approach to developing a benchmarking framework to measure the storage performance in consideration of availability under various faulty conditions. The research involves four tasks: 1) develop faults\/errors model and design fault injection schemes for storage systems; 2) develop an innovative benchmarking framework for high availability distributed storage systems under different faulty conditions; 3) implement an Availability and Performance Evaluation Toolset (APET) to integrate the fault injection and stress testing libraries and capture raw performance of storage systems at block level under various faults; 4) validate the benchmarking framework using APET for block-level storage systems.<br\/> <br\/>This research has direct contributions to understanding highly available data and I\/O services for HEC systems, establishing a general benchmarking framework for characterizing storage systems under faulty conditions, and thus benefiting the society by guiding develop high-availability oriented distributed storage systems which are crucial to many applications.","title":"CSR---PDOS: A Benchmarking Framework for High-Availability Distributed Storage Systems","awardID":"0720617","effectiveDate":"2007-09-01","expirationDate":"2010-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7793","name":"DATA-INTENSIVE COMPUTING"}}],"PIcoPI":["424849","550809"],"PO":["493916"]},"128177":{"abstract":"Collaborative Research: CT-ISG: Secure Capacity of Wireless Networks<br\/><br\/>The last decade has witnessed an amazing growth in wireless communications and networking applications. More and more subscribers are relying solely on their wireless communication and computing devices for communicating sensitive information. Preserving the security of wirelessly transmitted information is becoming ever more challenging, yet essential. This important issue is currently dealt with at the higher layers of the protocol hierarchies, yet the need to deal with it in physical layer is imminent as the security of many cryptographic algorithms is hard to evaluate and has caused disappointment in the past. In addition, there is rising interest in large networks of low-complexity transmitters including sensor nodes and RF-ID tags that may not have room for complicated and computationally intensive cryptographic algorithms.<br\/><br\/>The main design goal up to date, for wireless communications and networking at the lower protocol layers, has been to provide high data rate, reliable communication to as many users as possible, by efficiently dealing with the challenges of the radio channel and sharing limited wireless resources. Capacity maximization oriented research has been agnostic to the security requirements of information transmitted. At the same time, security of the information transmitted has been dealt with at the upper layers of the protocol hierarchy, and has been agnostic to the capacity of the underlying network. This project brings together the two most important issues in wireless network design, i.e., information capacity and information security, exposing the tight coupling between the two, and aims to identify design principles for high-capacity and provably-secure wireless networks.<br\/><br\/>This project takes an information theoretic approach to provide guarantees on information security and information reliability for wireless networks. The research includes the development of a comprehensive wireless network design framework that aims at achieving high capacity and secure transmission for all users. Accounting for the existence of a variety of malicious entities and a variety of levels at which these entities are capable to harm the network, the investigators identify the following fundamental research directions: (i) establishing the secrecy capacity of fundamental building blocks of wireless networks, i.e., the maximum rate of reliable information transmission in the presence of intelligent eavesdroppers; finding ways in which the legitimate system entities, i.e., transmitters and receivers, can cope with the security threats at the physical layer; (ii) identifying the fundamental tradeoffs between user cooperation between friendly nodes and the security and the confidentiality of relayed information; (iii) revisiting the notion of wirelessly transmitting channel state information (CSI) in the presence of security threats; identifying conditions under which this well-accepted notion to improve capacity may create security vulnerabilities, and developing methods to deal with this; (iv) introducing the notion of securing the network by utilizing the degrees of freedom in the communication channel available as a result of employing multiple antennas (MIMO links); (v) identifying the impact of the physical layer on the medium access and networking layers and developing secure cross-layer solutions.<br\/><br\/>The results of this project will help identify fundamental design trade-offs for capacity versus security for a variety of wireless networks, and will provide design principles for future wireless communication systems achieving the secure capacity limits. The project is a collaborative effort between the PI at Penn State and the PI at University of Maryland.","title":"Collaborative Research: CT-ISG: Secure Capacity of Wireless Networks","awardID":"0716325","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550356"],"PO":["565327"]},"129156":{"abstract":"Stream processing is a programming paradigm suitable for the class of data driven applications that must manipulate high-volumes of data in a timely and responsive fashion. Example applications include video processing, digital signal processing, and monitoring of business processes. The appeal of stream programming comes from its conceptual simplicity. A program is a set of independent filters that communicate exclusively by the means of unidirectional data channels. The output behavior of any filter is completely determined by the value on its input channels, thus reducing the chances of data races. Interestingly, the abstractions provided by stream processing languages are surprisingly close to event-driven real-time systems. Previous research has shown that stream programs can be implemented very efficiently on modern multiprocessors. The goal of this project is to integrate stream-based programming with real-time systems. The project extends Java to combine streams with objects and allow programmers to integrate stream computations with traditional object-oriented components in the same Java virtual machine. The work relies on the facilities provided by the Real-time Specification for Java to ensure that streaming codes meet real-time constraints of their target application. The broader impact of this project is to introduce a new programming paradigm that can be used by real-time and traditional developers. The choice of Java is expected to ease adoption, as programmers can use mainstream development environments, libraries and development methodologies for writing stream processing code.","title":"CSR-EHS: High-throughput Real-time Stream Processing in Java","awardID":"0720652","effectiveDate":"2007-09-01","expirationDate":"2012-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["549800"],"PO":["561889"]},"128199":{"abstract":"This project focuses on network control systems for buildings, typically called Building Automation Systems (BASs). BASs are increasingly used for the control of lighting, HVAC (i.e., heating, ventilation, and air conditioning), and (physical) security, in modern \"smart\" buildings and are extending their functionality to include advanced features like resource location and mesh networking. Opening such systems to the enterprise network and Internet entails significant risks for compromise and malicious activities while the benefits offer new capabilities for flexibility, survivability, and affordability. <br\/>Networked computer control systems enhance the convenience and functionality of controlling physical processes. Security of such systems is often by isolating the control network from compromised computers but there are costs to this strategy and this kind of protection is insufficient. Better solutions will depend upon the type of control system and the context of its usage such as for vehicles, power transmission grids and factory automation.<br\/><br\/>This research project begins with an examination of the way in which well-known techniques in computer security can be specialized to improve the connectivity of BASs without exposing them to undue risk. Specifically, the project will develop techniques for perimeter control, privacy and insider threats, and audit and intrusion detection for commercial BASs. The objective of this project is to show that perimeter control for such systems can profitably exploit a tiered system based on servers that divide responsibility between application support and control-system command processing.","title":"CT-ISG: Security for Building Automation Systems","awardID":"0716421","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["553855","432547"],"PO":["497499"]},"129178":{"abstract":"Temporal dependence within the workload of any computing or networking system<br\/>has been widely recognized as a significant factor affecting performance.<br\/>More specifically, burstiness, as a form of temporal dependency, <br\/>is catastrophic for performance. Experiments have shown that burstiness <br\/>in the arrival intensities or service demands in a single server system <br\/>may result in user response times that are slower by several orders <br\/>of magnitude. To this day, no analytic queueing models exist that explicitly <br\/>capture burstiness.<br\/><br\/>The proposed research will provide a formalization of burstiness using <br\/>autocorrelation which characterizes the temporal dependence structure in <br\/>request flows. New analytic models that capture the performance effects of<br\/>autocorrelation in queueing systems will be devised, and based on these, <br\/>new resource allocation and scheduling policies will be developed.","title":"CSR-SMA: Autocorrelated Flows in Systems: Analytic Models and Applications","awardID":"0720699","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["518455","518256"],"PO":["551712"]},"131180":{"abstract":"Sparse decomposition algorithms adaptively expand a signal in terms of an over-complete set of finite-support functions called atoms that comprise a dictionary. These nonlinear algorithms aim to find a representation that is at once sparse, efficient, and robust, as well as informative and malleable. The investigators are modeling the energy content of sparse decompositions for a variety of signals in order to optimize performance. This work will lead to better adaptive atom selection strategies for sparse decompositions, as well as dictionaries that are more coherent to the intrinsic structures of a class of signals. It will result in a way to determine which terms of a sparse representation actually belong to the signal and which are artifacts of the decomposition. This research has implications for applications that rely on representations of waveforms such as geological and biomedical data analyses, content retrieval, source separation, music sound transformation, etc.<br\/><br\/>Sparse representations provide an attractive alternative to standard orthonormal expan-<br\/>sions. One property of some algorithms for sparse representations is the creation of terms that are not physically meaningful, but reflect instead the greediness of the algorithm. The investigators refer to this phenomenon as dark energy because these terms are cancelled in the signal reconstruction. Although previous work addressing these spurious terms has viewed them as a nuisance, there is evidence suggesting that dark energy embodies useful information about the signal and its coherency with the dictionary. It can also provide a better strategy for choosing atoms or learning better ones. The investigators are exploring the nature of dark energy and its significance for the original signal, the dictionary, and the strategies used to generate decompositions.","title":"Optimizing Sparse Adaptive Representations of Signals Using Energy-Based Algorithm Enhancements","awardID":"0729229","effectiveDate":"2007-09-01","expirationDate":"2008-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":[348216,348217],"PO":["564898"]},"131092":{"abstract":"The proliferation of wireless and sensor networks has intensified the need for intelligent design of their infrastructure. For any particular communication burst, it is best to involve only a small collection of nodes and links, in order to reduce interference and to lower node power (battery) demands. However, it is also best to use as short a path between nodes as possible. Simultaneously achieving these (and other) various operational goals in network design requires a deep understanding of what are called ?proximity structures,? mathematical models that encapsulate the relevant geometric and communication relationships in a network. Such understanding leads to network designs and routing algorithms that achieve nearly optimal tradeoffs among the conflicting criteria.<br\/><br\/>This research investigates network topologies and algorithms for wireless ad hoc\/sensor networks, with the goal of constructing and handling dynamic updates of sparse distributed structures that achieve optimum interference, spanner paths between pairs of nodes, low weight (within a constant factor of the weight of a minimum spanning tree) and bounded degree. Efficient local constructions of optimal interference topologies will be integrated with pruning mechanisms to filter out unnecessary edges and with link redistribution methods to reduce the maximum degree at each node. These methods seek to achieve low communication complexity (constant to polylogarithmic number of communication rounds) to be employable in large scale networks. This research work also investigates extensions to the concept of wireless localization motivated by security issues in wireless networks.","title":"RUI: Proximity Structures Motivated by Wireless Networks","awardID":"0728909","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7351","name":"THEORETICAL FOUNDATIONS (TF)"}}],"PIcoPI":["518478"],"PO":["565157"]},"125680":{"abstract":"This is a collaborative research project (0704689: Yiming Yang, Carnegie-Mellon University; 0704628: Daqing He, University of Pittsburgh). Adaptive filtering (AF) is an open challenge in information retrieval, defined as the problem of incrementally learning about the topics of interest from user feedback (relevance judgments of the retrieved documents) over a chronologically processed stream of documents. The goal of this research project is to significantly improve adaptive filtering technologies. The approach consists of: (1) a new framework named the Enriched Vector Space Model (EVSM) that represents multi-type objects (including users, queries, topics, documents, Named Entities and sources of data), records the interactions among objects during the adaptive filtering process, and enables the comparison among objects based on both content similarity and relationship similarity; and (2) a system that bridges adaptive filtering, collaborative filtering, personalized active learning and Generalized Hubs and Authorities for effective learning about evolving interests of users. The experimental research is linked to educational benefits for graduate students via participation in the system implementation, data annotation, empirical evaluations and user studies in this project, as well as through course materials the Principal Investigators teach on the related topics and techniques. The results of this project will provide a significant contribution to the field of information search and to our understanding of how to effectively learn from multiple users, and how to combine multi-aspect user information in a new unified framework, with broad applications in information retrieval (web-based and enterprise search engines, for example) by giving them a major adaptive and personalization dimension.<br\/><br\/>The project Web sites (http:\/\/nyc.lti.cs.cmu.edu\/UserCentricAFCF\/ and http:\/\/amber.sis.pitt.edu\/UserCentricAFCF ) will be used to disseminate resulting publications, open-source code and annotated test data sets.","title":"III-COR: Collaborative Research: User-centric, Adaptive and Collaborative Information Filtering","awardID":"0704689","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["562858"],"PO":["563751"]},"135371":{"abstract":"One of goals in Cyber-Infrastructure project is for people to have ability<br\/>of doing remote data gathering and remote scientific experiments efficiently. This demands high-speed communication networks with mobile connectivity and flexible deployment. The wireless access network on top of the optical core network is an important ideal architecture for such a target. Indeed, the optical network in core provides the efficient high-speed communication with high bandwidth and the wireless network in access provides mobile communication with flexible deployment. The advantage of fiber-optical backbone network<br\/>combined with wireless technology has gained more and more interests in the study of the next generation communication networks. One of important issues is the optimal resource management. The increasing need of mission-critical traffic and real-time traffic from businesses and individuals has made the computer communication network grow very rapidly. Today there are a large amount of network resources and also a large amount of traffic. Therefore, efficient utilization of network resources becomes a very important task, which has impact in survivability, energy efficiency, and quality of service (QoS).<br\/><br\/>We propose an integrated research project that studies various optimization problems on (a) resilience schemes, including protection and restoration <br\/>schemes, for optical wavelength division multiplexing (WDM) networks to survive from failures with efficient utilization of network resource and less service disruption, (b) sensors' active\/sleep schedules for the wireless sensor networks to achieve longer lifetime or energy efficiency, and (c) tradeoff between two layers to achieve multi-layer optimization.","title":"SGER: Optimization Problems in Next Generation Networks","awardID":"0750992","effectiveDate":"2007-09-15","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["505880","450698"],"PO":["381214"]},"134161":{"abstract":"The Global Environment for Network Innovation (GENI) Project Office (GPO) GPO will carry out several planning activities, all aimed at ensuring that the best research and industry viewpoints are consulted and brought to bear in the design process for GENI's optical substrate. These activities include a focused study group activity along with a workshop. We will encourage that the broad optical research and academic community participate in our planning efforts. <br\/><br\/>This work is needed to address some of the capability\/cost\/complexity questions that have arisen recently specific to the optical area. The study group will also identify specific areas that are targets for risk reduction in GENI?s design effort. All the results will culminate in a final report that will flow, together with the existing substrate materials for the other areas, into a substrate working group that the GENI Project Office plans as one of the GENI facility design groups. <br\/><br\/>We plan to work on five specific tasks and workshops in order to further understanding and provide direction for the GENI facility substrate. These activities will focus primarily on the optical-fiber based systems and technologies, but are intended to enhance collaboration between and understanding between the optical layer and the wireless substrate as well as processing and higher layer functions of the GENI facility. Once this work is complete, it will be submitted to the emerging substrate working group, which will be charged with integrating the pieces of the GENI substrate into a cohesive architecture. The proposed activities include group brainstorming and preparation of a series of reports centered on five key topics crucial to the near-term development of the optical substrate architecture. The topics are:<br\/><br\/>- Cross layer research agenda,<br\/>- Photonic integration trends,<br\/>- Commercial roadmap,<br\/>- Optical edge architectures, and<br\/>- Multiple candidate GENI topologies.<br\/><br\/>Providing powerful infrastructure for research, the mission of GENI, and of the GPO, has broad benefits and impacts. This planning activity is expected to increase the future-proofing, relevance and realism of the optical substrate that experimenters will have available from the GENI design, and thus enhance the impact of the infrastructure.","title":"Pre-design Study Group Proposal","awardID":"0745188","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}}],"PIcoPI":["521729"],"PO":["495796"]},"133193":{"abstract":"A great deal of funding and effort has been applied over the last several years to deploy cutting edge networked information technologies to support emergency services at local to national levels. An important and open question is: do such technical systems actually work as promised when they are deployed within real organizations and in real emergency circumstances? This proposal will support a one-day workshop to address this issue. To give a consistent structure to the workshop, a set of cases will be developed to evaluate and characterize several existing systems. Approximately 25 academic experts and emergency services government practitioners will attend. In addition to the cases, a workshop report will be developed and distributed nationally.","title":"Workshop on Networked Disaster Management: Information Technology and Crisis Response","awardID":"0740067","effectiveDate":"2007-09-01","expirationDate":"2008-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[354231,354232],"PO":["371077"]},"135041":{"abstract":"Proposal Number: 0749648<br\/>PI: Nicholas Weaver <br\/>Institution: International Computer Science Institute, University of California Berkeley <br\/><br\/><br\/>Title: SGER: Architecting Effective Computer Security Grand Challenge Competitions<br\/><br\/>Proposal summary: <br\/><br\/>A Grand Challenge Competition (GCC), such as the DARPA robot grand challenge or the Ansari X Prize can energize the community, even those not currently funded, to produce research results that can have a transformative impact. It has been suggested that NSF create a GCC in the area of computer security. Working with NSF and other agencies, the PI identifies some of the difficulties attendant to such a competition on computer security, including the need to ensure the interest of the community, to develop a fair and credible rule set for judging entries, to ensure that any competition both presents an effective public face and will produce useful results.<br\/><br\/>Based on these insights, the PI is developing rules for an initial and scaled-down competition to be held in conjunction with a few universities or at a workshop or conference. If successful, the full GCC would be designed and offered on a large scale. <br\/><br\/>A key issue is the competition example. The PI is designing the competition based on a self-defending network, wherein the competitors would be given a reference system which their automated tools (the defense) must attempt to discover and remove vulnerabilities without human intervention.","title":"SGER: Architecting Effective Computer Security Grand Challenge Competitions","awardID":"0749648","effectiveDate":"2007-09-01","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["525668"],"PO":["529429"]},"125251":{"abstract":"Proposal Number<br\/>CCF-0702680<br\/><br\/>TITLE<br\/>Assertion-based Verification: From Compile-time Checking to Runtime Error Recovery<br\/><br\/>PI<br\/>Sarfraz Khurshid<br\/><br\/>Abstract<br\/>This project investigates assertion-based repair---a novel methodology for enabling software systems to recover from errors before they manifest into failures. Traditional approaches to error recovery use assertion evaluations to detect erroneous states and specialized routines to repair them. Most of these routines are ad hoc, ill-understood, and unable to handle a variety of errors.<br\/><br\/>The key insight of this project is to turn a violated assertion into a repair routine by using the assertion as a basis of performing repair. This project will develop systematic approaches that enable efficient repair using assertions written in common programming languages, such as Java. The repair approaches will be evaluated using a variety of complex data structures.<br\/><br\/>Realization of the proposed methodology enables a unified framework for compile-time checking and runtime error recovery -- two software reliability methodologies that traditionally have deployed very different algorithms. The unification has the potential to significantly increase the quality of software. Any program that is annotated with assertions, which programmers already write comfortably, can be: (1) systematically checked before deployment using existing techniques; and (2) guaranteed to continue to execute without failure, once deployed, using the proposed methodology.","title":"Assertion-based Verification: From Compile-time Checking to Runtime Error Recovery","awardID":"0702680","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["550525"],"PO":["564388"]},"129981":{"abstract":"The 2007 UW Seattle Innovation Symposium is the third in a series launched in<br\/>2005. The series seeks (1) to build and maintain a network of researchers who advance the body of knowledge on ?sustainable innovation,? and (2) to create artifacts such as case studies, published papers, and Educational TV programs to share research on sustainable innovation as widely as possible with other researchers, company innovators, and, through Public Television, the general public. The UW Seattle Innovation Symposium continues to build a critical<br\/>mass of leading researchers (academics, artists, PhD students studying innovation, and company<br\/>innovators\/entrepreneurs) to: (1) share intellectual assets and experiences that identify the innovations and innovation practices with potential to create new products and services, and (2) explore organizational structures and practices that will quickly create effective levels of ?sustainable innovation? in economics. The ongoing symposium series will create a multi-disciplined network of academic and company innovators that can continue to work collaboratively on the myriad individual research projects required to extend our knowledge base on innovation, and shorten the time that it takes for innovations in particular companies to make their positive impact on the economy at large. SIS07 will also begin to move its attention outward from individual businesses to larger, global concerns. Situations like global warming and the coming end of extraction industries will require, not just ingenious stop-gaps<br\/>but complete reconceivings of fundamental aspects of society. The multidisciplinary meeting engages senior researchers, corporate leaders and students to produce new insights.","title":"Seattle Innovation Symposium 2007","awardID":"0723914","effectiveDate":"2007-09-15","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[344919,344920,"559720",344922,"530092"],"PO":["565136"]},"127451":{"abstract":"The field of natural language processing (NLP) has, to date, largely focused its efforts on technology for English, even though it is a typological outlier and the majority of the world's people do not speak it. This project aims to develop statistical natural language analysis tools to disambiguate the morphological and syntactic structure of non-English text. Specifically, the objective of the pilot study is to design, train, implement, and disseminate statistical morpho-syntactic parsing models for Arabic and Hebrew. This project starts with a straightforward formalism (statistical head automaton grammars) and makes use of novel discriminative learning methods to build models that can be easily ported to new datasets. While previous work has simplified the problem by assuming perfect morphological disambiguation prior to parsing, for most languages, accurate morphological disambiguation is not yet available; this project aims to integrate morphological disambiguation into the parsing algorithm for better accuracy on both tasks. Impact: This project will improve global access to information by directly advancing core language processing technology in languages spoken by more than half a billion people and - because of the language-portability principle - by facilitating future work on many more languages. It is expected that this project will improve the state-of-the-art in parsing accuracy for the languages under consideration, and the models and algorithms developed will be made freely available for research purposes. These tools are expected to aid researchers working on applied technologies such as machine translation and multilingual information extraction.","title":"RI: Parsing Models and Algorithms for Morphologically Rich Languages","awardID":"0713265","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["563246"],"PO":["565215"]},"125031":{"abstract":"This award supports the development of software infrastructure for large scale simulations of gravitational wave sources (numerical relativity) through a collaboration among researchers at Louisiana State University, Pennsylvania State University, and Rochester Institute of Technology. Recent breakthroughs have provided the numerical relativity community with the basic techniques in to evolve binary black holes for multiple orbits, including the merger and final black hole ring-down phases. Information from these computer simulations have the potential both to enhance the likelihood that ground-based and space-based gravitational wave detectors will recognize these gravitational wave signals from these exotic events and to improve the ability to determine the properties of these systems if signals are detected. The infrastructure to be developed, called XiRel, will build upon and integrate several well developed and widely used computational infrastructures and emerging standards, including Cactus and Carpet. The initial and primary focus of this project is the development of a highly scalable, efficient and accurate adaptive mesh refinement layer based on the existing Carpet driver, which will be fully integrated and supported in Cactus and optimized for numerical relativity. This project will be driven by the scientific goal to perform accurate simulations of black hole binaries with larger initial separations than currently possible, with un-equal masses and unequal spins, and providing reliable physical results critical for gravitational wave astronomy and astrophysics. This award is supported by the Division of Physics in the Mathematical and Physical Sciences Directorate and by the Division of Computing and Communication Foundations in the Computer and Information Science and Engineering Directorate.","title":"Collaborative Research: XiRel, A Next Generation Infrastructure for Numerical Relativity","awardID":"0701566","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0301","name":"Division of PHYSICS","abbr":"PHY"},"pgm":{"id":"7244","name":"COMPUTATIONAL PHYSICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["496127","515500","345581"],"PO":["467733"]},"128200":{"abstract":"Title: Collaborative Research: CT-ISG: Accurate Sampling of the Internet<br\/><br\/>for Effective Anomaly Detection<br\/><br\/><br\/><br\/>Abstract:<br\/><br\/><br\/><br\/>Sampled traffic data has been increasingly used as input for anomaly<br\/><br\/>detection systems, as the high link speeds make it impossible to<br\/><br\/>examine each and every packet. This raises an important question of<br\/><br\/>whether sampling has a (negative) impact on the accuracy\/effectiveness<br\/><br\/>of anomaly detection, and if so how to mitigate this effect.<br\/><br\/><br\/><br\/>Intellectual Merit: This project systematically studies the question<br\/><br\/>mentioned above from the following three angles. First, we will<br\/><br\/>identify traffic features that are critical for a wide range of<br\/><br\/>anomaly detection schemes and quantify how much they are distorted by<br\/><br\/>various sampling schemes. Second, we will design new sampling or<br\/><br\/>measurement techniques that preserve enough accuracy to support<br\/><br\/>effective anomaly detection, while being cost-effective and<br\/><br\/>light-weight. Third, we will study how to correlate the NetFlow<br\/><br\/>samples obtained at the edge routers with the information-rich data<br\/><br\/>generated using existing data streaming algorithms, for much better<br\/><br\/>anomaly detection than pure sampling. The new scientific knowledge<br\/><br\/>learned through this research will provide us with much better<br\/><br\/>technologies to monitor large high-speed networks for anomalous<br\/><br\/>behaviors.<br\/><br\/><br\/><br\/>Broader impact: The results will be broadly disseminated through<br\/><br\/>publications, invited talks and tutorials, and open-sourcing of<br\/><br\/>software developed for this project. The PIs' collaboration with<br\/><br\/>tier-1 ISP's will facilitate the transfer of technology from research<br\/><br\/>environment to actual managing of production networks. Research<br\/><br\/>results will be incorporated into information security curriculum.<br\/><br\/>Both PIs have been actively engaging under-represented groups in<br\/><br\/>research and higher education and will continue and expand these<br\/><br\/>efforts.","title":"Collaborative Research: CT-ISG: Accurate Sampling of the Internet for Effective Anomaly Detection","awardID":"0716423","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["349186"],"PO":["529429"]},"129531":{"abstract":"Real-world security policies invariably involve questions of ``who'' and ``what''--who are the principals, what data are they seeking to access, and so forth. By contrast, the present-day Internet architecture concerns itself primarily with issues of ``how'' and ``where''-- what are the protocols by which a data item is delivered and to which topological endpoints. This inherent dissonance of purpose makes Internet security a bolt-on affair---with abstract access control policies pushed off to be implemented by particular applications or mapped onto the poor approximations provided by network-level abstractions (e.g., network firewalls). Moreover, these imperfect mechanisms are themselves attacked with impunity since today's Internet architecture provides a functional anonymity that insulates attackers from any meaningful liability.<br\/><br\/>This project is developing two key architectural capabilities--host attribution (which physical machine sent a packet) and data provenance (what is the ``origin'' of the data contained within a packet)--to enable the direct expression of a wide-range of security policies. Moreover, these properties are being implemented in a fashion that mandates their use (in a strong sense) by the network, but manages to preserve end-user privacy. The PIs are focusing on two key applications in this work: forensic trace-back and attribution for the purpose of attack deterrence, and defensive data-exfiltration to place precise controls over what kinds of data may move across a network.<br\/><br\/>Broader Impacts: This research is developing key architectural components to improve the level of security and assurance available to network services. In addition, the PIs are initiating a dialogue among both researchers and network operators about critical policy aspects of network security. In particular, information about the sources of both normal and attack traffic that must be safeguarded according to some policy.","title":"Collaborative Research: NeTS-FIND: Privacy Preserving Attribution & Provenance","awardID":"0722031","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["485593","525660","525661","548363"],"PO":["565090"]},"129542":{"abstract":"Recent Internet expansion, at least in terms of geographical coverage, has largely occurred using wireless technology. The goal of this research grant is to enable the deployment of service-capable and responsive wireless-based networks through real-time network diagnosis and dynamic adaptation. <br\/><br\/>Only through an integration of real-time measurement and analysis (localized, autonomous adaptation by network devices, and management though visualization and interactive analysis) can wireless networks achieve long-term utility and stability while also providing support for increasingly complex services. <br\/><br\/>The research in this project is divided into five areas: dynamic monitoring, which includes work to improve the accuracy of monitored data as well as the real-time capability to perform targeted high-fidelity monitoring; network health diagnosis, which attempts to determine the real-time operational status of a variety of metrics; dynamic provisioning, which uses status information to adjust network operation and protocol parameters in order to improve performance; interactive visualization, which attempts to aid network understanding through interactive and scalable display techniques; and finally, management and planning, which takes a longer-term view of wireless network operations and focuses on capabilities like additional resource placement. These projects provide intellectual merit through new designs for wireless networks, work to develop a clear set of design solutions, investigation of possible alternatives within each set, and evaluation of proposed solutions. <br\/><br\/>The research will have a broad impact on research, industry, society, and education. It will offer new directions in research, impact wireless network design and deployment, and improve the robustness of wireless network deployments.","title":"NeTS-WN: Wireless Network Health: Real-time Diagnosis, Adaptation, and Management","awardID":"0722075","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["552796","560332","518684"],"PO":["557315"]},"127485":{"abstract":"This is a project to provide improvements which may enable the emerging technology of sensor-driven models of human situation to move from laboratory demonstrations to practical widespread use in human-computer interaction systems. Interfaces as we see them today are largely static ? they act in the same way regardless of what human situations they are used in. In the past world of information workers in a fixed office setting, this was acceptable. However, as technological advances allow inexpensive computing devices to move into all the diverse settings of everyday life, this will no longer be appropriate. Our devices should adjust to the human context of each situation in a way that maximizes their ease of use and effectiveness in serving human needs across those varying situations. However, currently most interactive systems have no information about the human situations they are operating in, or the activities of the users they serve. This represents a significant barrier to creating interfaces which are more appropriate to the wider world they are now being placed in.<br\/><br\/>To overcome this basic obstacle, an emerging body of work has begun to develop techniques for modeling human situations and activities. Much of this work employs sensor-driven statistical models created with machine learning techniques. These models provide useful estimates of activities and situations. However, there are a number of serious practical barriers to widespread use of these techniques. This grant will support an aggressive body of work aimed at overcoming the most important of these barriers. One of the most important of them is the expense, difficulty, and disruptiveness to end-users of collecting sufficient training data to make these systems work. To address this problem, the project includes development and study of a collection of innovative techniques tuned to reducing the human costs associated with collecting the required training examples.<br\/><br\/>In addition, new techniques for internet-scale collection of training data will be developed. These techniques will enable a shift from the current practice of collecting a large amount of data from a few people to collection of a small amount of data from many people. Complementing this approach, new hierarchical modeling techniques will be developed which should allow a smooth and rapid transition from an initial generic model reflecting average behavior of many people, to models which are finely tuned to the particulars of an individual with minimal disruption for that end-user. Finally, the work to be funded here will explore the effectiveness of a variety of emerging advances in machine learning technology which have yet to be widely applied to human-computer interaction applications.<br\/><br\/>The impact of this research will go significantly beyond the specific issues it attacks because it is enabling in nature ? seeking to open up the possibility of what should be complete classes of new interface technology. In addition, this work is particularly important for some applications supporting special needs populations, and the project includes activities to enhance education.","title":"HCC: Enabling Practical Human Activity Modeling for Interactive Applications","awardID":"0713509","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["518043"],"PO":["564456"]},"129432":{"abstract":"Two important features distinguish wireless communication from wireline communication: the time-variations of the wireless links and the broadcast property of wireless transmissions.<br\/>In the past decade, a new fundamental understanding of time-variations from an information theoretic point of view has developed. This understanding has led to radical shifts in points of view regarding wireless system design, not only at the physical layer but also at<br\/>higher layers. In contrast, the progress in a fundamental understanding of the broadcast nature of wireless links has been far slower. Most of the techniques that exist as implemented in current wireless networks to deal with interference and cooperation are ad hoc.<br\/><br\/>In this project we focus on the broadcast nature of the wireless link by taking a cue from the success in dealing with the time varying nature of the wireless link: true progress in wireless communication comes from a synthesis of a fundamental and information theoretic understanding into networking ideas.<br\/><br\/>We propose to (a) obtain a fundamental understanding of how to optimally manage interference and achieve cooperation, (b) build an abstraction of the physical layer that captures the performance benefits of optimal interference management and cooperation, and (c) identify scenarios in which such optimal techniques yield significant improvement beyond<br\/>current techniques. We envision the broader impact of this research agenda to influence the design rules by which the interference and cooperation are dealt with in next generation of wireless networks.","title":"NeTS-WN: Collaborative Research: Interference Management and Cooperation in Wireless Networks: A Modern View","awardID":"0721652","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["523699"],"PO":["557315"]},"127375":{"abstract":"In recent years, we have experienced major events that have disrupted critical infrastructures all over the world: 9\/11, Hurricane Katrina, natural disasters, terrorist attacks, and numerous wars. These events have resulted in huge work disruptions with substantial economic costs. Such disruptions are not new. What is new is that we are now living in an age where networked mobile information and communication technologies (ICT) are nearly ubiquitous for many people worldwide. This research examines how human infrastructure, the patterns of relationships of people through various networks and social arrangements, can be repaired using ICTs when the environment is disrupted. <br\/><br\/>In partnership with IBM Haifa (Israel), the primary data collection for this project will be an ethnographic field study of people's experience with the recent Israeli-Lebanese war. Analysis of these data will inform requirements for technologies that support people in their attempts at restoring their human infrastructure for accomplishing work following a major disruption. The key innovation in this research is its comprehensive and integrated view of the interplay between the human and technical infrastructures. <br\/><br\/>Broader Impacts: Effective collaboration has a vital role in society and understanding how human infrastructure can be repaired in the aftermath of an environmental disruption will benefit people's lives in very real ways. These results can also help organizations to develop effective plans for restoring the human infrastructure for collaborative work.","title":"Collaboration Resilience: Restoring Human Infrastructure with Technology","awardID":"0712876","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[337818,"518420"],"PO":["564456"]},"127496":{"abstract":"Query Evaluation and View Materialization in Probabilistic Data<br\/>PI: Dan Suciu (U. Washington)<br\/>Award: IIS-0713576<br\/><br\/><br\/>Databases and data management tools have a deterministic semantics: a data item <br\/>either is in the data set or is not. But when data comes from multiple sources,<br\/>or is extracted automatically, it often contains a variety of imprecisions that<br\/>are difficult to model using the standard deterministic semantics: the same <br\/>data item may have different representations in different sources <br\/>and matching algorithms are imprecise; schemas differ across sources and <br\/>schema matching tools are imprecise or incomplete or both; data at different <br\/>sources may hold contradictory information; finally, some data, such as sensor <br\/>data, is inherently probabilistic and hence imprecise. This project represents <br\/>all sources of imprecision in a single uniform way, as data with a probabilistic<br\/>semantics, and extends today''s data management tools to manage efficiently <br\/>data with probabilistic semantics.<br\/><br\/>Re-designing databases to handle probabilistic data is a daunting task.<br\/>This project studies two problems that lie at the core of probabilistic <br\/>data management: the complexity of the query evaluation problem on <br\/>probabilistic databases, and the view materialization problem <br\/>(deciding whether a view can be materialized and whether it can be <br\/>used in other query plans). The results of this research will consists <br\/>of a range of fundamental techniques to be used in a general purpose <br\/>probabilistic query processor.<br\/><br\/>Intellectual Merits. The project makes new contributions that lie <br\/>at the intersection of several disparate fields: logic, probability theory, <br\/>knowledge representation, and traditional query processing and optimization. <br\/>The project enhances the understanding of the query evaluation problem on <br\/>probabilistic data, develops new algorithms for efficiently evaluating <br\/>such queries and for materializing views, while leveraging existing database <br\/>technology.<br\/><br\/>Broader Impact. Searching large information spaces (the Web; large collections<br\/>of scientific databases; Homeland Security data) is one the new and most <br\/>challenging frontiers in Computer Science. The innovation that is needed <br\/>to support complex searches that scale to large and heterogeneous <br\/>information spaces, has to come from the data management research community. <br\/>This project makes contributions to broaden our ability to search large <br\/>information spaces. If successful, the project will be one of the pieces<br\/>that will help data management technology undergo a new paradigm shift, <br\/>from supporting complex queries with deterministic semantics,<br\/>to supporting complex explorations with probabilistic semantics.<br\/><br\/>Project URL:<br\/>http:\/\/www.cs.washington.edu\/homes\/suciu\/project-probD","title":"III COR: Query Evaluation and View Materialization in Probabilistic Data","awardID":"0713576","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["531543"],"PO":["469867"]},"129201":{"abstract":"This project investigates embedded technologies for continuous monitoring and logging of vital medical signs and physiological parameters using a wireless body sensor network (BSN). BSNs consisting of a hybrid of implantable, ingestible and wearable sensors have emerged as a new paradigm of digital healthcare for disease alert and real-time monitoring of hospitalized as well as non-hospitalized, chronically-ill or aged patients. This project investigates embedded technologies to deal with unique challenges of a BSN including: extremely stringent energy constraints imposed by in vivo sensors, very limited on-sensor computing capability, and uniquely complex radio propagation body environments. The goal of this research project is to design, optimize and test embedded system communications techniques for wireless BSNs, in order to achieve unprecedented energy efficiency, reliability and cost structure. The proposed research directions and innovative claims include: the design of practical radios for around-body networks and the development of adaptive media access control which is flexible to deal with and capitalize on heterogeneous sensor environments with extremely asymmetric traffic patterns and energy constraints. This project has substantial broader impact. With the technological advances in sensor networks and system-on-chip design, BSNs can be expected to prevail in medical healthcare, but also permeate healthy lifestyles to improve the quality of life in the future. Leveraging the high-profile subjects on communication, networking and embedded systems enjoyed among students, the multi-disciplinary body sensor network research promotes the integration of research with education and outreach activities at both graduate and undergraduate levels.","title":"CSR---EHS: Reliable Networking and Communications for Embedded Body Sensor Networks","awardID":"0720781","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["565205","545821"],"PO":["561889"]},"129322":{"abstract":"Rapid advances in portable computing and wireless technologies are creating deployments of many different types of radio access networks such as WWANs, WLANs, and WPANs with different transmission rates, coverage ranges, power-levels, mobility-levels, services and price-levels. <br\/><br\/>In such a heterogeneous architecture, devices equipped with multi-network interfaces (i.e., multi-mode terminals) should be capable of performing network selection, location update, paging, and horizontal and vertical handoff. <br\/><br\/>The objective of this proposal is to provide an integrated heterogeneous wireless network to support multi-mode terminals in the multi-network environment, where the terminals take advantage of multiple interfaces to satisfy the QoS requirements. This proposal introduces new horizontal and vertical cross-layer features that allow multi-mode terminals to opportunistically exploit the available multi-networks. These new features include network availability detection and link quality estimation, and use information from different layers across multiple interfaces, in order to decide which connectivity-alternative best matches the requirements of an application. The multi-mode protocol stack will be defined such that it does not require any modifications to existing protocols so that different wireless technologies can also support multi-connection handoff and multi-network interfaces. From the system's perspective, proposed solution can help improve the overall system performance by redirecting the traffic to appropriate networks. Such an effective solution for connection and handoff management can lead to drastic performance enhancements.","title":"NeTS-WN: Collaborative Research: Supporting Multi-mode Terminals in Integrated Heterogeneous Wireless Netowrks","awardID":"0721264","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[342646],"PO":["557315"]},"129212":{"abstract":"With the emerging concerns of power dissipation and ever diminishing returns on the silicon investment, the industry has moved away from developing fast single-core solutions in favor of designs that integrate muiltiple processing cores within a single chip or package. Processor development efforts and related research have always relied on the use of accurate functional and timing simulators. It is useful to have an integrated simulation environment that permits the exploration of tradeoffs among performance, power and reliability in multicore microprocessors. The proposed effort addresses a current void in this respect and aims to investigate, design, develop and disseminate exactly such a tool system for use in processor design research and pedagogy. As another advantage, the proposed simulation framework is based on the commonly used X86 and X86-64 instruction set architectures (ISAs). This permits the implementation of a full system simulator that goes well beyond the commonly available user-mode simulators in simulating not just the user-level activities but also kernel level activities accurately. The use of the X86 ISAs also permits native mode execution on the underlying PC hardware, including multicore platforms, to significantly speed up simulation over portions of the simulated code that are not of interest. The outcome of this effort will be the development of methodologies and a prototype tool implementation for accurately estimating the energy and performance characteristics of multicore microprocessors. The resulting tool will be distributed to research groups via the web, fostering research activities in microprocessor design, including the consideration of energy-performance tradeoffs.","title":"CSR---SMA: A Design Space Exploration Tool for x86 and x86-64 Multicore Microprocessors","awardID":"0720811","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["494776","451773"],"PO":["535244"]},"129454":{"abstract":"Wireless mesh networks were originally proposed for connecting WLANs in residential or metropolitan areas to provide pervasive wireless access and share Internet connections. In the future, mesh networks will surely go far beyond the above application scenarios. <br\/>This project aims to push mesh networks into the arena of real-time applications. Supporting real-time data delivery in wireless mesh networks is much more difficult than its counterpart in the wired networks due to resource constraints, shared wireless channels, lossy communication, and highly dynamic traffic. It requires system support from the bottom all the way to the top of the network protocol stack. <br\/>The objective of this project is to develop new technologies at the MAC and network layers to support end-to-end, real-time data transport in wireless mesh networks. The research includes 1) real-time MAC protocols with bounded media access delay and minimized channel idle time, 2) queuing management for multiple service classes and distributed admission control of real-time traffic, and 3) end-to-end fairness, bandwidth assurance, quality-of-service (QoS) routing for real-time flows. <br\/>The research results are expected to have significant intellectual and practical impact. Not only will the new technologies provide solutions to an array of fundamental problems in real-time mesh networks, but also they will expand the application scope of mesh networks from access networks to distributed real-time systems in diverse domains such as transportation, battlefield surveillance\/command\/control, and wireless multimedia communications.","title":"NeTS-WN: New Technologies for Real-Time Wireless Mesh Networks with Transportation Applications","awardID":"0721731","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["485310"],"PO":["434241"]},"128255":{"abstract":"The performance pressures on implementing effective network security monitoring are growing fiercely in multiple dimensions, outpacing improvements in CPU performance. The situation has now become dire with the end of Moore's Law for single CPUs. In general, hardware vendors now turn to parallel execution---many cores and many threads---to sustain performance growth. But adapting network security monitoring to such parallelism raises a host of challenging issues.<br\/><br\/>This project seeks to develop methodologies for effectively parallelizing in-depth security analysis of network activity. Doing so requires structuring the processing into separate, low-level threads suitable for concurrent execution, for which several key issues must be addressed: forwarding packets only when all relevant threads have finished their vetting; minimizing inter-thread communication in the presence of global analysis algorithms; optimizing memory access patterns for locality; and providing effective performance debugging tools.<br\/><br\/>The work centers around an event-oriented underlying architecture, which allows for exposing many opportunities for concurrent execution due to the decoupled asynchrony that events introduce into the flow of analysis. In addition, by associating events with the packets that ultimately stimulated them, the system can make sound decisions for resolving whether and when it becomes safe to forward pending packets.<br\/><br\/>Ultimately, the effort aims to enable network intrusion prevention to reap both the benefits of executing on general purpose commodity hardware, as well as the exponential scaling that Moore's Law promises for future parallel processors.","title":"CT-T:Exploiting Multi-Core CPUs for Parallelizing Network Intrusion Prevention","awardID":"0716636","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["562327","525668","562329"],"PO":["529429"]},"129586":{"abstract":"Proposal Number: 0722231<br\/><br\/>Title: CPATH CB: The Software Communication Chautauqua<br\/><br\/>PI: Charles Wallace<br\/><br\/>Oral and written communication skills are crucial for effective software development. Software engineers interact with a diverse set of stakeholders: customers, end users, management, and coworkers, among other groups. Communication is complicated by the varying and competing goals of stakeholders, the lack of a common vocabulary, and the tendency of software developers to prefer the comforting precision of computers to the ambiguity and obscurity of human dialogue.<br\/><br\/>How can educators prepare students for the substantial communication challenges they will face in their careers? To develop an adequate response to this question, further conversation is needed to build bridges between industrial software developers and educators in technical communication and software engineering. This interchange will help to generate new pedagogical materials and curricula for software engineering students, informed by the communicative arts and grounded in the reality of industrial experience.<br\/><br\/>A Chautauqua meeting of these varied groups will help to start this conversation. The freeform and inclusive nature of the Chautauqua tradition will allow the diverse voices of multiple stakeholders to interact productively. The goal of the Chautauqua is to foster new alliances and projects focused on communication problems in software development.","title":"CPATH-CB: The Software Communication Chautauqua","awardID":"0722231","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}}],"PIcoPI":["528844",343421,"425208","545038",343424],"PO":["562944"]},"128266":{"abstract":"This research asks, \"What is the cyber-equivalent of a fingerprint -- that staple of forensic investigation in the physical world?\" If one is able to identify users forensically by their \"fingerprints\" in cyberspace, what would correspond to the familiar loops, whorls and minutiae of physical evidence? It is hypothesized that just as a person may be identified by his handwriting, or by his manner of expression in prose, so may a person be identified by his typing style -- the particular rhythm of a user's keystrokes.<br\/><br\/>The approach being investigated is keystroke dynamics, the use of precise keystroke timings as a mechanism for building unique user profiles for differentiating among users. Goals of the work are to determine whether keystrokes can be used to identify\/authenticate users in two-factor authentication protocols, whether user keystroke patterns can be used to thwart insider attacks, and whether keystroke habits are sufficiently distinct to show who issued a command or typed a document. The work will develop the science, methodologies and techniques to answer such questions.<br\/><br\/>The results of the project are expected to provide a basis for substantial increases in on-line security in applications such as web-based financial transactions, two-factor authentication in various domains, and questioned-document forensics. The involvement of students, minorities, jurists and lay people in the scientific process will raise community awareness regarding computer forensic techniques, and will provide a foundation for rigorous experimental science.","title":"CT-T: Keystroke Forensics - Fingerprints in the CyberWorld","awardID":"0716677","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["550270","492191"],"PO":["497499"]},"129366":{"abstract":"Energy-management is essential for wireless sensor networks to prolong network lifetime and to increase the amount of useful information conveyed. There is potential to substantially improve the energy efficiency of sensor networks by exploiting cross-layer interactions among various networking layers and functionalities. However, such a cross-layer solution could also become impractically complex and difficult to implement. To address this challenge, this collaborative NSF-funded project at The Ohio State University and Purdue University aims to develop a suite of high-performance cross-layer mechanisms for sensor networks that are simple, modular, distributed, and provably energy-efficient. The key distinguishing feature of the project is that the mechanisms developed are based on a solid theoretical foundation that rigorously manages both performance and complexity with the goal of practical implementation. The PIs will investigate four major functionalities that are crucial to the efficient operation of energy-constrained wireless sensor networks, including joint medium-access and routing, sleep\/wake scheduling, in-network aggregation\/computation, and reliable broadcast. The theoretical solutions developed in this project will be implemented and evaluated on two testbeds: the existing Kansei testbed at OSU, and a prototype deployment (SENSE@OSU).<br\/><br\/>Broader impact: The collaborative research will have a significant impact on wireless industry sectors, and will lead to breakthroughs in our understanding of the fundamental limits for developing energy-efficient distributed solutions for sensor networks. The PIs will also continue their current efforts to recruit and train women and under-represented minority groups both at the undergraduate and graduate levels.","title":"NeTS-NOSS: Collaborative Research: Energy-Efficient Distributed Sensor Network Control: Theory to Implementation","awardID":"0721434","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["548182","542039"],"PO":["557315"]},"128156":{"abstract":"This project will evaluate vulnerabilities in relatively unstudied model-based recommendation systems in which recommendations are based on a model that relates ratings on one item to ratings on other items. Recommendation systems are a means of reducing \"information overload\" by filtering a potentially overwhelming number of options (such as all the products available from a seller) to identify those calculated to be of greatest interest. This project extends research on collaborative recommendation systems, which base recommendations for an individual on the preferences expressed by other people, by investigating the problem of malicious manipulation of these systems, for example, by an attacker attempting to influence the outcome with biased or faked rating profiles. Research suggests that a specific model-based systems exhibit much more resistant to recommendation attacks than memory-based systems in which recommendations are based on the principle of finding similar users or similar items. Moreover, this research will identify any previously unknown attack methods that might be specifically effective against model-based recommendation systems.","title":"CT-ISG: Collaborative Research: Detecting and Preventing Attacks in Recommendation Systems","awardID":"0716261","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["229551","414759"],"PO":["543481"]},"128277":{"abstract":"Widely deployed for military and civilian applications, sensor networks have become an indispensable segment of national cyber infrastructure. In sensor networks, sensor nodes sense continuously and generate data to describe the environment; once data have been generated, an essential mission of the network is to manage sensor data such that useful data are stored safely and authorized users can have access to data of their interest. Meanwhile, sensor nodes are usually deployed in unattended even hostile environments, and they typically lack tamper resistance. As such, sensor data management is susceptible to various security attacks. Although a few schemes have been proposed against selected attacks, the limitations are also salient: lacking protection for emerging sensor data management approaches, disrupting normal data management operations, high overhead, lack of adaptability to balance security level and system overhead, and no systematic solutions to counter multiple types of attacks at the same time. To address these issues, this project is to design an integrated solution to provide novel privacy, confidentiality, integrity and reliability protection for sensor data management. It includes four components: location privacy protection, data confidentiality protection, data integrity protection and data reliability protection. These components will be integrated together via a carefully-designed hierarchical and modular software structure, and to be evaluated through a combination of model checking, simulation, and implementation on a sensor network testbed. The project will contribute to the development of innovative solutions for protecting sensor networks, training of a diverse cadre of young scientists, students and professionals in wireless networking and security, and most importantly enhanced cyber infrastructure security.","title":"An Integrated Solution to Provide Privacy, Confidentiality, Integrity and Reliability Protection for Sensor Data Management","awardID":"0716744","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["425154","382141","492059"],"PO":["565239"]},"129377":{"abstract":"Our physical world presents an incredibly rich set of observation modalities, such as heat, light, moisture, pressure, motion, etc. Recent advances in wireless sensor networks (WSNs) enable the continuous monitoring of various physical phenomena at unprecedented high spatial densities and long time durations and, hence, open new exciting opportunities for numerous scientific endeavors. Because sensor nodes are battery-powered, the most critical challenge in WSNs is minimizing the use of power, of which the most energy-consuming operation is data transmission. Given the commonly high correlations of sensed data in time and space, an analytical framework for correlation studies and new data gathering protocols is fundamentally important to reduce communication costs through lossless data compression in WSNs. This project is devoted to the fundamental investigation of exploiting temporal correlation In WSNs, for sustaining monitoring in harsh and possibly hostile environments, through an integrated theoretical and empirical approach. From this project, a novel, analytical, adaptive multimodal predictive transmission framework based on predictive coding is developed, for environmental monitoring WSN engineering, to achieve substantial energy savings and, hence, to significantly extend the lifetime of WSNs. Based on the developed framework, a new data gathering protocol suite is designed and implemented. Furthermore, a real-world environmental monitoring WSN testbed in a hilly watershed is deployed for evaluation and validation. Our interdisciplinary education plan uses the built WSN testbed and integrates our research results and new insights into education practice to provide hands-on training and experience for undergraduate and graduate students in both environmental and IT fields.","title":"NeTS-NOSS: Collaborative Research: Investigating Temporal Correlation for Energy Efficient and Lossless Communication in Wireless Sensor Networks","awardID":"0721474","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["460719"],"PO":["565303"]},"129388":{"abstract":"In deployment of sensor networks for various applications, sensors need to be placed in the areas of difficult terrain and natural obstacles. In such settings, many existing algorithms may perform poorly or may have high overhead while inefficiently consuming energy. One approach is to utilize mobile sensors in these situations, such as sensors with wheels. However, mobile wheeled sensors may not be able to move to the desired locations in the areas of difficult terrain with obstacles. Wheeled sensors can also be very expensive. A hopping sensor is a type of mobile sensor with a bionic mobility design that is inspired by creatures, such as grasshoppers. These sensors are still at an interesting concept stage. This proposal addresses the design, prototyping, and evaluation of hopping sensors and efficient algorithms for sensor deployment in difficult areas and rugged terrain. We focus on four research issues that are critical to the effective deployment and management of large scale sensor networks in such settings: robust and power-efficient hopping sensors, sensor localization, sensor coverage, and deployment of a self-adaptive all terrain sensor networks equipped with the hopping sensors and the proposed algorithms, which is called LEAPNet. Most future sensor networks are likely to be deployed in our targeted environments, and hence this research will benefit real-world applications such as monitoring ecosystems, disaster relief, and military reconnaissance. Strong collaborative efforts will be made to provide efficient and practical solutions with solid engineering designs and strong algorithmic foundations for this purpose. In addition, an innovative integration of the proposed research and education program will provide students with analytical skills and hands-on experiences by emerging technologies, which will better prepare them for strong technical careers in this rapidly growing and changing area.","title":"NeTS-NOSS: Collaborative Research: LEAPNET: Self-adaptable All Terrain Sensor Networks","awardID":"0721516","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["551992"],"PO":["564777"]},"129157":{"abstract":"Current high-level design methodologies and tools assume a classic static timing behavior and do not include effects of design variability on performance or energy. In support of a complete probabilistic design flow, high-level modeling of variability effects is needed for determining design choices that are most likely to meet initial design constraints. This project enables high-level analysis of design variability on overall system performance and power consumption. The problem of performance and power analysis is addressed for both latency- and throughput-constrained applications mapped onto platforms characterized by either globally synchronous or asynchronous on-chip communication. The research provides a comprehensive framework that includes (i) probabilistic latency, rate, and leakage analysis in the presence of variations; and (ii) design exploration capabilities for determining early in the design process the design choices more likely to meet prescribed performance or leakage power limits.<br\/><br\/> An integral component of the project is its impact on educational activities at Carnegie Mellon University, as well as its overall societal impact via enabling frontier application development. Without a strong foundation for training next generation''s system designers and computer architects, the achievement of aggressively scaled integrated system will not be possible. The proposed variability modeling framework (which will be distributed freely) can be used for the design of next generation Systems-on-Chip, thereby enabling applications having a broad societal impact. More precisely, complex systems that seamlessly integrate homogeneous or heterogeneous cores and have predictable performance and power budgets will most likely find their applications in large segments of the consumer market.","title":"CSR---SMA: Variability-Aware System Level Performance and Power Analysis","awardID":"0720653","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["554462"],"PO":["535244"]},"129399":{"abstract":"Aggregations of massively deployed sensors are expected to create sophisticated sensing, computation, communication and control platforms called Networked Sensor Systems (NSS) that will pervade society, revolutionizing the way in which we live and work. In order to scale, these systems must be largely autonomous, decentralized entities whose corporate resources can be made available to authorized users. Such autonomous, geographically-dispersed NSS are increasingly recognized as key to numerous applications ranging from healthcare to smart homes and homeland security. For example, autonomous NSS can assist first responders, often in inhospitable environments, by locating survivors, identifying danger areas and enhancing user awareness of the situation The resource-constrained sensors, the wireless communication medium, the large-scale deployment, combined with the mobility of users, the close interaction with the physical environment and the highly sensitive nature of mission-critical operations pose formidable challenges to autonomous NSS design. The key inter-related technical contributions of this project are: (1) Dynamic task-based networking supporting application-level tasks and queries while hiding resource-level details; (2) Smart AFN mobility subject to changing application requirements and network conditions; and (3) providing secure ANSWER operation and multi-level secure interactions with in-situ mobile users. ANSWER prototype can serve as a tool to explore mobile user behavior in ubiquitous networks under varying environmental and network conditions. This project will leverage programs at VT, UMBC, and ODU to actively recruit and involve under-represented groups in innovative multi-disciplinary hands-on experiments in ubiquitous networking, security and sensor systems. The research results will be disseminated via the project's Web site (http:\/\/www.nve.vt.edu\/cias\/cycarenet\/ANSWER).","title":"Collaborative Research-NeTS-NOSS: AutoNomouS netWorked sEnsoR Systems (ANSWER)","awardID":"0721563","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["485667"],"PO":["564993"]},"128189":{"abstract":"National Science Foundation<br\/>CISE\/CNS<br\/>Form 7 Review Analysis and Recommendation<br\/><br\/>Proposal Number: 0716368<br\/>PI: Daniel Lopresti<br\/>Institution: Lehigh University <br\/>Lead<br\/><br\/>Proposal Number: 0716393<br\/>PI: George Nagy<br\/>Institution: Rensselaer Polytechnic Institute<br\/>Sub<br\/><br\/>Proposal Number: 0716647<br\/>PI: Elisa H. Barney Smith<br\/>Institution: Boise State University<br\/>Sub<br\/><br\/>Proposal Number: 0716543<br\/>PI: Christopher Borick<br\/>Institution: Muhlenberg College<br\/>Sub<br\/><br\/><br\/><br\/>Title: Collaborative Research CT-T: Following the Paper Trail: Reliable Processing of Voting Records for Trustworthy Elections<br\/><br\/><br\/>Proposal Abstract<br\/><br\/>Provisions for the inclusion of a physical record, in the form of hand- or machine-marked ballots, or as a Voter Verified Paper Audit Trail (VVPAT), are central to guaranteeing safe and secure elections. However, the processing of such records during the initial counting of votes or in the conduct of audits has raised its own set of problems which span broad technical and social boundaries.<br\/><br\/>The aim of this project is to study issues that currently make paper records more of a nuisance than an integral component in trustworthy voting systems. Specifically, the principal investigators are working to characterize the statistical distribution of mark sense errors as a function of ballot layout and quality in optical scanning, to examine approaches for unbiased visual auditing based on ballot images, to investigate the possibility that a concept known as homogeneous class display (HCD) can facilitate manual recounts, and to evaluate recognition errors that may arise in processing the VVPAT used with Direct Recording Electronic (DRE) systems. They are also interested in the effects these issues have on procedures for testing the paper handling components of voting systems in accordance with operational constraints, including the modest training received by most poll workers. This work on voting technologies is supported by ? and supports ? a planned survey and focus groups they are conducting to measure voter confidence and acceptance and to identify common misconceptions and concerns, including accessibility to disabled voters. Beyond its broad impact on the development of more reliable and trustworthy voting technologies, this project more generally has implications for the highly accurate computer processing of any information encoded in human readable form.","title":"Collaborative Research: CT-T: Following the Paper Trail: Reliable Processing of Voting Records for Trustworthy Elections","awardID":"0716368","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["371100",339789],"PO":["529429"]},"131170":{"abstract":"We are living in a world full of various kinds of networks and the network flow is one of the most powerful and versatile tools to study the operation of the networks. For example, in data networks the flow may represent the connection in multi-hop links between two communicating nodes, and in transportation networks the flow may represent the movement of the people or the vehicles that are on the roads. The investigators studies the power optimal wireless communication problem and the evacuation-planning problem using contraflow schemes. The better understanding of wireless communications helps designing wireless network environments with increased network lifetime. The evacuation planning system has high importance in terms of Homeland Security; citizens, especially the residents of the areas where disasters such as hurricanes are of great threat, can be relieved from the fatal threats by the operation of efficient evacuation planning system.<br\/>Both problems are modeled as networks and flow-based modeling is used as an important tool for the theoretical study of both optimization problems. Solutions of these optimization problems help making innovations in theoretical methods for network design and distributed optimization, and extend to other network environments. The synergistic combination of the two problems brings up a new interesting problem of constructing autonomous contraflow evacuation planning systems using wireless sensor networks that requires immediate attention and further careful investigation. The research findings from this project provide a solid theoretical foundation for the new problem. The integration of the research findings into the education is considered a priority by the investigators. In addition, this project has the benefit of bringing together researchers from different areas of disciplines to collaborate on the problems.","title":"Network-flow Based Optimization Problems In Various Network Environments","awardID":"0729182","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":[348194,348195],"PO":["565157"]},"131181":{"abstract":"The protocols and architectures of today's ad hoc networks are derivatives of those developed in the past for the Internet, which in turn date back to the ARPANET design in the 1960s. This is the wrong approach for mobile ad hoc networks (MANET), because they are very different than wired networks. In particular, many-to-many communication is intrinsic to MANETs, because of their decentralized peer-to-peer nature and the broadcast nature of wireless channels. In contrast, the protocol stacks used today are designed to avoid multiple access interference (MAI) to support one-to-one communication.<br\/><br\/>This project proposes a blank-slate approach to the modeling and design of communication protocols for ad hoc networks and MANETs. The project will seek improvements on the order capacity of ad hoc networks by means of architectures and protocols for many-to-many communication enabled by the statistical multiplexing of wireless spectrum, processing, and storage resources in such networks. The project will re-examine commonly held notions about the way in which channel access and information transport should be accomplished when in-network storage and processing are affordable, thus making multi-packet reception (MPR) a viable approach. This project will provide fundamental advances to the understanding of (a) approaches that enable many-to-many communication in MANETs by exploiting processing and storage complexity in mobile nodes; (b) how to model communication protocols operating in MANETs; and (c) what are more meaningful fundamental limits for the dissemination of information over MANETs when many-to-many communication is allowed.","title":"Many-to-Many Communication for Scalable Ad Hoc Networks","awardID":"0729230","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":[348219,348220],"PO":["564924"]},"131071":{"abstract":"Fundamental Algorithms for Data Management<br\/><br\/>We are in an era where data (entertainment, media) is expected to be available on demand, and not primarily through broadcast methods such as TV. Storage technologies will need to cope with extremely high demand, with high quality of service. Storing large amounts of data and making it accessible to a very large number of users will be a challenge. The focus of this research is to develop fundamental algorithms for managing data in large scale storage systems. This research focuses on data of all types, ranging from multimedia data stored on a collection of disks, as well as data that is being collected and stored in a distributed sensor network. This research addresses the question of how to develop algorithms to manage this data effectively and efficiently. This project will involve training of a graduate student, and the development of a course on data management methods.<br\/><br\/>This research develops tools and methods for managing data, with a special focus on data layout and data migration. The data layout specifies for a storage system, how many replicas are required to cope with the demand, and which servers they should reside on.<br\/>This problem is NP-hard and our goal is to develop fast and practical approximation algorithms for it.<br\/>The goal of data migration is to focus on the problem of re-organizing the layout when the demand pattern changes over time.<br\/>We also consider energy issues in data collection and monitoring in sensor networks.","title":"CCF: Fundamental Algorithms for Data Management","awardID":"0728839","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7796","name":"ALGORITHMIC FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7926","name":"ALGORITHMS"}}],"PIcoPI":["538796"],"PO":["565251"]},"131082":{"abstract":"Image registration is one of today's challenging image processing problems.<br\/>Given two images, one attempts to find a reasonable transformation to deform one image into the other.<br\/>Image registration is applied whenever images resulting from different times and devices need to be compared or integrated. It is often used in radiation therapy and surgery planing.<br\/>Image registration is a highly ill-posed problem. To reduce the level of non-uniqueness, it is possible to use additional constraints such as rigidity of bones. <br\/>This research deals with the numerical treatment of image-based constraints.<br\/>While it is possible to formulate constrained image registration problems, such problems can be very difficult to solve. This project develops and experiments with inexact adaptive multilevel inexact Sequential Quadratic Programming methods that allow inaccurate solutions of the subproblem at each iteration.<br\/><br\/>Intellectual Merit: The challenges in this work are composed of two parts.<br\/>First, constrained image registration problems are formulated in a way that yields continuously differentiable objective functions. Second, constrained optimization techniques are develop. This involves SQP, multigrid and adaptive mesh refinement methods.<br\/>Broad Impact: Image registration is routinely used for clinical procedures.<br\/>Nevertheless a vast majority of registration problems use either rigid or affine linear transformations.<br\/>This is because fully nonlinear registration tends to be unreliable. <br\/>Using image-based constraints will<br\/>generate realistic deformations and thus expand the use of image registration algorithms to much more complicated problems. This can directly impact clinical procedures such as radiation planning and tumor tracking.","title":"Numerical Optimization For Image-Based Constrained Registration","awardID":"0728877","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["408684"],"PO":["565157"]},"131093":{"abstract":"Active contours (deformable curves that evolve within an image in order to capture an object of interest) rank among the most widely used tools in image processing and computer vision. This investigation focuses on the mathematical reformulation of many existing active contour models to improve their robustness and performance as well as the formulation of brand new active contour models that are not possible under the more traditional formulation. The impact of the this investigation is therefore expected to be quite broad given the prominence of active contour applications in many fields ranging from medical imaging, manufacturing, survelliance, target tracking, visual inspection, and video compression.<br\/><br\/>For over twenty years, gradient flow schemes for active contours have been mathematically founded upon a common, though often overlooked, geometric L2 norm. The investigator will study the benefits of changing this fundamental unifying mathematical foundation by proposing alternative classes of norms to greatly improve the behavior of gradient flow schemes for active contours.<br\/>A tremendous amount of effort has gone into designing more and more sophisticated energy functionals yet not into considering the mathematical foundations behind the \"\"standard recipe\"\" gradient flow calculations.<br\/>By changing the underlying norm behind gradient descent caluclations for active contours, the investigator will introduce in a mathematically rigorous and principled manner new active contour flows whose behaviors can be improved and tailored regardless of the corresponding energy functional.","title":"New Directions in Active Contours by Reformulating Geometric Gradients","awardID":"0728911","effectiveDate":"2007-09-01","expirationDate":"2011-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["561949"],"PO":["564898"]},"132193":{"abstract":"This proposal will support the initiation of a concept for courses at the interface of engineering and science and ethics. Educating students and faculty to regard attentively ethical determinations entails organizing hands-on coursework that demonstrate how the choices involved in the many activities associated with the research and professional practices of scientists and engineers should be framed in ethical parameters. These parameters are further determined by cultural and socio-political conditions that differentiate both needs and expectations. The plan will engage philosophy faculty, along with engineering and industry and policy professional. The focus for the first course will be issues related to computer technology development and use. Faculty will be engaged from around the El Paso region, enable participation by a number of Universities. In the interdisciplinary, international, and multi-cultural formal planned, an essential task will be to come to terms with the ethical nature of how each of the several other participants plays roles in defining identity and tasks. Additional relevant issues will be identified with an Advisory team. A summer seminar will begin the cross-disciplinary exploration.","title":"Institute for Science, Technology, Ethics, and Policy","awardID":"0734912","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[351279,"495130",351281],"PO":["565136"]},"125791":{"abstract":"III-COR: Collaborative Research: Graceful Evolution and Historical <br\/>Queries in Information Systems-- a Unified Approach <br\/><br\/>Database schema evolution represents a constant in the life cycle <br\/>of Information Systems, and is the source of major costs for <br\/>maintenance, upgrading, and service down time. The traditional <br\/>schema revision process depends on the installation of a new <br\/>schema along with the revised database, and a converted set of <br\/>applications (laboriously rewritten to work with this schema). <br\/>Instead, this project develops the novel enabling technology <br\/>whereby the schema evolution problem is reduced to coordinating <br\/>mappings between multiple concurrent versions of the schema, <br\/>applications, and the database. This is realized by the <br\/>Meta-Manager system which provides integrated management of <br\/>evolving (i) data, and (ii) metadata, and efficiently supports the <br\/>(iii) mappings, and (iv) software artifacts needed for graceful <br\/>schema evolution. Further, the Meta-Manager allows for <br\/>preservation and querying of database history while it assists the <br\/>user in planning how to evolve the current schema version with <br\/>``what-if'' evolution scenarios. The functionality and performance <br\/>of the system is validated using various testbeds, such as, the <br\/>San Diego Supercomputing Center's Storage Request Broker, which <br\/>hosts scientific data for various research groups ranging from <br\/>astrophysicists to biologists. <br\/><br\/>This novel and timely approach provides a unified solution to both <br\/>the evolution and preservation of information systems. Because of <br\/>the key role played by information systems, a broad range of <br\/>scientific, educational, and economic activities will benefit from <br\/>these advances. <br\/><br\/>Results are disseminated via publications, reports and <br\/>demos available from the project web sites: <br\/><br\/>http:\/\/www.cs.ucr.edu\/~tsotras\/meta-manager <br\/>http:\/\/wis.cs.ucla.edu\/projects\/meta-manager <br\/>http:\/\/db.ucsd.edu\/people\/alin\/meta-manager","title":"III-COR: Collaborative Research: Graceful Evolution and Historical Queries in Information Systems--a Unified Approach","awardID":"0705345","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["542091"],"PO":["469867"]},"134063":{"abstract":"This project leverages current advances in network hardware and sophisticated data streaming algorithms to solve challenging internet problems involving network management and network attacks. Content addressable memories are commodity hardware that is ubiquitous in network routing hardware due to their efficient, constant time searching abilities. This project exploits these properties of content addressable memories to solve diverse on-line data stream management problems with challenging analysis and security applications. In particular, the results of this project will include: (1) content addressable memory conscious algorithms for the on-line analysis of data streams and the detection of different network attacks, including distributed denial of service attacks and fraud in advertisement networks; and (2) a functioning implementation of these algorithms on a network processor with content addressable memories, thus demonstrating the feasibility and efficiency of the approach.<br\/><br\/>The research results will have significant impact in resolving many of the problems facing many internet applications: on-line statistics can provide the basis for efficient network management, as well as for detecting denial of service attacks and fraud in advertisement networks, which disrupts the everyday usage of many internet applications. Funds from this project support the training of one Ph.D. student. A new graduate research seminar covering databases, networks, hardware and security will be introduced into the curriculum. Publications, technical reports and experimental data from this research will be disseminated via the project website (http:\/\/www.cs.ucsb.edu\/~dsl\/hardware.html).","title":"SGER: Leveraging Advanced Hardware for Streaming Applications","awardID":"0744539","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["500153"],"PO":["469867"]},"125230":{"abstract":"The persistent drive for increased performance and more functionality poses continuing challenges to computing. Reconfigurable computing is an alternative method to address these concerns: complex operations execute as hardware circuits made from reconfigurable logic instead of as slower sequential instructions on a programmable processor. This research examines the integration of reconfigurable logic into modern computing systems consisting of multiple processor cores, multiple levels of memory hierarchy, and virtual memory support. The project compares different cache-based and queue-based memory structures for use in novel memory interfaces that connect reconfigurable logic to system memory at various connection points within the memory hierarchy. New specialized memory controller designs optimized for reconfigurable logic and flexible enough for different application types will allocate these memory structures to the data needed by the reconfigurable logic. The memory controller designs will also support virtual memory to ensure memory protection, a necessary feature for today's computing systems. The research will evaluate these different memory interfaces and controllers to identify those best suited for reconfigurable computing, supporting the needed types of memory accesses, and providing the memory bandwidth performance required by circuits implemented in reconfigurable logic. The overall goal of the project is to elevate reconfigurable computing to a mainstream technique for complex computing systems, providing power savings and performance benefits to a wide variety of applications.","title":"Reconfigurable Computing Memory System Integration","awardID":"0702605","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7941","name":"COMPUTER ARCHITECTURE"}}],"PIcoPI":["377736"],"PO":["559883"]},"128893":{"abstract":"Through a collaboration between the University of Kentucky, the University of Colorado at Denver, Rochester Institute of Technology, and cooperation with NCAR, a next generation wiland fire system is being created based on dynamic data-driven application system (DDDAS) principles.<br\/><br\/>A variety of sensors are used, from stationary sensors on the ground to sensors in satellites or attached to airplanes flying overhead. The use of the sensors changes with little warning and cannot be predicted in advance. Models change dynamically based on sensor networks. A dynamic execution environment is essential for acquiring the data, running a multi-model application, and pushing the results to the right places at the right times securely and robustly while still being simple enough for non-computer experts to operate the complex system while on a mountainside during stressful conditions.<br\/><br\/>The sensors used are reprogrammed in the field. New mathematical methods are being developed to change running simulation of a highly nonlinear system with coherent features in response to data and also controls sensors. The project employs virtual Grid technology in the computational environment.<br\/><br\/>Tens of billions of dollars in property and infrastructure burn up or are severely damaged every year due to wildfires.<br\/>The peak areas are not just low population density areas in Colorado and Montana, but include areas near large population areas and national labs in California, Florida, Georgia, Texas, New Mexico, and Oklahoma. Commerce is affected through disruptions of transportation of goods and loss of jobs.","title":"CSR-CSI: Collaborative Research: Dynamic Sensor\/Computation Network for Wildfire Management","awardID":"0719641","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["517181"],"PO":["535244"]},"126594":{"abstract":"Proposal #: CNS 07-08989 <br\/>PI(s): Erkip, Elza<br\/> Bertoni, Henry L.; Panwar, Shivendra S.; Wang, Yao<br\/>Institution: Polytechnic University of New York <br\/> Brooklyn, NY 11201-3840<br\/>Title: IAD: Cooperative Networking Testbed Amount Rec: $ 300,000<br\/><br\/>Project Proposed:<br\/><br\/>This project, building two complementary testbeds for cooperative networking, responds to the fading and multipath distortion, as well as interference caused by multiple users operating over a limited bandwidth, often suffered by wireless communication systems. Respectively, each testbeds will<br\/>. Use open source drivers for backward compatibility with the current WiFi technology based on the IEEE 802.11 standard. This approach uses a standard, non-cooperative physical layer since it is not possible to access the physical layer in commercial products.<br\/>. Be based on software defined radio, allowing maximum flexibility in the implementation of a cooperative physical layer, a cooperative medium access control (MAC) layer as well as cross-layer design.<br\/>Cooperative networking, where two or more active users in the network share their resources to jointly transmit their messages, provides resistance to fading, high throughput\/low delay and reduced interference\/low transmitted power. This infrastructure, leveraged in part by the WARP platform at Rice U, the ORBIT testbed at Rutgers U, and the CRAWDAD database at Dartmouth U, provides an open-access platform that will be used to build experimental deployable and scalable cooperative wireless networks, enabling current techniques to be moved beyond the current theoretical and simulation studies.<br\/>The testbeds validate the feasibility of cooperative networking, enable platforms where new algorithms can be tested, and lead to new theory founded on more realistic assumptions.<br\/><br\/>Broader Impacts: This first effort in implementing a fully cooperative network is expected to accelerate commercial developments in the field and impact current wireless standards. It facilitates a closer relationship with industry. Moreover, the infrastructure contributes to train students and service new courses.","title":"CRI: IAD Cooperative Networking Testbed","awardID":"0708989","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"5761","name":"INDUSTRY\/UNIV COOP RES CENTERS"}}],"PIcoPI":["421979","525973","491898","559524"],"PO":["557609"]},"127452":{"abstract":"Declarative, database-style models for programming distributed applications <br\/>are becoming widely adopted, in a variety of realms ranging from sensors <br\/>to publish-subscribe to network state management. They free the developer<br\/>to define high-level queries for the specific data of interest,<br\/>without regard to details about data sources, communications protocols,<br\/>or synchronization.<br\/><br\/>As this approach to programming gains momentum, there is increasing need<br\/>to abstract low-level stream data source variations away under a uniform<br\/> representation, i.e., a view; and to integrate, i.e., conjoin, different <br\/>types of stream data from large numbers of sources. Such tasks involve<br\/>much more distributed communication and coordination than in traditional<br\/>distributed databases or even data stream management systems. <br\/>It becomes essential to do in-network computation of the query, <br\/>and to optimize the processing of each stream (or few streams) separately, <br\/>in a way that considers the topology of the network.<br\/><br\/>This proposal develops the technologies to support integration of data streams, <br\/>including languages for stream schema mappings, focusing on issues relating<br\/>to combining distributed messages and maintaining timing information;<br\/>techniques for rapidly establishing query computation paths through a network,<br\/>for sets of data stream elements that need to be joined and aggregated together; <br\/>offline and adaptive, network-aware query optimization techniques for<br\/>distributed computation in the network. These techniques will scale<br\/>across widely heterogeneous (sensor, wireless, and<br\/>conventional) networks, and will be evaluated in environmental monitoring<br\/>applications.<br\/><br\/>The intellectual merit is the development of new techniques for performing<br\/>queries across large, highly distributed networks of stream-producing sources;<br\/>this increases understanding of the adaptive query processing space when access<br\/>costs to data items are non-uniform and query processing requires distributed<br\/>communication, and the trade-offs with respect to offline versus adaptive<br\/>optimization and relative to optimization granularity. The broader impact<br\/>includes the development of distributed stream integration capabilities that<br\/>can directly address a number of emerging and well-known challenges in the <br\/>network and environmental monitoring domains. The educational component <br\/>includes the training of two PhD students, and the teaching of stream data <br\/>integration in graduate and advanced undergraduate courses.<br\/><br\/>Project URL: http:\/\/www.cis.upenn.edu\/~zives\/stream-integration\/","title":"III: Distributed Stream Integration","awardID":"0713267","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["486185","517980"],"PO":["469867"]},"129520":{"abstract":"The full coverage model, where every point in the deployment region must be covered by at least one sensor, is pervasive in the wireless sensor network community. For applications that involve tracking movements at large scale such as tracking of thieves and robbers fleeing with stolen objects, tracking of animals in forests, and tracking the spread of forest fire, using the full coverage model makes sensor deployment prohibitively expensive. No sound model currently exists that can be used for systematic deployment of such large scale applications.<br\/><br\/>This project proposes a novel model of coverage called Trap Coverage that can be used for systematic deployment of sparse sensor networks, while ensuring frequent tracking of movements of interest. Most existing theoretical and systems work are not applicable to this new model because of the inherent sparsity of the network implied by the trap coverage model. The overall goal of this project is to establish a strong foundation for all large scale movement tracking applications and address the key systems issues faced in such applications. The project applies rigorous mathematical analysis, experimentation on a large scale sensor network testbed, and real-life deployment of a campus-wide object tracking system called AutoWitness to design, develop, and evaluate the algorithms and protocols developed in this project. In addition to providing hands-on research experience to undergraduate and graduate students in building a real wireless sensor network, the AutoWitness system is expected to help reduce property thefts in a university campus.","title":"NeTS-NOSS: Collaborative Research: Doing More with Less: Tracking Movements Using a Sparse Sensor Network","awardID":"0721983","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["541501","523520"],"PO":["565303"]},"127463":{"abstract":"The goal of this project is to develop a novel framework for preserving privacy in distance based data mining. This research helps protect the privacy of sensitive data such as medical exam reports and, at the same time, allow the discovery of interesting patterns using distance based mining algorithms. The approach in this project consists of a pre-processing step to de-correlate the data and an additive perturbation step to provide worst-case privacy guarantees. This approach also provides the necessary and sufficient conditions for such guarantees. In addition, modifications are made to existing distance-based data mining algorithms so that these algorithms can run accurately on the perturbed data. <br\/><br\/>The results of this project provide privacy preserving data mining techniques with both worst-case privacy guarantees and high accuracy of mining results. These techniques have potential applications in many areas, especially in critical areas such as law enforcement where finger prints, foot prints, and facial images are matched using distance-based algorithms. This research is also linked to educational goals through dissemination of the results to K-12 educational and outreach programs, undergraduate and graduate courses, and interdisciplinary conferences and workshops. The results of this project will be disseminated via the project website: http:\/\/www.is.umbc.edu\/privacy_research","title":"IIS-IPS: A privacy-preserving framework for distance-based mining","awardID":"0713345","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7486","name":"INFORMATION PRIVACY & SECURITY"}}],"PIcoPI":["353503",338027],"PO":["565136"]},"125285":{"abstract":"CCF-0702798<br\/><br\/>Mimir: A Geometric Approach to Multi-dimensional Program Profiling Architectures<br\/><br\/>Timothy P. Sherwood<br\/><br\/>While mixed static-dynamic program analysis can be done completely in software through binary instrumentation, the amount of analysis that can be done at test-time is bounded by the performance impact that can be tolerated. The end goal of the Mimir project is to enable a new breed of hardware\/software analysis tools, for researchers and system builders that can sift through on-line profile data at unprecedented speeds, yielding a highly accurate and timely image of computer system execution. The cross-layer approach to be investigated combines the raw computational ability of custom architectures with the formal guarantees provided by carefully crafted stream algorithms. At a high level, the proposed algorithmic approach to profiling is grounded in geometry, implicitly motivated by the belief that many profiling patterns, trends, or anomalies have natural geometric representations that become discernible under a geometric lens. At a low level, novel programmable hardware methods will provide a scalable and high performance substrate onto which these stream algorithms can be mapped. The combination of these two methods will allow online monitors to make streaming queries over live data at unprecedented speeds with the goal of enabling a new class of previously intractable dynamic analysis methods.","title":"Mimir: A Geometric Approach to Multi-dimensional Program Profiling Architectures","awardID":"0702798","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7944","name":"SOFTWARE ENG & FORMAL METHODS"}}],"PIcoPI":["536698","527086"],"PO":["564388"]},"129411":{"abstract":"Wireless mesh networks are becoming popular for ubiquitous and low-cost wireless broadband connectivity. However, they, suffer from serious interference problems which limit their capacity. We use TDMA scheduling to address these performance problems. We use a SINR-based physical interference modeling for realism, and various forms of diversities - such as transmit power control, directional antennas, multiple channels, and rates - to maximize performance. We also introduce a measurement-based modeling technique to make the physical interference modeling practical. We support these innovations by experimental studies. Our goal is developing a complete set of algorithms, protocols, and system solutions that target \"managed\" mesh networks. The protocol solutions include the routing layer and below, and are compatible with existing Inter-networking protocols for the transport layer and up.<br\/><br\/>The project's intellectual merit has the following components: (i) New protocols for TDMA scheduling with diversity and physical interference modeling, (ii) integration of scheduling with routing, (iii) measurement-based modeling of physical interference, and (iv) simulation modeling and testbed experiments to support the protocol innovations.<br\/><br\/>The project contributes to the education and training of graduate students in the two universities -Georgia Tech and Stony Brook University. The project gains leverage from existing international collaborations of PIs with IIT-CNR in Italy and CDAC in India, and strengthens this collaboration. Finally, success in this project means low cost, ubiquitous broadband connectivity. It competes well with WLANs and wired connectivity, and is expected to level the technological playing field.","title":"NeTS-WN: Collaborative Research: A Measurement-Driven Physical-Interference-Based Approach for the Design of Mesh Networks","awardID":"0721596","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["562753","562577"],"PO":["565090"]},"128201":{"abstract":"We live in the information age, a time when data and knowledge is plentiful and easily moved, processed and mined by machines. This makes it easier to discover knowledge and more efficiently manage our affairs but also increases concerns about information confidentiality, privacy and trust. Balancing these will be a defining challenge in the coming decades and is particularly urgent today in organizations responsible for national defense, law enforcement, emergency services, and public health and safety. The 9\/11 Commission addressed this in their report and called for \"a paradigm change from Need to Know to Need to Share\". This project will explore one concrete aspect of this shift -- how executable policies can help organizations enhance their ability to share information and access while still maintaining appropriate levels of security, confidentiality and privacy.<br\/><br\/>The University of Maryland, Baltimore County, the University of Texas at San Antonio and the University of Texas at Dallas will build on existing work at our three institutions to develop and refine a a conceptual framework for computational policies to support information sharing in a need to share environment. Our framework will integrate and extend our work on access control (RBAC), usage control (UCON) and deontic policies (REI), grounding them in ontologies expressed in the Semantic Web language OWL. We will use it to design a policy specification language and enumerate required software artifacts and tools. Finally, we will study the framework applicability to realistic applications such as the management of healthcare records and homeland security related data.","title":"CT-T: Collaborative Research: A Semantic Framework for Policy Specification and Enforcement in a Need to Share Environment","awardID":"0716424","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"H228","name":"CIA"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"H309","name":"CIA"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["551857","562519","558641"],"PO":["565136"]},"129532":{"abstract":"Two important features distinguish wireless communication from wireline communication: the time-variations of the wireless links and the broadcast property of wireless transmissions.<br\/>In the past decade, a new fundamental understanding of time-variations from an information theoretic point of view has developed. This understanding has led to radical shifts in points of view regarding wireless system design, not only at the physical layer but also at<br\/>higher layers. In contrast, the progress in a fundamental understanding of the broadcast nature of wireless links has been far slower. Most of the techniques that exist as implemented in current wireless networks to deal with interference and cooperation are ad hoc.<br\/><br\/>In this project we focus on the broadcast nature of the wireless link by taking a cue from the success in dealing with the time varying nature of the wireless link: true progress in wireless communication comes from a synthesis of a fundamental and information theoretic understanding into networking ideas.<br\/><br\/>We propose to (a) obtain a fundamental understanding of how to optimally manage interference and achieve cooperation, (b) build an abstraction of the physical layer that captures the performance benefits of optimal interference management and cooperation, and (c) identify scenarios in which such optimal techniques yield significant improvement beyond<br\/>current techniques. We envision the broader impact of this research agenda to influence the design rules by which the interference and cooperation are dealt with in next generation of wireless networks.","title":"NeTS-WN: Collaborative Research: Interference Management and Cooperation in Wireless Networks: A Modern View","awardID":"0722032","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["523728"],"PO":["557315"]},"127233":{"abstract":"This project develops systems that use machine learning to construct semantic analyzers for natural language by training on sentences paired only with their perceptual context. The PI's previous research developed systems that acquire semantic parsers by training on sentences annotated with formal meaning representations; however, the demands of building such annotated corpora limit the scope and accuracy of the resulting systems. This project extends these methods to learn language more like a human child, using only exposure to utterances in context. In order to temporarily circumvent the limitations of existing computer-vision and robotic systems, the project primarily studies the problem in simulated environments. It uses the Robocup soccer simulator as one domain in which to explore language acquisition. Existing methods for abstracting a description from the physical simulator state are used to construct a symbolic representation of the perceptual context. When learning from perceptual context instead of direct supervision, a system must address referential uncertainty, i.e. a sentence may refer to a multitude of different aspects of the current environment.<br\/>Consequently, this project designs, implements, and evaluates algorithms that can learn from sentences paired only with ambiguous supervision. The effectiveness of the techniques developed are evaluated in experiments in the Robocup environment and other applications. The techniques developed can eventually be ported to real robots, allowing for an integration of language and perception in robotics. By increasing our understanding of how language can be acquired from its use in context, the project should also provide insight into human language learning.","title":"RI: Learning Language Semantics from Perceptual Context","awardID":"0712097","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["450689"],"PO":["565215"]},"127354":{"abstract":"The goal of this research project is to facilitate the sharing of information across enterprise boundaries, by facilitating the integration of separately constructed data bases. Because such data bases never have identical content, it is necessary to write transforms (or adaptors) to convert such disparate data into a common form. The construction of such transforms is widely believed to be a major cost of data integration projects. <br\/>The purpose of the Morpheus project is to capture a large number of such transforms in a repository by crawling the web for publicly available ones and providing high level tools for efficient transform construction. In addition, powerful browsing tools are anticipated that allow users to locate \"\"interesting\"\" transforms quickly in the repository by providing keyword search of documentation, search within a classification hierarchy of transforms, search by the provenance of transforms, as well as search by the input\/output characteristics. <br\/>Morpheus is expected to dramatically reduce the cost of writing and maintaining data integration transforms, which will ease the difficulty of future data integration projects. <br\/>This project will support graduate students at both Massachusetts Institute of Technology and University of Florida. In addition, transform construction will be used as student exercises in data base classes at both institutions. Further information can be obtained from the project web site: http:\/\/www.cise.ufl.edu\/~jhammer\/morpheus\/ where research results will be disseminated and prototype code will be available.","title":"III-COR: Collaborative Research: The Morpheus Data Transformation Management System","awardID":"0712799","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["19581",337768,337769],"PO":["543481"]},"128212":{"abstract":"The project proposes \"manifest security\" as a new architectural principle for secure extensible systems. Its research objectives are to develop the theoretical foundations for manifestly secure software and to demonstrate its feasibility in practice.<br\/><br\/>Manifest security applies to extensible software platforms, where it addresses two fundamental problems: (1) how to specify policies about what resources an extension may use and how it can handle sensitive data, and (2) how to enforce such policies. The project is developing a novel high-level logical specification language, encompassing both authorization properties for access control and information flow properties to restrict the use of sensitive data. Adherence to the specification is enforced by a combination of static and dynamic methods, and trustworthiness of the code is established by the explicit representation and verification of formal proofs. Such proofs make the security properties manifest.<br\/><br\/>Because extensible systems are in widespread use (for example, in web browsers, office software, media players, games, virtual communities, and operating systems) the concept of manifest security has significant potential for broad impact. Rigorous verification methods based on logic and type theory are increasingly important to the software industry; the project advances the use of these methods to ensure security. Results from the research are released via publications and a software platform for secure browser extension, making advances accessible to researchers and practitioners. Results are being integrated into graduate and undergraduate teaching materials as well as courses at summer schools.","title":"CT-T: Collaborative Research: Manifest Security","awardID":"0716469","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":[339843,339844,"485877"],"PO":["497499"]},"129785":{"abstract":"Proposal #: CNS 07-22943<br\/>PI(s): Okamura, Allison M.<br\/> Cowan, Noah J.; Hager, Gregory D.; Kazanzides, Peter.; Taylor, Russell H\/<br\/>Institution: Johns Hopkins University <br\/> Baltimore, MD 21218-8268<br\/>Title: MRI\/Dev.: Infrastructure for Integrated Sensing, Modeling, and Manipulation with Robotic and Human-Machine Systems<br\/><br\/>Project Proposed:<br\/><br\/>This interdisciplinary project, developing infrastructure for sensorimotor integration that fosters new studies and enhances existing work in the area of manipulation for robotics and human-machine systems, aims to offer a publicly available systems framework, including software, mechatronics, and integrated hardware. Enforcing a general development approach that can be easily extended to other robotic and human-machine applications, two complementary robotics platforms will built addressing two different application domains: a<br\/>. Bimanual dexterous manipulation system with integrated environment sensing and the capability for modeling rigid objects commonly found in human environments, and<br\/>. Teleoperated surgical robotic system with integrated sensors that can acquire patient-specific deformable tissue models.<br\/>Moreover, via the project's website, dissemination is planned for:<br\/>. Open-source software for real-time system control and sensor\/model\/manipulation\/display integration;<br\/>. Design of a complementary mechatronic firewire controller board that includes A\/D, D\/A, encoders, amplifiers, and low-level control capabilities via FPGS, and<br\/>. Detailed descriptions of hardware integration, including WAM arms, Barrett hands, a tactile sensing suite from Pressure Profile Systems, surgical robots, cameras, ultrasound, OCT, a vision-based tracking system, visual and haptic displays, and more.<br\/><br\/>Broader Impact: Integrated robotic systems that fuse multimodal sensory information to enhance models and manipulate the environment positively impact human lives, particularly in health care, safety, and human assistance. The research also impacts related disciplines, including neuroscience, rehabilitation, and surgery. Researchers will have access to open software and designs. The platforms clearly impact education, people at many career stages, from high school students to senior faculty. The system, and detailed directions on how to produce it, will be made available. The design framework will be used in undergraduate classes in conjunction with existing educational hardware; experimental platforms will be used for course projects. Visiting students and faculty (including WISE girls) will make positive use of the integrated testbeds. There is an ongoing collaboration with Morgan State U. Involving REU and RET participants, outreach is well planned. The dissemination plan includes an active web site; the software will be made available via open-source repository. Furthermore, the website documents all hardware and respective vendors.","title":"MRI: Development of Infrastructure for Integrated Sensing, Modeling, and Manipulation with Robotic and Human-Machine Systems","awardID":"0722943","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["531055","553223","520895","522960","513313"],"PO":["557609"]},"127365":{"abstract":"Abstract <br\/>Project Title: Knowledge Compilation with Fast Response <br\/>PIs: <br\/><br\/>This project is concerned with the development, maintenance, and <br\/>utilization of index structures -- reduced implicate tries <br\/>(ri-tries) -- that answer logical queries of large databases. <br\/>The primary goals of this project are further development of ri-tries, <br\/>identification and classification of databases for which these tries <br\/>will be effective, and development of computer systems that implement <br\/>ri-tries. <br\/><br\/>A reduced implicate trie is a data structure for storing a propositional <br\/>database on a computer. Fast responses to queries are enabled by <br\/>making it easy to determine consequences -- queries with yes answers -- <br\/>of the database. Technically, once a database has been compiled into <br\/>an ri-trie, the response time to any query is guaranteed to be linear <br\/>in the size of the query, regardless of the size of the compiled <br\/>database. This response time represents a trade-off between <br\/>performance and space, since ri-tries may be large. A central focus <br\/>of this project will be determining what types of databases lend themselves <br\/>to ri-tries. This will be accomplished through experimentation and <br\/>through theoretical developments. <br\/><br\/>A prototype system that compiles logical formulas into ri-tries and <br\/>a query processing module will be developed. Initially, the system <br\/>will be designed for databases in conjunctive normal form; in the <br\/>longer term, any formula from propositional logic will be acceptable <br\/>input. The query processor will be designed to accept clauses as input, <br\/>since a clause is the typical form for a query. Students at the University <br\/>of New Haven and at SUNY at Albany will be active participants. <br\/><br\/><br\/>Broader Impacts of the Proposed Activity <br\/><br\/>The RUI component of this project will be extensive participation <br\/>by undergraduates at the University of New Haven. Students will be <br\/>introduced to the basic ideas of automated deduction and knowledge <br\/>compilation and will work on the prototype system. The goal is to <br\/>inspire students by engaging them in real research that contributes <br\/>to real publications. The PI is committed to attracting talented <br\/>young men and women into mathematics and computer science and to <br\/>preparing them for graduate school. The University at Albany has a <br\/>strong graduate program in computer science, and the PI at Albany <br\/>is committed to preparing students for careers in research. <br\/><br\/>Project Web Page: http:\/\/www.cs.albany.edu\/~nvm\/ritries\/ <br\/>Erik Rosenthal's Web Page: http:\/\/www.newhaven.edu\/show.asp?durki=1623 <br\/>Neil Murray's Web Page: http:\/\/www.cs.albany.edu\/~nvm\/","title":"III-COR: Collaborative Research: Knowledge Compilation with Fast Response","awardID":"0712849","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[337797],"PO":["560586"]},"129202":{"abstract":"This research focuses on the design, implementation, and evaluation of an advanced execution system, called REEact (Robust Execution Environment), which dynamically adapts an application's execution to the runtime resources landscape originating from the sources of heterogeneity in a next generation multi-core (CMP) chip.<br\/>The sources of heterogeneity of interest are those that arise from process variation that impacts the maximum performance of individual cores and memory blocks, from power optimizations such as DFVS that result in varying core performance over time and core shut down due to thermal emergencies, and from reliability effects resulting in cores that must be disabled due to permanent faults that occur in the field. REEact is a type of virtual execution environment (VEE) that mediates, controls, and adapts the application's execution. It employs a combination of techniques to adapt both the hardware resources and the application's software code to accommodate the heterogeneous nature of the CMP to provide the best performance and power solution where not all of the CMP cores and\/or memory blocks are available. <br\/>This research impacts CMP technology by enabling the use of these architectures for high performance computing. With effective strategies for managing heterogeneity, scientists, consumers and business people will more effectively use high-performance applications, leading to greater advances in areas such as pharmaceutical development, financial market forecasting, and environmental science model\u00acing. This research impacts both undergraduate and graduate students through their involvement in the research projects and through courses and course modules on CMPs.","title":"Collaborative Research: CSR-AES: REEact: A Robust Execution Environment for Fragile Multicore Systems","awardID":"0720789","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["385658","438734"],"PO":["493916"]},"127387":{"abstract":"Graphical representations often comprise an integral part of highly interactive interfaces to enhance human insight and creativity. The benefits of such interfaces are for the most part denied, however, to individuals who are blind or visually impaired, who are as a consequence are placed at a significant disadvantage with respect to learning throughout their lives. For young children, graphical representations in books are often critical for developing a vocabulary, as many objects cannot easily be obtained or safely handled physically. Later on, examination and interpretation of graphical information such as experimental time series data, mathematical waveforms and geographical diagrams are crucial for obtaining insight in these areas and a sign of creativity. Currently, the most frequent method of representing 2D graphical information so as to make it accessible to individuals who are blind or visually impaired is through static raised-line drawings, but this method is very poor at relaying information in unconstrained tasks such as those mentioned above. In this project the PI adopts a novel alternative haptics-based approach to address the challenge of developing more suitable interactive methods and appropriate representations that enhance understanding of unfamiliar information (whether patterns, groups of items, or individual items) and improve the user's ability to make discoveries or propose explanations. She will develop highly interactive graphics technology that allows the user to actively and separately control both the magnification and simplification of a graphic during its examination. This will allow the user to customize and vary as needed the trade-off between the two main limitations of haptic processing: the need to serially integrate information, and poor tactile spatial resolution. The enriched representations will use texture or vibration as a way to encode the separation of a graphic into objects and object parts, and to describe the 3D orientation of parts, which are two of the most difficult aspects of interpretation. The project will be conducted with input and feedback from members of the target user community, and validated experimentally.<br\/><br\/>Broader Impacts: This research will help move knowledge about human haptic processing from theory to practice. As the focus is on developing enabling technologies for higher level thinking skills, the project will empower individuals who are blind or visually impaired (and ultimately all users) with new tools to make more significant contributions to society. Thus, the work will in particular contribute to the effort of preventing individuals from the target community being left further behind as information technology advances forward, and will enable them to enjoy a better income and quality of life.","title":"HCC: Interactive and Enriched Haptic Graphical Representations for People who are Blind and Visually Impaired","awardID":"0712936","effectiveDate":"2007-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["518233"],"PO":["565227"]},"128124":{"abstract":"The goal of this project is to gain better insights and procedures in the area of timestamp analysis for computer forensics investigations.<br\/>Timestamps are used frequently in the investigations of computer incidents and also when analyzing digital evidence related to real-life crimes. They are used to establish the order of events that occurred on a computer, or to tie virtual events to those in the real world. The time-lining of events is common practice in the analysis of digital evidence. However, computer clocks may differ from the ``real time'', and they continuously drift ``away'' from that time, depending on the quality of those clocks. The consequences of these phenomena for a forensic investigation are yet unknown.<br\/><br\/>This research extends an existing model to correlate timestamps, which is based on having available complete information about a clock. Given a timestamp found on a computer, the investigator wants to map it to a reference time. This research expands on the basic model, so that error or uncertainty rates can be established, different scenarios of what might have happened on a computing device may be conjectured and analyzed, the ordering of events can be taken into account, and time information that may have originated from external clocks can be considered.<br\/><br\/>This project advances our understanding of how timed events relate to each other in distributed computing systems. It enables us to order events from disparate sources of digital evidence and quantify the error rate or uncertainty that arises due to granularity and accuracy constraints.","title":"CT-ER: An Analysis of Distributed Timestamps for Computer Forensic Investigations","awardID":"0716131","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["492610"],"PO":["529429"]},"127035":{"abstract":"Orthologous genes, or orthologs, are genes in different species<br\/>that have evolved directly from a common ancestral gene.<br\/>Genome-scale assignment of orthologs is a fundamental and<br\/>challenging problem in computational biology, and has a wide range<br\/>of applications in comparative genomics and functional genomics.<br\/>This project continues the development of the parsimony approach<br\/>for assigning orthologs between closely related genomes <br\/>which essentially attempts to transform <br\/>one genome into another by the smallest number of genome rearrangement<br\/>events including reversal, translocation, fusion, and fission, as well as<br\/>gene duplication events. The project addresses three key algorithmic<br\/>problems including (i) signed reversal distance with<br\/>duplicates, (ii) signed transposition distance with duplicates,<br\/>and (iii) minimum common string partition. Efficient solutions to each of<br\/>these problems are combined and incorporated into a software system for <br\/>ortholog assignment, called MSOAR. The project encompasses <br\/>genome-wide analysis of orthologous (and paralogous) relationships on <br\/>the human and mouse genomes to valdiate the approach, and more importantly,<br\/>to address several important evolutionary biological questions including <br\/>the characterization of gains and losses of duplicated genes in the <br\/>two genomes, the elucidation of gene movements in one genome with respect <br\/>to the other genome, and the quantification of different mechanisms of <br\/>gene duplication.<br\/><br\/>Intellectual merit.<br\/><br\/>The parsimony approach presents a novel method for performing genome-wide<br\/>ortholog assignment that takes into account both gene sequences and locations.<br\/>The above algorithmic problems are new in the literature and their solutions<br\/>likely require the introduction of novel algorithm design and analysis<br\/>techniques. The questions regarding gene duplication and quantification of <br\/>the duplication mechanisms in model species are of fundamental importance <br\/>in evolutionary biology.<br\/><br\/>Broader impact.<br\/><br\/>As ortholog assignment is a fundamental problem in comparative genomics and<br\/>has become a routine practice in almost all areas of genomics, MSOAR<br\/>will find itself a wide range of applications in biology and genomics.<br\/>Moreover, the research will provide the training opportunity for two computer <br\/>science graduate students in the interdisciplinary field of computational biology.<br\/><br\/>Information concerning this NSF project will be provided at the website:<br\/>http:\/\/msoar.cs.ucr.edu\/","title":"III-CXT: Collaborative Research: A High-Throughput Approach to the Assignment of Orthologous Genes Based on Genome Rearrangement","awardID":"0711129","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["538402"],"PO":["560586"]},"129697":{"abstract":"Proposal #: CNS 07-22625<br\/>PI(s): Apon, Amy W.<br\/> Bellaiche, Laurent; Fu, Huaxiang; Pulay, Peter; Thompson. Craig W.<br\/>Institution: University of Arkansas<br\/> Fayettesville, AR 72701-1201<br\/>Title: MRI\/Acq.: Supercomputer Cluster for Computational & Data-Intensive Applications in Science & Engineering<br\/><br\/>Project Proposed:<br\/>This project, acquiring a cluster for computational and data intensive applications, aims to enable projects in computer science, physics and chemistry, including<br\/>. Grid Capacity Planning, focusing on grid workload and systems characterization and building simulation models or performance analysis, capacity planning, evaluation of scheduling, and data placement;<br\/>. Approach to Design Low Loss, Tunable Ferroelectric Material, resolving dialectric loss at finite frequency and temperature for microscopic understanding of loss mechanism(s);<br\/>. Discovering New Physics of Nanostructured Materials to understand and discover new physics in novel types of nanomaterials;<br\/>. Developing Methods for Parallel Computing to Improve Fourier Transform Coulomb (FTC) and Efficient Implementation of Triple Substitutions in Coupled Cluster Theory;<br\/>. Data Indexing and Middleware, including RFID middleware, Synthetic data generation service, Subsetting the workflow grid, VMlab, and Technology transition;<br\/>. Computational Design of Self-assembly Systems for Nanostructured Formation;<br\/>. High Performance Computing for Spray Cooling Modeling and Nanofluids; and<br\/>. Atomistic Calculations of Interface Behavior in Nanostructured Materials.<br\/>The computing cluster, an integrated supercomputing platform for distributed memory parallel applications, also enables collaborative courses in high-performance and grid computing.<br\/>Broader Impact: The infrastructure contributes to outreach activities such as seminars and academic courses, attracting new users and building computational expertise in the region, as well as in the training of students.","title":"MRI: Acquisition of a Supercomputing Cluster for Computational and Data-Intensive Applications in Science and Engineering","awardID":"0722625","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["516195","540643","475852",343838,343839],"PO":["557609"]},"129103":{"abstract":"The EncoreJ project is developing tools and libraries for transparent rewriting of Java code, making distributable Java applications resilient in the face of execution node reconfiguration and failure. Developers control the system, but EncoreJ automatically rewrites compiled Java code, as packages are loaded, adding support for creating, accessing, and computing upon local and remote objects, and for resilience in the face of system failures and reconfigurations. EncoreJ further interfaces with a variety of persistence mechanisms (e.g., databases), both for providing fundamental resilience (saving\/restoring information) and for coordinating recovery with the mechanisms of the external database.<br\/><br\/>EncoreJ exploits resiliency support to make it easy to reconfigure applications as the host platform evolves, adding and removing resources dynamically; e.g., a virtual node might go down and be replaced by another, in order to force work to move to a newly available system. Programmers describe \"\"on the side\"\" (without modifying source code), how to place, move, and replicate objects and computations; the source code remains the primary mechanism for expressing algorithms clearly without hard-coded details of distribution or resilience.<br\/><br\/>The EncoreJ tools and prototype are a platform for research by the wider community working on policies\/algorithms for migration, replication, scheduling, etc., in Grid systems. The focus is a convenient and flexible platform, powerful and extensible, without over-commitment to any particular policies or strategies. EncoreJ builds on readily available and standard systems (Java virtual machines and packages) to ensure wide applicability and easy distribution and adoption.<br\/><br\/>This award is seed funding for project development.","title":"CSR-AES Collaborative: Encore\/J: Transparently Recoverable Java for Resilient Distributed Computing","awardID":"0720505","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["562118"],"PO":["551712"]},"129345":{"abstract":"The eFIT (Enabling Future Internet innovations through Transit wire) project aims to enable future innovations by ensuring strong universal connectivity at the architectural level. Innovations are enabled by the abundant and affordable computing resources provided by Moore's Law, and universal connectivity provided by the Internet. Computing resources are likely to become more plentiful and affordable, but the universal connectivity provided by the Internet is facing major challenges, as demonstrated by the prevalent use of network address translation (NAT) and accelerated growth of the global routing table. The current Internet architecture provides end-to-end connectivity by putting both user networks and Internet service providers (ISPs) in the same address and routing spaces. User networks and ISPs have different purposes, distinct characteristics, and are moving in almost opposite technological directions. However the inter-dependency between network users and ISPs imposed by the existing architecture creates a major roadblock to future Internet innovations.<br\/><br\/>When a system grows larger in size by orders of magnitude, a change in form becomes necessary. The eFIT design enables innovation by first focusing on universal connectivity. eFIT places user networks and provider networks in different address and routing spaces, removing the inter-dependency between the two worlds. With eFIT, users can simply treat the Internet transit core as a transit wire with strong universal connectivity, while providers are insulated from the various problems caused by explosive growth in user networks. Therefore both users and providers will be able to innovate freely on their own without any architectural constraints.<br\/><br\/>Broader Impact: This new architecture design will have a broad impact on the research community, service providers, and Internet users. eFIT enables graduate students to explore new directions for fundamental problems such as security. Even more broadly, it will liberate Internet users from the current architectural constraints and encourage a new wave of application innovations.","title":"NeTS-FIND: Collaborative Research: Enabling Future Internet innovations through Transit wire (eFIT)","awardID":"0721369","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["559197"],"PO":["565090"]},"129587":{"abstract":"Proposal Number: 0722234<br\/><br\/>Title: CPATH CB: Connecting Computing Educators Within and Outside the Traditional Boundaries<br\/><br\/>PI: Lillian Cassel<br\/><br\/>The primary focus of this one-year activity will be workshops to bring together those in the computing education community, across the subdomains of that group, and others who are integrating the fruits of computational thinking into a wide variety of disciplines. It is common to find curricula in the arts (music, graphical design), business (accounting, economics), sciences (biology, chemistry, physics), and social sciences with computational courses in their curriculum. In the one year of this project, the workshops will focus on identifying the scope of the similarities and differences among these communities and in identifying ways in which the computing community can best serve the entirety of the expanded community. The project will begin the integration of the computing ontology into the organization of curricular materials and the use of social software to deliver essential information. A centralized website will provide RSS feeds with news about computing education, blog entries about computing education, links to resources, and other community oriented information (e.g., conference calendars). Workshop participants will include faculty from all of the computing disciplines, industry representatives, students, and faculty from disciplines we do not usually think of as computing intensive.","title":"CPATH CB: Connecting Computing Educators Within and Outside the Traditional Boundaries","awardID":"0722234","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}}],"PIcoPI":["83531"],"PO":["562944"]},"129367":{"abstract":"In deployment of sensor networks for various applications, sensors need to be placed in the areas of difficult terrain and natural obstacles. In such settings, many existing algorithms may perform poorly or may have high overhead while inefficiently consuming energy. One approach is to utilize mobile sensors in these situations, such as sensors with wheels. However, mobile wheeled sensors may not be able to move to the desired locations in the areas of difficult terrain with obstacles. Wheeled sensors can also be very expensive. A hopping sensor is a type of mobile sensor with a bionic mobility design that is inspired by creatures, such as grasshoppers. These sensors are still at an interesting concept stage. This proposal addresses the design, prototyping, and evaluation of hopping sensors and efficient algorithms for sensor deployment in difficult areas and rugged terrain. We focus on four research issues that are critical to the effective deployment and management of large scale sensor networks in such settings: robust and power-efficient hopping sensors, sensor localization, sensor coverage, and deployment of a self-adaptive all terrain sensor networks equipped with the hopping sensors and the proposed algorithms, which is called LEAPNet. Most future sensor networks are likely to be deployed in our targeted environments, and hence this research will benefit real-world applications such as monitoring ecosystems, disaster relief, and military reconnaissance. Strong collaborative efforts will be made to provide efficient and practical solutions with solid engineering designs and strong algorithmic foundations for this purpose. In addition, an innovative integration of the proposed research and education program will provide students with analytical skills and hands-on experiences by emerging technologies, which will better prepare them for strong technical careers in this rapidly growing and changing area.","title":"NeTS-NOSS: Collaborative Research: LEAPNet: Self-adaptable All Terrain Sensor Networks","awardID":"0721441","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["512771","550894","550895"],"PO":["565303"]},"129488":{"abstract":"In this project, the PIs will focus on the emerging Dynamic Spectrum Access (DSA) Wireless Mesh Networks (WMNs). Cross-layer design is strongly needed for such a network due to its two special features; dynamic spectrum availability and spectrum heterogeneity. Quite different from other well-studied wireless networks, such as mobile ad hoc networks and wireless sensor networks, the major concerns of WMNs are throughput, fairness, and QoS support, instead of mobility support and power efficiency.<br\/><br\/>The PIs plan to conduct a comprehensive study on cross-layer optimization in DSA WMNs, and design protocols under the guidance of this cross-layer optimization. They will concentrate on the bottom four layers of the network stack and seek joint congestion control, routing, spectrum sharing, and power control solutions with the objective of maximizing throughput, achieving certain fairness, and providing QoS support. Furthermore, the research will be conducted under various network models including different interference models, different traffic models, and different fairness models.<br\/><br\/>The INTELLECTUAL MERIT of the project includes (1) a unified mathematical model which precisely characterizes all important features and the formal formulations of the cross-layer optimization problems under different network models, (2) centralized and distributed algorithms for solving the optimization problems, and (3) a spectrum-aware routing protocol.<br\/><br\/>The BROADER IMPACT of the project includes (1) novel cross-layer schemes for emerging DSA WMNs, with impact on the advancement of information technology, (2) high quality publications and training of highly skilled students, and (3) possible impact on the standardization in IETF and IEEE for DSA wireless networks in the future.","title":"NeTS-WN: Collaborative Research: Cross-layer Optimization for Dynamic Spectrum Access Wireless Mesh Networks","awardID":"0721880","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["445979"],"PO":["557315"]},"129136":{"abstract":"When the Internet protocols were standardized in the late 80s, most distributed applications were point-to-point, such as email, telnet, and ftp. Over the last few years, the nature of Internet traffic has changed dramatically. Driven by the production and distribution of vast amounts of user-created content, current Internet traffic is overwhelmingly many-to-many, leading to a mismatch between application demand and the underlying protocols.<br\/><br\/>This project is to develop a peer-to-peer solution, called OneSwarm, to serve as a universal communication layer for multi-point communication. By relying solely on software running on end-hosts, OneSwarm will avoid the high operational cost of infrastructure solutions and the deployability issues of clean-slate redesigns to the network architecture. Among the open questions that need answers: can swarming techniques work and meet desired levels of service quality when content files are no longer large, when there are strict deadlines on delivery, when the communication is not all-to-all, or when different nodes have different needs, all without working at cross-purposes to ISP objectives? This proposal will also investigate incentives to encourage end hosts to contribute resources to support demanding applications, by allowing users to trade resources across time, across swarms, and across applications.","title":"CSR-PDOS: Scalable Peer-to-Peer Data Dissemination","awardID":"0720589","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["549890","463055"],"PO":["493916"]},"129378":{"abstract":"Energy-management is essential for wireless sensor networks to prolong network lifetime and to increase the amount of useful information conveyed. There is potential to substantially improve the energy efficiency of sensor networks by exploiting cross-layer interactions among various networking layers and functionalities. However, such a cross-layer solution could also become impractically complex and difficult to implement. To address this challenge, this collaborative NSF-funded project at The Ohio State University and Purdue University aims to develop a suite of high-performance cross-layer mechanisms for sensor networks that are simple, modular, distributed, and provably energy-efficient. The key distinguishing feature of the project is that the mechanisms developed are based on a solid theoretical foundation that rigorously manages both performance and complexity with the goal of practical implementation. The PIs will investigate four major functionalities that are crucial to the efficient operation of energy-constrained wireless sensor networks, including joint medium-access and routing, sleep\/wake scheduling, in-network aggregation\/computation, and reliable broadcast. The theoretical solutions developed in this project will be implemented and evaluated on two testbeds: the existing Kansei testbed at OSU, and a prototype deployment (SENSE@OSU).<br\/><br\/>Broader impact: The collaborative research will have a significant impact on wireless industry sectors, and will lead to breakthroughs in our understanding of the fundamental limits for developing energy-efficient distributed solutions for sensor networks. The PIs will also continue their current efforts to recruit and train women and under-represented minority groups both at the undergraduate and graduate levels.","title":"NeTS-NOSS: Collaborative Research: Energy-Efficient Distributed Sensor Network Control: Theory to Implementation","awardID":"0721477","effectiveDate":"2007-09-01","expirationDate":"2011-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["382234"],"PO":["557315"]},"128289":{"abstract":"This project will evaluate vulnerabilities in relatively unstudied model-based recommendation systems in which recommendations are based on a model that relates ratings on one item to ratings on other items. Recommendation systems are a means of reducing \"information overload\" by filtering a potentially overwhelming number of options (such as all the products available from a seller) to identify those calculated to be of greatest interest. This project extends research on collaborative recommendation systems, which base recommendations for an individual on the preferences expressed by other people, by investigating the problem of malicious manipulation of these systems, for example, by an attacker attempting to influence the outcome with biased or faked rating profiles. Research suggests that a specific model-based systems exhibit much more resistant to recommendation attacks than memory-based systems in which recommendations are based on the principle of finding similar users or similar items. Moreover, this research will identify any previously unknown attack methods that might be specifically effective against model-based recommendation systems.","title":"CT-ISG: Collaborative Research: Detecting and Preventing Attacks in Recommendation Systems","awardID":"0716827","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["560876"],"PO":["529429"]},"129389":{"abstract":"Aggregations of massively deployed sensors are expected to create sophisticated sensing, computation, communication and control platforms called Networked Sensor Systems (NSS) that will pervade society, revolutionizing the way in which we live and work. In order to scale, these systems must be largely autonomous, decentralized entities whose corporate resources can be made available to authorized users. Such autonomous, geographically-dispersed NSS are increasingly recognized as key to numerous applications ranging from healthcare to smart homes and homeland security. For example, autonomous NSS can assist first responders, often in inhospitable environments, by locating survivors, identifying danger areas and enhancing user awareness of the situation The resource-constrained sensors, the wireless communication medium, the large-scale deployment, combined with the mobility of users, the close interaction with the physical environment and the highly sensitive nature of mission-critical operations pose formidable challenges to autonomous NSS design. The key inter-related technical contributions of this project are: (1) Dynamic task-based networking supporting application-level tasks and queries while hiding resource-level details; (2) Smart AFN mobility subject to changing application requirements and network conditions; and (3) providing secure ANSWER operation and multi-level secure interactions with in-situ mobile users. ANSWER prototype can serve as a tool to explore mobile user behavior in ubiquitous networks under varying environmental and network conditions. This project will leverage programs at VT, UMBC, and ODU to actively recruit and involve under-represented groups in innovative multi-disciplinary hands-on experiments in ubiquitous networking, security and sensor systems. The research results will be disseminated via the project's Web site (http:\/\/www.nve.vt.edu\/cias\/cycarenet\/ANSWER).","title":"Collaborative Research-NeTS-NOSS: AutoNomouS netWorked sEnsoR systems (ANSWER)","awardID":"0721523","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["296385","474437"],"PO":["564993"]},"129158":{"abstract":"The use of software to control devices deployed, for example, in medical, transportation, and power systems demands correct software operation. Current approaches to assuring the correct operation of embedded software face significant challenges in scaling to the next generation of embedded applications. A promising strategy for meeting these challenges is to deploy \"\"monitoring\"\" software that will \"\"watch\"\" and \"\"warn\"\" of problematic situations that the operational software should adapt to avoid. Unfortunately, current approaches for software monitoring result in excessive overhead and are not sensitive to the fundamental timeliness requirements in embedded software.<br\/><br\/>This project is investigating technologies for the timely and efficient monitoring of software in embedded systems. Specifically, the project explores the synergistic combination of three approaches: (1) exploiting the results of static analysis to calculate a minimal \"\"residual\"\" analysis problem to be monitored at run-time, (2) \"\"adapting\"\" the degree of observation of the software dynamically during execution while preserving the fidelity of monitoring, and (3) using scheduling techniques to ensure that monitors detect patterns of software behavior with a \"\"predictable\"\" worst-case delay. Together these techniques are being combined into a single predictable, adaptable, residual (PAR) monitoring infrastructure within which a variety of implementation strategies will be realized. Evaluation of the cost-effectiveness of these techniques will be carried out in the context of RTSJ and sensor-network infrastructures and applications. These techniques and the PAR infrastructure are the basis for projects in both real-time systems and software validation courses to train the next generation of embedded software engineers.","title":"CSR-EHS Predictable Adaptive Residual Monitoring for Real-time Embedded Systems","awardID":"0720654","effectiveDate":"2007-09-01","expirationDate":"2012-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["561782","486378","518212"],"PO":["561889"]},"133591":{"abstract":"Spelman College proposes the ARTSI (Advancing Robotics Technology for Societal Impact) Alliance in collaboration with Florida A&M University, the University of the District of Columbia, Hampton University, Morgan State University, Norfolk State University, Winston-Salem State University, the University of Arkansas-Pine Bluff, Carnegie Mellon University, Georgia Institute of Technology, Brown University, Duke University, the University of Alabama, the University of Washington, and the University of Pittsburgh. Seven of these partners are HBCUs and seven are Carnegie Research I institutions. Their collaboration joins the strengths of HBCUs in conducting outreach and education in a nurturing learning environment with those of the R1's for conducting world class research. The ARTSI Alliance will motivate students to pursue computer science careers by emphasizing the creativity and socially beneficial aspects robotics technology with hands-on projects, curriculum, and media. ARTSI activities will span the academic pipeline from K-12 through the faculty ranks. At the K-12 level, students will be recruited with community outreach using robotics and art, robotics road shows, and a robotics educational film online repository. At the undergraduate level, HBCU students will be exposed to new robotics curriculum, and they will be encouraged to pursue advanced training in graduate school through summer research experiences, collaborative, interdisciplinary robotics projects in the arts and health, instruction in technical film documentation, student virtual film festivals, annual robotics conferences, and instruction in entrepreneurship for computer science. At the faculty level, it will increase the number of HBCU faculty who educate students in robotics and involve students in robotics research by providing faculty mentoring, summer research experiences for underrepresented faculty at R1 robotics labs, robotics summer workshops, and development and dissemination of robotics educational material through a web-based portal. The Alliance will have industry partners, including Seagate, iRobot, Microsoft Research, and Juxtopia, as well as educational partners, including Florida-Georgia Louis Stokes Alliance for Minority Participation and Computer Science Teachers Association.","title":"Collaborative Research: BPC-A: ARTSI: Advancing Robotics for Societal Impact","awardID":"0742074","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7584","name":"ITR-BROADENING PARTICIPATION"}}],"PIcoPI":["527412"],"PO":["561855"]},"131050":{"abstract":"As more and more day-to-day communication moves online, there is newfound access to large-scale data on human interactions and friendships through the records of activity in online communities. Social networks, structures encoding these interactions, contain large amounts of information about people and the social fabric that connects them. The study of these networks is an emerging interdisciplinary topic, found at the intersection of computer science with sociology, economics, and other disciplines. This research seeks<br\/>to develop basic understanding of social networks and their applications, such as marketing, epidemiology, and the search for information and expertise through trusted connections. The investigator is involving undergraduate students in the research program and is also developing educational materials based on social<br\/>networks for use throughout the computer science curriculum.<br\/><br\/>This research involves a broad array of questions related to algorithmic aspects of social networks, with two main threads. One thread is the development and study of formal mathematical models of social networks, especially focusing on models in which salient features of real-world social networks are proveably reproduced. The second thread is the systematic analysis of large-scale real-world social networks, especially focusing on the possibility of extracting useful predictive information from those networks. The investigator is simultaneously pursuing an educational plan to integrate social networks into the computer science curriculum at Carleton College, a selective undergraduate-only liberal arts college, through the<br\/>development of courses and course materials integrating complex real-world phenomena into the computer science curriculum at all levels.","title":"Algorithms for Social Networks","awardID":"0728779","effectiveDate":"2007-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7351","name":"THEORETICAL FOUNDATIONS (TF)"}}],"PIcoPI":[347913],"PO":["565251"]},"132381":{"abstract":"Manifold learning approach for nonlinear dimension reduction has drawn considerable interests from the machine learning as well as applied mathematics communities. The basic idea is to consider data as samples from a low-dimensional nonlinear manifold embedded in a high-dimensional space. Hongyuan Zha and Haesun Park propose to develop efficient computational algorithms for nonlinear dimension reduction and theoretical tools for analyzing and better understanding their behaviors as well as applications to video sequence annotation and ad-hoc sensor network localization problems, focusing on the following two important issues in manifold learning: 1) deeper understanding of the behaviors of manifold learning methods such as local tangent space alignment through analysis of the spectral properties of the alignment matrix, and developing specialized pre-conditioning methods for effectively handling ill-conditioned problems; and 2) exploring and adapting methods such as domain decomposition to develop more efficient and scalable computational algorithms for manifold learning. As applications of the proposed algorithms, video sequence annotation in the context of semi-supervised manifold learning and algorithms for ad-hoc sensor network localization problems especially for the case when the terrain is nonflat will <br\/>be developed. <br\/><br\/>Extracting compact representations of complex and high-dimensional data are at the core of many scientific and engineering endeavors. Manifold learning has become a very active research field aiming at discovering hidden structures from the statistical and geometric regularity inherent in many complex high-dimensional data. The investigators study methods that have the promise of significantly expanding the applicability and functionality of existing and new manifold learning methods and thus advancing the state of the art in manifold learning research. The proposed research lies at the interface between scientific computing and machine learning applications and provides an ideal setting for research cross-fertilization and collaboration as well as training of graduate students in interdisciplinary research. The applications in Video sequence annotation is important in surveillance analysis for homeland security and localization methods for sensor networks will contribute to the development of new generation of networking systems.","title":"Computational Methods for Nonlinear Dimension Reduction","awardID":"0736328","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["562362","549456"],"PO":["565027"]},"131072":{"abstract":"Networks underlie much of the progress in global connectivity and communications, and have enabled many of the advances in modern life. Network optimization studies networks in the abstract by formulating problems on the construction and usage of such networks. Many of the computational problems posed in this area are intractable motivating the design of heuristic approximation algorithms that run fast and deliver solutions that are provably near-optimal. The key thrust of the proposal is to design new and improved approximation algorithms for basic network problems incorporating side constraints and directionality of links building on some recent successes.<br\/><br\/>Fundamental problems in network optimization remain unresolved in their approximation guarantee achievable in polynomial time, particularly problems with side constraints (such as bi-criteria<br\/>network design problems) as well as those in directed graphs (such as the directed Steiner tree problem). This proposal addresses these shortcomings. A secondary thrust of this proposal is to formulate new network optimization problems drawing upon frameworks from Operations Research such as chance-constrained programming. The intellectual merit of the proposal include pushing the frontiers of approximation algorithms, and introducing new theoretical models for network optimization. The proposal will enable the continuation of the investigator's strong involvement in broader educational goals such as participation in invited talks, tutorials and teaching workshops, as well as new course and lecture note development. The broader impacts of the proposal include training and placement of very strong graduate students in the interdisciplinary areas of<br\/>algorithms, combinatorics and optimization.","title":"Approximation Algorithms for Network Optimization","awardID":"0728841","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["561985"],"PO":["565251"]},"131083":{"abstract":"A wide range of practical problems in the natural sciences, economics, and engineering are modeled as complementarity problems. This project involves a three-year research effort on several fundamental theoretical and computational issues related to the development, analysis, and implementation of novel interior point method for complementarity problems. The intellectual merit<br\/>of this research consists in the development of interior point algorithm with polynomial complexity and superlinear convergence for solving complementarity problems in a rather general setting.<br\/>The broader impacts will be reflected in the applicability of the theoretical results and the resulting software packages to several important areas of natural sciences, economics, and technology,<br\/>such as: simulation of multibody systems with contact and friction, robotics, hybrid systems, option pricing in mathematical finance, equilibrium problems in energy markets, etc. Another impact of the proposal is the training of students in a vital, cutting edge area.<br\/><br\/>The project is expected to contribute in tangible ways to elucidate some important problems that are still open about the behavior of interior point methods for solving linear complementarity problems over symmetric cones. Particular attention will be given to the analyticity and the curvature of<br\/>different weighted central paths and the complexity of the corresponding interior point methods. New classes of nonlinear complementarity problems over symmetric cones that are solvable in<br\/>polynomial time, either in the worst case scenario or in terms of the expected value of the number of iterations, will be identified. Furthermore, new interior point methods with polynomial complexity and superlinear convergence over a class nonsymmetric cones will be developed.","title":"Interior Point Methods for Complementarity Problems","awardID":"0728878","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["547027"],"PO":["550329"]},"133052":{"abstract":"Most word-centered linguistic annotations of texts proceed by identifying keywords and labeling the phrases around them that show their roles in the meaning structures evoked by the keywords. This procedure misses most idioms (took a turn for the worse) and irregular grammatical patterns (only then would she agree to it). The \"Beyond the Core\" project is exploring ways of augmenting such annotations with layered representations of multiword units and \"non-core\" grammatical constructions present in such texts. Toward this end, using FrameNet annotation tools, researchers are finding non-core structures in texts and labeling the phrases in a way that shows how they satisfy formal and semantic constraints dictated by the individual constructions. The \"Constructicon\", where such information is archived, links each construction with annotated sentences that exemplify it.<br\/><br\/>Although there is a strong interest in non-core structures in the Computational Linguistics community, researchers don't know how many there are, how important they are in NLP applications, how frequent they are in texts of different kinds, or whether the skills that enable trained linguists to recognize them can be reliably communicated to time-pressured annotators. This empirical study is providing that missing information.<br\/><br\/>The Constructicon and the full body of annotations will be made available to researchers via the FrameNet website, in both human-browsable and machine-readable form. The data will provide rich material for research on parsing, language understanding, and compositional semantics, and may possibly serve as a training corpus for machine-learning methods of detecting known non-core constructions in raw text.","title":"SGER: Beyond the Core: A Pilot Project on Cataloguing Grammatical Constructions and Multiword Expressions in English.","awardID":"0739426","effectiveDate":"2007-09-15","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[353897,"561714"],"PO":["565215"]},"134152":{"abstract":"This project uses a novel approach of applying expertise in perceptual science to solve the engineering problem of creating displays that are perceived veridically. This project applies a sophisticated understanding of the perceptual information needed to visually determine distances to the engineering of effective virtual environment visual displays. Distance perception involves a complex interaction between different sources of sensory information and between different aspects of the available visual information. The nature of this interaction rapidly adapts over time. Taken together, this significantly complicates our ability to understand and describe the processes involved. While perceptual psychologists have for many years manipulated visual stimuli in ways that change depth perception, the idea that we can do so in a way that is stable over time and which satisfies a variety of engineering constraints associated with virtual environment applications is novel and untested.<br\/><br\/>The project is intrinsically multidisciplinary, involving genuine collaboration between computer scientists and cognitive psychologists and leading to an exceptional educational environment. The investigators have a well established record of involving undergraduates and women in research and will continue that tradition with this work. Undergraduate students in both computer science and psychology at the University of Utah have been directly involved in research projects similar to this one, leading to high quality senior theses and journal publications.","title":"HCC: Improving Spatial Perception in Virtual Environments","awardID":"0745131","effectiveDate":"2007-09-01","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["560997","553308"],"PO":["565227"]},"127981":{"abstract":"The team proposes to develop a system to estimate the source and transmitter characteristics of HEL and Laser Communications beams from the off-axis scatter of the high energy laser (HEL) or communications laser beams. The algorithm incorporates detailed models of meteorological effects to deconvolve the state of the atmosphere on laser propagation and scattering. Analysis begins with the forward problem of laser propagation and scattering. A computational assessment tool is used to quantify the off-axis propagation in arbitrary directions for simulated) engagement geometries, defined laser characteristics, and atmospheric conditions. These simulations can be used to bound the problem and provide a database for analysis of potential algorithms for the estimation of transmitter characteristics, information content for communication beams, and possibly geophysical data. The PI developed High Energy Laser End-to End Operational Simulation (HELEEOS) software package exploits fast-running scaling law propagation methods and robust probabilistic atmospheric database to provide probability densities of atmospheric effects on laser propagation and scattering. Linking the algorithm to databases of potential sources will allow improved estimates in hypothesis testing of candidate transmitter characteristics as may be available within the intelligence community. The first year will be devoted to parametric analysis of the forward problem and definition of performance for an omniscient observer for various locations, geometries and receiving optics\/sensors. Students at a variety of levels are engaged in the research.","title":"High Energy Laser-Laser Communications Performance Assessments from Remotely-Sensed Measurements of Atmospheric Beam Scatter (18U07AFITCusu)","awardID":"0715252","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"I331","name":"Defense Intelligence Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T768","name":"DIA -MASINT RESEARCH PROJECT"}}],"PIcoPI":[339272,339273,339274,339275],"PO":["565136"]},"135373":{"abstract":"This grant will support the development of a novel Web-based visual semantic query system and a bottom-up semantic integration method to enhance the geospatial data search capability of the multi-agency Federal Web-based geospatial data portal, Geospatial One Stop (GOS). The efficiency and accuracy of data search will be increased with a searchable global view of semantically heterogeneous geospatial attributes. The results can be employed to other geospatial data portals and applications that need a solution to semantic integration. <br\/><br\/>Intellectual Merit<br\/><br\/>This project is interdisciplinary, involving GI Science, information science, and domain knowledge and will add visual semantic query functionality to geospatial portals and provide bottom-up semantic integration using local semantics without the need of an upper ontology or standardized terminology.<br\/><br\/>Impact<br\/><br\/>Broadly, this research will contribute to geospatial data integration that is an essential (but missing) component of the U.S. National Spatial Data Infrastructure. With GOS as a collaborator, a variety of users from both the public and academic community can benefit from the project results, e.g. emergency response and management activities that need a large amount of geospatial data.","title":"Developing a Visual Semantic Query System to Enhance the Search Capability of Geospatial Data Portals","awardID":"0751001","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["433346"],"PO":["371077"]},"126540":{"abstract":"The principle goal of this proposal is to build a reconfigurable Optical Burst Switching (OBS) testbed that integrates the world's first commercial optical burst switch with a reconfigurable control plane. The insights and experiences obtained from the testbed will be of great value in developing the OBS network into a commercially viable solution for the next generation Internet. The key aspects of the proposed testbed are summarized as W4:<br\/><br\/>What is the proposed testbed ? An OBS testbed utilizing commercially available EtherBurst Optical switches and FPGA based reconfigurable control plane.<br\/><br\/>Who can benefit from the proposed testbed ? The testbed will benefit the PI, as well as the OBS research community by allowing remote users to run real experiments using a remote laboratory interface. It also encourages students and industrial participation.<br\/><br\/>Why an OBS testbed is in need ? Theoretical and simulation based analysis cannot fully capture the characteristics of real traffic, which has non-negligible impact on the performance of the OBS network. In addition, simulation will not address the practical implementation issues in building ultra high speed OBS routers.<br\/><br\/>When can the proposed testbed be in operation ?The testbed can be in operation after initial configuration. Dynamically reconfigurable control plane is deployed incrementally over a working system.<br\/><br\/>The proposed testbed will enable research projects that are not feasible otherwise. In addition, the proposed testbed can be potentially made available to OBS research community worldwide through a Remote Laboratory Interface (RLI) developed through the NSF funded Open Network Laboratory (ONL) project.","title":"CRI: IAD : Reconfigurable Optical Burst Switching Research Testbed Acquisition and Development","awardID":"0708613","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["486128"],"PO":["564778"]},"127420":{"abstract":"The goal of this research project, called Moirae, is to investigate the benefits and challenges of integrating history into a near-real-time monitoring system and to build a new continuous query engine that supports this integration. To achieve this goal, the project takes the following steps: (1) develop new query models for integrated queries over live and historical data; (2) develop new algorithms that effectively match new events with similar past observations; (3) develop a new continuous query engine that effectively supports the new query model (the engine includes a partitioned stream data store, a scheduler for fair and incremental historical query execution, new operators for merging historical data with data streams, and mechanisms for user-feedback); and (4) evaluate the practicality and performance of the system on data traces from real application domains. <br\/><br\/>Project funds support the training of PhD students. However, the project includes a large system development component that serves to train both graduate and undergraduate students in research and systems building. The result of this project will provide a new type of continuous processing engine that will better support monitoring applications in domains ranging from computer system monitoring, to network monitoring, and sensor-based environment monitoring. Such large-scale monitoring applications are critical for enterprises that operate at large scales. These enterprises need to carefully monitor their infrastructures to effectively handle and diagnose failures and deliver high-quality services to their customers. The software and technical papers resulting from this project will be disseminated through the project website(http:\/\/data.cs.washington.edu\/moirae\/moirae.shtml).","title":"III-COR: Exploiting History in Continuous Monitoring Systems","awardID":"0713123","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["536677"],"PO":["560586"]},"125242":{"abstract":"Advances in bio-medical imaging, such as microscopy, MRI, CT, and PET scanning, are producing a growing body of available 3D data. While computer modeling to date has largely focused on viewing or recovering the 3D shapes of anatomical structures from this data, more and more application areas involve further analysis of the data itself. One such area is the comparative analysis of 3D data collected from different individuals or from the same subject at different times. These comparisons are often the basis for making clinical decisions as well as scientific hypothesis. Supporting multi-subject analysis on this type of data requires establishing a mapping from one individual's volume to another's. This is a challenging problem not only because the shape of anatomical structures may vary greatly from one individual to another, but also because of noise and resolution issues inherent in the 3D capture process.<br\/><br\/>The goal of this research is to develop a new modeling paradigm suitable for comparative analysis of 3D data of different subjects. This paradigm consists of constructing a topologically correct surface from segmented data of individual subjects, establishing a consistent mapping among all individuals on their boundary surfaces, and a simple, direct extension from surface mapping (2D) to smooth mappings between enclosed volumes (3D). The methods can be applied to both manifold and non-manifold surface representations, and the resulting volume mapping supports organization of a large repository of 3D images for efficient volume-based queries. As the boarder impact, the research will directly benefits medical researchers by providing them with the necessary computational tools to perform multi-subject, 2D and 3D data comparisons.","title":"Geometric Modeling for Spatial Analysis of Bio-Medical Data","awardID":"0702662","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["547864","550459"],"PO":["565272"]},"126573":{"abstract":"Rapid development of digital imaging technology has created a flood of images being collected, sorted, searched and shared over the Internet. This in turn has led to the acceleration of research in systems for content-based image management. Such systems necessarily rely on computer vision and image processing for the extraction of image descriptors, the detection of objects and faces, image similarity measures, classification algorithms, etc. While many methods have been proposed, progress is being stifled by insufficient access to `real' image collections for testing and a lack of practical tools for evaluation. At the moment, tools for object\/scene detection, visual search, and database navigation are being evaluated on small (somewhat arbitrary) collections of images, and if at all, using a very small number of users.<br\/><br\/>This proposal seeks funding to develop a resource for the computer vision and image processing communities consisting of a public web-based photo collection. To a public user, it will be presented as a state-of-the-art online system for organizing, searching and sharing personal photos. It's true purpose will be for researchers, however, to whom it will provide a large `real' database of images for testing, and a large pool of unbiased users for evaluation. By exploiting the blossoming public demand for web-based image services, this resource will provide the ability to develop and evaluate individual components of content-based image management systems at an unprecedented scale.<br\/><br\/>In addition to providing this research resource, the proposed system will enable unique educational experiences for students in computer science and engineering. For this purpose, the system will include a secondary `online laboratory' that is accessible from the principal website and allows consenting public users to try experimental services. This `online laboratory' will give students the ability to implement and test their projects---not only in the areas of computer vision and image processing, but in areas such as peer-to-peer systems, distributed computing, programming languages, security and privacy, and interface design.<br\/><br\/>Progress reports for this project will be regularly updated at http:\/\/www.eecs.harvard.edu\/~zickler.","title":"CRI: CRD: Public web-based photo-collections as a research testbed","awardID":"0708895","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["518022",335831,"515747"],"PO":["564316"]},"128762":{"abstract":"In this project, we are investigating the theory, algorithms and applications of fusible data structures for fault-tolerance in parallel or distributed programs with low overhead. Fusible data structures are based on combining partial replication with erasure coding to satisfy three main properties: recovery, space constraint and efficient maintenance. The recovery property ensures that in case of a failure, the fused structure, along with the remaining original data structures, can be used to reconstruct the failed structure. The space constraint ensures that the number of nodes in the fused structures is strictly smaller than the number of nodes in the original structures. Finally, the efficient maintenance property ensures that when any of the original data structures is updated, the fused structure can be updated incrementally using local information about the update and does not need to be entirely recomputed.<br\/><br\/>The project is carrying out the following three tasks: (i) develop algorithms for fusible data structures for other commonly used structures such as trees and graphs, (ii) develop theory and associated algorithms for multiple faults (iii) apply fusible data structures for recovery of parallel and distributed applications and evaluate the performance benefits of our approach in real applications.","title":"CSR --- PDOS: Combining Replication with Erasure Coding for Efficient Fault-Tolerance","awardID":"0718990","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["561475"],"PO":["561889"]},"125275":{"abstract":"The emergence of multicores as the standard machine design has created one of the most important challenges to the software industry in the history of computing. To take advantage of the additional computational power of each new generation of machines, programs must be able to profit from the most important characteristic of multicores: the presence of multiple processors. In other words, programs must be able to execute in parallel. Furthermore, for efficient execution, this parallelism must take a form that is consistent with the internal organization of the multicore machine where the program is to execute. If these programs were to be manually designed, the need to take into account machine characteristics would increase the cost of program development significantly. Also, since newer multicore designs are likely to include novel architectural features, the process of porting programs from one generation to the next will also involve significant costs. In other words, if nothing is done, the significant increases in the cost of software will be necessary for widespread acceptance of multicores.<br\/>Our objective in this project is to develop techniques for automating the process of generating efficient parallel programs. To this end, we will extend Pivot, a prototype C++ compiler, under development at Texas A&M, with techniques capable of automatically detecting the parallelism implicit in most conventional C++ programs and mapping it onto a wide range of multicore systems. That is, we will extend Pivot with automatic parallelization techniques. We will build on static and hybrid (static and dynamic) analysis techniques developed at Illinois and Texas A&M for numerical computations and extend them to handle the irregular data structures that are often used in C++ programs.","title":"Collaborative Research: Next Generation Compilers for Emerging Multicore Systems","awardID":"0702765","effectiveDate":"2007-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}}],"PIcoPI":["496841","501668","502347"],"PO":["565272"]},"129400":{"abstract":"Wireless networks bring mobility to users by allowing them to change location without disrupting connectivity. On one hand, this opens space for a wide variety of location-aware services. On the other hand, it also poses a concern to users as to what extent their location can, or should, be identified in different scenarios.<br\/><br\/>The main focus of the research is to address the proper identification of mobile device locations in wireless networks. There are two sides of the problem: the accurate determination of a mobile device's location in applications such as E911 services, and the effective protection of location information against adversaries which intend to intrude mobile device users' privacy. This project takes a systematic view of both sides of the problem, explores a solution space that spans both ends of wireless communication, and delivers solutions for various application scenarios. The sticking point is to determine the minimum location information necessary for the intended network service by understanding, analyzing, structuring, and controlling the complex interactions among different entities in the system including end-devices, base stations, and (potential) adversaries across application, network, and physical layers. Both control plane and data plane are considered.<br\/><br\/>The intellectual merit of this project is to form a scientific foundation for proper location identification.","title":"Collaborative Research: WN: Proper Location Identification in Wireless Networks","awardID":"0721569","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["453727"],"PO":["557315"]},"129533":{"abstract":"The Internet has evolved greatly from its original incarnation. For instance, the vast majority of current Internet usage is data retrieval and service access, whereas the architecture was designed around host-to-host applications such as telnet and ftp. Moreover, the original Internet was a purely transparent carrier of packets, but now the various network stakeholders use middleboxes to improve security and accelerate applications. To adapt to these changes, this project will design, develop and deploy a design called the Data- Oriented Network Architecture (DONA). DONA replaces DNS names with flat, self-certifying names, and replaces DNS name resolution with a name-based anycast primitive that lives above the IP layer. <br\/><br\/>Broader Impact: DONA improves data retrieval and service access by providing stronger and more architecturally coherent support for name persistence, content availability, and data authentication. It can also be extended to provide support for caching and RSS-like updates.","title":"NeTS-FIND: Collaborative Research: A New Approach to Internet Naming and Name Resolution","awardID":"0722033","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560562"],"PO":["565090"]},"127476":{"abstract":"Spoken language systems are difficult to build in part because they combine many diverse sources of knowledge, each of which needs to fit the needs of a particular domain and application. Learning approaches used in dialogue often (though not always) rely on the existence of a labeled corpus from which models parameters can be estimated; unfortunately this requires human effort to create labels or annotations.<br\/>This project is developing a new approach, implicit learning, that addresses current shortcomings by leveraging natural patterns that occur in conversation to generate learning instances.<br\/>The project is approaching the problem from three perspectives: 1) Understanding the leverage provided by implicit learning, specifically how the quality of information, its quantity and the distribution of learning opportunities affects its efficiency. 2) Determining the conditions under which learning opportunities can be elicited, specifically computing the utility of given interventions in terms of cost to the user versus gain in knowledge. 3) Augmenting the set of useful patterns through discovery, specifically through the retrospective analysis of past interactions. The project is using working dialog systems to conduct experiments and gather empirical data for analysis.<br\/>The techniques and analyses created in this project should be applicable to the design of a wide variety of interactive systems and allow them to incorporate a natural non-obtrusive learning component. Their value lies in the reduction of the need for expert supervision of learning and the corresponding ability to evolve behavior over time. As such they constitute a key element of robust intelligence.","title":"RI: Implicit Learning in Spoken Language Interfaces","awardID":"0713441","effectiveDate":"2007-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[338056,"495152"],"PO":["565215"]},"135099":{"abstract":"The research plan of this project is: (1) develop new principled foundations for information security, including new cryptographic primitives and new abstractions, based on lattice theory, (2) explore the implications of this approach to information security requirements as may emerge novel applications, including synthetic biology, communication-efficient networks, and nano-electronic computer architectures, and (3) develop a vision of a bridge from the new foundations to the new applications. Many anticipated and emerging technologies pose novel information security requirements that are not necessarily well supported by existing information security infrastructure and cryptographic primitives. This research will investigate these issues from this new perspective on computing and information security. Overall, the plan takes a clean-slate approach to computationally re-conceptualizing the basis of information security in forward-looking domains.","title":"SGER: SCIF: Securing the Computing and Information Future: Principled Foundations and New Cryptographic Abstractions","awardID":"0749931","effectiveDate":"2007-09-01","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["521343"],"PO":["362818"]},"129423":{"abstract":"Wireless ad hoc networking has become a critical technology enabling node communications without network infrastructure. However, current technologies do not provide satisfactory performance in terms of capacity, connectivity, and delay. Recently, several cooperation schemes have been proposed to improve the network performance. They significantly depart from the traditional point-to-point link abstraction and conventional network architectures and will have a profound impact on the network performance and design.<br\/><br\/>The goal of this research is to develop the foundations and practical algorithms for applying emerging cooperation schemes in wireless ad hoc networks. These schemes include (i) cooperative communications where multiple nodes intentionally transmit concurrently at the physical layer, for example, cooperative diversity, distributed multiple-input multiple-output (MIMO), and distributed beamforming, (ii) network coding where nodes combine data received from neighbors and then transmit these combinations to their neighbors to reduce the number of transmissions and improve throughput, (iii) cooperative infrastructure where infrastructure (e.g., wired base stations) is overlaid over wireless ad hoc networks. This research will develop fundamental performance bounds for cooperative networks, as well as new algorithms and mechanisms for providing network-level services.<br\/><br\/>The broader impacts of this project include the dissemination of research results through journal and conference publications, and a strong education component that promotes teaching, training, and learning through the active involvement of research students. Education materials will be developed and disseminated for a new course to be taught jointly at the two universities.","title":"NeTS-WN: Collaborative Research: Cooperative Wireless Networking: Foundations and Practice","awardID":"0721626","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["451664"],"PO":["557315"]},"127487":{"abstract":"This project will develop an information-theoretic framework for the planning and control of robotic sensor networks. Concepts from distributed sensor networking, cooperative control, networked communication, sensor fusion, and information theory are combined into a single framework that incorporates both communication and sensing objectives. This new framework enables robust intelligence in robot teams through reasoning about the combined effects of sensor uncertainty and wireless networked communication on model-based active sensing. Communication models move beyond line-of-sight or proximity constraints to consider the dependency of channel capacity on relative separation, asynchronous communication, and interference or noise that cannot be modeled. Sensing strategies will perform distributed decision-making over finite planning horizons and will integrate new methods to achieve desired levels of uncertainty rapidly. Research thrusts include: i.) information-theoretic formulation of robot sensor network planning and control; ii.) distributed optimization that combines predefined maneuvers with random search techniques; iii.) robustness to sensor uncertainty and radio noise using receding horizon control and multivariable extremum seeking; and iv.) experimental validation. Education activities will address the leakage of students from the engineering and technology pipeline by focusing on the engineering challenges, scientific questions, and societal benefits associated with the development of robot sensor networks.","title":"RI: Information-Theoretic Control of Robotic Sensor Networks","awardID":"0713525","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["507819"],"PO":["562760"]},"127498":{"abstract":"In this project, the PI will lead an interdisciplinary team in a quest for fundamental insights into how to effectively harness the full potential of virtual reality technology for visualization and design. The specific focus of the research will be on architectural applications. Within this context, the PI will seek to enable accurate and intuitive spatial understanding of large, immersive 3D virtual environments presented both via head mounted displays and on large projection screens. For environments presented via a head mounted display, the PI will explore how the accuracy of the user's spatial perception and sense of presence is affected by factors such as: providing a faithful representation of the user's body; providing low latency visual and haptic feedback about the sizes and distances from the user of tracked objects that co-exist in both the real and virtual environments; and providing spatialized 3D ambient sound cues. For information presented via a stereoscopic large screen rear-projection system, the PI will explore how the viewer's ability to attain a maximally accurate intuitive spatial understanding of an interior or exterior is impacted by questions such as: the importance of presenting people with an image of a scene that is generated from a viewpoint that is as close as possible to their own eye position, both laterally and in distance from the ground; the conditions under which the viewer is likely to adopt an interpretation of size and distance relationships in a virtual environment shown via a projection system that is based on the assumptions that underlie interpretations of size and distance in pictures, as opposed to interpretations of size and distance in directly viewed scenes; and whether, when considering display on a large screen, bigger is always better, or if the maximum benefit comes from displaying a scene at \"life size\" with the possibility that negative consequences might arise from displaying things too large. The PI will further explore the design and evaluation of improved metaphors for enabling intuitive locomotion through very large scale immersive virtual environments, as well as the effective use of abstraction for the representation of uncertain or ambiguous information in such environments.<br\/><br\/>Broader Impacts: This work will lead to basic observations and rules of thumb derived from careful human subjects experiments that will inform a broad range of research efforts involving the use of virtual environments, in such domains as scientific and information visualization, situational awareness, and diversity training. It will also result in improvements in architectural education stemming from the effective use of virtual environment technology to teach fundamental concepts in visual imagination and integration of an egocentric perspective into the earliest stages of the design process.","title":"IIS: Effectively Harnessing Virtual Environments Technology for Visualization and Design","awardID":"0713587","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["543617","565146"],"PO":["565227"]},"129203":{"abstract":"Software misbehaves too frequently due to bugs, security attacks, and intermittent hardware errors. While powerful tools?called ?lifeguards??have been developed in the past to monitor a program as it executes for the sake of detecting and sometimes even fixing problems as they happen, these tools have historically run so slowly (often an order of magnitude slowdown) that it was impractical to run them continuously in the field. To address this problem, this project is developing a new general-purpose framework that harnesses idle processor cores in a chip multiprocessor to enable powerful lifeguards to run continuously on deployed code in order to detect, diagnose, and fix incorrect behaviors with no perceived cost to the user. A key technology in this new lifeguard framework is a novel mechanism for efficient dynamic program inspection and rewind via a log that is captured by the hardware, managed by the operating system, and exposed to the lifeguard software. This project is expected to have impact in the following ways. First and foremost, it should make software more robust, not only by allowing existing lifeguards to be run continuously in the field, but also by hopefully spawning the creation of new lifeguards that are even more sophisticated and useful than what we have today. These tools will be especially important for programmers as they try to avoid correctness and performance bugs when they write parallel programs for chip multiprocessors. This new service will provide a new type of end-user value from a parallel machine beyond raw speedup (i.e. improved robustness against software bugs, security attacks, and other errors). The existence of a hardware-generated log may also lead to new ways to write software (e.g., by inspecting its past behavior or exploiting the log as a recovery mechanism).","title":"CSR---PDOS: Log-Based Architectures: Extending Chip Multiprocessors to Help Software Behave Correctly","awardID":"0720790","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["485986",342331,342332],"PO":["535244"]},"127388":{"abstract":"As separate sovereign governments, Indian tribes, just like state and local governments, have an obligation to improve the lives of their citizens. However, tribal governments are much more limited in their ability to access capital. Many tribal communities are often burdened with extremely low socio-economic factors, including low educational achievement, high unemployment, high poverty, and low per capita income. Upwards of $50 billion of unmet capital needs go unfunded each year in Indian Country, in large part due to impediments to tribal access to the capital markets. There are numerous reasons tribes are at a disadvantage, but one little studied is information asymmetry. Relatively poor market awareness is both a cause of tribal underdevelopment and an impediment to any solution. Because most tribes confront information asymmetries for any debt financing strategy they might consider, an empirical study of successful information sharing and integration strategies for tax-exempt bonds will help identify suitable strategies to induce sharing in other domains where tribes operate at an informational disadvantage.<br\/><br\/>Based on preliminary work (IIS 0534905), this Tribal Finance Information Clearinghouse (TFIC) project will make three unique contributions to information science. First it will collect, aggregate, analyze, and disseminate new digital content consisting of access to market-actionable data on tribal tax-exempt bonds that is not currently available. Second, it will generate data about the factors that impede or induce contributions of private information to a collective information good. (Broadly, insight into how to design information systems that resolve the social dilemmas of information collaboration is an increasingly important.) Finally, the TFIC will be an exercise in informational empowerment. By presenting original financial data as part of a larger infrastructure that includes updated content regarding regulatory, legal, and legislative changes, industry news, and a forum to contribute lessons learned, the TFIC will add significant informational value to transactional data. The TFIC will also support multidisciplinary research on the design and use of information technologies and the resulting impact on government institutions and citizens.<br\/><br\/>Broader Impact<br\/>Without empirical data about tribal interactions with capital markets, many research questions remain unanswerable. With this project, for the first time, these may be answerable as the TFIC will offer researchers and policy-makers an unparalleled opportunity to analyze a complete data set related to a significant minority group and to determine whether information asymmetries, legal regulations, or other variables impact capital markets access for tribes. Not only will the outcomes directly impact Native Americans, but the results may be generalizable to other minority enterprises that also face impeded market access. The relatively small number of actors (i.e., 88 tribal issuers since 2001) with durable presence in the data makes study of capital access questions more manageable than might be the case with non-tribal entities.<br\/><br\/>The TFIC may also impact the marketplace itself, given that a recent study of non-tribal tax-exempt bonds found that the \"most critical consequence\" of information asymmetry is higher borrowing costs, but that \"alleviating information asymmetry\" reliably eliminates the risk premium and reduces borrowing costs, particularly for new or infrequent issuers such as tribes.","title":"HCC: Digital Tribal Government: The Tribal Finance Information Clearinghouse (TFIC)","awardID":"0712941","effectiveDate":"2007-09-15","expirationDate":"2009-03-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[337849,"400168"],"PO":["388678"]},"129335":{"abstract":"This project studies three fundamental problems to improve the performance of wireless mesh networks. <br\/><br\/>(1) Managing delay and jitter. One fundamental problem affecting the performance of current mesh networks is the hop-by-hop relaying of data, resulting in significant per-hop and per-packet delay and\/or jitter. This project designs a new MAC paradigm and a distributed method of scheduling data transmissions in a path-aware manner, to eliminate per-packet delay and jitter while minimizing per-hop delays. <br\/><br\/>(2) Capacity analysis and utility optimization. As an augmentation to the large amount of simulation studies on multi-channel<br\/>multi-radio mesh networks, this project develops a general theoretical model to analyze both unicast and broadcast capacities of mesh networks, and applies the model to optimally assign channels to maximize capacity, as well as optimizing application-specific utility functions relevant to user-perceived network performance. <br\/><br\/>(3) Channel assignment for dynamic spectrum access mesh networks. Recent advancement in cognitive radio technology and regulatory reform in spectrum policy offer dynamic spectrum access (DSA) capability to mesh networks via providing dynamically available channels. This project adopts a cross-layer and path-centric approach for assigning dynamic channels in<br\/>DSA mesh networks to achieve high spectrum utilization and traffic throughput. <br\/><br\/>Through developing innovative protocols, analysis and optimization models, this project promotes development of high-performance multi-radio, multi-channel, and DSA-capable mesh networks. The research on DSA mesh networks potentially facilitates the communication among different emergency management divisions in disaster rescues operations. This project also benefits the underrepresented minority students through education and research.","title":"NeTS-WN: Collaborative Research: Toward High-Performance Mesh Networks","awardID":"0721313","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["565184"],"PO":["564993"]},"129478":{"abstract":"Modern wireless computing devices raise privacy concerns by leaking information that can be used to track and profile users. These privacy concerns are inherent to the low-level design of network and link-layer protocols and are, therefore, not addressed by the traditional approach of encrypting messages to ensure that their contents remain confidential. This project studies the question of how to protect user privacy in the context of a future Internet with rich connectivity to these wireless computing devices. The research focuses on designs that accomplish this without sacrificing the requirements for manageability and accountability.<br\/><br\/>The research approach is to study existing systems such as 802.11 to characterize privacy threats and design improved network and link protocols that provide stronger privacy guarantees. Part of the project is to rethink names and addresses in their various forms to limit the disclosure of identity information only to trusted parties This includes names that conceal identity without compromising network functions, such as routing, that rely on them; name discovery and resolution protocols that do not reveal information across system layers.; techniques to detect implicit names exposed by end-points. Finally, the project also explores methods to expose the privacy status to users.<br\/><br\/>Broader Impact: The combination of improving privacy and educating end-users about their privacy risks significantly and justifiably reduces the fears of Internet users. This makes the Internet a more widely accessible resource by allowing users to perform tasks, such as online-shopping, that they may not have been comfortable with before.","title":"Collaborative Research: NeTS-FIND: Protecting User Privacy in a Network with Ubiquitous Computing","awardID":"0721857","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["458795"],"PO":["565090"]},"129368":{"abstract":"Sensor networks will be deployed everywhere around us, e.g., in offices and residential houses. There are many concerns related to privacy in this scenario because people and their activities will be monitored all the time. For example, data collected for temperature monitoring in an office should not be used to imply the presence of a person, which is a private information; unauthorized person should not be allowed to access the sensed data that is privacy-sensitive. To make the sensor network deployment more realistic in our daily life, it is imperative to consider the privacy concerns in sensor networks. <br\/><br\/>This project aims to build a privacy-preserving infrastructure for sensor networks. It considers the privacy breaches due to the information leakage to (1) untrusted sensor networks, (2) untrusted users, and (3) outside observers. In the context of the three adversary models, this project focuses on the most important operations in sensor networks: data query, data sharing, and data routing. Specifically, the problems addressed in the project include how to store data or aggregate data so that data query can be responded in a privacy-preserving fashion, how to provide security primitives to prevent unauthorized users from accessing collected data, and how to design routing algorithms to preserve location privacy. <br\/><br\/>The research conducted in this project is expected to deepen our understanding in building a privacy preserving sensor network, and provide a realistic implementation suite for security and privacy support for sensor networks.","title":"NeTS-NOSS: Privacy-Preserving Sensor Networks","awardID":"0721443","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["551983"],"PO":["564777"]},"129489":{"abstract":"Sensor networking and video data streaming represent two maturing technologies for scientific observation and data collection with very different technical requirements. The former is designed assuming large numbers of units and long-term deployment in settings with small data generation rates. The latter can provide rich visual detail in collected data but requires significant energy resources to sustain data recording, communication, and storage. The research in this project seeks to enable networked video cameras to operate within sensor network constraints: at low energy consumption, in remote un-tethered settings, and in large spatial measurement scales. <br\/><br\/>The work is motivated by collaborations with ecologists and biologists that reveal many opportunities for the observation of species behavior that are characterized by events that are disturbed by human presence, are remotely sited, require long periods of waiting or require large, detailed area coverage. Detecting, recording, and streaming to enable scientific discovery in these settings can expand our understanding of the environment.<br\/><br\/>The project involves the development of a novel low-cost video sensor that operates on energy harvested from the environment and supports spatial and temporal sub-sampling of the camera field of view. Complementary research thrusts include the investigation of localized and cooperative in-network image analysis, data compression, and network path formation to enable delivery of video data to an outside observer while minimizing contention caused by multiple streams. <br\/><br\/>The project includes a demonstration using a video sensor field comprised of 50 video sources in pilots involving the observation of woodland animals at Boston University's Sargent Camp and in the study of shorebirds and grey seals at a coastal site selected in collaboration with the University of Massachusetts Field Station.","title":"NeTS-NOSS: Localized Computation and Network Path Formation to Enable Pervasive Video Sensing","awardID":"0721884","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["371069","521649","521650"],"PO":["565090"]},"129379":{"abstract":"Wireless P2P networks, such as ad hoc networks, mesh networks, and sensor networks, have received considerable attention due to their potential applications in many civilian and military environments. The design of such networks that consider performance and power optimization has become a recent research focus. <br\/><br\/>As nodes in wireless P2P networks may perform similar tasks using common data sets, collaborative data access, which allows sharing and coordination of cached or replicated data among multiple nodes, can be used to reduce the bandwidth and power consumption. The specific goal of this project is to provide a collaborative data access framework for wireless P2P networks. <br\/><br\/>The project addresses four intertwined issues: (i) various cooperative caching schemes will be designed, implemented, and evaluated; (ii) suitable cache replacement and cache admission control algorithms are proposed and evaluated to balance the tradeoffs between access latency and data accessibility; (iii) novel data replication and data discovery techniques are investigated to further reduce the access latency and increase the data accessibility; (iv) possible security violations to maintain data consistency will be identified, and solutions to defend against such attacks will be proposed. The project will make significant theoretical advances in understanding and designing wireless P2P networks using the collaborative data access concept, and will develop a comprehensive software support for collaborative data access in wireless P2P networks. <br\/><br\/>The success of this project is likely to have a broader impact on making wireless P2P networks more affordable and amenable to commercial, civilian, and military applications. The results of the project will be disseminated widely through high-quality publications and discussions. The proposed research will also be integrated with the education curricula at Penn State.","title":"NeTS-WN: Collaborative Data Access in Wireless P2P Networks","awardID":"0721479","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["550859","550785"],"PO":["557315"]},"131150":{"abstract":"Many common communication situations are over inherently two-way channels, such as telephone systems, digital subscriber lines (DSL), cellular networks, and the Internet. In fact, even `point-to-point' systems, where the end goal is to transfer information in one direction, often give rise to two-way communication scenarios due to the presence of feedback. In such systems, one can receive feedback from the other end of the channel, which can be used to improve the quality of communication. Although feedback is present in many communication systems, and is being used in certain primitive forms as in channel estimation and automatic repeat request, the theory behind its use is far from complete. This research investigates the role of feedback in two-way communication networks and provides architecture-level guidance for designing robust and efficient communication systems. While positive results lead to novel approaches to communication systems design, negative results prevent over-engineering and allow more confidence in simple and modular implementations. At the same time, feedback is a pivotal concept in biological and artificial control systems, learning machines, and communication networks. A deeper understanding of the role of feedback in one area (communication) will lead to a better understanding of the role of feedback in a broader multidisciplinary context.<br\/><br\/>Concretely, this research focuses on and develops new approaches for tackling problems arising in the following areas: 1) feedback capacity of single-user channels with memory (new coding theorems based on directed information, causal conditioning, and Shannon strategy, as well as the development of concrete schemes for achieving the fundamental limits), 2) multiple-user channels with feedback (emphasis on multiple access channels and broadcast channels: characterization of fundamental limits as well as the construction of practical coding schemes), 3) capacity region of the two-way channel such as the Blackwell-Shannon binary multiplying channel (dynamic programming and infinite-dimensional convex optimization), 4) robust feedback coding techniques under channel uncertainty (universal decoding schemes), and 5) reliable communication with noisy feedback (new perspectives on cross-layer design of channel codes and network protocols). Massey's directed information takes the role of Shannon's mutual information in many feedback communication problems. Thus the role of directed information is investigated as a fundamental notion in general causal inference problems. Examples include gambling in horse-race markets with causal side information and its dual in source coding.","title":"Collaborative Research: The Role of Feedback in Two-Way Communication Networks","awardID":"0729119","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["551175"],"PO":["432103"]},"131040":{"abstract":"Geometric Analysis of Large Wireless Networks:<br\/>Interference, Outage, and Delay<br\/><br\/>Martin Haenggi, University of Notre Dame<br\/><br\/>Abstract:<br\/>Large wireless systems, in particular ad hoc and sensor networks, have great potential for numerous applications. They have been the subject of intense investigation over the last decade. Despite these efforts, many of their fundamental properties are still not well understood, and it is unknown how to design network protocols in an optimum fashion. Important progress has been made in determining the capacity scaling behavior of these systems, but the asymptotic nature of these results severely restricts their applicability to practical networks. This project complements such scaling studies by aiming at a precise characterization of certain performance metrics, including reliability and delay.<br\/>Further, some of the standard modeling assumptions, such as the uniformly random node distribution are questioned, and existing results are extended to other node distributions that better reflect real networks with interacting nodes.<br\/><br\/>The investigators use a rigorous analytic approach that combines tools from stochastic geometry, point process theory, branching processes, and information theory. Since the network geometry critically affects the interference and signal-to-noise-ratios, an emphasis is put on the geometric properties of the underlying node distribution. The project focuses on several concrete problems in interference characterization, link outage, and the tradeoff between end-to-end delay and outage in large networks with randomly distributed nodes. The objectives are to analytically determine or bound these quantities for general node distributions and to derive guidelines for protocol design from the theoretical insight gained.","title":"Geometric Analysis of Large Wireless Networks: Interference, Outage, and Delay","awardID":"0728763","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["540624"],"PO":["564924"]},"131161":{"abstract":"Capacity and Coding in Resource-Limited Wireless Networks<br\/><br\/>Performance of wireless networks is limited by the resources available in the network. The fundamental physical resources used by wireless networks are bandwidth and energy. Designing wireless networks is mainly a question of utilizing these resources in the most efficient way possible. This research considers the two resources separately and defines the bandwidth limited regime and the energy limited regime by focusing on one resource at a time. In each regime, the investigators propose to concentrate on a few measures of performance related to the Shannon capacity, find bounds for these measures, and design practical codes to approach these bounds.<br\/>Treating the two resources separately makes it possible in many cases to obtain concise, exact capacity results rather than numerical upper and lower bounds. Specifically, this research aims to 1) find fundamental bounds for performance of resource-limited wireless networks, 2) develop a new concept of deterministic capacity of networks, 3) use obtained information-theoretic results directly in guiding practical code designs, 4) employ source-channel coding in code designs, and 5) extend the source-channel coding approach to networks with correlated sources.","title":"Collaborative Research: Capacity and Coding in Resource-Limited Wireless Networks","awardID":"0729149","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["516912"],"PO":["564924"]},"133592":{"abstract":"Spelman College proposes the ARTSI (Advancing Robotics Technology for Societal Impact) Alliance in collaboration with Florida A&M University, the University of the District of Columbia, Hampton University, Morgan State University, Norfolk State University, Winston-Salem State University, the University of Arkansas-Pine Bluff, Carnegie Mellon University, Georgia Institute of Technology, Brown University, Duke University, the University of Alabama, the University of Washington, and the University of Pittsburgh. Seven of these partners are HBCUs and seven are Carnegie Research I institutions. Their collaboration joins the strengths of HBCUs in conducting outreach and education in a nurturing learning environment with those of the R1's for conducting world class research. The ARTSI Alliance will motivate students to pursue computer science careers by emphasizing the creativity and socially beneficial aspects robotics technology with hands-on projects, curriculum, and media. ARTSI activities will span the academic pipeline from K-12 through the faculty ranks. At the K-12 level, students will be recruited with community outreach using robotics and art, robotics road shows, and a robotics educational film online repository. At the undergraduate level, HBCU students will be exposed to new robotics curriculum, and they will be encouraged to pursue advanced training in graduate school through summer research experiences, collaborative, interdisciplinary robotics projects in the arts and health, instruction in technical film documentation, student virtual film festivals, annual robotics conferences, and instruction in entrepreneurship for computer science. At the faculty level, it will increase the number of HBCU faculty who educate students in robotics and involve students in robotics research by providing faculty mentoring, summer research experiences for underrepresented faculty at R1 robotics labs, robotics summer workshops, and development and dissemination of robotics educational material through a web-based portal. The Alliance will have industry partners, including Seagate, iRobot, Microsoft Research, and Juxtopia, as well as educational partners, including Florida-Georgia Louis Stokes Alliance for Minority Participation and Computer Science Teachers Association.","title":"Collaborative Research: BPC-A: ARTSI: Advancing Robotics Technology for Societal Impact","awardID":"0742075","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7584","name":"ITR-BROADENING PARTICIPATION"}}],"PIcoPI":["550054"],"PO":["561855"]},"131051":{"abstract":"The research goal of this project is to develop scalable algorithms for a number of fundamental problems in terrain processing and implement these algorithms into open-source modules used by the GIS (Geographic Information Systems) community. The research will address three problems on terrains: the computation of visibility, overlay, and simplification. These problems come up in some of the most basic terrain processing applications, and have received a lot of attention both in theory and in practice. However, solutions that are both optimally I\/O-efficient and practically scalable are not known.<br\/><br\/>The central theme of the research is to develop algorithms that are simple and optimal and also perform well in practice and scale to very large inputs by exploiting the geometry of realistic terrains. So far, theoretical research into scalable algorithms has focused on algorithms that are I\/O-efficient for any worst-case input. However, worst-case inputs are often artificial constructions that occur rarely in real-life. The research will use the notion of realistic input developed in computational geometry, thus combining the theory of I\/O-efficient algorithms with realistic input models as a new approach to obtain optimal, practical and realistic I\/O-efficient algorithms.","title":"Scalable Algorithms for Realistic Terrain Processing in GIS","awardID":"0728780","effectiveDate":"2007-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[347915],"PO":["565157"]},"131293":{"abstract":"0729792<br\/>Ramaswamy<br\/><br\/>This International Research Experiences for Students project will support U.S. undergraduate students from the University of Arkansas Little Rock (UALR) who will conduct research at the Institut National de Sciences Appliquees de Rouen (INSA) in France. The U.S. team will partner with The Laboratoire d'Informatique, de Traitement de l'Information et des Systemes laboratory at INSA-Rouen directed by Roger Goglu. The proposal will fund eight U.S. undergraduate students per year to spend six weeks in Rouen over a three-year-period. Students will research software systems with applications to maritime transportation logistics. These systems will resemble real-world applications by stressing on a multi-disciplinary research to bridge discipline-specific theoretical research issues with real-world practice. Students will take part in pre-visit activities, such as a discussion course where they will formulate research questions, identify specific resources they will need to answer those questions, and develop active learning techniques for critical learning and comprehension. After the research visit to INSA, the students will present their research project to their peers at UALR and compile their results into a scientific paper for appropriate dissemination. Faculty members from UALR plan to visit Rouen to strengthen ties and facilitate collaborative research projects: one faculty member will go with the students during the beginning of the trip to ensure their orientation and adjustment to the new environment; the other will go towards the end of their research activities.<br\/><br\/>This project is co-funded by the Office of International Science and Engineering and the Directorate for Computer and Information Science and Engineering.","title":"IRES: U.S.-France Cooperative Research in Engineering Innovative Software Systems with Applications to Maritime Transportation Logistics","awardID":"0729792","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7316","name":"EAPSI"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7727","name":"IRES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["411431",348553,348554,"474701","564180"],"PO":["537967"]},"122471":{"abstract":"CAREER: Improving Network Operations with a View From the Edge<br\/>--------------------------------------------------------------<br\/><br\/>The Kaleidoscope project is developing techniques, tools, and systems to<br\/>facilitate network operations---a class of tasks that includes<br\/>monitoring network conditions, detecting actionable problems, and taking<br\/>steps to remediate them. We focus on two areas of network operations:<br\/>(1) network security (specifically, unwanted traffic) and (2) network<br\/>monitoring, diagnosis, and troubleshooting. The results from this<br\/>project will both streamline today's network operations tasks and<br\/>provide design insights for network operations in the next-generation<br\/>Internet.<br\/><br\/>Kaleidoscope specifically focuses on improvements to network operations<br\/>that rely on cooperation between users (or edge networks) and operators.<br\/>Users and operators have common goals but, more importantly, they have<br\/>complementary perspectives. Operators typically have broad views of<br\/>network traffic but have little fine-grained information about<br\/>compromised hosts or end-to-end performance. End users possess<br\/>fine-grained security and performance information, but they have neither<br\/>visibility the into network internals (e.g., configuration) nor a<br\/>comprehensive perspective of network conditions.<br\/><br\/>The first part of the project involves performing measurements and<br\/>analysis on the current Internet to better understand both the extent of<br\/>network operations problems today and the degree to which cooperation<br\/>between users and operators can mitigate them. Based on these findings,<br\/>the project will propose new approaches to network operations both for<br\/>the current Internet and for future networks. This research leverages<br\/>recent advances in streaming data management, machine learning,<br\/>economics, and privacy and may inspire new work in these areas, as well.","title":"CAREER: Improving Network Operations with a View from the Edge","awardID":"0643974","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}}],"PIcoPI":["561756"],"PO":["565327"]},"133482":{"abstract":"IIS - 0741556<br\/>Lewis Lancaster, PI<br\/>Text Analysis and Pattern Detection: 3-D and Virtual Reality Environments<br\/><br\/>Abstract<br\/><br\/>This project will explore the use of high dimensional visualization for analyzing text structure and patterns for scholars in the humanities. The use of computing in text study has not exploited virtual reality and 3D visualization to the degree that can significantly extend scholarly examination. This project suggests new, untried approaches to text analysis of significant foundational texts. The test document of study will be the Korean Buddhist Canon, the oldest complete set of the texts that make up the Buddhist canon for East Asia. The document consists of the more than 83,000 blocks of text which has been digitized with each characters marked up with a Unicode designation. Millions of glyphs will be converted into an image that will have the same metadata as the glyph rendering it capable of being linked to the appropriate description in the text. In this way patterns of visualized word distribution and frequencies can be used to examine more complex document structures. Ancient literature generally exhibits multiple structures that are critical to interpretation of origin and meaning. New methods for revealing and analyzing structure are of great interest to social scientists, linguists and humanists. These present primary challenges to computer science in multiple areas.","title":"SGER: Text Analysis and Pattern Detection: 3-D and Virtual Reality Environments","awardID":"0741556","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["441922"],"PO":["433760"]},"131062":{"abstract":"Some Efficient Error Control Codes Designs for Various Error Channel Models<br\/><br\/> Abstract<br\/><br\/>In the last five decades error control codes have been successfully used to improve the reliability of modern computer, communication and multimedia systems. As the data rate of these systems keeps increasing and as more reliable and secure systems are required for many applications, it is expected that more powerful and efficient codes need to be designed and applied to these systems. This research involves in the design of some efficient error control codes for various error models.<br\/><br\/>First, some Z-channel capacity achieving codes with error free feedback are investigated. In a Z-channel model, the errors in a data word are of 1 to 0 type only. Next, based on this theory some novel diversity combining ARQ (Automatic Repeat Request) protocols are studied. Furthermore, some theory related to elementary symmetric functions is developed. Based on this theory, some new classes of codes capable of correcting t_1 1 to 0 errors and t_0 0 to 1 errors are designed. In addition, based on the elementary symmetric function theory some efficient decoding algorithms for many classes of codes - t-asymmetric error correcting codes, BCH and Goppa codes, error correcting balanced codes, higher order spectral null codes, etc. are studied. Some applications of the theory developed here to other areas are also investigated.","title":"Some Efficient Error Control Codes Designs for Various Error Channel Models","awardID":"0728810","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["486183"],"PO":["564924"]},"131183":{"abstract":"Rapid advances in computing and communicating technologies, combined with inexpensive access to local area wireless networks, have the potential to revolutionize our nation's vehicular networks. The fundamental bottleneck to the timely deployment of these systems is the the infrastructure needed to support them. This proposal seeks to understand infrastructure requirements and explore architectures driven by considerations of cost, scalability, and robustness. In particular, we<br\/>opportunistically utilize devices such as cellular phones, WiFi networks, and GPS receivers which, though originally deployed for unrelated applications, can significantly enhance the operation of vehicular networks.<br\/>This proposal focuses on the systems theory needed to realize this, focusing on an interdisciplinary attack around intelligent distributed signal processing, communications, control and networking. The theoretical advances resulting from this work will in turn provide guidance on the design of new protocols for vehicular networks, particularly in rural areas and the developing world, where cost limits the growth of transportation systems.<br\/><br\/>This proposal seeks to develop both the theoretical foundations and novel constructive designs for next-generation intelligent transportation systems that require minimum cost infrastructure. Motivated by the considerations of cost, scalability, robustness, and reliability, the proposed research thrusts include:<br\/>(i) high-capacity communication based on multihop relaying and random linear network coding for data distribution in vehicular ad hoc networks;<br\/>(ii) reliable estimation of traffic field information for congestion management based on parsimonious mobile sampling of probe vehicles, and distributed sensing, compressing, and aggregation of data based on accurate traffic-flow models such as METANET; and (iii) robust low-latency estimation for critical safety and collision avoidance based on investigation of concurrent, real-time distributed<br\/>estimation of multiple dynamical systems over a shared multi-access wireless channel.","title":"Reduced Infrastructure Cost in Transportation Systems through Intelligent Signal Processing","awardID":"0729237","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["521731","495382"],"PO":["564898"]},"131073":{"abstract":"Collaborative Research: Greedy Approximation with Nonsubmodular Potential Functions<br\/><br\/>Presented in the literature are many greedy optimization algorithms. However, not many of them can be successfully analyzed. Actually, most existing techniques for analysis of greedy approximation require the submodularity of potential functions. For greedy heuristics with nonsubmodular potential functions, the analysis is a largely unexplored open area. Indeed, many have good performance in computational experiments, but have not received much theoretical analysis due to the difficulty of dealing with nonsubmodular potential functions. The PIs have developed new techniques to analyze some of them. They propose to extend their techniques to other greedy heuristics for problems arising from computer system, computer networks and computational molecular biology. Therefore, the research will have the following broader impacts: It will enhance advanced theory for design and analysis of approximation algorithms and the theory of optimization and will provide helps in development of in some computer systems and engineering areas, including computer networking and computational molecular biology. The proposed approximations\/heuristics will provide excellent solutions for optimization problems arising from those areas. The graduate student involvement will have numerous future benefits. The discovery and research experience of the students will prepare them for productive careers in academia, research labs, and industry in highly important, current research areas affecting fundamental development in science and engineering.","title":"Collaborative Research: Greedy Approximations with Nonsubmodular Potential Functions","awardID":"0728851","effectiveDate":"2007-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["382009"],"PO":["565251"]},"125870":{"abstract":"Proposal 0705765<br\/>PIs: Thomas Dietterich, David Lytle, Andrew Moldenke, Robert Paasch, Eric Mortensen, Linda Shapiro<br\/><br\/>Institution: Oregon State University<br\/><br\/>Title: RI: Machine Learning for Robust Recognition of Invertebrate Specimens in Ecological Science<br\/><br\/>Abstract<br\/><br\/>An interdisciplinary team of computer scientists, mechanical engineers, and entomologists from Oregon State University and the University of Washington are developing computer vision, machine learning, and robotic methods for high-precision generic object recognition and applying these methods to the imaging and classification of invertebrate specimens of soil mesofauna and freshwater zooplankton. Current manual methods for recognizing and counting these organisms are extremely tedious and time-consuming, and require a high degree of expertise. Automated, rapid-throughput population counting will provide a revolutionary new tool for <br\/>ecologists to understand and monitor soil and freshwater ecosystems. <br\/>Soil arthropods form a central component of ecological processes in soils, so accurate soil arthopod population counting is critical to improving our understanding of ecosystem functions and community ecology. Freshwater zooplankton species are a fundamental component of many ecosystems, because they transfer energy from primary producers to consumers such as fish and birds. Zooplankton also serve as a model system for understanding basic ecosystem processes, predator-prey dynamics, and disease ecology.<br\/><br\/>Automated recognition of these organisms poses difficult classification problems because it requires much more precise discrimination than generic object recognition tasks of the type commonly studied in computer vision. Current approaches to generic object recognition employ a bag-of-keypoints methodology in which hand-crafted region detectors, hand-crafted region descriptors, and unsupervised feature dictionaries are applied to convert an image into a fixed-length feature vector. Machine learning is only employed at the final step to classify this feature vector into a generic object class. This project seeks to integrate machine learning into all aspects of the vision pipeline. It will develop and test discriminative learning algorithms for the automated discovery of region detectors, region descriptors, feature dictionaries, and classifiers. To reduce the risk of overfitting, sub-part correspondences and spatial constraints will be imposed to constrain the learning algorithms. In addition to discriminative methods, the investigators will also learn generative models to help reject debris and unknown species that appear in the images. Model adaptation methods will be developed to take advantage of the fact that in any given biological sample, organisms of the same taxon tend to be more similar to each other than they are when samples from multiple sites are pooled.<br\/><br\/>Progress on this project will be regularly reported at http:\/\/ web.engr.oregonstate.edu\/~tgd\/bugid\/","title":"RI: Machine Learning for Robust Recognition of Invertebrate Specimens in Ecological Science","awardID":"0705765","effectiveDate":"2007-09-01","expirationDate":"2011-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[334067,334068,"554550",334070,334071],"PO":["460643"]},"125881":{"abstract":"Intellectual Merits. <br\/>The characterization of land cover and usage over large geographical regions, as well as the near\/long-term forecasting of changes in land use, is a key problem in geo-informatics that is particularly important for regions that are subject to rapid ecological changes or urbanization. At present, the data and knowledge required for detailed and accurate characterization is scattered across both traditional (GIS) spatial data sources and across remotely sensed data, and their associated models, none of which inter-operate well. This research will develop a comprehensive framework for efficient and accurate mapping, monitoring and modeling of land cover and changes in usage over large regions. This endeavor involves three complementary activities: (i) large scale classification of remote sensing imagery using advanced learning methods, including transfer learning, active learning and manifold based data descriptors; (ii) next-generation spatial modeling using ensembles for forecasting land transformations; and (iii) integration of GIS and remote sensing data by distributed, privacy aware learning, integrating taxonomies obtained from different data sources and portal building. A plan of interaction with various stakeholders is proposed to ensure that the results are meaningful and actionable. This project will result in substantial advances in analysis of remotely sensed data over extended regions and lead to a substantial reduction in the uncertainty of long-term forecasts of change. Concurrently, the chosen application domain will also provide a concrete setting that motivates several new data mining problems, leading to new algorithmic formulations and solutions that benefit the broader data mining community. <br\/><br\/>Broader Impacts. <br\/>This project is designed to have many, diverse broader impacts. First is the involvement of application scientists in the remote sensing and modeling communities who will benefit from advanced methods in machine learning. The research results will be brought into the classroom through new graduate courses. Popular science lectures for middle and high school are also planned since the subject matter and results can be conveyed meaningfully to this audience in a visual way that emphasizes issues of broader concern, such as the impact of ecological changes and urban sprawl. Two project-wide workshops are proposed that will also involve stakeholders (e.g., planners) who would directly benefit from the results and provide valuable feedback. A portal will be created in year 3 to provide access to data, code and toolkits produced by the project. Results will be disseminated in each of the three main disciplines represented within the project through scholarly publications. Finally, tools will be developed so that they may eventually be incorporated into Commercial Off The Shelf software, such as GIS and remote sensing software.","title":"III-CXT: Collaborative Research: Advanced learning and integrative knowledge transfer approaches to remote sensing and forecast modeling for understanding land use change","awardID":"0705836","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["456825","552420"],"PO":["565136"]},"132184":{"abstract":"This project, funded through the Ethics Education in Science and Engineering (EESE) cross-directorate program, involves interdisciplinary collaboration to design, pilot, and evaluate a web-based curriculum for graduate students, faculty and professionals. The investigators expand science & engineering ethics education by incorporating international dimensions. Specifically, the interdisciplinary project team produces teaching materials, pedagogies, teaching notes and web-based tools in: workplace ethics, international accountability, transnational spread and conduct, variation in international regulatory processes, responsible participation, ethical conflict between nations, and stakeholder and social inclusion. These materials are developed for inquiry-based web modules that are customized tutorials for diverse learners.<br\/><br\/>The researchers will pilot test these tutorials in multiple sites and disciplines. The curriculum will be evaluated objectively by tests of students? acquisition of target knowledge and reasoning skills, and subjectively by student and instructor perceptions of the content, usability and importance of the materials. The refined curriculum will be disseminated through the National Online Resource Center and the National Center for Digital Government, among other modes.<br\/><br\/>This important expansion of ethics education will be innovative in several ways: 1) by using interactive, customizable software that allows students to engage in active inquiry in the nine education modules; 2) by focusing on the ethical issues inherent in globalization of science and engineering and the international regulation of science and technology; and 3) by making visible the diversity of ethical structures and processes in governmental bodies around the world. The widely disseminated curriculum will benefit scientists and engineers across the disciplines, who face the challenges of globalization in the economy and in their research settings. This educational project is designed to effect a broad impact by affording scientists and engineers a greater capacity to work reflectively and ethically across countries and cultures and to engage ethical challenges involved in working in multiple political and social settings.","title":"International Dimensions of Ethics Education in Science and Engineering","awardID":"0734887","effectiveDate":"2007-09-15","expirationDate":"2011-01-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0405","name":"Division of OF SOCIAL AND ECONOMIC SCIENCE","abbr":"SES"},"pgm":{"id":"7915","name":"Ethics & Values of SET"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":[351256,"558897","552841",351259,"424075"],"PO":["447804"]},"131095":{"abstract":"This research deals with computationally hard algebraic and combinatorial problems. It investigates variations of the recent faster integer multiplication algorithm and explores its applications to polynomial multiplication and Fourier transforms. Integer multiplication is such a fundamental arithmetic task that understanding and improving it is an obvious basic intellectual challenge. There could be an impact on the search for Mersenne primes. Another major goal is to design and analyze discrete algorithms that are approximating solutions to combinatorial optimization and counting problems. Exact solutions for hard problems are often not feasible. In such cases approximation algorithms are a viable alternative. Of particular interest is the monomer dimer problem, the counting of matchings in grid graphs, which is of much importance in statistical physics.<br\/><br\/>As a tool for approximating the permanent, this research explores the possibility of doing matrix scaling efficiently in parallel. Such a solution would allow to solve (in NC) the outstanding bipartite matching problem of parallel computing. Even though the matching problem is easy for a<br\/>sequential machine, it is very challenging to coordinate the many processors of a parallel machine to work simultaneously on the same matching and be efficient. The intellectual merit of this research relies on the fact that many solutions require sophisticated methods of mathematical reasoning.<br\/>Successful solutions have the potential to enhance the understanding of the possibilities of approximations and parallel computations in general. A broader impact is given by the potential of having a significant effect on a major problem in statistical physics.","title":"Algorithms for Algebraic and Combinatorial Problems","awardID":"0728921","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["551015"],"PO":["565251"]},"135352":{"abstract":"The goal of this proposal is to study the development of new and<br\/>efficient class of parallel guaranteed quality and three-dimensional<br\/>(3D) mesh generation methods for real-time finite element computations<br\/>on current and emerging parallel architectures. Specifically, we<br\/>will: (1) generalize the point insertion theory for 3D guaranteed<br\/>quality Delaunay mesh generation, (2) develop a parallel theoretical<br\/>framework that can deploy this method with limited additional effort<br\/>from sequential to multicore\/multithreaded processors and eventually<br\/>on clusters of multiprocessor nodes with multicore\/multithreaded<br\/>processors, (3) perform complexity analysis using the practical LogP<br\/>model and (4) finally implement the first ever 3D parallel guaranteed<br\/>quality mesh generation method using existing state-of-the-art fully<br\/>functional sequential software and the parallel framework we will<br\/>develop.<br\/><br\/>The intellectual merit of this proposal is to derive an entire 3D<br\/>region inside the circumscribed sphere, for the selection of Steiner<br\/>point insertion. The novelty of the approach is that we have the<br\/>flexibility to use many new positions for point insertion of Delaunay<br\/>methods rather than one or two choices were used in the past; the<br\/>additional choices create more opportunities to improve size<br\/>optimality along with other application-centric criteria (multiple<br\/>tissues\/materials). In addition, for the first time ever, we can<br\/>achieve code re-use for 3D geometries. The project will have broader<br\/>impact on several scientific computing and engineering communities <br\/>like mesh generation and bioengineering.","title":"SGER: Three-Dimensional Generalized Parallel Delaunay Mesh Generation for the Numerical Solution of Partial Differential Equations","awardID":"0750901","effectiveDate":"2007-09-15","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["561580"],"PO":["399214"]},"134274":{"abstract":"This project makes a fundamental contribution to the field of direct brain interfaces (DBI) by introducing new paradigms for continuous control interfaces for human-computer interaction. One of the most effective direct brain interfaces is an evoked-response method based on Steady State Visual Evoked Potentials (SSVEP), with relatively high information rates, accuracy averaging over 95%, and no training required. Control in of SSVEP-based systems is implemented in a simple discrete selection paradigm, such as choosing from a set of icons. Discrete selection techniques work well for applications such as spelling or choosing a channel on a television. Unfortunately, they do not work well for continuous tasks such as drawing, moving a cursor on a screen, or driving a wheelchair. This project will explore, develop, and validate an SSVEP-based direct brain interface to provide a continuous channel of control for people with severe physical disabilities. The objectives are: 1) to create and evaluate SSVEP-based DBI paradigms for continuous control; and 2) to validate the control methods by applying the new continuous control interface to a wheelchair navigation task.<br\/><br\/>Methods for continuous SSVEP-based DBI control signals have broad applications for commercial, military and assistive technologies that go beyond users with motor impairment. Such developments could be applied as enhancements or replacements for traditional interfaces in places where the environment itself impairs the user?s control abilities, such as a fighter pilot?s cockpit, an astronaut?s space suit or a deep-sea diver?s helmet; or where the user is required to dedicate their physical resources elsewhere, such as a doctor performing surgery. Mainstream users, particularly the elderly, may benefit from a hands-free interface, and continuous neural control could provide an added dimension to more common interactions such as gaming.","title":"SGER: HCC: Evoked-Response Direct Brain Interfaces for Continuous Control","awardID":"0745829","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["554219"],"PO":["565227"]},"138784":{"abstract":"Proposal Number: 0716389<br\/>PI: Rafail Ostrovsky<br\/>Institution: University of California, Los Angeles <br\/>Lead<br\/><br\/>Proposal Number: 0716199<br\/>PI: Brent Waters<br\/>Institution: SRI International<br\/>Sub<br\/><br\/>Proposal Number: 0715739<br\/>PI: Dan Boneh<br\/>Institution: Stanford University<br\/>Sub<br\/><br\/>Proposal Number 0716230<br\/>PI: Dawn Song<br\/>Institution: Carnegie Mellon University<br\/>Sub<br\/><br\/><br\/><br\/>Title: Collaborative Research CT-T: Cryptographic Techniques for Searching and Processing Encrypted Data<br\/><br\/><br\/><br\/><br\/><br\/>In this proposal we consider the question of what constitutes identities in cryptography. Typical examples of identities include your name and your social-security number, or your fingerprint\/iris-scan, or your address, or your (non-revoked) Public-Key coming from some trusted public-key infrastructure. In many situations, however, where you are defines your identity. For example, we know the role of a bank-teller behind a bullet-proof bank window not because he or she shows us her<br\/>credentials but by merely knowing her location. In this proposal, we ask the following question: is it possible to have the \"\"geographical position\"\" of a party take part in defining the set of credentials<br\/>she has? What are the new possibilities in terms of what we can achieve in this setting?<br\/><br\/>First, we propose to consider the central task in this setting, i.e.,<br\/>securely verifying the position of a device. Despite much work in this area, we have preliminary results that show that in the \"\"vanilla\"\" (i.e., standard) model, the above task (i.e., of secure<br\/>positioning) is impossible to achieve.<br\/><br\/>We propose to study the proof of position in the bounded storage model (i.e. where we assume some bound on the total memory of the adversary).<br\/>In this setting, we wish to achieve two tasks: secure positioning, and position-based key exchange. While the question of secure positioning has been asked in the past, no satisfactory answers exist. <br\/><br\/>The second question (of position-based key exchange) has not been asked in the past. We also ask a broader question: whether position-based Secure Multi-Party Computation can be achieved in this setting.","title":"Collaborative Research: CT-T: Cryptographic Techniques for Searching and Processing Encrypted Data","awardID":"0808617","effectiveDate":"2007-09-24","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["526903"],"PO":["565239"]},"135044":{"abstract":"This project addresses the dearth of knowledge regarding the impact of communication ergonomics on the information exchange systems of an emergency response effort. Information exchange during a disaster event is vital to ensure the coordination of response efforts, to manage the allocation of resources, and to prevent further harm from occurring. Yet yhe unpredictable and urgency associated with natural or man-made disasters presents a unique set of extraordinary conditions in which ordinary methods, procedures, and infrastructure are often proven to be inadequate. In a substantial disaster situation the inherent situational stressors have the potential to further confound the human impact risk factors. The psychological, physiological and cognitive states of individuals are increasingly stressed. In particular, communication ergonomics may be impacted not only by the introduction of new, unfamiliar and possibly unidentified stressors, but also as a consequence of challenges arising from numerous organizations simultaneously responding to the event without the ability to share needed information. Proper evaluation of the human impact on disaster information exchange systems is vital to ensure effective communication during a disaster situation. While niche work has been carried out on improving communication infrastructures, developing alternative means of communications and establishing universal protocols, there is a significant lack of knowledge on the impact human factors have on the overall system mechanics. The PI argues that human reliability modeling, human computer interaction, and cognitive ergonomics all need to be considered when designing information exchange systems. In this project, she will work with first responders such as the U.S. Army Corp of Engineers (USACE), the Orange County Florida Emergency Response Office, the Federal Emergency Management Agency (FEMA), the University of Central Florida Disaster Response Team, as well as various private companies that were contractors in hurricanes Katrina, Rita and Wilma, to explore a novel approach that considers information exchange systems in disaster management as a human-systems interface design problem. The goal is to develop a methodology, collect data and validate the methodology in the 2007 hurricane season, so time is of the essence. Project outcomes will include accumulation and analysis of historical information exchange data, definition of a conceptual model of current information exchange as well as of a taxonomy of human factors stressors affecting human performance and reliability, identification of physical and physiological factors impacting delivery of disaster management services, and development of a methodology for addressing critical human factors issues in disaster management communication issues, along with a \"mock\" application. The University of Central Florida campus will serve as the test bed environment to model disaster occurrence; with on-campus housing, medical facilities, emergency response services, and communication networks, along with an independent police force, limited traffic corridors and a population of over 45,000 students and 10,000 employees, the University of Central Florida can accurately represent a scale model of a medium to large size American city.<br\/><br\/>Broader Impacts: This project will lead to a new information exchange conceptual model using a user centered approach. The research will lay the groundwork for the design of decision support systems that augment human abilities, and for the development of a global knowledge base that can be utilized to minimize the psychological and physiological impact of disaster preparation on individuals.","title":"SGER-Human Factors and Ergonomics in Disaster Management Information Exchange","awardID":"0749658","effectiveDate":"2007-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["533425"],"PO":["565227"]},"126596":{"abstract":"The proposed project aims to build a programmable network infrastructure for advancing research and education in areas of computer network and wireless communication technologies at the University of Massachusetts Lowell. This infrastructure provides an extensible network test bed that is highly desirable in network research and education, but not yet available from conventional off-the-shelf network devices.<br\/><br\/>The objective of the project is to build a programmable network platform for collaborative research and education. In particular, this research will (1) construct a network infrastructure with programmable components for experimenting new network designs; (2) study the programmability of the infrastructure and evaluate its performance on network processing; (3) apply the infrastructure in a broad range of research topics, including network security, network processor design, and dynamic spectrum sharing; (4) integrate experiment, theory and computational research in networks and communications into educational modules.<br\/><br\/>The proposed programmable network infrastructure is a customized network infrastructure equipped with high-speed wired switches, wireless routers with programmable radio interfaces, and spectrum analyzers for physical layer measurements. The incorporation of network processors, FPGAs, and software radios provides programmability at each layer of the network and within each device, making it possible to conduct experiments on packet-processing workload characterization, security protocol evaluation, dynamic spectrum access, and sliced network services. Such experimental research provides necessary validation to theoretical results and leads to new research directions. Most importantly, the proposed infrastructure will foster collaborations among co-PIs to study principal research challenges towards the GENI architecture.","title":"CRI: IAD: Programmable Network Infrastructure with Emerging Technologies","awardID":"0709001","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["554394","388427","463098","431963"],"PO":["565090"]},"129511":{"abstract":"Wireless sensor networks have revealed vast potential in providing accurate and cost-effective monitoring for a plethora of applications. In stark contrast with traditional data forwarding networks exemplified by the Internet, wireless sensor networks are uniquely characterized by drastically low data rate, often at several bytes per minute, owing to application specific requirements. Despite numerous groundbreaking work in this field, the underlying communication techniques, particularly at the physical and link layers, are still largely germinating along the Internet root and its wireless extensions. Moreover, energy efficiency has overwhelmingly relied on coordinated sleep\/wakeup schemes, where communications are synchronized into a short time window. Inevitably this will augment the collision probability and irrelevant packet listening, the two dominant power consumption components in wireless networks.<br\/><br\/>Motivated by recent advancements in semi-passive RFID technology, this project will develop an innovative asynchronous communication architecture, in which a sensor node is allowed to directly write data into a special, reactive module (RFID tag based) residing on the receiving node while its main platform (the central controller) is asleep. Owing to the low duty cycle of a sensor node, the proposed asynchronous architecture will liberate the network from collisions and idle listening by fully exploiting time as one dimension of resource (no conventional MAC needed) and hence achieve high energy efficiency. Furthermore, with this fundamentally new paradigm for communication in energy-constrained systems, this project will also study the overlaying computation paradigm, including sampling, in-network processing, and routing, in order to accommodate, fully unleash, and demonstrate its enormous impact.","title":"NOSS: ARCADIA: An Asynchronous Communication Architecture Toward Novel Networking and Computation Paradigms in Wireless Sensor Networks","awardID":"0721951","effectiveDate":"2007-09-01","expirationDate":"2013-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["564777","486502","492475"],"PO":["565303"]},"127454":{"abstract":"IIS - 0713273<br\/>Alcock, Charles<br\/>Harvard University<br\/>Collaborative Research: Discovering Unexpected Planets and Other Astronomical Oddities<br\/><br\/>This project seeks to provide automated methods for analyzing sky surveys to detect extra-solar planets via anomaly and novelty detection methods. Extremely large astronomical synoptic surveys will soon monitor much of the sky regularly, detecting vast numbers of interesting, variable astronomical objects. The objective of this proposal is to develop the tools necessary to exploit these new data in order advance discovery. The proposed work will explore the scientific analysis and modeling of massive datasets of light-curves (66 million light-curves now available, growing to 100 billion in a decade) from a broad range of perspectives. The unique complications posed by the data in this domain will drive research for data mining techniques to allow these analyses. A comprehensive framework of models and their relationships with the data will be developed that readily separates two kinds of interesting objects: (1) Rare objects that reveal special insights about the models; and (2) Potential truly novel objects that cannot be described by the models. New computationally tractable time series algorithms for novelty detection will be developed for these purposes.","title":"SEI: Collaborative Research: Discovering Unexpected Planets and Other Astronomical Oddities","awardID":"0713273","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["471355"],"PO":["565136"]},"129522":{"abstract":"The design of wireless ad-hoc networks faces a number of unique challenges in wireless communications including 1) co-channel interference among active links in a neighborhood, and 2) time-varying channel conditions over fading channels. Experimental data reveals that, in many realistic scenarios, fading effects can often adversely affect the MAC layer, and the coupling between the timescales of fading and MAC calls for a unified PHY\/MAC design. Due to the distributed nature of ad hoc communications, little work has been done to develop channel-aware, distributed scheduling for throughput maximization. There are virtually no systematic studies on channel-aware scheduling for real-time traffic under latency constraints. <br\/><br\/>A principal goal of this project is to fill this void and build a theoretic foundation for channel-aware, distributed scheduling in wireless ad-hoc networks, for both elastic traffic and inelastic traffic. With the goal of developing a framework for unified PHY\/MAC optimization, the proposed research consists of three thrusts. The first two thrusts investigate distributed opportunistic scheduling for elastic traffic and focus on throughput maximization from network-centric and user-centric perspectives, respectively. The third thrust focuses on channel-aware scheduling for network models under explicit delay constraints, for real-time traffic. The proposed research draws on a combination of fundamental tools in scheduling, stochastic optimization, game theory, and control theory. This project will open a new avenue for exploring channel-aware distributed scheduling for ad-hoc communications.<br\/><br\/>The PIs expect that the proposed work will culminate in the formulation of both new fundamental theories and advanced design methodologies for wireless ad hoc networks, and will have a significant impact on many wireless applications including wireless LANs and wireless mesh networks. In addition to the technical impacts, the broader impacts of the proposed research also include educational elements.","title":"NeTS-WN: Collaborative Research: Channel-Aware Distributed Scheduling for Optimal Throughput and Latency: A Unified PHY\/MAC Approach","awardID":"0721992","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["541861"],"PO":["557315"]},"125166":{"abstract":"The introduction of multi-core processors personal computing platforms such as desktops, laptops and game consoles open up interesting end-user application possibilities making parallelism more ubiquitous than ever. Trends show an increasing presence of immersive multimedia and gaming applications on newer personal computing platforms. One of the desirable features of such applications is that the applications exhibit varying degrees of sophistication based on the resource-richness of the platform on which they execute. Current programming paradigms are limited in their ability to express variable semantics of applications that could scale dynamically to the resource availability. <br\/>This limitation leads to huge barriers causing applications to evolve slowly as the platforms emerge. On the other hand, multi-core processors are rapidly evolving and if one is unable to use the extra cores their value will be severely diminished. In order to bridge this gap, it is important to develop languages and compiler technology that offers a scaling of application semantics with the processor power.<br\/><br\/>This work investigates a new paradigm, called Opportunistic Computing, that allows a specification of scalable semantics in applications that can be enriched and thus adapt to the amount of available resources at runtime. A domain specific programming language involving extensions to C++ allows the programmer to define a specification of how the current semantics of a program can be opportunistically enriched. It can take the form of an additional computation, the choice of the best computation at runtime for a given quality of result or the adaptation of the current computation into a better one. The work develops and investigates new analyses and techniques for managing the runtime and software transactional memory under compiler control coupled with the compiler controlled scheduling of soft real-time tasks.","title":"Opportunistic Computing: A New Paradigm for Scalable Programming on Multicore Processors","awardID":"0702286","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7329","name":"COMPILERS"}}],"PIcoPI":["550988"],"PO":["565272"]},"125287":{"abstract":"Topology-based Methods for Analysis and Visualization of Noisy Data<br\/>Principal Investigator: Bernd Hamann, University of California, Davis<br\/><br\/>Abstract<br\/><br\/>The size of scientific data sets that are generated by evolving supercomputers, large sensor networks, and high-resolution imaging devices is increasing rapidly, at an exponential rate. This project addresses the need for more effective data analysis methods. It develops technologies concerned with the analysis and representation of very large scientific data sets, emphasizing concepts that capture qualitative characteristics. In light of the limitations of purely visualization-based approaches applied to \"raw\" scientific data sets directly, this project aims at devising new concepts for visualizing very large and complex data sets. The methods being developed first extract meaningful qualitative information from a given data set, which is then used to present the higher-level information content of the data set in a significantly more compact form, thus stressing relevant qualitative behavior.<br\/><br\/>The project builds on concepts from classical topology and geometry, which have contributed substantially to the development of the relatively new fields of computational topology and computational geometry. These two fields hold great potential for substantially advancing the visualization technology for understanding extremely large, complicated data sets. This projects adapts (and generalizes) computational topology and computational geometry algorithms that are well-established for smooth mathematical functions to real-world, finite-sample data sets, i.e., functions sampled at a finite number of points (that could possibly be connected by a mesh). Real-world data sets are noisy, which further complicates the application of topological methods that were developed originally for smooth functions. This project investigates the generalization of techniques based on Morse and Morse-Smale theory (studying critical-point behavior and drawing qualitative conclusions about functions) to discretized scalar fields that change over time and also contain noise.","title":"Topology-based Methods for Analysis and Visualization of Noisy Data","awardID":"0702817","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["495182","548347",332462],"PO":["565157"]},"129413":{"abstract":"The project aims at developing the foundations and the technology required for fine-grain indoor localization of wireless nodes using radio interferometry. Specifically, the project will develop a propagation model for radio interference signals in severe Multipath environments and an allocation strategy of frequency bands and channels to minimize RF multipath effects, maximize accuracy, and minimize measurement time. <br\/>The project will also investigate how localization algorithms could work with linear combinations of distances of four nodes provided by the interferometric measurements as opposed to traditional pair-wise range estimates. <br\/>The expected results of the research are a set of ranging, localization, and tracking services that achieve high precision localization even indoors and a corresponding reference implementation on an existing hardware platform. <br\/>The implementation will enable extensive experimentation to gain additional insight into different reverberant environments as well as to validate the theoretical results under a range of different real-world conditions. <br\/>The results can potentially enable many location-aware applications, such as accurate asset tracking in warehouses, precise localization of 802.11 nodes in WiFi networks, navigation for emergency personnel, as well as many indoor applications of wireless sensor networks.","title":"Radio Interferometric Tracking of Wireless Nodes Indoors","awardID":"0721604","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["551714","533198","527012"],"PO":["557315"]},"128203":{"abstract":"Energy infrastructure is a critical underpinning of modern society that any compromise or sabotage of its secure and reliable operation will have a prominent impact on people's daily lives and the national economy. This project develops a hardware-in-the-loop reconfigurable system with embedded intelligence and resilient coordination schemes that would tackle the vulnerabilities of the power grid. This system differentiates itself from previous and existing research efforts in the following key aspects. First, it capitalizes and integrates new power electronic technologies in the system design to facilitate a more direct reconfiguration of the physical makeup of the grid. Second, it pushes the intelligence toward the lower level of the power grid such that local devices have the capability to make decisions and to react more quickly to contingencies. Third, it adopts control-theoretic real-time adaptation strategies for analytic assurance on providing desired dynamic responses to unpredictable system changes to efficiently maintain the availability of large distributed systems. Finally, the system is evaluated not only through simulation, it is also implemented and demonstrated on a microgrid testbed. The evaluation is conducted from three aspects, including real-time responsibility, fault resiliency, local collaboration capability. The power grid is a typical example of complex networks of highly interacting subsystems. Solving these fundamental problems to create a resilient power grid has a direct and immediate impact on this and other critical infrastructure. The project is coupled with a strong educational component including an innovative multi-university curriculum design, active recruitment of students from underrepresented groups supported by existing programs, and broad dissemination of research findings.","title":"Collaborative Research: CT-T: A Resilient Real-Time System for a Secure and Reconfigurable Power Grid","awardID":"0716435","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["553866"],"PO":["521752"]},"129534":{"abstract":"Troubleshooting is an inherent part of network operation: no matter how well networks are designed, something eventually fails, and in large networks, failures are ever-present. In the past, troubleshooting has mostly relied on ad hoc techniques cobbled together as afterthoughts. However, both the importance and difficulty of troubleshooting has intensified as networks have become crucial, ubiquitous components of modern life, while at the same time their size and complexity continues to grow. These twin pressures highlight the urgent need to integrate troubleshooting as a first-class citizen when developing a network architecture.<br\/><br\/>Armed with a set of general principles, we are building a set of key building blocks for troubleshooting. The task of troubleshooting is one of vast range and eclectic trajectories. As such, the approaches we are developing are not limited to specific domains (e.g., web surfing performance, or routing connectivity failures) but are designed to be generally applicable across architectures, and evolvable as a network's structure and uses inevitably change. The goal is for our experiences to both inform broader communities, such as NSF's Future Internet Design (FIND) community, about ways to weave troubleshooting into new architectures, and in turn to take from these other architectural efforts both requirements and synergistic insights.<br\/><br\/>The health and failure of networks is of broad societal impact and improvements and breakthroughs in troubleshooting will have corresponding impact. Due to the wide reach of troubleshooting, privacy of information becomes a consideration, so we are developing privacy-aware principles throughout our work.","title":"NeTS-FIND: Architectural Support for Network Trouble-Shooting","awardID":"0722035","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560562","562327","563433"],"PO":["565090"]},"127356":{"abstract":"This project investigates a novel approach for assessing the fluency and<br\/>grammaticality of alternative translation hypotheses that are created within<br\/>search-based Machine Translation (MT) systems. This task, commonly termed<br\/>\"\"Language Modeling\"\" (LM), has been explored primarily in the context of speech<br\/>recognition; however, current state-of-the-art language models (LMs) are not<br\/>effective at distinguishing between more fluent grammatical translations and<br\/>their poor alternatives. In contrast, the proposed approach, \"\"Discriminative<br\/>Knowledge-Rich Language Modeling\"\" (DKRLM), is explicitly designed to find the<br\/>most fluent and grammatical translations within the search space by comparing<br\/>the linguistic features of the translation hypotheses against very large<br\/>\"\"clean\"\" monolingual corpora. The intuition is that more grammatical<br\/>translation hypotheses should contain higher proportions of features seen in<br\/>the large corpora. An important contribution of the project is in exploring<br\/>different types of linguistic features to identify those that are most<br\/>informative for the comparisons. Moreover, discriminative training is<br\/>performed to incorporate the features into a system-independent scoring<br\/>function, replacing traditional LMs in MT systems. The broader impacts of the<br\/>proposed work include both broader adoption for the methodology as well as<br\/>wider use of the new DKRLM functions to other search-based NLP applications<br\/>that aim at generating fluent grammatical text. This includes search-based<br\/>approaches to Speech Recognition, Natural Language Generation (NLG), Optical<br\/>Character Recognition (OCR), Summarization, and others.","title":"Collaborative: Discriminative Knowledge-Rich Language Modeling for Machine Translation","awardID":"0712810","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["357107"],"PO":["565215"]},"128214":{"abstract":"Trust in a system can be compromised in many places. Extensive research has been conducted on the development of trustworthy requirements and policies, but those requirements and policies are effective only if they are carried out correctly. Ensuring the absence of implementation flaws by testing is inadequate; testing cannot be exhaustive and thus can miss critical vulnerabilities. Formal verification?proof that the system correctly implements its specification and enforces its policies?is an attractive alternative.<br\/><br\/>Standard approaches to formal verification are powerful, but experience has shown them to challenging to use. Specification languages fail to describe complete systems, tools with limited capabilities cannot be integrated, verification techniques are difficult and time consuming to apply, and verification requires high levels of expertise. Current approaches also impose limitations on developers that make it difficult to fit formal verification into the development cycle.<br\/><br\/>Our approach, Echo, is a new approach to formal software verification that makes such verification readily available, applicable, cost effective, and useful to the community that needs it. The basis of our approach, in stark contrast to traditional methods, is to transform the program, extract a high-level specification from a low-level one, and prove that it implies the original specification. The required analysis is split between a powerful general-purpose theorem-proving system and a low-level verification system.<br\/><br\/>Echo will improve security and other facets of dependability in important computer applications thereby reducing losses resulting from security attacks and other failures.","title":"CT-T: Practical Formal Verification By Specification Extraction","awardID":"0716478","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["402466","385658",339851,"496766"],"PO":["565327"]},"129545":{"abstract":"The Internet has evolved greatly from its original incarnation. For instance, the vast majority of current Internet usage is data retrieval and service access, whereas the architecture was designed around host-to-host applications such as telnet and ftp. Moreover, the original Internet was a purely transparent carrier of packets, but now the various network stakeholders use middleboxes to improve security and accelerate applications. To adapt to these changes, this project will design, develop and deploy a design called the Data- Oriented Network Architecture (DONA). DONA replaces DNS names with flat, self-certifying names, and replaces DNS name resolution with a name-based anycast primitive that lives above the IP layer. <br\/><br\/>Broader Impact: DONA improves data retrieval and service access by providing stronger and more architecturally coherent support for name persistence, content availability, and data authentication. It can also be extended to provide support for caching and RSS-like updates.","title":"NeTS-FIND: Collaborative Research: A New Approach to Internet Naming and Name Resolution","awardID":"0722081","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["508219"],"PO":["565090"]},"129314":{"abstract":"In large and complex communication networks, architectural decisions regarding functionality allocation are often more important than the details of resource allocation algorithms themselves. This NSF-funded project aims to develop a scientific foundation for designing network architectures by building upon recent successes in understanding protocols as optimizers and layering as mathematical decompositions. In particular, the PIs at five institutions collaborate to conduct a wide range of closely-connected research activities that substantially improve upon the state-of-the-art. Starting from a convex optimization formulation of the architecture design problem, the project investigates a wide range of alternative decompositions that provide different scalability, convergence, and complexity tradeoffs. The PIs then determine whether the properties of these alternative architectures continue to hold under stochastic network dynamics and non-convex objectives and constraints, and develop new architectural designs from a careful study of such dynamics. Mathematically, this project leads to a long-overdue union between network optimization and stochastic networks theory, and enables a systematic approach to leverage advances in general non-convex optimization.<br\/><br\/>Broader Impact: This project has clear synergy with the NSF's GENI initiative. The research provides a strong, analytic foundation for the design of future network architectures, including clean-slate solutions that deviate from todays Internet. The exploration of new ways to decompose functionality, with the influence of network dynamics and non-convexity in mind, will result in new protocols and mechanisms that can be evaluated in the GENI infrastructure.","title":"FIND: Collaborative Research: Towards An Analytic Foundation for Network Architectures","awardID":"0721236","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["548182"],"PO":["565090"]},"129556":{"abstract":"TITLE: Can Humanitarian Open-Source Software Development Help Revitalize Undergraduate Computing Education?<br\/><br\/>PI: Ralph Morelli (ralph.morelli@trincoll.edu)<br\/><br\/>This community building project creates a diverse community of individuals from academic computing departments, social service organizations, and computing and IT corporations, to test the hypothesis that humanitarian free and open-source software development (H-FOSS) can help revitalize undergraduate computing education. The project will capitalize on two contemporary interests that are under served in computing curricula: the open-source development model, as a way to teach software engineering; and, service-learning, as a means by which students and faculty can contribute to the surrounding community. A software development version of the Habitat for Humanity model will be investigated: instead of building houses, students and faculty will learn computing by building software systems that benefit humanity. To combat the computing-is-coding myth, community-based summer and academic year internships will demonstrate that computing is working together with other people to design and develop solutions to real problems. By engaging students and faculty from participating schools in summer institutes, credit courses, spring-break community-help projects, and an academic curriculum workshop, the project will develop a portable and sustainable educational model that attracts socially engaged students to the computing discipline, bridges the divide between town and gown, and builds truly useful humanitarian software.","title":"CPATH CB Collaborative: Can Humanitarian Open-Source Development Help Revitalize Undergraduate Computing Education?","awardID":"0722134","effectiveDate":"2007-09-01","expirationDate":"2010-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["425175","550122"],"PO":["562944"]},"129204":{"abstract":"Critical systems should be built in a manner that makes them not only adequately dependable, but demonstrably adequately dependable. An assurance case is an argument that demonstrates how the specific evidence resulting from system development efforts (test results, results of static analysis, etc.) combine to support the conclusion that the system is adequately dependable. The assurance case moreover documents the rationale used to draw conclusions about each piece of evidence. In the event of a failure that is not a random event, this record can be examined to discover the faulty reasoning that led to the release of the flawed system, thus helping developers to redress the system?s flaws and to avoid making similar mistakes in future development efforts. <br\/><br\/>This research is developing methods for Assurance Based Development that couples the development of the system with the development of its assurance case so that explicit criteria for the dependability impact of each development decision are available at the time the decision is made. The need for assurance of dependability drives system development, leading developers to make choices that give rise to both the needed dependability and evidence of that dependability. The explicit evaluation of dependability throughout the development process also facilitates detection and avoidance of potential assurance difficulties as they arise, rather than after development is complete?when they are much harder to address. Furthermore, knowing the assurance obligation incident on each part of the system will give developers the flexibility to deploy expensive technology, such as formal verification, only on components whose assurance needs demand it.","title":"CSR: EHS: Assurance-Based Development of Critical Embedded Systems","awardID":"0720794","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["402466","402467"],"PO":["561889"]},"129215":{"abstract":"Significant pieces of our nation's critical infrastructures depend on automation systems that operate under tight safety and timing constraints. Critical infrastructure security, bottling and packaging, material and container handling, automated manufacturing, on-board ship systems, locomotion systems, airport baggage handling, and amusement park rides are a few examples of such systems. With over a trillion dollars of installed base in North America, and over $90 Billion dollars forecasted revenues for year 2008, these systems represent an important class of embedded real-time systems. However, there are serious design and operational problems in existing automation systems. Rigid architectures and proprietary\/inflexible implementations have resulted in systems that are difficult to operate and maintain. This project addresses research issues that are critical for incorporating advances in networked embedded computing into automation systems with flexible topologies. Technology support for atomic and coordinated actions enables cooperative operation in complex, coupled automation systems. A real-time middleware framework for sensor-actuator systems is being developed, providing services for node-level execution, scheduling, synchronization, mode-management, and fault management. By incorporating these advances, it is possible to reduce costs, achieve fine-grained control, improve safety, and design automation systems with flexible topologies for a variety of applications such as automotive assembly lines, chemical process industries, warehouses, airport baggage carousels, amusement park rides and package distribution centers. By focusing on the specific domain of automation systems, this project seeks to drive several innovations that include: targeted integration of sensors and actuators in low-cost nodes, dynamic re-configurability of wireless sensor networks driven by exception conditions, exploitation of redundancy to mask individual node or sensor failures, a scalable infrastructure, monitoring of large-scale operations, performance under constrained conditions, specialized algorithms and communication protocols that address real-life automation requirements, and inter-operability with current automation systems.","title":"Collaborative Research: CSR-EHS: Real-time Sensor-Actuator Systems for Automation","awardID":"0720816","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["461012"],"PO":["561889"]},"128126":{"abstract":"Encryption and signatures are two of the most fundamental cryptographic tools, enabling private and authentic communication. Yet, their adoption in applications, such as email, distributed storage, digital rights management and health care systems, has been slow. A primary reason is that many common operations that arise when using these tools in practice create (sometimes insurmountable) key management<br\/>problems. This research studies how to design encryption and signature schemes with greater key management flexibility.<br\/><br\/>In particular, this research focuses on situations where data encrypted (or signed) under one cryptographic key needs to be re-encrypted (or re-signed) under another cryptographic key by a semi-trusted proxy given special information. For example, suppose Alice wants her mail server to forward her encrypted email to Bob without being able to read her messages. Investigators will broaden the theoretical foundations of proxy re-cryptography and work with industry partners to evaluate their performance in practice. The research will study the application of proxy re-signatures for maintaining the integrity of dynamic content distribution of documents on the Web.<br\/><br\/>Graduate students and women researchers will be involved in all aspects of this project, collaborating on both the theory and practice. Techniques derived from this research will be incorporated into cryptography and computer security courses at both universities.<br\/>Thus, this project will help develop future well-rounded scientists able to design and apply cryptographic tools.","title":"CT-ISG Collaborative Research: New directions and applications of proxy re-cryptography","awardID":"0716142","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":[339640,"521326"],"PO":["565264"]},"129457":{"abstract":"Increasing demand for high data rate applications, such as multimedia services and mobile TV over wireless ad hoc networks, urges researchers to develop more flexible network protocols in order to meet various Quality of Service (QoS) requirements. Unfortunately, the traditional strict layering design approach is no longer effective in wireless ad hoc networks, particularly in the mobile ad hoc networks, and fails to achieve the desired flexibility. Thus, cross-layer network design becomes much more important than ever and should be investigated thoroughly. <br\/>In this project, the PI carefully selects three research tasks ? joint design of flow\/congestion control and medium access control, active collaborative relaying, and opportunistic medium access control and auto rate control ? to demonstrate how cross-layer design should be done and how this design could improve the performance. In all these problems, the medium access control (MAC) layer acts as the anchor point to extract the needed information about the wireless environment to be used for other layers. In so doing, network protocols can be made more adaptive and responsive. <br\/>It is expected that cross-layer design methodology can be significantly advanced through this research. Moreover, the basic ideas and the cross-layer design methodology introduced in this research open a new avenue to the design of efficient network protocols and the proposed technologies could be easily incorporated into the commercial products, and hence will have significant economic impact on the telecommunication industries. Finally, any research outcome of cross-layer design can be easily incorporated into wireless network courses that train the future work force.","title":"NeTS-WN: A Novel Cross-layer Design Approach for Wireless Ad Hoc Networks","awardID":"0721744","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["560200"],"PO":["557315"]},"129468":{"abstract":"In this project, the PIs will focus on the emerging Dynamic Spectrum Access (DSA) Wireless Mesh Networks (WMNs). Cross-layer design is strongly needed for such a network due to its two special features; dynamic spectrum availability and spectrum heterogeneity. Quite different from other well-studied wireless networks, such as mobile ad hoc networks and wireless sensor networks, the major concerns of WMNs are throughput, fairness, and QoS support, instead of mobility support and power efficiency.<br\/><br\/>The PIs plan to conduct a comprehensive study on cross-layer optimization in DSA WMNs, and design protocols under the guidance of this cross-layer optimization. They will concentrate on the bottom four layers of the network stack and seek joint congestion control, routing, spectrum sharing, and power control solutions with the objective of maximizing throughput, achieving certain fairness, and providing QoS support. Furthermore, the research will be conducted under various network models including different interference models, different traffic models, and different fairness models.<br\/><br\/>The INTELLECTUAL MERIT of the project includes (1) a unified mathematical model which precisely characterizes all important features and the formal formulations of the cross-layer optimization problems under different network models, (2) centralized and distributed algorithms for solving the optimization problems, and (3) a spectrum-aware routing protocol.<br\/><br\/>The BROADER IMPACT of the project includes (1) novel cross-layer schemes for emerging DSA WMNs, with impact on the advancement of information technology, (2) high quality publications and training of highly skilled students, and (3) possible impact on the standardization in IETF and IEEE for DSA wireless networks in the future.","title":"NeTS-WN: Collaborative Research: Cross-layer Optimization for Dynamic Spectrum Access Wireless Mesh Networks","awardID":"0721803","effectiveDate":"2007-09-01","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["517891"],"PO":["434241"]},"128258":{"abstract":"CT-ER: Privacy Assurance in Location-Based Services: <br\/>Integrating Economic Exchange and Social Justice Perspectives<br\/><br\/>Recent advances in wireless computing and communication have led to the proliferation of location-based services (LBS). While LBS offer users the flexibility of accessing network services on the move, potential privacy violations have emerged as a contentious issue because details of user identities, movements and behaviors are available to LBS providers. Drawing on the economic exchange and social justice theories, this research addresses privacy issues by examining key mechanisms that can alleviate users' privacy concerns. A theoretical framework is developed to link three privacy assurance mechanisms (technology control, industry self-regulation, and government legislation) to the individual privacy decision making process. In addition, as the individual privacy decision making is usually dynamic, context-specific and culture-dependent, two-stage studies are performed to test the research model in three different social contexts and in two countries with different cultures (Singapore and United States). <br\/><br\/>This research is novel to the extent that existing privacy research has not examined the complex set of inter-related issues in the LBS context. It contributes to a better understanding of the dynamic and dialectic nature of information privacy through a combination of theoretical and empirical research efforts. The findings will have a broader impact in addressing the controversy surrounding the role of technology, industry self-regulation and legislation in bearing the responsibility of assuring individual privacy. Moreover, the interplay between social and technological issues associated with the privacy assurance will be the subject of a number of educational initiatives for Penn State's new major in Security and Risk Analysis.","title":"CT-ER: Privacy Assurance in Location-Based Services: Integrating Economic Exchange and Social Justice Perspectives","awardID":"0716646","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["550223","549540","549541"],"PO":["529429"]},"129479":{"abstract":"Many architectural elements of today's Internet implicitly assume that hosts remain attached to the network over extended periods of time. However, there is much to be gained by supporting a style of networking that does not require an end system to maintain full, ongoing connectivity in order to maintain its network \"presence.\" In this project we explore a style of networking that we term \"selectively-connected\", by which we mean an end system, can knowingly manage the extent of its network connectivity in response to internal or exterior events, as it anticipates changes in connectivity.<br\/><br\/>While selectively-connected networking also has applications for end systems that enter outage periods (e.g., a user closing a notebook, or a mobile device entering no-coverage area), one highly significant form of operation it can enable concerns placing end systems into some degree of \"sleep\" in order to operate with much greater energy efficiency. Such sleeping not only can benefit portable devices by greatly extending their battery lifetime, but can also realize energy savings at a national scale by enabling desktop systems and set-top devices to enter states of greatly reduced processing without sacrificing their network presence.<br\/><br\/>In this project the researchers undertake initial designs of new architectural components for better supporting selectively-connected networking, by which sleeping hosts can retain their standing in the network or delegate agents to act on their behalf during their absence. These span: exposing selective connectivity; evolving soft state into notions of \"proxyable\" or \"limbo\" state; facilitating host-based control; introducing \"assistants\" to work in concert with sleeping end systems; exploring primitives that applications might use to express the semantics they wish to preserve when selectively-connected; and considering network links that can themselves sleep when the end systems they serve are likewise sleeping.","title":"NeTS-FIND: Collaborative Research: Architectural Support for Selectively-Connected End Systems: Enabling an Energy-Efficient Future Internet","awardID":"0721858","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["528187"],"PO":["565090"]},"129369":{"abstract":"The wireless network of the future is envisioned to be a seamless integration of several existing and emerging wireless networks. A key enabler for this network of the future is the cognitive software defined radio (SDR) which takes advantage of programmable hardware modules to dynamically and adaptively modify the functionality of various radio subsystems. The goal of this research is to facilitate seamless integration of wireless networks where information sent from a source to a destination can traverse multiple links that belong to heterogeneous underlying networks. The design and operation of the resulting hybrid wireless network is determined by three characteristics of future software defined radios: Cognition, Collaboration, and Competition. Research results will demonstrate how inherently competitive SDRs (i) work together to learn about current local network conditions; and (ii) use this information to construct adaptive links and routes across these local networks (and \"non-networks\") so that end-to end quality of service requirements are met. Specific research outcomes will include distributed, collaborative algorithms that aid cognitive SDRs in spectrum sensing and hybrid wireless network formation.<br\/><br\/>This research will impact both commercial and military service providers who wish to extend network capacity and coverage by interconnecting existing and emerging wireless systems. The PIs aim to demonstrate broader impact of hybrid wireless networks by offering short workshops that educate rural Pennsylvania communities on its benefits. Additionally, research results will be disseminated and incorporated into wireless communications and networking courses at the respective institutions.","title":"NeTS-WN: Collaborative Research: Cognition, Collaboration, and Competition in Hybrid Wireless Networks","awardID":"0721445","effectiveDate":"2007-09-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["550356"],"PO":["557315"]},"130590":{"abstract":"Small-scale, few-bit quantum computers have now been realized in laboratories around the world, with technologies ranging from superconductors to trapped ions. However, this new computing technology will only be useful if large-scale machines with thousands to tens of millions of quantum bits can be realized. Because of the inherent high error rate of quantum devices, the key to large-scale quantum computation will be realistic application of fault-tolerance techniques to construct reliable systems from unreliable technologies.<br\/><br\/>Using new ideas from quantum codes, recently available data from implementation technologies, and new concepts for optimization of circuit reliability, this project addresses the challenge of large-scale fault-tolerant quantum computation in three areas. First, the investigators will study the requirements for fault-tolerant encoded operations. Second, the project will explore optimized circuits for quantum fault-tolerant architecture. Third, the investigators will perform a technology performance evaluation to<br\/>determine how well several implementation technologies can realize large-scale fault-tolerant quantum computation.","title":"Collaborative Research: EMT: Novel Operations, Circuit Optimization, and Technology Evaluation for Large-Scale, Fault-Tolerant Quantum Computing","awardID":"0726648","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["483569"],"PO":["565157"]},"131690":{"abstract":"During the last few decades, considerable progress has been made in the understanding of binary classification (learning of binary-valued functions) and regression (learning of real-valued functions), both classical problems in machine learning. Although several questions remain to be answered, there is a well-developed theory in place for these problems, and practical successes have been demonstrated in a variety of applications. Recently, a new learning problem, namely that of ranking, has begun to gain attention. In ranking, one learns a real-valued function that assigns scores to objects, but the scores themselves do not matter; instead, what is important is the relative ranking of objects induced by those scores. This problem is distinct from both classification and regression, and cannot be analyzed using existing results for these problems. Consequently, there is a need for a separate theoretical understanding for ranking. This project aims to develop such an understanding. Specifically, the project will investigate three directions: (1) Generalization bounds for ranking; (2) Learnability of ranking functions; and (3) Transductive ranking.<br\/><br\/>Ranking has applications in a vast number of domains: in information retrieval, one wants to rank documents according to relevance to some query or topic; in user-preference modeling, one wants to rank books or movies according to a user''''s likes and dislikes; in computational biology, one wants to rank genes according to their relevance to some disease. Currently, the mathematical properties of ranking are not well understood; save in a few special cases, not much is known about what kinds of ranking functions can be learned, how the performance of a learned ranking function on the training data translates to its expected performance on future data, and so on. By addressing these questions, the project will provide both a better mathematical understanding of ranking, and a strong theoretical foundation for its applications.","title":"MSPA-MCS: Learning to Rank","awardID":"0732334","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"7454","name":"MSPA-INTERDISCIPLINARY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["399045","517766",349733],"PO":["565286"]},"120580":{"abstract":"There is a great deal of interest in using new technologies to help developing nations improve the quality of lives of their citizens. Yet without a careful analysis of existing social and cultural norms and infrastructures, there is a great danger that technology-based \"solutions\" will fail. This grant will fund a collaboration between technologists, educators, and learning scientists in India and the US to design, implement and evaluate distance learning systems that help resource-starved village primary schools in rural villages to benefit from the better human and content resources available in urban environments. The basis of the project is a combination of YouTube, NetFlix, and file sharing: excellent teachers are videotaped in the classroom demonstrating good pedagogy teaching the same subject matter as is taught in village schools, these video clips will be automatically assembled and distributed using DVDs and the postal system to village schools, where the videos are used for on-site teacher training and mediated instruction by the local teacher.<br\/><br\/>Over a billion people on the planet are illiterate, in large part due to the lack of trained teachers in rural villages where most children in poverty live. Finding trained teachers for primary school education is nearly impossible in rural areas, despite these skills being essential for upward mobility in today's economy. Of course, distance education is nowhere near as good as a qualified teacher at the primary school level, at least with current technologies, but many students don't have that luxury. The goal of this project to improve the existing educational baseline in a cost-effective way, using solutions that can be scaled to match the scope of the problem.","title":"Technologies for Cooperative Learning in Rural India","awardID":"0633850","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1707","name":"ADVANCED LEARNING TECHNOLOGIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["533534","24192","549890","463055","24192"],"PO":["564318"]},"129039":{"abstract":"Modern data centers employ a virtualized architecture where application components run inside virtual machines and one or more virtual machines are mapped onto each physical server. This project focuses on the design of a virtualized data center that can dynamically remap physical to virtual resources and employ such dynamic reconfiguration capabilities to automate management tasks such as server consolidation, dynamic capacity provisioning, and system evolution. There are three areas of focus: low-overhead non-intrusive monitoring in a virtualized data center, agile reconfiguration for consolidation and provisioning, and the use of virtualized replicas for managed evolution. Non-intrusive monitoring involves a novel black-box approach that infers resource usage solely from external observations. Agile system reconfiguration utilizes these black-box measurements to automate reconfiguration tasks such as capacity provisioning and server consolidation using a combination of virtual machine migration and agile replication. The final technique exploits the ability to run concurrent application replicas inside virtual machine to ease hurdles faced in the evolution of the system from one version to another. A combination of system prototyping and experimental evaluation on a Linux\/Xen cluster testbed running real-world data center applications will be employed to demonstrate the effectiveness of these methods.<br\/>Broader impacts include source code release of the prototype to enable further experimentation by other researchers and participation of undergraduate students in this research via summer REU projects.","title":"CSR-VCM: Dynamic Reconfiguration in Virtualized Data Centers","awardID":"0720271","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["497218","558563"],"PO":["493916"]},"134671":{"abstract":"Proposal No: 0747864 <br\/>PI: Giorgio A. Ascoli<br\/><br\/>Abstract:<br\/><br\/>This award supports the preparation and sharing of computational neuroscience data as part of an exploratory activity aimed at catalyzing rapid and innovative advances in computational neuroscience and related fields. The data to be shared in this project are physiological and anatomical data from the rat hippocampus, including (1) recordings from hippocampal CA1 neurons during open field foraging, (2) simultaneous intracellular and extracellular in vivo recordings from CA1 pyramidal cells and histological identities of those neurons, (3) quantitative information on the cellular connectivity of the hippocampal formation, and (4) axonal reconstruction data from in vivo preparations. Anatomical and physiological data will be cross-annotated to facilitate browsing and integration, and provided in a form that is compatible with widely used simulators. It is anticipated that these data will be useful for developing anatomically and physiologically realistic neural networks and understanding emergent behavior of neuronal populations, in particular, the mechanisms of memory.","title":"CRCNS data sharing: Physiological and anatomical properties of hippocampal neurons and connections in vivo","awardID":"0747864","effectiveDate":"2007-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7327","name":"CRCNS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[357909],"PO":["564318"]},"131162":{"abstract":"Capacity and Coding in Resource-Limited Wireless Networks<br\/><br\/>Performance of wireless networks is limited by the resources available in the network. The fundamental physical resources used by wireless networks are bandwidth and energy. Designing wireless networks is mainly a question of utilizing these resources in the most efficient way possible. This research considers the two resources separately and defines the bandwidth limited regime and the energy limited regime by focusing on one resource at a time. In each regime, the investigators propose to concentrate on a few measures of performance related to the Shannon capacity, find bounds for these measures, and design practical codes to approach these bounds.<br\/>Treating the two resources separately makes it possible in many cases to obtain concise, exact capacity results rather than numerical upper and lower bounds. Specifically, this research aims to 1) find fundamental bounds for performance of resource-limited wireless networks, 2) develop a new concept of deterministic capacity of networks, 3) use obtained information-theoretic results directly in guiding practical code designs, 4) employ source-channel coding in code designs, and 5) extend the source-channel coding approach to networks with correlated sources.","title":"Collaborative Research: Capacity and Coding in Resource-Limited Wireless Networks","awardID":"0729152","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["451433"],"PO":["564924"]},"135892":{"abstract":"IEEE 7th International Symposium on Bioinformatics & Bioengineering (IEEE BIBE 2007) will be held at Harvard Medical School Conference Center, Cambridge - Boston, Massachusetts, USA, October 14-17, 2007. IEEE BIBE 2007 hosts keynote sessions, workshop keynote sessions, cutting edge research sessions, special sessions, workshops, and tutorials. The goal of the project is to financially support international and domestic students to attend IEEE BIBE 2007. The students such as underrepresented minorities, women, and persons with disabilities will be able to attend all technical events such as tutorials, workshops, research sessions, special sessions, keynote sessions and poster sessions. The students will learn advanced knowledge in bioinformatics and bioengineering to continue to do strong research in them in the near future. The support will maximize learning outcomes of IEEE BIBE and maximize research outcomes of IEEE BIBE 2007. Because students will be major future research experts to develop new techniques in bioinformatics and bioengineering, it is necessary to provide them with the best chances to improve themselves.","title":"Student Fellowships for Participating IEEE 7th International Symposium on BioInformaitcs and BioEngineering","awardID":"0753259","effectiveDate":"2007-09-15","expirationDate":"2008-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["529917",360979,"417163"],"PO":["565136"]},"131052":{"abstract":"The goal of this project is to obtain new algorithms and insights for<br\/>some fundamental problems in graphs and networks with a focus on<br\/>routing and network design. A prototypical question in routing is to<br\/>find paths that connect a given set of source-destination pairs while<br\/>obeying the link and node capacity constraints of an underlying<br\/>network. Similarly, a prototypical question in network design is to<br\/>build a minimum cost network to support a given communication<br\/>pattern. Problems in these two areas are at the core of combinatorial<br\/>optimization with many applications. They also play a crucial role in<br\/>the development of algorithms and structural graph theory.<br\/><br\/>The problems considered in this project are NP-hard and the approach<br\/>is to obtain polynomial time approximation algorithms as well as<br\/>bounds on the integrality gaps of linear programming based<br\/>relaxations. Questions central to the agenda are disjoint paths<br\/>problems in undirected graphs, buy-at-bulk network design, and<br\/>orienteering. In addition to improved algorithms for these and<br\/>related problems, new broadly applicable algorithmic techniques are<br\/>expected to be discovered. There are several applications that can<br\/>directly benefit including VLSI design, bandwidth and resource<br\/>allocation in networks, design of optical networks, and vehicle<br\/>routing. The project will support and train PhD students and help in<br\/>the dissemination of advanced algorithmic ideas via new classes and<br\/>lecture notes.","title":"Approximation Algorithms for Routing and Network Design","awardID":"0728782","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["550375"],"PO":["565251"]},"131173":{"abstract":"Many common communication situations are over inherently two-way channels, such as telephone systems, digital subscriber lines (DSL), cellular networks, and the Internet. In fact, even `point-to-point' systems, where the end goal is to transfer information in one direction, often give rise to two-way communication scenarios due to the presence of feedback. In such systems, one can receive feedback from the other end of the channel, which can be used to improve the quality of communication. Although feedback is present in many communication systems, and is being used in certain primitive forms as in channel estimation and automatic repeat request, the theory behind its use is far from complete. This research investigates the role of feedback in two-way communication networks and provides architecture-level guidance for designing robust and efficient communication systems. While positive results lead to novel approaches to communication systems design, negative results prevent over-engineering and allow more confidence in simple and modular implementations. At the same time, feedback is a pivotal concept in biological and artificial control systems, learning machines, and communication networks. A deeper understanding of the role of feedback in one area (communication) will lead to a better understanding of the role of feedback in a broader multidisciplinary context.<br\/><br\/>Concretely, this research focuses on and develops new approaches for tackling problems arising in the following areas: 1) feedback capacity of single-user channels with memory (new coding theorems based on directed information, causal conditioning, and Shannon strategy, as well as the development of concrete schemes for achieving the fundamental limits), 2) multiple-user channels with feedback (emphasis on multiple access channels and broadcast channels: characterization of fundamental limits as well as the construction of practical coding schemes), 3) capacity region of the two-way channel such as the Blackwell-Shannon binary multiplying channel (dynamic programming and infinite-dimensional convex optimization), 4) robust feedback coding techniques under channel uncertainty (universal decoding schemes), and 5) reliable communication with noisy feedback (new perspectives on cross-layer design of channel codes and network protocols). Massey's directed information takes the role of Shannon's mutual information in many feedback communication problems. Thus the role of directed information is investigated as a fundamental notion in general causal inference problems. Examples include gambling in horse-race markets with causal side information and its dual in source coding.","title":"Collaborative Research: The Role of Feedback in Two-Way Communication Networks","awardID":"0729195","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["551039"],"PO":["432103"]},"131063":{"abstract":"Collaborative Research: Greedy Approximation with Nonsubmodular Potential Functions<br\/><br\/>Presented in the literature are many greedy optimization algorithms. However, not many of them can be successfully analyzed. Actually, most existing techniques for analysis of greedy approximation require the submodularity of potential functions. For greedy heuristics with nonsubmodular potential functions, the analysis is a largely unexplored open area. Indeed, many have good performance in computational experiments, but have not received much theoretical analysis due to the difficulty of dealing with nonsubmodular potential functions. The PIs have developed new techniques to analyze some of them. They propose to extend their techniques to other greedy heuristics for problems arising from computer system, computer networks and computational molecular biology. Therefore, the research will have the following broader impacts: It will enhance advanced theory for design and analysis of approximation algorithms and the theory of optimization and will provide helps in development of in some computer systems and engineering areas, including computer networking and computational molecular biology. The proposed approximations\/heuristics will provide excellent solutions for optimization problems arising from those areas. The graduate student involvement will have numerous future benefits. The discovery and research experience of the students will prepare them for productive careers in academia, research labs, and industry in highly important, current research areas affecting fundamental development in science and engineering.","title":"Collaborative Research: Greedy Approximations with Nonsubmodular Potential Functions","awardID":"0728812","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["562362"],"PO":["565251"]},"135430":{"abstract":"Multimedia Production and Distribution Services.","title":"Multimedia Production and Distribution Services","awardID":"0751232","effectiveDate":"2007-09-01","expirationDate":"2011-09-30","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0105","name":"Office of LEGISLATIVE & PUBLIC AFFAIRS","abbr":"LPA"},"pgm":{"id":"050P","name":"SECTION 508 CONTRACTOR"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0105","name":"Office of LEGISLATIVE & PUBLIC AFFAIRS","abbr":"LPA"},"pgm":{"id":"051P","name":"WEB CONTRACT"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0105","name":"Office of LEGISLATIVE & PUBLIC AFFAIRS","abbr":"LPA"},"pgm":{"id":"053P","name":"NSF KIDS"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0105","name":"Office of LEGISLATIVE & PUBLIC AFFAIRS","abbr":"LPA"},"pgm":{"id":"054P","name":"NSF RADIO"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0105","name":"Office of LEGISLATIVE & PUBLIC AFFAIRS","abbr":"LPA"},"pgm":{"id":"055P","name":"NSF DISCUSSION SERIES"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0105","name":"Office of LEGISLATIVE & PUBLIC AFFAIRS","abbr":"LPA"},"pgm":{"id":"056P","name":"PROGRAM ACQUISITION CONTRACTOR"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0105","name":"Office of LEGISLATIVE & PUBLIC AFFAIRS","abbr":"LPA"},"pgm":{"id":"057P","name":"WINDOWS TO THE UNIVERSE"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0105","name":"Office of LEGISLATIVE & PUBLIC AFFAIRS","abbr":"LPA"},"pgm":{"id":"059P","name":"SCIENCE IN MOTION"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0105","name":"Office of LEGISLATIVE & PUBLIC AFFAIRS","abbr":"LPA"},"pgm":{"id":"060P","name":"SCIENTIST & ENGINEER PROFILES"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0105","name":"Office of LEGISLATIVE & PUBLIC AFFAIRS","abbr":"LPA"},"pgm":{"id":"061P","name":"CONVERSATIONS WITH SCIENTISTS"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0105","name":"Office of LEGISLATIVE & PUBLIC AFFAIRS","abbr":"LPA"},"pgm":{"id":"0636","name":"ADMINISTRATIVE CONTRACTS"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0105","name":"Office of LEGISLATIVE & PUBLIC AFFAIRS","abbr":"LPA"},"pgm":{"id":"097P","name":"IN-HOUSE PRODUCTION SUPP SVCS"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0105","name":"Office of LEGISLATIVE & PUBLIC AFFAIRS","abbr":"LPA"},"pgm":{"id":"108P","name":"IN-HOUSE PROD SUPP SVCS"}},{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0105","name":"Office of LEGISLATIVE & PUBLIC AFFAIRS","abbr":"LPA"},"pgm":{"id":"7957","name":"COMMUNICATING SCIENCE BROADLY"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0500","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"7315","name":"ITR RESERVE FY 2005 AND ON"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0709","name":"Division of BIOENGINEERING & ENVIRON SYSTE","abbr":"BES"},"pgm":{"id":"1385","name":"SPECIAL STUDIES AND ANALYSES"}}],"PIcoPI":["388560"],"PO":["392896"]},"131074":{"abstract":"Linear differential equations and difference equations appear in a wide variety of problems in mathematics and its applications. The main goal of this research is to develop a complete algorithm that finds all closed form solutions of such equations. Closed form solutions are not approximations of solutions, instead, they are given by an exact formula, written in terms of well known special functions.<br\/><br\/>This research will combine a wide variety of techniques in novel ways.<br\/>Key information about closed form solutions will be obtained from local data (the asymptotic behavior at each singular point) in a new way that involves interesting number theoretical and combinatorial problems. The most important feature of this new approach is that it will lead to a provably complete algorithm to find all closed form solutions.","title":"Closed Form Solutions for Linear Differential and Difference Equations","awardID":"0728853","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["550445"],"PO":["565157"]},"131085":{"abstract":"TF07: An Automata-Theoretic Approach to Design Synthesis<br\/><br\/>As computerized systems are becoming larger, more complex, and increasingly distributed, a larger and larger portion of the design effort goes into the validation and verification effort. There is a growing need for formal methods that guarantee systems reliability, correctness, and efficiency by design. The investigators will address this challenge by contributing to the the establishment of a theory of automated design synthesis of computing systems. The new techniques will enable the development of systems of higher quality within shorter design cycles and with lower costs. The goal of the project is the development of a fundamental theory for automated system design synthesis. <br\/>The ultimate goal is a demonstrable improvement in design productivity.<br\/><br\/>The focus of this project will be the development of algorithmic tools for assertion-based design synthesis. The investigators will develop automata- and game-theoretic approach to assertion-based intentional system design. <br\/>While the main focus of games and automata has traditionally been on finite objects (or very simple infinite ones), it is necessary to extend this approach to the more complex situations that we face in most practical applications, and for which the method is not yet adequately developed or exploited. The intellectual merit of this project is the interplay between games, automata, and logic. Our aim is to make fundamental progress in this area, aimed at the development of automated design techniques. These are crucial for the development of reliable, robust, and scalable computing systems.","title":"An Automata-Theoretic Approach to Design Synthesis","awardID":"0728882","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["565263"],"PO":["565157"]},"133032":{"abstract":"Mobile computing and wireless telephony are increasing converging, with many<br\/>handheld devices (e.g., PALM Treos and RIM Blackberries) able to assume roles as<br\/>either cellular telephones or as computers. A key research question that arises as a<br\/>consequence of this convergence is whether the strategies such as virtualization used for<br\/>isolation and resource sharing in larger cabled computers will be applicable to machines<br\/>that are limited by size, computational power and battery life. This question also has great<br\/>bearing on the extent to which NSF's proposed GENI initiative will impact the most<br\/>numerous network endpoints (there are more than 2 billion GSM mobile phones in use,<br\/>for example).<br\/><br\/>The project focuses on an experimental effort to anticipate this need and provide a definitive<br\/>answer to the question of resource division and isolation in handheld devices. Our<br\/>candidate devices are HP iPaq handhelds, although if time permits we will also<br\/>investigate a cellphone platform that uses a reduced version of the Linux operating<br\/>system. The experiment will be to demonstrate virtualization of a handheld node that<br\/>allows it to be used as a MANET (i.e., as a packet relay) concurrently with its use as a<br\/>VoIP edge device. The performance will be evaluated using the e-Model for voice<br\/>quality. Maintaining voice quality will demonstrate the effectiveness of the resource<br\/>management and isolation.","title":"SGER: Xen In The Hand (XenITH)","awardID":"0739347","effectiveDate":"2007-09-01","expirationDate":"2010-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["527253"],"PO":["434241"]},"122384":{"abstract":"Abstract for Proposal 0643552<br\/><br\/>CAREER: Design Principles, Algorithms, and Interfaces for Visual Communication<br\/>Maneesh Agrawala, University of California, Berkeley<br\/><br\/>Visual communication is fundamental to the process of exploring and disseminating concepts and information. The most effective visualizations are carefully crafted by human designers, who use a variety of design principles to graphically emphasize important information while de-emphasizing or omitting irrelevant details. Such visualizations help analysts rapidly find patterns lurking within large data sets and they help audiences quickly understand complex ideas. Yet, even with the aid of computers, hand-designing effective visualizations is time-consuming and consumes considerable human skill and effort. Too often, this lack of time and skill results in poorly designed visualizations that hinder understanding. This work is developing algorithms and user interfaces that facilitate visual communication by making it fast and easy to generate compelling visualizations.<br\/><br\/>The investigators develop a three-stage approach for building such algorithms and interfaces. In stage 1 they identify domain-specific design principles that are used to create the most effective visualizations within an information domain. In stage 2 they instantiate the design principles within new algorithms and interfaces for creating visualizations. In stage 3 they evaluate the resulting visualizations and the creation tools. Although the general approach has application to a wide variety of information domains, the investigators focus on visual design problems in cartographic visualization, structural visualization of complex 3D objects such as human anatomy and mechanical parts, and the design of diagrams and slide presentations. While the initial results are producing domain-specific algorithms and interfaces, the broader goals of this line of research are to refine the general three-stage approach and develop strategies to apply it to wider varieties of information domains.","title":"CAREER: Design Principles, Algorithms, and Interfaces for Visual Communication","awardID":"0643552","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["534062"],"PO":["532791"]},"131096":{"abstract":"Abstract: In several real-life scenarios, wireless sensors may be deployed in thin strip regions, such as when deploying sensors along international borders to detect illegal intrusion, around forests to detect the spread of forest fire, around a chemical factory to detect the spread of lethal chemicals, or on both sides of a long gas pipeline to detect potential sabotage. Most existing work on coverage and connectivity are not applicable to these strip deployment regions since they often ignore the boundaries of the deployment region. Further, most existing work on coverage and connectivity for random deployments provide only asymptotic results, and do not give reliable numerical conditions for determining the density required for adequate coverage in finite regions.<br\/><br\/> <br\/><br\/>This project is aimed at establishing a strong foundation for coverage and connectivity when wireless sensors are deployed in thin strip regions. To achieve this goal, this project is investigating the coverage and connectivity properties for three kinds of sensors omnidirectional sensors, directional sensors (such as lasers and cameras), and mobile sensors. The project uses rigorous mathematical analysis to derive precise numerical estimates for achieving coverage and connectivity for random deployments. It is also investigating optimal algorithms (both centralized and distributed versions) for critical network activities such as coverage\/connectivity verification, coverage restoration upon sensor failures, and sleep-wakeup schedule determination for network lifetime maximization. The new techniques developed in this project for deriving precise density estimates make the coverage and connectivity results readily usable in real-life, thus bridging the gap between theory and practice. The comprehensive foundation for coverage and connectivity for thin strips being created in this project is expected to make perimeter security with wireless sensors more practical.","title":"Foundations of Coverage and Connectivity for Wireless Sensor Networks Deployed in Thin Strips","awardID":"0728928","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["541501","541502","523520"],"PO":["564924"]},"125893":{"abstract":"III-COR: Collaborative Research: Graceful Evolution and Historical<br\/>Queries in Information Systems-- a Unified Approach<br\/><br\/>Database schema evolution is a constant in the life-cycle of<br\/>Information Systems (IS), and a source of major costs for maintenance,<br\/>upgrading, and service down time. The traditional process of<br\/>installing a new schema, converting the database, and rewriting<br\/>applications is slow and laborious. Instead, this project develops<br\/>the novel technology whereby the schema evolution problem is<br\/>reduced to coordinating mappings between multiple concurrent<br\/>versions of schema, applications, and database. The project's<br\/>approach consists of developing: (i) XML-based architectures for<br\/>unifying the management of evolving data and metadata, (ii)<br\/>methods for capturing evolution via schema mappings, (iii)<br\/>efficient mapping techniques for queries and applications. These<br\/>advances will enable the development of the MetaManager, a system<br\/>that supports: (a) preserving and querying database histories, and<br\/>(b) better planning on how-to evolve current schema versions, via<br\/>evaluation and testing of ``what-if'' scenarios. Its<br\/>functionality and performance are validated using various testbeds,<br\/>including the SDSC Storage Request Broker, which hosts scientific<br\/>data for research groups ranging from astrophysicists to<br\/>biologists.<br\/><br\/>This novel and timely approach provides a solution to both the<br\/>evolution and preservation of IS. Because of the<br\/>key role played by IS, a broad range of scientific, educational,<br\/>and economic activities will benefit. Project funds support<br\/>training of PhD students while undergraduate research interns are<br\/>trained on schema-evolution scenarios using the MetaManager. The<br\/>technology is a part of database design courses. Results are<br\/>disseminated via publications, reports and demos which are available from:<br\/><br\/>http:\/\/www.cs.ucr.edu\/~tsotras\/meta-manager<br\/>http:\/\/wis.cs.ucla.edu\/projects\/meta-manager<br\/>http:\/\/db.ucsd.edu\/people\/alin\/meta-manager","title":"III-COR: Collaborative Research: Graceful Evolution and Historical Queries in Information Systems -- a Unified Approach","awardID":"0705916","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["543515"],"PO":["469867"]},"127510":{"abstract":"Wireless networks and inexpensive sensors are leading to a world rich in geographically distributed sources of data. Various massively networked systems are being designed to manage this information. Such systems typically contain two key architectural components: a software \"\"network\"\" connecting the participating nodes in the system, and a query engine running across the nodes. There is little consensus on how to co-engineer these components to achieve an efficient, robust solution. However, recent work on Declarative Networking showed that both these layers can be naturally implemented in a high-level language, in which the programmer specifies \"\"what\"\" result is desired, not \"\"how\"\" it is to be achieved.<br\/><br\/>This project develops \"\"Dynamic Metacompilation\"\" to enable automatic co-optimization of the network and query components of such systems. In this framework, the optimizing compiler for a networked information system is bootstrapped from optimization rules written in the very same declarative, distributed language that is being optimized. Such a scheme will bring remarkable ease of software engineering for this new class of systems.<br\/><br\/>The results of the work can significantly accelerate the development of a new generation of systems to harness the potential of a massively networked and data-rich world, with implications for a broad range of applications including environmental monitoring, public health, disaster response, and computer system management. Project funds support the training and research of two graduate students, and plans are underway for use of the software in coursework. Publications, technical reports, software and experimental data from this research will be disseminated via the project web site (http:\/\/ p2.cs.berkeley.edu).","title":"III-COR; Dynamic Meta-Compilation in Networked Information Systems","awardID":"0713661","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["451018"],"PO":["427499"]},"126421":{"abstract":"0708025<br\/><br\/>CRI-IAD: Acquisition of a Trusted Hardware Infrastructure for Secure Data Management<br\/><br\/>Radu Sion<br\/><br\/>This project will acquire secure tamper-proof hardware required in the design and implementation of trusted, efficient, and scalable data management. Specifically, the infrastructure will consist of a trusted computing and storage cluster to support three ongoing research projects that address such security assurances in networked file-systems (NSF CyberTrust NS3), relational data outsourcing (Secure Query Interface SQi), and regulatory ? compliant storage (SecureWORM). The cluster will be composed of a set of servers, associated compatible trusted co-processors, a storage sub-system, and a set of On-Disk Encryption hard drive.<br\/><br\/>This hardware is an essential requirement in the target projects. For example, in the NS3 project, in recent results the researchers have shown that data access pattern privacy cannot be achieved efficiently in the absence of server-side trusted hardware support, mainly due to provable prohibitive lower bounds on required server-side work. In the SecureWORM project, the researchers have also shown that existing WORM systems are vulnerable to simple attackers due to the lack of strong tamper-resistance. In the Secure Query Interface (SQi) framework, trusted server-hosted hardware closely cooperates with the server relational query processor to provide clients with execution assurances and query privacy.","title":"CRI: IAD: Acquisition of a Trusted Hardware Infrastructure for Secure Data Management","awardID":"0708025","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["553485"],"PO":["565136"]},"125222":{"abstract":"Data-driven Animation of Skin Deformations<br\/><br\/>Optical motion capture has been used very successfully to create compelling human animations for entertainment applications; however, it provides only a much simplified version of what we would see if we were to view a person actually performing those actions. The data contain the motion of the skeleton but miss such visually important effects as the bulging of muscles and the jiggling of flesh. The current state of the art uses 40-60 markers to approximate the rigid body motion of<br\/>15-22 segments. To the extent possible, the markers are placed on joint axes and bony landmarks so that they can more easily be used to find the motion of an idealized skeleton. The investigators are taking a different approach to motion capture and use a very large set of markers (approximately 350-500) placed on the muscular and fleshy parts of the body to capture not only the motion of the skeleton but also the motion of the surface of the skin. Models of skin and muscle deformations will have long term applications in such fields as computer animation, video games, surgical planning, humanoid robotics, and bioengineering.<br\/><br\/>The investigators are using captured data to construct dynamic models of the deformations seen in human motion parameterized by joint angle, velocity, and torque. Those models are used to generalize captured data to new motions and new subjects with a similar body type.<br\/>The investigators have been able to accurately reconstruct the motion of the surface of the body by applying the three-dimensional trajectories for this dense marker set to a subject-specific polygonal model. They are exploring a number of different approaches to generalize this data ranging from simple statistical dynamic models to relatively accurate anatomical models with parameters identified from the data.","title":"Data-Driven Animation of Skin Deformations","awardID":"0702556","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["438709"],"PO":["532791"]},"127411":{"abstract":"This project explores three new related approaches to making the indexing and retrieval of videos (1) more efficient by developing rapid feature selection, (2) more meaningful by devising measurably useful indexing ontologies, and (3) more humanly navigable by demonstrating integrated multimedia browsers, even when the videos are unedited.<br\/><br\/>The first approach consists of heuristic adaptations of machine learning algorithms to the overly redundant data that is video. The second approach consists of using statistical tools to examine the descriptive tags that can be affixed to video segments, in order to measure and refine their quality. The third approach consists of exploiting the first two approaches to discover and display the weak structure that is latent even in the unedited videos of student presentations. The experimental research will be refined by continuing user studies, involving students from middle school, high school, college, and post-graduates.<br\/><br\/>The results of this project will provide advances at the multiple intersections of computer vision, machine learning, data management, information retrieval, ontology design, user interface technology, and user studies, with possible applications in the wider areas of sensory retrieval in general.<br\/><br\/>Broader impacts: We expect that the browser will enhance the effectiveness of undergraduate education by allowing accurate and rapid review of both instructor and student recorded presentations.<br\/>We also expect that the underlying novel technologies will permit real-time analysis and access of more standard videos. The project Web site (http:\/\/www.cs.columbia.edu\/~jrk\/unstructured) will be used to disseminate resulting publications, open-source code, and instructions on how to obtain annotated video data sets.","title":"III-COR: Analysis and Display of Semantics of Structured and Unstructured Videos","awardID":"0713064","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[337904],"PO":["563751"]},"126564":{"abstract":"The project team will build at the University of Minnesota's Laboratory for Computational Science & Engineering (LCSE) a system especially targeted at enabling exploratory science through interactive supercomputing. Both Cell-based and Intel-based multicore CPU technology will be applied in an Infiniband cluster to achieve sustained performance levels with the team?s application codes approaching 2 Tflop\/s. The raw processing power of the multicore CPUs will be combined with fast attached disk systems, the latest GPU technology, and the LCSE's PowerWall display to enable interactive control of on-going fluid dynamics simulations with immediate feedback through user-controlled flow visualizations on the PowerWall. The system will also be utilized for applications in genomics. This project will support research in astrophysical and geophysical fluid dynamics, genomics, multicore implementation of numerical algorithms for scientific computation, high performance scientific visualization for very large datasets, Grid computing, and job\/resource scheduling. It will also support teaching and student training. The project involves an on-going collaboration of the LCSE team with the Fond du Lac Tribal and Community College. The techniques and software developed using the new interactive supercomputing system should have broad applicability in the high performance computing community. This software will be deployable on super-computing systems at national centers, where the enabled interactive capability can be enjoyed at much higher grid resolutions in a more production-oriented context.","title":"CRI: IAD Exploiting Multicore Processor Technology for Interactive Supercomputing","awardID":"0708822","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["468762","382574","383980","455559",335810],"PO":["565272"]},"129842":{"abstract":"Proposal #: CNS 07-23190<br\/>PI(s): Sabharwal, Ashutosh<br\/> Koushanfar, Farinaz; Tittel, Frank K.; Wysocki, Gerard; Zhong, Lin<br\/>Institution: Rice University <br\/> Houston, TX 77251-1892<br\/>Title: MRI\/Dev.: Development of Open-access Photonic Networked Sensors (PHOTONS) for Security, Industrial and Environmental Applications<br\/><br\/>Project Proposed:<br\/>This project, developing a prototype integrating trace-gas sensing platform to overcome the biggest barriers (sensor performance, integrated networked platforms, and at-scale deployments), explores the development of sensor technologies, sensor platforms, networking, data analysis, and control in one integrated platform. The PHOTOnic Networked Sensors (PHOTONS) platform, developed from the ground-up, enables researchers, developers, and commercial organizations to rapidly experiment with never-before-possible trace-gas sensing applications in security, and industrial and environmental monitoring in an affordable, portable, power-efficient manner. The key innovations of PHOTONS include advanced sensor technologies, system platform development, and a framework to accelerate development of novel applications such as<br\/>. Sensor Miniaturization<br\/>. Three-tier System Platform, and<br\/>. Open-access Collaborative Development. <br\/>Planned is the development of a novel trace-gas sensor at least two orders of magnitude smaller, lower cost, and lower power than any commercially available and a three-pier platform consisting of sensor node, new networking primitives, and application toolbox permitting flexible control. This architecture allows the node, the network, of the application to control sensor's sensing accuracy and corresponding energy consumption at fine granularity. The PHOTONS open-access repository provides a standard set of hardware, software, and application libraries, along with complete characterization of performance metrics at multiple granularities.<br\/><br\/>Broader Impacts: The platform provides the basic mechanism to establish an interdisciplinary, global community with academic and industrial collaborators that may have far-reaching impact on national security. Open-access collaborative development will be combined with a multi-pronged education and dissemination program, seeds new collaborations, promotes open experiments, and provides standardization for scientific comparisons. Furthermore, the platform provides educators and students with technologies for cutting edge research in many disciplines.","title":"MRI: Development of Open-access Photonic Networked Sensors (PHOTONS) for Security, Industrial and Environmental Applications","awardID":"0723190","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["489746","548311","485958","548312","492047"],"PO":["557609"]},"127422":{"abstract":"There has been successful research on establishing metric representations of the environment required together with motion planning for any navigation task. Such metric maps require though excessive amounts of storage to memorize the robots' trajectories and all landmark positions. On the other hand, animals have excellent navigation capabilities based on visual sensing and simple path integration.<br\/><br\/>The technical approach can be summarized in the modeling of places and the map creation. An abstraction hierarchy is introduced for the visual modeling of places with the layers of feature landmarks, salient regions, and objects. A novel image similarity score will be used for tracking as well as loop closing and is robust to perceptual aliasing. Objects are learned from training sets of appearances of salient landmarks and in the highest abstraction level places are labeled depending on their object content and the constellation of objects in space. Topological maps are made of nodes labeled with place labels and associated with an action to neighboring nodes obtained from the relative pose between the two places. Learning of the maps will happen in the space of all possible topologies of place sets. A collaboration with biologists will try to cross-validate hypotheses based on visual inputs obtained from the animal's viewpoint.","title":"RI: Collaborative Research: Bion-Inspired Navigation","awardID":"0713134","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["485377"],"PO":["564316"]},"127433":{"abstract":"Abstract for Proposal 0713185 <br\/>PI: Daniel Huttenlocher<br\/>Institution: Cornell University<br\/><br\/>Title: RI: A Context-Based Approach to the Recognition and Localization of Visual Object Categories<br\/><br\/>The primary goal of this project is to achieve a qualitative improvement in the robustness of object category recognition and localization, by formulating the problem as a single overall estimation problem. In contrast, most current approaches rely on successive stages of processing, in which individual features are first detected and then those features are combined in order to detect objects. A central focus of the project is not only to determine which objects are present in an image but also to localize those objects and their subparts. Objects are modeled as a collection of local patches arranged in a deformable configuration, where certain pairs of parts are connected by spring-like connections. These models provide a way of exploiting local contextual information, delaying decisions about the presence or absence of individual features until more is known about other features and the spatial relations between them. Such models can further be adapted to the larger problem of representing scene-level context, encoding both the context immediately around an object and more long-range relationships between objects in a scene. This project is investigating both the use of local context to improve detection of features and objects, and the use of scene context to improve the detection of objects and relations between objects, within a single overall optimization-based framework.<br\/><br\/>Accurate recognition and localization of objects is of central importance for applications and systems that use computer vision to interact with the world, such as mobile robots, autonomous vehicles, interactive games, animation and film-making, tele-operation for hazardous situations, and remote surgery. In such applications, a computer vision system must not only determine whether objects are present in a scene, but also identify where the objects are and what pose or configuration they are in. For instance, detecting a pedestrian for an automotive safety system should also inform the car and driver where the pedestrian is located. In applications such as tele-operation and interactive games, further detail about a person's pose and gestures are required to enable hands-free control of complex systems. This project seeks to advance the capability of such systems by taking an approach based on simultaneously combining multiple sources of information into a single overall decision, rather than making multiple smaller decisions that are each potentially error-prone<br\/><br\/>Progress on this project will be regularly reported at http:\/\/ www.cs.cornell.edu\/~dph\/context\/","title":"RI: A Context-Based Approach to the Recognition and Localization of Visual Object Categories","awardID":"0713185","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["420975"],"PO":["564316"]},"125255":{"abstract":"Computer systems are becoming increasingly complex both from hardware and software perspectives. Designing these systems is becoming increasingly challenging due to the difficulty in evaluating performance and power of the systems before the system is built. But unless performance and power can be quickly estimated during early design space analysis, it is impossible to identify good design points and design the right systems. Simulation is the de facto method of presilicon performance analysis in the microprocessor and computer system design community, however, often it takes days, weeks and sometimes months to simulate a few design choices using common simulators. The proposed research involves investigating performance evaluation methodologies for effective design of next generation computing systems.<br\/><br\/>Through this project, a workload distiller will be developed to capture essential properties of workloads and create miniature program sequences to help evaluate performance and power during presilicon design exploration. Specifically, the following objectives will be pursued: (i) creation of efficient and manageable benchmarks, (ii) capture of the essence of emerging workloads for power and performance modeling, (iii) development of a methodology to create scalable benchmarks for performance estimation of futuristic systems and workloads, (iv) development of a benchmarking methodology for multicore systems, (v) development of benchmark similarity metrics and clustering techniques for understanding workloads, and (vi) development of a methodology for predicting performance of applications using benchmark similarity metrics. The proposed scalable benchmarks and the evaluation methodologies for multicore systems will help designers during the design of next generation computer systems. In addition, this research will result in training several graduate students in an area that is critical to maintaining our nation's edge in the design of computer systems.","title":"Simplifying Computer Performance Evaluation using Workload Characterization","awardID":"0702694","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["556800"],"PO":["559883"]},"127444":{"abstract":"For individuals who suffer form extreme paralysis, the ability to communicate is often limited to yes\/no responses using small head, hand, or eye movements. Providing these people with the ability to participate in the Information Society (for example, by browsing the Web, posting messages, or emailing friends), would greatly enhance their emotional well being by alleviating the frustration caused by having an active mind trapped in a paralyzed body. Previously, the PI has developed camera-based interfaces that have afforded partial attainment of such goals. In the current project, the PI will build upon her prior achievements and push forward on several fronts concurrently. She will develop a mouse-replacement interface that computes pointer coordinates from the user's head movements, which are detected by a multi-camera computer vision system. She will explore context-aware approaches for gesture detection that can distinguish a user's communicative motions from involuntary movements or social interactions. She will design and implement a novel tool that allows users to develop their own semaphore-based communication interfaces. She will build an application mediator that serves as an intercessor between several separate software components. And she will develop innovative assistive software for a variety of common applications including text entry, web browsing, and animation (in the latter case, which enables users capable only of controlling a mouse cursor with limited precision to create and interact with 3D objects). <br\/><br\/>Broader Impacts: Project outcomes will have a direct and positive impact on the quality of life of adults and children with severe disabilities, as well as their friends, families and caregivers. The software to be developed will be disseminated at special care facilities (including a hospital, schools for children with severe physical disabilities, and a long-term care facility for people with Multiple Sclerosis and ALS), and will also be available on the internet via free download. This work will also advance the state of the art in computer vision, through the development of technology that employs 3D models for real-time tracking of facial features with multiple pan\/tilt\/zoom cameras.","title":"HCC: Intelligent Interfaces to Empower People with Disabilities to Participate in the Information Society","awardID":"0713229","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["557296"],"PO":["565227"]},"127686":{"abstract":"Proposal 0714277<br\/>CT-ISG: PacketSpread; Practical Network Capabilities<br\/>Angelos Keromytis<br\/>Columbia University<br\/><br\/><br\/>Network denial of service attacks occur with increasing frequency and<br\/>devastating economic and psychological effects for the targeted sites<br\/>and their users. Addressing the problem has proven difficult, primarily<br\/>due to deployment and complexity concerns about previously proposed<br\/>mechanisms. In particular, receiver-controlled capabilities are an<br\/>elegant way for preventing communication interference, but are<br\/>difficult to deploy in practice and are susceptible to control-channel<br\/>attacks.<br\/><br\/>This project is investigating a new communication paradigm, named<br\/>PacketSpread, which makes feasible the use of capability-like mechanisms<br\/>on the current Internet, without requiring architectural modifications<br\/>to networks or hosts. The high-level hypothesis of the research is that<br\/>practical network capability schemes can be constructed through the<br\/>use of end-point traffic-redirection mechanisms that use a<br\/>spread-spectrum-like communication paradigm enabled by an overlay<br\/>network. To test this hypothesis, the project is prototyping and<br\/>experimentally validating the resistance of such a scheme against<br\/>attacks launched by realistic adversaries, while minimizing the<br\/>impact of the approach to end-to-end communication latency and<br\/>throughput.<br\/><br\/>The results of this research will enable a better understanding how<br\/>network-capability schemes can be deployed and used to provide robust<br\/>and secure communications under both normal operation and in times of<br\/>crisis. Improvements in the security and reliability of large-scale<br\/>systems on which society, business, government, and individuals depend<br\/>on will have a positive impact on society.","title":"CT-ISG: PacketSpread: Practical Network Capabilities","awardID":"0714277","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["564223"],"PO":["497499"]},"125266":{"abstract":"Virtually all fields of science and engineering depend on fundamental advances in computing. High- End Computing (HEC) simulations in various areas of science enable to understand the world around us. Unfortunately, HEC is known for lack of sustained performance and reliability. Its system-wide failure rate increases significantly with the growing number of components. The conventional method for fault tolerance in HEC, checkpointing, is costly and triggers a cycle of deterioration. This deterioration is fueled by ever-increasing HEC complexity. A new fault tolerant approach is a must for next generation HEC. <br\/>In this research, the PIs propose a novel Hybrid Fault Tolerant (HFT) approach for HEC that combines long-term and short-term techniques to improve fault management. Long-term prediction models the possibility of faults based on historical data, and consequently facilitates failure-aware scheduling by intelligently mapping jobs to available resources. Short-term prediction diagnoses the root causes of unusual runtime events, and triggers job rescheduling on-the-fly to move running jobs away from these troublesome resources. The long-term support and the short-term support complement each other, where failure-aware scheduling prevents inactive jobs (i.e. the jobs that are not scheduled yet) from the failures that are well captured in the long-term failure models and failure-aware rescheduling enables active jobs (i.e. the jobs that are already scheduled and running) to avoid irregular failures that may not follow any long-term pattern but can be discovered at runtime (e.g. sudden hardware and software errors). The integrated long-term and short-term approach promotes a better understanding of failure trends and modes and consequently improves system productivity in HEC.","title":"CPA: A Hybrid Fault Tolerant Approach for High-End Computing","awardID":"0702737","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":["557489","550730"],"PO":["565272"]},"129402":{"abstract":"This project investigates a new class of abstractions to simplify network design and configuration which is (i) task-driven, i.e., captures the intended performance, security, manageability, or resilience of a network design; and (ii) network-wide, i.e., captures the requirements of the network as a whole rather than of individual devices. It is a radical departure from prior efforts that merely model the underlying protocols and mechanisms.<br\/><br\/>The focus is on enterprise networks, an area largely unexplored by researchers. Through bottom-up studies of actual enterprise network designs, the project obtains insights into the goals operators have for their networks. The studies employ unique ?white-box? methodologies involving extensive and iterative interactions with operators.<br\/><br\/>The project develops abstractions, along with the rationale and criteria for measuring their effectiveness in three areas: (i) implementation of security and resilience policies; (ii) use of VLANs to simplify management; and (iii) network evolution through planned maintenance. It demonstrates the power of these abstractions in simplifying both top-down network design, and validation of network properties. More specifically, it develops the theory for ?configurators?, or systems that can generate box level configuration from high-level design requirements, and a pre-selected set of protocols and mechanisms, and it investigates ?semantic auditing? techniques for formally verifying that a network's existing box-level configuration produces the intended network behavior. <br\/><br\/>Broader Impact: The research aims to produce fundamental knowledge and principles for turning network design and configuration into a science. It will also help enhance the coverage of network management in undergraduate and graduate curriculum. A new graduate class on Network Management will be created at Purdue and the usability of abstractions will be validated using controlled studies involving students training to become IT professionals.","title":"Collaborative Research: NBD: An Abstraction Driven Approach to Characterizing and Designing Networks with Analyzable Properties","awardID":"0721574","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["491613"],"PO":["564993"]},"129523":{"abstract":"Real-world security policies invariably involve questions of ``who'' and ``what''--who are the principals, what data are they seeking to access, and so forth. By contrast, the present-day Internet architecture concerns itself primarily with issues of ``how'' and ``where''-- what are the protocols by which a data item is delivered and to which topological endpoints. This inherent dissonance of purpose makes Internet security a bolt-on affair---with abstract access control policies pushed off to be implemented by particular applications or mapped onto the poor approximations provided by network-level abstractions (e.g., network firewalls). Moreover, these imperfect mechanisms are themselves attacked with impunity since today's Internet architecture provides a functional anonymity that insulates attackers from any meaningful liability.<br\/><br\/>This project is developing two key architectural capabilities--host attribution (which physical machine sent a packet) and data provenance (what is the ``origin'' of the data contained within a packet)--to enable the direct expression of a wide-range of security policies. Moreover, these properties are being implemented in a fashion that mandates their use (in a strong sense) by the network, but manages to preserve end-user privacy. The PIs are focusing on two key applications in this work: forensic trace-back and attribution for the purpose of attack deterrence, and defensive data-exfiltration to place precise controls over what kinds of data may move across a network.<br\/><br\/>Broader Impacts: This research is developing key architectural components to improve the level of security and assurance available to network services. In addition, the PIs are initiating a dialogue among both researchers and network operators about critical policy aspects of network security. In particular, information about the sources of both normal and attack traffic that must be safeguarded according to some policy.","title":"Collaborative Research NeTS-FIND: Privacy Preserving Attribution and Provenance","awardID":"0722000","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["559051"],"PO":["565090"]},"129535":{"abstract":"This project aim at defining, optimizing and implementing a novel underwater sensor network architecture, called SEA-Swarm (Sensor Equipped Aquatic Swarm), that consists of a large number of low cost underwater sensors that operate and move as a group (swarm) with water current and dispersion. The proposed SEA-Swarm architecture will enable a whole new era of observations, monitoring and explorations in the aqueous environment. Such tool will be by its very essence multidisciplinary and is expected to foster a broad collaboration between researchers in networking and communications and other scientific communities, such as environmental sciences, marine biology and coastal surveillance and security. A number of technological challenges shall be addressed by this project, along with the related fundamental research aspects: a new generation of underwater acoustic communications modems is to be designed based on OFDM, achieving unprecedented data rates thanks to Doppler compensation and MIMO space-time signal processing techniques. Cooperative communication protocols, driven by the information theoretic relay channel, are synergistically optimized jointly with a new energy efficient geo-routing algorithm. In essence, all the nodes in a virtual pipe from source to destination cooperate to reliably deliver the message. For reliable data transport, network coding for erasure correction and packet combining for energy efficiency is investigated. Finally, efficient localization schemes based on underwater GPS and nodes with dedicated data-collection functions (data mules) are advocated in order to tackle the mobility and the topology randomness problems due to the swarm nature of the network. The cross-layer design involving the above aspects is validated through a dedicated simulation environment (Aqua-Sim). A cost-effective over-the-water acoustic communication testbed shall be developed by USC in order to provide proof of concept of the basic network algorithms. Finally, an underwater testbed proof of concept is planned in synergy with other existing projects such as MyPond and MySound at U-Conn, and at the UCLA Marina Aquatic Center. The theoretical and experimental work at all three collaborating teams shall involve graduate students and also expose undergraduate students to state-of-the art communication engineering projects, developed in the framework of the above mentioned testbeds.","title":"Collaborative Research NeTS-NOSS: SEA-Swarm: A Rapidly Deployable Underwater Sensor Network","awardID":"0722046","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["558959"],"PO":["564777"]},"129304":{"abstract":"Prevention of jamming attacks is critical to the successful deployment of ad hoc or mesh networks. The objective of this project is to consider the problem of jamming in a holistic way and design a framework towards coping with these attacks. The framework will unify the functionalities of deterring, detecting, and alleviating the effects of jamming.<br\/><br\/>Unlike previous efforts this research will (a) exploit physical layer capabilities such as the tunability of power\/rate and the use of smart antennas to cope with jamming and (b) design solutions that are based on strong experimental foundation. Furthermore, the design will seek to address jamming attacks by not only external adversaries but also internally compromised nodes that send large volumes of seemingly legitimate data. The project will encompass the following tasks: (i) Extensive experiments to understand the impact of jamming and identification of behavioral traits during a jamming attack. (ii) Design of methods to obfuscate traffic patterns such that the jammer will be unable to target important nodes or locations in the network (iii) Use of the experimental knowhow in the design of the framework for detecting jamming attacks and (iv) Exploiting physical layer capabilities such as rate\/power and smart antennas to cope with attacks.<br\/><br\/>This research is expected to broadly impact successful future deployments of vehicular and municipal ad hoc\/mesh networks. It will also be tightly knit with educational programs that will augment wireless teaching laboratories and introduce cross-disciplinary courses that bridge the physical and higher layers.","title":"Collaborative Research: NeTS: WN: Coping with Jamming Attacks in Ad hoc \/ Mesh Networks","awardID":"0721183","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7371","name":"CYBER TRUST"}}],"PIcoPI":["466424"],"PO":["557315"]},"128215":{"abstract":"This project addresses transparent Damage Quarantine and Recovery (DQR), an important problem faced by a large number of mission\/life\/business-critical applications and information systems that must manage risk, business continuity, and assurance in the presence of severe cyber attacks. Today, these critical applications still have a ?good? chance to suffer from a big ?hit? from attacks. Due to data sharing, interdependencies, and interoperability, the hit could greatly ?amplify? its damage by causing catastrophic cascading effects, which may ?force? an application to halt for hours or even days before the application is recovered.<br\/><br\/>Traditional failure recovery techniques, though mature in handling random failures, cannot solve the DQR problem due to several fundamental differences between failure recovery and attack recovery. DQR is not a new concept, but there is still a big gap in engineering practical DQR capabilities for real-world applications, and no prior DQR techniques address Web Services or Service-Oriented Architectures. In this project, we will take a holistic approach and make an integrated set of innovative contributions on four fundamental aspects of DQR: theories, mechanisms, applications, and systems. The proposed innovations include the first theory that integrates recoverability and quarantinability, the first DQR scheme that uses mark-based causality tracing to replace read-write-dependency analysis, a novel DQR scheme that does ?cleaning-free? recovery, and the first set of DQR theories and mechanisms for Web Services. In addition, complete open-source DQR tools and systems will be prototyped.","title":"Collaborative Research: CT-T: Transparent Damage Quarantine and Recovery in Transactional Applications and Web Services","awardID":"0716479","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["277956"],"PO":["529429"]},"129557":{"abstract":"TITLE: Can Humanitarian Open-Source Software Development Help Revitalize Undergraduate Computing Education?<br\/><br\/>PI: Ralph Morelli (ralph.morelli@trincoll.edu)<br\/><br\/>This community building project creates a diverse community of individuals from academic computing departments, social service organizations, and computing and IT corporations, to test the hypothesis that humanitarian free and open-source software development (H-FOSS) can help revitalize undergraduate computing education. The project will capitalize on two contemporary interests that are under served in computing curricula: the open-source development model, as a way to teach software engineering; and, service-learning, as a means by which students and faculty can contribute to the surrounding community. A software development version of the Habitat for Humanity model will be investigated: instead of building houses, students and faculty will learn computing by building software systems that benefit humanity. To combat the computing-is-coding myth, community-based summer and academic year internships will demonstrate that computing is working together with other people to design and develop solutions to real problems. By engaging students and faculty from participating schools in summer institutes, credit courses, spring-break community-help projects, and an academic curriculum workshop, the project will develop a portable and sustainable educational model that attracts socially engaged students to the computing discipline, bridges the divide between town and gown, and builds truly useful humanitarian software.","title":"CPATH CB: Collaborative: Can Humanitarian Open-Source Software Development Help Revitalize Undergraduate Computing Education?","awardID":"0722137","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["527969"],"PO":["562944"]},"127379":{"abstract":"Recent developments in tangible and ubiquitous computing have raised an interesting question: What if the everyday world can not only be an object of computational representation, but the site of computational interaction? In the material world, the presence and absence of others ? the sounds of conversation, the glimpse of people passing in corridors, the sight of lights and motion in offices ? helps people maintain an awareness of each other?s action that aids in work coordination. Awareness technologies attempt to reproduce this informal sense of collective activity for distributed groups who work in virtual rather than physical space. Tangible and ambient interfaces provide a new way of thinking about these systems, because they use physical space for input and for output.<br\/><br\/>The proposed research lies at this intersection of ambient displays, tangible interfaces, and collaborative awareness. The development of a prototype ambient-tangible system, Nimio, and the evaluation of its successful deployment to a distributed workgroup, both demonstrated the utility of these systems and raised important new research questions, namely: How can these experiences be scaled up? How should such systems be evaluated?<br\/><br\/>A program of research is proposed that integrates conceptual, technical, and empirical research which will not only generate new technologies for ambient and tangible support for awareness, but also new understandings of the relationship between interaction and interpretation and new methods for designing, building, and assessing ambient and tangible systems. This will make conceptual contributions to our emerging understandings of embodied interaction, the link between physical, social, and computational systems. It will contribute to an emerging corpus of design studies with concrete prototypes. It will also provide new, generalizable and transferable models for evaluating ambient and tangible technologies. This will contribute to contemporary discussions of evaluation of digital systems in non-traditional settings such as domestic environments, galleries, exhibits, and public spaces.<br\/><br\/>Broader Impact:<br\/>The prevalence of digital devices means that computation is increasingly taking on new forms in our everyday lives, and familiar objects (cameras, music players, door keys, entertainment devices) are increasingly digital in nature. New models for understanding the relationship between digital technology and everyday practice are critical to the successful development and deployment of new ranges of computational devices. By linking technological design to social practice, this research will provide new insights into the ways in which technology is incorporated into everyday life, and create new opportunities for creative design and engagement.","title":"HCC: Designing and Evaluating Ambient-Tangible Displays for Collaboration","awardID":"0712890","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["464219"],"PO":["564456"]},"129205":{"abstract":"The on-going shift in processor technology to favor multicore<br\/>multiprocessors is opening new opportunities for software speculation,<br\/>where program code is speculatively executed to improve speed at the<br\/>cost of having to monitor for errors and the risk of having to<br\/>re-execute code when an error happens.<br\/><br\/>This project develops a new, behavior-based approach, which allows a<br\/>user or a profiling tool to parallelize or optimize a program based on<br\/>partial information about the program code and the input. It mainly<br\/>develops two programming techniques: Behavior-oriented parallelization<br\/>(BOP), which speculatively executes possibly parallel regions, and<br\/>Fast track, which uses software speculation to support the use of<br\/>unsafely optimized code.<br\/><br\/>The exponential increase in microprocessor performance over the past<br\/>30 years has had incalculable impact on science, commerce, government,<br\/>and quality of life. Continuing this revolution through the coming<br\/>decade will depend on a large degree of processor-level parallelism.<br\/>Behavior-based oftware speculation promises to improve the performance<br\/>of existing, sequential software and of new software that reuses an<br\/>existing code base. It simplifies parallelization and should thus<br\/>improve the productivity of future software development. The outcome<br\/>of this proposal will be a suite of techniques for general-purpose<br\/>software, and new tools that will be transitioned to industrial<br\/>partners wherever possible, and will be used in both undergraduate and<br\/>graduate courses.","title":"CSR-AES: Collaborative Research: Behavior-Based Speculative Parallelization and Optimization on Desktop Multiprocessors","awardID":"0720796","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["564815","550486"],"PO":["535244"]},"129326":{"abstract":"In large and complex communication networks, architectural decisions regarding functionality allocation are often more important than the details of resource allocation algorithms themselves. This NSF-funded project aims to develop a scientific foundation for designing network architectures by building upon recent successes in understanding protocols as optimizers and layering as mathematical decompositions. In particular, the PIs at five institutions collaborate to conduct a wide range of closely-connected research activities that substantially improve upon the state-of-the-art. Starting from a convex optimization formulation of the architecture design problem, the project investigates a wide range of alternative decompositions that provide different scalability, convergence, and complexity tradeoffs. The PIs then determine whether the properties of these alternative architectures continue to hold under stochastic network dynamics and non-convex objectives and constraints, and develop new architectural designs from a careful study of such dynamics. Mathematically, this project leads to a long-overdue union between network optimization and stochastic networks theory, and enables a systematic approach to leverage advances in general non-convex optimization.<br\/><br\/>Broader Impact: This project has clear synergy with the NSF's GENI initiative. The research provides a strong, analytic foundation for the design of future network architectures, including clean-slate solutions that deviate from todays Internet. The exploration of new ways to decompose functionality, with the influence of network dynamics and non-convexity in mind, will result in new protocols and mechanisms that can be evaluated in the GENI infrastructure.","title":"FIND: Collaborative Research: Towards An Analytic Foundation for Network Architectures","awardID":"0721286","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["509442"],"PO":["565090"]},"129568":{"abstract":"Abstract: <br\/>NSF CPATH Proposal 0722176<br\/><br\/>Planning Grant: Building a Community to Revitalize Community College Undergraduate<br\/>Computing Pathways<br\/><br\/>PI: Jeffrey Johnson<br\/><br\/>The National Workforce Center for Emerging Technologies (NWCET) at Bellevue Community College will lead a community-building, planning grant to analyze learning needs; research and evaluate educational models; and design and implement pilot learning projects to revitalize undergraduate computing education. Partners include the University of Washington-Bothell computer science\/information technology (IT) program as well as IT computer science\/transfer programs at Bellevue, Shoreline, and Cascadia Community Colleges. The Society for Information Management will provide industry-based validation. <br\/><br\/>The project will focus on redesigning the first year of a computer science program to retain and support community college students in computer science transfer programs, thereby addressing attrition and promoting more computer science degree holders. The team will:<br\/><br\/>adapt existing curricula in first-year math, science, and computer science courses to enhance learning for students;<br\/><br\/>investigate and create learning experiences wherein students complete difficult technical requirements in an integrated format; and<br\/><br\/>research the effectiveness of alternative pedagogical methodologies, mentorship by advanced students, and the establishment of learning communities.<br\/><br\/>The technology-rich Seattle area provides an excellent test-bed for evaluating new computing pathway models. The project team will collaborate with community colleges locally and ATE centers nationally to develop pilot sites for the new models.","title":"CPATH: Planning Grant: Building A Community to Revitalize Community College Undergraduate Computing Pathways","awardID":"0722176","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}}],"PIcoPI":[343353,343354,"443512","564733"],"PO":["562944"]},"129216":{"abstract":"Despite consumer demand for sleek, lightweight electronics, mobile embedded systems often use bulky discrete voltage regulation components to deliver noise-free power. Dedicated motherboard-level regulators increase the form factor of portable electronics. This project is developing a novel paradigm in which power regulation circuitry is designed synergistically with the computational elements of system, thereby reducing or eliminating the need for off-chip regulation. The focal point of the research is the development of models, design methodologies, and management techniques that allow low power high-performance SoCs to be directly connected to an energy source, enabling the next step in system integration.<br\/><br\/>The project seeks to develop integrated, programmable, on-chip switching regulators that leverage novel packaging technology to provide noise free supply voltages at high-efficiency. In addition, on-chip regulation improves the feasibility of fine-grained voltage domains. The project examines unique cross-boundary system optimizations spanning both software-level task management and regulation hardware design. It is developing integrated operating system and hardware methods to limit peak current, improve slew rate demands, and reduce voltage ripples through balanced scheduling. In special cases, it may be possible to completely remove regulation circuitry and allow the operating system to adapt computation under \"\"deregulated\"\"gradually declining battery voltages.<br\/><br\/>The removal of dedicated off-chip regulation from embedded systems has broad potential for commercial and social impact by enabling new generations of compact, reliable embedded devices, such as consumer electronics and medical devices. This project provides educational benefits through training of graduate students and incorporation of resulting advanced material in courses.","title":"COLLABORATIVE RESEARCH -- CSR-EHS: Integrated Power Delivery - Hardware-Software Techniques to Eliminate Off-Chip Regulation from Embedded Systems","awardID":"0720820","effectiveDate":"2007-09-01","expirationDate":"2012-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["485831","550572"],"PO":["561889"]},"129579":{"abstract":"The goal of this project is to develop a model for a campus wide computation initiative that will transform undergraduate computing education in the institution and academic environment. The activities that make up this model will engage in computation students and faculty who are outside the typical computing community. The transformation is achieved through the involvement of (1) faculty leaders inside the computing community in teaching and research collaborations with faculty and students from outside the computing community, and (2) faculty and industrial partners who develop programs that highlight the increasingly important role of computation in their respective industries. The two colleges have developed and will implement a coordinated model for a computation initiative that will (1) attract non-traditional CS students to take introductory computing courses (not computer literacy courses) and (2) encourage faculty from non-CS departments to develop discipline specific courses that build on the introductory computation courses and incorporate higher level computation skills. The model is based on the framework of a curriculum in computational methods that includes a core of courses that addresses common applications of computation across disciplines, followed by additional discipline specific courses within other departments that focus on computation activities in those fields. The strategies that will be developed and implemented for transforming undergraduate computing education, specifically fostering change in the attitudes of students and faculty and increasing the visibility of computation, will serve as a blueprint for implementing similar changes at other institutions. Dissemination of the model for a campus wide computation initiative, along with strategies for implementation, will make it possible for the changes to be replicated at other institutions. This will ultimately result in increased competence and familiarity with computing skills amongst all graduates, particularly in the sciences, and a more visible role and presence for computing in the academy.","title":"CPATH T: Campus Wide Computation Initiative - A New Model For Computing Education","awardID":"0722211","effectiveDate":"2007-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7640","name":"CPATH"}}],"PIcoPI":["439711"],"PO":["565136"]},"129106":{"abstract":"This project is aimed at developing scalable as well as highly efficient techniques for performing Dynamic Information Flow Tracking (DIFT) in multithreaded programs.<br\/>The approach being developed is based upon dynamic instrumention of binaries to perform information flow tracking so that the application source code is not required and applications involving dynamically generated code can be handled. For achieving scalability, a novel strategy based upon the integration of checkpointing logging with fine-grained tracing is being used. Initially the program is executed with logging turned on. When DIFT needs to be performed, the execution of relevant execution intervals is replayed and fine-grained tracing is selectively performed.<br\/>For achieving further efficiency, idle cores on a multicore processor are being used.<br\/>Dynamically, a monitoring thread is generated by analyzing the application binary and the monitoring thread and the application execute concurrently on different cores.<br\/>By achieving scalability and efficiency, the developed techniques can be applied to realistic programs such as server programs. The DIFT techniques are being evaluated in context of following applications: (debugging) bug location and avoidance; (security) software attack detection and location of vulnerability; and (data validation) maintaining lineage of scientific data.","title":"CSR-AES-RCS: Scalable and Efficient Dynamic Information Flow Tracking in Multithreaded Programs","awardID":"0720516","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550848"],"PO":["493916"]},"129227":{"abstract":"Collections of heterogeneous, network-connected computational devices<br\/>have emerged as a new computational paradigm. This new network-based<br\/>paradigm simplifies constructing flexible and scalable hardware<br\/>infrastructure. Unfortunately, making such systems robust to failures<br\/>can be difficult. Many of these distributed software systems contain<br\/>a large number of devices, and therefore, have a significant chance of<br\/>experiencing a hardware failure. Developers have to manually develop<br\/>code to allow the software system to recover from such hardware<br\/>failures. As a result, developing robust distributed software systems<br\/>is typically more difficult than robust centralized software systems.<br\/><br\/>This work builds upon the Principal Investigator's prior work on the<br\/>Bristlecone language for developing robust software systems. The key<br\/>insight behind the Bristlecone language is that most errors propagate<br\/>through software systems to cause further damage either by corrupting<br\/>data structures or through the control-flow--induced coupling between<br\/>conceptual operations. Bristlecone programs are architected as a set<br\/>of decoupled tasks that are linked through a set of task<br\/>specifications that describe how these decoupled tasks interact and<br\/>what consistent data structures look like. Bristlecone then uses<br\/>these specifications to adapt the program's execution in response to<br\/>failures.<br\/><br\/>This project extends the previous work to support distributed software<br\/>systems. This project develops static analyses to help developers<br\/>understand how failures in the underlying hardware will affect the<br\/>software system and to manage data and tasks so that hardware failures<br\/>have a minimal affect on the computation.","title":"CSR---AES: Programming Language and Runtime System Support for Robust Distributed Software Systems","awardID":"0720854","effectiveDate":"2007-09-15","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550574"],"PO":["551712"]},"129469":{"abstract":"Sensor communications has been a bottleneck in automotive vehicles. It is extremely important for the automotive industry to improve vehicle safety, reliability, fuel economy, reduce emissions and cost. Powerful electronic control units and the associated distributed sensors and actuators have been introduced. Revolutionary changes from the conventional wired sensors to wireless sensors are required to improve vehicle performance, reduce vehicle weight and cost. <br\/> This research project undertakes a multidisciplinary and cross-layer approach to develop UWB intra-vehicle sensor network theory and methods. Packet detection theory will be established considering channel propagation statistics and multiple access interference for an intra-vehicle sensor network consisting of 50 mission critical sensors and 50 non-mission critical sensors. Methods will be developed to achieve the packet loss rate of in the detection stage. Reliable MAC protocols will be developed for multi-channel direct-sequence spread spectrum ALOHA UWB sensor networks to guarantee that the maximum delay is ms and the probability of message failure is for message delivery through non-line of sight intra-vehicle channels. Network performance will be analyzed including message throughput, packet loss rate and BER in the presence of multiple access interference considering UWB channel propagation effects and transmission power uncertainty. A UWB intra-vehicle sensor network testbed will be designed and built using cross-layer approaches for real time control and computing. <br\/> This project can help to reduce the parts cost for intra-vehicle sensor communications and improve fuel economy, reliability and safety. Students will be trained in communications, networks, real-time operating systems and programming in embedded systems.","title":"NOSS: Ultra-Wideband Sensor Networks for Automotive Vehicles","awardID":"0721813","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["554666",343049],"PO":["557315"]},"128259":{"abstract":"National Science Foundation <br\/>CISE\/CNS <br\/>Form 7 Review Analysis and Recommendation <br\/><br\/>Proposal Number: 0716368 <br\/>PI: Daniel Lopresti <br\/>Institution: Lehigh University <br\/>Lead <br\/><br\/>Proposal Number: 0716393 <br\/>PI: George Nagy <br\/>Institution: Rensselaer Polytechnic Institute <br\/>Sub <br\/><br\/>Proposal Number: 0716647 <br\/>PI: Elisa H. Barney Smith <br\/>Institution: Boise State University <br\/>Sub <br\/><br\/>Proposal Number: 0716543 <br\/>PI: Christopher Borick <br\/>Institution: Muhlenberg College <br\/>Sub <br\/><br\/><br\/><br\/>Title: Collaborative Research CT-T: Following the Paper Trail: Reliable Processing of Voting Records for Trustworthy Elections <br\/><br\/><br\/>Proposal Abstract <br\/><br\/>Provisions for the inclusion of a physical record, in the form of hand- or machine-marked ballots, or as a Voter Verified Paper Audit Trail (VVPAT), are central to guaranteeing safe and secure elections. However, the processing of such records during the initial counting of votes or in the conduct of audits has raised its own set of problems which span broad technical and social boundaries. <br\/><br\/>The aim of this project is to study issues that currently make paper records more of a nuisance than an integral component in trustworthy voting systems. Specifically, the principal investigators are working to characterize the statistical distribution of mark sense errors as a function of ballot layout and quality in optical scanning, to examine approaches for unbiased visual auditing based on ballot images, to investigate the possibility that a concept known as homogeneous class display (HCD) can facilitate manual recounts, and to evaluate recognition errors that may arise in processing the VVPAT used with Direct Recording Electronic (DRE) systems. They are also interested in the effects these issues have on procedures for testing the paper handling components of voting systems in accordance with operational constraints, including the modest training received by most poll workers. This work on voting technologies is supported by ? and supports ? a planned survey and focus groups they are conducting to measure voter confidence and acceptance and to identify common misconceptions and concerns, including accessibility to disabled voters. Beyond its broad impact on the development of more reliable and trustworthy voting technologies, this project more generally has implications for the highly accurate computer processing of any information encoded in human readable form.","title":"Collaborative Research: CT-T: Following the Paper Trail: Reliable Processing of Voting Records for Trustworthy Elections","awardID":"0716647","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["551082"],"PO":["529429"]},"130690":{"abstract":"Project Abstract (NSF 0727001)<br\/><br\/>Computational Methods for Tertiary RNA Folding and Novel RNA Design<br\/><br\/>Recent discoveries have revealed RNA's wonderful capacity to form complex three-dimensional structures, as well as perform many molecular functions beyond storage of biological information. RNA's newly realized powers are being exploited in bioengineering and nanotechnology for design and application of biological sensors for detecting chemical compounds (for example, toxins), RNA enzymes for enabling faster chemical reactions, RNA switches for controlling protein synthesis in the cell, and RNA microarrays for monitoring gene expression. These advances in RNA science have relied mostly on experimental techniques (for example, X-ray crystallography). However, the systematic theoretical 3D structure determination and design approaches that have greatly benefited protein science are largely lacking for RNA. This void hampers the integration of experimental and theoretical tools required for advancing emerging RNA applications in bioengineering and nanotechnology. <br\/><br\/>This research focuses on developing computational technologies for RNA 3D structure prediction and design. For RNA 3D structure prediction, the investigators study algorithmic development issues involving calculating and testing RNA statistical potentials, and developing\/applying effective Monte Carlo conformational sampling algorithms coupled with the fragment assembly approach, a successful method for protein structure prediction. In particular, the investigators examine the role of multibody interactions in RNA 3D structure prediction. For RNA 3D design, the investigators focus on procedures for designing novel RNAs with tailored functions by a systematic computational approach. This work involves integrating RNA 2D\/3D folding algorithms with advanced dynamics analysis tools (for example, QM\/MM, transition path sampling) to screen and elucidate the structural, dynamical, and ligand-binding properties of designed RNAs. The computational tools for RNA 3D structure prediction and design resulting from the studies are being made available as a software package to the research community.","title":"Computational Methods for Tertiary RNA Folding and Novel RNA Design","awardID":"0727001","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7353","name":"EMERGING MODELS & TECHNOLOGIES"}}],"PIcoPI":["446672",346806],"PO":["565223"]},"129128":{"abstract":"Despite consumer demand for sleek, lightweight electronics, mobile embedded systems often use bulky discrete voltage regulation components to deliver noise-free power. Dedicated motherboard-level regulators increase the form factor of portable electronics. This project is developing a novel paradigm in which power regulation circuitry is designed synergistically with the computational elements of system, thereby reducing or eliminating the need for off-chip regulation. The focal point of the research is the development of models, design methodologies, and management techniques that allow low power high-performance SoCs to be directly connected to an energy source, enabling the next step in system integration.<br\/><br\/>The project seeks to develop integrated, programmable, on-chip switching regulators that leverage novel packaging technology to provide noise free supply voltages at high-efficiency. In addition, on-chip regulation improves the feasibility of fine-grained voltage domains. The project examines unique cross-boundary system optimizations spanning both software-level task management and regulation hardware design. It is developing integrated operating system and hardware methods to limit peak current, improve slew rate demands, and reduce voltage ripples through balanced scheduling. In special cases, it may be possible to completely remove regulation circuitry and allow the operating system to adapt computation under \"\"deregulated\"\"gradually declining battery voltages.<br\/><br\/>The removal of dedicated off-chip regulation from embedded systems has broad potential for commercial and social impact by enabling new generations of compact, reliable embedded devices, such as consumer electronics and medical devices. This project provides educational benefits through training of graduate students and incorporation of resulting advanced material in courses.","title":"COLLABORATIVE RESEARCH -- CSR-EHS: Integrated Power Delivery - Hardware-Software Techniques to Eliminate Off-Chip Regulation from Embedded Systems","awardID":"0720566","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["518228","518229"],"PO":["561889"]},"129139":{"abstract":"The wireless sensor network (WSN) has been emerged as a promising embedded computing platform for many nontraditional applications. In many cases, the computation and data acquisition processes of these applications are dynamically correlated, which poses the need for code changes after the deployment. For example: code patches to handle new phenomena, or software bugs. A na\u00efve way of performing code changes in a WSN is to send the code or code differences in form of data packets, and let the sensor nodes compute the new code. Since energy consumed by data transmission is much higher than that consumed by local instruction execution, it is important to be energy-efficient during the code dissemination in WSNs.<br\/><br\/> <br\/><br\/>This project proposes update-conscious compilation for achieving energy-efficient code dissemination. The integrated compilation framework consists of a set of sink-side update-aware compilation techniques, and a sensor-side software-decoder\/binary-rewriter. Specifically, the intellectual merits of this project are: 1) update-aware register allocation techniques; 2) update-aware data allocation techniques; 3) update-aware code placement techniques; 4) tools for enabling update-aware compilation.<br\/><br\/> <br\/><br\/>The proposal also contains interesting problems that are simple to understand for students at their early research stages. This will attract more students into the traditional fields from a new angle. At the same time, this project provides students with opportunities to connect classic fields with the latest prevailing areas. Through this research, the PIs are committed to cultivating a strong interest and a positive attitude among students towards embedded software development.","title":"CSR-CSI: An Update-conscious Compilation Framework for Energy-Efficient Code Dissemination in Wireless Sensor Networks","awardID":"0720595","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["508314","448722"],"PO":["535244"]},"133660":{"abstract":"The PI proposes to investigate how to model the deformations of grasped objects. A main thrust will be on the search for a geometric formulation of surface strain energy that satisfies the strain-displacement relationships under the linear elasticity model. A graphical interface will be developed not only for the simulation purpose, but also to be experimentally tested with a three-fingered BarrettHand. The developed model based on linear elasticity will be extended to deal with large deformations, possibly combined with tools from the Nonlinear Finite Element Method (NFEM). The objective is to push the boundary of linear elasticity based modeling to achieve real-time computation by exploiting the fact that a grasp is decided by deformations in the contact areas with the fingers not by that of the entire shape. With efforts balanced between theoretical inquiry and experimental demonstration, the PI hopes to gain in-depth understanding of the geometry and mechanics of grasping in the presence of deformation. The proposed work will pave the way for designing strategies for grasping deformable objects, and have potential impact on haptics, computer graphics, and medical robotics.","title":"SGER: Modeling of Deformation under Grasping","awardID":"0742334","effectiveDate":"2007-09-01","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["409118"],"PO":["403839"]},"134991":{"abstract":"Differentiated instruction plays a critical role in today's inclusive classrooms to meet the diverse needs of individual students for allowing all students to access the same classroom curriculum by providing different entry points and learning tasks that are tailored to students' needs. The proposed research is to construct a differentiated instructional system of mathematical word problem solving with the following functionalities. First, the system maintains a pool of instructional materials generated by pre-defined templates or shared from students\/teachers; features such as readability and the noise level of irrelevant information will be automatically extracted from instructional materials by proposed statistical natural language processing techniques. Second, the system provides computer-assisted instruction to train students' abilities for analyzing and solving mathematical word problems. Third, it enables formative evaluation to monitor students' progress. Fourth, the system provides the recommendation of differentiated instructional materials for a specific student by utilizing a student performance-driven recommendation algorithm. The proposed work includes cutting-edge research for computer science techniques. A joint statistical learning algorithm will be designed for identifying levels of readability, word difficulty, and syntactic complexity of available instructional materials in a unified framework. A relational learning algorithm will be designed for identifying sentences with relevant information from sentences with irrelevant information in a mathematical word problem.","title":"SGER III-CXT: Integrating Computer Science Techniques into Differentiated Instruction of Mathematical Word Problem Solving","awardID":"0749462","effectiveDate":"2007-09-15","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["548255","376742"],"PO":["427499"]},"131141":{"abstract":"Information sources (voice, images and video) are analog in nature: they can be represented by real numbers. On the other hand, the common currency of today's information age is digital: an abstract sequence of bits. The analog-digital separation architecture is the dominant mode of operation today, due primarily to its modularity and scalability. While still not employing joint source-channel coding, lossy compression might be helped by ``analog-tagging'' the digitally compressed information sources (example: most and least significant bits).<br\/><br\/>In this project, a fundamental view of lossy compression to shed insight into what architectures are appropriate for different network configurations is taken. An important component of this study is the focus on simple statistical knowledge of the analog information source. On the reconstruction side, of particular interest is the quadratic fidelity criterion. The goals of this project are: (a) to understand regimes where the analog-digital separation architecture is optimal; (b) to identify the appropriate analog tags to digital representation that can be best utilized when it comes to communicating over a network; (c) identify scenarios where such new architectures yield significant improvement over the conventional analog-digital separation architecture. Recent progress by the principal investigator in resolving decades-long open problems in distributed compression and multiple description is used as the starting point for the research agenda.","title":"Architectures for Lossy Compression: A Fundamental Study","awardID":"0729075","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["523699"],"PO":["564924"]},"131152":{"abstract":"Piecewise smooth surfaces are used to describe the boundary shape of solid objects, such as those that can be fabricated with machine tools. They are composed of smooth surface patches meeting along piecewise smooth patch boundary curves called feature lines, across which the surface normal fields can be discontinuous. Structured lighting triangulation systems (e.g. based on lasers, or coded pattern projection) are used to capture the location of points on smooth surface patches, but are unable to sample feature lines. As a result, postprocessing operations are used to detect the feature lines lost in the clouds of sample points. Unfortunately, reconstructing feature lines from these samples is intrinsically impossible, because a continuous function with discontinuous derivatives is not a band-limited signal. <br\/><br\/>This project introduces a new primal-dual framework for representation, capture, processing, and display of piecewise smooth surfaces, based on a new dual representation for piecewise smooth surfaces in the space of oriented 3D lines, or rays. In alternative dual representations tangent planes are used. An image capture process detects depth discontinuities, for example using multi-flash photography, from a generalized camera moving with respect to the object, or from a static camera and a moving object. Articulated and deformable objects, as well as real-time capture for 3D cinematography applications, will be considered in later phases of the project. A depth discontinuity sweep is a surface in dual space composed of the time-dependent family of depth discontinuity curves span as the camera pose describes a curved path in 3D space. Only part of this surface is visible and measurable from the moving camera. Silhouettes are included in the visible depth discontinuities. Locally convex points deep inside concavities can be estimated from the additional information, but not locally concave point laying at the bottom of concavities, resulting in holes in the reconstructed surface. New methods to fill these holes are proposed. One of these extrapolates the non-visible depth discontinuity curves from the visible ones by exploiting symmetries in the captured data. A second approach is based on interpreting the data as captured with a cylindrical camera looking at a fully visible toroidal surface. A new highly compressed surface representation composed of simple curve primitives in dual space will be developed. While sampling is regular for triangulation-based systems in primal space, in the dual space of rays samples are highly concentrated in the vicinity of high curvature points. Feature line points, which are highly localized in primal space, are easy to estimate in dual space because they correspond to extended and smooth curve segments. The investigators will implement hybrid systems combining depth discontinuities with triangulation-based systems, as well as photometric stereo, to achieve more accurate reconstructions of solid objects bound by piecewise smooth surfaces with accuracy guarantees for metrology applications. The proposed research includes applications ranging from reverse engineering to real-time 3D cinematography, and development of variational algorithms to fit watertight piecewise smooth implicit surfaces to the capture data, as well as isosurface algorithms to triangulate these implicit surfaces preserving feature lines.","title":"Computing Shape From Depth Discontinuities","awardID":"0729126","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["408988"],"PO":["565157"]},"122462":{"abstract":"An increasing number of information systems, especially in networking and electronic commerce, require algorithms to make decisions without full knowledge of the optimization problem they are trying to solve. Challenges of this sort underlie decision problems in electronic commerce (where relevant information is hidden by parties who may have an incentive to misreport it), online resource allocation (where the quality of decisions in the present depends on information revealed only in the future), and decentralized networking (where system components try to optimize global objectives armed with only a local view of the network<br\/>state). This research focuses on algorithms which meet provable guarantees in the face of such uncertainty.<br\/><br\/>Recent developments in online learning theory and algorithmic mechanism design have opened up the exciting<br\/>prospect of designing efficient algorithms with meet provable worst-case guarantees while still performing nearly as well as existing algorithms in the common case. The intellectual merit of such algorithms lies in providing an appealing bridge between worst-case and average-case analysis. The PI will pursue this prospect in several application domains, including multi-agent learning systems (studying algorithmic notions of trust and reputation based on extending online learning techniques to situations in which multiple learners share information) and auctiondesign (exploring the roles of optimal stopping theory, learning theory, and randomization over outcomes in the design of approximately profit-maximizing auctions). <br\/><br\/>This research holds the potential to have a broad impact on technology and society. For example, improved algorithms for multi-agent online learning could lead to safer and better systems for e-commerce, spam filtering, and sharing information and content on the Internet. The PI's education plan further contributes to the project's impact, by developing a new undergraduate course which will make randomness a central notion in the undergraduate computer science curriculum and by encouraging the participation of graduate students and talented undergraduates in the PI's research.","title":"CAREER: Algorithms for Environments with Incomplete Information","awardID":"0643934","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["406684"],"PO":["565251"]},"133594":{"abstract":"Spelman College proposes the ARTSI (Advancing Robotics Technology for Societal Impact) Alliance in collaboration with Florida A&M University, the University of the District of Columbia, Hampton University, Morgan State University, Norfolk State University, Winston-Salem State University, the University of Arkansas-Pine Bluff, Carnegie Mellon University, Georgia Institute of Technology, Brown University, Duke University, the University of Alabama, the University of Washington, and the University of Pittsburgh. Seven of these partners are HBCUs and seven are Carnegie Research I institutions. Their collaboration joins the strengths of HBCUs in conducting outreach and education in a nurturing learning environment with those of the R1's for conducting world class research. The ARTSI Alliance will motivate students to pursue computer science careers by emphasizing the creativity and socially beneficial aspects robotics technology with hands-on projects, curriculum, and media. ARTSI activities will span the academic pipeline from K-12 through the faculty ranks. At the K-12 level, students will be recruited with community outreach using robotics and art, robotics road shows, and a robotics educational film online repository. At the undergraduate level, HBCU students will be exposed to new robotics curriculum, and they will be encouraged to pursue advanced training in graduate school through summer research experiences, collaborative, interdisciplinary robotics projects in the arts and health, instruction in technical film documentation, student virtual film festivals, annual robotics conferences, and instruction in entrepreneurship for computer science. At the faculty level, it will increase the number of HBCU faculty who educate students in robotics and involve students in robotics research by providing faculty mentoring, summer research experiences for underrepresented faculty at R1 robotics labs, robotics summer workshops, and development and dissemination of robotics educational material through a web-based portal. The Alliance will have industry partners, including Seagate, iRobot, Microsoft Research, and Juxtopia, as well as educational partners, including Florida-Georgia Louis Stokes Alliance for Minority Participation and Computer Science Teachers Association.","title":"Collaborative Research: BPC-A: ARTSI: Advancing Robotics Technology for Societal Impact","awardID":"0742082","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7482","name":"BROADENING PARTIC IN COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7584","name":"ITR-BROADENING PARTICIPATION"}}],"PIcoPI":["531300","560704"],"PO":["561855"]},"131053":{"abstract":"Reconfiguration problems underlie modern mathematical investigations in robotics, mechanical design, structural engineering, and bio-geometry, and have the potential of impacting computational biology, especially the problems emerging from modeling protein folding or, more generally, protein flexibility and motion.<br\/><br\/>This research is focused on fundamental mathematical properties and algorithms for reconfiguration problems (in particular, motion planning) of linkages and other flexible structures made from rigid parts connected together with various types of joints and hinges. The research builds upon the principal investigator's previous work on 2-dimensional robot arm reconfiguration (the Carpenter's Rule problem and pointed pseudo-triangulations), as well as on her current work in Combinatorial Rigidity (generalizations of Pebble Game algorithms for 2-dimensional-rigidity to other classes of sparse graphs, computation of rigid and stressed clusters) and Motion generation (for pseudo-triangulations in the plane, and for molecular structures with many loops in 3-dimensions). The goal of this research is furthering the general understanding of a notorious 140-old open problem in the Combinatorial Rigidity of bar-and-joint frameworks, expansive motions and pseudo-triangulations in 3-dimensions, as well as motion and reconfiguration for other 3d-structures (linkages, panel-and-hinge and polyhedral structures). These problems transcend application domains, but they are motivated by and may lead to developing models and techniques for addressing questions that arise in other areas of science and engineering.","title":"Rigidity, Flexibility, Stress and Motion: Foundations of Reconfiguration Problems in Computational Geometry","awardID":"0728783","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["550373"],"PO":["565157"]},"133484":{"abstract":"Abstract<br\/>Proposal Number: 0741571 <br\/>PI: Stephen E. Fienberg <br\/>Institution: Carnegie Mellon University <br\/><br\/><br\/><br\/><br\/><br\/>Title: Travel Grant Proposal for Workshop on Data Confidentiality <br\/><br\/>Abstract <br\/><br\/><br\/>Carnegie Mellon University will host a workshop September 6-7, 2007 on data confidentiality. Increasingly, organizations are collecting data to, among other things, be made available to researchers. Many kinds of data are needed by researchers, including: <br\/><br\/>- Census data <br\/>- Health data <br\/>- Network data, for example collected from users' access to the Internet or general background data collected from routers or other network services. <br\/><br\/><br\/>Building on his extensive background involving security for statistical databases, the PI has assembled an impressive collection of experts. This workshop will explore ways to apply existing statistical methods for sanitization of data for these applications and, as needed, new methods suitable to other applications. <br\/><br\/>Before data can be released to researchers it is essential that data confidentiality policies be respected. For example, from a released data set associated with the Census Bureau, it should not be possible to associate a particular individual or household with particular sensitive data items, such as household income. Network data made available should not associate a packet, and its associated destination on the Internet or Web, with an individual or even an IP address. <br\/><br\/>Various techniques will be considered for the specification of data confidentiality requirements and for sanitization of the data to meet the requirements, including masking fields and data transformation techniques that preserve properties essential for the research use of the data. <br\/><br\/>The technical topics to be covered in the workshop are as follows: <br\/><br\/>- Languages to express confidentiality needs <br\/>- Legal, regulation and policy issues <br\/>- Societal and economic impacts <br\/>- Limitations of the technology, particularly in the face of the limitations of cryptographic methods <br\/>- Applications, including network data, census data, other databases <br\/>- Education and training <br\/>- Needed infrastructure support <br\/><br\/>The PI will produce a report on the workshop's deliberations. <br\/><br\/>The proposed workshop will assemble Government, industry and academic organizations representing different disciplines with diverse needs for data, and will consider different techniques for data sanitization. Microsoft and IBM will be co-sponsoring the workshop. Microsoft's needs, for example, are to sanitize data gathered from use of their search engines and browsers.","title":"Travel Grant Proposal for Workshop on Data Confidentiality","awardID":"0741571","effectiveDate":"2007-09-01","expirationDate":"2008-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7456","name":"ITR-CYBERTRUST"}}],"PIcoPI":["493252"],"PO":["521752"]},"131064":{"abstract":"Design techniques for approximation algorithms.<br\/><br\/>The MaxCut problem strives to cut a graph into two pieces so that many edges cross the cut. The investigator studies new algorithms for MaxCut and other fundamental problems of combinatorial optimization. Why?<br\/>Because MaxCut is a simplified abstraction of a wide range of partitioning problems that are pervasive in applications such as scientific computing, sparse-matrix ordering for linear solvers, VLSI design, or task partitioning for parallel processors. The hope that the insight currently being gained on core theory problems can later translate into progress for more applied problems.<br\/>Thus, speeding up scientific computing applications could eventually have impacts on computer simulations for engineering problems such as automotive crash studies or for exploring major scientific issues such as global climate change.<br\/><br\/>How does the investigator proceed in her study?<br\/>In two ways: first, by exploring the power of the \"\"lift-and-project\"\" technique to obtain better linear programming models. Better, in the sense that adding constraints makes the linear program resemble more closely the real problem under study.<br\/>Lift-and-project<br\/>is an exciting technique whose power is not yet well understood. Second, by unifying and simplifying existing algorithms. Known dense graph algorithms can seem forbiddingly technical and numerous for prospective users. In contrast, the investigator is shifting the technical difficulties from the design to the analysis of algorithms, by proving that variants of greedy algorithms work well: greedy algorithms are simple, natural, and attractive, and thus much more likely to be used. Such foundational work on algorithms for combinatorial optimization is the way to engineering and technological improvements in the long term.","title":"Designing Approximation Schemes","awardID":"0728816","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["438411"],"PO":["550329"]},"122484":{"abstract":"Jared Saia<br\/>University of New Mexico<br\/>CAREER: Foundations for Attack-Resistant Collaborative Peer-to-Peer Systems<br\/>0644058<br\/>Panel ID: 070111<br\/><br\/>Abstract<br\/><br\/><br\/><br\/>How can a group of agents achieve a goal despite efforts by some of the agents to prevent this? This important question cuts across many disciplines including political science, economics, mathematics and computer science. In this proposal, we are exploring this question by focusing on the following problem. A set of n agents wants to compute the value of a function, f, of n inputs, where each agent holds a unique input of f. Our goal is to create a distributed algorithm that ensures that each agent learns the output of f. Our algorithm will be attack-resistant in that it works correctly even when up to a constant fraction of the agents are controlled by an omniscient adversary that tries to prevent the function from being computed. Our algorithm will also be scalable in the sense that each node in the network sends and receives a number of messages and bits that is only polylogarithmic in n i.e. O(logc n) where c is a fixed constant. We are making use of several tools to solve this problem including: the use of expander-like graphs to enable robust communication; the use of small randomly chosen committees as single trustworthy functional units; and algorithmic techniques to harden against denial of service attacks. Solving this problem will likely have broader impact in such diverse areas as voting, spam detection, worm and malware detection, distributed file systems, auction and mechanism enforcement, collaborative filtering, and web search.","title":"CAREER: Foundations for Attack-Resistant, Collaborative Peer-to-peer Systems","awardID":"0644058","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7795","name":"TRUSTWORTHY COMPUTING"}}],"PIcoPI":["551090"],"PO":["565327"]},"125872":{"abstract":"This research will evaluate a generative approach to creating families of processes, by generating families of Online Dispute Resolution (ODR) processes, and evaluating them through use at the National Mediation Board (NMB). The generative approach will be guided by NMB specifications of process goals, which will vary in emphasis according to different weightings of both tangible goals, such as resolving a specific conflict, and such nontangible goals as empowerment and relationship-building. The process families will be generated by binding different combinations of process concerns, such as coordination, agent behaviors, and artifact flows, into a high-level metaprocess framework. The generated process instances will also include specified instrumentation and measurement vehicles. This will facilitate the evaluation of the processes by NMB and project researchers and will form the foundation for evaluation of the overall generative approach. This approach will require a process definition language that features clear separation of concerns. An example is the Little-JIL process definition language, developed at UMass, which will be used as the basis for this research. The project will add to understanding of process generation and process technology in general, while also creating useful processes for the NMB, and a superior framework for social science experimentation with dispute resolution processes as well as processes in general. The project team includes computer science researchers, an ODR expert, dispute resolution researchers, and representatives from the NMB. The team has conducted successful NSF-funded research on a previous project, whose results indicate the need for the research proposed here. <br\/><br\/>Intellectual Merit: This project continues the exploration of the value of using software engineering perspectives and technology to deal with processes as rigorously definable objects. The main issue addressed here is the management of families of processes. Previous research indicates that organizations like NMB require families of processes, rather than a single process, and that such processes may not always be aimed at producing a single product nor one that is tangible. Use of a process definition language featuring clean separation of concerns seems to be a promising way to address these needs, and that approach will be pursued and evaluated in this research, thus making an important contribution to understanding the formal nature of processes. A process generation framework will be built and used to generate real ODR processes that will be used and evaluated by the NMB. The rigor and precision of these processes, and their incorporation of vehicles for evaluation, will facilitate the comparison of processes that differ in precisely documented ways. This will be an important contribution to social science research, supporting the ability of social scientists to perform precise experimentation with processes, with ODR processes being used as a first example. <br\/><br\/>Broader Impact: The ODR processes provided will be of considerable value to the NMB in a number of ways. The processes will improve NMB's effectiveness in dealing with disputes in the airline and railroad industries. They will also serve as an aid that NMB can use to train new personnel. The clarity and precision of the processes will render them suitable subjects for ongoing discussion and evaluation, leading to improvements in conflict resolution effectiveness. Moreover, success at the NMB will demonstrate the applicability of these ideas and approaches to the dozens of other government agencies responsible for dispute resolution.","title":"III-CXT: Process Families and Their Application to Online Dispute Resolution","awardID":"0705772","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["440692","536735","536737","387450"],"PO":["427499"]},"122374":{"abstract":"To produce high quality solutions during complex problem solving, groups must be able to realize effective problem solving processes including the ability to quickly create, share, and exchange task artifacts, the ability to maintain awareness of each other's activity, and the ability to transition between performing individual work in parallel and joint work in a shared space. Yet despite many years of research, groups are still unable to realize effective processes when using digital artifacts and their supporting devices. This can severely inhibit a group's ability to produce quality solutions. Though not new, this problem is becoming extremely urgent as more users are collaborating with digital artifacts to solve increasingly complex problems in critical domains such as software, design, and security. In this project, the PI will investigate one promising approach for facilitating group problem solving: multi-user, multi-display environments (MDEs). An MDE networks personal and shared devices to form a single virtual workspace. Personal devices such as laptops provide physically separate spaces for performing individual work in parallel, while large displays provide a shared visual space for joint work. But these spaces must be integrated through enabling systems and supporting interactions. While many enabling systems exist, designing interfaces, interactions, and visualizations (collectively comprising the interaction framework), which combine to facilitate effective group problem solving in an MDE, remains a grand challenge. In this project, building upon the current state-of-the-art in our theoretical understanding of group work and his extensive multidisciplinary research experience, the PI will develop an MDE interaction framework consisting of three core components: a management interface, overview visualization, and input redirection. The management interface will enable a user to relocate applications among displays in the MDE while minimizing disruption to other ongoing work, yet also preventing when desired others from relocating or interacting with given applications on a shared display. The overview visualization will enable users to maintain awareness of each other's ongoing work relative to the central activity. Input redirection to any shared display will allow users to jointly interact with applications on those displays. The PI will study how these core components interrelate and affect in combination the ability of an MDE to support effective group problem solving. A successful outcome will facilitate effective group problem solving by allowing users to create, share, and exchange task artifacts, to maintain awareness of each other's activity, and to seamlessly transition between individual and joint work. <br\/><br\/>Broader Impact: The PI will disseminate the software developed as part of the research, to enable end users to utilize MDEs for their own problem solving activities and researchers to further investigate techniques for facilitating effective group work in MDEs. The empirical results and lessons learned from the project will advance scientific understanding of how to develop interaction frameworks for MDEs that allow groups to better realize effective problem solving processes. By enabling more effective processes, the longer-term impact of the work is that groups will be able to create higher quality solutions for complex problems more of the time. The various research activities will be tightly integrated by the PI into his courses at both the graduate and undergraduate level.","title":"CAREER: An Interaction Framework that Enables and Facilitates Productive Problem Solving in Multi-User, Multi-Display Environments","awardID":"0643512","effectiveDate":"2007-09-15","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["515821"],"PO":["565227"]},"131097":{"abstract":"The objective of the investigator's research is to learn how to encode the organization of complex structures for efficient classification, recognition and browsing. Complex structures such as objects, images, 3D scans and web documents are considered. The focus of the investigation is on very large datasets (e.g., several millions). Because of computational issues, such large sizes cannot be handled by existing browsing methods. As part of this research, theoretical tools and methods for addressing these issues are being developed; these tools and methods are then applied to the problem of automatically identifying a target from 3-D imaging Laser Radar (Ladar) measurements. <br\/><br\/>The difficulty of indexing a large database for geometry\/structure-based queries is mostly due to two factors: 1) The inherent conflict between speed and accuracy, and 2) The curse of dimensionality. The structure representations that are being developed by the investigator, which are based on invariant statistics, address these difficulties. First of all, they are fully invariant and so they allow fast data comparison by bypassing the problem of finding the best mapping between two structures. Secondly, for a generic structure, they are lossless, and so they do not compromise accuracy. Moreover, they allow for low complexity metrics, thus yielding fast comparison algorithms that are almost surely 100% accurate (as opposed to approximate algorithms, which are always approximate.) In addition, as they contain no ambiguity, it is possible to index them with high-dimensional indexing techniques that address the curse of dimensionality. Finally, they are floating-point arithmetic and low-level data friendly.","title":"Efficient Methods for Automatic Recognition With Application to Target Identification","awardID":"0728929","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":[348016],"PO":["565157"]},"138852":{"abstract":"Proposal #: CNS 07-09217 07-07874 07-07701<br\/>PI(s): Leavens, Gary T. Cheon, Yoonsik Clifton, Curtis C.<br\/> Basu, Samik; Rajan, Hridesh <br\/>Institution: Iowa State University UTEP Rose-Hulman Institute Tech<br\/> Ames, IA 50011-2207 El Paso, TX 79968-0587 Terra Haute, IN 47803-3920<br\/>Proposal #: CNS 07-07885 07-08330 07-09169<br\/>PI(s): Flanagan, Cormac Naumann, David A. Robby<br\/>Institution: UC-Santa Cruz Stevens Institute of Tech Kansas State U<br\/> Santa Cruz, CA 95064-4107 Hoboken, NJ 07030-5991 Manhattan, KS 66506-1103<br\/>Title: CRD: Collab Rsch: JML Community Infr-Revitalizing Tools and Documentation to Aid Formal Methods Rsch<br\/>Project Proposed:<br\/>This collaborative project, revitalizing tools and documentations to aid formal methods research, aims to<br\/>. Enhance JML's infrastructure including its type checker, runtime assertion checking compiler, and IDE support;<br\/>. Make JML's software infrastructure more extensible; <br\/>. Substantially improve the documentation of the language and its supporting tools; <br\/>. Develop course materials and tutorials to facilitate classroom use of JML; and<br\/>. Disseminate a well-documented, extensible, open source suite of enhanced JML tools.<br\/>JML (Java Modeling Language), a formal specification language that can document detailed designs of Java and interfaces, has been used in different projects with great benefit. Feedback is obtained from users who are attracted by the ability to check Java code against JML specifications using a variety of tools. New research problems, however, are forcing re-inventing the infrastructure that JML provides, slowing the innovation, since JML does not support many of the new features of Java version 5, most notably generics. The Verified Software grand challenge has identified lack of extensible tools for formal methods research as a major impediment to experimentation. This project responds to the challenge by enhancing, extending, and well-documenting the infrastructure to advance and accelerate Java formal methods research.<br\/><br\/>Broader Impacts: The infrastructure is expected to open barriers to formal methods adoption among software engineering professionals by endowing a large collection of tools that share a common, mature specification language. These advantages should attract more educators and improve reliability in safety- and mission-critical systems. Moreover, strengthening the formal methods component in software engineering curriculum, courses will be developed and targeted to undergraduate research,. The collaborative involves two minority-serving institutions and an institution in an EPSCoR state.","title":"Collaborative Research: CRI: CRD: A JML Community Infrastructure -- Revitalizing Tools and Documentation to Aid Formal Methods Research","awardID":"0808913","effectiveDate":"2007-09-28","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["521544"],"PO":["557609"]},"134023":{"abstract":"Recent introduction and rapid growth of wavelength-division-multiplexing (WDM) technology provide a platform to exploit the huge capacity of optical fiber in computing and communication systems. The main difficulty of optical packet switching is how to resolve packet contention while minimizing packet loss. In this SGER project, a novel packet buffering scheme is explored for WDM optical interconnects which combines optical switching with electronic buffering. In the proposed scheme, arrived packets that do not cause contention are switched to output fibers directly; other packets are switched to shared receivers and converted to electronic signals and will be stored in the buffer until being sent out by shared transmitters. This project focuses on exploring the feasibility of the proposed buffering scheme. The performance of the scheme is studied through analytical modeling and simulations, and several related implementation issues are also investigated. The outcome of this project will be the foundation on which subsequent research on WDM optical packet interconnects will be launched to provide high-performance interconnects that enjoy both fast switching and large buffering capacity for <br\/>future computer systems.","title":"SGER: Cost-Effective Buffering Scheme for WDM Optical Packet Interconnects","awardID":"0744234","effectiveDate":"2007-09-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["550688"],"PO":["550859"]},"125795":{"abstract":"IIS 0705359, IIS 0705215<br\/><br\/>III-COR: Collaborative Research: Mining Biomedical <br\/>and Network Data Using Tensors Christos Faloutsos (christos@cs.cmu.edu) CMU <br\/>Vasileios Megalooikonomou (vasilis@cis.temple.edu) Temple Univ.<br\/><br\/>Given a large collection of functional Magnetic Resonance (fMR) images over time,<br\/>how can one find patterns and correlations? Similarly, given a never-ending stream <br\/>of network traffic information, how can one monitor for anomalies, intrusions, <br\/>and potential failures? The main idea behind this proposal is to treat both <br\/>problems using the theory of tensors. Despite the seemingly wide differences in <br\/>the two settings, they both boil down to finding patterns in multidimensional <br\/>arrays, sparse or dense. Tensors are exactly generalizations of matrices, <br\/>and correspond roughly to ``DataCubes'' of data mining. Matrix analysis <br\/>and decompositions are part of the standard toolbox for data mining, <br\/>providing methods for dimensionality reduction, pattern discovery and<br\/>``hidden variable'' discovery. Extending these tools to higher dimensionalities <br\/>is valuable and tensors provide the tools to do this generalization. <br\/>However, these tools have not yet been put to use in large volume data mining. <br\/>This is the main contribution of this proposal. The investigators propose <br\/>(a) to design tensor decomposition algorithms that scale for large datasets,<br\/>with special attention to sparse datasets, and to never-ending streams of data <br\/>and (b) to apply them on two driving applications, fMRI data analysis and network<br\/>data analysis.<br\/><br\/>The investigators propose to analyze large volumes of fMRI data performing<br\/>the following sub-tasks: cluster voxels with similar behavior over time for<br\/>a given subject and\/or task or across subjects and\/or tasks, <br\/>classify patterns of brain activity, and detect lag correlations<br\/>and spatio-temporal patterns among fMRI time sequences. <br\/>The investigators also propose to perform the following inter-related <br\/>tasks on multiple GigaBytes of network flow data: anomaly detection, <br\/>pattern discovery, and compression.<br\/><br\/>Both of these applications are important for medicine, health management,<br\/>and for computer and national security. Analysis of fMRI data can help understanding<br\/>how the brain functions, which parts of the brain collaborate with what other parts, <br\/>and whether there are variations across subjects and across task-related activities. <br\/>For the network traffic monitoring setting, fast detection of anomalies is important,<br\/>to spot malware, port-scanning attempts, and just plain non-malicious failures.<br\/><br\/>The educational goals include incorporating the research findings in <br\/>advanced graduate courses at CMU (15-826) and at Temple (9664, 9665)<br\/>and proposing tutorials in leading conferences in databases, <br\/>data mining and bio-informatics audiences.<br\/><br\/>For further information see the web page: <br\/>http:\/\/knight.cis.temple.edu\/~vasilis\/research\/tensors.html","title":"III-COR: Collaborative Research: Mining Biomedical and Network Data Using Tensors","awardID":"0705359","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["548220"],"PO":["560586"]},"134287":{"abstract":"In 2005, Americans consumed 100 quadrillion BTUs of energy in the course of everyday activities, almost six times the world wide average per person. This in turn caused the release of 2.2 billion metric tons of carbon dioxide (CO2), a greenhouse gas indicated as a major cause of adverse climate change. By taking simple actions to conserve energy, individuals can help reduce total CO2 emission significantly. Many of these changes, such as replacing incandescent light bulbs with compact fluorescent bulbs, are easy, cost-saving measure for individuals. <br\/><br\/>Although pro-environmental attitudes and beliefs are widespread, these rarely transform into actual energy saving behaviors. The relationship between attitudes and behaviors is complex, and barriers to behavior change include issues such as insufficient motivation and uncertainty about what choices will have the most impact. Social psychological research and studies of interventions help to define some promising features that could support energy behavior change, including personalization, goal-setting, and dynamic, comparative feedback both about individual results and others' successes. The prototype system in this proposal, StepGreen, attempts to induce changes in energy consumption through personalized information presented frequently and appropriately, through social influence processes (e.g., persuasion by peers) and by competitive interaction with other groups who are similarly trying to save energy. The Internet, with its proven abilities as a locus for mass change, provides an opportune place to experiment with these features in the large.<br\/><br\/>Specifically, this project will gather data about how to best support and encourage behavioral change regarding energy use, the results of which will inform the design of the prototype StepGreen system. A fundamental premise of this work is that suggestions will need to be personalized to each individual StepGreen member along a variety of dimensions, including what actions are recommended, the order in which they are recommended, and the manner (text and graphics) in which they are presented. To be effective such a system must achieve a massive user base. The other central activity to this project is developing partnerships with relevant civic organizations to identify appropriate populations and proven techniques for engaging those individuals. <br\/><br\/>Broader impacts: The results of this interdisciplinary project will benefit fields ranging from environmental engineering to social psychology to Human Computer Interaction by identifying misconceptions and educating individuals about relationships between behavior and energy consumption, providing a detailed understanding of how internet-scale technology can be leveraged to support widespread behavioral change. Finally, the work will benefit society by helping to address a critical social issue, energy consumption, leading to concrete reductions in U.S. energy use and by providing results that inform other domains in which societal benefits depend on individual behavior change (e.g., health, littering, community action).","title":"SGER: Footprints: Exploring Methods of Personalizing Suggestions for Actions in an Energy Conservation Social Network Site","awardID":"0745885","effectiveDate":"2007-09-15","expirationDate":"2009-02-28","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":["550147","551035",357086,"518044"],"PO":["388678"]},"126664":{"abstract":"Researchers all over the world in a variety of disciplines are working on developing the means for understanding extremist groups, terrorism and terrorists: their effects on the world; how they communicate, organize and propagate themselves; how they are funded; and who they connect with and why. This project is intended to create a large archive, known as the ?Dark Web Archive,? and a research infrastructure for use by computer and information scientists as well as social scientists studying a wide range of computational problems and social and organizational phenomena. The archive will ultimately comprise testbed data containing thousands of multilingual websites and multimedia files by U.S. domestic, Middle Eastern, and Latin American terrorist and extremist groups.<br\/><br\/>The intent is to support computer and information science (CIS) researchers in using the Dark Web archive for a wide range of exercises: to develop video and voice recognition technologies, advance information retrieval techniques whether in English or other languages, and improve methodologies in data and text mining as well as machine learning and artificial intelligence. Social scientists will also be able to use the archive, for example, to study dynamic ?dark? networks and the linkages or relationships between organizations, examine use of the web by extremist\/terrorist groups, and study the inter-relationship of culture, religion and politics. The Dark Web archive will support the comparison of current and historical data, minimize manual analysis by researchers in the social sciences; and enable the replication of experiments by researchers. In addition to supporting researchers in information, computer and social sciences, this project will also have some utility for the national security sector, including law enforcement and the intelligence community.<br\/><br\/>The project Web site (http:\/\/ai.arizona.edu\/research\/terror\/CRDabstract.htm) provides access to the Dark Web archive, research infrastructure, and additional information.","title":"CRI: CRD - Developing a Dark Web Collection and Infrastructure for Computational and Social Sciences","awardID":"0709338","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["548216"],"PO":["563751"]},"129942":{"abstract":"The objective of this study is to model the effects of urbanization and resultant habitat fragmentation on disease dynamics in large carnivore species--ecologically pivotal organisms that are sensitive to human disturbances. Bobcats, puma, and domestic cats will be evaluated simultaneously in three divergent ecosystems: high mountain desert (Colorado), everglades (Florida), and Mediterranean scrub habitat (California). The research will: (1) assess the relationship between habitat fragmentation and prevalence of viral, bacterial, and parasitic pathogens across a gradient of urbanization, (2) use transmission dynamics of selected disease agents as markers of connectivity of fragmented populations, and (3) evaluate the effect of urbanization on the incidence of cross-species disease transmission. <br\/><br\/>The combination of a uniquely qualified research team with an extensive dataset on large carnivores presents an unprecedented opportunity to investigate the disease dynamics in these rare and difficult to study species. Training of graduate students in ecology, infectious disease, and epidemiology will be emphasized, as will training for pre- and post-doctoral veterinarians. Results will be made widely available to other scientists, conservation practitioners, and the general public. This research has a tremendous capacity to broadly impact areas of public and post-graduate education, career development for new investigators and persons from under-represented groups, and to enhance understanding of complex infectious disease ecological problems using extensive multi-disciplinary collaborations.","title":"The Effects of Urban Fragmentation and Landscape Connectivity on Disease Prevalence and Transmission in North American Felids","awardID":"0723676","effectiveDate":"2007-09-01","expirationDate":"2013-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"I435","name":"Defense Intelligence Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"J265","name":"Defense Intelligence Agency"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7242","name":"ECOLOGY OF INFECTIOUS DISEASES"}}],"PIcoPI":[344799,344800],"PO":["564220"]},"127401":{"abstract":"Dynamic vision is uniquely positioned to enhance the quality of life for large segments of the population in a cost effective way. Scene analysis capabilities can prevent crime, allow elderly people to continue living independently and monitor and coordinate responses to environmental threats to minimize their effect. However, a critical factor limiting widespread use of vision techniques is their potential fragility. This project aims precisely at removing this limitation.<br\/><br\/>The research team is developing a systematic approach to robust dynamic vision that addresses several key sub-problems - tracking, appearance modeling, structure from motion, and motion-based segmentation -- in a common framework. Its conceptual backbone is a unified, operator--theoretic approach stressing the use of dynamic models to address robustness and computational complexity issues. Advantages of the proposed framework include the abilities to:(a) Recast a wide range of problems into a convex optimization form amenable to real time implementations. (b) Furnish worst--case bounds and guaranteed performance certificates that help reducing the on--line computational burden when solving these problems. (c)Exploit camera cooperation to optimize performance.(d) Take advantage of additional information available about the target to improve robustness and falsify the current models when no longer valid, for instance due to data obsolescence.<br\/><br\/>Education is proactively integrated into this project by using computer vision to convey ideas on robustness and computation complexity in undergraduate and graduate courses. Results of this research effort, including video clips with demos are regularly posted at the Robust Systems Lab (http:\/\/robustsystems.ece.neu.edu) website.)","title":"Systems Theoretic Methods for Dynamic Problems in Computer Vision","awardID":"0713003","effectiveDate":"2007-09-01","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["549739","549740"],"PO":["564316"]},"127412":{"abstract":"Most digital divide research assumes that the fundamental infrastructure of the information society is an internet accessed through personal computers. This was a reasonable assumption for research on the impact of the internet on the social lives of the first billion users, most of who live in rich countries, but today there are more mobile phones in the world than personal computers. These will be the primary informational portal for the next billion internet users. <br\/><br\/>Regardless of the devices' original design specifications, users in developing countries are rapidly adapting the hardware, software and overall functionalities of mobile phones. For example, in Tanzania mobile phones function as ATMs for a community bank, monitors illegal logging, and data collection points for arsenic detection in water wells. This process of evolution is widespread and accompanied by restructuring in local economic, political and cultural organizations. Yet little is known little of these users' design priorities, the infrastructural limits, the social process of organizing field innovations, the consequences of these technical adaptations on information access, and the overall impact on the quality of life and economic prosperity in the developing world.<br\/><br\/>This project will analyze rigorous social science data gathered at sites of technical repurposing and innovation. This study has three inter-related components: (I) an \"industrial ethnography,\" collecting qualitative evidence through a multi-sited study of innovation in IT field labs in Tanzania, focusing on workaround to overcome infrastructural limitations and applications of IT in unexpected organizational contexts; (II) the development of new methodological approach to the digital divide, relying upon quantitative evidence that produces better benchmarks of information access within countries; (III) an integration of education and research activities through an undergraduate research class and publication of an annual World Information Access Report that identifies government policies to help transport innovative ideas between countries.<br\/><br\/>The project will advance understanding of evolving socio-technical systems, identify IT policy \"best practices\", and involve undergraduate students in original research. It will advance telecommunications policy research by investigating the important causal relationships between telecommunications policy, field innovation, and information inequality in developing countries. It will advance computer engineering by investigating the ways in which IT is being adopted and adapted by the next large user group. It will advance knowledge of human-software-device interaction in a lived context, and contribute to the fields of communication, usability, information systems, and telecommunications policy.<br\/><br\/>Broader Impact<br\/>This project will improve our understanding of the digital divide, of how to use telecommunications policy and IT innovation to promote social development, and of how the arrival of new human-computer interaction systems becomes an occasion for organizational restructuring in the context of developing countries. Students will be engaged with a new immersive research course and results will be widely disseminated to academics, private industry, and policy makers. Discovering how devices are used in the tough, chaotic conditions of a developing country will benefit us with design concepts for new mobile telephony\/computing technologies useful in complex humanitarian disasters, whether at home or abroad.<br\/><br\/>This award is co-funded by NSF's Office of International Science and Engineering.","title":"HCC: Information Access, Field Innovation, and Mobile Telephony\/Computing in Developing Countries","awardID":"0713074","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0801","name":"Division of ENVIRONMENTAL BIOLOGY","abbr":"DEB"},"pgm":{"id":"7298","name":"COLLABORATIVE RESEARCH"}}],"PIcoPI":["499677"],"PO":["565227"]},"128985":{"abstract":"Large-scale applications distributed across thousands of machines over the wide area network are difficult to build and maintain. To enable sharing <br\/>of data across machines, many applications use specialized storage and data transfer tools such as a DHT, scp or GridFTP. Although file systems are <br\/>successful in becoming a common building block for cluster applications, it remains unclear if file systems could provide similar benefits to wide area distributed applications. This research describes a novel wide-area file system, WheelFS, that allows distributed application developers to use a generic file system interface to store and share application data easily among wide-area machines. <br\/><br\/>Two new approaches make WheelFS attractive for use by distributed applications. First, WheelFS provides semantic cues for application developers <br\/>to express desired tradeoffs among failure resilience, data consistency and file system performance at the granularity of individual files and directories.<br\/>Second, WheelFS optimizes wide area data transfer by writing application data <br\/>to local disks and reading a cached copy from a nearby machine whenever possible.<br\/><br\/>This project demonstrates the uselessness of WheelFS via the experience of building a number of distributed applications, such as a cooperative web cache, a data-intensive Grid application, a distributed digital library and a<br\/>PlanetLab measurement utility.","title":"CSR-PDOS: ISG: Collaborative Research: Building distributed, wide-area applications using WheelFS","awardID":"0720029","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["562011","541752"],"PO":["493916"]},"125113":{"abstract":"P0701957<br\/><br\/>Static and Dynamic Techniques for Classifying, Locating, and Fixing Bugs <br\/><br\/>Susan Horwitz and Ben Liblit<br\/><br\/>Testing and debugging are vital but notoriously difficult parts of the software-development process. Languages like C and C++, with weak type systems, exacerbate the problem by making it easy for programmers to introduce memory- and type-safety bugs. These bugs are hard to identify because the actual error and the symptom often seem to have no logical connection.<br\/><br\/>This research focuses on designing, implementing, and evaluating innovative new ways to identify, reproduce, and eliminate bugs. Questions addressed include: How to determine whether a program failure is due to a memory\/type-safety bug, and in that case how to locate the buggy code (not just the code where the symptom occurs); given a failure that is not due to a memory\/type-safety bug, how to reproduce that failure, and how to find the source of the problem.<br\/><br\/>One of the most creative aspects of the work is the combination of complementary techniques to achieve powerful synergies: dynamic memory type inference is combined with static program slicing to attack memory\/type-safety bugs, while program slicing is paired with statistical bug identification to implement new algorithms for finding, reproducing, and repairing other kinds of bugs.","title":"Static and Dynamic Techniques for Classifying, Locating, and Fixing Bugs","awardID":"0701957","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":[331999,"549944"],"PO":["564388"]},"127423":{"abstract":"Cluster analysis is an indispensable tool in the data miner's arsenal which enables one to understand the structure of the data while conducting exploratory data analysis. Recent times have seen increased occurrences of bi-modal and multi-modal data that manifest themselves as two-dimensional matrices and higher-dimensional tensors. Co-clustering is becoming an increasingly popular technique for exploratory analysis of such data, and has been successfully applied in wide range of areas, including web mining, natural language processing, image and video content analysis, recommender systems, and bioinformatics . The broad goal of this project is to develop sound, theoretical formulations of varied types of co-cluster analyses so that co-cluster analysis becomes an indispensable and efficient tool in the exploratory analysis of bi-modal and multi-modal data. <br\/><br\/>This research focuses on extending co-cluster analysis to include multi-dimensional tensors where one desires to cluster on more than two modes simultaneously, and matrix data with added row and column attributes such as those describing networked knowledge structures or multiple interlinked tables. This will enable co-clustering to reach a much wider class of applications and also make it computationally practical. <br\/><br\/>In order to broaden the impact of this project, the principal investigators are jointly organizing workshops that foster and promote research on various aspects of co-cluster analysis. Data, papers and software developed under this project will be shared with the scientific community via the project Web site (http:\/\/hercules.ece.utexas.edu\/~ghosh\/scalclust.html). Finally, as part of community outreach, the investigators plan to design outreach modules that illustrate data analysis concepts and capabilities at levels appropriate for high school students as well as for freshmen students.","title":"III-COR: Versatile Co-clustering Analysis for Bi-modal and Multi-modal Data","awardID":"0713142","effectiveDate":"2007-09-01","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["485856","550986"],"PO":["563751"]},"126455":{"abstract":"Proposal #: CNS 07-08199 07-08464<br\/>PI(s): Gupta, Rajiv; Gupta, Neelam Zhang, Xiangyu<br\/>Institution: University of Arizona Purdue University<br\/> Tucson, AZ 85721-0001 Wes Lafayette, IN 47907-2108<br\/>Title: IAD: Advanced Infr for Generation, Storage, and Analysis of Program Execution Traces <br\/><br\/>Project Proposed:<br\/>This collaborative project, developing an open source software infrastructure that is capable of tracing and analyzing long program executions, features customizability, extensibility, and most importantly, the capability of collecting prolific types of execution traces for realistic executions on single- and multi-threaded programs. The work is feasible due to the fact that, at present, checkpointing\/logging can be effectively combined with tracing through a technique called Execution Fast Forwarding (EFF) that enables scaling up tracing by orders of magnitude and availability of a highly compacted trace representation called Whole Execution Trace (WET) composed of static program representation that is annotated with dynamic traces including control flow, address, value, and a dependence trace that can contain complete program execution history in compacted form. Components of the infrastructure include<br\/>. Checkpointing\/logging environment that will execute a given binary on the supplied input to produce a set of checkpoints and logs which can be used to replay the execution;<br\/>. Execution fast forwarding components that will eliminate part of the execution that is not relevant to reproducing a given event;<br\/>. Tracing component to generate, compress, and store the WET (Whole Execution Trace) of a replayed execution interval; and<br\/>. Trace analysis component to provide an API that will enable users to access WET's with ease, without having to understand the low level detailed representation of WET.<br\/>Dynamic analysis techniques analyze traces of program executions to characterize the runtime behavior of programs. Distinctive runtime characteristics are then exploited in designing the systems to <br\/>. Develop highly reliable systems by detecting bugs, locating faults, and testing programs; <br\/>. Develop secure systems by detecting information leaks and unsafe behavior, and performing software marking; <br\/>. Validate and verify data by associating the output produced by highly complicated data processing procedures to the raw input data that can greatly facilitate verification of results;<br\/>. Develop hardware and software for highly optimized systems (e.g., embedded systems that must optimize performance, power, & memory usage) exploiting a wide range of runtime program characteristics (e.g., recurring code sequences to achieve compression, narrow width data to develop energy efficient cache designs & pipelines, etc.). <br\/><br\/>Broader Impacts: The infrastructure enables rapid prototyping for data verification, computer architecture, compilers, embedded systems, software engineering such as building testers and debuggers, security such as designing watermarking and information flow analysis tools. The uniform representation of logs and WETs provides standard interface to easily exchange traces. Moreover, encouraging synergy among projects, course projects will be designed and provided with the infrastructure.","title":"CRI: IAD An Advanced Infrastructure for Generation, Storage, and Analysis of Program Execution Traces","awardID":"0708199","effectiveDate":"2007-09-01","expirationDate":"2007-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7399","name":"CISE MINOR INST INFRA (MII) PR"}}],"PIcoPI":[335484,"549718"],"PO":["557609"]},"136498":{"abstract":"Abstract<br\/>Language Towers as Desigh Frameworks<br\/>Olin Shivers, Panagiotis Manolios (Georgia Tech) 0438871; <br\/>Matthew Flatt (University of Utah) 0438847<br\/><br\/>Good notations enable good design: they channel designer effort away from infeasible designs, highlight novel aspects of a specific design, supress inessential detail, and enable both human and automated reasoning about the artifact being described. Unfortunately, a tremendous amount of labor is required at the meta-design level to implement the tool suites supporting design in a new, extended, or domains-specific notation. This labor overhead means it is not practical for most designers and engineers to incorporate notation design, or meta-design, into their design methodology.<br\/><br\/>This research explores developing the meta-tools to allow the development of specialized notations, allowing designers to better express and reason about their artifacts. The focus of the research is on enabling design-time reasoning---what the programming-language community refers to as \"static semantics\"---of the designed artifact.<br\/><br\/>The resulting framework allows the construction of \"language towers,\" that is, notations defined at varying levels of abstraction, linked by procedurally-encoded static semantics (analyses) and dynamic semantics (translations) between the levels of the tower. While the work has its origin in the research underlying the Scheme macro system, it is intended to be applied to language frameworks that have much greater static-semantic content.","title":"SoD: Collaborative: Language Towers as Design Frameworks","awardID":"0757025","effectiveDate":"2007-09-01","expirationDate":"2009-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7372","name":"ITR-SCIENCE OF DESIGN"}}],"PIcoPI":[362708],"PO":["564388"]},"127434":{"abstract":"Programming a sensor network is quite hard, since it forces the programmer<br\/>to program in low-level languages that exposes details of the hardware, <br\/>make low-level optimization decisions, and build a great deal of network<br\/>machinery. A programming methodology is sorely needed that will allow<br\/>a user to specify the overall functionality of the application at a<br\/> high-level using a suitable programming framework.<br\/>Ideally, the specified user program would be automatically translated <br\/>to optimized distributed code that runs on individual nodes.<br\/><br\/>This project attempts to realize the above vision by viewing the sensor<br\/>network as a distributed database of facts gathered from the environment. <br\/>The belief is that the collaborative behavior of a sensor network<br\/>application can be easily abstracted in terms of deductive rules<br\/>that manipulate the facts, while the non-collaborative behavior can be<br\/> embedded in built-in functions.<br\/><br\/>The main goal of the project is to develop a query engine for efficient<br\/> in-network evaluation of deductive queries in sensor networks. <br\/>The query processing plan includes translation of the user program <br\/>into optimized virtual memory code, which is downloaded into the sensor <br\/>nodes for distributed execution. The research results would be prototyped<br\/>in networking simulators (TOSSIM and ns2) and in real sensor network <br\/>platforms based on Berkeley motes and Gumstix-like boards.<br\/><br\/>The above research plan has the potential of greatly simplifying the <br\/>design and use of sensor networks, by bundling all the low-level <br\/>complexities of design choices and optimizations in the query engine.<br\/>Examples of domains that will benefit from our contributions include <br\/>ground traffic, emergency response and disaster relief operations,<br\/>physical phenomenon such as weather and storm tracking, <br\/>forest fire tracking, migration patterns of animals\/birds, etc.<br\/><br\/>The project web site (http:\/\/www.cs.sunysb.edu\/~hgupta\/logicSense)<br\/>will be used for dissemination of all course materials, publications, <br\/>and software that result from our project.","title":"III-COR: Deductive Framework for Programming Sensor Networks","awardID":"0713186","effectiveDate":"2007-09-15","expirationDate":"2012-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["509519","563568","486433"],"PO":["565136"]},"128886":{"abstract":"Through a collaboration between the University of Kentucky, the University of Colorado at Denver, Rochester Institute of Technology, and cooperation with NCAR, a next generation wiland fire system is being created based on dynamic data-driven application system (DDDAS) principles.<br\/><br\/>A variety of sensors are used, from stationary sensors on the ground to sensors in satellites or attached to airplanes flying overhead. The use of the sensors changes with little warning and cannot be predicted in advance. Models change dynamically based on sensor networks. A dynamic execution environment is essential for acquiring the data, running a multi-model application, and pushing the results to the right places at the right times securely and robustly while still being simple enough for non-computer experts to operate the complex system while on a mountainside during stressful conditions.<br\/><br\/>The sensors used are reprogrammed in the field. New mathematical methods are being developed to change running simulation of a highly nonlinear system with coherent features in response to data and also controls sensors. The project employs virtual Grid technology in the computational environment.<br\/><br\/>Tens of billions of dollars in property and infrastructure burn up or are severely damaged every year due to wildfires.<br\/>The peak areas are not just low population density areas in Colorado and Montana, but include areas near large population areas and national labs in California, Florida, Georgia, Texas, New Mexico, and Oklahoma. Commerce is affected through disruptions of transportation of goods and loss of jobs.","title":"CSR-CSI: Collaborative Research: Dynamic Sensor\/Computation Network for Wildfire Management","awardID":"0719626","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["448331"],"PO":["535244"]},"126466":{"abstract":"0708232<br\/><br\/>CRI: Reconfigurable High Performance Cluster Computing and Medical Engineering Applications<br\/><br\/>Chengzhong Xu<br\/><br\/>The goal of this project is to develop a reconfigurable high performance and energy efficient networked computing solution for a variety of Internet services and real-time medical engineering applications. A cluster of multi-core servers is constructed as a reconfigurable distributed virtual machine (DVM) to provide a shared computing resource in support of multi-disciplinary research at Wayne State University, including in particular, the following activities: (1) development of resource management technologies for high performance and energy efficient computing; (2) development of hybrid storage systems for data-intensive applications in server clusters; (3) development of bandwidth efficient resource management techniques for scalable streaming services; (4) development of algorithms for fast and accurate port placement and arm positioning in robotic surgery; and (5) real-time anesthesia planning, diagnosis, and decision support. <br\/><br\/>This project leverages the success of the targeted research activities. The systems research develops novel resource management technologies with respect to processing power, memory\/storage, network-I\/O bandwidth, and energy efficiency. The medical engineering applications require intense computations and entail retrieving and processing of large amounts of data. The research activities share the requirements of real-time and high assurance processing. DVM facilitates experimental evaluation of new resource management technologies and make it possible to experiment with various design choices in applications and to study the impacts of and the interactions among many important factors in reasonable times. The DVM solution also advances medical information processing and patient treatments to a new level of timeliness and accuracy.","title":"CRI: Reconfigurable High Performance Cluster Computing and Medical Engineering Applications","awardID":"0708232","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["509467","451038","383956",335517,"518050"],"PO":["564778"]},"129502":{"abstract":"Wireless sensor networks have the potential to revolutionize research areas and<br\/>industries that require the distributed collection and aggregation of data,<br\/>e.g., civil engineering, biology, and geology. However, to date their impact<br\/>has fallen short of this potential. This is not surprising; wireless sensor<br\/>networks are difficult to design and program. Experts in application domains<br\/>such as biology and civil engineering have neither the training in embedded<br\/>system programming and design required to develop adequate wireless sensor<br\/>networks, nor the time or inclination to become embedded systems designers.<br\/>For wireless sensor networks to live up to their potential, they must be easy<br\/>for application experts to design and program instead of requiring embedded<br\/>systems design expertise.<br\/><br\/>This project seeks to put wireless sensor network design and deployment within<br\/>the reach of applications experts. This project will identify a small set of<br\/>application archetypes, described in terms meaningful to application<br\/>developers, that capture the most common application structures. Each<br\/>archetype will be backed by a compilable specification written in a simple<br\/>high-level archetype-specific language. After customization, a specification<br\/>will be passed to a synthesis algorithm to produce a working hardware-software<br\/>system. Synthesis of efficient wireless sensor networks would be intractable<br\/>without an appropriate hardware-software platform. Therefore, this project<br\/>will also determine the particular types of hardware and software components<br\/>necessary to enable support for wide range of archetypes. A configurable<br\/>hardware-software platform will be developed based on these findings.","title":"Collaborative Research: NeTS-NOSS: Sensor Network Synthesis - Opening the Use of Wireless Sensor Networks to Application Experts","awardID":"0721926","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["421837"],"PO":["564777"]},"129513":{"abstract":"Proliferation of wireless networks has dramatically changed the way we live and work. However, wireless innovation and deployment has been blocked by the spectrum shortage problem as a result of today's static spectrum assignment. While most spectrum bands have been allocated to existing wireless networks and technologies, they are severely under-utilized. <br\/>This research will seek to improve spectrum utilization using dynamic spectrum access. In this new system, components of future wireless networks no longer have statically assigned spectrum. Instead, they request spectrum on-demand matching their time-varying demand and pay for what they use. To exploit the full potential of dynamic spectrum access, this research will focus on developing an efficient spectrum auction system which auctions spectrum periodically to wireless nodes and dynamically assign spectrum to minimize interference. Moving away from traditional centralized solutions, this project focuses on distributed auction system to manage large volume of spectrum requests across large geographic areas. <br\/>The success of this project will advance understanding in dynamic spectrum access systems, and impact development of cognitive radios and future wireless networks. The educational impacts of the project include integration of research with interdisciplinary training programs at both undergraduate and graduate levels.","title":"WN: Real-Time Spectrum Auctioning Through Distributed Coordination","awardID":"0721961","effectiveDate":"2007-09-01","expirationDate":"2009-08-31","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7731","name":"OTHER GLOBAL LEARNING & TRNING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["536698","551126"],"PO":["434241"]},"127456":{"abstract":"IIS - 0713290 <br\/>Wu, Harris <br\/>Old Dominion University Research Foundation <br\/>III-COR ollaborative Classification of Large, Growing Collections <br\/><br\/>This proposal addresses the problem of exploring large digital collections or primarily non-textual content to make them more useable and useful, by allowing users to collectively develop a faceted classification system and then to populate the schema (system). The proposal seeks to implement this collaborative classification system on a subset of the federated US Government Photographs and Multimedia Collection, and then to perform a series of comprehensive evaluation activities that look at various indicators of success for the project. The primary contributions of the project are expected to be new user interfaces, open source tools, algorithms and schemes for automated classification. These resources will be made available for use by others.","title":"III-COR: Collaborative Classification of Large, Growing Collections with Evolving Facets","awardID":"0713290","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"8010","name":"Computing in the Cloud"}}],"PIcoPI":[338005,"345726","555190"],"PO":["565136"]},"129403":{"abstract":"In this project we explore the vulnerabilities inherent to and countermeasures appropriate for evolving telecommunications networks. We perform a broad study of the availability, integrity and confidentiality of telecommunications networks via formal analysis, gray-box testing, and simulation. We characterize countermeasures addressing attacks on these communication properties. We are working to integrate the solutions created in this work with existing telecommunications and IP networks and communication systems. In so doing, we provide protection for critical pieces of national communications infrastructure while allowing users to receive the full benefits from interconnected voice and data systems.<br\/><br\/>We are producing: 1) realistic threat and adversary models, 2) a taxonomy of vulnerabilities in current and next generation cellular networks, 3) techniques to identify and characterize vulnerabilities in these systems, 4) domain specific and general detection and mitigation strategies and their inherent tradeoffs and 5) solutions integrated the into current telecommunications infrastructure, public networks and end devices.<br\/><br\/>The work allows telecommunications networks to continue to provide for critical communication in times of normal and emergency use while enabling increased connectivity to third party data networks such as the Internet. We are leveraging our relationships with industry and regulatory and standards bodies to ensure that the techniques arising from this work are brought to the attention of Internet and telecommunications providers.","title":"NeTS WN: Protecting Services for Emerging Wireless Telecommunications Infrastructure","awardID":"0721579","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["518380","521556","547471"],"PO":["565090"]},"129524":{"abstract":"This research project establishes a permanent Spectrum Observatory in Chicago to monitor and support the analysis of spectrum usage for a three-year period. This observatory is supplemented by a mobile spectrum occupancy platform to nomadically examine various target cities to both explore \"unused spectrum\" and in Chicago to validate the fixed observatory readings as representative measurements for the city. Selected suburban and rural measurements are performed to expand the understanding of the differences in spectrum usage in these environments. The research focuses on: 1) obtaining the occupancy data, 2) analyzing the anomalies and trends in the data, and 3) examining the opportunities for improved spectral utilization suggested by the observed usage patterns. <br\/><br\/>This grant supports collaborative research across and between academia, industry, and government entities. The research impacts: 1) transceiver designers, 2) cognitive radio researchers, 3) spectrum owners and stakeholders, 4) engineering students and faculty, and 5) regulators. The greatest impact of this information may be to U.S. government communications policy. Currently, information on spectrum occupancy is spotty at best, leading to worst-case analysis, conservative policies, and poor utilization of the scare spectrum resource. Emerging telecommunication technologies require a vastly improved understanding of spectrum utilization and trends to be effective. This Spectrum Observatory serves as the basis for spectrum forecasting that is crucial for the successful broad scale deployment of cognitive radio systems, new wireless devices, and networks. Finally, this study provides a very useful academic platform for graduate and undergraduate courses in wireless communication networks.","title":"NeTS - WN - Spectrum Observatory System","awardID":"0722003","effectiveDate":"2007-09-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["353259",343207,"52879","560175","560174",343211],"PO":["557315"]},"127346":{"abstract":"Project Title: Knowledge Compilation with Fast Response<br\/>PIs: <br\/><br\/>This project is concerned with the development, maintenance, and <br\/>utilization of index structures -- reduced implicate tries <br\/>(ri-tries) -- that answer logical queries of large databases. <br\/>The primary goals of this project are further development of ri-tries, <br\/>identification and classification of databases for which these tries <br\/>will be effective, and development of computer systems that implement <br\/>ri-tries.<br\/><br\/>A reduced implicate trie is a data structure for storing a propositional <br\/>database on a computer. Fast responses to queries are enabled by <br\/>making it easy to determine consequences -- queries with yes answers -- <br\/>of the database. Technically, once a database has been compiled into <br\/>an ri-trie, the response time to any query is guaranteed to be linear <br\/>in the size of the query, regardless of the size of the compiled <br\/>database. This response time represents a trade-off between <br\/>performance and space, since ri-tries may be large. A central focus <br\/>of this project will be determining what types of databases lend themselves <br\/>to ri-tries. This will be accomplished through experimentation and <br\/>through theoretical developments.<br\/><br\/>A prototype system that compiles logical formulas into ri-tries and <br\/>a query processing module will be developed. Initially, the system<br\/>will be designed for databases in conjunctive normal form; in the <br\/>longer term, any formula from propositional logic will be acceptable <br\/>input. The query processor will be designed to accept clauses as input, <br\/>since a clause is the typical form for a query. Students at the University <br\/>of New Haven and at SUNY at Albany will be active participants.<br\/><br\/><br\/>Broader Impacts of the Proposed Activity<br\/><br\/>The RUI component of this project will be extensive participation <br\/>by undergraduates at the University of New Haven. Students will be <br\/>introduced to the basic ideas of automated deduction and knowledge <br\/>compilation and will work on the prototype system. The goal is to <br\/>inspire students by engaging them in real research that contributes <br\/>to real publications. The PI is committed to attracting talented <br\/>young men and women into mathematics and computer science and to <br\/>preparing them for graduate school. The University at Albany has a <br\/>strong graduate program in computer science, and the PI at Albany <br\/>is committed to preparing students for careers in research.<br\/><br\/>Project Web Page: http:\/\/www.cs.albany.edu\/~nvm\/ritries\/<br\/>Erik Rosenthal's Web Page: http:\/\/www.newhaven.edu\/show.asp?durki=1623<br\/>Neil Murray's Web Page: http:\/\/www.cs.albany.edu\/~nvm\/","title":"III-COR: Collaborative Research: Knowledge Compilation with Fast Response","awardID":"0712752","effectiveDate":"2007-09-15","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[337750],"PO":["560586"]},"125168":{"abstract":"This research aims to develop the foundations for a new approach to quantum computing based on coherently controlling a solid-state spin system. The key feature is to use an electron\/nuclear spin system and to take the best from each. Nuclear spins make great qubits since they have long coherence times, but they are difficult to prepare and readout. Electron spins can be prepared in well-defined computational states and individual electron spin readout has been demonstrated. So, the new approach employs the electron spin for state preparation and readout, but the nuclear spins are the qubits. <br\/>The development of these electron\/nuclear control methods will be enabling of a new class of solid-state quantum information processors and have relevance to quantum dots, spintronics and other electron\/nuclear spin approaches to quantum computation, communication, sensors and actuators.<br\/><br\/>The element that makes this approach viable is the mediation of nuclear\/nuclear coherent spin gates via the anisotropic hyperfine interaction. The direct dipolar nuclear\/nuclear spin interactions are typically slow, generally a few kHz, however the electron\/nuclear spin interaction, the hyperfine coupling, can be quite large, up to a few 100 MHz, and this provides a means of rapid information exchange between electron and nuclear spin systems. The anisotropic hyperfine interaction also enables nuclear\/nuclear gates. In the presence of the anisotropic hyperfine interaction the quantization axis of the nuclear spin is not static: It changes depending on the state of the electron spin. The control space of the nuclear spin is thus far richer than has been explored for either electron or nuclear spins alone. This research will both develop the theory of such electron\/nuclear control methods and experimentally demonstrate them.","title":"Electron Mediated Quantum Computing with Nuclear Spins","awardID":"0702295","effectiveDate":"2007-09-15","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":[332141],"PO":["565272"]}}